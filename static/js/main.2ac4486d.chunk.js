(this["webpackJsonpcomposite-visualizations"]=this["webpackJsonpcomposite-visualizations"]||[]).push([[0],{227:function(e){e.exports=JSON.parse('{"A. Dalpke":false,"A. Johannes Pretorius":false,"A. Wentzel":false,"Aaron Ault":false,"Aaron Barsky":false,"Aaron Knoll":false,"Aaron Striegel":false,"Abish Malik":false,"Abishek Puri":false,"Acar Tamersoy":false,"Adam Bodnar":false,"Adam Jur\u010d\xedk":false,"Adam Perer":false,"Adam Sah":false,"Adel Ahmed":false,"Aditya Kalro":false,"Adrian Maries":false,"Agn\xe8s Braud":false,"Agus Sudjianto":false,"Ahmad M. Abusalah":false,"Ahsan Qamar":false,"Aidan Slingsby":false,"Aidong Lu":false,"Airong Luo":false,"Akhilesh Camisetty":false,"Alan Lez":false,"Alan M. MacEachren":false,"Alan Ratner":false,"Alark Joshi":false,"Alberto Gonzalez":false,"Alberto S\xe1nchez":false,"Alex Endert":false,"Alex Godwin":false,"Alex Kale":false,"Alexander Eiselmayer":false,"Alexander Erath":false,"Alexander Kachkaev":false,"Alexander Kumpf":false,"Alexander Lex":false,"Alexander M. Rush":false,"Alexander Rind":false,"Alexander Savelyev":false,"Alexander Soen":false,"Alexander Wiebel":false,"Alexandra Lee":false,"Alexandru Romosan":false,"Alexis Kai-Hon Lau":false,"Alexis Pister":false,"Ali K. Al-Awami":false,"Ali Sarvghad":false,"Alice Chu":false,"Alice Thudt":false,"Alina Gvozdik":false,"Alistair D. M. Dove":false,"Alla Zelenyuk":false,"Allan Hanbury":false,"Alon Y. Halevy":false,"Alper Sarikaya":false,"Alvar Vinacua":false,"Alvitta Ottley":false,"Amanda Randles":false,"Amelio V\xe1zquez Reina":false,"Amin Abbasloo":false,"Amin Jourabloo":false,"Amir Hossein Hajizadeh":false,"Amy K. Karlson":false,"Ana Jofre":false,"Anastasia Bezerianos":false,"Anbang Xu":false,"Anders Ynnerman":false,"Andrada Tatu":false,"Andrea Gomes Campos Bianchi":false,"Andrea Unger":false,"Andreas Ammer":false,"Andreas Bannach":false,"Andreas Kerren":false,"Andreas M\xfcller":false,"Andreas Rauber":false,"Andreas Stoffel":false,"Andreas Thom":false,"Andreas Walch":false,"Andres Lalama":false,"Andrew Burks":false,"Andrew E. Johnson":false,"Andrew J. Hanson":false,"Andrew J. Solis":false,"Andrew Mercer":false,"Andrew T. Wilson":false,"Andrew Vande Moere":false,"Andr\xe9s Monroy-Hern\xe1ndez":false,"Angela H. DePace":false,"Angela Mayhua":false,"Angela Mellema":false,"Angela Nyhout":false,"Angelos Chatzimparmpas":false,"Angus G. Forbes":false,"Angus Graeme Forbes":false,"Anjul Tyagi":false,"Anna A. Shaverdian":false,"Anna Gogolou":false,"Anna MacKay-Brandt":false,"Anna Tikhonova":false,"Anna Vilanova":false,"Anne E. Carpenter":false,"Anne Laprie":false,"Anne Mai Wassermann":false,"Annette Haworth":false,"Anqi Cao":false,"Anshul Vikram Pandey":false,"Anthony C. Robinson":false,"Anthony K. H. Tung":false,"Antoine Lambert":false,"Antonello Moneta":false,"Antoni Sagrist\xe0":false,"Antonios Somarakis":false,"Anuj R. Jaiswal":false,"Anushka Anand":false,"Anzu Hakone":false,"Aoyu Wu":false,"Arie E. Kaufman":false,"Arin M. Ellingson":false,"Aritra Dasgupta":false,"Arjun Srinivasan":false,"Arlen Fan":false,"Arnaud Prouzeau":false,"Arnaud Sallaberry":false,"Arno Kr\xfcger":false,"Arpit Narechania":false,"Artem Amirkhanov":false,"Artem Sokolov":false,"Arthur G. Erdman":false,"Arthur G. Telea":false,"Arthur R. A. Bouwman":false,"Arun Reddy Nelakurthi":false,"Arvind Satyanarayan":false,"Ashish Kapoor":false,"Atul Rungta":false,"Audra Buck-Coleman":false,"Audrey Bowerman":false,"Austin H. Patton":false,"Avin Pattath":false,"Avital Steinitz":false,"Aviv Madar":false,"Awalin Sopan":false,"Axel J. Soto":false,"Ayan Biswas":false,"Azam Khan":false,"B. Elgohari":false,"B. L. William Wong":false,"Bahador Saket":false,"Baining Guo":false,"Baoquan Chen":false,"Barbora Kozl\xedkov\xe1":false,"Barry Drake":false,"Barry J. Dickson":false,"Bart M. ter Haar Romeny":false,"Basak Alper":false,"Been Kim":false,"Bei Wang":false,"Ben Eysenbach":false,"Ben Maule":false,"Ben Shneiderman":false,"Ben Torkian":false,"Benedikt Stehno":false,"Benjamin B. Bederson":false,"Benjamin Bach":false,"Benjamin Holland":false,"Benjamin H\xf6ferlin":false,"Benjamin Lee":false,"Benjamin P. Bowen":false,"Benjamin Rowland":false,"Benjamin Schindler":false,"Benjamin T. Readshaw":false,"Benjamin Tyner":false,"Benjamin Watson":false,"Benno Stein":false,"Berk Geveci":false,"Bernd Froehlich":false,"Bernhard Jenny":false,"Bernhard Kainz":false,"Bernhard Preim":false,"Bertjan Broeksema":false,"Bettina Speckmann":false,"Bharath Kalidindi":false,"Bilal Alsallakh":false,"Bill Howe":false,"Billy Cheung":false,"Bin Wang":false,"Bin Zhu":false,"Bing Ni":false,"Bing Wang":false,"Binghan Xu":false,"Bj\xf6rn Hartmann":false,"Bj\xf6rn Kr\xfcger":false,"Bo Hyoung Kim":false,"Bo Qiao":false,"Bonan Li":false,"Bongshin Lee":false,"Boris M\xfcller":false,"Boudewijn P. F. Lelieveldt":false,"Boudewijn P.F. Lelieveldt":false,"Bowen Yu":false,"Boyd Kenkhuis":false,"Boyu Wang":false,"Bram C. M. Cappers":false,"Bram Platel":false,"Brant Peterson":false,"Brian C. Van Essen":false,"Brian D. Bue":false,"Brian D. Fisher":false,"Brian Horst":false,"Brian N. Wylie":false,"Brian Summa":false,"Bridger Herman":false,"Bridget Moynihan":false,"Bruno Gon\xe7alves":false,"Bruno L\xe9vy":false,"Bruno Pinaud":false,"Bryan Chan":false,"Bryan Genest":false,"Bryan McDonnel":false,"Bryan Mehta":false,"Bum Chul Kwon":false,"C.D. Fuller":false,"Cagatay Turkay":false,"Caitlin Gutheil":false,"Caleb Robinson":false,"Carey L. Williamson":false,"Carissa Mai-Ping Knipe":false,"Carlos D. Correa":false,"Carlos Eduardo Scheidegger":false,"Carlos J. Felix":false,"Carolina Nobre":false,"Carolina Ruiz":false,"Caroline Ziemkiewicz":false,"Carson Brownlee":false,"Carsten Dachsbacher":false,"Carsten G\xf6rg":false,"Cassiano Sugiyama":false,"Caterina Rosano":false,"Catherine Plaisant":false,"Cecilia R. Aragon":false,"Cesar Palomo":false,"Chad A. Steed":false,"Chad Jones":false,"Chaitanya Chandurkar":false,"Chandan K. Reddy":false,"Chandrakant D. Patel":false,"Changhong Zhang":false,"Changhyun Lee":false,"Changjian Chen":false,"Chaoguang Lin":false,"Chaoli Wang":false,"Chaomei Chen":false,"Charilaos Papadopoulos":false,"Charl P. Botha":false,"Charles D. Stolper":false,"Charles Gueunet":false,"Charles L. Feldman":false,"Charles Perin":false,"Chat Wacharamanotham":false,"Chelsea S. Yeh":false,"Cheng Tang":false,"Cheng Zheng":false,"Chengbo Zheng":false,"Chenyang Ji":false,"Cheryl Z. Qian":false,"Chi-Chun Pan":false,"Chi-Lun Lin":false,"Chi-Wing Fu":false,"Ching-Shan Chou":false,"Ching-Yung Lin":false,"Chittayong Surakitbanharn":false,"Chongxuan Li":false,"Chris Brunsdon":false,"Chris Bryan":false,"Chris Muelder":false,"Chris North":false,"Chris P. Gale":false,"Chris R. Johnson":false,"Chris Weaver":false,"Christian Dick":false,"Christian D\xf6ring":false,"Christian Heine":false,"Christian Luksch":false,"Christian Partl":false,"Christian P\xf6litz":false,"Christian Rohrdantz":false,"Christian Scheible":false,"Christian Tominski":false,"Christina Stoiber":false,"Christof Seeger":false,"Christoph Flamm":false,"Christoph Hafemeister":false,"Christoph Heinzl":false,"Christoph Kubisch":false,"Christoph Peters":false,"Christophe Hurter":false,"Christophe Mion":false,"Christophe Viau":false,"Christopher Andrews":false,"Christopher Collins":false,"Christopher Gates":false,"Christopher P. Diehl":false,"Christopher Wood":false,"Christopher deFilippi":false,"Chufan Lai":false,"Cindy Grimm":false,"Claudia M\xfcller-Birn":false,"Claudio Silva":false,"Clemens Arbesser":false,"Clemens H. Cap":false,"Cl\xe1udio T. Silva":false,"Cody Dunne":false,"Colin Swindells":false,"Colin Ware":false,"Cong Guo":false,"Cong Liu":false,"Cong Xie":false,"Conglei Shi":false,"Corrado Cal\xec":false,"Cristian Felix":false,"Cristina Nita-Rotaru":false,"Cullen Bash":false,"Cydney B. Nielsen":false,"D. Archambault":false,"D. Vock":false,"Daisaku Yokoyama":false,"Daisuke Sakurai":false,"Dajian Liu":false,"Dan Goldwasser":false,"Dan Gruen":false,"Dan Imre":false,"Dan Maljovec":false,"Dan Man\xe9":false,"Dan Zhang":false,"Dane M. Coffey":false,"Dang Tuan Nhon":false,"Daniel A. Keim":false,"Daniel A. Kern":false,"Daniel Archambault":false,"Daniel F. Keefe":false,"Daniel Fink":false,"Daniel Haehn":false,"Daniel J. Wigdor":false,"Daniel J\xf6nsson":false,"Daniel Keim":false,"Daniel M. Dunlavy":false,"Daniel M. Russell":false,"Daniel Nascimento":false,"Daniel Olson":false,"Daniel Orban":false,"Daniel Plakinger":false,"Daniel R. Tesone":false,"Daniel Seebacher":false,"Daniel Smilkov":false,"Daniel W. Archambault":false,"Daniel Weiskopf":false,"Daniela Oelke":false,"Daniela Ushizima":false,"Daniele Quercia":false,"Danny Holten":false,"Danqing Shi":false,"Danyel Fisher":false,"Darrel Palke":false,"David Bailey":false,"David Borland":false,"David Duran":false,"David F. Tate":false,"David Fyfe":false,"David G. C. Hildebrand":false,"David Gotz":false,"David H. Laidlaw":false,"David H. Rogers":false,"David H. S. Chung":false,"David J. Duke":false,"David J. Israel":false,"David J. Nuckley":false,"David Koop":false,"David Lazer":false,"David Lloyd":false,"David M. Krum":false,"David M. Mountain":false,"David Patrone":false,"David S. Ebert":false,"David Saffo":false,"David Scarlatti":false,"David Schroeder":false,"David Schroh":false,"David Spretke":false,"David Uribe":false,"David Van Riper":false,"David W. Sprague":false,"Dawei Cheng":false,"Dazhen Deng":false,"Deborah Silver":false,"Debprakash Patnaik":false,"Denis Gracanin":false,"Denis Kalkofen":false,"Denis Lalanne":false,"Denis Larkin":false,"Dennis Chau":false,"Dennis D. Spencer":false,"Dennis Dingen":false,"Dennis Thom":false,"Derek Stephens":false,"Derek Swingley":false,"Deryck Holdsworth":false,"Desney S. Tan":false,"Devin Singh":false,"Dhiraj Barnwal":false,"Di Wang":false,"Di Weng":false,"Diane Tang":false,"Dianne Cook":false,"Diansheng Guo":false,"Diem Tran":false,"Dieter Schmalstieg":false,"Dieter W. Fellner":false,"Dik Lun Lee":false,"Dilip Krishnan":false,"Dimitrios Papadopoulos":false,"Dimitris Mitsouras":false,"Dino Pedreschi":false,"Dirk J. Lehmann":false,"Dmitriy Morozov":false,"Dogan Demir":false,"Dominic Schneider":false,"Dominik J\xe4ckle":false,"Dominik Moritz":false,"Dominik Sacha":false,"Dominikus Baur":false,"Donald J. Jacobs":false,"Dong Hyun Jeong":false,"Dong Sun":false,"Donghao Ren":false,"Dongjin Choi":false,"Dongming Han":false,"Dongshi Xu":false,"Dongyu Liu":false,"Donna Peuquet":false,"Dora Kiesel":false,"Doris Dransch":false,"Doug A. Bowman":false,"Doug Fritz":false,"Drew Skau":false,"Duen Horng Chau":false,"Duen Horng Polo Chau":false,"Dustin Scheinost":false,"Dylan Cashman":false,"E. Wes Bethel":false,"E. Yanli":false,"Eamonn Maguire":false,"Edward Choi":false,"Edward J. Coyle":false,"Edwin Puttmann":false,"Edyta P. Bogucka":false,"Elaine Huynh":false,"Eli T. Brown":false,"Elizabeth Braunstein":false,"Elizabeth H. Keating":false,"Elizabeth Munch":false,"Elke A. Rundensteiner":false,"Ellen Gasparovic":false,"Elmar Eisemann":false,"Elsie Lee":false,"Emanuele Santos":false,"Emily R. Miraldi":false,"Emily Wall":false,"Emmanuel Pietriga":false,"Emmy-Charlotte F\xf6rster":false,"Enrico Bertini":false,"Enya Shen":false,"Enylton Machado Coelho":false,"Erdem Kaya":false,"Eren Cakmak":false,"Erez Zadok":false,"Eric C. Alexander":false,"Eric D. Ragan":false,"Eric E. Monson":false,"Eric Lecolinet":false,"Eric P. Hoffman":false,"Eric SanJuan":false,"Eric Sauda":false,"Eric T. Stanton":false,"Erich Gstrein":false,"Erich P. Stuntebeck":false,"Erik W. Anderson":false,"Erik-Jan van der Linden":false,"Ernesto A. Bjerg":false,"Ethan R. Deyle":false,"Eugene Zhang":false,"Eun Ju Nam":false,"Evan A. Suma":false,"Evanthia Dimara":false,"Eveline H. J. Mestrom":false,"Eytan Adar":false,"Fabian Beck":false,"Fabian Fischer":false,"Fabian G. Beck":false,"Fabian Maass":false,"Fabian Sperrle":false,"Fabiano Petronetto":false,"Fabio Dias":false,"Faisal Taher":false,"Falk Schreiber":false,"Fan Du":false,"Fan Hong":false,"Fang-Xin Ou-Yang":false,"Fangfang Sheng":false,"Fangfang Zhou":false,"Fangzhao Wu":false,"Fangzhou Guo":false,"Fanny Chevalier":false,"Faraz Zaidi":false,"Fatih Korkmaz":false,"Fedor Korsakov":false,"Fei Wang":false,"Fei Wu":false,"Feiran Wu":false,"Felesia Stukes":false,"Felix Brodkorb":false,"Feng Luo":false,"Feng Wang":false,"Fenjin Ye":false,"Fereshteh Amini":false,"Fernanda B. Vi\xe9gas":false,"Fernanda Vi\xe9gas":false,"Fernando Vieira Paulovich":false,"Fidelia Ibekwe-Sanjuan":false,"Filip Sadlo":false,"Finale Doshi-Velez":false,"Firdaus Janoos":false,"Flavie Cernesson":false,"Florence Le Ber":false,"Florian Grassinger":false,"Florian Heimerl":false,"Florian Mansmann":false,"Florian Spechtenhauser":false,"Florian Stoffel":false,"Fosca Giannotti":false,"Francesca Samsel":false,"Francine Chen":false,"Francis Kilian":false,"Frank J. Rybicki":false,"Frank Keul":false,"Frank Kr\xfcger":false,"Frans Vos":false,"Fred Hohman":false,"Fred Olislagers":false,"Frederik L. Dennig":false,"Frederik Seiffert":false,"Frits H. Post":false,"Frits Koning":false,"Fritz Gschwantner":false,"Fritz Lekschas":false,"Fr\xe9d\xe9ric Gilbert":false,"Fuling Sun":false,"Fuqu Wu":false,"Furu Wei":false,"Furui Cheng":false,"F\xe1bio Miranda":false,"G. Canahuate":false,"G. David Richardson":false,"G. Elisabeta Marai":false,"G. Scheuermann":false,"G.E. Marai":false,"Gabor Heinemann":false,"Gabriela Ferracutti":false,"Galileo Namata":false,"Garnett Carl Wilson":false,"Gary K. L. Tam":false,"Gennady Andrienko":false,"Gennady L. Andrienko":false,"George Chin Jr.":false,"George G. Robertson":false,"George Michailidis":false,"George Sugihara":false,"Georgia Albuquerque":false,"Gerald M. Pao":false,"Gerald Penn":false,"Gerik Scheuermann":false,"Gero Strau\xdf":false,"Gianmaria Silvello":false,"Ginette Wessel":false,"Giuseppe Di Battista":false,"Giuseppe Santucci":false,"Glenn Taylor":false,"Gokhan Sever":false,"Gonzalo Ramos":false,"Graziano Blasilli":false,"Greg Abram":false,"Greg Smith":false,"Gregory Abram":false,"Gregory D. Abowd":false,"Gregory Guterman":false,"Gregory P. Johnson":false,"Gromit Yeuk-Yin Chan":false,"Guang Lin":false,"Guangchen Ruan":false,"Guangliang Chen":false,"Guido Granato":false,"Guido Reina":false,"Guido Tack":false,"Guillaume Favelier":false,"Gunther H. Weber":false,"Gunther Heidemann":false,"Guodao Sun":false,"Guoning Chen":false,"Guowei Huang":false,"Guy Danon":false,"Guy Melan\xe7on":false,"G\xfcnter Bl\xf6schl":false,"H. Elhalawani":false,"H. V. Jagadish":false,"Haejin Jeong":false,"Haekyu Park":false,"Haesun Park":false,"Haeyong Chung":false,"Haibin Liu":false,"Haidong Chen":false,"Haidong Zhang":false,"Haipeng Zeng":false,"Haiyan Yang":false,"Halld\xf3r Janetzko":false,"Hamish A. Carr":false,"Han Hong":false,"Han-Wei Shen":false,"Haneen Mohammed":false,"Hanghang Tong":false,"Hangzai Luo":false,"Hanna Sch\xe4fer":false,"Hannah Kim":false,"Hanqi Guo":false,"Hans-J\xf6rg Schulz":false,"Hans-Peter Seidel":false,"Hanseung Lee":false,"Hanspeter Pfister":false,"Hao Dong":false,"Hao Wei":false,"Hao Yang":false,"Hao Zhou":false,"Haohui Chen":false,"Haolin Zhi":false,"Haoling Dong":false,"Haoyu Li":false,"Harald Bosch":false,"Harald Piringer":false,"Harinarayan Krishnan":false,"Harish Doraiswamy":false,"Harlan Foote":false,"Harris Lewin":false,"Harry Stavropoulos":false,"Harry Yeh":false,"Harshit Mehrotra":false,"Hartmut Ziegler":false,"Hayder Mahdi AI-maneea":false,"He Huang":false,"He Xiao":false,"Heather Lipford":false,"Heidi Lam":false,"Heidi Werner":false,"Heidrun Schumann":false,"Heike Hofmann":false,"Heike Leitte":false,"Helmut Doleisch":false,"Helwig Hauser":false,"Hendrik Strobelt":false,"Hendrikus H. M. Korsten":false,"Henning Wachsmuth":false,"Henry V\xf6lzke":false,"Henryk Dobslaw":false,"Heungseok Park":false,"Hilko Cords":false,"Hiroaki Natsukawa":false,"Ho Van Quan":false,"Hoi Ying Tsang":false,"Holger Steeb":false,"Holger Stitz":false,"Holger Theisel":false,"Hong Wang":false,"Hong Zhou":false,"Honghui Mei":false,"Hongsen Liao":false,"Hongwei Li":false,"Hongye Liang":false,"Hongyuan Zha":false,"Hossam Sharara":false,"Hossein Siadati":false,"Houda Lamqaddam":false,"Hrvoje Ribicic":false,"Hsiang-Yun Wu":false,"Hua Guo":false,"Huamin Qu":false,"Hui Zhang":false,"Huihua Guan":false,"Hujun Bao":false,"Huub van de Wetering":false,"Huy T. Vo":false,"Hyejin Im":false,"Hyungsuk Choi":false,"Hyunjoo Song":false,"Hyunmo Kang":false,"Ian Bowman":false,"Ian Gorton":false,"Ian M. Thornton":false,"Ievgeniia Gutenko":false,"Ignacio Ponzoni":false,"Igor Jurisica":false,"Ines F\xe4rber":false,"Ingo Wald":false,"Isaac Cho":false,"Ismail Demir":false,"Iulian Peca":false,"Ivan Koles\xe1r":false,"Ivan Viola":false,"Ivo L. Hofacker":false,"Iwan W. Griffiths":false,"J. Alex Godwin":false,"J. Edward Swan":false,"J. Gunther":false,"J. Jeffers":false,"J. T. Fry":false,"J. Xavier Prochaska":false,"Jacheng Pan":false,"Jack Pegg":false,"Jacky Yuan":false,"Jadran Vrabec":false,"Jaebum Kim":false,"Jaegul Choo":false,"Jaemin Jo":false,"Jaeseok Huh":false,"Jaeyeon Kihm":false,"Jai Y. Yu":false,"Jaime Montemayor":false,"Jamal Alsakran":false,"James A. Sethian":false,"James Davey":false,"James J. Thomas":false,"James O\'Brien":false,"James P. Ahrens":false,"James Shearer":false,"James T. Klosowski":false,"James Tompkin":false,"James Wexler":false,"Jamie Dyer":false,"Jamie Morgenstern":false,"Jan By\u0161ka":false,"Jan C. van Gemert":false,"Jan Mi\u010dan":false,"Janu Verma":false,"Jared Hoberock":false,"Jarke J. van Wijk":false,"Jason A. Laska":false,"Jason Alexander":false,"Jason D. Williams":false,"Jason Dalton":false,"Jason Dykes":false,"Jason Leboe-McGowan":false,"Jason Leigh":false,"Javier Bescos":false,"Jay Koven":false,"Jay Summet":false,"Jayaraman J. Thiagarajan":false,"Jean Krivine":false,"Jean Villerd":false,"Jean-Daniel Fekete":false,"Jean-Fran\xe7ois Im":false,"Jeff Klingner":false,"Jeff Lichtman":false,"Jefferson Amstutz":false,"Jeffrey Baumes":false,"Jeffrey Heer":false,"Jeffrey T. Morisette":false,"Jen Rogers":false,"Jennifer Frazier":false,"Jennifer L. Gardy":false,"Jennifer L. Horsman":false,"Jennis Meyer-Spradow":false,"Jens-Peter Kreiss":false,"Jeongjin Lee":false,"Jeremiah Duncan":false,"Jeremy Millar":false,"Jeremy de Oliveira-Kumar":false,"Jesse Fugitt":false,"Jessica Hullman":false,"Jessica Peter":false,"Jesus J. Caban":false,"Ji Hwan Park":false,"Ji Lan":false,"Ji Soo Yi":false,"Ji-Hoon Kim":false,"Jia Zeng":false,"Jia-Kai Chou":false,"Jiachen Wang":false,"Jiacheng Pan":false,"Jiahui Chen":false,"Jian Chen":false,"Jian Huang":false,"Jian Ma":false,"Jian Zhang":false,"Jian Zhao":false,"Jianfei Chen":false,"Jiang Wu":false,"Jianguang Weng":false,"Jiannan Xiao":false,"Jianping Fan":false,"Jianping Kelvin Li":false,"Jiawan Zhang":false,"Jiawei Zhang":false,"Jiaxin Bai":false,"Jiaxin Shi":false,"Jiayao Wang":false,"Jiayi Xu":false,"Jiayun Fu":false,"Jiazhi Xia":false,"Jibonananda Sanyal":false,"Jie Bao":false,"Jie Li":false,"Jie Liang":false,"Jie Liu":false,"Jie Lu":false,"Jie Tang":false,"Jieqiong Zhao":false,"Jiewen Lai":false,"Jiexun Li":false,"Jim Davies":false,"Jim Zhu":false,"Jimbo Wilson":false,"Jimeng Sun":false,"Jimmy Johansson":false,"Jin Chen":false,"Jina Huh":false,"Jina Suh":false,"Jing Jin":false,"Jing Ma":false,"Jing Wu":false,"Jing Xia":false,"Jing Yang":false,"Jingmin Chen":false,"Jingrui He":false,"Jinwook Seo":false,"Jinyan Chen":false,"Jir\xed Hladuvka":false,"Jishang Wei":false,"Jo Wood":false,"Joachim Giesen":false,"Joanne Taery Kim":false,"Jocelyn Ng":false,"Jock D. Mackinlay":false,"Joe Bruce":false,"Joe Kohlmann":false,"Joel A. Ferstay":false,"Joel Daniels II":false,"Joel W. Reed":false,"Joerg Meyer":false,"Johann Kastner":false,"Johanna Beyer":false,"Johanna Schmidt":false,"Johannes H\xe4u\xdfler":false,"Johannes Kehrer":false,"Johannes Knittel":false,"Johannes Kuntner":false,"Johannes Sorger":false,"Johannes Weissenb\xf6ck":false,"John A. Greenfield":false,"John Alexis Guerra G\xf3mez":false,"John Allen Crow":false,"John C. Hart":false,"John D. Van Horn":false,"John E. Wenskovitch":false,"John Gerth":false,"John Hardy":false,"John R. Goodall":false,"John Stasko":false,"John T. Stasko":false,"John V. Carlis":false,"Johnny Rodgers":false,"Jonathan Dubois":false,"Jonathan Feinberg":false,"Jonathan J. H. Zhu":false,"Jonathan Komperda":false,"Jonathan Leidig":false,"Jonathan Roberts":false,"Jonathan W. Decker":false,"Jonathan Woodring":false,"Jonathan Woodruff":false,"Jonathan Zhang":false,"Jonathan Zong":false,"Jonghun Park":false,"Joon-Yong Lee":false,"Jordan Swartz":false,"Jorge Estrada":false,"Jorge Piazentin Ono":false,"Jorge Poco":false,"Jorik Blaas":false,"Jorji Nonaka":false,"Jose Manuel Cordero Garcia":false,"Joseph Botros":false,"Joseph F. DeRose":false,"Joseph N. Burchett":false,"Joshua A. Levine":false,"Joshua Shrestha":false,"Josua Krause":false,"Joyce Ma":false,"Jozef B\xe1trna":false,"Judith Muehl":false,"Juhee Bae":false,"Julian Stahnke":false,"Juliana Freire":false,"Julie Gerdes":false,"Julie Lein":false,"Julien Tierny":false,"Jun Tao":false,"Jun Wang":false,"Jun Yuan":false,"Jun Zhu":false,"Jundong Li":false,"Jung-Hong Chuang":false,"Junghoon Chae":false,"Junhai Yong":false,"Junlin Liu":false,"Junpeng Wang":false,"Junping Zhang":false,"Junqi Wu":false,"Junyoung Choi":false,"Juraj Palenik":false,"Juri Buchm\xfcller":false,"Juri F. Buchm\xfcller":false,"Jussi Hakanen":false,"Justin Mauger":false,"Justin Talbot":false,"Justine I. Blanford":false,"J\xf6rn Kohlhammer":false,"J\xf6rn Schneidewind":false,"J\xfcrgen Bernard":false,"J\xfcrgen Lerner":false,"J\xfcrgen Waser":false,"Kai Kang":false,"Kai Lawonn":false,"Kai Xu":false,"Kai Yan":false,"Kai Zhao":false,"Kai-Lun Chung":false,"Kaisa Miettinen":false,"Kalyan Veeramachaneni":false,"Kan Dai":false,"Kang Zhang":false,"Kanit Wongsuphasawat":false,"Kanupriya Singhal":false,"Karen B. Schloss":false,"Karl J. Proctor":false,"Karl J. Runge":false,"Karl Kashofer":false,"Karthik Ramani":false,"Kartik Chanana":false,"Kasper Dinkla":false,"Kasper Hornbaek":false,"Kasper Hornb\xe6k":false,"Katar\xedna Furmanov\xe1":false,"Katerina Vrotsou":false,"Katherine Coles":false,"Katja B\xfchler":false,"Katrien Verbert":false,"Katrin Hegenscheid":false,"Kay Hamacher":false,"Ke Li":false,"Ke Xu":false,"Ke Zhou":false,"Keiji Yamamoto":false,"Keith Clarke":false,"Kejian Zhao":false,"Kejie Yu":false,"Kelei Cao":false,"Kelly M. T. Huffer":false,"Kelly P. Gaither":false,"Kenneth Moreland":false,"Kenneth P. Vives":false,"Kenney Ng":false,"Keshav Dasu":false,"Kevin A. Roundy":false,"Kevin Tate":false,"Kevin Verbeek":false,"Kevin Yager":false,"Khairi Reda":false,"Kim F. Wong":false,"Kim Marriott":false,"Klaus H. Hinrichs":false,"Klaus Mueller":false,"Ko-Chih Wang":false,"Koenraad Brosens":false,"Koji Koyamada":false,"Kostiantyn Kucher":false,"Kresimir Matkovic":false,"Krist Wongsuphasawat":false,"Kristin A. Cook":false,"Kristine Lee":false,"Krist\xedna Z\xe1kop\u010danov\xe1":false,"Krzysztof Z. Gajos":false,"Kun Zhou":false,"Kuno Kurzhals":false,"Kwan-Liu Ma":false,"Kyoung Ho Lee":false,"Lane Harrison":false,"Lars Kuehne":false,"Lars Stegger":false,"Lars-Erik Haug":false,"Laura Monroe":false,"Laura von R\xfcden":false,"Lauren Bradel":false,"Lauren Thorson":false,"Laurent Castanie":false,"Laurent Lessard":false,"Lauro Didier Lins":false,"Lawrence H. Staib":false,"Lawrence T. Glickman":false,"Layne T. Watson":false,"Leanna House":false,"Lei Shi":false,"Leilani Battle":false,"Leland Wilkinson":false,"Len Kne":false,"Lendie Follett":false,"Leni Yang":false,"Leslie M. Blaha":false,"Lexing Xie":false,"Lezhi Li":false,"Li Chen":false,"Li Tan":false,"Li Yu":false,"Li Zhang":false,"Liang Gou":false,"Liang Zhou":false,"Liang-Chi Hsieh":false,"Lijing Lin":false,"Lin Shao":false,"Lin Yan":false,"Ling Xiao":false,"Lingxiao Zhao":false,"Lingyun Yu":false,"Linhao Meng":false,"Lionel M. Ni":false,"Lisa G. Ice":false,"Lisa Kuchy":false,"Lisa Singh":false,"Lise Getoor":false,"Liting Sun":false,"Liu Ren":false,"Long Wang":false,"Lorenz Linhardt":false,"Louis Bavoil":false,"Louise Barrett":false,"Luc Wilson":false,"Luis Gustavo Nonato":false,"Lukas Birn":false,"Luke Harmon":false,"Luke S. Snyder":false,"Lyn Bartram":false,"Lyndsey Franklin":false,"Lynn McVey":false,"M. Andrew Eick":false,"M. Bottinger":false,"M. Chen":false,"M. Eduard Gr\xf6ller":false,"M. Hohn":false,"M. Lieser":false,"M. Marschollek":false,"M. Okan Irfanoglu":false,"M. Petzold":false,"M. Shahriar Hossain":false,"M. Wunderlich":false,"Madelaine Boyd":false,"Madelaine Daianu":false,"Madeleine Grunde-McLaughlin":false,"Magnus Heitzler":false,"Maguelonne Teisseire":false,"Mahbubul Majumder":false,"Mahdi Pakdaman Naeini":false,"Mahima Pushkarna":false,"Mahsa Mirzargar":false,"Mai Elshehaly":false,"Malgorzata Migut":false,"Mal\xfa Castellanos":false,"Maneesh Agrawala":false,"Manish Marwah":false,"Manuel Rubio-S\xe1nchez":false,"Manuel Stein":false,"Manuela Waldner":false,"Mao Ye":false,"Maoyuan Sun":false,"Marc Rautenhaus":false,"Marc Streit":false,"Marcel Hlawatsch":false,"Marcel Worring":false,"Marcel van \'t Veer":false,"Marco Ament":false,"Marco Angelini":false,"Marco Cavallo":false,"Marco Hutter":false,"Marco Jenny":false,"Marcos Lage":false,"Marcus A. Magnor":false,"Marcus Dostie":false,"Marcus Ewert":false,"Margit Pohl":false,"Margo I. Seltzer":false,"Maria Florencia Gargiulo":false,"Maria Luj\xe1n Ganuza":false,"Marian D\xf6rk":false,"Marian Talbert":false,"Marieke E. Ijsselsteijn":false,"Mario Beric":false,"Mario Hlawitschka":false,"Mario Jelovic":false,"Mario Luis Arrieta-Ortiz":false,"Mario Romero":false,"Mark A. Livingston":false,"Mark Borowsky":false,"Mark Gahegan":false,"Mark Last":false,"Mark Sifer":false,"Mark Tautzenberger":false,"Mark W. Jones":false,"Mark-Anthony Bray":false,"Marko \u0158eh\xe1\u010dek":false,"Markus B\xf6gl":false,"Markus H. Gross":false,"Markus Hadwiger":false,"Markus H\xf6ferlin":false,"Markus Jakobsson":false,"Markus John":false,"Markus Steinberger":false,"Marta Farre":false,"Martin Eisemann":false,"Martin Falk":false,"Martin Hess":false,"Martin Imre":false,"Martin Luboschik":false,"Martin Mladenov":false,"Martin R\xf6hlig":false,"Martin Wattenberg":false,"Martin Wikelski":false,"Mary Czerwinski":false,"Maryam Nafari":false,"Marzieh Berenjkoub":false,"Mar\xeda Luj\xe1n Ganuza":false,"Mar\xeda Virginia Sabando":false,"Masahiko Itoh":false,"Masaru Kitsuregawa":false,"Masashi Toyoda":false,"Mathieu Brulin":false,"Matthew Berger":false,"Matthew Brehmer":false,"Matthew D. Cooper":false,"Matthew E. Hawkins":false,"Matthew Kay":false,"Matthew L. Parry":false,"Matthew O. Ward":false,"Matthew Tobiasz":false,"Matthias Kraus":false,"Matthias Schlachter":false,"Matthias Zeppelzauer":false,"Matthias Zieker":false,"Mat\xedas Selzer":false,"Maureen C. Stone":false,"Maurizio Patrignani":false,"Maurizio Pizzonia":false,"Mauro Maggioni":false,"Max Hermann":false,"Max Sondag":false,"Maxim Khailo":false,"Maxime Cordeil":false,"Megan Monroe":false,"MeganOlson Hunt":false,"Mehmet Adil Yal\xe7in":false,"Meichun Hsu":false,"Melanie G\xf6rner":false,"Melanie Tory":false,"Meng Xia":false,"Mengchen Liu":false,"Mengdie Hu":false,"Mennatallah El-Assady":false,"Mi Chen":false,"Miaoxin Hu":false,"Michael Beham":false,"Michael Behrisch":false,"Michael Blumenschein":false,"Michael Bostock":false,"Michael Brooks":false,"Michael Brudno":false,"Michael Burch":false,"Michael B\xf6ttinger":false,"Michael Correll":false,"Michael Delz":false,"Michael E. Papka":false,"Michael Garland":false,"Michael Gleicher":false,"Michael Glueck":false,"Michael J. McGuffin":false,"Michael L. Pack":false,"Michael Michaux":false,"Michael Mock":false,"Michael Ogawa":false,"Michael Oppermann":false,"Michael Pekala":false,"Michael Regenscheit":false,"Michael Riemer":false,"Michael Schw\xe4rzler":false,"Michael Sch\xe4fers":false,"Michael Sedlmair":false,"Michael Steptoe":false,"Michael Stonebraker":false,"Michael Wade":false,"Michael Wimmer":false,"Michael Witmore":false,"Michael Wolverton":false,"Michael Woodward":false,"Michael Wybrow":false,"Michael W\xf6rner":false,"Michail Schwab":false,"Michel Crampes":false,"Michelle A. Borkin":false,"Michelle Borkin":false,"Michelle Dowling":false,"Michelle X. Zhou":false,"Micka\xebl Fabr\xe8gue":false,"Miguel A. Nacenta":false,"Miguel Nunes":false,"Mihaela Jarema":false,"Mikael Jern":false,"Mike Cammarano":false,"Mike Roberts":false,"Mike Sips":false,"Milos Krstajic":false,"Min Chen":false,"Min Lu":false,"Min Zhu":false,"Min-Je Choi":false,"Minfeng Zhu":false,"Ming C. Hao":false,"Mingdong Zhang":false,"Minghui Chen":false,"Mingjie Tang":false,"Mingliang Xu":false,"Mingqian Zhao":false,"Mingxuan Yuan":false,"Mingze Ma":false,"Minh Hoai":false,"Minjeong Shin":false,"Minsuk Kahng":false,"Mirco Nanni":false,"Miriah D. Meyer":false,"Miriah Meyer":false,"Mitchell Whitelaw":false,"Mohamed Yakout":false,"Mohammad Ghoniem":false,"Mohammad Raji":false,"Mondrian Hsieh":false,"Morgan Mathiaut":false,"Morteza Karimzadeh":false,"Mosab Khayat":false,"Mourad Ouzzani":false,"Muchan Park":false,"Mukund Raj":false,"My T. Thai":false,"Nadia Boukhelifa":false,"Nadine Drager":false,"Nadir Weibel":false,"Najmeh Abedzadeh":false,"Nam Wook Kim":false,"Nan Cao":false,"Nan Chen":false,"Nan-Chen Chen":false,"Naohisa Sakamoto":false,"Narayanan Kasthuri":false,"Naren Ramakrishnan":false,"Narges Mahyar":false,"Natalia Andrienko":false,"Natalia V. Andrienko":false,"Natascha Sauber":false,"Natasha Alvarado":false,"Nathalie Henry Riche":false,"Nathalie Lalande":false,"Nathan Mays":false,"Nathan Winters":false,"Naveen Pitipornvivat":false,"Naz Khalili-Shavarini":false,"Neel Parekh":false,"Neel Sundaresan":false,"Neil Spring":false,"Nick Cramer":false,"Nicola Ferro":false,"Nicola Pezzotti":false,"Nicole Sultanum":false,"Niels Willems":false,"Nikhil Thorat":false,"Niklas Elmqvist":false,"Nils Gehlenborg":false,"Nils Wilhelm":false,"Nina McCurdy":false,"Nitesh V. Chawla":false,"Nivan Ferreira":false,"Nivedita R. Kadaba":false,"Noel F.C.C. de Miranda":false,"Norman Au":false,"Oh-Hyun Kwon":false,"Olav Lenz":false,"Oliver Deussen":false,"Oliver R\xfcbel":false,"Omar ElTayeby":false,"Orland Hoeber":false,"Osamu Saeki":false,"Oskar Elek":false,"P. Hanula":false,"P. Nardini":false,"P. Samuel Quinan":false,"Pak Chung Wong":false,"Panpan Xu":false,"Paola Valdivia":false,"Paolo Buono":false,"Paolo Crisafulli":false,"Paolo Simonetto":false,"Pascal Poncelet":false,"Pascale Proulx":false,"Pat Hanrahan":false,"Patrice Y. Simard":false,"Patricia Crossno":false,"Patricia F. Anderson":false,"Patricia Ganea":false,"Patrick Chiu":false,"Patrick Hertzog":false,"Patrick Houthuizen":false,"Patrick J. Fitzpatrick":false,"Patrick K\xf6thur":false,"Patrick Mackey":false,"Patrick Riehmann":false,"Paul A. Navr\xe1til":false,"Paul E. Keel":false,"Paul K. J. Han":false,"Paul Klemm":false,"Paul M. Thompson":false,"Paul Vincent":false,"Paula Kayongo":false,"Paulo Ivson":false,"Pavol Ulbrich":false,"Pedro A. Szekely":false,"Pedro Hermosilla":false,"Peer-Timo Bremer":false,"Peihong Guo":false,"Peiran Ren":false,"Peng Mi":false,"Peng Xu":false,"Penny Rheingans":false,"Pepe Eulzer":false,"Pere-Pau V\xe1zquez":false,"Peter Bak":false,"Peter F. Stadler":false,"Peter Filzmoser":false,"Peter Hamilton":false,"Peter J. Stuckey":false,"Peter K. Sorger":false,"Peter Kerpedjiev":false,"Peter Macko":false,"Petra Isenberg":false,"Phil Moore":false,"Philip A. Legg":false,"Philip Amburn":false,"Philipp Meschenmoser":false,"Philipp Muigg":false,"Philipp Roskosch":false,"Philipp Weil":false,"Philippas Tsigas":false,"Philippe Rocca-Serra":false,"Phillip J. Wolfram":false,"Phong H. Nguyen":false,"Pier Francesco Cortese":false,"Piero Molino":false,"Pierre Accorsi":false,"Pierre Boutillier":false,"Pierre Dragicevic":false,"Pierre J. Magistretti":false,"Pierre Y. Andrews":false,"Pierre-Yves Koenig":false,"Ping Guo":false,"Po-Ming Law":false,"Pourang Irani":false,"Prasenjit Mitra":false,"Praveen Kumar Reddy Ojili":false,"Preeti Raghavan":false,"Puripant Ruchikachorn":false,"Qi Han":false,"Qi Liao":false,"Qianliang Wu":false,"Qianwen Wang":false,"Qiaomu Shen":false,"Qing Chen":false,"Qingguang Cui":false,"Qingsong Liu":false,"Qingyang Xu":false,"Qinhan Liu":false,"Qinying Liao":false,"Qiuhan Zhu":false,"Quan Hoang Nguyen":false,"Quan Li":false,"Qunsheng Peng":false,"R. Bujack":false,"Rachel Brady":false,"Rachel Shadoan":false,"Rafael M. Martins":false,"Raghu Machiraju":false,"Rahul C. Basole":false,"Raimund Dachselt":false,"Rainer Reich":false,"Rainer Splechtna":false,"Ralf P. Botchen":false,"Ralph Brecheisen":false,"Rama Akkiraju":false,"Ramik Sadana":false,"Ran Chen":false,"Ranko Miklin":false,"Raphael Fuchs":false,"Ratnesh K. Sharma":false,"Ratul Mahajan":false,"Ravin Balakrishnan":false,"Ravish Chawla":false,"Rebecca Kehlbeck":false,"Rebecca Nowak":false,"Rebecca Randell":false,"Reem Hourieh":false,"Reinhold Preiner":false,"Remco Chang":false,"Remo Aslak Burkhard":false,"Ren Liu":false,"Renaud Blanch":false,"Renfei Huang":false,"Renzhong Li":false,"Ren\xe9 Enguehard":false,"Reshika Palaniyappan Velumani":false,"Reyk Hillert":false,"Rhodri Bown":false,"Ricardo Langner":false,"Richard Bonneau":false,"Richard E. Parent":false,"Richard Strelitz":false,"Richen Liu":false,"Rick Walker":false,"Rimma V. Nehme":false,"Rita Borgo":false,"Rita Sevastjanova":false,"Robert A. Bridges":false,"Robert A. Lafrance":false,"Robert Barnes":false,"Robert Boudreau":false,"Robert E. Roth":false,"Robert Harper":false,"Robert J. Moorhead II":false,"Robert Kincaid":false,"Robert Kosara":false,"Robert Krueger":false,"Robert Kr\xfcger":false,"Robert Michael Kirby":false,"Robert Pienta":false,"Robert S. Laramee":false,"Robin Valenza":false,"Rock Leung":false,"Rodolfo Ostilla Monico":false,"Rodolphe Devillers":false,"Roel Truyen":false,"Roel Vliegen":false,"Roeland Scheepens":false,"Roger A. Leite":false,"Roger Beecham":false,"Roland Fernandez":false,"Roland N. Boubela":false,"Rolf Mueller":false,"Rollin C. Thomas":false,"Romain Vuillemot":false,"Roman Garnett":false,"Ronan Sicre":false,"Ronghua Liang":false,"Ronghua Shi":false,"Rongjian Lan":false,"Rongwen Zhao":false,"Rongzheng Bian":false,"Roque Lopez":false,"Ross Maciejewski":false,"Ross T. Whitaker":false,"Rostislav Khlebnikov":false,"Roy A. Ruddle":false,"Rudolf Netzel":false,"Rudy Hashim":false,"Rui Li":false,"Ruixiang Zhang":false,"Runlin Li":false,"Rupayan Neogy":false,"Rusheng Pan":false,"Rushil Anirudh":false,"Russ Burtner":false,"Russell A. Lankenau":false,"Ryan Armstrong":false,"Ryan Eccles":false,"Ryan Hafen":false,"Ryan M. Kilgore":false,"Ryan Wesslen":false,"Ryan Wilson":false,"R\xe9my Vieux":false,"R\xfcdiger Westermann":false,"S. Peter Henzi":false,"S. Scheithauer":false,"Saad Nadeem":false,"Sabine Bauer":false,"Sadia Rubab":false,"Sagar Joglekar":false,"Sai Prashanth Dasari":false,"Saleema Amershi":false,"Salman Mahmood":false,"Salvatore Rinzivillo":false,"Sam Ade Jacobs":false,"Samana Shrestha":false,"Samuel Gerber":false,"Samuel Gratzl":false,"Samuel H. Payne":false,"Samuel Huron":false,"Sana Malik":false,"Sandra Bringay":false,"Sanja \u0160\u0107epanovi\u0107":false,"Santhosh Dharmapuri":false,"Santhosh Nandhakumar":false,"Sara Di Bartolomeo":false,"Sara Diamond":false,"Sara Johansson":false,"Sarah Goodwin":false,"Sarah Peck":false,"Sarah S. Poon":false,"Sasha Schriber":false,"Scotland Leman":false,"Scott Barlowe":false,"Scott D. Rothenberger":false,"Scott Pezanowski":false,"Sebastian Baltes":false,"Sebastian Boring":false,"Sebastian Bremm":false,"Sebastian Gehrmann":false,"Sebastian Grottel":false,"Sebastian Koch":false,"Sebastian Mittelst\xe4dt":false,"Sebastien Boyer":false,"Selim Balcisoy":false,"Seok-Hee Hong":false,"Sergej Stoppel":false,"Seth Johnson":false,"Seung Hyun Kim":false,"Seyedkoosha Mirhosseini":false,"Seymour Knowles-Barley":false,"Shade T. Shutters":false,"Shah Rukh Humayoun":false,"Shahid Latif":false,"Shamkant B. Navathe":false,"Shantanu H. Joshi":false,"Shantanu Singh":false,"Shaozu Cao":false,"Sharon Lin":false,"Shash Sinha":false,"Shaun J. Grannis":false,"Shaun Kennedy":false,"Shayan Monadjemi":false,"Sheelagh Carpendale":false,"Shehzad Afzal":false,"Shenghui Cheng":false,"Shengjie Gao":false,"Shenyu Xu":false,"Shichao Jia":false,"Shigeo Takahashi":false,"Shilpika":false,"Shimei Pan":false,"Shin\'ichi Satoh":false,"Shiping Huang":false,"Shiry Ginosar":false,"Shixia Liu":false,"Shoubin Cheng":false,"Shouxing Xiang":false,"Shuai Chen":false,"Shuhan Liu":false,"Shuirun Wei":false,"Shunan Guo":false,"Shusen Liu":false,"Shuyue Zhou":false,"Si Li":false,"Si Qin":false,"Sietse J. Luk":false,"Sihang Li":false,"Sikun Li":false,"Siliang Tang":false,"Silvia Mabel Castro":false,"Silvia Miksch":false,"Siming Chen":false,"Simon Breslav":false,"Simon Harding":false,"Simon J. Walton":false,"Simon Schubiger-Banz":false,"Simone D. J. Barbosa":false,"Simone Kriglstein":false,"Simone Lenti":false,"Simone Melchionna":false,"Siwei Fu":false,"Sixiao Yang":false,"Siyuan Liu":false,"Smiti Kaul":false,"Sol\xe9akh\xe9na Ken":false,"Song Ge":false,"Song Zhang":false,"Sonia Castelo":false,"Soo-Yeon Ji":false,"Soonwook Kwon":false,"Srikanth Kandula":false,"Srinivasan Parthasarathy":false,"Stef van den Elzen":false,"Stefan Bruckner":false,"Stefan Janicke":false,"Stefan Jordan":false,"Stefan M\xfcller Arisona":false,"Stefania Forlini":false,"Steffen Frey":false,"Steffen Hadlak":false,"Steffen Koch":false,"Steffen Oeltze-Jafra":false,"Stephan Huber":false,"Stephan Pajer":false,"Stephan Reiling":false,"Stephan Sellien":false,"Stephanie Dudzic":false,"Stephen Correia":false,"Stephen G. Eick":false,"Stephen Ingram":false,"Stephen J. Bailey":false,"Stephen M. Blackburn":false,"Stephen Rudolph":false,"Steve James Szigeti":false,"Steve Kelling":false,"Steven Bergner":false,"Steven Landis":false,"Steven M. Drucker":false,"Steven P. Callahan":false,"Steven R. Gomez":false,"Stina S. Bridgeman":false,"Subhajit Das":false,"Subhashis Hazarika":false,"Sujan Anreddy":false,"Sujin Jang":false,"Sukwon Lee":false,"Sumeet Tandon":false,"Sung-Hee Kim":false,"SungYe Kim":false,"Sungahn Ko":false,"Sungsoo Ha":false,"Suphanut Jamonnak":false,"Susan Knoblach":false,"Susan M. Mniszewski":false,"Susan S. Hubbard":false,"Susanna-Assunta Sansone":false,"Suvi Tarkkanen":false,"Sven Hermann":false,"Sven Schulte":false,"Svitlana Volkova":false,"Swethan Anand":false,"Sye-Min Chan":false,"Sylvia Gla\xdfer":false,"Sylvie Ranwez":false,"T. Baumgartl":false,"T. J. Jankun-Kelly":false,"T. Luciani":false,"Tae Jung Kim":false,"Tai-Quan Peng":false,"Takahiro Yamamoto":false,"Takanori Fujiwara":false,"Tamara Munzner":false,"Tan Tang":false,"Tangzhi Ye":false,"Tanja Blascheck":false,"Tanner Hobson":false,"Tao Li":false,"Tarik Crnovrsanin":false,"Tariq Yousef":false,"Tatiana von Landesberger":false,"Tavi Murray":false,"Tera Marie Green":false,"Themis Palpanas":false,"Theophanis Tsandilas":false,"Theresia Gschwandtner":false,"Thilo Spinner":false,"Thomas Auzinger":false,"Thomas Baudel":false,"Thomas Butkiewicz":false,"Thomas Ertl":false,"Thomas H\xf6llt":false,"Thomas Kapler":false,"Thomas Kirste":false,"Thomas Lindemeier":false,"Thomas L\xf6we":false,"Thomas M. Hamill":false,"Thomas M\xfchlbacher":false,"Thomas M\xfcller":false,"Thomas Nocke":false,"Thomas Ortner":false,"Thomas Ramm":false,"Thomas Schultz":false,"Thomas Seidl":false,"Thomas Spengler":false,"Thomas Torsney-Weir":false,"Thomas Zichner":false,"Thorsten May":false,"Tiankai Xie":false,"Tianyi Lao":false,"Tianyi Zhang":false,"Tianyu Gu":false,"Till Wollenberg":false,"Tim Althoff":false,"Tim Dwyer":false,"Tim Lammarsch":false,"Timo Ropinski":false,"Timothy C. Johnson":false,"Timothy Luciani":false,"Timothy M. Shead":false,"Timothy Major":false,"Timothy Sullivan":false,"Timothy W. Collins":false,"Ting-Chuen Pong":false,"Tino Gruse":false,"Tiziana Catarci":false,"Tobias H\xf6llerer":false,"Tobias Isenberg":false,"Tobias Rapp":false,"Tobias Ruppert":false,"Tobias Schreck":false,"Tobias \xc5str\xf6m":false,"Tolga Bolukbasi":false,"Tom Peterka":false,"Tom Polk":false,"Tomislav Lipic":false,"Tongshuang Wu":false,"Tonya L. Smith-Jackson":false,"Torsten M\xf6ller":false,"Tran Minh Quan":false,"Trevor Kennedy":false,"Trung-Tien Phan-Quang":false,"Trustin Clear":false,"Tyler Estro":false,"Udo Schlegel":false,"Uli Niemann":false,"Ulrich Bartling":false,"Ulrik Brandes":false,"Ulrike Kister":false,"Umeshwar Dayal":false,"Uta Hinrichs":false,"Uwe Mikolajewicz":false,"Vadim Ogievetsky":false,"Valerio Pascucci":false,"Vaughan Greer":false,"Vero Vanden Abeele":false,"Veronika Irvine":false,"Veronika Solt\xe9szov\xe1":false,"Victor Guallar":false,"Victor Pascual-Cid":false,"Victor Y. Chen":false,"Vidya Setlur":false,"Vikram Aggarwal":false,"Vincent van Unen":false,"Viswanath Aluru":false,"Vitalis Wiens":false,"Vivek Kothari":false,"Vivek Srikumar":false,"Volker Klemann":false,"Wai Tong":false,"Waldemar Celes Filho":false,"Walter F. Stewart":false,"Walter Fontana":false,"Walter Schubert":false,"Wan-Yi Sabrina Lin":false,"Wanqi Hu":false,"Wei Chen":false,"Wei Xu":false,"Wei Zeng":false,"Weichao Wang":false,"Weifeng Chen":false,"Weikai Yang":false,"Weiwei Cui":false,"Weixia Xu":false,"Wen Zhong":false,"Wen-Chin Chen":false,"Wen-Feng Cheng":false,"Wenbin He":false,"Wenbo Tao":false,"Wenchao Wu":false,"Wendy E. Mackay":false,"Wenlong Chen":false,"Wenping Wang":false,"Wentao Gu":false,"Wenwen Dou":false,"Wenyuan Wang":false,"Werner Purgathofer":false,"Wesley Kendall":false,"Wesley Willett":false,"Whitney Huang":false,"Will Epperson":false,"William Alexander":false,"William J. Layton":false,"William J. Tolone":false,"William Ribarsky":false,"William S. Cleveland":false,"William Wright":false,"Wing Yan So":false,"Wing-Yi Chan":false,"Winston H. Hsu":false,"Wolfgang Aigner":false,"Wolfgang Freiler":false,"Wolfgang Herzner":false,"Won-Dong Jang":false,"Won-Ki Jeong":false,"Wonyoung So":false,"Woohyuk Choi":false,"Wouter Meulemans":false,"Xavier Cavin":false,"Xenophon Papademetris":false,"Xi Chen":false,"Xi Ye":false,"Xian Teng":false,"Xiangyang Wu":false,"Xiao Xie":false,"Xiao Zhang":false,"Xiaodong Zhao":false,"Xiaohua Sun":false,"Xiaojuan Ma":false,"Xiaolong Zhang":false,"Xiaoming Li":false,"Xiaoming Liu":false,"Xiaoru Yuan":false,"Xiaotao Nie":false,"Xiaotong Liu":false,"Xiaoxiao Lian":false,"Xiaoyan Fu":false,"Xiaoyi Wang":false,"Xiaoyu Wang":false,"Xiaoyun Hu":false,"Xidao Wen":false,"Xin Dong":false,"Xin Tong":false,"Xing Li":false,"Xing Mu":false,"Xingbo Wang":false,"Xinhuan Shu":false,"Xinke Wu":false,"Xinlei Zhao":false,"Xinli Hou":false,"Xinnan Du":false,"Xinsong Yang":false,"Xinxin Huang":false,"Xinyi Huang":false,"Xinyi Zhou":false,"Xinyu Zhu":false,"Xinyue Xu":false,"Xinzhu Mu":false,"Xiting Wang":false,"Xizhou Zhu":false,"Xu-Meng Wang":false,"Xuan Zhong":false,"Xuanwu Yue":false,"Xue Wu":false,"Xumeng Wang":false,"Xun Zhao":false,"Yadong Wu":false,"Yafeng Lu":false,"Yahui Zhao":false,"Yale Song":false,"Yalong Yang":false,"Yang Chen":false,"Yang Liu":false,"Yang Shi":false,"Yang Wang":false,"Yang Yang":false,"Yangqiu Song":false,"Yanhong Wu":false,"Yanna Lin":false,"Yao Ming":false,"Ye Yuan":false,"Ye Zhao":false,"Yea-Seul Kim":false,"Yedendra Babu Shrinivasan":false,"Yen-Ting Kuan":false,"Yernar Abdrazakov":false,"Yeting Xu":false,"Yeukyin Chan":false,"Yi Chen":false,"Yi Han":false,"Yi Wang":false,"Yi-Chih Tsai":false,"Yi-Shan Lin":false,"Yifan Hu":false,"Yifang Wang":false,"Yin-Hsi Kuo":false,"Yindalon Aphinyanagphongs":false,"Ying Tu":false,"Ying Zhao":false,"Yingcai Wu":false,"Yingchao Wang":false,"Yinggang Li":false,"Yiping Han":false,"Yiwen Sun":false,"Yixian Zheng":false,"Yixuan Zhang":false,"Yiyang Tang":false,"Yizhou Yu":false,"Yong Wang":false,"Yong Xu":false,"Yongjun Zheng":false,"Yongsu Ahn":false,"Yongxian Zhang":false,"Yoonsoo Nam":false,"Youn ah Kang":false,"Young Bin Kim":false,"Youssef S. G. Nashed":false,"Yu Ye":false,"Yu Zheng":false,"Yu-Hsuan Chan":false,"Yu-Ru Lin":false,"Yu-Shuen Wang":false,"Yuan Chen":false,"Yuan He":false,"Yuanyuan Tang":false,"Yuanzhe Chen":false,"Yue Wang":false,"Yueqi Hu":false,"Yueting Zhuang":false,"Yuhong Li":false,"Yujie Liu":false,"Yuki Asano":false,"Yumeng Hou":false,"Yumeng Xue":false,"Yun Jang":false,"Yun Wang":false,"Yunhai Wang":false,"Yuntao Jia":false,"Yusi Wang":false,"Yusu Wang":false,"Yutao Zhang":false,"Yuxin Ma":false,"Yves Chiricota":false,"Yvonne Jansen":false,"Zachary Leggon":false,"Zachary Wartell":false,"Zafar Ahmed":false,"Zahid Hossain":false,"Zaixian Xie":false,"Zan Armstrong":false,"Zekai Gao":false,"Zeng Dai":false,"Zengsheng Zhong":false,"Zeqian Shen":false,"Zexian Chen":false,"Zeyu Li":false,"Zhan Guo":false,"Zhao-Peng Meng":false,"Zhaosong Huang":false,"Zhen Cao":false,"Zhen Li":false,"Zhen Wen":false,"Zheng Zhou":false,"Zhenhua Xu":false,"Zhenhuang Wang":false,"Zhenyu Cheryl Qian":false,"Zhenyu Guo":false,"Zheqing Yu":false,"Zhibin Niu":false,"Zhibin Wang":false,"Zhicheng Liu":false,"Zhicheng Yan":false,"Zhifang Jiang":false,"Zhiguang Zhou":false,"Zhimin Li":false,"Zhipeng Wang":false,"Zhiqi Liu":false,"Zhiqiang Ma":false,"Zhiyong Guo":false,"Zhiyuan Zhang":false,"Zhong Su":false,"Zhongzang Lin":false,"Zhuming Ai":false,"Zhuochen Jin":false,"Zhuofeng Wu":false,"Zhutian Chen":false,"Zi\'ang Ding":false,"Zicheng Liao":false,"Zikun Deng":false,"Ziyang Guo":false,"Zoltan Konyha":false,"Zuchao Wang":false,"Zudi Lin":false,"Zuobin Wang":false,"\xc1ngel Alexander Cabrera":false,"\xc7agatay Demiralp":false}')},228:function(e){e.exports=JSON.parse('{"2177_0":{"comp":[["glyph_based","glyph_based",["repeated"]]],"visType":["glyph_based"],"compType":["repeated"],"compressed_tree":[{"composite_pattern":"repeated","visualization_type":[["glyph_based"]]}],"coOccurrence":[["glyph_based","glyph_based",["coOccurrence"]]],"year":2011,"conference":["Vis"],"authors":["Darrel Palke","Zhongzang Lin","Guoning Chen","Harry Yeh","Paul Vincent","Robert S. Laramee","Eugene Zhang"],"title":"Asymmetric Tensor field Visualization for Surfaces","doi":"10.1109/TVCG.2011.170","abstract":"Asymmetric tensor field visualization can provide important insight into fluid flows and solid deformations. Existing techniques for asymmetric tensor fields focus on the analysis, and simply use evenly-spaced hyperstreamlines on surfaces following eigenvectors and dual-eigenvectors in the tensor field. In this paper, we describe a hybrid visualization technique in which hyperstreamlines and elliptical glyphs are used in real and complex domains, respectively. This enables a more faithful representation of flow behaviors inside complex domains. In addition, we encode tensor magnitude, an important quantity in tensor field analysis, using the density of hyperstreamlines and sizes of glyphs. This allows colors to be used to encode other important tensor quantities. To facilitate quick visual exploration of the data from different viewpoints and at different resolutions, we employ an efficient image-space approach in which hyperstreamlines and glyphs are generated quickly in the image plane. The combination of these techniques leads to an efficient tensor field visualization system for domain scientists. We demonstrate the effectiveness of our visualization technique through applications to complex simulated engine fluid flow and earthquake deformation data. Feedback from domain expert scientists, who are also co-authors, is provided.","keywords":"Aasymmetric tensor fields, vector fields, glyph packing, hyperstreamline placement, view-dependent","caption":"Fig. 1. Visualization of the ground deformation associated with a simulation of the June, 1992 Mw=7.3 Landers, CA earthquake. (a) new hybrid visualization of the displacement-gradient tensor \ufb01eld (\u03b1 = 0.022, \u03b2 = 0.8, iter = 800, mr = 10), (b) previous visualization using hyperstreamlines only, (c) a common visualization method used in earthquake deformation studies showing the displacement vector \ufb01eld only, (d) the expected deformation modes for a right-lateral fault. Note how the glyph packing in the complex domains (see the highlighted region) better conveys the elliptical deformation pattern than the previous methods (e.g. (b) and (c)). ","img_size":{"width":2070,"height":1015},"subfigures":[{"x":6.277136124570026,"y":3.6177423543751233,"width":2059.6049693925106,"height":1001.28321488394,"type":"interface","id":"interface-0"}],"visualizations":[{"x":6.543320977487901,"y":8.545868601334277,"width":822.6184255497643,"height":823.7626517998135,"type":"glyph_based","id":"glyph_based-0"},{"x":827.084507359432,"y":13.73235577294965,"width":839.9153523314687,"height":816.0084084490276,"type":"glyph_based","id":"glyph_based-1"},{"x":1681.3629099178997,"y":376.4271919013654,"width":377.4336010167448,"height":438.9099581872298,"type":"glyph_based","id":"glyph_based-2"},{"x":1669.6053558076421,"y":3.6225182728915244,"width":387.85968556286707,"height":380.5688907639097,"type":"heatmap","id":"heatmap-3"}],"relations":[{"vislist":[{"vislist":["glyph_based-0","glyph_based-1"],"relation":null,"id":"group-0"}],"relation":"repeated","id":"relation-0"}]},"2182_9":{"comp":[["scivis","scivis",["repeated"]]],"visType":["scivis"],"compType":["repeated"],"compressed_tree":[{"composite_pattern":"repeated","visualization_type":[["scivis"]]}],"coOccurrence":[["scivis","scivis",["coOccurrence"]]],"year":2011,"conference":["Vis"],"authors":["Rostislav Khlebnikov","Bernhard Kainz","Judith Muehl","Dieter Schmalstieg"],"title":"Crepuscular Rays for Tumor Accessibility Planning","doi":"10.1109/TVCG.2011.184","abstract":"In modern clinical practice, planning access paths to volumetric target structures remains one of the most important and most complex tasks, and a physician\'s insufficient experience in this can lead to severe complications or even the death of the patient. In this paper, we present a method for safety evaluation and the visualization of access paths to assist physicians during preoperative planning. As a metaphor for our method, we employ a well-known, and thus intuitively perceivable, natural phenomenon that is usually called crepuscular rays. Using this metaphor, we propose several ways to compute the safety of paths from the region of interest to all tumor voxels and show how this information can be visualized in real-time using a multi-volume rendering system. Furthermore, we show how to estimate the extent of connected safe areas to improve common medical 2D multi-planar reconstruction (MPR) views. We evaluate our method by means of expert interviews, an online survey, and a retrospective evaluation of 19 real abdominal radio-frequency ablation (RFA) interventions, with expert decisions serving as a gold standard. The evaluation results show clear evidence that our method can be successfully applied in clinical practice without introducing substantial overhead work for the acting personnel. Finally, we show that our method is not limited to medical applications and that it can also be useful in other fields.","keywords":"Accessibility, ray casting, medical visualization","caption":"Fig. 9. A screenshot of our medical visualization system with area safety and path safety augmentation. In this example, the path safety volume shows all dangerous and impassable paths in red. The area safety ge- ometry shows all safe access areas. The 2D MPR views are aligned with the direction of the main axis of one safe access area. For datasets similar to this one, which show mainly large safe access areas, the area safety geometry can be smoothed and additionally displayed as translu- cent geometry in 3D, as shown here. The tool to be placed into the tumor (green) is a RFA needle. All vulnerable vessels are displayed in shades of blue. ","img_size":{"width":954,"height":710},"subfigures":[{"x":6.3152208373611005,"y":7.064588087320302,"width":945.899492217738,"height":701.1601609393705,"type":"single","id":"single-0"}],"visualizations":[{"x":482.6795284702265,"y":10.050086360278302,"width":465.0389907500501,"height":346.0929148687139,"type":"scivis","id":"scivis-0"},{"x":6.978137605257049,"y":9.303564188422317,"width":471.95055590182864,"height":347.5859592124257,"type":"scivis","id":"scivis-1"},{"x":6.224388088415537,"y":358.4155060225934,"width":474.21304391758804,"height":350.57705294442803,"type":"scivis","id":"scivis-2"},{"x":478.9383630372622,"y":359.87857018574897,"width":472.5213216159778,"height":344.62844626725393,"type":"scivis","id":"scivis-3"}],"relations":[{"vislist":[{"vislist":["scivis-0","scivis-1","scivis-3","scivis-2"],"relation":null,"id":"group-0"}],"relation":"repeated","id":"relation-0"}]},"2184_6":{"comp":[["proportional_area_chart","proportional_area_chart",["repeated"]]],"visType":["proportional_area_chart"],"compType":["repeated"],"compressed_tree":[{"composite_pattern":"repeated","visualization_type":[["proportional_area_chart"]]}],"coOccurrence":[["proportional_area_chart","proportional_area_chart",["coOccurrence"]]],"year":2011,"conference":["Vis"],"authors":["Mark A. Livingston","Jonathan W. Decker"],"title":"Evaluation of Trend Localization with Multi-Variate Visualizations","doi":"10.1109/TVCG.2011.194","abstract":"Multi-valued data sets are increasingly common, with the number of dimensions growing. A number of multi-variate visualization techniques have been presented to display such data. However, evaluating the utility of such techniques for general data sets remains difficult. Thus most techniques are studied on only one data set. Another criticism that could be levied against previous evaluations of multi-variate visualizations is that the task doesn\'t require the presence of multiple variables. At the same time, the taxonomy of tasks that users may perform visually is extensive. We designed a task, trend localization, that required comparison of multiple data values in a multi-variate visualization. We then conducted a user study with this task, evaluating five multivariate visualization techniques from the literature (Brush Strokes, Data-Driven Spots, Oriented Slivers, Color Blending, Dimensional Stacking) and juxtaposed grayscale maps. We report the results and discuss the implications for both the techniques and the task.","keywords":"User study, multi-variate visualization, visual task design, visual analytics","caption":"Fig. 6. The screen layout showed subjects the technique legend for multi-variate techniques, the visualization, question, and a \u201cNext\u201d button. This image shows Juxtaposed Maps, which did not need a legend.","img_size":{"width":988,"height":639},"subfigures":[{"x":12.687617544280169,"y":18.474107413353618,"width":955.8260875233551,"height":604.0919580601253,"type":"interface","id":"interface-0"}],"visualizations":[{"x":148.13418229441976,"y":78.24900780627762,"width":589.0716068510843,"height":453.25950634284044,"type":"proportional_area_chart","id":"proportional_area_chart-0"}],"relations":[{"vislist":[{"vislist":["proportional_area_chart-0"],"relation":null,"id":"group-0"}],"relation":"repeated","id":"relation-0"}]},"2417_0":{"comp":[["scivis","scivis",["repeated"]],["tree","tree",["repeated"]]],"visType":["scivis","tree"],"compType":["repeated"],"compressed_tree":[{"composite_pattern":"repeated","visualization_type":[["scivis"]]},{"composite_pattern":"repeated","visualization_type":[["tree"]]}],"coOccurrence":[["scivis","tree",["coOccurrence"]]],"year":2013,"conference":["SciVis"],"authors":["Adrian Maries","Nathan Mays","MeganOlson Hunt","Kim F. Wong","William J. Layton","Robert Boudreau","Caterina Rosano","G. Elisabeta Marai"],"title":"GRACE: A Visual Comparison Framework for Integrated Spatial and Non-Spatial Geriatric Data","doi":"10.1109/TVCG.2013.161","abstract":"We present the design of a novel framework for the visual integration, comparison, and exploration of correlations in spatial and non-spatial geriatric research data. These data are in general high-dimensional and span both the spatial, volumetric domain - through magnetic resonance imaging volumes - and the non-spatial domain, through variables such as age, gender, or walking speed. The visual analysis framework blends medical imaging, mathematical analysis and interactive visualization techniques, and includes the adaptation of Sparse Partial Least Squares and iterated Tikhonov Regularization algorithms to quantify potential neurologymobility connections. A linked-view design geared specifically at interactive visual comparison integrates spatial and abstract visual representations to enable the users to effectively generate and refine hypotheses in a large, multidimensional, and fragmented space. In addition to the domain analysis and design description, we demonstrate the usefulness of this approach on two case studies. Last, we report the lessons learned through the iterative design and evaluation of our approach, in particular those relevant to the design of comparative visualization of spatial and non-spatial data.","keywords":"Design studies, methodology design, task and requirements analysis, integrating spatial and non-spatial data visualization, visual comparison, high-dimensional data, applications of visualization","caption":"Fig. 1. GRACE collaborative layout, supporting visual integration and comparison of spatial and non-spatial geriatric data. Following a hybrid visual comparison design, the layout consists of five linked views: Two juxtaposed volume rendering panels (left) encode spatial information; Two linked, juxtaposed dendrogram panels and one overlayed Kiviat diagram panel (center) encode non-spatial information; Additional widgets (right, top, bottom) allow data selection (datasets, variables, and algorithms), filtering (data types, correlations and significance values) and data manipulation. Correlations are encoded across all panels using two sequential multihue color schemes (green-blue for gray matter, and orange-red for white matter). This flexible design successfully supports the comparison of spatial and non-spatial variables, functional attributes, datasets, and algorithms, while interaction enables seamless formation and refinement of hypotheses. ","img_size":{"width":2055,"height":1677},"subfigures":[{"x":7.668120005940541,"y":4.26944737970273,"width":2041.4486963276588,"height":1672.0306096028462,"type":"interface","id":"interface-0"}],"visualizations":[{"x":747.747697943921,"y":829.1764710219386,"width":732.6434290476369,"height":743.2564434933263,"type":"polar_plot","id":"polar_plot-3"},{"x":17.315896549864412,"y":117.57914599455778,"width":729.8592334121138,"height":722.5865790170583,"type":"scivis","id":"scivis-0"},{"x":17.296230702249197,"y":831.6275216187333,"width":731.683501446885,"height":741.9238466619895,"type":"scivis","id":"scivis-4"},{"x":747.7707622599111,"y":103.47129093889268,"width":736.1671730947371,"height":367.08057018627153,"type":"tree","id":"tree-1"},{"x":747.7592343076399,"y":466.113007635361,"width":734.4052926597393,"height":377.1150354172986,"type":"tree","id":"tree-2"}],"relations":[{"vislist":[{"vislist":["scivis-4","scivis-0"],"relation":null,"id":"group-0"}],"relation":"repeated","id":"relation-0"},{"vislist":[{"vislist":["tree-1","tree-2"],"relation":null,"id":"group-1"}],"relation":"repeated","id":"relation-1"}]},"2420_4":{"comp":[["scivis","scivis",["repeated"]]],"visType":["scivis"],"compType":["repeated"],"compressed_tree":[{"composite_pattern":"repeated","visualization_type":[["scivis"]]}],"coOccurrence":[["scivis","scivis",["coOccurrence"]]],"year":2013,"conference":["SciVis"],"authors":["Atul Rungta","Brian Summa","Dogan Demir","Peer-Timo Bremer","Valerio Pascucci"],"title":"ManyVis: Multiple Applications in an Integrated Visualization Environment","doi":"10.1109/TVCG.2013.174","abstract":"As the visualization field matures, an increasing number of general toolkits are developed to cover a broad range of applications. However, no general tool can incorporate the latest capabilities for all possible applications, nor can the user interfaces and workflows be easily adjusted to accommodate all user communities. As a result, users will often chose either substandard solutions presented in familiar, customized tools or assemble a patchwork of individual applications glued through ad-hoc scripts and extensive, manual intervention. Instead, we need the ability to easily and rapidly assemble the best-in-task tools into custom interfaces and workflows to optimally serve any given application community. Unfortunately, creating such meta-applications at the API or SDK level is difficult, time consuming, and often infeasible due to the sheer variety of data models, design philosophies, limits in functionality, and the use of closed commercial systems. In this paper, we present the ManyVis framework which enables custom solutions to be built both rapidly and simply by allowing coordination and communication across existing unrelated applications. ManyVis allows users to combine software tools with complementary characteristics into one virtual application driven by a single, custom-designed interface.","keywords":"Visualization environments, integrated applications, macros, linked views","caption":"Fig. 5.Interactive Simulation Filmstrip.Automatic creation of a filmstrip illustration for time-dependent data. ManyVis provides buttons to define the number of windows to display.  Two additional sliders provide user input to denote the desired range of time steps.","img_size":{"width":803,"height":468},"subfigures":[{"x":4.7061625423026285,"y":7.138154793208558,"width":789.6027903888935,"height":232.0823730365251,"type":"interface","id":"interface-0"}],"visualizations":[{"x":20.237733797816823,"y":34.889462630332325,"width":222.78314935115546,"height":152.66550832004535,"type":"scivis","id":"scivis-0"},{"x":271.62642258649475,"y":33.87195746614041,"width":234.86726040593132,"height":151.6501389413576,"type":"scivis","id":"scivis-1"},{"x":534.5609179520702,"y":34.87483709865992,"width":229.9527936753371,"height":149.64437967631872,"type":"scivis","id":"scivis-2"}],"relations":[{"vislist":[{"vislist":["scivis-0","scivis-1","scivis-2"],"relation":null,"id":"group-0"}],"relation":"repeated","id":"relation-0"}]},"1887_0":{"comp":[["bar_chart","bar_chart",["repeated"]],["scivis","scivis",["large_view"]],["scatterplot","scatterplot",["large_view"]]],"visType":["bar_chart","scivis","scatterplot"],"compType":["repeated","large_view"],"compressed_tree":[{"composite_pattern":"repeated","visualization_type":[["bar_chart"]]},{"composite_pattern":"large_view","visualization_type":[["scivis"],["scivis"]]},{"composite_pattern":"large_view","visualization_type":[["scatterplot"],["scatterplot"]]}],"coOccurrence":[["bar_chart","scivis",["coOccurrence"]],["bar_chart","scatterplot",["coOccurrence"]],["scivis","scatterplot",["coOccurrence"]]],"year":2009,"conference":["Vis"],"authors":["Wei Che","Zi\'ang Ding","Song Zhan","Anna MacKay-Brandt","Stephen Correia","Huamin Qu","John Allen Crow","David F. Tate","Zhicheng Yan","Qunsheng Peng"],"title":"A Novel Interface for Interactive Exploration of DTI fibers","doi":"10.1109/TVCG.2009.112","abstract":"Visual exploration is essential to the visualization and analysis of densely sampled 3D DTI fibers in biological speciments, due to the high geometric, spatial, and anatomical complexity of fiber tracts. Previous methods for DTI fiber visualization use zooming, color-mapping, selection, and abstraction to deliver the characteristics of the fibers. However, these schemes mainly focus on the optimization of visualization in the 3D space where cluttering and occlusion make grasping even a few thousand fibers difficult. This paper introduces a novel interaction method that augments the 3D visualization with a 2D representation containing a low-dimensional embedding of the DTI fibers. This embedding preserves the relationship between the fibers and removes the visual clutter that is inherent in 3D renderings of the fibers. This new interface allows the user to manipulate the DTI fibers as both 3D curves and 2D embedded points and easily compare or validate his or her results in both domains. The implementation of the framework is GPU based to achieve real-time interaction. The framework was applied to several tasks, and the results show that our method reduces the user\'s workload in recognizing 3D DTI fibers and permits quick and accurate DTI fiber selection.","keywords":"Diffusion Tensor Imaging, fibers, fiber Clustering, Visualization Interface","caption":"Fig. 1: A snapshot of our DTI fiber exploration system. The figure shows a sagittal view fibers in the corpus callosum and cingulate bundle (left-right orientation) of a human brain dataset (anterior is to the viewer\u2019s left).","img_size":{"width":1870,"height":1277},"subfigures":[{"x":7.566010402713414,"y":7.302498122824744,"width":1848.0752663917988,"height":1267.8312077741432,"type":"interface","id":"interface-0"}],"visualizations":[{"x":1111.0496416098529,"y":988.0682180999837,"width":251.09361366685474,"height":250.84021625878964,"type":"bar_chart","id":"bar_chart-4"},{"x":1357.766075559042,"y":987.8338889136026,"width":250.811695250056,"height":244.7692729913971,"type":"bar_chart","id":"bar_chart-5"},{"x":1601.860982253306,"y":985.1724042750749,"width":253.05574622199836,"height":252.81034427834612,"type":"bar_chart","id":"bar_chart-6"},{"x":1111.4950960419624,"y":250.5371219814115,"width":739.2780266025508,"height":735.1542258887307,"type":"scatterplot","id":"scatterplot-2"},{"x":1633.0158468693842,"y":246.17148928021697,"width":221.99249588261713,"height":212.49654835639348,"type":"scatterplot","id":"scatterplot-3"},{"x":17.560840224890434,"y":251.97898041875018,"width":1093.1140814870128,"height":985.0539959344089,"type":"scivis","id":"scivis-0"},{"x":894.0116762817368,"y":247.50887155983477,"width":223.26507373428123,"height":209.82178379715768,"type":"scivis","id":"scivis-1"}],"relations":[{"vislist":[{"vislist":["bar_chart-4","bar_chart-5","bar_chart-6"],"relation":null,"id":"group-0"}],"relation":"repeated","id":"relation-0"},{"vislist":[{"vislist":["scivis-1"],"relation":null,"id":"group-2"},{"vislist":["scivis-0"],"relation":null,"id":"group-1"}],"relation":"large_view","id":"relation-1"},{"vislist":[{"vislist":["scatterplot-3"],"relation":null,"id":"group-4"},{"vislist":["scatterplot-2"],"relation":null,"id":"group-3"}],"relation":"large_view","id":"relation-2"}]},"1894_0":{"comp":[["scivis","scivis",["repeated"]]],"visType":["scivis"],"compType":["repeated"],"compressed_tree":[{"composite_pattern":"repeated","visualization_type":[["scivis"]]}],"coOccurrence":[["scivis","scivis",["coOccurrence"]]],"year":2009,"conference":["Vis"],"authors":["Stefan Bruckner","Veronika Solt\xe9szov\xe1","M. Eduard Gr\xf6ller","Jir\xed Hladuvka","Katja B\xfchler","Jai Y. Yu","Barry J. Dickson"],"title":"BrainGazer - Visual Queries for Neurobiology Research","doi":"10.1109/TVCG.2009.121","abstract":"Neurobiology investigates how anatomical and physiological relationships in the nervous system mediate behavior. Molecular genetic techniques, applied to species such as the common fruit fly Drosophila melanogaster, have proven to be an important tool in this research. Large databases of transgenic specimens are being built and need to be analyzed to establish models of neural information processing. In this paper we present an approach for the exploration and analysis of neural circuits based on such a database. We have designed and implemented \\\\emph{BrainGazer}, a system which integrates visualization techniques for volume data acquired through confocal microscopy as well as annotated anatomical structures with an intuitive approach for accessing the available information. We focus on the ability to visually query the data based on semantic as well as spatial relationships. Additionally, we present visualization techniques for the concurrent depiction of neurobiological volume data and geometric objects which aim to reduce visual clutter. The described system is the result of an ongoing interdisciplinary collaboration between neurobiologists and visualization researchers.","keywords":"Biomedical visualization, neurobiology, visual queries, volume visualization","caption":"Fig. 1: Neural projections in the brain of the fruit fly visualized using the BrainGazer system.","img_size":{"width":1608,"height":439},"subfigures":[{"x":872.7674415690897,"y":6.929984202207939,"width":727.3608967608409,"height":422.62532260954515,"type":"interface","id":"interface-0"}],"visualizations":[{"x":882.0106938109545,"y":71.43615704320538,"width":305.5924351348286,"height":245.2123933245752,"type":"scivis","id":"scivis-0"},{"x":1193.8612732094361,"y":62.84385124588214,"width":122.15291786576684,"height":116.77926811464333,"type":"scivis","id":"scivis-1"},{"x":1315.3333523878216,"y":60.892853474407715,"width":132.3846226509066,"height":122.71787536115247,"type":"scivis","id":"scivis-2"},{"x":1188.8278560111003,"y":200.0211492380896,"width":132.21975226243785,"height":124.49539307336356,"type":"scivis","id":"scivis-3"},{"x":1318.3683778613677,"y":198.97237749833258,"width":128.34811277322774,"height":123.53801899753697,"type":"scivis","id":"scivis-4"}],"relations":[{"vislist":[{"vislist":["scivis-1","scivis-2","scivis-3","scivis-4"],"relation":null,"id":"group-1"}],"relation":"repeated","id":"relation-0"}]},"1921_1":{"comp":[["scivis","scivis",["repeated"]]],"visType":["scivis"],"compType":["repeated"],"compressed_tree":[{"composite_pattern":"repeated","visualization_type":[["scivis"]]},{"composite_pattern":"repeated","visualization_type":[["scivis"]]}],"coOccurrence":[["scivis","scivis",["coOccurrence"]]],"year":2009,"conference":["Vis"],"authors":["Timo Ropinski","Sven Hermann","Rainer Reich","Michael Sch\xe4fer","Klaus H. Hinrichs"],"title":"Multimodal Vessel Visualization of Mouse Aorta PET/CT Scans","doi":"10.1109/TVCG.2009.169","abstract":"In this paper, we present a visualization system for the visual analysis of PET/CT scans of aortic arches of mice. The system has been designed in close collaboration between researchers from the areas of visualization and molecular imaging with the objective to get deeper insights into the structural and molecular processes which take place during plaque development. Understanding the development of plaques might lead to a better and earlier diagnosis of cardiovascular diseases, which are still the main cause of death in the western world. After motivating our approach, we will briefly describe the multimodal data acquisition process before explaining the visualization techniques used. The main goal is to develop a system which supports visual comparison of the data of different species. Therefore, we have chosen a linked multi-view approach, which amongst others integrates a specialized straightened multipath curved planar reformation and a multimodal vessel flattening technique. We have applied the visualization concepts to multiple data sets, and we will present the results of this investigation.","keywords":"Vessel visualization, plaque growth, multipath CPR, vessel flattening","caption":"Fig. 2. Screenshots of the interactive cropping and registration dialog. By selecting the region of interest, the user can generate a cropped data set (a). By double clicking on a marker, the user initiates a region growing process, which is used to determine the center of the markers, which are depicted by the differently colored circles (b).","img_size":{"width":990,"height":417},"subfigures":[{"x":1.5969544458489462,"y":8.135318037488151,"width":479.08134700756756,"height":355.8005195262829,"type":"interface","id":"interface-0"},{"x":506.74124247197443,"y":4.541214100858007,"width":480.11441570881317,"height":358.8573394088541,"type":"interface","id":"interface-1"}],"visualizations":[{"x":309.95492796565924,"y":23.287626483134257,"width":166.01519234531958,"height":155.54712154106693,"type":"scivis","id":"scivis-0"},{"x":306.23094701200176,"y":187.42804774760023,"width":171.5851638993519,"height":166.81051521337113,"type":"scivis","id":"scivis-1"},{"x":510.0733631876458,"y":111.48681041752356,"width":237.15390057524598,"height":245.39654036145006,"type":"scivis","id":"scivis-2"},{"x":743.5662898707716,"y":115.2256045596538,"width":241.54362588289445,"height":242.30420974030528,"type":"scivis","id":"scivis-3"},{"x":3.0223419726531398,"y":115.8127051100182,"width":243.40112007697255,"height":237.99768173735097,"type":"scivis","id":"scivis-4"}],"relations":[{"vislist":[{"vislist":["scivis-1","scivis-0"],"relation":null,"id":"group-0"}],"relation":"repeated","id":"relation-0"},{"vislist":[{"vislist":["scivis-2","scivis-3"],"relation":null,"id":"group-1"}],"relation":"repeated","id":"relation-1"}]},"1921_3":{"comp":[["scivis","scivis",["repeated"]]],"visType":["scivis"],"compType":["repeated"],"compressed_tree":[{"composite_pattern":"repeated","visualization_type":[["scivis"]]}],"coOccurrence":[["scivis","scivis",["coOccurrence"]]],"year":2009,"conference":["Vis"],"authors":["Timo Ropinski","Sven Hermann","Rainer Reich","Michael Sch\xe4fer","Klaus H. Hinrichs"],"title":"Multimodal Vessel Visualization of Mouse Aorta PET/CT Scans","doi":"10.1109/TVCG.2009.169","abstract":"In this paper, we present a visualization system for the visual analysis of PET/CT scans of aortic arches of mice. The system has been designed in close collaboration between researchers from the areas of visualization and molecular imaging with the objective to get deeper insights into the structural and molecular processes which take place during plaque development. Understanding the development of plaques might lead to a better and earlier diagnosis of cardiovascular diseases, which are still the main cause of death in the western world. After motivating our approach, we will briefly describe the multimodal data acquisition process before explaining the visualization techniques used. The main goal is to develop a system which supports visual comparison of the data of different species. Therefore, we have chosen a linked multi-view approach, which amongst others integrates a specialized straightened multipath curved planar reformation and a multimodal vessel flattening technique. We have applied the visualization concepts to multiple data sets, and we will present the results of this investigation.","keywords":"Vessel visualization, plaque growth, multipath CPR, vessel flattening","caption":"Fig. 4. Multiple linked views are employed to allow a comparative visu- alization of aortic arches of mice while still supporting spatial compre- hension. From upper left to lower right: A multipath straightened CPR, flattening views, showing wall thickness, lumen diameter and PET up- take. The 2D cross section allows in-detail inspection, and the 3D view supports spatial comprehension by providing an overview.","img_size":{"width":1058,"height":635},"subfigures":[{"x":0.6143891962731605,"y":7.6604299375058815,"width":1052.0411958004213,"height":625.0855450624483,"type":"interface","id":"interface-0"}],"visualizations":[{"x":822.754285045004,"y":150.50293939519915,"width":209.83863738071287,"height":79.21728853179158,"type":"line_chart","id":"line_chart-0"},{"x":5.355139626229656,"y":65.39122496271361,"width":793.8954810852334,"height":544.0897864883416,"type":"scivis","id":"scivis-1"}],"relations":[{"vislist":[{"vislist":["scivis-1"],"relation":null,"id":"group-0"}],"relation":"repeated","id":"relation-0"}]},"1922_4":{"comp":[["line_chart","line_chart",["repeated"]]],"visType":["line_chart"],"compType":["repeated"],"compressed_tree":[{"composite_pattern":"repeated","visualization_type":[["line_chart"]]}],"coOccurrence":[],"year":2009,"conference":["Vis"],"authors":["Ralph Brecheisen","Anna Vilanova","Bram Platel","Bart M. ter Haar Romeny"],"title":"Parameter Sensitivity Visualization for DTI fiber Tracking","doi":"10.1109/TVCG.2009.170","abstract":"Fiber tracking of diffusion tensor imaging (DTI) data offers a unique insight into the three-dimensional organisation of white matter structures in the living brain. However, fiber tracking algorithms require a number of user-defined input parameters that strongly affect the output results. Usually the fiber tracking parameters are set once and are then re-used for several patient datasets. However, the stability of the chosen parameters is not evaluated and a small change in the parameter values can give very different results. The user remains completely unaware of such effects. Furthermore, it is difficult to reproduce output results between different users. We propose a visualization tool that allows the user to visually explore how small variations in parameter values affect the output of fiber tracking. With this knowledge the user cannot only assess the stability of commonly used parameter values but also evaluate in a more reliable way the output results between different patients. Existing tools do not provide such information. A small user evaluation of our tool has been done to show the potential of the technique.","keywords":"fiber Tracking, Parameter Sensitivity, Stopping Criteria, Diffusion Tensor Imaging, Uncertainty Visualization","caption":"Fig. 5. Main viewports of our exploration tool. Top-left: 3D visualiza- tion of fiber tract together with anatomical context and axial fractional anisotropy slice. Top-right: color map view used for selecting individual threshold combinations and definition of color detail regions. Bottom- right: feature map view showing changes in quantitative tract features as a function of threshold combination at discrete sample points of the parameter space. Bottom-left: cummulative histograms of both thresh- old and feature values.","img_size":{"width":1044,"height":833},"subfigures":[{"x":564.7362452088222,"y":18.882561998512696,"width":472.98098668177096,"height":411.3705471668397,"type":"single","id":"single-0"},{"x":4.2565553434244725,"y":342.1103395824279,"width":492.1027917545125,"height":469.7005380145459,"type":"single","id":"single-1"},{"x":567.9480068641601,"y":423.1308426753188,"width":470.1031997336312,"height":401.6309379641701,"type":"single","id":"single-2"}],"visualizations":[{"x":571.4703317883477,"y":24.989671448051528,"width":464.83141806652327,"height":393.8371920714179,"type":"heatmap","id":"heatmap-3"},{"x":12.175158513513185,"y":343.5343701084326,"width":481.58418995814014,"height":147.70430518191606,"type":"line_chart","id":"line_chart-0"},{"x":7.749735093476385,"y":495.80656021872807,"width":479.7978277106051,"height":166.7407102388979,"type":"line_chart","id":"line_chart-1"},{"x":5.107242126885028,"y":662.1705248674584,"width":482.4235113718863,"height":145.18224842754262,"type":"line_chart","id":"line_chart-2"}],"relations":[{"vislist":[{"vislist":["line_chart-0","line_chart-1","line_chart-2"],"relation":null,"id":"group-0"}],"relation":"repeated","id":"relation-0"}]},"1927_0":{"comp":[["scivis","scivis",["repeated"]]],"visType":["scivis"],"compType":["repeated"],"compressed_tree":[{"composite_pattern":"repeated","visualization_type":[["scivis"]]}],"coOccurrence":[["scivis","scivis",["coOccurrence"]]],"year":2009,"conference":["Vis"],"authors":["Won-Ki Jeong","Johanna Beyer","Markus Hadwiger","Amelio V\xe1zquez Reina","Hanspeter Pfister","Ross T. Whitaker"],"title":"Scalable and Interactive Segmentation and Visualization of Neural Processes in EM Datasets","doi":"10.1109/TVCG.2009.178","abstract":"Recent advances in scanning technology provide high resolution EM (electron microscopy) datasets that allow neuro-scientists to reconstruct complex neural connections in a nervous system. However, due to the enormous size and complexity of the resulting data, segmentation and visualization of neural processes in EM data is usually a difficult and very time-consuming task. In this paper, we present NeuroTrace, a novel EM volume segmentation and visualization system that consists of two parts: a semi-automatic multiphase level set segmentation with 3D tracking for reconstruction of neural processes, and a specialized volume rendering approach for visualization of EM volumes. It employs view-dependent on-demand filtering and evaluation of a local histogram edge metric, as well as on-the-fly interpolation and ray-casting of implicit surfaces for segmented neural structures. Both methods are implemented on the GPU for interactive performance. NeuroTrace is designed to be scalable to large datasets and data-parallel hardware architectures. A comparison of NeuroTrace with a commonly used manual EM segmentation tool shows that our interactive workflow is faster and easier to use for the reconstruction of complex neural processes.","keywords":"Segmentation, neuroscience, connectome, volume rendering, implicit surface rendering, graphics hardware","caption":"Fig. 1. NeuroTrace allows neuroscientists to interactively explore and segment neural processes in high-resolution EM data.","img_size":{"width":1627,"height":914},"subfigures":[{"x":4.576539747999901,"y":5.214272896033072,"width":1618.8194762526446,"height":904.5441813955008,"type":"interface","id":"interface-0"}],"visualizations":[{"x":225.3471379603341,"y":109.62695941850986,"width":996.2684165580008,"height":715.33137807239,"type":"scivis","id":"scivis-0"},{"x":1271.2871023453527,"y":141.320171586148,"width":352.917224873867,"height":314.3460844227842,"type":"scivis","id":"scivis-1"},{"x":1271.287102345353,"y":493.3946495738267,"width":352.9172248738683,"height":398.6140000778398,"type":"scivis","id":"scivis-2"}],"relations":[{"vislist":[{"vislist":["scivis-1","scivis-2"],"relation":null,"id":"group-0"}],"relation":"repeated","id":"relation-0"}]},"1934_4":{"comp":[["line_chart","line_chart",["repeated"]],["scivis","scivis",["repeated"]]],"visType":["line_chart","scivis"],"compType":["repeated"],"compressed_tree":[{"composite_pattern":"repeated","visualization_type":[["line_chart"]]},{"composite_pattern":"repeated","visualization_type":[["scivis"]]}],"coOccurrence":[["line_chart","scivis",["coOccurrence"]]],"year":2009,"conference":["Vis"],"authors":["Emanuele Santos","Lauro Didier Lins","James P. Ahrens","Juliana Freire","Cl\xe1udio T. Silva"],"title":"VisMashup: Streamlining the Creation of Custom Visualization Applications","doi":"10.1109/TVCG.2009.195","abstract":"Visualization is essential for understanding the increasing volumes of digital data. However, the process required to create insightful visualizations is involved and time consuming. Although several visualization tools are available, including tools with sophisticated visual interfaces, they are out of reach for users who have little or no knowledge of visualization techniques and/or who do not have programming expertise. In this paper, we propose VisMashup, a new framework for streamlining the creation of customized visualization applications. Because these applications can be customized for very specific tasks, they can hide much of the complexity in a visualization specification and make it easier for users to explore visualizations by manipulating a small set of parameters. We describe the framework and how it supports the various tasks a designer needs to carry out to develop an application, from mining and exploring a set of visualization specifications (pipelines), to the creation of simplified views of the pipelines, and the automatic generation of the application and its interface. We also describe the implementation of the system and demonstrate its use in two real application scenarios.","keywords":"Scientific Visualization, Dataflow, Visualization Systems","caption":"Fig. 5: Comparing visualizations derived by two different isosurface algorithms and their associated quality histograms.","img_size":{"width":1038,"height":626},"subfigures":[{"x":9.23529328008157,"y":4.854522172543705,"width":1022.1948649874755,"height":608.2962875662894,"type":"interface","id":"interface-0"}],"visualizations":[{"x":327.2023966937284,"y":36.482856792773795,"width":303.6316601834157,"height":247.23823202465343,"type":"line_chart","id":"line_chart-2"},{"x":628.8619674281971,"y":37.146650875145674,"width":310.7009231234854,"height":247.24308854134702,"type":"line_chart","id":"line_chart-3"},{"x":323.8819910773573,"y":316.56512800709584,"width":305.60793120779135,"height":246.70045579956323,"type":"line_chart","id":"line_chart-4"},{"x":629.5155773129769,"y":317.2236466214878,"width":308.06097758010776,"height":245.38341857077813,"type":"line_chart","id":"line_chart-5"},{"x":15.33856436210813,"y":23.297103066557618,"width":302.310936925643,"height":266.94751606990025,"type":"scivis","id":"scivis-0"},{"x":14.668831509011856,"y":312.3515781367311,"width":300.31858819728905,"height":266.4533353325065,"type":"scivis","id":"scivis-1"}],"relations":[{"vislist":[{"vislist":["line_chart-2","line_chart-3","line_chart-4","line_chart-5"],"relation":null,"id":"group-0"}],"relation":"repeated","id":"relation-0"},{"vislist":[{"vislist":["scivis-0","scivis-1"],"relation":null,"id":"group-1"}],"relation":"repeated","id":"relation-1"}]},"1934_7":{"comp":[["scivis","scivis",["repeated"]]],"visType":["scivis"],"compType":["repeated"],"compressed_tree":[{"composite_pattern":"repeated","visualization_type":[["scivis"]]}],"coOccurrence":[["scivis","scivis",["coOccurrence"]]],"year":2009,"conference":["Vis"],"authors":["Emanuele Santos","Lauro Didier Lins","James P. Ahrens","Juliana Freire","Cl\xe1udio T. Silva"],"title":"VisMashup: Streamlining the Creation of Custom Visualization Applications","doi":"10.1109/TVCG.2009.195","abstract":"Visualization is essential for understanding the increasing volumes of digital data. However, the process required to create insightful visualizations is involved and time consuming. Although several visualization tools are available, including tools with sophisticated visual interfaces, they are out of reach for users who have little or no knowledge of visualization techniques and/or who do not have programming expertise. In this paper, we propose VisMashup, a new framework for streamlining the creation of customized visualization applications. Because these applications can be customized for very specific tasks, they can hide much of the complexity in a visualization specification and make it easier for users to explore visualizations by manipulating a small set of parameters. We describe the framework and how it supports the various tasks a designer needs to carry out to develop an application, from mining and exploring a set of visualization specifications (pipelines), to the creation of simplified views of the pipelines, and the automatic generation of the application and its interface. We also describe the implementation of the system and demonstrate its use in two real application scenarios.","keywords":"Scientific Visualization, Dataflow, Visualization Systems","caption":"Fig. 8: Astrophysics VisMashup for comparing different visualiza- tions. (a) Medley created for the VisMashup using 3 instances of a pipeline view with parameters \u03c1min and propagation time synchro- nized. (b) Using the VisMashup interface, the user explores different values for \u03a9 frame. From top to bottom, the values used are \u22120.06, \u22120.041, and 0.0.","img_size":{"width":900,"height":1168},"subfigures":[{"x":8.070927906688533,"y":4.194724181122337,"width":881.3731195148785,"height":1159.610551637758,"type":"interface","id":"interface-0"}],"visualizations":[{"x":334.04458300773587,"y":306.0605912495658,"width":282.8538397552787,"height":263.76267040754874,"type":"scivis","id":"scivis-0"},{"x":331.5446708872921,"y":563.0977312472593,"width":281.6411023168051,"height":259.33783853242215,"type":"scivis","id":"scivis-1"},{"x":329.08455191864755,"y":829.7536340390544,"width":284.0763155823505,"height":250.5920502823689,"type":"scivis","id":"scivis-2"}],"relations":[{"vislist":[{"vislist":["scivis-0","scivis-1","scivis-2"],"relation":null,"id":"group-0"}],"relation":"repeated","id":"relation-0"}]},"1937_2":{"comp":[["scatterplot","scatterplot",["repeated"]]],"visType":["scatterplot"],"compType":["repeated"],"compressed_tree":[{"composite_pattern":"repeated","visualization_type":[["scatterplot"]]}],"coOccurrence":[["scatterplot","scatterplot",["coOccurrence"]]],"year":2009,"conference":["Vis"],"authors":["Raphael Fuchs","J\xfcrgen Waser","M. Eduard Gr\xf6ller"],"title":"Visual Human+Machine Learning","doi":"10.1109/TVCG.2009.199","abstract":"In this paper we describe a novel method to integrate interactive visual analysis and machine learning to support the insight generation of the user. The suggested approach combines the vast search and processing power of the computer with the superior reasoning and pattern recognition capabilities of the human user. An evolutionary search algorithm has been adapted to assist in the fuzzy logic formalization of hypotheses that aim at explaining features inside multivariate, volumetric data. Up to now, users solely rely on their knowledge and expertise when looking for explanatory theories. However, it often remains unclear whether the selected attribute ranges represent the real explanation for the feature of interest. Other selections hidden in the large number of data variables could potentially lead to similar features. Moreover, as simulation complexity grows, users are confronted with huge multidimensional data sets making it almost impossible to find meaningful hypotheses at all. We propose an interactive cycle of knowledge-based analysis and automatic hypothesis generation. Starting from initial hypotheses, created with linking and brushing, the user steers a heuristic search algorithm to look for alternative or related hypotheses. The results are analyzed in information visualization views that are linked to the volume rendering. Individual properties as well as global aggregates are visually presented to provide insight into the most relevant aspects of the generated hypotheses. This novel approach becomes computationally feasible due to a GPU implementation of the time-critical parts in the algorithm. A thorough evaluation of search times and noise sensitivity as well as a case study on data from the automotive domain substantiate the usefulness of the suggested approach.","keywords":"Interactive Visual Analysis, Volumetric Data, Multiple Competing Hypotheses, Knowledge Discovery, Computerassisted Multivariate Data Exploration, Curse of Dimensionality, Predictive Analysis, Genetic Algorithm","caption":"Fig. 3. Interaction example. (1) The user has the idea that attributes a8 and a9 describe a feature of interest. The resulting feature is shown in a rendering to the right. (2) The user runs the machine learning algorithm to search for hypotheses. The best resulting hypothesis has 65% fitness. The coloring (dark green) shows that attributes a0 and a1 are important in the entire population. (3) The user deactivates genes on other attributes and the fitness increases. (4) Via interactive visual analysis, the user improves the hypothesis. It is still unclear whether there are alternative hypotheses. (5) A larger search has found an alternative hypothesis. (6) The alternative explanation consists of two clauses combined by conjunction (AND). If one of the two clauses is missing, the feature vanishes. (7) The first clause contains the disjunction (OR) of multiple selections. Attributes a2, a3 select the shape \u201dVis\u201d only. (8) Automatic local optimization via hill climbing finds the optimal selections.","img_size":{"width":2154,"height":828},"subfigures":[{"x":1.117074799477789,"y":207.5473744855561,"width":450.95362790025143,"height":206.2399361257083,"type":"interface","id":"interface-0"}],"visualizations":[{"x":64.55449026359558,"y":217.67662972221868,"width":371.4020826855644,"height":125.84421606223464,"type":"scatterplot","id":"scatterplot-0"}],"relations":[{"vislist":[{"vislist":["scatterplot-0"],"relation":null,"id":"group-0"}],"relation":"repeated","id":"relation-0"}]},"3165_4":{"comp":[["others","others",["repeated"]]],"visType":["others"],"compType":["repeated"],"compressed_tree":[{"composite_pattern":"repeated","visualization_type":[["others"]]},{"composite_pattern":"repeated","visualization_type":[["others"]]}],"coOccurrence":[["others","others",["coOccurrence"]]],"year":2019,"conference":["SciVis"],"authors":["Seth Johnson","Francesca Samsel","Gregory Abram","Daniel Olson","Andrew J. Solis","Bridger Herman","Phillip J. Wolfram"],"title":"Artifact-Based Rendering: Harnessing Natural and Traditional Visual Media for More Expressive and Engaging 3D Visualizations","doi":"10.1109/TVCG.2019.2934260","abstract":"We introduce Artifact-Based Rendering (ABR), a framework of tools, algorithms, and processes that makes it possible to produce real, data-driven 3D scientific visualizations with a visual language derived entirely from colors, lines, textures, and forms created using traditional physical media or found in nature. A theory and process for ABR is presented to address three current needs: (i) designing better visualizations by making it possible for non-programmers to rapidly design and critique many alternative data-to-visual mappings; (ii) expanding the visual vocabulary used in scientific visualizations to depict increasingly complex multivariate data; (iii) bringing a more engaging, natural, and human-relatable handcrafted aesthetic to data visualization. New tools and algorithms to support ABR include front-end applets for constructing artifact-based colormaps, optimizing 3D scanned meshes for use in data visualization, and synthesizing textures from artifacts. These are complemented by an interactive rendering engine with custom algorithms and interfaces that demonstrate multiple new visual styles for depicting point, line, surface, and volume data. A within-the-research-team design study provides early evidence of the shift in visualization design processes that ABR is believed to enable when compared to traditional scientific visualization systems. Qualitative user feedback on applications to climate science and brain imaging support the utility of ABR for scientific discovery and public communication.","keywords":"Visualization Design, Art and Visualization, Data Physicalization, Multivariate Visualization","caption":"Fig. 5. The Texture Shaper applet. A: Original source images, B: Select- ing a cropping box; C: Output images and normal maps. ","img_size":{"width":1059,"height":491},"subfigures":[{"x":2.8281308349199077,"y":1.1232565381370445,"width":1048.3762539990178,"height":485.99602326777296,"type":"interface","id":"interface-0"}],"visualizations":[{"x":132.1412883033519,"y":6.415434491421445,"width":489.36757370928365,"height":476.82906934047793,"type":"others","id":"others-0"},{"x":2.205692792022989,"y":2.402830004147472,"width":119.11988632699237,"height":114.32722471331583,"type":"others","id":"others-1"},{"x":3.5455335735861047,"y":121.74077397516582,"width":121.1275928072608,"height":122.22268528019296,"type":"others","id":"others-2"},{"x":4.216311366525594,"y":247.0365407446411,"width":122.46454467475048,"height":122.22268528019234,"type":"others","id":"others-3"},{"x":2.229441571471356,"y":367.6021531334621,"width":128.44716485488595,"height":117.34418192580534,"type":"others","id":"others-4"},{"x":806.7342763217083,"y":4.418083414141541,"width":245.06592218709102,"height":478.81367898001946,"type":"others","id":"others-5"}],"relations":[{"vislist":[{"vislist":["others-5"],"relation":null,"id":"group-0"}],"relation":"repeated","id":"relation-0"},{"vislist":[{"vislist":["others-1","others-2","others-3","others-4"],"relation":null,"id":"group-2"}],"relation":"repeated","id":"relation-1"}]},"3165_5":{"comp":[["others","others",["repeated"]]],"visType":["others"],"compType":["repeated"],"compressed_tree":[{"composite_pattern":"repeated","visualization_type":[["others"]]},{"composite_pattern":"repeated","visualization_type":[["others"]]}],"coOccurrence":[["others","others",["coOccurrence"]]],"year":2019,"conference":["SciVis"],"authors":["Seth Johnson","Francesca Samsel","Gregory Abram","Daniel Olson","Andrew J. Solis","Bridger Herman","Phillip J. Wolfram"],"title":"Artifact-Based Rendering: Harnessing Natural and Traditional Visual Media for More Expressive and Engaging 3D Visualizations","doi":"10.1109/TVCG.2019.2934260","abstract":"We introduce Artifact-Based Rendering (ABR), a framework of tools, algorithms, and processes that makes it possible to produce real, data-driven 3D scientific visualizations with a visual language derived entirely from colors, lines, textures, and forms created using traditional physical media or found in nature. A theory and process for ABR is presented to address three current needs: (i) designing better visualizations by making it possible for non-programmers to rapidly design and critique many alternative data-to-visual mappings; (ii) expanding the visual vocabulary used in scientific visualizations to depict increasingly complex multivariate data; (iii) bringing a more engaging, natural, and human-relatable handcrafted aesthetic to data visualization. New tools and algorithms to support ABR include front-end applets for constructing artifact-based colormaps, optimizing 3D scanned meshes for use in data visualization, and synthesizing textures from artifacts. These are complemented by an interactive rendering engine with custom algorithms and interfaces that demonstrate multiple new visual styles for depicting point, line, surface, and volume data. A within-the-research-team design study provides early evidence of the shift in visualization design processes that ABR is believed to enable when compared to traditional scientific visualization systems. Qualitative user feedback on applications to climate science and brain imaging support the utility of ABR for scientific discovery and public communication.","keywords":"Visualization Design, Art and Visualization, Data Physicalization, Multivariate Visualization","caption":"Fig. 6. The Infinite Line applet. A: The user interface with parameter con- trols and texture synthesis preview. B: Examples of textures synthesized from inkwash, rice grains, and ink dots.","img_size":{"width":1064,"height":784},"subfigures":[{"x":13.486234771530105,"y":1.9853664882906426,"width":1045.373028761696,"height":779.1948927181096,"type":"interface","id":"interface-0"}],"visualizations":[{"x":293.7585801746215,"y":27.460282898371258,"width":71.72617187002048,"height":507.97024329642187,"type":"others","id":"others-0"},{"x":466.89374362927833,"y":21.634529307369657,"width":595.0567683164306,"height":508.7748845094112,"type":"others","id":"others-1"},{"x":16.7976960284256,"y":564.6186455098563,"width":1038.7501062479068,"height":67.7779901081493,"type":"others","id":"others-2"},{"x":15.150096283111493,"y":636.2551299347533,"width":1043.7144053994834,"height":69.84310594474596,"type":"others","id":"others-3"},{"x":16.798619515839512,"y":710.0174055840084,"width":1037.9137094426019,"height":68.33405807527716,"type":"others","id":"others-4"}],"relations":[{"vislist":[{"vislist":["others-1"],"relation":null,"id":"group-0"}],"relation":"repeated","id":"relation-0"},{"vislist":[{"vislist":["others-3","others-4","others-2"],"relation":null,"id":"group-1"}],"relation":"repeated","id":"relation-1"}]},"3174_7":{"comp":[["tree","tree",["repeated"]]],"visType":["tree"],"compType":["repeated"],"compressed_tree":[{"composite_pattern":"repeated","visualization_type":[["tree"]]},{"composite_pattern":"repeated","visualization_type":[["tree"]]}],"coOccurrence":[["tree","tree",["coOccurrence"]]],"year":2019,"conference":["SciVis"],"authors":["Lin Yan","Yusu Wang","Elizabeth Munch","Ellen Gasparovic","Bei Wang"],"title":"A Structural Average of Labeled Merge Trees for Uncertainty Visualization","doi":"10.1109/TVCG.2019.2934242","abstract":"Physical phenomena in science and engineering are frequently modeled using scalar fields. In scalar field topology, graph-based topological descriptors such as merge trees, contour trees, and Reeb graphs are commonly used to characterize topological changes in the (sub)level sets of scalar fields. One of the biggest challenges and opportunities to advance topology-based visualization is to understand and incorporate uncertainty into such topological descriptors to effectively reason about their underlying data. In this paper, we study a structural average of a set of labeled merge trees and use it to encode uncertainty in data. Specifically, we compute a 1-center tree that minimizes its maximum distance to any other tree in the set under a well-defined metric called the interleaving distance. We provide heuristic strategies that compute structural averages of merge trees whose labels do not fully agree. We further provide an interactive visualization system that resembles a numerical calculator that takes as input a set of merge trees and outputs a tree as their structural average. We also highlight structural similarities between the input and the average and incorporate uncertainty information for visual exploration. We develop a novel measure of uncertainty, referred to as consistency, via a metric-space view of the input trees. Finally, we demonstrate an application of our framework through merge trees that arise from ensembles of scalar fields. Our work is the first to employ interleaving distances and consistency to study a global, mathematically rigorous, structural average of merge trees in the context of uncertainty visualization.","keywords":"Topological data analysis, uncertainty visualization, merge trees","caption":"Fig. 8. User interface for the interactive visualization of labeled merge trees and their 1-center.","img_size":{"width":1843,"height":982},"subfigures":[{"x":10.85399215087032,"y":6.659980545071353,"width":1829.6518632528555,"height":974.9506172349589,"type":"interface","id":"interface-0"}],"visualizations":[{"x":1247.8264557713724,"y":108.42117637674271,"width":509.2167222741888,"height":535.5416078457819,"type":"tree","id":"tree-0"},{"x":638.624602101689,"y":104.35161019013141,"width":336.1737467876581,"height":221.98517232762234,"type":"tree","id":"tree-1"},{"x":637.7074492203886,"y":367.0246039166307,"width":377.6304874045989,"height":370.3349756036765,"type":"tree","id":"tree-2"},{"x":26.032603472310296,"y":106.61473838099319,"width":555.3460883934267,"height":628.9028850243685,"type":"tree","id":"tree-3"},{"x":1064.6895531364798,"y":360.72989614018906,"width":180.93255186203675,"height":196.4342068717021,"type":"tree","id":"tree-4"},{"x":1058.9133535486144,"y":561.729465735814,"width":190.154219575746,"height":190.72670928577745,"type":"tree","id":"tree-5"},{"x":23.008820514873417,"y":804.4501744224623,"width":1789.990164584191,"height":171.21097411129432,"type":"tree","id":"tree-6"}],"relations":[{"vislist":[{"vislist":["tree-6"],"relation":null,"id":"group-0"}],"relation":"repeated","id":"relation-0"},{"vislist":[{"vislist":["tree-4","tree-5"],"relation":null,"id":"group-1"}],"relation":"repeated","id":"relation-1"}]},"3176_0":{"comp":[["heatmap","heatmap",["repeated"]]],"visType":["heatmap"],"compType":["repeated"],"compressed_tree":[{"composite_pattern":"repeated","visualization_type":[["heatmap"]]}],"coOccurrence":[["heatmap","heatmap",["coOccurrence"]]],"year":2019,"conference":["SciVis"],"authors":["A. Wentzel","P. Hanula","T. Luciani","B. Elgohari","H. Elhalawani","G. Canahuate","D. Vock","C.D. Fuller","G.E. Marai"],"title":"Cohort-based T-SSIM Visual Computing for Radiation Therapy Prediction and Exploration","doi":"10.1109/TVCG.2019.2934546","abstract":"We describe a visual computing approach to radiation therapy (RT) planning, based on spatial similarity within a patient cohort. In radiotherapy for head and neck cancer treatment, dosage to organs at risk surrounding a tumor is a large cause of treatment toxicity. Along with the availability of patient repositories, this situation has lead to clinician interest in understanding and predicting RT outcomes based on previously treated similar patients. To enable this type of analysis, we introduce a novel topology-based spatial similarity measure, T-SSIM, and a predictive algorithm based on this similarity measure. We couple the algorithm with a visual steering interface that intertwines visual encodings for the spatial data and statistical results, including a novel parallel-marker encoding that is spatially aware. We report quantitative results on a cohort of 165 patients, as well as a qualitative evaluation with domain experts in radiation oncology, data management, biostatistics, and medical imaging, who are collaborating remotely.","keywords":"Biomedical and Medical Visualization, Spatial Techniques, Visual Design, High-Dimensional Data","caption":"Figure 1. Visual computing for cohort-based radiation therapy (RT) prediction. A stylized 3D view of the predicted radiation plan of the current patient is placed centrally; top pale markers (front and back of eyes) receive the least radiation; tumors (black markers) receive the most. Additional RT views show the most similar patients under our novel T-SSIM measure, who contribute to the prediction; the most similar patient is currently highlighted (white) for comparison. A scatterplot (left) shows 4 clusters generated through the T-SSIM measure, with the current (cross) and comparison patient highlighted. A parallel-marker encoding (bottom) shows the predicted (blue cross) per-organ dose distribution within the context of the most similar patients; spatially collocated organs are in contiguous sections of the x-axis. ","img_size":{"width":1956,"height":923},"subfigures":[{"x":2.1913579227048943,"y":4.777150830897887,"width":1947.5394751726487,"height":913.4456983382041,"type":"interface","id":"interface-0"}],"visualizations":[{"x":15.308979921949438,"y":436.2764563856631,"width":1237.7112937428308,"height":467.49818127184864,"type":"glyph_based","id":"glyph_based-3"},{"x":1004.0935835092913,"y":84.21157080107344,"width":275.56957362802837,"height":333.81314333945727,"type":"heatmap","id":"heatmap-0"},{"x":1294.1776384595598,"y":91.56552447312423,"width":263.10087488520685,"height":327.76801836420515,"type":"heatmap","id":"heatmap-1"},{"x":1577.0462088129163,"y":86.67546959178885,"width":262.58950955774526,"height":333.83550711165486,"type":"heatmap","id":"heatmap-2"},{"x":1284.3407649227736,"y":459.3534993034421,"width":276.59053251261605,"height":329.76611039416764,"type":"heatmap","id":"heatmap-4"},{"x":1571.4471887172128,"y":464.59269309129195,"width":271.6334008247067,"height":316.91605953364615,"type":"heatmap","id":"heatmap-5"},{"x":14.647130030562328,"y":57.328446349899025,"width":979.303236786783,"height":370.2538275041087,"type":"scatterplot","id":"scatterplot-6"}],"relations":[{"vislist":[{"vislist":["heatmap-0","heatmap-1","heatmap-2","heatmap-4","heatmap-5"],"relation":null,"id":"group-0"}],"relation":"repeated","id":"relation-0"}]},"3180_4":{"comp":[["bar_chart","bar_chart",["repeated"]]],"visType":["bar_chart"],"compType":["repeated"],"compressed_tree":[{"composite_pattern":"repeated","visualization_type":[["bar_chart"]]}],"coOccurrence":[],"year":2019,"conference":["VAST"],"authors":["Subhashis Hazarika","Haoyu Li","Ko-Chih Wang","Han-Wei Shen","Ching-Shan Chou"],"title":"NNVA: Neural Network Assisted Visual Analysis of Yeast Cell Polarization Simulation (J) (Best Paper Honorable Ment","doi":"10.1109/TVCG.2019.2934591","abstract":"Complex computational models are often designed to simulate real-world physical phenomena in many scientific disciplines. However, these simulation models tend to be computationally very expensive and involve a large number of simulation input parameters, which need to be analyzed and properly calibrated before the models can be applied for real scientific studies. We propose a visual analysis system to facilitate interactive exploratory analysis of high-dimensional input parameter space for a complex yeast cell polarization simulation. The proposed system can assist the computational biologists, who designed the simulation model, to visually calibrate the input parameters by modifying the parameter values and immediately visualizing the predicted simulation outcome without having the need to run the original expensive simulation for every instance. Our proposed visual analysis system is driven by a trained neural network-based surrogate model as the backend analysis framework. In this work, we demonstrate the advantage of using neural networks as surrogate models for visual analysis by incorporating some of the recent advances in the field of uncertainty quantification, interpretability and explainability of neural network-based models. We utilize the trained network to perform interactive parameter sensitivity analysis of the original simulation as well as recommend optimal parameter configurations using the activation maximization framework of neural networks. We also facilitate detail analysis of the trained network to extract useful insights about the simulation model, learned by the network, during the training process. We performed two case studies, and discovered multiple new parameter configurations, which can trigger high cell polarization results in the original simulation model. We evaluated our results by comparing with the original simulation model outcomes as well as the findings from previous parameter analysis performed by our experts.","keywords":"Surrogate modeling, Neural networks, Computational biology, Visual analysis, Parameter analysis","caption":"Fig. 5: Multiple high-level analysis views of our visual analysis system.","img_size":{"width":990,"height":1269},"subfigures":[{"x":8.17636105652554,"y":17.74415753802862,"width":495.7738881827786,"height":293.53794585242434,"type":"interface","id":"interface-0"},{"x":484.4039011062808,"y":7.214250859989545,"width":500.4155123212811,"height":310.5461482642307,"type":"interface","id":"interface-1"},{"x":308.58615846559104,"y":315.4366463593319,"width":681.960469063888,"height":350.4623302378983,"type":"interface","id":"interface-2"},{"x":10.825896788567936,"y":331.21504044638067,"width":308.23496471286495,"height":291.8948024353076,"type":"interface","id":"interface-3"},{"x":7.787685445855433,"y":657.3678931874467,"width":973.0747042786162,"height":240.5780536871214,"type":"interface","id":"interface-4"},{"x":9.147246936598977,"y":915.0914324299574,"width":974.4053557861472,"height":346.37798665741184,"type":"interface","id":"interface-5"}],"visualizations":[{"x":49.30695138176741,"y":29.903076777461305,"width":231.27285552646674,"height":274.62225529925814,"type":"bar_chart","id":"bar_chart-0"},{"x":755.4250713139401,"y":109.6963611666851,"width":216.20881437346847,"height":100.17977972513826,"type":"bar_chart","id":"bar_chart-3"},{"x":755.1119902095788,"y":207.78638567712045,"width":217.25538668924602,"height":98.22300423220219,"type":"bar_chart","id":"bar_chart-4"},{"x":613.737815790159,"y":951.6117675652324,"width":294.3947513107648,"height":222.27096288993496,"type":"bar_chart","id":"bar_chart-6"},{"x":272.0435021030609,"y":15.156003709914334,"width":209.67615060113883,"height":282.5078097315577,"type":"graph","id":"graph-1"},{"x":320.5424979522409,"y":315.00246309325644,"width":655.3479404312436,"height":282.45331071739383,"type":"heatmap","id":"heatmap-10"},{"x":516.6168745530272,"y":45.807007716112246,"width":225.4012919988315,"height":225.2574126634351,"type":"heatmap","id":"heatmap-2"},{"x":613.2967705407241,"y":1192.5434141779335,"width":301.09695123538086,"height":64.53654520643614,"type":"heatmap","id":"heatmap-7"},{"x":161.83481124540552,"y":951.2149216697146,"width":392.2956370856115,"height":307.8944327135128,"type":"heatmap","id":"heatmap-8"},{"x":25.35386407679292,"y":329.6890432725944,"width":265.6797818396882,"height":273.33820508008654,"type":"heatmap","id":"heatmap-9"},{"x":14.443954674199453,"y":676.5512952247237,"width":957.0623161625812,"height":160.59865498561297,"type":"table","id":"table-5"}],"relations":[{"vislist":[{"vislist":["bar_chart-3","bar_chart-4"],"relation":null,"id":"group-0"}],"relation":"repeated","id":"relation-0"}]},"3181_1":{"comp":[["bar_chart","bar_chart",["repeated"]],["bar_chart","scatterplot",["large_view"]]],"visType":["bar_chart","scatterplot"],"compType":["repeated","large_view"],"compressed_tree":[{"composite_pattern":"repeated","visualization_type":[["bar_chart"]]},{"composite_pattern":"repeated","visualization_type":[["bar_chart"]]},{"composite_pattern":"repeated","visualization_type":[["bar_chart"]]},{"composite_pattern":"repeated","visualization_type":[["bar_chart"]]},{"composite_pattern":"large_view","visualization_type":[["bar_chart"],["scatterplot"]]}],"coOccurrence":[["bar_chart","scatterplot",["coOccurrence"]]],"year":2019,"conference":["VAST"],"authors":["Takanori Fujiwara","Oh-Hyun Kwon","Kwan-Liu Ma"],"title":"Supporting Analysis of Dimensionality Reduction Results with Contrastive Learning (J) (Best Paper Honorable Ment","doi":"10.1109/TVCG.2019.2934251","abstract":"Dimensionality reduction (DR) is frequently used for analyzing and visualizing high-dimensional data as it provides a good first glance of the data. However, to interpret the DR result for gaining useful insights from the data, it would take additional analysis effort such as identifying clusters and understanding their characteristics. While there are many automatic methods (e.g., density-based clustering methods) to identify clusters, effective methods for understanding a cluster\'s characteristics are still lacking. A cluster can be mostly characterized by its distribution of feature values. Reviewing the original feature values is not a straightforward task when the number of features is large. To address this challenge, we present a visual analytics method that effectively highlights the essential features of a cluster in a DR result. To extract the essential features, we introduce an enhanced usage of contrastive principal component analysis (cPCA). Our method, called ccPCA (contrasting clusters in PCA), can calculate each feature\'s relative contribution to the contrast between one cluster and other clusters. With ccPCA, we have created an interactive system including a scalable visualization of clusters\' feature contributions. We demonstrate the effectiveness of our method and system with case studies using several publicly available datasets.","keywords":"Dimensionality reduction, contrastive learning, principal component analysis, high-dimensional data, visual analytics","caption":"Fig. 2: A screenshot of our prototype system. The dimensionality reduction (DR) view (a) visualizes a result after DR and clustering. The feature contributions view (b) shows the measures of each feature\u2019s contribution to contrasting each cluster with the others. The feature values of the selected cells in (b) are visualized as histograms, as shown in (c). In (d), we can change the settings for the analysis methods and visualizations. ","img_size":{"width":1919,"height":935},"subfigures":[{"x":7.1363511906603145,"y":2.192388102289306,"width":1904.7272976186798,"height":931.6154008699976,"type":"interface","id":"interface-0"}],"visualizations":[{"x":333.9978142121574,"y":189.18302913807935,"width":527.8048298862448,"height":171.88702950269249,"type":"bar_chart","id":"bar_chart-0"},{"x":542.3312688917983,"y":15.402090285203704,"width":529.7685277129631,"height":165.04481140852025,"type":"bar_chart","id":"bar_chart-1"},{"x":1034.1192486787816,"y":472.54935783639286,"width":532.7046946381854,"height":174.38560816827078,"type":"bar_chart","id":"bar_chart-3"},{"x":806.7068687647245,"y":747.9282753072972,"width":521.5753873375317,"height":168.36247466854235,"type":"bar_chart","id":"bar_chart-4"},{"x":1562.4252910069308,"y":82.42364279456783,"width":344.9027976490694,"height":700.9710929704685,"type":"matrix","id":"matrix-2"},{"x":337.4702490581189,"y":16.79258764533272,"width":1214.9373726882134,"height":906.269675336731,"type":"scatterplot","id":"scatterplot-5"}],"relations":[{"vislist":[{"vislist":["bar_chart-0"],"relation":null,"id":"group-0"}],"relation":"repeated","id":"relation-0"},{"vislist":[{"vislist":["bar_chart-1"],"relation":null,"id":"group-1"}],"relation":"repeated","id":"relation-1"},{"vislist":[{"vislist":["bar_chart-3"],"relation":null,"id":"group-2"}],"relation":"repeated","id":"relation-2"},{"vislist":[{"vislist":["bar_chart-4"],"relation":null,"id":"group-3"}],"relation":"repeated","id":"relation-3"},{"vislist":[{"vislist":["bar_chart-0","bar_chart-1","bar_chart-3","bar_chart-4"],"relation":null,"id":"group-5"},{"vislist":["scatterplot-5"],"relation":null,"id":"group-4"}],"relation":"large_view","id":"relation-4"}]},"3182_5":{"comp":[["table","table",["repeated"]]],"visType":["table"],"compType":["repeated"],"compressed_tree":[{"composite_pattern":"repeated","visualization_type":[["table"]]},{"composite_pattern":"repeated","visualization_type":[["table"]]}],"coOccurrence":[["table","table",["coOccurrence"]]],"year":2019,"conference":["VAST"],"authors":["James Wexler","Mahima Pushkarna","Tolga Bolukbasi","Martin Wattenberg","Fernanda Vi\xe9gas","Jimbo Wilson"],"title":"The What-If Tool: Interactive Probing of Machine Learning Models","doi":"10.1109/TVCG.2019.2934619","abstract":"A key challenge in developing and deploying Machine Learning (ML) systems is understanding their performance across a wide range of inputs. To address this challenge, we created the What-If Tool, an open-source application that allows practitioners to probe, visualize, and analyze ML systems, with minimal coding. The What-If Tool lets practitioners test performance in hypothetical situations, analyze the importance of different data features, and visualize model behavior across multiple models and subsets of input data. It also lets practitioners measure systems according to multiple ML fairness metrics. We describe the design of the tool, and report on real-life usage at different organizations.","keywords":"Interactive Machine Learning, Model Debugging, Model Comparison","caption":"Fig. 6: Performance view of our Census example models broken down by sex, (a) showing performance when the positive classi\ufb01cation thresholds are left at their default levels of 0.5 for each sex, and (b) showing performance when the thresholds have been set to achieve demographic parity between sexes. Each confusion matrix refers to a given model: teal for model 1 (neural network) and orange for model 2 (linear classi\ufb01er). Achieving demographic party on either model requires lowering the threshold for females and raising it for males. ","img_size":{"width":2090,"height":1167},"subfigures":[{"x":8.653701410325192,"y":2.7394887778053523,"width":1001.7712379506407,"height":1109.3577288214217,"type":"interface","id":"interface-0"}],"visualizations":[{"x":148.26135664241164,"y":282.96974720258567,"width":356.9537768506289,"height":261.12438106357985,"type":"line_chart","id":"line_chart-0"},{"x":132.51682454690268,"y":770.6835181078739,"width":380.5135484388936,"height":284.34187435452696,"type":"line_chart","id":"line_chart-3"},{"x":532.083454213623,"y":274.2752145847802,"width":443.03008527076076,"height":142.27445475554217,"type":"table","id":"table-1"},{"x":535.9608909085548,"y":429.4499676391615,"width":433.95366311377137,"height":155.98856930886245,"type":"table","id":"table-2"},{"x":541.2335725266349,"y":767.0174854904719,"width":422.0867511104872,"height":179.24370384942333,"type":"table","id":"table-4"},{"x":543.8760491603284,"y":945.2280958687535,"width":423.4095416787222,"height":140.09033619430735,"type":"table","id":"table-5"}],"relations":[{"vislist":[{"vislist":["table-1","table-2"],"relation":null,"id":"group-0"}],"relation":"repeated","id":"relation-0"},{"vislist":[{"vislist":["table-4","table-5"],"relation":null,"id":"group-1"}],"relation":"repeated","id":"relation-1"}]},"3185_3":{"comp":[["matrix","matrix",["repeated"]]],"visType":["matrix"],"compType":["repeated"],"compressed_tree":[{"composite_pattern":"repeated","visualization_type":[["matrix"]]}],"coOccurrence":[["matrix","matrix",["coOccurrence"]]],"year":2019,"conference":["VAST"],"authors":["Michael Behrisch","Tobias Schreck","Hanspeter Pfister"],"title":"GUIRO: User-Guided Matrix Reordering","doi":"10.1109/TVCG.2019.2934300","abstract":"Matrix representations are one of the main established and empirically proven to be effective visualization techniques for relational (or network) data. However, matrices-similar to node-link diagrams-are most effective if their layout reveals the underlying data topology. Given the many developed algorithms, a practical problem arises: \u201cWhich matrix reordering algorithm should I choose for my dataset at hand?\u201d To make matters worse, different reordering algorithms applied to the same dataset may let significantly different visual matrix patterns emerge. This leads to the question of trustworthiness and explainability of these fully automated, often heuristic, black-box processes. We present GUIRO, a Visual Analytics system that helps novices, network analysts, and algorithm designers to open the black-box. Users can investigate the usefulness and expressiveness of 70 accessible matrix reordering algorithms. For network analysts, we introduce a novel model space representation and two interaction techniques for a user-guided reordering of rows or columns, and especially groups thereof (submatrix reordering). These novel techniques contribute to the understanding of the global and local dataset topology. We support algorithm designers by giving them access to 16 reordering quality metrics and visual exploration means for comparing reordering implementations on a row/column permutation level. We evaluated GUIRO in a guided explorative user study with 12 subjects, a case study demonstrating its usefulness in a real-world scenario, and through an expert study gathering feedback on our design decisions. We found that our proposed methods help even inexperienced users to understand matrix patterns and allow a user-guided steering of reordering algorithms. GUIRO helps to increase the transparency of matrix reordering algorithms, thus helping a broad range of users to get a better insight into the complex reordering process, in turn supporting data and reordering algorithm ...","keywords":"Visual Analytics, matrix, black-box algorithms, seriation, ordering, sorting, steerable algorithm, interaction, 2D projection","caption":"Fig. 4: A simple example demonstrating the basic design of GUIRO. The screenshot shows the Petit Test Suite G95c dataset with three reordering options (left). The projection space (right) depicts that distinct groups of rows/columns can be formed. ","img_size":{"width":1058,"height":493},"subfigures":[{"x":9.986960682649215,"y":6.597167456235703,"width":1043.5402937457554,"height":482.5621923796009,"type":"interface","id":"interface-0"}],"visualizations":[{"x":695.6926640165824,"y":105.24882704993895,"width":347.8239274791438,"height":344.1141029438788,"type":"graph","id":"graph-1"},{"x":357.23254396938455,"y":142.73766065268475,"width":311.42317398005275,"height":328.73911374810854,"type":"matrix","id":"matrix-0"},{"x":34.05585932912325,"y":121.74168040340984,"width":61.99284970439689,"height":61.33290300518396,"type":"matrix","id":"matrix-2"},{"x":32.717309409576245,"y":253.1082896413731,"width":59.98698773998489,"height":57.77087991984267,"type":"matrix","id":"matrix-3"},{"x":32.82116668560444,"y":379.12337960606135,"width":61.22260248799432,"height":56.15523179445066,"type":"matrix","id":"matrix-4"}],"relations":[{"vislist":[{"vislist":["matrix-2","matrix-3","matrix-4"],"relation":null,"id":"group-0"}],"relation":"repeated","id":"relation-0"}]},"3186_0":{"comp":[["scatterplot","scatterplot",["repeated"]],["bar_chart","matrix",["nested"]],["proportional_area_chart","tree",["nested"]]],"visType":["scatterplot","bar_chart","matrix","proportional_area_chart","tree"],"compType":["repeated","nested"],"compressed_tree":[{"composite_pattern":"repeated","visualization_type":[["scatterplot"]]},{"composite_pattern":"nested","visualization_type":[["bar_chart"],["matrix"]]},{"composite_pattern":"nested","visualization_type":[["proportional_area_chart"],["tree"]]}],"coOccurrence":[["scatterplot","bar_chart",["coOccurrence"]],["scatterplot","matrix",["coOccurrence"]],["scatterplot","proportional_area_chart",["coOccurrence"]],["scatterplot","tree",["coOccurrence"]],["bar_chart","matrix",["coOccurrence"]],["bar_chart","proportional_area_chart",["coOccurrence"]],["bar_chart","tree",["coOccurrence"]],["matrix","proportional_area_chart",["coOccurrence"]],["matrix","tree",["coOccurrence"]],["proportional_area_chart","tree",["coOccurrence"]]],"year":2019,"conference":["VAST"],"authors":["Robert Krueger","Johanna Beyer","Won-Dong Jang","Nam Wook Kim","Artem Sokolov","Peter K. Sorger","Hanspeter Pfister"],"title":"Facetto: Combining Unsupervised and Supervised Learning for Hierarchical Phenotype Analysis in Multi-Channel Image Data","doi":"10.1109/TVCG.2019.2934547","abstract":"Facetto is a scalable visual analytics application that is used to discover single-cell phenotypes in high-dimensional multi-channel microscopy images of human tumors and tissues. Such images represent the cutting edge of digital histology and promise to revolutionize how diseases such as cancer are studied, diagnosed, and treated. Highly multiplexed tissue images are complex, comprising 109 or more pixels, 60-plus channels, and millions of individual cells. This makes manual analysis challenging and error-prone. Existing automated approaches are also inadequate, in large part, because they are unable to effectively exploit the deep knowledge of human tissue biology available to anatomic pathologists. To overcome these challenges, Facetto enables a semi-automated analysis of cell types and states. It integrates unsupervised and supervised learning into the image and feature exploration process and offers tools for analytical provenance. Experts can cluster the data to discover new types of cancer and immune cells and use clustering results to train a convolutional neural network that classifies new cells accordingly. Likewise, the output of classifiers can be clustered to discover aggregate patterns and phenotype subsets. We also introduce a new hierarchical approach to keep track of analysis steps and data subsets created by users; this assists in the identification of cell types. Users can build phenotype trees and interact with the resulting hierarchical structures of both high-dimensional feature and image spaces. We report on use-cases in which domain scientists explore various large-scale fluorescence imaging datasets. We demonstrate how Facetto assists users in steering the clustering and classification process, inspecting analysis results, and gaining new scientific insights into cancer biology.","keywords":"Clustering, Classi\ufb01cation, Visual Analysis, Multiplex Tissue Imaging, Digital Pathology, Cancer Systems Biology","caption":"Fig. 1. Multiple coordinated views in Facetto for interactive and hierarchical phenotype analysis of 36-channel image data (image resolution: 31, 616 \xd7 22, 272 pixels; raw image size: 49.8 GB). (a) Phenotype tree resulting from hierarchical data \ufb01ltering and cell calling. (b) Multi-channel visualization of high-resolution CyCIF image data showing the current clustering and classi\ufb01cation results. (c) Ridgeplot of high-dimensional feature data to steer visual analysis and data \ufb01ltering. (d) UMAP projection of the sampled feature space of cells, colored by cluster ID. (e) Scatterplots showing feature value correlations. (f) Table view of all cells and their features. ","img_size":{"width":1959,"height":643},"subfigures":[{"x":2.1996540520830528,"y":6.943990074364153,"width":1952.5586602507399,"height":627.0695531534848,"type":"interface","id":"interface-0"}],"visualizations":[{"x":20.789526668060788,"y":545.6883990203768,"width":1919.8983763622487,"height":86.32806117410927,"type":"bar_chart","id":"bar_chart-6"},{"x":15.86502036081904,"y":519.0078651246066,"width":1930.9861038259203,"height":107.5191346305123,"type":"matrix","id":"matrix-5"},{"x":1330.8860091254874,"y":27.697383671249344,"width":220.07054439208204,"height":488.62063470322926,"type":"parallel_coordinate","id":"parallel_coordinate-3"},{"x":14.155610040241752,"y":31.463674277129936,"width":298.0626086932855,"height":347.4588462532013,"type":"proportional_area_chart","id":"proportional_area_chart-1"},{"x":1573.8559634064059,"y":29.111778757186766,"width":365.87520891474975,"height":360.82378961408733,"type":"scatterplot","id":"scatterplot-4"},{"x":1828.0476723555066,"y":402.03144226468,"width":108.03216741651165,"height":90.29856304140047,"type":"scatterplot","id":"scatterplot-7"},{"x":1691.56301840497,"y":398.0898559772784,"width":130.78107578215707,"height":89.52058329520497,"type":"scatterplot","id":"scatterplot-8"},{"x":1560.511626484843,"y":398.77553364286433,"width":130.27631159512168,"height":104.23422513160305,"type":"scatterplot","id":"scatterplot-9"},{"x":336.1661460209014,"y":27.627495731727926,"width":960.8857026224607,"height":480.0992582612735,"type":"scivis","id":"scivis-2"},{"x":16.615552091147162,"y":30.403578994273893,"width":294.38143944065473,"height":368.13864893533935,"type":"tree","id":"tree-0"}],"relations":[{"vislist":[{"vislist":["scatterplot-7","scatterplot-8","scatterplot-9"],"relation":null,"id":"group-0"}],"relation":"repeated","id":"relation-0"},{"vislist":[{"vislist":["bar_chart-6"],"relation":null,"id":"group-2"},{"vislist":["matrix-5"],"relation":null,"id":"group-1"}],"relation":"nested","id":"relation-1"},{"vislist":[{"vislist":["proportional_area_chart-1"],"relation":null,"id":"group-4"},{"vislist":["tree-0"],"relation":null,"id":"group-3"}],"relation":"nested","id":"relation-2"}]},"3191_0":{"comp":[["bar_chart","bar_chart",["repeated"]],["comb","comb",["repeated"]],["graph","matrix",["nested"]]],"visType":["bar_chart","comb","graph","matrix"],"compType":["repeated","nested"],"compressed_tree":[{"composite_pattern":"repeated","visualization_type":[["bar_chart"]]},{"composite_pattern":"repeated","visualization_type":[[{"composite_pattern":"nested","visualization_type":[["graph"],["matrix"]]}]]}],"coOccurrence":[["graph","matrix",["coOccurrence"]],["graph","bar_chart",["coOccurrence"]],["matrix","bar_chart",["coOccurrence"]]],"year":2019,"conference":["VAST"],"authors":["Tom Polk","Dominik J\xe4ckle","Johannes H\xe4u\xdfler","Jing Yang"],"title":"CourtTime: Generating Actionable Insights into Tennis Matches Using Visual Analytics","doi":"10.1109/TVCG.2019.2934243","abstract":"Tennis players and coaches of all proficiency levels seek to understand and improve their play. Summary statistics alone are inadequate to provide the insights players need to improve their games. Spatio-temporal data capturing player and ball movements is likely to provide the actionable insights needed to identify player strengths, weaknesses, and strategies. To fully utilize this spatio-temporal data, we need to integrate it with domain-relevant context meta-data. In this paper, we propose CourtTime, a novel approach to perform data-driven visual analysis of individual tennis matches. Our visual approach introduces a novel visual metaphor, namely 1-D Space-Time Charts that enable the analysis of single points at a glance based on small multiples. We also employ user-driven sorting and clustering techniques and a layout technique that aligns the last few shots in a point to facilitate shot pattern discovery. We discuss the usefulness of CourtTime via an extensive case study and report on feedback from an amateur tennis player and three tennis coaches.","keywords":"Visual analytics, tennis analysis, sports analytics, spatio-temporal analysis","caption":"Fig. 1. CourtTime visual analytics system. CourtTime provides an overview of the match score (A) and lets the user switch seamlessly between high-level overview of played points (B) and a detailed view on the shot level (C) that displays the serve, return, and last three shots in the point from each player. To facilitate access to the analysis, we provide a rich set of different spatio-temporal encodings, as well as ordering and aggregation capabilities (not shown). An interconnected \ufb01lter list (D) provides a multi-faceted means to effectively drill-down to speci\ufb01c points. We enable shot-speci\ufb01c, spatial feature-driven re-orderings (E) to aid in \ufb01nding shot patterns. A 1-D Space-Time Chart displaying the left/right dimension of a point over time is shown in the inset in (B). Solid circles are forehands and hollow circles are backhands. The inset in (C) shows a second serve by player one up the middle. Clicking on a shot or point opens a new window with a video playing the selected situation. ","img_size":{"width":2053,"height":601},"subfigures":[{"x":5.505948845652188,"y":8.30596501197798,"width":2041.9881023086955,"height":587.5994647501589,"type":"interface","id":"interface-0"}],"visualizations":[{"x":17.70466541331778,"y":430.765643681406,"width":422.16072102182324,"height":69.23712507733505,"type":"bar_chart","id":"bar_chart-0"},{"x":8.661764789915942,"y":507.7934067003742,"width":428.56314591926576,"height":73.88276088418249,"type":"bar_chart","id":"bar_chart-1"},{"x":460.657055656312,"y":12.972565267770072,"width":1558.7782019028814,"height":293.0605120936962,"type":"graph","id":"graph-4"},{"x":477.50585549684973,"y":325.5458897521351,"width":1544.5528961374066,"height":243.59819637495875,"type":"graph","id":"graph-5"},{"x":458.08500291432927,"y":10.459117172778841,"width":1566.5186132422616,"height":300.6864346188921,"type":"matrix","id":"matrix-2"},{"x":474.92923268200127,"y":321.71358252338507,"width":1551.0042946948083,"height":251.26281083245925,"type":"matrix","id":"matrix-3"}],"relations":[{"vislist":[{"vislist":["bar_chart-0","bar_chart-1"],"relation":null,"id":"group-4"}],"relation":"repeated","id":"relation-2"},{"vislist":[{"vislist":[{"vislist":[{"vislist":["graph-4"],"relation":null,"id":"group-1"},{"vislist":["matrix-2"],"relation":null,"id":"group-0"}],"relation":"nested","id":"relation-0"},{"vislist":[{"vislist":["graph-5"],"relation":null,"id":"group-3"},{"vislist":["matrix-3"],"relation":null,"id":"group-2"}],"relation":"nested","id":"relation-1"}],"relation":null,"id":"group-5"}],"relation":"repeated","id":"relation-3"}]},"3192_4":{"comp":[["comb","comb",["repeated"]],["glyph_based","matrix",["nested"]],["bar_chart","matrix",["nested"]]],"visType":["comb","glyph_based","matrix","bar_chart"],"compType":["repeated","nested"],"compressed_tree":[{"composite_pattern":"nested","visualization_type":[["glyph_based","bar_chart"],["matrix"]]},{"composite_pattern":"nested","visualization_type":[["glyph_based","bar_chart"],["matrix"]]},{"composite_pattern":"repeated","visualization_type":[[{"composite_pattern":"nested","visualization_type":[["glyph_based","bar_chart"],["matrix"]]}]]}],"coOccurrence":[["glyph_based","bar_chart",["coOccurrence"]],["glyph_based","matrix",["coOccurrence"]],["bar_chart","matrix",["coOccurrence"]]],"year":2019,"conference":["VAST"],"authors":["Jiachen Wang","Kejian Zhao","Dazhen Deng","Anqi Cao","Xiao Xie","Zheng Zhou","Hui Zhang","Yingcai Wu"],"title":"Tac-Simur: Tactic-based Simulative Visual Analytics of Table Tennis","doi":"10.1109/TVCG.2019.2934630","abstract":"Simulative analysis in competitive sports can provide prospective insights, which can help improve the performance of players in future matches. However, adequately simulating the complex competition process and effectively explaining the simulation result to domain experts are typically challenging. This work presents a design study to address these challenges in table tennis. We propose a well-established hybrid second-order Markov chain model to characterize and simulate the competition process in table tennis. Compared with existing methods, our approach is the first to support the effective simulation of tactics, which represent high-level competition strategies in table tennis. Furthermore, we introduce a visual analytics system called Tac-Simur based on the proposed model for simulative visual analytics. Tac-Simur enables users to easily navigate different players and their tactics based on their respective performance in matches to identify the player and the tactics of interest for further analysis. Then, users can utilize the system to interactively explore diverse simulation tasks and visually explain the simulation results. The effectiveness and usefulness of this work are demonstrated by two case studies, in which domain experts utilize Tac-Simur to find interesting and valuable insights. The domain experts also provide positive feedback on the usability of Tac-Simur. Our work can be extended to other similar sports such as tennis and badminton.","keywords":"Simulative Visual Analytics, Table Tennis, Design Study","caption":"Fig. 5. The system interface. The donut charts and the pie charts encode the scoring rates and utilization rates, respectively. (A) is the player view which displays all matches of Ito Mima and her opponents. It provides navigation of matches. (B) is the tactic view which displays the tactics speci\ufb01ed by stroke placement at the serve phase. It provides navigation of tactics. (C) is the simulation view which is under the exploration mode. It contains (D), the exploration component for implementation of adjustments and (E), the evaluation component for evaluation of adjustments. (D) displays all of the adjustment options speci\ufb01ed by stroke placement and stroke technique. (E) displays the three optimum strategies generated by the system. ","img_size":{"width":2150,"height":1185},"subfigures":[{"x":13.586328905359712,"y":9.275573003956032,"width":2125.3488891896886,"height":1171.4934129297965,"type":"interface","id":"interface-0"}],"visualizations":[{"x":1605.0853700845303,"y":204.0701610703646,"width":102.54264511610334,"height":625.9272260411457,"type":"bar_chart","id":"bar_chart-10"},{"x":1206.223793942565,"y":202.76833607019904,"width":103.2546750175373,"height":635.3296351323834,"type":"bar_chart","id":"bar_chart-11"},{"x":1943.392600654092,"y":212.12050995096152,"width":67.60650401437177,"height":609.8265282799521,"type":"bar_chart","id":"bar_chart-12"},{"x":2013.0364168500284,"y":212.0961689519138,"width":102.33333129365496,"height":605.7959548235044,"type":"bar_chart","id":"bar_chart-13"},{"x":1960.0079837070145,"y":910.0729324919672,"width":154.0106789324472,"height":168.81702835164413,"type":"bar_chart","id":"bar_chart-18"},{"x":521.6946187495056,"y":704.3632528765255,"width":123.70096295218656,"height":460.2286587921438,"type":"bar_chart","id":"bar_chart-6"},{"x":399.71571981733746,"y":697.481334405994,"width":112.0750231745139,"height":469.9132402786628,"type":"bar_chart","id":"bar_chart-7"},{"x":1119.271061608946,"y":198.6627975233985,"width":92.26977628417215,"height":629.9431940441708,"type":"bar_chart","id":"bar_chart-8"},{"x":1530.2507532244053,"y":204.06214178057553,"width":86.00317276179435,"height":624.5835128025424,"type":"bar_chart","id":"bar_chart-9"},{"x":185.90140235220548,"y":694.7666296179018,"width":193.0342267286392,"height":480.781657127572,"type":"glyph_based","id":"glyph_based-14"},{"x":1025.6387835068106,"y":217.55213672647832,"width":83.7680653583886,"height":609.8412892743692,"type":"glyph_based","id":"glyph_based-15"},{"x":1430.6196472787244,"y":214.82811949459713,"width":88.13962955692898,"height":608.4905646472256,"type":"glyph_based","id":"glyph_based-16"},{"x":1843.5636373191137,"y":208.09548977370318,"width":86.45253118226877,"height":617.876568634469,"type":"glyph_based","id":"glyph_based-17"},{"x":919.4218981819516,"y":895.3848468200501,"width":230.94641363142338,"height":180.16685726869198,"type":"glyph_based","id":"glyph_based-19"},{"x":1207.630915885083,"y":892.3205666050222,"width":243.18666758149564,"height":175.76697194373003,"type":"glyph_based","id":"glyph_based-20"},{"x":187.86195506124395,"y":689.2490805987201,"width":462.37020251293137,"height":482.29849243866767,"type":"matrix","id":"matrix-1"},{"x":933.8494921093726,"y":141.9526232357677,"width":373.38670951537296,"height":683.5344626194553,"type":"matrix","id":"matrix-2"},{"x":1344.8321090011634,"y":135.18844103936246,"width":371.19271933888365,"height":687.5445642849969,"type":"matrix","id":"matrix-3"},{"x":1760.4111141678757,"y":136.5310261487161,"width":361.51661477921203,"height":684.8593940662888,"type":"matrix","id":"matrix-4"},{"x":755.1453861876066,"y":862.1254149690815,"width":1356.5105600026088,"height":229.35851612470285,"type":"matrix","id":"matrix-5"},{"x":65.16048585611304,"y":131.3760118060989,"width":645.236694478868,"height":484.4078909334234,"type":"tree","id":"tree-0"}],"relations":[{"vislist":[{"vislist":["glyph_based-14","bar_chart-7","bar_chart-6"],"relation":null,"id":"group-1"},{"vislist":["matrix-1"],"relation":null,"id":"group-0"}],"relation":"nested","id":"relation-0"},{"vislist":[{"vislist":["glyph_based-19","glyph_based-20","bar_chart-18"],"relation":null,"id":"group-9"},{"vislist":["matrix-5"],"relation":null,"id":"group-8"}],"relation":"nested","id":"relation-4"},{"vislist":[{"vislist":[{"vislist":[{"vislist":["glyph_based-15","bar_chart-8","bar_chart-11"],"relation":null,"id":"group-3"},{"vislist":["matrix-2"],"relation":null,"id":"group-2"}],"relation":"nested","id":"relation-1"},{"vislist":[{"vislist":["bar_chart-9","bar_chart-10","glyph_based-16"],"relation":null,"id":"group-5"},{"vislist":["matrix-3"],"relation":null,"id":"group-4"}],"relation":"nested","id":"relation-2"},{"vislist":[{"vislist":["glyph_based-17","bar_chart-12","bar_chart-13"],"relation":null,"id":"group-7"},{"vislist":["matrix-4"],"relation":null,"id":"group-6"}],"relation":"nested","id":"relation-3"}],"relation":null,"id":"group-10"}],"relation":"repeated","id":"relation-5"}]},"3193_2":{"comp":[["sunburst_icicle","sunburst_icicle",["repeated"]]],"visType":["sunburst_icicle"],"compType":["repeated"],"compressed_tree":[{"composite_pattern":"repeated","visualization_type":[["sunburst_icicle"]]}],"coOccurrence":[["sunburst_icicle","sunburst_icicle",["coOccurrence"]]],"year":2019,"conference":["VAST"],"authors":["David Borland","Wenyuan Wang","Jonathan Zhang","Joshua Shrestha","David Gotz"],"title":"Selection Bias Tracking and Detailed Subset Comparison for High-Dimensional Data","doi":"10.1109/TVCG.2019.2934209","abstract":"The collection of large, complex datasets has become common across a wide variety of domains. Visual analytics tools increasingly play a key role in exploring and answering complex questions about these large datasets. However, many visualizations are not designed to concurrently visualize the large number of dimensions present in complex datasets (e.g. tens of thousands of distinct codes in an electronic health record system). This fact, combined with the ability of many visual analytics systems to enable rapid, ad-hoc specification of groups, or cohorts, of individuals based on a small subset of visualized dimensions, leads to the possibility of introducing selection bias-when the user creates a cohort based on a specified set of dimensions, differences across many other unseen dimensions may also be introduced. These unintended side effects may result in the cohort no longer being representative of the larger population intended to be studied, which can negatively affect the validity of subsequent analyses. We present techniques for selection bias tracking and visualization that can be incorporated into high-dimensional exploratory visual analytics systems, with a focus on medical data with existing data hierarchies. These techniques include: (1) tree-based cohort provenance and visualization, including a user-specified baseline cohort that all other cohorts are compared against, and visual encoding of cohort \u201cdrift\u201d, which indicates where selection bias may have occurred, and (2) a set of visualizations, including a novel icicle-plot based visualization, to compare in detail the per-dimension differences between the baseline and a user-specified focus cohort. These techniques are integrated into a medical temporal event sequence visual analytics tool. We present example use cases and report findings from domain expert user interviews.","keywords":"High-dimensional visualization, visual analytics, cohort selection, medical informatics, selection bias","caption":"Fig. 3. Overview of the Cadence visual analytics tool, with selection bias tracking (the focus of this paper) on the left, and temporal event sequence visualization on the right. Closeup images of the selection bias tracking components show the (a) cohort provenance tree, (b) cohort overlap, (c) detailed cohort distance, and (d) selected variable distribution visualizations. ","img_size":{"width":1041,"height":789},"subfigures":[{"x":4.474686808377859,"y":7.719146738553519,"width":1029.5320081698185,"height":773.5617065228926,"type":"interface","id":"interface-0"}],"visualizations":[{"x":21.576101041129792,"y":304.27284539495867,"width":72.04553111084947,"height":170.59005528125897,"type":"sunburst_icicle","id":"sunburst_icicle-1"},{"x":94.07808019713138,"y":298.84173281719524,"width":69.07547709643747,"height":175.014184484821,"type":"sunburst_icicle","id":"sunburst_icicle-2"},{"x":202.7452982075019,"y":106.42134729059842,"width":36.07826878973624,"height":26.156707061574913,"type":"bar_chart","id":"bar_chart-7"},{"x":263.9206470953607,"y":104.45688003859937,"width":412.4139772722596,"height":130.00941439688572,"type":"proportional_area_chart","id":"proportional_area_chart-8"},{"x":701.4235686464298,"y":122.48239441182972,"width":54.564407326816614,"height":63.72934513002744,"type":"scatterplot","id":"scatterplot-10"},{"x":11.731926470110794,"y":89.58010044025303,"width":145.25470581009344,"height":162.28206030361113,"type":"tree","id":"tree-0"}],"relations":[{"vislist":[{"vislist":["sunburst_icicle-1","sunburst_icicle-2"],"relation":null,"id":"group-9"}],"relation":"repeated","id":"relation-5"}]},"3196_0":{"comp":[["scivis","scivis",["large_view","repeated"]],["bar_chart","bar_chart",["repeated"]],["glyph_based","tree",["nested"]]],"visType":["scivis","bar_chart","glyph_based","tree"],"compType":["large_view","repeated","nested"],"compressed_tree":[{"composite_pattern":"nested","visualization_type":[["glyph_based"],["tree"]]},{"composite_pattern":"repeated","visualization_type":[["scivis"]]},{"composite_pattern":"large_view","visualization_type":[["scivis"],["scivis"]]},{"composite_pattern":"repeated","visualization_type":[["bar_chart"]]}],"coOccurrence":[["glyph_based","tree",["coOccurrence"]],["glyph_based","scivis",["coOccurrence"]],["glyph_based","bar_chart",["coOccurrence"]],["tree","scivis",["coOccurrence"]],["tree","bar_chart",["coOccurrence"]],["scivis","bar_chart",["coOccurrence"]]],"year":2019,"conference":["VAST"],"authors":["Andreas Walch","Michael Schw\xe4rzler","Christian Luksch","Elmar Eisemann","Theresia Gschwandtner"],"title":"LightGuider: Guiding Interactive Lighting Design using Suggestions, Provenance, and Quality Visualization","doi":"10.1109/TVCG.2019.2934658","abstract":"LightGuider is a novel guidance-based approach to interactive lighting design, which typically consists of interleaved 3D modeling operations and light transport simulations. Rather than having designers use a trial-and-error approach to match their illumination constraints and aesthetic goals, LightGuider supports the process by simulating potential next modeling steps that can deliver the most significant improvements. LightGuider takes predefined quality criteria and the current focus of the designer into account to visualize suggestions for lighting-design improvements via a specialized provenance tree. This provenance tree integrates snapshot visualizations of how well a design meets the given quality criteria weighted by the designer\'s preferences. This integration facilitates the analysis of quality improvements over the course of a modeling workflow as well as the comparison of alternative design solutions. We evaluate our approach with three lighting designers to illustrate its usefulness.","keywords":"guidance, 3D modeling, lighting design, provenance, global illumination","caption":"Fig. 1. The components of LightGuider : (a) a 3D modeling view to place and modify luminaires, augmented with (b) a provenance tree, depicting several sequential modeling steps and parallel modeling branches, integrating information on the quality of the individual solutions, and providing guidance by pre-simulating and suggesting possible next steps to improve the design. A \ufb01lm-strip-like visualization (c) of screenshots helps to depict the evolution up to the currently selected state. A quality view (d) informs about the ful\ufb01llment level of the illumination constraints that need to be met, using bullet charts. Changing the weights of these constraints (e), and therefore, the lighting designer\u2019s focus, triggers an update of the provenance tree node visualizations (re\ufb02ecting the weights of the constraints in the distribution of the treemap space). Moreover, the de\ufb01ned weights are also considered in the generation of new suggestions, which are tailored towards satisfying constraints with higher weights. ","img_size":{"width":1956,"height":860},"subfigures":[{"x":6.270545126711751,"y":8.440186885377626,"width":1947.5367187285137,"height":850.2580952173096,"type":"interface","id":"interface-0"}],"visualizations":[{"x":1358.353151254657,"y":308.3367949514526,"width":544.4560574849905,"height":122.06277222111531,"type":"bar_chart","id":"bar_chart-4"},{"x":1382.6487494857224,"y":484.6810673187701,"width":546.2549076273709,"height":207.4081847119577,"type":"bar_chart","id":"bar_chart-5"},{"x":1362.9556146373868,"y":727.6775865613304,"width":553.803399058014,"height":131.59885643445517,"type":"bar_chart","id":"bar_chart-6"},{"x":23.1224310695251,"y":410.07440443871366,"width":915.3535549180225,"height":236.5952566560491,"type":"glyph_based","id":"glyph_based-3"},{"x":10.576913048032885,"y":10.093234937547198,"width":1318.9108650661472,"height":841.0509141848637,"type":"scivis","id":"scivis-0"},{"x":5.906884512905778,"y":709.2831836186956,"width":939.8901049173998,"height":138.6904448807071,"type":"scivis","id":"scivis-1"},{"x":19.43887560924764,"y":414.9819366258511,"width":922.7206658385776,"height":231.72972852161058,"type":"tree","id":"tree-2"}],"relations":[{"vislist":[{"vislist":["glyph_based-3"],"relation":null,"id":"group-1"},{"vislist":["tree-2"],"relation":null,"id":"group-0"}],"relation":"nested","id":"relation-0"},{"vislist":[{"vislist":["scivis-1"],"relation":null,"id":"group-2"}],"relation":"repeated","id":"relation-1"},{"vislist":[{"vislist":["scivis-1"],"relation":null,"id":"group-4"},{"vislist":["scivis-0"],"relation":null,"id":"group-3"}],"relation":"large_view","id":"relation-2"},{"vislist":[{"vislist":["bar_chart-4","bar_chart-5","bar_chart-6"],"relation":null,"id":"group-5"}],"relation":"repeated","id":"relation-3"}]},"3197_0":{"comp":[["heatmap","heatmap",["repeated"]],["heatmap","tree",["stacked"]],["bar_chart","bar_chart",["repeated","mirrored"]],["bar_chart","flow_diagram",["nested"]],["line_chart","area_chart",["accompanied"]],["area_chart","line_chart",["accompanied"]],["stripe_graph","parallel_coordinate",["nested"]],["glyph_based","flow_diagram",["nested"]],["tree","heatmap",["stacked"]]],"visType":["heatmap","tree","bar_chart","flow_diagram","line_chart","area_chart","stripe_graph","parallel_coordinate","glyph_based"],"compType":["repeated","stacked","mirrored","nested","accompanied"],"compressed_tree":[{"composite_pattern":"nested","visualization_type":[["stripe_graph"],["parallel_coordinate"]]},{"composite_pattern":"repeated","visualization_type":[["heatmap"]]},{"composite_pattern":"stacked","visualization_type":[["tree","heatmap"]]},{"composite_pattern":"mirrored","visualization_type":[["bar_chart"]]},{"composite_pattern":"repeated","visualization_type":[["bar_chart"]]},{"composite_pattern":"accompanied","visualization_type":[["line_chart","area_chart"]]},{"composite_pattern":"accompanied","visualization_type":[["area_chart","line_chart"]]},{"composite_pattern":"nested","visualization_type":[["glyph_based","bar_chart"],["flow_diagram"]]}],"coOccurrence":[["stripe_graph","parallel_coordinate",["coOccurrence"]],["stripe_graph","heatmap",["coOccurrence"]],["stripe_graph","tree",["coOccurrence"]],["stripe_graph","bar_chart",["coOccurrence"]],["stripe_graph","line_chart",["coOccurrence"]],["stripe_graph","area_chart",["coOccurrence"]],["stripe_graph","glyph_based",["coOccurrence"]],["stripe_graph","flow_diagram",["coOccurrence"]],["parallel_coordinate","heatmap",["coOccurrence"]],["parallel_coordinate","tree",["coOccurrence"]],["parallel_coordinate","bar_chart",["coOccurrence"]],["parallel_coordinate","line_chart",["coOccurrence"]],["parallel_coordinate","area_chart",["coOccurrence"]],["parallel_coordinate","glyph_based",["coOccurrence"]],["parallel_coordinate","flow_diagram",["coOccurrence"]],["heatmap","tree",["coOccurrence"]],["heatmap","bar_chart",["coOccurrence"]],["heatmap","line_chart",["coOccurrence"]],["heatmap","area_chart",["coOccurrence"]],["heatmap","glyph_based",["coOccurrence"]],["heatmap","flow_diagram",["coOccurrence"]],["tree","bar_chart",["coOccurrence"]],["tree","line_chart",["coOccurrence"]],["tree","area_chart",["coOccurrence"]],["tree","glyph_based",["coOccurrence"]],["tree","flow_diagram",["coOccurrence"]],["bar_chart","line_chart",["coOccurrence"]],["bar_chart","area_chart",["coOccurrence"]],["bar_chart","glyph_based",["coOccurrence"]],["bar_chart","flow_diagram",["coOccurrence"]],["line_chart","area_chart",["coOccurrence"]],["line_chart","glyph_based",["coOccurrence"]],["line_chart","flow_diagram",["coOccurrence"]],["area_chart","glyph_based",["coOccurrence"]],["area_chart","flow_diagram",["coOccurrence"]],["glyph_based","flow_diagram",["coOccurrence"]]],"year":2019,"conference":["VAST"],"authors":["Dong Sun","Renfei Huang","Yuanzhe Chen","Yong Wang","Jia Zeng","Mingxuan Yuan","Ting-Chuen Pong","Huamin Qu"],"title":"PlanningVis: A Visual Analytics Approach to Production Planning in Smart Factories","doi":"10.1109/TVCG.2019.2934275","abstract":"Production planning in the manufacturing industry is crucial for fully utilizing factory resources (e.g., machines, raw materials and workers) and reducing costs. With the advent of industry 4.0, plenty of data recording the status of factory resources have been collected and further involved in production planning, which brings an unprecedented opportunity to understand, evaluate and adjust complex production plans through a data-driven approach. However, developing a systematic analytics approach for production planning is challenging due to the large volume of production data, the complex dependency between products, and unexpected changes in the market and the plant. Previous studies only provide summarized results and fail to show details for comparative analysis of production plans. Besides, the rapid adjustment to the plan in the case of an unanticipated incident is also not supported. In this paper, we propose PlanningVis, a visual analytics system to support the exploration and comparison of production plans with three levels of details: a plan overview presenting the overall difference between plans, a product view visualizing various properties of individual products, and a production detail view displaying the product dependency and the daily production details in related factories. By integrating an automatic planning algorithm with interactive visual explorations, PlanningVis can facilitate the efficient optimization of daily production planning as well as support a quick response to unanticipated incidents in manufacturing. Two case studies with real-world data and carefully designed interviews with domain experts demonstrate the effectiveness and usability of PlanningVis.","keywords":"Production Planning, Time Series Data, Comparative Analysis, Visual Analytics, Smart Factory, Industry 4.0 ","caption":"Fig. 1. PlanningVis supports interactive exploration, comparison and optimization of production plans. (a) The control panel enables interactively building the con\ufb01guration data of the planning algorithm. (b) The plan overview summarizes each plan and their differences. (c) The product view reveals the distribution of all the products (c1 ) and presents various properties of the selected products (c2 ). (d) The production detail view displays the dependency between products (d1 , d2 ) and the daily production details in related plants (d3 , d4 ). ","img_size":{"width":1755,"height":1029},"subfigures":[{"x":3.465607766299326,"y":9.144236065368554,"width":1741.4990311603415,"height":1016.1871092478515,"type":"interface","id":"interface-0"}],"visualizations":[{"x":7.336840692966783,"y":85.73652054133404,"width":339.85769425259974,"height":318.42354785859584,"type":"area_chart","id":"area_chart-0"},{"x":785.4567079876722,"y":614.3541138418003,"width":818.8473234341332,"height":53.204483677286625,"type":"area_chart","id":"area_chart-10"},{"x":794.1061952295686,"y":888.109387786645,"width":805.1641698172175,"height":41.66326157652281,"type":"area_chart","id":"area_chart-11"},{"x":13.94628321330818,"y":709.889826805213,"width":328.85825235670677,"height":260.5533650799579,"type":"area_chart","id":"area_chart-2"},{"x":6.185495452813444,"y":496.21643240899107,"width":322.18539642981165,"height":167.4605559740557,"type":"bar_chart","id":"bar_chart-1"},{"x":364.0744320037045,"y":22.875982800930164,"width":146.84192908399964,"height":92.50721324553781,"type":"bar_chart","id":"bar_chart-15"},{"x":624.0879756870954,"y":28.38031380705419,"width":150.6034238872747,"height":90.37268145647727,"type":"bar_chart","id":"bar_chart-16"},{"x":883.2258495259973,"y":36.06518702515694,"width":151.67737208994873,"height":82.76779896556303,"type":"bar_chart","id":"bar_chart-17"},{"x":1139.2654335734326,"y":33.874564710811164,"width":157.83817830316582,"height":86.03977731635558,"type":"bar_chart","id":"bar_chart-18"},{"x":1401.57600718811,"y":29.485121567866486,"width":146.16997112218507,"height":91.49086476854924,"type":"bar_chart","id":"bar_chart-19"},{"x":782.1700616769549,"y":485.69628653465054,"width":828.7497807727474,"height":121.94487104882019,"type":"bar_chart","id":"bar_chart-6"},{"x":785.4840598317858,"y":623.5902994012982,"width":823.2315060354791,"height":119.03634967858873,"type":"bar_chart","id":"bar_chart-7"},{"x":784.866083637601,"y":758.5682359946635,"width":825.8638361459423,"height":121.04442814090777,"type":"bar_chart","id":"bar_chart-8"},{"x":789.2668942661119,"y":888.9498584103574,"width":819.2816580337048,"height":87.68077027874173,"type":"bar_chart","id":"bar_chart-9"},{"x":364.4326384169684,"y":26.490826394201367,"width":1198.1415668871614,"height":160.70763295610215,"type":"flow_diagram","id":"flow_diagram-28"},{"x":362.1811352830434,"y":27.574335116773067,"width":1189.3279142862823,"height":156.32208295516148,"type":"glyph_based","id":"glyph_based-29"},{"x":591.8636282764662,"y":493.947518007272,"width":145.13965964769875,"height":508.1060669807815,"type":"heatmap","id":"heatmap-14"},{"x":946.6376080339242,"y":214.6473817737633,"width":657.3951513387848,"height":251.3956251923028,"type":"heatmap","id":"heatmap-20"},{"x":792.1119586658587,"y":612.1787982608885,"width":812.195151512122,"height":55.33658228331513,"type":"line_chart","id":"line_chart-12"},{"x":795.2159168019634,"y":881.7938443220838,"width":805.1641698172201,"height":58.73141361724109,"type":"line_chart","id":"line_chart-13"},{"x":532.0309135621715,"y":205.07098715230228,"width":380.2161326052833,"height":270.54841443522446,"type":"parallel_coordinate","id":"parallel_coordinate-3"},{"x":531.014452335005,"y":209.1801448270221,"width":382.249055059617,"height":261.2208328078868,"type":"stripe_graph","id":"stripe_graph-4"},{"x":369.70863193326585,"y":505.7261559341568,"width":204.37626671331597,"height":476.7839271817191,"type":"tree","id":"tree-5"}],"relations":[{"vislist":[{"vislist":["stripe_graph-4"],"relation":null,"id":"group-1"},{"vislist":["parallel_coordinate-3"],"relation":null,"id":"group-0"}],"relation":"nested","id":"relation-0"},{"vislist":[{"vislist":["heatmap-20"],"relation":null,"id":"group-2"}],"relation":"repeated","id":"relation-1"},{"vislist":[{"vislist":["tree-5","heatmap-14"],"relation":null,"id":"group-3"}],"relation":"stacked","id":"relation-2"},{"vislist":[{"vislist":["bar_chart-9","bar_chart-7"],"relation":null,"id":"group-4"}],"relation":"mirrored","id":"relation-3"},{"vislist":[{"vislist":["bar_chart-6","bar_chart-7","bar_chart-8","bar_chart-9"],"relation":null,"id":"group-5"}],"relation":"repeated","id":"relation-4"},{"vislist":[{"vislist":["line_chart-12","area_chart-10"],"relation":null,"id":"group-6"}],"relation":"accompanied","id":"relation-5"},{"vislist":[{"vislist":["area_chart-11","line_chart-13"],"relation":null,"id":"group-7"}],"relation":"accompanied","id":"relation-6"},{"vislist":[{"vislist":["glyph_based-29","bar_chart-19","bar_chart-18","bar_chart-17","bar_chart-16","bar_chart-15"],"relation":null,"id":"group-9"},{"vislist":["flow_diagram-28"],"relation":null,"id":"group-8"}],"relation":"nested","id":"relation-7"}]},"3199_0":{"comp":[["bar_chart","comb",["repeated"]],["comb","bar_chart",["repeated"]],["area_chart","line_chart",["repeated"]],["area_chart","area_chart",["repeated"]],["line_chart","area_chart",["repeated"]],["line_chart","line_chart",["repeated"]],["line_chart","matrix",["nested"]],["line_chart","comb",["large_view"]],["polar_plot","polar_plot",["repeated"]]],"visType":["bar_chart","comb","area_chart","line_chart","matrix","polar_plot"],"compType":["repeated","nested","large_view"],"compressed_tree":[{"composite_pattern":"large_view","visualization_type":[["line_chart"],[{"composite_pattern":"nested","visualization_type":[["line_chart"],["matrix"]]}]]},{"composite_pattern":"repeated","visualization_type":[["bar_chart",{"composite_pattern":"repeated","visualization_type":[["area_chart","line_chart"]]}]]},{"composite_pattern":"repeated","visualization_type":[["line_chart"]]},{"composite_pattern":"repeated","visualization_type":[["polar_plot"]]},{"composite_pattern":"repeated","visualization_type":[["area_chart"]]}],"coOccurrence":[["line_chart","matrix",["coOccurrence"]],["line_chart","area_chart",["coOccurrence"]],["line_chart","bar_chart",["coOccurrence"]],["line_chart","polar_plot",["coOccurrence"]],["matrix","area_chart",["coOccurrence"]],["matrix","bar_chart",["coOccurrence"]],["matrix","polar_plot",["coOccurrence"]],["area_chart","bar_chart",["coOccurrence"]],["area_chart","polar_plot",["coOccurrence"]],["bar_chart","polar_plot",["coOccurrence"]]],"year":2019,"conference":["VAST"],"authors":["Xuanwu Yue","Jiaxin Bai","Qinhan Liu","Yiyang Tang","Abishek Puri","Ke Li","Huamin Qu"],"title":"sPortfolio: Stratified Visual Analysis of Stock Portfolios","doi":"10.1109/TVCG.2019.2934660","abstract":"Quantitative Investment, built on the solid foundation of robust financial theories, is at the center stage in investment industry today. The essence of quantitative investment is the multi-factor model, which explains the relationship between the risk and return of equities. However, the multi-factor model generates enormous quantities of factor data, through which even experienced portfolio managers find it difficult to navigate. This has led to portfolio analysis and factor research being limited by a lack of intuitive visual analytics tools. Previous portfolio visualization systems have mainly focused on the relationship between the portfolio return and stock holdings, which is insufficient for making actionable insights or understanding market trends. In this paper, we present sPortfolio, which, to the best of our knowledge, is the first visualization that attempts to explore the factor investment area. In particular, sPortfolio provides a holistic overview of the factor data and aims to facilitate the analysis at three different levels: a Risk-Factor level, for a general market situation analysis; a Multiple-Portfolio level, for understanding the portfolio strategies; and a Single-Portfolio level, for investigating detailed operations. The system\'s effectiveness and usability are demonstrated through three case studies. The system has passed its pilot study and is soon to be deployed in industry.","keywords":"Stock portfolio, visual analytics, factor investment, \ufb01nancial data analysis","caption":"Fig. 1. With sPortfolio, we can observe the management and strategy of stock portfolios from different perspectives. A) The portfolio cluster view gives an overview of all stock portfolios within a given time-period. B) The factor correlation view reveals the return correlations of risk factors, which can be used to validate the effectiveness of the factors in a multi-factor model. C) The comparison view is designed to compare the risk preference and sector position of portfolios, which reveals their strategies. D) The individual portfolio view illustrates the stock holdings and trading style of a speci\ufb01c portfolio. ","img_size":{"width":1953,"height":984},"subfigures":[{"x":11.36040050553349,"y":9.768516178953957,"width":1929.232361832599,"height":966.5574174288881,"type":"interface","id":"interface-0"}],"visualizations":[{"x":834.3540287582957,"y":376.2468621321164,"width":279.35225876629033,"height":137.54068040521798,"type":"area_chart","id":"area_chart-12"},{"x":1442.8417621247272,"y":378.5606031448523,"width":284.03258793454347,"height":123.02208308179394,"type":"area_chart","id":"area_chart-17"},{"x":1138.6530161115445,"y":381.099700051448,"width":291.919511487475,"height":130.30778339104373,"type":"area_chart","id":"area_chart-18"},{"x":141.44533588236723,"y":746.9332972709508,"width":1798.5411048803544,"height":206.09121390159976,"type":"area_chart","id":"area_chart-4"},{"x":531.1608430749595,"y":379.7670977320746,"width":275.68769106879824,"height":120.60909390734977,"type":"area_chart","id":"area_chart-8"},{"x":28.285399161306668,"y":754.224623153007,"width":66.27638448488905,"height":190.18383397104623,"type":"bar_chart","id":"bar_chart-5"},{"x":829.5226115359169,"y":109.2471608368196,"width":296.42461878672566,"height":121.34679454721008,"type":"line_chart","id":"line_chart-11"},{"x":1134.8587036583003,"y":110.43955670291203,"width":285.92400617188645,"height":115.25283457829327,"type":"line_chart","id":"line_chart-15"},{"x":1454.8295251742015,"y":111.66820310315157,"width":278.58087577479233,"height":115.26832060230147,"type":"line_chart","id":"line_chart-16"},{"x":18.243953339898695,"y":461.13744118695,"width":467.9498432751329,"height":213.80101533211774,"type":"line_chart","id":"line_chart-2"},{"x":33.63176872853643,"y":574.1434929087031,"width":229.70749637886686,"height":108.95507428852913,"type":"line_chart","id":"line_chart-3"},{"x":147.59624660113403,"y":755.5373469502498,"width":1788.7091253013773,"height":196.21311226226868,"type":"line_chart","id":"line_chart-6"},{"x":523.7995134068298,"y":112.88227276481194,"width":283.0008248293795,"height":112.84018127898152,"type":"line_chart","id":"line_chart-9"},{"x":25.619147381576152,"y":462.4625301033733,"width":463.078822626012,"height":219.893902139174,"type":"matrix","id":"matrix-1"},{"x":835.4914346735126,"y":237.09305882360383,"width":278.3123678651327,"height":142.82785510760638,"type":"polar_plot","id":"polar_plot-10"},{"x":1447.7395038274915,"y":242.08157472378488,"width":282.8815510339673,"height":135.10197394043556,"type":"polar_plot","id":"polar_plot-13"},{"x":1145.4427495660032,"y":231.13015235826433,"width":286.0685669977399,"height":150.82287161025513,"type":"polar_plot","id":"polar_plot-14"},{"x":534.8267002123597,"y":262.8280869081639,"width":268.355976793996,"height":114.62756957982424,"type":"polar_plot","id":"polar_plot-7"},{"x":35.43267866885606,"y":106.51842310191643,"width":453.33112748568965,"height":282.5893359597662,"type":"scatterplot","id":"scatterplot-0"}],"relations":[{"vislist":[{"vislist":["line_chart-3"],"relation":null,"id":"group-3"},{"vislist":[{"vislist":[{"vislist":["line_chart-2"],"relation":null,"id":"group-1"},{"vislist":["matrix-1"],"relation":null,"id":"group-0"}],"relation":"nested","id":"relation-0"}],"relation":null,"id":"group-2"}],"relation":"large_view","id":"relation-1"},{"vislist":[{"vislist":["bar_chart-5",{"vislist":[{"vislist":["area_chart-4","line_chart-6"],"relation":null,"id":"group-4"}],"relation":"repeated","id":"relation-2"}],"relation":null,"id":"group-5"}],"relation":"repeated","id":"relation-3"},{"vislist":[{"vislist":["line_chart-16","line_chart-15","line_chart-11","line_chart-9"],"relation":null,"id":"group-6"}],"relation":"repeated","id":"relation-4"},{"vislist":[{"vislist":["polar_plot-7","polar_plot-10","polar_plot-14","polar_plot-13"],"relation":null,"id":"group-7"}],"relation":"repeated","id":"relation-5"},{"vislist":[{"vislist":["area_chart-8","area_chart-12","area_chart-18","area_chart-17"],"relation":null,"id":"group-8"}],"relation":"repeated","id":"relation-6"}]},"3200_0":{"comp":[["graph","graph",["repeated"]],["comb","comb",["repeated"]],["bar_chart","chord_diagram",["nested"]],["box_plot","table",["nested"]],["glyph_based","graph",["nested"]],["scatterplot","heatmap",["nested"]]],"visType":["graph","comb","bar_chart","chord_diagram","box_plot","table","glyph_based","scatterplot","heatmap"],"compType":["repeated","nested"],"compressed_tree":[{"composite_pattern":"nested","visualization_type":[["bar_chart"],["chord_diagram"]]},{"composite_pattern":"repeated","visualization_type":[["graph"]]},{"composite_pattern":"nested","visualization_type":[["box_plot"],["table"]]},{"composite_pattern":"repeated","visualization_type":[[{"composite_pattern":"nested","visualization_type":[["glyph_based"],["graph"]]}]]},{"composite_pattern":"repeated","visualization_type":[[{"composite_pattern":"nested","visualization_type":[["scatterplot"],["heatmap"]]}]]}],"coOccurrence":[["bar_chart","chord_diagram",["coOccurrence"]],["bar_chart","glyph_based",["coOccurrence"]],["bar_chart","graph",["coOccurrence"]],["bar_chart","box_plot",["coOccurrence"]],["bar_chart","table",["coOccurrence"]],["bar_chart","scatterplot",["coOccurrence"]],["bar_chart","heatmap",["coOccurrence"]],["chord_diagram","glyph_based",["coOccurrence"]],["chord_diagram","graph",["coOccurrence"]],["chord_diagram","box_plot",["coOccurrence"]],["chord_diagram","table",["coOccurrence"]],["chord_diagram","scatterplot",["coOccurrence"]],["chord_diagram","heatmap",["coOccurrence"]],["glyph_based","graph",["coOccurrence"]],["glyph_based","box_plot",["coOccurrence"]],["glyph_based","table",["coOccurrence"]],["glyph_based","scatterplot",["coOccurrence"]],["glyph_based","heatmap",["coOccurrence"]],["graph","box_plot",["coOccurrence"]],["graph","table",["coOccurrence"]],["graph","scatterplot",["coOccurrence"]],["graph","heatmap",["coOccurrence"]],["box_plot","table",["coOccurrence"]],["box_plot","scatterplot",["coOccurrence"]],["box_plot","heatmap",["coOccurrence"]],["table","scatterplot",["coOccurrence"]],["table","heatmap",["coOccurrence"]],["scatterplot","heatmap",["coOccurrence"]]],"year":2019,"conference":["VAST"],"authors":["Zikun Deng","Di Weng","Jiahui Chen","Ren Liu","Zhibin Wang","Jie Bao","Yu Zheng","Yingcai Wu"],"title":"AirVis: Visual Analytics of Air Pollution Propagation","doi":"10.1109/TVCG.2019.2934670","abstract":"Air pollution has become a serious public health problem for many cities around the world. To find the causes of air pollution, the propagation processes of air pollutants must be studied at a large spatial scale. However, the complex and dynamic wind fields lead to highly uncertain pollutant transportation. The state-of-the-art data mining approaches cannot fully support the extensive analysis of such uncertain spatiotemporal propagation processes across multiple districts without the integration of domain knowledge. The limitation of these automated approaches motivates us to design and develop AirVis, a novel visual analytics system that assists domain experts in efficiently capturing and interpreting the uncertain propagation patterns of air pollution based on graph visualizations. Designing such a system poses three challenges: a) the extraction of propagation patterns; b) the scalability of pattern presentations; and c) the analysis of propagation processes. To address these challenges, we develop a novel pattern mining framework to model pollutant transportation and extract frequent propagation patterns efficiently from large-scale atmospheric data. Furthermore, we organize the extracted patterns hierarchically based on the minimum description length (MDL) principle and empower expert users to explore and analyze these patterns effectively on the basis of pattern topologies. We demonstrated the effectiveness of our approach through two case studies conducted with a real-world dataset and positive feedback from domain experts.","keywords":"Air pollution propagation, pattern mining, graph visualization","caption":"Fig. 1. The system interface of AirVis: (A) the control panel enables the interactive mining, \ufb01ltering, and selection of the propagation patterns; (B) the motif view presents the extracted signi\ufb01cant motifs with uncertainty-aware visualizations; (C) the pattern view depicts the patterns with compact pattern glyphs and pattern graphs; (D) the instance view helps users inspect the propagation instances. ","img_size":{"width":1952,"height":994},"subfigures":[{"x":7.159728656883061,"y":6.732349893142281,"width":1937.6805426862318,"height":984.7667699049239,"type":"interface","id":"interface-0"}],"visualizations":[{"x":383.7524120879245,"y":58.07016704518632,"width":83.50973633263978,"height":154.17271955821224,"type":"bar_chart","id":"bar_chart-17"},{"x":386.19549150182996,"y":225.04603202052607,"width":78.62357750482911,"height":152.42540695997315,"type":"bar_chart","id":"bar_chart-18"},{"x":1442.55489497615,"y":133.56616663316439,"width":473.9792246444755,"height":457.6462430056699,"type":"bar_chart","id":"bar_chart-2"},{"x":1626.4019973806285,"y":668.1783588534473,"width":292.9814333457963,"height":93.03915592072633,"type":"box_plot","id":"box_plot-16"},{"x":1447.527486533582,"y":132.2829489747446,"width":475.1426390132677,"height":449.09803238878595,"type":"chord_diagram","id":"chord_diagram-1"},{"x":993.9426184123545,"y":65.28362791375399,"width":386.2414675543225,"height":350.92407056184845,"type":"glyph_based","id":"glyph_based-14"},{"x":989.0686569033616,"y":434.45123880773366,"width":395.98939057230825,"height":384.43926083811067,"type":"glyph_based","id":"glyph_based-15"},{"x":464.13196613225557,"y":222.58896405147757,"width":199.23127672615146,"height":152.39970026086002,"type":"graph","id":"graph-10"},{"x":466.5976879511045,"y":379.86089014342866,"width":200.47127613493004,"height":156.47569817706912,"type":"graph","id":"graph-11"},{"x":996.5837032450786,"y":55.56083686544338,"width":387.130740935351,"height":371.6046133177724,"type":"graph","id":"graph-12"},{"x":984.3286296386412,"y":427.14690453225944,"width":405.4694451017502,"height":397.8129687297571,"type":"graph","id":"graph-13"},{"x":467.70565883720496,"y":58.04366752393232,"width":193.3181799255471,"height":149.2858759635091,"type":"graph","id":"graph-9"},{"x":26.465275653995818,"y":707.6767452299868,"width":319.1800287938742,"height":263.504436346803,"type":"heatmap","id":"heatmap-0"},{"x":681.9717896193614,"y":54.33147475658566,"width":181.97546830308502,"height":162.33982568846642,"type":"heatmap","id":"heatmap-4"},{"x":690.4928733746489,"y":230.33443634978474,"width":162.46472357391764,"height":156.66812621308972,"type":"heatmap","id":"heatmap-5"},{"x":692.9113368646757,"y":402.2528189639719,"width":167.50210546822734,"height":163.5601882266975,"type":"heatmap","id":"heatmap-6"},{"x":696.556885004377,"y":578.2645678468562,"width":157.74243197023634,"height":169.67528165872847,"type":"heatmap","id":"heatmap-7"},{"x":683.0812644192332,"y":754.5378790061093,"width":171.11649843827166,"height":164.15260460429482,"type":"heatmap","id":"heatmap-8"},{"x":719.7127626599387,"y":90.92854380128409,"width":111.43067665911198,"height":104.51045461695196,"type":"scatterplot","id":"scatterplot-25"},{"x":716.0817092640557,"y":259.0964280992365,"width":123.62993788806016,"height":106.55390667000276,"type":"scatterplot","id":"scatterplot-26"},{"x":719.7371678754089,"y":426.4010920361957,"width":116.3190206653538,"height":120.20348471946225,"type":"scatterplot","id":"scatterplot-27"},{"x":716.0513516078263,"y":607.9448201146023,"width":117.51921015404159,"height":102.90501316742066,"type":"scatterplot","id":"scatterplot-28"},{"x":717.2819875390147,"y":790.2255615093709,"width":117.52651551025612,"height":97.17184312873336,"type":"scatterplot","id":"scatterplot-29"},{"x":1423.0054758011688,"y":603.0051852090128,"width":518.015217431609,"height":332.06204122823823,"type":"table","id":"table-3"}],"relations":[{"vislist":[{"vislist":["bar_chart-2"],"relation":null,"id":"group-1"},{"vislist":["chord_diagram-1"],"relation":null,"id":"group-0"}],"relation":"nested","id":"relation-0"},{"vislist":[{"vislist":["graph-9","graph-10","graph-11"],"relation":null,"id":"group-7"}],"relation":"repeated","id":"relation-3"},{"vislist":[{"vislist":["box_plot-16"],"relation":null,"id":"group-9"},{"vislist":["table-3"],"relation":null,"id":"group-8"}],"relation":"nested","id":"relation-4"},{"vislist":[{"vislist":[{"vislist":[{"vislist":["glyph_based-14"],"relation":null,"id":"group-4"},{"vislist":["graph-12"],"relation":null,"id":"group-3"}],"relation":"nested","id":"relation-1"},{"vislist":[{"vislist":["glyph_based-15"],"relation":null,"id":"group-6"},{"vislist":["graph-13"],"relation":null,"id":"group-5"}],"relation":"nested","id":"relation-2"}],"relation":null,"id":"group-10"}],"relation":"repeated","id":"relation-5"},{"vislist":[{"vislist":[{"vislist":[{"vislist":["scatterplot-29"],"relation":null,"id":"group-20"},{"vislist":["heatmap-8"],"relation":null,"id":"group-19"}],"relation":"nested","id":"relation-10"},{"vislist":[{"vislist":["scatterplot-28"],"relation":null,"id":"group-18"},{"vislist":["heatmap-7"],"relation":null,"id":"group-17"}],"relation":"nested","id":"relation-9"},{"vislist":[{"vislist":["scatterplot-27"],"relation":null,"id":"group-16"},{"vislist":["heatmap-6"],"relation":null,"id":"group-15"}],"relation":"nested","id":"relation-8"},{"vislist":[{"vislist":["scatterplot-26"],"relation":null,"id":"group-14"},{"vislist":["heatmap-5"],"relation":null,"id":"group-13"}],"relation":"nested","id":"relation-7"},{"vislist":[{"vislist":["scatterplot-25"],"relation":null,"id":"group-12"},{"vislist":["heatmap-4"],"relation":null,"id":"group-11"}],"relation":"nested","id":"relation-6"}],"relation":null,"id":"group-21"}],"relation":"repeated","id":"relation-11"}]},"3203_0":{"comp":[["table","table",["repeated"]],["line_chart","line_chart",["repeated"]],["box_plot","scatterplot",["accompanied"]],["scatterplot","box_plot",["accompanied"]]],"visType":["table","line_chart","box_plot","scatterplot"],"compType":["repeated","accompanied"],"compressed_tree":[{"composite_pattern":"accompanied","visualization_type":[["box_plot","scatterplot"]]},{"composite_pattern":"repeated","visualization_type":[["table"]]},{"composite_pattern":"repeated","visualization_type":[["line_chart"]]}],"coOccurrence":[["box_plot","scatterplot",["coOccurrence"]],["box_plot","table",["coOccurrence"]],["box_plot","line_chart",["coOccurrence"]],["scatterplot","table",["coOccurrence"]],["scatterplot","line_chart",["coOccurrence"]],["table","line_chart",["coOccurrence"]]],"year":2019,"conference":["VAST"],"authors":["Mosab Khayat","Morteza Karimzadeh","Jieqiong Zhao","David S. Ebert"],"title":"VASSL: A Visual Analytics Toolkit for Social Spambot Labeling","doi":"10.1109/TVCG.2019.2934266","abstract":"Social media platforms are filled with social spambots. Detecting these malicious accounts is essential, yet challenging, as they continually evolve to evade detection techniques. In this article, we present VASSL, a visual analytics system that assists in the process of detecting and labeling spambots. Our tool enhances the performance and scalability of manual labeling by providing multiple connected views and utilizing dimensionality reduction, sentiment analysis and topic modeling, enabling insights for the identification of spambots. The system allows users to select and analyze groups of accounts in an interactive manner, which enables the detection of spambots that may not be identified when examined individually. We present a user study to objectively evaluate the performance of VASSL users, as well as capturing subjective opinions about the usefulness and the ease of use of the tool.","keywords":"Spambot, Labeling, Detection, Visual Analytics, Social Media Annotation","caption":"Fig. 1. The default layout of the front-end of VASSL: A) the timeline view, B) the dimensionality reduction view, C) the user/tweet detail views, D) & E) the topics view (clustering / words), F) the feature explorer view, G) the general control panel, H) the labeling panel, and I) the control panels for all the views (the opened control panel in the \ufb01gure is for topics clustering view). ","img_size":{"width":1947,"height":1074},"subfigures":[{"x":7.245689447224104,"y":10.686433247580279,"width":1932.5086211055516,"height":1060.628187111103,"type":"interface","id":"interface-0"}],"visualizations":[{"x":48.53379942190938,"y":16.723718444518955,"width":1272.5338337597411,"height":317.5022193554962,"type":"box_plot","id":"box_plot-0"},{"x":8.406516855849341,"y":742.752788715398,"width":518.997396723139,"height":326.3791837032481,"type":"line_chart","id":"line_chart-6"},{"x":532.8136077695517,"y":755.0726909830307,"width":482.48763342370154,"height":311.5935576178021,"type":"line_chart","id":"line_chart-7"},{"x":1017.8836960107059,"y":750.0718214070109,"width":472.94454107564616,"height":314.20466293248,"type":"line_chart","id":"line_chart-8"},{"x":52.212334708845326,"y":17.943750247645887,"width":1268.8701442139948,"height":316.2939280554685,"type":"scatterplot","id":"scatterplot-1"},{"x":10.907337129030632,"y":387.7201324016187,"width":499.5402488867704,"height":341.6717659147198,"type":"scatterplot","id":"scatterplot-2"},{"x":1023.2041821103732,"y":519.5941742931087,"width":496.4571083163029,"height":214.65040812297943,"type":"scatterplot","id":"scatterplot-5"},{"x":511.9541326404183,"y":382.865845402796,"width":490.9661544288674,"height":350.14856760613793,"type":"table","id":"table-4"},{"x":1026.8362928929328,"y":378.60242151961177,"width":486.7306327324343,"height":143.11526178271782,"type":"word_cloud","id":"word_cloud-3"}],"relations":[{"vislist":[{"vislist":["box_plot-0","scatterplot-1"],"relation":null,"id":"group-0"}],"relation":"accompanied","id":"relation-0"},{"vislist":[{"vislist":["table-4"],"relation":null,"id":"group-1"}],"relation":"repeated","id":"relation-1"},{"vislist":[{"vislist":["line_chart-6","line_chart-7","line_chart-8"],"relation":null,"id":"group-2"}],"relation":"repeated","id":"relation-2"}]},"3206_0":{"comp":[["bar_chart","bar_chart",["repeated"]],["area_chart","area_chart",["repeated"]]],"visType":["bar_chart","area_chart"],"compType":["repeated"],"compressed_tree":[{"composite_pattern":"repeated","visualization_type":[["bar_chart"]]},{"composite_pattern":"repeated","visualization_type":[["bar_chart"]]},{"composite_pattern":"repeated","visualization_type":[["bar_chart"]]},{"composite_pattern":"repeated","visualization_type":[["area_chart"]]},{"composite_pattern":"repeated","visualization_type":[["area_chart"]]},{"composite_pattern":"repeated","visualization_type":[["area_chart"]]}],"coOccurrence":[["bar_chart","area_chart",["coOccurrence"]]],"year":2019,"conference":["VAST"],"authors":["Gromit Yeuk-Yin Chan","Luis Gustavo Nonato","Alice Chu","Preeti Raghavan","Viswanath Aluru","Cl\xe1udio T. Silva"],"title":"Motion Browser: Visualizing and Understanding Complex Upper Limb Movement Under Obstetrical Brachial Plexus Injuries","doi":"10.1109/TVCG.2019.2934280","abstract":"The brachial plexus is a complex network of peripheral nerves that enables sensing from and control of the movements of the arms and hand. Nowadays, the coordination between the muscles to generate simple movements is still not well understood, hindering the knowledge of how to best treat patients with this type of peripheral nerve injury. To acquire enough information for medical data analysis, physicians conduct motion analysis assessments with patients to produce a rich dataset of electromyographic signals from multiple muscles recorded with joint movements during real-world tasks. However, tools for the analysis and visualization of the data in a succinct and interpretable manner are currently not available. Without the ability to integrate, compare, and compute multiple data sources in one platform, physicians can only compute simple statistical values to describe patient\'s behavior vaguely, which limits the possibility to answer clinical questions and generate hypotheses for research. To address this challenge, we have developed MOTION BROWSER, an interactive visual analytics system which provides an efficient framework to extract and compare muscle activity patterns from the patient\'s limbs and coordinated views to help users analyze muscle signals, motion data, and video information to address different tasks. The system was developed as a result of a collaborative endeavor between computer scientists and orthopedic surgery and rehabilitation physicians. We present case studies showing physicians can utilize the information displayed to understand how individuals coordinate their muscles to initiate appropriate treatment and generate new hypotheses for future research.","keywords":"Medical Data Visualization, Visual Analytics Application, Time Series Data, Multimodal Data, Brachial Plexus Injuries","caption":"Fig. 1. M OTION B ROWSER interface showing how to analyze patients\u2019 limb muscles and movement with data collected from muscle sensors, motion sensors, and video recordings.  A Muscle Bundle Comparison View displays the muscle signals of affected and unaffected limbs side by side. Statistics from motion sensors (a1 ) and stacked muscle activities (a2 ) are shown. Visual highlighting technique allows the extraction of the relatively stronger muscle activities on both sides (a3 ).                                                                                                    B Time Series View on raw muscle EMG signals. Each view visualizes the signals from an individual motion and users can align the x- and y-axis of all views (b1 ).  C Video Inspection View displays the cut scenes and \ufb01ltered signals from  A and allows the export to the presentation slide show (c1 ). ","img_size":{"width":1695,"height":942},"subfigures":[{"x":8.261337694457126,"y":11.376882472573996,"width":1678.4773246110847,"height":930.2740240237417,"type":"interface","id":"interface-0"}],"visualizations":[{"x":29.77350355612891,"y":243.20855330453102,"width":424.3389110158289,"height":96.17894040625183,"type":"area_chart","id":"area_chart-0"},{"x":31.902597001989875,"y":354.58768020588593,"width":421.15250649744206,"height":163.16544094642654,"type":"bar_chart","id":"bar_chart-1"},{"x":969.7786323314926,"y":408.55815735008093,"width":342.7794759262256,"height":56.83174170688081,"type":"area_chart","id":"area_chart-10"},{"x":1347.2572287646408,"y":240.3328177019371,"width":314.76758812252467,"height":86.24637190951317,"type":"area_chart","id":"area_chart-11"},{"x":1338.7956955304937,"y":330.88208881677116,"width":327.4035250974696,"height":77.68830631568655,"type":"area_chart","id":"area_chart-12"},{"x":1334.6411009541105,"y":410.53768092037313,"width":332.49736713022475,"height":44.83535964282603,"type":"area_chart","id":"area_chart-13"},{"x":976.9013666523687,"y":738.574730293836,"width":306.0265774443748,"height":140.54450131796838,"type":"bar_chart","id":"bar_chart-14"},{"x":38.334383469291915,"y":601.8818246864565,"width":428.65279865626275,"height":77.95890400324562,"type":"area_chart","id":"area_chart-2"},{"x":490.69052120482297,"y":230.890905632095,"width":441.3862347625085,"height":108.34523598651143,"type":"area_chart","id":"area_chart-3"},{"x":466.17660430344915,"y":360.3200189167152,"width":465.7630739784825,"height":147.4140436083511,"type":"bar_chart","id":"bar_chart-4"},{"x":38.345543035018736,"y":737.6992877176069,"width":432.91760901815985,"height":166.9440259898309,"type":"bar_chart","id":"bar_chart-5"},{"x":503.48580264011144,"y":586.1072409251178,"width":428.6570603719851,"height":99.86295171398305,"type":"area_chart","id":"area_chart-6"},{"x":501.34437905362535,"y":709.2817559618254,"width":429.72456042494684,"height":187.34197021183837,"type":"bar_chart","id":"bar_chart-7"},{"x":983.6319759957698,"y":233.96645537709995,"width":324.71882995771125,"height":90.40565672635158,"type":"area_chart","id":"area_chart-8"},{"x":986.7688680548835,"y":332.93292291535107,"width":315.2296987194704,"height":68.22823822300444,"type":"area_chart","id":"area_chart-9"},{"x":1348.4310372955088,"y":717.8264138594872,"width":314.563535807466,"height":70.58641635978516,"type":"bar_chart","id":"bar_chart-15"}],"relations":[{"vislist":[{"vislist":["bar_chart-1"],"relation":null,"id":"group-0"}],"relation":"repeated","id":"relation-0"},{"vislist":[{"vislist":["bar_chart-5"],"relation":null,"id":"group-1"}],"relation":"repeated","id":"relation-1"},{"vislist":[{"vislist":["bar_chart-14"],"relation":null,"id":"group-2"}],"relation":"repeated","id":"relation-2"},{"vislist":[{"vislist":["area_chart-0","area_chart-3","area_chart-2","area_chart-6"],"relation":null,"id":"group-3"}],"relation":"repeated","id":"relation-3"},{"vislist":[{"vislist":["area_chart-8","area_chart-9"],"relation":null,"id":"group-4"}],"relation":"repeated","id":"relation-4"},{"vislist":[{"vislist":["area_chart-11","area_chart-12"],"relation":null,"id":"group-5"}],"relation":"repeated","id":"relation-5"}]},"3213_3":{"comp":[["area_chart","area_chart",["repeated"]],["bar_chart","bar_chart",["repeated"]],["bar_chart","area_chart",["large_view"]],["matrix","matrix",["repeated"]],["scatterplot","contour_graph",["coordinated"]]],"visType":["area_chart","bar_chart","matrix","scatterplot","contour_graph"],"compType":["repeated","large_view","coordinated"],"compressed_tree":[{"composite_pattern":"repeated","visualization_type":[["area_chart"]]},{"composite_pattern":"repeated","visualization_type":[["area_chart"]]},{"composite_pattern":"repeated","visualization_type":[["area_chart"]]},{"composite_pattern":"repeated","visualization_type":[["bar_chart"]]},{"composite_pattern":"repeated","visualization_type":[["bar_chart"]]},{"composite_pattern":"repeated","visualization_type":[["bar_chart"]]},{"composite_pattern":"repeated","visualization_type":[["bar_chart"]]},{"composite_pattern":"repeated","visualization_type":[["bar_chart"]]},{"composite_pattern":"coordinated","visualization_type":[["scatterplot"],["contour_graph"]]},{"composite_pattern":"repeated","visualization_type":[["area_chart"]]},{"composite_pattern":"large_view","visualization_type":[["bar_chart"],["area_chart"]]},{"composite_pattern":"repeated","visualization_type":[["bar_chart"]]},{"composite_pattern":"repeated","visualization_type":[["matrix"]]}],"coOccurrence":[["area_chart","bar_chart",["coOccurrence"]],["area_chart","scatterplot",["coOccurrence"]],["area_chart","contour_graph",["coOccurrence"]],["area_chart","matrix",["coOccurrence"]],["bar_chart","scatterplot",["coOccurrence"]],["bar_chart","contour_graph",["coOccurrence"]],["bar_chart","matrix",["coOccurrence"]],["scatterplot","contour_graph",["coOccurrence"]],["scatterplot","matrix",["coOccurrence"]],["contour_graph","matrix",["coOccurrence"]]],"year":2019,"conference":["VAST"],"authors":["Ke Xu","Yun Wang","Leni Yang","Yifang Wang","Bo Qiao","Si Qin","Yong Xu","Haidong Zhang","Huamin Qu"],"title":"CloudDet: Interactive Visual Analysis of Anomalous Performances in Cloud Computing Systems","doi":"10.1109/TVCG.2019.2934613","abstract":"Detecting and analyzing potential anomalous performances in cloud computing systems is essential for avoiding losses to customers and ensuring the efficient operation of the systems. To this end, a variety of automated techniques have been developed to identify anomalies in cloud computing. These techniques are usually adopted to track the performance metrics of the system (e.g., CPU, memory, and disk I/O), represented by a multivariate time series. However, given the complex characteristics of cloud computing data, the effectiveness of these automated methods is affected. Thus, substantial human judgment on the automated analysis results is required for anomaly interpretation. In this paper, we present a unified visual analytics system named CloudDet to interactively detect, inspect, and diagnose anomalies in cloud computing systems. A novel unsupervised anomaly detection algorithm is developed to identify anomalies based on the specific temporal patterns of the given metrics data (e.g., the periodic pattern). Rich visualization and interaction designs are used to help understand the anomalies in the spatial and temporal context. We demonstrate the effectiveness of CloudDet through a quantitative evaluation, two case studies with real-world data, and interviews with domain experts.","keywords":"Cloud computing, anomaly detection, multidimensional data, performance visualization, visual analytics","caption":"Fig. 4. The CloudDet system contains \ufb01ve interactive modules: (1) Spatial Overview, (2) Temporal Overview, (3) Rank View, (4) Performance View in the horizon chart mode, and (5) Cluster View. The performance view contains two other views/modes: (6) the multi-line mode and (7) the PCA mode. Users can select and \ufb01lter data in (a), switch to different visualization modes in different views by buttons (b) and (d), and change the layout by the slider bar in (c). (f) is the explanation of the glyph in (5). (e) shows the color schemes used in different views. ","img_size":{"width":2131,"height":1030},"subfigures":[{"x":3.495759617279379,"y":6.842848935065768,"width":2120.6764980428525,"height":1014.0918512260382,"type":"interface","id":"interface-0"}],"visualizations":[{"x":244.21042542251953,"y":192.03301225789514,"width":928.4179893206772,"height":206.46682622811147,"type":"area_chart","id":"area_chart-1"},{"x":291.39754362794656,"y":446.98723159940585,"width":528.1671806789136,"height":175.11924026261946,"type":"area_chart","id":"area_chart-6"},{"x":276.8879382556532,"y":632.7897863619173,"width":617.8227163150896,"height":201.19145905216465,"type":"area_chart","id":"area_chart-7"},{"x":283.5931687562488,"y":862.9262864086488,"width":612.4970986327772,"height":165.55696207425626,"type":"area_chart","id":"area_chart-8"},{"x":1661.8676927848037,"y":606.7434520051487,"width":417.8439795743023,"height":177.7928383229362,"type":"bar_chart","id":"bar_chart-10"},{"x":1199.0973486522594,"y":783.9914393439468,"width":453.7038319621634,"height":146.83096125719337,"type":"bar_chart","id":"bar_chart-11"},{"x":1665.9376985056183,"y":772.0426199672931,"width":444.73828918114606,"height":154.51006954525218,"type":"bar_chart","id":"bar_chart-12"},{"x":48.944383637389016,"y":810.6009244532449,"width":76.57914955657812,"height":105.70269411438599,"type":"bar_chart","id":"bar_chart-15"},{"x":49.043393105086054,"y":681.8263017023266,"width":84.46597394006365,"height":115.2509570317891,"type":"bar_chart","id":"bar_chart-16"},{"x":30.932815665038156,"y":449.9354148571641,"width":99.12754663648295,"height":101.81993674463477,"type":"bar_chart","id":"bar_chart-17"},{"x":55.03346377452146,"y":935.2091531248424,"width":73.83330648767279,"height":81.3617117217523,"type":"bar_chart","id":"bar_chart-18"},{"x":240.03217098984743,"y":197.85312329885437,"width":430.12431686962503,"height":81.58966998204562,"type":"bar_chart","id":"bar_chart-2"},{"x":1201.7320639716988,"y":603.9822240928047,"width":445.7394535503223,"height":173.87888296727962,"type":"bar_chart","id":"bar_chart-9"},{"x":919.6613471846106,"y":492.44865474118905,"width":278.2025667659804,"height":343.02367206853484,"type":"contour_graph","id":"contour_graph-3"},{"x":261.31504509279995,"y":17.67439918393784,"width":773.2841709975112,"height":181.77178138234603,"type":"glyph_based","id":"glyph_based-0"},{"x":912.9330291578759,"y":841.4072512693311,"width":278.18446395465065,"height":181.63385755190532,"type":"line_chart","id":"line_chart-5"},{"x":122.24091292689229,"y":442.0832835037316,"width":102.46274844698551,"height":117.52419945150059,"type":"matrix","id":"matrix-19"},{"x":127.60424155114238,"y":677.8842417228253,"width":99.82093451736635,"height":124.48313573084306,"type":"matrix","id":"matrix-20"},{"x":123.56146262365246,"y":803.9693425212984,"width":94.43175350754818,"height":118.52103110755377,"type":"matrix","id":"matrix-21"},{"x":124.91150740921329,"y":932.5264551348416,"width":97.12155948234299,"height":85.6712091840431,"type":"matrix","id":"matrix-22"},{"x":1226.1091810031937,"y":293.7911871804446,"width":224.5085620179222,"height":231.1406776518279,"type":"pie_chart","id":"pie_chart-13"},{"x":1582.6506958694722,"y":275.3758692913977,"width":236.36648321148652,"height":227.16127702797,"type":"pie_chart","id":"pie_chart-14"},{"x":914.3180936531594,"y":508.26339831182486,"width":284.84665216944364,"height":322.1786548476587,"type":"scatterplot","id":"scatterplot-4"}],"relations":[{"vislist":[{"vislist":["area_chart-6"],"relation":null,"id":"group-0"}],"relation":"repeated","id":"relation-0"},{"vislist":[{"vislist":["area_chart-7"],"relation":null,"id":"group-1"}],"relation":"repeated","id":"relation-1"},{"vislist":[{"vislist":["area_chart-8"],"relation":null,"id":"group-2"}],"relation":"repeated","id":"relation-2"},{"vislist":[{"vislist":["bar_chart-9"],"relation":null,"id":"group-3"}],"relation":"repeated","id":"relation-3"},{"vislist":[{"vislist":["bar_chart-10"],"relation":null,"id":"group-4"}],"relation":"repeated","id":"relation-4"},{"vislist":[{"vislist":["bar_chart-11"],"relation":null,"id":"group-5"}],"relation":"repeated","id":"relation-5"},{"vislist":[{"vislist":["bar_chart-12"],"relation":null,"id":"group-6"}],"relation":"repeated","id":"relation-6"},{"vislist":[{"vislist":["bar_chart-9","bar_chart-10","bar_chart-11","bar_chart-12"],"relation":null,"id":"group-7"}],"relation":"repeated","id":"relation-7"},{"vislist":[{"vislist":["scatterplot-4"],"relation":null,"id":"group-9"},{"vislist":["contour_graph-3"],"relation":null,"id":"group-8"}],"relation":"coordinated","id":"relation-8"},{"vislist":[{"vislist":["area_chart-6","area_chart-7","area_chart-8"],"relation":null,"id":"group-10"}],"relation":"repeated","id":"relation-9"},{"vislist":[{"vislist":["bar_chart-2"],"relation":null,"id":"group-12"},{"vislist":["area_chart-1"],"relation":null,"id":"group-11"}],"relation":"large_view","id":"relation-10"},{"vislist":[{"vislist":["bar_chart-17","bar_chart-16","bar_chart-15","bar_chart-18"],"relation":null,"id":"group-13"}],"relation":"repeated","id":"relation-11"},{"vislist":[{"vislist":["matrix-19","matrix-20","matrix-21","matrix-22"],"relation":null,"id":"group-14"}],"relation":"repeated","id":"relation-12"}]},"3216_0":{"comp":[["graph","graph",["repeated"]]],"visType":["graph"],"compType":["repeated"],"compressed_tree":[{"composite_pattern":"repeated","visualization_type":[["graph"]]}],"coOccurrence":[["graph","graph",["coOccurrence"]]],"year":2019,"conference":["VAST"],"authors":["Zeyu Li","Changhong Zhang","Shichao Jia","Jiawan Zhang"],"title":"Galex: Exploring the Evolution and Intersection of Disciplines","doi":"10.1109/TVCG.2019.2934667","abstract":"Revealing the evolution of science and the intersections among its sub-fields is extremely important to understand the characteristics of disciplines, discover new topics, and predict the future. The current work focuses on either building the skeleton of science, lacking interaction, detailed exploration and interpretation or on the lower topic level, missing high-level macro-perspective. To fill this gap, we design and implement Galaxy Evolution Explorer (Galex), a hierarchical visual analysis system, in combination with advanced text mining technologies, that could help analysts to comprehend the evolution and intersection of one discipline rapidly. We divide Galex into three progressively fine-grained levels: discipline, area, and institution levels. The combination of interactions enables analysts to explore an arbitrary piece of history and an arbitrary part of the knowledge space of one discipline. Using a flexible spotlight component, analysts could freely select and quickly understand an exploration region. A tree metaphor allows analysts to perceive the expansion, decline, and intersection of topics intuitively. A synchronous spotlight interaction aids in comparing research contents among institutions easily. Three cases demonstrate the effectiveness of our system.","keywords":"Science evolution, science mapping, interdisciplinary, knowledge domain visualization, visual analysis","caption":"Fig. 1: Interface of Galex consists of three panels: area picker panel (left), main panel (middle), and network panel (right). The main panel includes three layers: discipline, area, and institution layers. To date, all papers (over 86,000) from all 26 areas are shown in the discipline layer, forming an overview (galaxy) of computer science. The area picker controls the areas that are displayed. A contour line indicates the paper distribution of one area (here, visualization). The spotlight reveals the semantics of the regions of interest. The time brush acts as a time \ufb01lter. The toolbox provides useful components, such as pallet, spotlight, and time slice selector. The network panel includes three kinds of networks to uncover the structure of one area. ","img_size":{"width":1949,"height":1003},"subfigures":[{"x":4.360525148345608,"y":8.899502522795345,"width":1938.1447466782615,"height":987.3358863529417,"type":"interface","id":"interface-0"}],"visualizations":[{"x":354.71038398354773,"y":58.73429735637276,"width":1123.7344169946996,"height":56.436526230596684,"type":"bar_chart","id":"bar_chart-1"},{"x":1490.8725117886308,"y":46.48965689251742,"width":444.8925639845232,"height":290.6670712053786,"type":"graph","id":"graph-2"},{"x":1487.211893861702,"y":338.1019612876303,"width":453.44619148772273,"height":320.62721671747113,"type":"graph","id":"graph-3"},{"x":1491.715734744035,"y":661.4250781289641,"width":444.75685321921736,"height":324.8289949710662,"type":"graph","id":"graph-4"},{"x":362.0243874975169,"y":123.52380621377056,"width":1102.9444517200445,"height":855.887931030181,"type":"scatterplot","id":"scatterplot-0"}],"relations":[{"vislist":[{"vislist":["graph-2","graph-3","graph-4"],"relation":null,"id":"group-0"}],"relation":"repeated","id":"relation-0"}]},"3217_0":{"comp":[["polar_plot","polar_plot",["repeated"]],["bar_chart","matrix",["nested"]],["bar_chart","table",["nested"]],["glyph_based","scatterplot",["nested"]]],"visType":["polar_plot","bar_chart","matrix","table","glyph_based","scatterplot"],"compType":["repeated","nested"],"compressed_tree":[{"composite_pattern":"repeated","visualization_type":[["polar_plot"]]},{"composite_pattern":"repeated","visualization_type":[["polar_plot"]]},{"composite_pattern":"nested","visualization_type":[["bar_chart"],["matrix"]]},{"composite_pattern":"nested","visualization_type":[["bar_chart"],["table"]]},{"composite_pattern":"nested","visualization_type":[["glyph_based"],["scatterplot"]]}],"coOccurrence":[["polar_plot","bar_chart",["coOccurrence"]],["polar_plot","matrix",["coOccurrence"]],["polar_plot","table",["coOccurrence"]],["polar_plot","glyph_based",["coOccurrence"]],["polar_plot","scatterplot",["coOccurrence"]],["bar_chart","matrix",["coOccurrence"]],["bar_chart","table",["coOccurrence"]],["bar_chart","glyph_based",["coOccurrence"]],["bar_chart","scatterplot",["coOccurrence"]],["matrix","table",["coOccurrence"]],["matrix","glyph_based",["coOccurrence"]],["matrix","scatterplot",["coOccurrence"]],["table","glyph_based",["coOccurrence"]],["table","scatterplot",["coOccurrence"]],["glyph_based","scatterplot",["coOccurrence"]]],"year":2019,"conference":["VAST"],"authors":["Jieqiong Zhao","Morteza Karimzadeh","Luke S. Snyder","Chittayong Surakitbanharn","Zhenyu Cheryl Qian","David S. Ebert"],"title":"MetricsVis: A Visual Analytics Framework for Evaluating Individual, Team, and Organization Performance","doi":"10.1109/TVCG.2019.2934603","abstract":"Evaluating employee performance in organizations with varying workloads and tasks is challenging. Specifically, it is important to understand how quantitative measurements of employee achievements relate to supervisor expectations, what the main drivers of good performance are, and how to combine these complex and flexible performance evaluation metrics into an accurate portrayal of organizational performance in order to identify shortcomings and improve overall productivity. To facilitate this process, we summarize common organizational performance analyses into four visual exploration task categories. Additionally, we develop MetricsVis, a visual analytics system composed of multiple coordinated views to support the dynamic evaluation and comparison of individual, team, and organizational performance in public safety organizations. MetricsVis provides four primary visual components to expedite performance evaluation: (1) a priority adjustment view to support direct manipulation on evaluation metrics; (2) a reorderable performance matrix to demonstrate the details of individual employees; (3) a group performance view that highlights aggregate performance and individual contributions for each group; and (4) a projection view illustrating employees with similar specialties to facilitate shift assignments and training. We demonstrate the usability of our framework with two case studies from medium-sized law enforcement agencies and highlight its broader applicability to other domains.","keywords":"Organizational performance analysis, multi-dimensional data, hierarchical relationships, visual analytics","caption":"Fig. 1. MetricsVis overview: The priority adjustment view (2) encodes the crowdsourced crime severity ratings from police officers and citizens (perceived importance of factors); the red dots indicate the currently assigned weights used in the evaluation metrics. The projection view (6) shows the dimensionality reduction results. The group performance view (5) contains three visual representations that show an overview of group performance and the contribution of each member. The performance matrix view (3) displays the individual employee performance with employees in columns and job types in rows (here, employees are sorted based on their group first and then their total performance scores). The control panel shows the filters (1) and grouping method (4) applied in use case 1.","img_size":{"width":1944,"height":740},"subfigures":[{"x":2.180362207254157,"y":6.974372519645505,"width":1936.5996817737998,"height":727.0651906966344,"type":"interface","id":"interface-0"}],"visualizations":[{"x":227.97335710861447,"y":117.85771677718147,"width":126.06639102402173,"height":406.0157415585144,"type":"bar_chart","id":"bar_chart-1"},{"x":372.50844678908663,"y":497.89622393823174,"width":1564.0644310999387,"height":236.78003687023624,"type":"bar_chart","id":"bar_chart-3"},{"x":1451.4976699182746,"y":39.192349665402205,"width":480.43304803574165,"height":365.58046569674013,"type":"glyph_based","id":"glyph_based-5"},{"x":462.74280154125756,"y":176.6605574356044,"width":959.5113545452652,"height":145.92026415534232,"type":"polar_plot","id":"polar_plot-6"},{"x":464.9178014843928,"y":337.1710337698883,"width":958.8490448072588,"height":139.3595511255651,"type":"polar_plot","id":"polar_plot-7"},{"x":370.0515053021951,"y":506.454073338471,"width":1565.2906239254578,"height":229.49122055847027,"type":"matrix","id":"matrix-2"},{"x":1451.4842596400526,"y":36.76453630219234,"width":478.00140849333985,"height":367.9793718009814,"type":"scatterplot","id":"scatterplot-4"},{"x":3.1661376031175092,"y":98.45303319621149,"width":353.19019108976545,"height":432.5415056095643,"type":"table","id":"table-0"}],"relations":[{"vislist":[{"vislist":["polar_plot-6"],"relation":null,"id":"group-1"}],"relation":"repeated","id":"relation-0"},{"vislist":[{"vislist":["polar_plot-7"],"relation":null,"id":"group-2"}],"relation":"repeated","id":"relation-1"},{"vislist":[{"vislist":["bar_chart-3"],"relation":null,"id":"group-4"},{"vislist":["matrix-2"],"relation":null,"id":"group-3"}],"relation":"nested","id":"relation-2"},{"vislist":[{"vislist":["bar_chart-1"],"relation":null,"id":"group-6"},{"vislist":["table-0"],"relation":null,"id":"group-5"}],"relation":"nested","id":"relation-3"},{"vislist":[{"vislist":["glyph_based-5"],"relation":null,"id":"group-8"},{"vislist":["scatterplot-4"],"relation":null,"id":"group-7"}],"relation":"nested","id":"relation-4"}]},"3223_12":{"comp":[["bar_chart","bar_chart",["repeated"]]],"visType":["bar_chart"],"compType":["repeated"],"compressed_tree":[{"composite_pattern":"repeated","visualization_type":[["bar_chart"]]}],"coOccurrence":[["bar_chart","bar_chart",["coOccurrence"]]],"year":2019,"conference":["VAST"],"authors":["Melanie Tory","Vidya Setlur"],"title":"Do What I Mean, Not What I Say! Design Considerations for Supporting Intent and Context in Analytical Conversation","doi":"10.1109/VAST47406.2019.8986918","abstract":"Natural language can be a useful modality for creating and interacting with visualizations but users often have unrealistic expectations about the intelligence of natural language systems. The gulf between user expectations and system capabilities may lead to a disappointing user experience. So - if we want to engineer a natural language system, what are the requirements around system intelligence? This work takes a retrospective look at how we answered this question in the design of Ask Data, a natural language interaction feature for Tableau. We examine two factors contributing to perceived system intelligence: the system\'s ability to understand the analytic intent behind an input utterance and the ability to interpret an utterance contextually (i.e. taking into account the current visualization state and recent actions). Our aim was to understand the ways in which a system would need to support these two aspects of intelligence to enable a positive user experience. We first describe a pre-design Wizard of Oz study that offered insight into this question and narrowed the space of designs under consideration. We then reflect on the impact of this study on system development, examining how design implications from the study played out in practice. Our work contributes insights for the design of natural language interaction in visual analytics as well as a reflection on the value of pre-design empirical studies in the development of visual analytic systems.","keywords":":Human-centered computing\u2014Visualization\u2014Empirical studies in visualization; Human-centered computing\u2014Interaction paradigms\u2014Natural language interfaces","caption":"Figure 12:  (Top) Response to, \u201cHow many passengers in class 1 sur- vived?\u201d [P5.B] (Bottom) Because Classis also a row attribute, adjusting the filter control creates a comparative visualization.","img_size":{"width":597,"height":468},"subfigures":[{"x":7.023569875796102,"y":10.56107952003325,"width":585.9410248015059,"height":446.3797705838051,"type":"single","id":"single-0"}],"visualizations":[{"x":9.578964813893649,"y":26.655222678067926,"width":464.29181735443734,"height":158.18331093783132,"type":"bar_chart","id":"bar_chart-0"},{"x":11.552933436756279,"y":232.09543645722283,"width":459.34782525767883,"height":222.96009258197128,"type":"bar_chart","id":"bar_chart-1"}],"relations":[{"vislist":[{"vislist":["bar_chart-0","bar_chart-1"],"relation":null,"id":"group-0"}],"relation":"repeated","id":"relation-0"}]},"3224_0":{"comp":[["matrix","matrix",["repeated"]]],"visType":["matrix"],"compType":["repeated"],"compressed_tree":[{"composite_pattern":"repeated","visualization_type":[["matrix"]]}],"coOccurrence":[["matrix","matrix",["coOccurrence"]]],"year":2019,"conference":["VAST"],"authors":["Hannah Kim","Dongjin Choi","Barry Drake","Alex Endert","Haesun Park"],"title":"TopicSifter: Interactive Search Space Reduction Through Targeted Topic Modeling","doi":"10.1109/VAST47406.2019.8986922","abstract":"Topic modeling is commonly used to analyze and understand large document collections. However, in practice, users want to focus on specific aspects or \u201ctargets\u201d rather than the entire corpus. For example, given a large collection of documents, users may want only a smaller subset which more closely aligns with their interests, tasks, and domains. In particular, our paper focuses on large-scale document retrieval with high recall where any missed relevant documents can be critical. A simple keyword matching search is generally not effective nor efficient as 1) it is difficult to find a list of keyword queries that can cover the documents of interest before exploring the dataset, 2) some documents may not contain the exact keywords of interest but may still be highly relevant, and 3) some words have multiple meanings, which would result in irrelevant documents included in the retrieved subset. In this paper, we present TopicSifter, a visual analytics system for interactive search space reduction. Our system utilizes targeted topic modeling based on nonnegative matrix factorization and allows users to give relevance feedback in order to refine their target and guide the topic modeling to the most relevant results.","keywords":":Human-centered computing\u2014Visualization\u2014Visualization application domains\u2014Visual analytics; Informationsystems\u2014Information retrieval\u2014Users and interactive retrieval\u2014Search interfaces","caption":"Figure 1: The TopicSifter system has (a) the control panel, (b) the main view, (c) the detail panel. The keyword module (d) in the control panel (a) shows the current set of good-to-have keywords, bad-to-have keywords, and stopwords and allows users to modify them. The system recommends additional keywords based on the current set of keywords.The main view (b) shows the sifting status bar (e) showing how many documents are retrieved from the total dataset and the topical overview (f) of current retrieved documents.  The users can give positive or negative feedback on topics and documents to indicate relevancy. The detail panel (c) has two tab menus for showing document details and sifting history.","img_size":{"width":1661,"height":922},"subfigures":[{"x":7.604905723368306,"y":8.09694046410141,"width":1643.8282119970224,"height":888.1437772721739,"type":"interface","id":"interface-0"}],"visualizations":[{"x":277.3801324395433,"y":20.021146750897785,"width":1044.2730089824174,"height":55.417009101632594,"type":"bar_chart","id":"bar_chart-10"},{"x":278.9682635706475,"y":95.9791115397864,"width":565.3183239958363,"height":209.12159152182448,"type":"matrix","id":"matrix-0"},{"x":850.9423594488215,"y":89.75206465977885,"width":471.65362611227727,"height":217.37471604475476,"type":"matrix","id":"matrix-1"},{"x":285.64040663895577,"y":316.1783368433224,"width":362.9230089621204,"height":268.63848012792715,"type":"matrix","id":"matrix-2"},{"x":652.5581641340974,"y":316.05755747426787,"width":356.9339552256795,"height":253.1264042269655,"type":"matrix","id":"matrix-3"},{"x":1018.9427174058854,"y":313.95087317187426,"width":303.6982692177981,"height":252.0885612853963,"type":"matrix","id":"matrix-4"},{"x":285.6369720739818,"y":592.651018692873,"width":361.87959459819314,"height":251.31669415722706,"type":"matrix","id":"matrix-5"},{"x":652.8178830010869,"y":570.0079505536419,"width":405.77784170372036,"height":143.2674532820684,"type":"matrix","id":"matrix-6"},{"x":1065.241210958605,"y":574.1360993629185,"width":258.36403933663183,"height":178.07109034364106,"type":"matrix","id":"matrix-7"},{"x":654.9300225315654,"y":717.3083656965637,"width":403.6541296305068,"height":135.43595892343745,"type":"matrix","id":"matrix-8"},{"x":1059.5837132202062,"y":758.6093822191361,"width":255.24636838618568,"height":99.044587486233,"type":"matrix","id":"matrix-9"}],"relations":[{"vislist":[{"vislist":["matrix-0","matrix-1","matrix-2","matrix-3","matrix-4","matrix-5","matrix-6","matrix-7","matrix-8","matrix-9"],"relation":null,"id":"group-0"}],"relation":"repeated","id":"relation-0"}]},"3226_5":{"comp":[["bar_chart","bar_chart",["repeated"]]],"visType":["bar_chart"],"compType":["repeated"],"compressed_tree":[{"composite_pattern":"repeated","visualization_type":[["bar_chart"]]}],"coOccurrence":[["bar_chart","bar_chart",["coOccurrence"]]],"year":2019,"conference":["VAST"],"authors":["Minjeong Shin","Alexander Soen","Benjamin T. Readshaw","Stephen M. Blackburn","Mitchell Whitelaw","Lexing Xie"],"title":"Influence Flowers of Academic Entities","doi":"10.1109/VAST47406.2019.8986934","abstract":"We present the Influence Flower, a new visual metaphor for the influence profile of academic entities, including people, projects, institutions, conferences, and journals. While many tools quantify influence, we aim to expose the flow of influence between entities. The Influence Flower is an ego-centric graph, with a query entity placed in the centre. The petals are styled to reflect the strength of influence to and from other entities of the same or different type. For example, one can break down the incoming and outgoing influences of a research lab by research topics. The Influence Flower uses a recent snapshot of Microsoft Academic Graph, consisting of 212 million authors, their 176 million publications, and 1.2 billion citations. An interactive web app, Influence Map, is constructed around this central metaphor for searching and curating visualisations. We also propose a visual comparison method that highlights change in influence patterns over time. We demonstrate through several case studies that the Influence Flower supports data-driven inquiries about the following: researchers\' careers over time; paper(s) and projects, including those with delayed recognition; the interdisciplinary profile of a research institution; and the shifting topical trends in conferences. We also use this tool on influence data beyond academic citations, by contrasting the academic and Twitter activities of a researcher.","keywords":": Human-centered computing \u2013 Visualization \u2013{Visualisation application domains \u2013 Visual analytics; Visualizationsystems and tools; Empirical studies in visualization.}","caption":"Figure 6: Snapshot of the Influence Map system containing an author-to-venue Influence Flower. The ego entity is Shafi Goldwasser, 2012 Turing Awardee for foundational work on modern cryptography. The alter nodes are publication venues, with conferences shown as acronyms and journals as full names. The system consists of (a) year range filter and statistical summary, (b) fine-grained control, (c) influence type tabs, (d) Influence Flower, and (e) influence overview bars. See Sec. 5 for a description of system components and Sec. 6.1 for a discussion on Goldwasser\u2019s influence profile.","img_size":{"width":2129,"height":1055},"subfigures":[{"x":9.811146482098454,"y":8.24841755471055,"width":2109.377707035802,"height":1040.748738594918,"type":"interface","id":"interface-0"}],"visualizations":[{"x":68.01588752964453,"y":144.2097128078256,"width":436.750335973718,"height":142.43745650091256,"type":"bar_chart","id":"bar_chart-0"},{"x":55.98570501654085,"y":286.3199907905999,"width":455.42586401388076,"height":148.045778170221,"type":"bar_chart","id":"bar_chart-1"},{"x":766.7866983412281,"y":847.9670881234058,"width":1096.2164430197245,"height":162.08980069626872,"type":"bar_chart","id":"bar_chart-3"},{"x":569.103425792481,"y":131.52120366744998,"width":1544.0851487311559,"height":694.8986196897056,"type":"hierarchical_edge_bundling","id":"hierarchical_edge_bundling-2"}],"relations":[{"vislist":[{"vislist":["bar_chart-0","bar_chart-1"],"relation":null,"id":"group-0"}],"relation":"repeated","id":"relation-0"}]},"3227_0":{"comp":[["scatterplot","scatterplot",["repeated"]],["bar_chart","bar_chart",["repeated"]],["others","others",["repeated"]],["glyph_based","tree",["nested"]]],"visType":["scatterplot","bar_chart","others","glyph_based","tree"],"compType":["repeated","nested"],"compressed_tree":[{"composite_pattern":"repeated","visualization_type":[["scatterplot"]]},{"composite_pattern":"repeated","visualization_type":[["scatterplot"]]},{"composite_pattern":"repeated","visualization_type":[["scatterplot"]]},{"composite_pattern":"nested","visualization_type":[["glyph_based"],["tree"]]},{"composite_pattern":"repeated","visualization_type":[["bar_chart"]]},{"composite_pattern":"repeated","visualization_type":[["others"]]},{"composite_pattern":"repeated","visualization_type":[["others"]]},{"composite_pattern":"repeated","visualization_type":[["others"]]}],"coOccurrence":[["scatterplot","glyph_based",["coOccurrence"]],["scatterplot","tree",["coOccurrence"]],["scatterplot","bar_chart",["coOccurrence"]],["glyph_based","tree",["coOccurrence"]],["glyph_based","bar_chart",["coOccurrence"]],["tree","bar_chart",["coOccurrence"]]],"year":2019,"conference":["VAST"],"authors":["Frederik L. Dennig","Tom Polk","Zudi Lin","Tobias Schreck","Hanspeter Pfister","Michael Behrisch"],"title":"FDive: Learning Relevance Models using Pattern-based Similarity Measures","doi":"10.1109/VAST47406.2019.8986940","abstract":"The detection of interesting patterns in large high-dimensional datasets is difficult because of their dimensionality and pattern complexity. Therefore, analysts require automated support for the extraction of relevant patterns. In this paper, we present FDive, a visual active learning system that helps to create visually explorable relevance models, assisted by learning a pattern-based similarity. We use a small set of user-provided labels to rank similarity measures, consisting of feature descriptor and distance function combinations, by their ability to distinguish relevant from irrelevant data. Based on the best-ranked similarity measure, the system calculates an interactive Self-Organizing Map-based relevance model, which classifies data according to the cluster affiliation. It also automatically prompts further relevance feedback to improve its accuracy. Uncertain areas, especially near the decision boundaries, are highlighted and can be refined by the user. We evaluate our approach by comparison to state-of-the-art feature selection techniques and demonstrate the usefulness of our approach by a case study classifying electron microscopy images of brain cells. The results show that FDive enhances both the quality and understanding of relevance models and can thus lead to new insights for brain research.","keywords":" Visual analytics, similarity measure selection, relevance feedback, active learning, self-organizing maps.","caption":"Figure 1: FDIVE learns to distinguish relevant from irrelevant data through an iteratively improving classification model by learning the best-fitting feature descriptor and distance function. (1) Users express their notion of relevance by labeling a set of query items, in this case, images. (2) These labels are used to rank all similarity measures by their ability to distinguish relevant from irrelevant data. (3) The system applies the selected similarity measure to learn a Self-Organizing Map (SOM)-based relevance model. Users explore and refine the model by supplying relevance labels in uncertain data regions, especially near the decision boundaries.","img_size":{"width":1912,"height":735},"subfigures":[{"x":5.627348781496098,"y":72.69254319273712,"width":714.8867619944506,"height":589.6149136145257,"type":"interface","id":"interface-0"},{"x":773.4140420791156,"y":70.71794123454049,"width":302.3911695830475,"height":592.5671755258909,"type":"interface","id":"interface-1"},{"x":1125.8408341289203,"y":66.73218175460286,"width":777.4170072346852,"height":592.5631584455454,"type":"interface","id":"interface-2"}],"visualizations":[{"x":1407.471489419786,"y":302.3653351837862,"width":343.5317011926976,"height":344.13246335846094,"type":"bar_chart","id":"bar_chart-11"},{"x":1275.1349682322266,"y":110.96361977904184,"width":525.9930284929447,"height":173.54993232318566,"type":"glyph_based","id":"glyph_based-10"},{"x":173.5444646613667,"y":119.28793613806944,"width":515.5027076627046,"height":164.15089735855497,"type":"others","id":"others-6"},{"x":180.20243762406517,"y":294.8622622375949,"width":507.9194407537584,"height":159.77467103165924,"type":"others","id":"others-7"},{"x":183.72079311481875,"y":468.1743884592871,"width":508.1367046318,"height":162.14456716178393,"type":"others","id":"others-8"},{"x":11.076441309236282,"y":300.81368611640903,"width":162.19210499926112,"height":153.9131547352188,"type":"scatterplot","id":"scatterplot-0"},{"x":11.07951948531129,"y":495.2617621062446,"width":163.39494445703733,"height":157.70354773272734,"type":"scatterplot","id":"scatterplot-1"},{"x":1134.7568417781806,"y":241.45224541560194,"width":128.50263203333373,"height":127.64408106833572,"type":"scatterplot","id":"scatterplot-2"},{"x":1140.461220487028,"y":388.7132046664605,"width":125.55684528510946,"height":125.52260528808766,"type":"scatterplot","id":"scatterplot-3"},{"x":1136.8325184018952,"y":531.9388220471672,"width":126.76927040575177,"height":116.97261774129375,"type":"scatterplot","id":"scatterplot-4"},{"x":955.8228963329453,"y":120.83296356274984,"width":86.19290983875602,"height":489.70927399778725,"type":"scatterplot","id":"scatterplot-5"},{"x":1272.7105385695213,"y":110.95375973506967,"width":526.0059045786574,"height":172.36138611889223,"type":"tree","id":"tree-9"}],"relations":[{"vislist":[{"vislist":["scatterplot-5"],"relation":null,"id":"group-0"}],"relation":"repeated","id":"relation-0"},{"vislist":[{"vislist":["scatterplot-0","scatterplot-1"],"relation":null,"id":"group-1"}],"relation":"repeated","id":"relation-1"},{"vislist":[{"vislist":["scatterplot-2","scatterplot-3","scatterplot-4"],"relation":null,"id":"group-2"}],"relation":"repeated","id":"relation-2"},{"vislist":[{"vislist":["glyph_based-10"],"relation":null,"id":"group-4"},{"vislist":["tree-9"],"relation":null,"id":"group-3"}],"relation":"nested","id":"relation-3"},{"vislist":[{"vislist":["bar_chart-11"],"relation":null,"id":"group-5"}],"relation":"repeated","id":"relation-4"},{"vislist":[{"vislist":["others-6"],"relation":null,"id":"group-6"}],"relation":"repeated","id":"relation-5"},{"vislist":[{"vislist":["others-7"],"relation":null,"id":"group-7"}],"relation":"repeated","id":"relation-6"},{"vislist":[{"vislist":["others-8"],"relation":null,"id":"group-8"}],"relation":"repeated","id":"relation-7"}]},"3228_0":{"comp":[["others","others",["repeated"]],["bar_chart","graph",["nested"]]],"visType":["others","bar_chart","graph"],"compType":["repeated","nested"],"compressed_tree":[{"composite_pattern":"nested","visualization_type":[["bar_chart"],["graph"]]},{"composite_pattern":"repeated","visualization_type":[["others"]]},{"composite_pattern":"repeated","visualization_type":[["others"]]}],"coOccurrence":[["bar_chart","graph",["coOccurrence"]],["bar_chart","others",["coOccurrence"]],["graph","others",["coOccurrence"]]],"year":2019,"conference":["VAST"],"authors":["Shouxing Xiang","Xi Ye","Jiazhi Xia","Jing Wu","Yang Chen","Shixia Liu"],"title":"Interactive Correction of Mislabeled Training Data","doi":"10.1109/VAST47406.2019.8986943","abstract":"In this paper, we develop a visual analysis method for interactively improving the quality of labeled data, which is essential to the success of supervised and semi-supervised learning. The quality improvement is achieved through the use of user-selected trusted items. We employ a bi-level optimization model to accurately match the labels of the trusted items and to minimize the training loss. Based on this model, a scalable data correction algorithm is developed to handle tens of thousands of labeled data efficiently. The selection of the trusted items is facilitated by an incremental tSNE with improved computational efficiency and layout stability to ensure a smooth transition between different levels. We evaluated our method on real-world datasets through quantitative evaluation and case studies, and the results were generally favorable.","keywords":" Labeled data debugging, trusted item, tSNE.","caption":"Figure 1: DataDebugger: (a) the navigation stack records the explored hierarchical levels; (b) the tSNE-based visualization shows the item distribution and the confusion between different classes; (c)(d) the selected item view and the trusted item view display the images of selected items and trusted items, respectively; (e) The action trail records the correction history.","img_size":{"width":1922,"height":943},"subfigures":[{"x":5.5020878615758075,"y":5.396796424033202,"width":1910.9958242768478,"height":937.2243597661302,"type":"interface","id":"interface-0"}],"visualizations":[{"x":1369.3655457687134,"y":844.2489351534007,"width":100.83476083689125,"height":87.92217126444916,"type":"bar_chart","id":"bar_chart-4"},{"x":1348.6081445630189,"y":843.0214621113288,"width":279.6806113519858,"height":101.31224533987816,"type":"graph","id":"graph-3"},{"x":1344.1883564836405,"y":76.50498855570814,"width":571.6895167865263,"height":197.06308291666318,"type":"others","id":"others-1"},{"x":1338.1125154986614,"y":377.2155078887833,"width":575.3339656881142,"height":256.6097806126534,"type":"others","id":"others-2"},{"x":189.60147781282146,"y":39.24007250288028,"width":1140.526452141379,"height":893.6801963043338,"type":"scatterplot","id":"scatterplot-0"}],"relations":[{"vislist":[{"vislist":["bar_chart-4"],"relation":null,"id":"group-1"},{"vislist":["graph-3"],"relation":null,"id":"group-0"}],"relation":"nested","id":"relation-0"},{"vislist":[{"vislist":["others-1"],"relation":null,"id":"group-2"}],"relation":"repeated","id":"relation-1"},{"vislist":[{"vislist":["others-2"],"relation":null,"id":"group-3"}],"relation":"repeated","id":"relation-2"}]},"3229_0":{"comp":[["bar_chart","bar_chart",["repeated"]],["stripe_graph","stripe_graph",["repeated"]],["comb","comb",["repeated"]],["proportional_area_chart","table",["nested"]]],"visType":["bar_chart","stripe_graph","comb","proportional_area_chart","table"],"compType":["repeated","nested"],"compressed_tree":[{"composite_pattern":"repeated","visualization_type":[["bar_chart"]]},{"composite_pattern":"repeated","visualization_type":[["stripe_graph"]]},{"composite_pattern":"repeated","visualization_type":[["bar_chart"]]},{"composite_pattern":"repeated","visualization_type":[[{"composite_pattern":"nested","visualization_type":[["proportional_area_chart"],["table"]]}]]}],"coOccurrence":[["bar_chart","stripe_graph",["coOccurrence"]],["bar_chart","proportional_area_chart",["coOccurrence"]],["bar_chart","table",["coOccurrence"]],["stripe_graph","proportional_area_chart",["coOccurrence"]],["stripe_graph","table",["coOccurrence"]],["proportional_area_chart","table",["coOccurrence"]]],"year":2019,"conference":["VAST"],"authors":["\xc1ngel Alexander Cabrera","Will Epperson","Fred Hohman","Minsuk Kahng","Jamie Morgenstern","Duen Horng Chau"],"title":"FairVis: Visual Analytics for Discovering Intersectional Bias in Machine Learning","doi":"10.1109/VAST47406.2019.8986948","abstract":"The growing capability and accessibility of machine learning has led to its application to many real-world domains and data about people. Despite the benefits algorithmic systems may bring, models can reflect, inject, or exacerbate implicit and explicit societal biases into their outputs, disadvantaging certain demographic subgroups. Discovering which biases a machine learning model has introduced is a great challenge, due to the numerous definitions of fairness and the large number of potentially impacted subgroups. We present FAIRVIS, a mixed-initiative visual analytics system that integrates a novel subgroup discovery technique for users to audit the fairness of machine learning models. Through FAIRVIS, users can apply domain knowledge to generate and investigate known subgroups, and explore suggested and similar subgroups. FAIRVIS\'s coordinated views enable users to explore a high-level overview of subgroup performance and subsequently drill down into detailed investigation of specific subgroups. We show how FAIRVIS helps to discover biases in two real datasets used in predicting income and recidivism. As a visual analytics system devoted to discovering bias in machine learning, FAIRVIS demonstrates how interactive visualization may help data scientists and the general public understand and create more equitable algorithmic systems.","keywords":" Machine learning fairness, visual analytics, intersec-tional bias, subgroup discovery","caption":"Figure 1:  FAIRVIS integrates multiple coordinated views for discovering intersectional bias.  Above, our user investigates the intersectional subgroups of sex and race. A. The Feature Distribution View allows users to visualize each feature\u2019s distribution and generate subgroups. B.The Subgroup Overview lets users select various fairness metrics to see the global average per metric and compare subgroups to one another, e.g.,pinned Caucasian Males versus hovered African-American Males. The plots for Recall and False Positive Rate show that for African-American Males, the model has relatively high recall but also the highest false positive rate out of all subgroups of sex and race. C.The Detailed Comparison View lets users compare the details of two groups and investigate their class balances. Since the difference in False Positive Rates between Caucasian Males and African-American Males is far larger than their difference in base rates, a user suspects this part of the model merits further inquiry. D. The Suggested and Similar Subgroup View shows suggested subgroups ranked by the worst performance in a given metric.","img_size":{"width":1823,"height":960},"subfigures":[{"x":6.957208438214125,"y":5.4853927834165,"width":1813.1699554879185,"height":952.0942629016472,"type":"interface","id":"interface-0"}],"visualizations":[{"x":11.042176236523739,"y":133.99124578199294,"width":342.72569340138136,"height":97.6662925741805,"type":"area_chart","id":"area_chart-0"},{"x":11.036306450974898,"y":233.89140606124462,"width":340.43199430983145,"height":110.21669768281707,"type":"bar_chart","id":"bar_chart-1"},{"x":9.901836704108112,"y":339.4364301627916,"width":346.15909179753913,"height":99.93657483886835,"type":"bar_chart","id":"bar_chart-2"},{"x":7.606479647498951,"y":438.35098598123454,"width":347.29164791678255,"height":104.07146859192417,"type":"bar_chart","id":"bar_chart-3"},{"x":1360.769122732481,"y":143.46337449451568,"width":382.13293163662416,"height":337.2359620482626,"type":"bar_chart","id":"bar_chart-4"},{"x":8.74390390521035,"y":540.9713855370799,"width":342.71136073870986,"height":99.64059483937784,"type":"bar_chart","id":"bar_chart-6"},{"x":11.048046022072679,"y":637.2876846254824,"width":345.01939249293525,"height":106.66384199091836,"type":"bar_chart","id":"bar_chart-7"},{"x":11.048046022072622,"y":742.2196785748888,"width":345.01939249292974,"height":98.86608846847656,"type":"bar_chart","id":"bar_chart-8"},{"x":7.606479647498913,"y":842.2494922971523,"width":347.29164791678187,"height":105.28455755066085,"type":"bar_chart","id":"bar_chart-9"},{"x":517.9462356441445,"y":676.8823889105863,"width":178.471721772344,"height":238.67107905704978,"type":"proportional_area_chart","id":"proportional_area_chart-17"},{"x":839.244727836496,"y":697.3532479263924,"width":167.56493095349947,"height":218.50280157983156,"type":"proportional_area_chart","id":"proportional_area_chart-18"},{"x":1146.326363212795,"y":684.305947803254,"width":174.7173797848402,"height":234.21068154891094,"type":"proportional_area_chart","id":"proportional_area_chart-19"},{"x":385.54715738658786,"y":122.2064169200294,"width":937.7864714256934,"height":438.6079587680192,"type":"stripe_graph","id":"stripe_graph-13"},{"x":1363.3572465929583,"y":480.11956476816124,"width":431.13449248792404,"height":205.18711594601962,"type":"table","id":"table-10"},{"x":696.105419094116,"y":621.88555451751,"width":312.0590706853386,"height":293.2689063648177,"type":"table","id":"table-11"},{"x":1004.3772029478798,"y":628.1174415943561,"width":316.8312225617477,"height":292.34593251912156,"type":"table","id":"table-12"},{"x":369.51212168113824,"y":623.8205696216457,"width":328.94459462013475,"height":292.96334523537416,"type":"table","id":"table-5"}],"relations":[{"vislist":[{"vislist":["bar_chart-1","bar_chart-2","bar_chart-3","bar_chart-6","bar_chart-7","bar_chart-8","bar_chart-9"],"relation":null,"id":"group-0"}],"relation":"repeated","id":"relation-0"},{"vislist":[{"vislist":["stripe_graph-13"],"relation":null,"id":"group-1"}],"relation":"repeated","id":"relation-1"},{"vislist":[{"vislist":["bar_chart-4"],"relation":null,"id":"group-2"}],"relation":"repeated","id":"relation-2"},{"vislist":[{"vislist":[{"vislist":[{"vislist":["proportional_area_chart-19"],"relation":null,"id":"group-8"},{"vislist":["table-12"],"relation":null,"id":"group-7"}],"relation":"nested","id":"relation-5"},{"vislist":[{"vislist":["proportional_area_chart-18"],"relation":null,"id":"group-6"},{"vislist":["table-11"],"relation":null,"id":"group-5"}],"relation":"nested","id":"relation-4"},{"vislist":[{"vislist":["proportional_area_chart-17"],"relation":null,"id":"group-4"},{"vislist":["table-5"],"relation":null,"id":"group-3"}],"relation":"nested","id":"relation-3"}],"relation":null,"id":"group-9"}],"relation":"repeated","id":"relation-6"}]},"2264_3":{"comp":[["others","others",["repeated"]]],"visType":["others"],"compType":["repeated"],"compressed_tree":[{"composite_pattern":"repeated","visualization_type":[["others"]]}],"coOccurrence":[["others","others",["coOccurrence"]]],"year":2012,"conference":["SciVis"],"authors":["Lars Kuehne","Joachim Giesen","Zhiyuan Zhang","Sungsoo Ha","Klaus Mueller"],"title":"A Data-Driven Approach to Hue-Preserving Color-Blending","doi":"10.1109/TVCG.2012.186","abstract":"Color mapping and semitransparent layering play an important role in many visualization scenarios, such as information visualization and volume rendering. The combination of color and transparency is still dominated by standard alpha-compositing using the Porter-Duff over operator which can result in false colors with deceiving impact on the visualization. Other more advanced methods have also been proposed, but the problem is still far from being solved. Here we present an alternative to these existing methods specifically devised to avoid false colors and preserve visual depth ordering. Our approach is data driven and follows the recently formulated knowledge-assisted visualization (KAV) paradigm. Preference data, that have been gathered in web-based user surveys, are used to train a support-vector machine model for automatically predicting an optimized hue-preserving blending. We have applied the resulting model to both volume rendering and a specific information visualization technique, illustrative parallel coordinate plots. Comparative renderings show a significant improvement over previous approaches in the sense that false colors are completely removed and important properties such as depth ordering and blending vividness are better preserved. Due to the generality of the defined data-driven blending operator, it can be easily integrated also into other visualization frameworks.","keywords":"Color blending, hue preservation, knowledge-assisted visualization, volume rendering, parallel coordinates","caption":"Fig. 3. A prototype interface. This version was not used for the final data collection. ","img_size":{"width":939,"height":567},"subfigures":[{"x":5.900996051086899,"y":5.774957306408297,"width":927.1980078978255,"height":557.7734891286113,"type":"interface","id":"interface-0"}],"visualizations":[{"x":210.96372602371835,"y":13.769263572500105,"width":514.5877796372273,"height":542.7708928038289,"type":"others","id":"others-0"}],"relations":[{"vislist":[{"vislist":["others-0"],"relation":null,"id":"group-0"}],"relation":"repeated","id":"relation-0"}]},"2264_4":{"comp":[["others","others",["repeated"]]],"visType":["others"],"compType":["repeated"],"compressed_tree":[{"composite_pattern":"repeated","visualization_type":[["others"]]}],"coOccurrence":[["others","others",["coOccurrence"]]],"year":2012,"conference":["SciVis"],"authors":["Lars Kuehne","Joachim Giesen","Zhiyuan Zhang","Sungsoo Ha","Klaus Mueller"],"title":"A Data-Driven Approach to Hue-Preserving Color-Blending","doi":"10.1109/TVCG.2012.186","abstract":"Color mapping and semitransparent layering play an important role in many visualization scenarios, such as information visualization and volume rendering. The combination of color and transparency is still dominated by standard alpha-compositing using the Porter-Duff over operator which can result in false colors with deceiving impact on the visualization. Other more advanced methods have also been proposed, but the problem is still far from being solved. Here we present an alternative to these existing methods specifically devised to avoid false colors and preserve visual depth ordering. Our approach is data driven and follows the recently formulated knowledge-assisted visualization (KAV) paradigm. Preference data, that have been gathered in web-based user surveys, are used to train a support-vector machine model for automatically predicting an optimized hue-preserving blending. We have applied the resulting model to both volume rendering and a specific information visualization technique, illustrative parallel coordinate plots. Comparative renderings show a significant improvement over previous approaches in the sense that false colors are completely removed and important properties such as depth ordering and blending vividness are better preserved. Due to the generality of the defined data-driven blending operator, it can be easily integrated also into other visualization frameworks.","keywords":"Color blending, hue preservation, knowledge-assisted visualization, volume rendering, parallel coordinates","caption":"Fig. 4. Final user-interface. This version was used to collect the prefer- ence data. ","img_size":{"width":705,"height":767},"subfigures":[{"x":6.926255806127642,"y":5.724128626929754,"width":692.1954113525331,"height":755.551742746139,"type":"interface","id":"interface-0"}],"visualizations":[{"x":17.295978775420007,"y":16.79653083020036,"width":675.6476572731005,"height":676.8339012070442,"type":"others","id":"others-0"}],"relations":[{"vislist":[{"vislist":["others-0"],"relation":null,"id":"group-0"}],"relation":"repeated","id":"relation-0"}]},"2267_5":{"comp":[["scatterplot","scatterplot",["repeated"]],["bar_chart","bar_chart",["repeated"]]],"visType":["scatterplot","bar_chart"],"compType":["repeated"],"compressed_tree":[{"composite_pattern":"repeated","visualization_type":[["scatterplot"]]},{"composite_pattern":"repeated","visualization_type":[["scatterplot"]]},{"composite_pattern":"repeated","visualization_type":[["bar_chart"]]}],"coOccurrence":[["scatterplot","bar_chart",["coOccurrence"]]],"year":2012,"conference":["SciVis"],"authors":["Andrea Unger","Sven Schulte","Volker Klemann","Doris Dransch"],"title":"A Visual Analysis Concept for the Validation of Geoscientific Simulation Models","doi":"10.1109/TVCG.2012.190","abstract":"Geoscientific modeling and simulation helps to improve our understanding of the complex Earth system. During the modeling process, validation of the geoscientific model is an essential step. In validation, it is determined whether the model output shows sufficient agreement with observation data. Measures for this agreement are called goodness of fit. In the geosciences, analyzing the goodness of fit is challenging due to its manifold dependencies: 1) The goodness of fit depends on the model parameterization, whose precise values are not known. 2) The goodness of fit varies in space and time due to the spatio-temporal dimension of geoscientific models. 3) The significance of the goodness of fit is affected by resolution and preciseness of available observational data. 4) The correlation between goodness of fit and underlying modeled and observed values is ambiguous. In this paper, we introduce a visual analysis concept that targets these challenges in the validation of geoscientific models - specifically focusing on applications where observation data is sparse, unevenly distributed in space and time, and imprecise, which hinders a rigorous analytical approach. Our concept, developed in close cooperation with Earth system modelers, addresses the four challenges by four tailored visualization components. The tight linking of these components supports a twofold interactive drill-down in model parameter space and in the set of data samples, which facilitates the exploration of the numerous dependencies of the goodness of fit. We exemplify our visualization concept for geoscientific modeling of glacial isostatic adjustments in the last 100,000 years, validated against sea levels indicators - a prominent example for sparse and imprecise observation data. An initial use case and feedback from Earth system modelers indicate that our visualization concept is a valuable complement to the range of validation methods.","keywords":"Earth science visualization, model validation, coordinated multiple views, spatio-temporal visualization, sea level indicators","caption":"Fig. 6. Exploration of goodness of fit in model parameter space. The goodness of fit is mapped to color according to the color scale at the bottom. A - A scatterplot matrix provides an overview of the model pa- rameter space. B - 2-D slices through parameter space support the exploration of dependencies on two parameters. C - The distribution of the goodness of fit is directly visualized in the 3-D parameter space. D - 1-D plots for each parameter convey variances of the goodness of fit across parameter values. E - A table provides a detailed representation of the model parameter space together with the respective fits. ","img_size":{"width":1055,"height":614},"subfigures":[{"x":7.443358231463471,"y":7.92508143698376,"width":1042.629776214571,"height":603.1818297088786,"type":"interface","id":"interface-0"}],"visualizations":[{"x":610.0161577785904,"y":319.06086939151044,"width":434.25816680191,"height":254.12963368900023,"type":"bar_chart","id":"bar_chart-3"},{"x":13.528677793218913,"y":308.1031150052896,"width":594.2945624580708,"height":276.9757490583375,"type":"bar_chart","id":"bar_chart-4"},{"x":776.951039065954,"y":25.068499304119577,"width":271.61425632978,"height":253.97100462526217,"type":"others","id":"others-0"},{"x":244.16447952433086,"y":39.77317580925925,"width":518.2811262266893,"height":237.5901439715324,"type":"scatterplot","id":"scatterplot-1"},{"x":25.625629175904795,"y":60.85861101763504,"width":196.9399711430155,"height":207.51715931443394,"type":"scatterplot","id":"scatterplot-2"}],"relations":[{"vislist":[{"vislist":["scatterplot-1"],"relation":null,"id":"group-0"}],"relation":"repeated","id":"relation-0"},{"vislist":[{"vislist":["scatterplot-2"],"relation":null,"id":"group-1"}],"relation":"repeated","id":"relation-1"},{"vislist":[{"vislist":["bar_chart-4"],"relation":null,"id":"group-2"}],"relation":"repeated","id":"relation-2"}]},"2281_7":{"comp":[["others","others",["repeated"]]],"visType":["others"],"compType":["repeated"],"compressed_tree":[{"composite_pattern":"repeated","visualization_type":[["others"]]}],"coOccurrence":[["others","others",["coOccurrence"]]],"year":2012,"conference":["SciVis"],"authors":["Mark A. Livingston","Jonathan W. Decker","Zhuming Ai"],"title":"Evaluation of Multivariate Visualization on a Multivariate Task","doi":"10.1109/TVCG.2012.223","abstract":"Multivariate visualization techniques have attracted great interest as the dimensionality of data sets grows. One premise of such techniques is that simultaneous visual representation of multiple variables will enable the data analyst to detect patterns amongst multiple variables. Such insights could lead to development of new techniques for rigorous (numerical) analysis of complex relationships hidden within the data. Two natural questions arise from this premise: Which multivariate visualization techniques are the most effective for high-dimensional data sets? How does the analysis task change this utility ranking? We present a user study with a new task to answer the first question. We provide some insights to the second question based on the results of our study and results available in the literature. Our task led to significant differences in error, response time, and subjective workload ratings amongst four visualization techniques. We implemented three integrated techniques (Data-driven Spots, Oriented Slivers, and Attribute Blocks), as well as a baseline case of separate grayscale images. The baseline case fared poorly on all three measures, whereas Datadriven Spots yielded the best accuracy and was among the best in response time. These results differ from comparisons of similar techniques with other tasks, and we review all the techniques, tasks, and results (from our work and previous work) to understand the reasons for this discrepancy.","keywords":"Quantitative evaluation, multivariate visualization, visual task design, texture perception","caption":"Fig. 5. Screen-captured  images  for  the  (top)  Data-driven  Spots  and (bottom) Juxtaposed Layers techniques.","img_size":{"width":1031,"height":1314},"subfigures":[{"x":14.508511373193883,"y":18.66658598913263,"width":1005.5704162526588,"height":634.1289086726761,"type":"interface","id":"interface-0"},{"x":10.937267529714799,"y":667.67584030433,"width":1007.3317454410466,"height":628.5273997374852,"type":"interface","id":"interface-1"}],"visualizations":[{"x":139.13490717786576,"y":737.139926564959,"width":673.8065276652411,"height":482.2580662191384,"type":"others","id":"others-0"},{"x":324.92276831599145,"y":121.0324352548456,"width":424.2037313565768,"height":424.01281416905215,"type":"scatterplot","id":"scatterplot-1"}],"relations":[{"vislist":[{"vislist":["others-0"],"relation":null,"id":"group-0"}],"relation":"repeated","id":"relation-0"}]},"2293_0":{"comp":[["scivis","scivis",["repeated"]],["others","others",["repeated"]],["scatterplot","map",["coordinated"]]],"visType":["scivis","others","scatterplot","map"],"compType":["repeated","coordinated"],"compressed_tree":[{"composite_pattern":"repeated","visualization_type":[["scivis"]]},{"composite_pattern":"repeated","visualization_type":[["others"]]},{"composite_pattern":"coordinated","visualization_type":[["scatterplot"],["map"]]}],"coOccurrence":[["scivis","others",["coOccurrence"]],["scivis","scatterplot",["coOccurrence"]],["scivis","map",["coOccurrence"]],["others","scatterplot",["coOccurrence"]],["others","map",["coOccurrence"]],["scatterplot","map",["coOccurrence"]]],"year":2012,"conference":["SciVis"],"authors":["Thomas H\xf6llt","Wolfgang Freiler","Fritz Gschwantner","Helmut Doleisch","Gabor Heinemann","Markus Hadwiger"],"title":"SeiVis: An Interactive Visual Subsurface Modeling Application","doi":"10.1109/TVCG.2012.259","abstract":"The most important resources to fulfill today\'s energy demands are fossil fuels, such as oil and natural gas. When exploiting hydrocarbon reservoirs, a detailed and credible model of the subsurface structures is crucial in order to minimize economic and ecological risks. Creating such a model is an inverse problem: reconstructing structures from measured reflection seismics. The major challenge here is twofold: First, the structures in highly ambiguous seismic data are interpreted in the time domain. Second, a velocity model has to be built from this interpretation to match the model to depth measurements from wells. If it is not possible to obtain a match at all positions, the interpretation has to be updated, going back to the first step. This results in a lengthy back and forth between the different steps, or in an unphysical velocity model in many cases. This paper presents a novel, integrated approach to interactively creating subsurface models from reflection seismics. It integrates the interpretation of the seismic data using an interactive horizon extraction technique based on piecewise global optimization with velocity modeling. Computing and visualizing the effects of changes to the interpretation and velocity model on the depth-converted model on the fly enables an integrated feedback loop that enables a completely new connection of the seismic data in time domain and well data in depth domain. Using a novel joint time/depth visualization, depicting side-by-side views of the original and the resulting depth-converted data, domain experts can directly fit their interpretation in time domain to spatial ground truth data. We have conducted a domain expert evaluation, which illustrates that the presented workflow enables the creation of exact subsurface models much more rapidly than previous approaches.","keywords":"Seismic visualization, volume deformation, exploded views, seismic interpretation","caption":"Fig. 1. A screenshot of our application illustrating our novel joint time/depth domain visualization for a seismic reflection dataset with two interactively interpreted seismic horizons. The two 3D views on the left show volume renderings of the seismic in time and depth domain, respectively, cut open at the horizons. The two 2D views on the top right show our interpretation views in time and depth as well. The 2D slice view on the bottom right shows the reflection data from the top in combination with well positions. ","img_size":{"width":1836,"height":679},"subfigures":[{"x":11.520906447539444,"y":6.353071877766979,"width":1811.6246493578599,"height":664.960971650587,"type":"interface","id":"interface-0"}],"visualizations":[{"x":1311.6762336389602,"y":450.6182030213858,"width":500.1226936843362,"height":176.7449701056738,"type":"map","id":"map-2"},{"x":1305.2094935379753,"y":63.17297989401277,"width":504.9588458299416,"height":272.0695764978225,"type":"others","id":"others-1"},{"x":1313.2050361414774,"y":447.1459506282285,"width":487.3482950116633,"height":167.47071976400355,"type":"scatterplot","id":"scatterplot-3"},{"x":353.86277220802685,"y":65.58607530479391,"width":930.6996510086058,"height":568.9122310567934,"type":"scivis","id":"scivis-0"}],"relations":[{"vislist":[{"vislist":["scivis-0"],"relation":null,"id":"group-0"}],"relation":"repeated","id":"relation-0"},{"vislist":[{"vislist":["others-1"],"relation":null,"id":"group-1"}],"relation":"repeated","id":"relation-1"},{"vislist":[{"vislist":["scatterplot-3"],"relation":null,"id":"group-2"},{"vislist":["map-2"],"relation":null,"id":"group-3"}],"relation":"coordinated","id":"relation-2"}]},"1618_17":{"comp":[["scatterplot","scatterplot",["repeated"]],["scatterplot","parallel_coordinate",["stacked"]],["parallel_coordinate","scatterplot",["stacked"]]],"visType":["scatterplot","parallel_coordinate"],"compType":["repeated","stacked"],"compressed_tree":[{"composite_pattern":"repeated","visualization_type":[["scatterplot"]]},{"composite_pattern":"repeated","visualization_type":[["scatterplot"]]},{"composite_pattern":"stacked","visualization_type":[["scatterplot","parallel_coordinate"]]}],"coOccurrence":[],"year":2007,"conference":["Vis"],"authors":["Huamin Qu","Wing-Yi Chan","Anbang Xu","Kai-Lun Chung","Alexis Kai-Hon Lau","Ping Guo"],"title":"Visual Analysis of the Air Pollution Problem in Hong Kong","doi":"10.1109/TVCG.2007.70523","abstract":"We present a comprehensive system for weather data visualization. Weather data are multivariate and contain vector fields formed by wind speed and direction. Several well-established visualization techniques such as parallel coordinates and polar systems are integrated into our system. We also develop various novel methods, including circular pixel bar charts embedded into polar systems, enhanced parallel coordinates with S-shape axis, and weighted complete graphs. Our system was used to analyze the air pollution problem in Hong Kong and some interesting patterns have been found.","keywords":"Weather data visualization, polar system, parallel coordinates, air pollution, visual analytics","caption":"Fig. 17. Using a weighted complete graph as a visual aid in explor- ing dimension correlations for year 2006 data of the Yuen Long station: (a) By arranging more correlated attributes together, positive and nega- tive correlations are clearly shown in the parallel coordinates; (b) Users can also plot the attributes demonstrating interesting relationships in the weighted complete graph as the embedded pixel bar in the polar sys- tem. ","img_size":{"width":768,"height":894},"subfigures":[{"x":10.56534473099063,"y":-0.3978862593037931,"width":754.4853467150542,"height":487.57854141029105,"type":"single","id":"single-0"},{"x":3.9062892801807867,"y":564.679583417704,"width":754.4753943068606,"height":288.8854461101129,"type":"single","id":"single-1"}],"visualizations":[{"x":395.6324198930388,"y":724.6164844177653,"width":223.30433144545745,"height":116.48517406744347,"type":"graph","id":"graph-10"},{"x":13.18241917792144,"y":18.38946018207287,"width":378.9214387128254,"height":446.1980800125054,"type":"graph","id":"graph-4"},{"x":372.05984390216287,"y":580.9250698072708,"width":172.39301764787322,"height":157.44449194017366,"type":"graph","id":"graph-5"},{"x":6.667648064040188,"y":567.411192495055,"width":170.1339272844201,"height":173.05494101951237,"type":"graph","id":"graph-6"},{"x":12.294004927166336,"y":723.7262055164582,"width":159.8332180802961,"height":123.02294251384633,"type":"graph","id":"graph-9"},{"x":391.26783737583617,"y":131.3781949839986,"width":362.45811601160074,"height":103.19322857144991,"type":"parallel_coordinate","id":"parallel_coordinate-1"},{"x":396.02116978125986,"y":9.40710088825456,"width":359.61548285565976,"height":124.49795863362311,"type":"scatterplot","id":"scatterplot-0"},{"x":395.9690614228153,"y":238.49937078185607,"width":354.00767243977225,"height":125.85996703641506,"type":"scatterplot","id":"scatterplot-2"},{"x":395.00449722578355,"y":355.9334065156005,"width":353.08078726744714,"height":113.62935369824069,"type":"scatterplot","id":"scatterplot-3"},{"x":166.91438489490488,"y":610.7218887188299,"width":199.0261132442089,"height":203.46093040916637,"type":"scatterplot","id":"scatterplot-7"},{"x":539.8683796782873,"y":614.1235640080878,"width":204.24969163760258,"height":196.65757983064958,"type":"scatterplot","id":"scatterplot-8"}],"relations":[{"vislist":[{"vislist":["scatterplot-0"],"relation":null,"id":"group-0"}],"relation":"repeated","id":"relation-0"},{"vislist":[{"vislist":["scatterplot-2"],"relation":null,"id":"group-1"}],"relation":"repeated","id":"relation-1"},{"vislist":[{"vislist":["scatterplot-0","parallel_coordinate-1","scatterplot-2","scatterplot-3"],"relation":null,"id":"group-2"}],"relation":"stacked","id":"relation-2"}]},"1654_3":{"comp":[["scatterplot","scatterplot",["repeated"]],["heatmap","scivis",["repeated"]],["scivis","heatmap",["repeated"]]],"visType":["scatterplot","heatmap","scivis"],"compType":["repeated"],"compressed_tree":[{"composite_pattern":"repeated","visualization_type":[["scatterplot"]]},{"composite_pattern":"repeated","visualization_type":[["heatmap","scivis"]]}],"coOccurrence":[["scatterplot","heatmap",["coOccurrence"]],["scatterplot","scivis",["coOccurrence"]],["heatmap","scivis",["coOccurrence"]]],"year":2007,"conference":["Vis"],"authors":["Philipp Muigg","Markus Hadwiger","Helmut Doleisch","Helwig Hauser"],"title":"Scalable Hybrid Unstructured and Structured Grid Raycasting","doi":"10.1109/TVCG.2007.70588","abstract":"This paper presents a scalable framework for real-time raycasting of large unstructured volumes that employs a hybrid bricking approach. It adaptively combines original unstructured bricks in important (focus) regions, with structured bricks that are resampled on demand in less important (context) regions. The basis of this focus+context approach is interactive specification of a scalar degree of interest (DOI) function. Thus, rendering always considers two volumes simultaneously: a scalar data volume, and the current DOI volume. The crucial problem of visibility sorting is solved by raycasting individual bricks and compositing in visibility order from front to back. In order to minimize visual errors at the grid boundary, it is always rendered accurately, even for resampled bricks. A variety of different rendering modes can be combined, including contour enhancement. A very important property of our approach is that it supports a variety of cell types natively, i.e., it is not constrained to tetrahedral grids, even when interpolation within cells is used. Moreover, our framework can handle multi-variate data, e.g., multiple scalar channels such as temperature or pressure, as well as time-dependent data. The combination of unstructured and structured bricks with different quality characteristics such as the type of interpolation or resampling resolution in conjunction with custom texture memory management yields a very scalable system.","keywords":"Volume Rendering of Unstructured Grids, Focus+Context Techniques, Hardware-Assisted Volume Rendering","caption":"Fig. 2. The SimVis system with our raycasting view showing high/low temperature (red/green) regions, and low pressure (yellow) regions within theGeneratordataset containing more than six million cells.","img_size":{"width":1053,"height":757},"subfigures":[{"x":4.3188216178911984,"y":5.127151779787421,"width":1044.3623567642185,"height":749.9682543440914,"type":"interface","id":"interface-0"}],"visualizations":[{"x":871.3447699609816,"y":55.182942502527766,"width":175.1986465738505,"height":432.33401440107525,"type":"bar_chart","id":"bar_chart-1"},{"x":281.025694753123,"y":59.160043196299426,"width":538.461090012611,"height":423.5741735376168,"type":"heatmap","id":"heatmap-4"},{"x":687.4945382752823,"y":544.6149717282722,"width":357.680969448007,"height":168.0721710877877,"type":"scatterplot","id":"scatterplot-2"},{"x":297.86451474220985,"y":545.3714076015513,"width":359.83012268877025,"height":162.5311019616458,"type":"scatterplot","id":"scatterplot-3"},{"x":281.0558526912288,"y":51.21293402098257,"width":544.8431442406524,"height":442.69094979191624,"type":"scivis","id":"scivis-0"}],"relations":[{"vislist":[{"vislist":["scatterplot-2","scatterplot-3"],"relation":null,"id":"group-0"}],"relation":"repeated","id":"relation-0"},{"vislist":[{"vislist":["heatmap-4","scivis-0"],"relation":null,"id":"group-1"}],"relation":"repeated","id":"relation-1"}]},"3237_3":{"comp":[["graph","graph",["repeated"]]],"visType":["graph"],"compType":["repeated"],"compressed_tree":[{"composite_pattern":"repeated","visualization_type":[["graph"]]},{"composite_pattern":"repeated","visualization_type":[["graph"]]}],"coOccurrence":[["graph","graph",["coOccurrence"]]],"year":2020,"conference":["InfoVis"],"authors":["Jiacheng Pan","Wei Chen","Xiaodong Zhao","Shuyue Zhou","Wei Zeng","Minfeng Zhu","Jian Chen","Siwei Fu","Yingcai Wu"],"title":"Exemplar-based Layout Fine-tuning for Node-link Diagrams","doi":"10.1109/TVCG.2020.3030393","abstract":"We design and evaluate a novel layout fine-tuning technique for node-link diagrams that facilitates exemplar-based adjustment of a group of substructures in batching mode. The key idea is to transfer user modifications on a local substructure to other substructures in the entire graph that are topologically similar to the exemplar. We first precompute a canonical representation for each substructure with node embedding techniques and then use it for on-the-fly substructure retrieval. We design and develop a light-weight interactive system to enable intuitive adjustment, modification transfer, and visual graph exploration. We also report some results of quantitative comparisons, three case studies, and a within-participant user study.","keywords":"Node-link diagram, graph layout, graph visualization, user interactions","caption":"Figure 3. The user interface of our prototype system: (a) an exemplar view; (b) a control panel; (c) a suggestions gallery; (d) a node-link view; (e) a modi\ufb01cation history view. ","img_size":{"width":984,"height":558},"subfigures":[{"x":8.487321714118346,"y":8.68342076814698,"width":963.9762949781016,"height":540.6331584637055,"type":"interface","id":"interface-0"}],"visualizations":[{"x":734.1876742449521,"y":35.41645810258495,"width":239.62174727596081,"height":504.5244736053785,"type":"graph","id":"graph-1"},{"x":8.24616492207847,"y":28.66072197836273,"width":155.97545828445604,"height":144.85206492702082,"type":"graph","id":"graph-2"},{"x":5.681592403145491,"y":307.4141521616988,"width":163.70844999142759,"height":239.9830614369894,"type":"graph","id":"graph-3"},{"x":168.25823129151462,"y":9.600579264249841,"width":561.5565973364711,"height":535.3273635093902,"type":"others","id":"others-0"}],"relations":[{"vislist":[{"vislist":["graph-1"],"relation":null,"id":"group-0"}],"relation":"repeated","id":"relation-0"},{"vislist":[{"vislist":["graph-3"],"relation":null,"id":"group-1"}],"relation":"repeated","id":"relation-1"}]},"3239_5":{"comp":[["polar_plot","polar_plot",["repeated"]],["treemap","treemap",["repeated"]]],"visType":["polar_plot","treemap"],"compType":["repeated"],"compressed_tree":[{"composite_pattern":"repeated","visualization_type":[["polar_plot"]]},{"composite_pattern":"repeated","visualization_type":[["treemap"]]}],"coOccurrence":[["polar_plot","treemap",["coOccurrence"]]],"year":2020,"conference":["InfoVis"],"authors":["Wonyoung So","Edyta P. Bogucka","Sanja \u0160\u0107epanovi\u0107","Sagar Joglekar","Ke Zhou","Daniele Quercia"],"title":"Humane Visual AI: Telling the Stories Behind a Medical Condition","doi":"10.1109/TVCG.2020.3030391","abstract":"A biological understanding is key for managing medical conditions, yet psychological and social aspects matter too. The main problem is that these two aspects are hard to quantify and inherently difficult to communicate. To quantify psychological aspects, this work mined around half a million Reddit posts in the sub-communities specialised in 14 medical conditions, and it did so with a new deep-learning framework. In so doing, it was able to associate mentions of medical conditions with those of emotions. To then quantify social aspects, this work designed a probabilistic approach that mines open prescription data from the National Health Service in England to compute the prevalence of drug prescriptions, and to relate such a prevalence to census data. To finally visually communicate each medical condition\'s biological, psychological, and social aspects through storytelling, we designed a narrative-style layered Martini Glass visualization. In a user study involving 52 participants, after interacting with our visualization, a considerable number of them changed their mind on previously held opinions: 10% gave more importance to the psychological aspects of medical conditions, and 27% were more favourable to the use of social media data in healthcare, suggesting the importance of persuasive elements in interactive visualizations.","keywords":"complex problem communication, storytelling, AI, social media data, healthcare, Martini Glass structure","caption":"Fig. 4. The dashboard used in the elicitation study among medical experts. A map encodes prescription prevalence together with socio-economic indicators (left), and blue/green bubbles show not only the typical symptoms but also those emerging from social media conversations (right). ","img_size":{"width":1896,"height":1020},"subfigures":[{"x":6.415370796223768,"y":8.920463916353786,"width":1883.1692584075545,"height":989.6200678484735,"type":"interface","id":"interface-0"}],"visualizations":[{"x":8.180200518556754,"y":10.367198324172058,"width":941.4291881652354,"height":572.8540696784827,"type":"heatmap","id":"heatmap-1"},{"x":4.8627070917674615,"y":13.685258269192603,"width":946.3917856947522,"height":571.2345560669486,"type":"map","id":"map-0"},{"x":9.824139920204464,"y":586.1805549719094,"width":934.7965307138195,"height":416.1876016204153,"type":"polar_plot","id":"polar_plot-2"},{"x":956.3251180990346,"y":277.1849232647417,"width":931.5945105439461,"height":552.5846622979873,"type":"treemap","id":"treemap-3"}],"relations":[{"vislist":[{"vislist":["polar_plot-2"],"relation":null,"id":"group-0"}],"relation":"repeated","id":"relation-0"},{"vislist":[{"vislist":["treemap-3"],"relation":null,"id":"group-1"}],"relation":"repeated","id":"relation-1"}]},"3242_2":{"comp":[["line_chart","line_chart",["repeated"]]],"visType":["line_chart"],"compType":["repeated"],"compressed_tree":[{"composite_pattern":"repeated","visualization_type":[["line_chart"]]},{"composite_pattern":"repeated","visualization_type":[["line_chart"]]}],"coOccurrence":[["line_chart","line_chart",["coOccurrence"]]],"year":2020,"conference":["InfoVis"],"authors":["Xi Chen","Wei Zeng","Yanna Lin","Hayder Mahdi AI-maneea","Jonathan Roberts","Remco Chang"],"title":"Composition and Configuration Patterns in Multiple-View Visualizations","doi":"10.1109/TVCG.2020.3030338","abstract":"Multiple-view visualization (MV) is a layout design technique often employed to help users see a large number of data attributes and values in a single cohesive representation. Because of its generalizability, the MV design has been widely adopted by the visualization community to help users examine and interact with large, complex, and high-dimensional data. However, although ubiquitous, there has been little work to categorize and analyze MVs in order to better understand its design space. As a result, there has been little to no guideline in how to use the MV design effectively. In this paper, we present an in-depth study of how MVs are designed in practice. We focus on two fundamental measures of multiple-view patterns: composition, which quantifies what view types and how many are there; and configuration, which characterizes spatial arrangement of view layouts in the display space. We build a new dataset containing 360 images of MVs collected from IEEE VIS, EuroVis, and PacificVis publications 2011 to 2019, and make fine-grained annotations of view types and layouts for these visualization images. From this data we conduct composition and configuration analyses using quantitative metrics of term frequency and layout topology. We identify common practices around MVs, including relationship of view types, popular view layouts, and correlation between view types and layouts. We combine the findings into a MV recommendation system, providing interactive tools to explore the design space, and support example-based design.","keywords":"Multiple views, design pattern, quantitative analysis, example-based design","caption":"Fig. 2. Our annotation tool consists of three components: Annotation View, Control Panel, and Historical View.","img_size":{"width":993,"height":480},"subfigures":[{"x":7.660277905028556,"y":9.804496344117569,"width":975.5157138258395,"height":458.2260519421273,"type":"interface","id":"interface-0"}],"visualizations":[{"x":675.2031473130003,"y":155.6681757479983,"width":288.1227535329585,"height":148.5240119599974,"type":"bar_chart","id":"bar_chart-3"},{"x":369.10828113137177,"y":14.489476568814311,"width":592.0001046859657,"height":139.2944986160188,"type":"line_chart","id":"line_chart-1"},{"x":369.68166969230265,"y":158.291447546034,"width":296.5551454997759,"height":148.53128659279702,"type":"line_chart","id":"line_chart-2"},{"x":267.0750892246882,"y":41.114371324817604,"width":97.9841935431717,"height":100.93052741914644,"type":"scatterplot","id":"scatterplot-0"}],"relations":[{"vislist":[{"vislist":["line_chart-2"],"relation":null,"id":"group-0"}],"relation":"repeated","id":"relation-0"},{"vislist":[{"vislist":["line_chart-1"],"relation":null,"id":"group-1"}],"relation":"repeated","id":"relation-1"}]},"3248_2":{"comp":[["storyline","storyline",["repeated"]]],"visType":["storyline"],"compType":["repeated"],"compressed_tree":[{"composite_pattern":"repeated","visualization_type":[["storyline"]]}],"coOccurrence":[["storyline","storyline",["coOccurrence"]]],"year":2020,"conference":["InfoVis"],"authors":["Tan Tang","Renzhong Li","Xinke Wu","Shuhan Liu","Johannes Knittel","Steffen Koch","Thomas Ertl","Lingyun Yu","Peiran Ren"],"title":"PlotThread: Creating Expressive Storyline Visualizations using Reinforcement Learning","doi":"10.1109/TVCG.2020.3030467","abstract":"Storyline visualizations are an effective means to present the evolution of plots and reveal the scenic interactions among characters. However, the design of storyline visualizations is a difficult task as users need to balance between aesthetic goals and narrative constraints. Despite that the optimization-based methods have been improved significantly in terms of producing aesthetic and legible layouts, the existing (semi-) automatic methods are still limited regarding 1) efficient exploration of the storyline design space and 2) flexible customization of storyline layouts. In this work, we propose a reinforcement learning framework to train an AI agent that assists users in exploring the design space efficiently and generating well-optimized storylines. Based on the framework, we introduce PlotThread, an authoring tool that integrates a set of flexible interactions to support easy customization of storyline visualizations. To seamlessly integrate the AI agent into the authoring process, we employ a mixed-initiative approach where both the agent and designers work on the same canvas to boost the collaborative design of storylines. We evaluate the reinforcement learning model through qualitative and quantitative experiments and demonstrate the usage of PlotThread using a collection of use cases.","keywords":"Storyline visualization, reinforcement learning, mixed-initiative design","caption":"Fig. 3. PlotThread is composed of a menubar for (a) loading story scripts, setting canvas, and exporting storylines; (l) a toolbar that provides a set of easy-to-use interactions (b) to (i); The red lines indicate the interactions that change original layouts (black lines) into desired layouts (blue lines). (j) buttons for activating and stopping the AI agent and (k) a panel for presenting AI-generated layouts; (m) a setting panel for changing the parameters of storylines and (n) an embellishing panel for inserting icons or images into the canvas. ","img_size":{"width":1893,"height":966},"subfigures":[{"x":302.6806691977792,"y":5.8256546923176185,"width":1268.3895236019266,"height":948.8542723252374,"type":"interface","id":"interface-0"}],"visualizations":[{"x":1246.0184984613804,"y":128.81063528387222,"width":319.32172920859784,"height":756.8284628206201,"type":"storyline","id":"storyline-0"}],"relations":[{"vislist":[{"vislist":["storyline-0"],"relation":null,"id":"group-0"}],"relation":"repeated","id":"relation-0"}]},"3252_0":{"comp":[["bar_chart","bar_chart",["repeated"]]],"visType":["bar_chart"],"compType":["repeated"],"compressed_tree":[{"composite_pattern":"repeated","visualization_type":[["bar_chart"]]}],"coOccurrence":[],"year":2020,"conference":["InfoVis"],"authors":["Mai Elshehaly","Rebecca Randell","Matthew Brehmer","Lynn McVey","Natasha Alvarado","Chris P. Gale","Roy A. Ruddle"],"title":"QualDash: Adaptable Generation of Visualisation Dashboards for Healthcare Quality Improvement","doi":"10.1109/TVCG.2020.3030424","abstract":"Adapting dashboard design to different contexts of use is an open question in visualisation research. Dashboard designers often seek to strike a balance between dashboard adaptability and ease-of-use, and in hospitals challenges arise from the vast diversity of key metrics, data models and users involved at different organizational levels. In this design study, we present QualDash, a dashboard generation engine that allows for the dynamic configuration and deployment of visualisation dashboards for healthcare quality improvement (QI). We present a rigorous task analysis based on interviews with healthcare professionals, a co-design workshop and a series of one-on-one meetings with front line analysts. From these activities we define a metric card metaphor as a unit of visual analysis in healthcare QI, using this concept as a building block for generating highly adaptable dashboards, and leading to the design of a Metric Specification Structure (MSS). Each MSS is a JSON structure which enables dashboard authors to concisely configure unit-specific variants of a metric card, while offloading common patterns that are shared across cards to be preset by the engine. We reflect on deploying and iterating the design of OualDash in cardiology wards and pediatric intensive care units of five NHS hospitals. Finally, we report evaluation results that demonstrate the adaptability, ease-of-use and usefulness of QualDash in a real-world scenario.","keywords":"Information visualisation, task analysis, co-design, dashboards, design study, healthcare.","caption":"Fig. 1. A dashboard with four dynamically generated QualCards (left) including one for the Mortality metric (a); and an expansion of the Mortality QualCard with categorical (b), quantitative (c) and temporal (d) subsidiary views, which are customisable via a popover (e). ","img_size":{"width":1821,"height":665},"subfigures":[{"x":5.163075348695494,"y":30.149886840786905,"width":559.4537313402918,"height":453.8769722316973,"type":"interface","id":"interface-0"},{"x":570.6748915932325,"y":11.87865346924897,"width":1233.8375629300363,"height":637.2736600592198,"type":"interface","id":"interface-1"}],"visualizations":[{"x":1419.4208154669261,"y":401.9815150614028,"width":381.1887780258672,"height":241.61224006055403,"type":"bar_chart","id":"bar_chart-0"},{"x":1052.3248329051921,"y":274.1371106651368,"width":259.2576570695048,"height":161.68825784750695,"type":"bar_chart","id":"bar_chart-2"},{"x":573.0480320146082,"y":118.97943796898778,"width":456.45601907236517,"height":271.2782497675689,"type":"bar_chart","id":"bar_chart-4"},{"x":22.55840234602255,"y":83.57686453603026,"width":539.0824893389716,"height":383.83427015570885,"type":"bar_chart","id":"bar_chart-5"},{"x":595.4671558747835,"y":466.6358507951312,"width":707.1649530381098,"height":152.44863928754452,"type":"line_chart","id":"line_chart-3"},{"x":1055.5631283561688,"y":122.27706462519713,"width":260.81223958293555,"height":155.48840416625393,"type":"pie_chart","id":"pie_chart-1"}],"relations":[{"vislist":[{"vislist":["bar_chart-5"],"relation":null,"id":"group-0"}],"relation":"repeated","id":"relation-0"}]},"3253_0":{"comp":[["bar_chart","bar_chart",["repeated"]],["glyph_based","glyph_based",["repeated"]],["comb","comb",["repeated"]],["others","others",["repeated"]],["scatterplot","scatterplot",["mirrored"]]],"visType":["bar_chart","glyph_based","comb","others","scatterplot"],"compType":["repeated","mirrored"],"compressed_tree":[{"composite_pattern":"mirrored","visualization_type":[["scatterplot"]]},{"composite_pattern":"repeated","visualization_type":[["bar_chart"]]},{"composite_pattern":"repeated","visualization_type":[["glyph_based"]]},{"composite_pattern":"mirrored","visualization_type":[["scatterplot"]]},{"composite_pattern":"repeated","visualization_type":[[{"composite_pattern":"mirrored","visualization_type":[["scatterplot"]]}]]},{"composite_pattern":"repeated","visualization_type":[["others"]]},{"composite_pattern":"repeated","visualization_type":[["glyph_based"]]}],"coOccurrence":[["scatterplot","bar_chart",["coOccurrence"]],["scatterplot","glyph_based",["coOccurrence"]],["scatterplot","others",["coOccurrence"]],["bar_chart","glyph_based",["coOccurrence"]],["bar_chart","others",["coOccurrence"]],["glyph_based","others",["coOccurrence"]]],"year":2020,"conference":["InfoVis"],"authors":["Qianwen Wang","Zhenhua Xu","Zhutian Chen","Yong Wang","Shixia Liu","Huamin Qu"],"title":"Visual Analysis of Discrimination in Machine Learning","doi":"10.1109/TVCG.2020.3030471","abstract":"The growing use of automated decision-making in critical applications, such as crime prediction and college admission, has raised questions about fairness in machine learning. How can we decide whether different treatments are reasonable or discriminatory? In this paper, we investigate discrimination in machine learning from a visual analytics perspective and propose an interactive visualization tool, DiscriLens, to support a more comprehensive analysis. To reveal detailed information on algorithmic discrimination, DiscriLens identifies a collection of potentially discriminatory itemsets based on causal modeling and classification rules mining. By combining an extended Euler diagram with a matrix-based visualization, we develop a novel set visualization to facilitate the exploration and interpretation of discriminatory itemsets. A user study shows that users can interpret the visually encoded information in DiscriLens quickly and accurately. Use cases demonstrate that DiscriLens provides informative guidance in understanding and reducing algorithmic discrimination.","keywords":"Machine Learning, Discrimination, Data Visualization.","caption":"Fig. 1. DiscriLens facilitates a better understanding and analysis of algorithmic discrimination: (a) scatter plots offer an overview of the discriminatory itemsets; (b) RippleSets reveal the intersections among these itemsets; (c) the attribute matrix represents the details of each discriminatory itemset; (d) the comparison mode enables users to compare two models side by side. ","img_size":{"width":1812,"height":767},"subfigures":[{"x":7.458265987939843,"y":5.362775340975795,"width":1799.7156797862922,"height":752.3252272042723,"type":"interface","id":"interface-0"}],"visualizations":[{"x":575.5284597211598,"y":33.815913270975734,"width":801.5931396596374,"height":176.73524667859266,"type":"bar_chart","id":"bar_chart-3"},{"x":252.14766772272995,"y":216.20568670872743,"width":251.23092516370792,"height":539.166652967163,"type":"glyph_based","id":"glyph_based-11"},{"x":1401.3683197253958,"y":261.93045953538694,"width":404.57587868566446,"height":479.6824239364406,"type":"glyph_based","id":"glyph_based-2"},{"x":512.0239916913786,"y":220.88841928753197,"width":882.2514880606001,"height":528.2029219784242,"type":"others","id":"others-12"},{"x":1401.2631333687984,"y":-0.3308453500104256,"width":391.9998823895861,"height":257.81489056960385,"type":"scatterplot","id":"scatterplot-0"},{"x":254.05673968402272,"y":-0.7138356336426394,"width":324.1309952967352,"height":212.23116203410356,"type":"scatterplot","id":"scatterplot-6"},{"x":3.9000580031822505,"y":8.24514413865916,"width":245.8611609890059,"height":708.9548001133052,"type":"scatterplot","id":"scatterplot-8"}],"relations":[{"vislist":[{"vislist":["scatterplot-0"],"relation":null,"id":"group-0"}],"relation":"mirrored","id":"relation-0"},{"vislist":[{"vislist":["bar_chart-3"],"relation":null,"id":"group-1"}],"relation":"repeated","id":"relation-1"},{"vislist":[{"vislist":["glyph_based-2"],"relation":null,"id":"group-2"}],"relation":"repeated","id":"relation-2"},{"vislist":[{"vislist":["scatterplot-6"],"relation":null,"id":"group-3"}],"relation":"mirrored","id":"relation-3"},{"vislist":[{"vislist":[{"vislist":[{"vislist":["scatterplot-8"],"relation":null,"id":"group-4"}],"relation":"mirrored","id":"relation-4"}],"relation":null,"id":"group-5"}],"relation":"repeated","id":"relation-5"},{"vislist":[{"vislist":["others-12"],"relation":null,"id":"group-6"}],"relation":"repeated","id":"relation-6"},{"vislist":[{"vislist":["glyph_based-11"],"relation":null,"id":"group-7"}],"relation":"repeated","id":"relation-7"}]},"3256_8":{"comp":[["scatterplot","scatterplot",["repeated"]]],"visType":["scatterplot"],"compType":["repeated"],"compressed_tree":[{"composite_pattern":"repeated","visualization_type":[["scatterplot"]]}],"coOccurrence":[["scatterplot","scatterplot",["coOccurrence"]]],"year":2020,"conference":["InfoVis"],"authors":["Michail Schwab","David Saffo","Yixuan Zhang","Shash Sinha","Cristina Nita-Rotaru","James Tompkin","Cody Dunne","Michelle A. Borkin"],"title":"VisConnect: Distributed Event Synchronization for Collaborative Visualization","doi":"10.1109/TVCG.2020.3030366","abstract":"Tools and interfaces are increasingly expected to be synchronous and distributed to accommodate remote collaboration. Yet, adoption of these techniques for data visualization is low partly because development is difficult: existing collaboration software systems either do not support simultaneous interaction or require expensive redevelopment of existing visualizations. We contribute VisConnect: a web-based synchronous distributed collaborative visualization system that supports most web-based SVG data visualizations, balances system safety with responsiveness, and supports simultaneous interaction from many collaborators. VisConnect works with existing visualization implementations with little-to-no code changes by synchronizing low-level JavaScript events across clients such that visualization updates proceed transparently across clients. This is accomplished via a peer-to-peer system that establishes consensus among clients on the per-element sequence of events, and uses a lock service to grant access over elements to clients. We contribute collaborative extensions of traditional visualization interaction techniques, such as drag, brush, and lasso, and discuss different strategies for collaborative visualization interactions. To demonstrate the utility of VisConnect, we present novel examples of collaborative visualizations in the healthcare domain, remote collaboration with annotation, and show in an education case study for e-learning with 22 participants that students found the ability to remotely collaborate on class activities helpful and enjoyable for understanding concepts. A free copy of this paper and source code are available on OSF at osf.io/ut7e6 and at visconnect.us.","keywords":"Collaborative visualization, distributed visualization, toolkit.","caption":"Fig. 9. A collaborative scenario where a doctor (top) and a patient (bottom) use IDMVis to share decision-making processes in diabetes management with the help of VisConnect. After the doctor selects a date from the Overview 1 , both the doctor and the patient see the same graph in the Detail View 2 . Upon interaction, both can see the same details on demand in the Mouseover tooltip 3 . ","img_size":{"width":941,"height":778},"subfigures":[{"x":158.44049838267568,"y":9.947255735233234,"width":766.4588487407603,"height":367.04153509868416,"type":"interface","id":"interface-0"}],"visualizations":[{"x":161.5947223247154,"y":11.881861374238484,"width":760.1504008566804,"height":146.38687137531193,"type":"scatterplot","id":"scatterplot-0"},{"x":163.70980053910313,"y":157.103699485826,"width":758.0447197339672,"height":217.25228256107326,"type":"scatterplot","id":"scatterplot-1"}],"relations":[{"vislist":[{"vislist":["scatterplot-0"],"relation":null,"id":"group-0"}],"relation":"repeated","id":"relation-0"}]},"3257_4":{"comp":[["others","others",["repeated"]]],"visType":["others"],"compType":["repeated"],"compressed_tree":[{"composite_pattern":"repeated","visualization_type":[["others"]]}],"coOccurrence":[["others","others",["coOccurrence"]]],"year":2020,"conference":["InfoVis"],"authors":["Yea-Seul Kim","Paula Kayongo","Madeleine Grunde-McLaughlin","Jessica Hullman"],"title":"Bayesian-Assisted Inference from Visualized Data","doi":"10.1109/TVCG.2020.3028984","abstract":"A Bayesian view of data interpretation suggests that a visualization user should update their existing beliefs about a parameter\'s value in accordance with the amount of information about the parameter value captured by the new observations. Extending recent work applying Bayesian models to understand and evaluate belief updating from visualizations, we show how the predictions of Bayesian inference can be used to guide more rational belief updating. We design a Bayesian inference-assisted uncertainty analogy that numerically relates uncertainty in observed data to the user\'s subjective uncertainty, and a posterior visualization that prescribes how a user should update their beliefs given their prior beliefs and the observed data. In a pre-registered experiment on 4,800 people, we find that when a newly observed data sample is relatively small (N=158), both techniques reliably improve people\'s Bayesian updating on average compared to the current best practice of visualizing uncertainty in the observed data. For large data samples (N=5208), where people\'s updated beliefs tend to deviate more strongly from the prescriptions of a Bayesian model, we find evidence that the effectiveness of the two forms of Bayesian assistance may depend on people\'s proclivity toward trusting the source of the data. We discuss how our results provide insight into individual processes of belief updating and subjective uncertainty, and how understanding these aspects of interpretation paves the way for more sophisticated interactive visualizations for analysis and communication.","keywords":"Bayesian cognition, Belief updating, Uncertainty visualization, Adaptive visualization.","caption":"Fig. 5. Conditions in our experiment, including visualizing observed data as a point estimate with sample size, using a high probability interval with shading to visualize uncertainty in the observed data only, providing an uncertainty analogy based on the participant\u2019s prior, and providing a predicted posterior visualization based on the user\u2019s prior. ","img_size":{"width":1864,"height":588},"subfigures":[{"x":6.292977604989183,"y":6.508241370672883,"width":917.2403472082408,"height":572.2718300684888,"type":"interface","id":"interface-0"}],"visualizations":[{"x":11.245364856597618,"y":30.096984797351787,"width":904.3361642597715,"height":352.23210772235825,"type":"others","id":"others-0"}],"relations":[{"vislist":[{"vislist":["others-0"],"relation":null,"id":"group-0"}],"relation":"repeated","id":"relation-0"}]},"3258_0":{"comp":[["scatterplot","scatterplot",["repeated"]],["bar_chart","bar_chart",["repeated"]]],"visType":["scatterplot","bar_chart"],"compType":["repeated"],"compressed_tree":[{"composite_pattern":"repeated","visualization_type":[["scatterplot"]]},{"composite_pattern":"repeated","visualization_type":[["bar_chart"]]}],"coOccurrence":[["bar_chart","bar_chart",["coOccurrence"]]],"year":2020,"conference":["InfoVis"],"authors":["Jonathan Zong","Dhiraj Barnwal","Rupayan Neogy","Arvind Satyanarayan"],"title":"Lyra 2: Designing Interactive Visualizations by Demonstration","doi":"10.1109/TVCG.2020.3030367","abstract":"Recent graphical interfaces offer direct manipulation mechanisms for authoring visualizations, but are largely restricted to static output. To author interactive visualizations, users must instead turn to textual specification, but such approaches impose a higher technical burden. To bridge this gap, we introduce Lyra 2, a system that extends a prior visualization design environment with novel methods for authoring interaction techniques by demonstration. Users perform an interaction (e.g., button clicks, drags, or key presses) directly on the visualization they are editing. The system interprets this performance using a set of heuristics and enumerates suggestions of possible interaction designs. These heuristics account for the properties of the interaction (e.g., target and event type) as well as the visualization (e.g., mark and scale types, and multiple views). Interaction design suggestions are displayed as thumbnails; users can preview and test these suggestions, iteratively refine them through additional demonstrations, and finally apply and customize them via property inspectors. We evaluate our approach through a gallery of diverse examples, and evaluate its usability through a first-use study and via an analysis of its cognitive dimensions. We find that, in Lyra 2, interaction design by demonstration enables users to rapidly express a wide range of interactive visualizations.","keywords":"Direct manipulation, interactive visualization, interaction design by demonstration","caption":"Fig. 1. An example interactive visualization designed in Lyra 2, a visualization design environment. Users can (a) brush in the scatterplot to re-aggregate the histogram, and (b) click histogram bars to \ufb01lter for corresponding points in the scatterplot. This visualization was designed by demonstration \u2014 users did not have to write any textual code. ","img_size":{"width":1718,"height":614},"subfigures":[{"x":10.717573130158806,"y":9.165971351038204,"width":824.3309339323482,"height":585.6879046384166,"type":"interface","id":"interface-0"},{"x":855.4599751416715,"y":10.40162943213168,"width":851.8616859249055,"height":584.4641075586677,"type":"interface","id":"interface-1"}],"visualizations":[{"x":243.17460575148223,"y":316.320642035684,"width":164.82164263760478,"height":152.47996057526493,"type":"bar_chart","id":"bar_chart-2"},{"x":956.6796916713992,"y":105.07433660569146,"width":130.44781319097612,"height":302.3900578388427,"type":"bar_chart","id":"bar_chart-3"},{"x":1096.8323166309324,"y":314.69759113145926,"width":178.98052442460502,"height":148.15432589492428,"type":"bar_chart","id":"bar_chart-5"},{"x":105.87877926188483,"y":130.72467738379515,"width":130.27530448707768,"height":301.0628371086436,"type":"scatterplot","id":"scatterplot-0"},{"x":244.61799863053778,"y":105.4032711682187,"width":472.5882303186733,"height":210.87135084832013,"type":"scatterplot","id":"scatterplot-1"},{"x":1105.7016529325776,"y":108.3542426963519,"width":470.37984295103547,"height":206.48375508981172,"type":"scatterplot","id":"scatterplot-4"}],"relations":[{"vislist":[{"vislist":["scatterplot-0"],"relation":null,"id":"group-0"}],"relation":"repeated","id":"relation-0"},{"vislist":[{"vislist":["bar_chart-3"],"relation":null,"id":"group-1"}],"relation":"repeated","id":"relation-1"}]},"3258_4":{"comp":[["area_chart","area_chart",["repeated"]],["line_chart","line_chart",["repeated"]]],"visType":["area_chart","line_chart"],"compType":["repeated"],"compressed_tree":[{"composite_pattern":"repeated","visualization_type":[["area_chart"]]},{"composite_pattern":"repeated","visualization_type":[["line_chart"]]}],"coOccurrence":[["line_chart","line_chart",["coOccurrence"]]],"year":2020,"conference":["InfoVis"],"authors":["Jonathan Zong","Dhiraj Barnwal","Rupayan Neogy","Arvind Satyanarayan"],"title":"Lyra 2: Designing Interactive Visualizations by Demonstration","doi":"10.1109/TVCG.2020.3030367","abstract":"Recent graphical interfaces offer direct manipulation mechanisms for authoring visualizations, but are largely restricted to static output. To author interactive visualizations, users must instead turn to textual specification, but such approaches impose a higher technical burden. To bridge this gap, we introduce Lyra 2, a system that extends a prior visualization design environment with novel methods for authoring interaction techniques by demonstration. Users perform an interaction (e.g., button clicks, drags, or key presses) directly on the visualization they are editing. The system interprets this performance using a set of heuristics and enumerates suggestions of possible interaction designs. These heuristics account for the properties of the interaction (e.g., target and event type) as well as the visualization (e.g., mark and scale types, and multiple views). Interaction design suggestions are displayed as thumbnails; users can preview and test these suggestions, iteratively refine them through additional demonstrations, and finally apply and customize them via property inspectors. We evaluate our approach through a gallery of diverse examples, and evaluate its usability through a first-use study and via an analysis of its cognitive dimensions. We find that, in Lyra 2, interaction design by demonstration enables users to rapidly express a wide range of interactive visualizations.","keywords":"Direct manipulation, interactive visualization, interaction design by demonstration","caption":"Fig. 5. Example interactive visualizations demonstrating Lyra 2\u2019s coverage over Yi et al.\u2019s taxonomy [61]. (a, b) Selecting marks of interest; (c) Exploring subsets of data via pan & zoom; (d) Recon\ufb01guring data via an index chart; Abstract/Elaborate data via (e) tooltips or (f) an overview+detail visualization; (f) Filtering data via query widgets, recreating a New York Times visualization [12]; (g) Connecting related tuples via brushing & linking. Walkthroughs are provided in supplementary material. ","img_size":{"width":1942,"height":2502},"subfigures":[{"x":1012.752563604278,"y":1343.664488669572,"width":903.8632710823715,"height":511.8396627872008,"type":"interface","id":"interface-0"},{"x":1019.6554660658527,"y":833.510639694829,"width":896.8904654553503,"height":476.1419205453131,"type":"interface","id":"interface-1"}],"visualizations":[{"x":1127.1122878500735,"y":1393.636399074,"width":781.0553116808089,"height":422.14832198020184,"type":"area_chart","id":"area_chart-1"},{"x":1133.5295173241411,"y":880.4692512608685,"width":754.5548541404131,"height":406.14715075089964,"type":"line_chart","id":"line_chart-0"}],"relations":[{"vislist":[{"vislist":["area_chart-1"],"relation":null,"id":"group-0"}],"relation":"repeated","id":"relation-0"},{"vislist":[{"vislist":["line_chart-0"],"relation":null,"id":"group-2"}],"relation":"repeated","id":"relation-2"}]},"3259_0":{"comp":[["graph","graph",["repeated"]],["area_chart","stripe_graph",["accompanied"]],["stripe_graph","area_chart",["accompanied"]]],"visType":["graph","area_chart","stripe_graph"],"compType":["repeated","accompanied"],"compressed_tree":[{"composite_pattern":"accompanied","visualization_type":[["area_chart","stripe_graph"]]},{"composite_pattern":"repeated","visualization_type":[["graph"]]}],"coOccurrence":[["area_chart","stripe_graph",["coOccurrence"]],["area_chart","graph",["coOccurrence"]],["stripe_graph","graph",["coOccurrence"]]],"year":2020,"conference":["InfoVis"],"authors":["Alexandra Lee","Daniel Archambault","Miguel A. Nacenta"],"title":"The Effectiveness of Interactive Visualization Techniques for Time Navigation of Dynamic Graphs on Large Displays","doi":"10.1109/TVCG.2020.3030446","abstract":"Dynamic networks can be challenging to analyze visually, especially if they span a large time range during which new nodes and edges can appear and disappear. Although it is straightforward to provide interfaces for visualization that represent multiple states of the network (i.e., multiple timeslices) either simultaneously (e.g., through small multiples) or interactively (e.g., through interactive animation), these interfaces might not support tasks in which disjoint timeslices need to be compared. Since these tasks are key for understanding the dynamic aspects of the network, understanding which interactive visualizations best support these tasks is important. We present the results of a series of laboratory experiments comparing two traditional approaches (small multiples and interactive animation), with a more recent approach based on interactive timeslicing. The tasks were performed on a large display through a touch interface. Participants completed 24 trials of three tasks with all techniques. The results show that interactive timeslicing brings benefit when comparing distant points in time, but less benefits when analyzing contiguous intervals of time.","keywords":"Dynamic networks, Information visualization, Large displays","caption":"Fig. 1. The interfaces used in this experiment. Interactive animation is at the top, small multiples in the middle, and interactive timeslicing at the bottom. ","img_size":{"width":1770,"height":2460},"subfigures":[{"x":6.827964897248048,"y":816.2471663026845,"width":1736.1711556918126,"height":817.4252913736249,"type":"interface","id":"interface-0"}],"visualizations":[{"x":86.71300854725781,"y":870.9111594603012,"width":1643.644116770757,"height":257.840509453207,"type":"area_chart","id":"area_chart-2"},{"x":83.18070020222592,"y":1137.7495209821136,"width":1620.449361690289,"height":406.26923049802417,"type":"graph","id":"graph-0"},{"x":80.11622665865316,"y":882.9112318708147,"width":1653.475528129018,"height":254.00111667420404,"type":"stripe_graph","id":"stripe_graph-1"}],"relations":[{"vislist":[{"vislist":["area_chart-2","stripe_graph-1"],"relation":null,"id":"group-0"}],"relation":"accompanied","id":"relation-0"},{"vislist":[{"vislist":["graph-0"],"relation":null,"id":"group-1"}],"relation":"repeated","id":"relation-1"}]},"3262_5":{"comp":[["matrix","matrix",["repeated"]]],"visType":["matrix"],"compType":["repeated"],"compressed_tree":[{"composite_pattern":"repeated","visualization_type":[["matrix"]]}],"coOccurrence":[["matrix","matrix",["coOccurrence"]]],"year":2020,"conference":["InfoVis"],"authors":["Arpit Narechania","Ahsan Qamar","Alex Endert"],"title":"SafetyLens: Visual Data Analysis of Functional Safety of Vehicles","doi":"10.1109/TVCG.2020.3030382","abstract":"Modern automobiles have evolved from just being mechanical machines to having full-fledged electronics systems that enhance vehicle dynamics and driver experience. However, these complex hardware and software systems, if not properly designed, can experience failures that can compromise the safety of the vehicle, its occupants, and the surrounding environment. For example, a system to activate the brakes to avoid a collision saves lives when it functions properly, but could lead to tragic outcomes if the brakes were applied in a way that\'s inconsistent with the design. Broadly speaking, the analysis performed to minimize such risks falls into a systems engineering domain called Functional Safety. In this paper, we present SafetyLens, a visual data analysis tool to assist engineers and analysts in analyzing automotive Functional Safety datasets. SafetyLens combines techniques including network exploration and visual comparison to help analysts perform domain-specific tasks. This paper presents the design study with domain experts that resulted in the design guidelines, the tool, and user feedback.","keywords":"Visual data analysis, Design study, Network visualization, Functional safety, Automotive engineering.","caption":"Fig. 5. The Summary View shows three projects P1, P2, and P3 and the distribution of nodes by their Types, links by their Relations, and ASILs by their values. The column S is a count of shared entities (nodes and links) between the projects. Project P1 has 318 nodes and 675 links. The projects share 15 nodes and 0 links among them. ","img_size":{"width":987,"height":672},"subfigures":[{"x":12.868988272550995,"y":8.633297239029249,"width":965.8551904246962,"height":652.8976297262453,"type":"interface","id":"interface-0"}],"visualizations":[{"x":20.113312010199145,"y":75.95235191100917,"width":939.4243088279255,"height":555.8929241940614,"type":"matrix","id":"matrix-0"}],"relations":[{"vislist":[{"vislist":["matrix-0"],"relation":null,"id":"group-0"}],"relation":"repeated","id":"relation-0"}]},"3268_0":{"comp":[["pie_chart","pie_chart",["repeated"]]],"visType":["pie_chart"],"compType":["repeated"],"compressed_tree":[{"composite_pattern":"repeated","visualization_type":[["pie_chart"]]}],"coOccurrence":[["pie_chart","pie_chart",["coOccurrence"]]],"year":2020,"conference":["InfoVis"],"authors":["Elaine Huynh","Angela Nyhout","Patricia Ganea","Fanny Chevalier"],"title":"Designing Narrative-Focused Role-Playing Games for Visualization Literacy in Young Children","doi":"10.1109/TVCG.2020.3030464","abstract":"Building on game design and education research, this paper introduces narrative-focused role-playing games as a way to promote visualization literacy in young children. Visualization literacy skills are vital in understanding the world around us and constructing meaningful visualizations, yet, how to better develop these skills at an early age remains largely overlooked and understudied. Only recently has the visualization community started to fill this gap, resulting in preliminary studies and development of educational tools for use in early education. We add to these efforts through the exploration of gamification to support learning, and identify an opportunity to apply role-playing game-based designs by leveraging the presence of narratives in data-related problems involving visualizations. We study the effects of including narrative elements on learning through a technology probe, grounded in a set of design considerations stemming from visualization, game design and education science. We create two versions of a game - one with narrative elements and one without - and evaluate our instances on 33 child participants between 11- to 13-years old using a between-subjects study design. Despite participants requiring double the amount of time to complete their game due to additional narrative elements, the inclusion of such elements were found to improve engagement without sacrificing learning; our results indicate no significant differences in development of graph-reading skills, but significant differences in engagement and overall enjoyment of the game. We report observations and qualitative feedback collected, and note areas for improvement and room for future work.","keywords":"Visualization Literacy; Educational technology; Gami\ufb01cation; Narrative","caption":"Fig. 1. Sample screenshots from our educational role-playing game (RPG) to support visualization literacy education at ages 11 - 13. Our game encompasses data-related problems involving visualizations that young learners are required to solve to make progress in the game. Players must \ufb01rst indicate the right graph to solve the problem (a), and then interpret the selected graph to answer a question (b). In this work, we investigate the effect of incorporating narrative elements on learning and engagement (c). ","img_size":{"width":1821,"height":364},"subfigures":[{"x":9.211280549425021,"y":13.007136349817143,"width":591.0366058636415,"height":339.31200088561616,"type":"interface","id":"interface-0"}],"visualizations":[{"x":303.954823052991,"y":63.69801814472718,"width":167.43157521115057,"height":251.08115963614702,"type":"pie_chart","id":"pie_chart-0"}],"relations":[{"vislist":[{"vislist":["pie_chart-0"],"relation":null,"id":"group-0"}],"relation":"repeated","id":"relation-0"}]},"3271_7":{"comp":[["scatterplot","scatterplot",["repeated"]]],"visType":["scatterplot"],"compType":["repeated"],"compressed_tree":[{"composite_pattern":"repeated","visualization_type":[["scatterplot"]]}],"coOccurrence":[["scatterplot","scatterplot",["coOccurrence"]]],"year":2020,"conference":["InfoVis"],"authors":["Arpit Narechania","Arjun Srinivasan","John Stasko"],"title":"NL4DV: A Toolkit for Generating Analytic Specifications for Data Visualization from Natural Language Queries","doi":"10.1109/TVCG.2020.3030378","abstract":"Natural language interfaces (NLls) have shown great promise for visual data analysis, allowing people to flexibly specify and interact with visualizations. However, developing visualization NLIs remains a challenging task, requiring low-level implementation of natural language processing (NLP) techniques as well as knowledge of visual analytic tasks and visualization design. We present NL4DV, a toolkit for natural language-driven data visualization. NL4DV is a Python package that takes as input a tabular dataset and a natural language query about that dataset. In response, the toolkit returns an analytic specification modeled as a JSON object containing data attributes, analytic tasks, and a list of Vega-Lite specifications relevant to the input query. In doing so, NL4DV aids visualization developers who may not have a background in NLP, enabling them to create new visualization NLIs or incorporate natural language input within their existing systems. We demonstrate NL4DV\'s usage and capabilities through four examples: 1) rendering visualizations using natural language in a Jupyter notebook, 2) developing a NLI to specify and edit Vega-Lite charts, 3) recreating data ambiguity widgets from the DataTone system, and 4) incorporating speech input to create a multimodal visualization system.","keywords":"Natural Language Interfaces; Visualization Toolkits;","caption":"Fig. 7: A Vega-Lite editor that supports NL-based chart speci\ufb01cation and presents design alternatives using the visList returned by NL4DV. Here, the query \u201cShow debt and earnings for different types of colleges\u201d issued in the context of a U.S. colleges dataset results in the system suggesting a colored scatterplot and a colored + faceted scatterplot. The faceted scatterplot is selected as the active chart by the user. ","img_size":{"width":933,"height":549},"subfigures":[{"x":7.09937833756908,"y":4.088998726550961,"width":915.0518439075985,"height":539.3222392852344,"type":"interface","id":"interface-0"}],"visualizations":[{"x":330.43676772625116,"y":112.7323454976286,"width":582.3837922026581,"height":296.3478111746605,"type":"scatterplot","id":"scatterplot-0"}],"relations":[{"vislist":[{"vislist":["scatterplot-0"],"relation":null,"id":"group-0"}],"relation":"repeated","id":"relation-0"}]},"3273_4":{"comp":[["bar_chart","bar_chart",["repeated"]]],"visType":["bar_chart"],"compType":["repeated"],"compressed_tree":[{"composite_pattern":"repeated","visualization_type":[["bar_chart"]]}],"coOccurrence":[["bar_chart","bar_chart",["coOccurrence"]]],"year":2020,"conference":["InfoVis"],"authors":["Houda Lamqaddam","Andrew Vande Moere","Vero Vanden Abeele","Koenraad Brosens","Katrien Verbert"],"title":"Introducing Layers of Meaning (LoM): A Framework to Reduce Semantic Distance of Visualization In Humanistic Research","doi":"10.1109/TVCG.2020.3030426","abstract":"Information visualization (infovis) is a powerful tool for exploring rich datasets. Within humanistic research, rich qualitative data and domain culture make traditional infovis approaches appear reductive and disconnected, leading to low adoption. In this paper, we use a multi-step approach to scrutinize the relationship between infovis and the humanities and suggest new directions for it. We first look into infovis from the humanistic perspective by exploring the humanistic literature around infovis. We validate and expand those findings though a co-design workshop with humanist and infovis experts. Then, we translate our findings into guidelines for designers and conduct a design critique exercise to explore their effect on the perception of humanist researchers. Based on these steps, we introduce Layers of Meaning, a framework to reduce the semantic distance between humanist researchers and visualizations of their research material, by grounding infovis tools in time and space, physicality, terminology, nuance, and provenance.","keywords":"Infovis, Humanities, Digital Humanities","caption":"Fig. 4. Design submitted by D4. Humanists critiqued the choice of the cross symbol to denote death, when this symbol is not universal, nor necessarily relevant for the displayed region. ","img_size":{"width":816,"height":477},"subfigures":[{"x":11.45149778681966,"y":8.735822125507818,"width":800.9140410726745,"height":464.08911124141724,"type":"interface","id":"interface-0"}],"visualizations":[{"x":12.739770288557986,"y":398.60763523951357,"width":563.7952738446251,"height":74.9970417369188,"type":"bar_chart","id":"bar_chart-1"},{"x":590.1875441620647,"y":254.52514892491453,"width":221.51158170984837,"height":136.4008516192624,"type":"bar_chart","id":"bar_chart-3"},{"x":14.137586031538543,"y":9.626584433638534,"width":562.439167346463,"height":387.9187905408336,"type":"map","id":"map-0"}],"relations":[{"vislist":[{"vislist":["bar_chart-1"],"relation":null,"id":"group-0"}],"relation":"repeated","id":"relation-0"}]},"3278_7":{"comp":[["scatterplot","scatterplot",["repeated"]]],"visType":["scatterplot"],"compType":["repeated"],"compressed_tree":[{"composite_pattern":"repeated","visualization_type":[["scatterplot"]]}],"coOccurrence":[["scatterplot","scatterplot",["coOccurrence"]]],"year":2020,"conference":["InfoVis"],"authors":["Sara Di Bartolomeo","Yixuan Zhang","Fangfang Sheng","Cody Dunne"],"title":"Sequence Braiding: Visual Overviews of Temporal Event Sequences and Attributes","doi":"10.1109/TVCG.2020.3030442","abstract":"Temporal event sequence alignment has been used in many domains to visualize nuanced changes and interactions overtime. Existing approaches align one or two sentinel events. Overview tasks require examining all alignments of interest using interaction and time or juxtaposition of many visualizations. Furthermore, any event attribute overviews are not closely tied to sequence visualizations. We present SEQUENCE BRAIDING, a novel overview visualization for temporal event sequences and attributes using a layered directed acyclic network. SEQUENCE BRAIDING visually aligns many temporal events and attribute groups simultaneously and supports arbitrary ordering, absence, and duplication of events. In a controlled experiment we compare SEQUENCE BRAIDING and IDMVis on user task completion time, correctness, error, and confidence. Our results provide good evidence that users of SEQUENCE BRAIDING can understand high-level patterns and trends faster and with similar error. A full version of this paper with all appendices; the evaluation stimuli, data, and analysis code; and source code are available at osf.io/mq2wt.","keywords":"Temporal event sequence visualization, network visualization, algorithm, evaluation","caption":"Fig. 8: Comparison of the stimuli used in the experiment (Top: SE- QUENCE BRAIDING vs. Bottom: IDMVis). ","img_size":{"width":863,"height":681},"subfigures":[{"x":9.520610672725986,"y":6.021904839521877,"width":839.3059886399041,"height":672.6769144783055,"type":"single","id":"single-0"}],"visualizations":[{"x":13.199785037156444,"y":5.933698761272673,"width":830.086523905185,"height":155.67266876329998,"type":"parallel_coordinate","id":"parallel_coordinate-0"},{"x":11.368327993525407,"y":191.99048184330815,"width":836.5411120012324,"height":485.8457872988423,"type":"scatterplot","id":"scatterplot-1"}],"relations":[{"vislist":[{"vislist":["scatterplot-1"],"relation":null,"id":"group-0"}],"relation":"repeated","id":"relation-0"}]},"3283_1":{"comp":[["bar_chart","bar_chart",["repeated"]],["comb","comb",["repeated"]],["comb","stripe_graph",["stacked"]],["scatterplot","scatterplot",["repeated"]],["stripe_graph","comb",["stacked"]],["area_chart","area_chart",["mirrored"]]],"visType":["bar_chart","comb","stripe_graph","scatterplot","area_chart"],"compType":["repeated","stacked","mirrored"],"compressed_tree":[{"composite_pattern":"repeated","visualization_type":[["bar_chart"]]},{"composite_pattern":"repeated","visualization_type":[[{"composite_pattern":"stacked","visualization_type":[["stripe_graph",{"composite_pattern":"mirrored","visualization_type":[["area_chart"]]}]]}]]},{"composite_pattern":"repeated","visualization_type":[["scatterplot"]]},{"composite_pattern":"repeated","visualization_type":[["scatterplot"]]},{"composite_pattern":"repeated","visualization_type":[[{"composite_pattern":"stacked","visualization_type":[["stripe_graph",{"composite_pattern":"mirrored","visualization_type":[["area_chart"]]}]]}]]}],"coOccurrence":[["bar_chart","area_chart",["coOccurrence"]],["bar_chart","stripe_graph",["coOccurrence"]],["bar_chart","scatterplot",["coOccurrence"]],["area_chart","stripe_graph",["coOccurrence"]],["area_chart","scatterplot",["coOccurrence"]],["stripe_graph","scatterplot",["coOccurrence"]]],"year":2020,"conference":["InfoVis"],"authors":["Jen Rogers","Austin H. Patton","Luke Harmon","Alexander Lex","Miriah Meyer"],"title":"Insights From Experiments With Rigor in an EvoBio Design Study","doi":"10.1109/TVCG.2020.3030405","abstract":"Design study is an established approach of conducting problem-driven visualization research. The academic visualization community has produced a large body of work for reporting on design studies, informed by a handful of theoretical frameworks, and applied to a broad range of application areas. The result is an abundance of reported insights into visualization design, with an emphasis on novel visualization techniques and systems as the primary contribution of these studies. In recent work we proposed a new, interpretivist perspective on design study and six companion criteria for rigor that highlight the opportunities for researchers to contribute knowledge that extends beyond visualization idioms and software. In this work we conducted a year-long collaboration with evolutionary biologists to develop an interactive tool for visual exploration of multivariate datasets and phylogenetic trees. During this design study we experimented with methods to support three of the rigor criteria: ABUNDANT, REFLEXIVE, and TRANSPARENT. As a result we contribute two novel visualization techniques for the analysis of multivariate phylogenetic datasets, three methodological recommendations for conducting design studies drawn from reflections over our process of experimentation, and two writing devices for reporting interpretivist design study. We offer this work as an example for implementing the rigor criteria to produce a diverse range of knowledge contributions.","keywords":"Methodologies, Application Motivated Visualization, Guidelines, Life Sciences Visualization, Health, Medicine, Biology,Bioinformatics, Genomics","caption":"Fig. 2. Trait view showing four continuous and two discrete trait variables for 100 Anolis lizard species. (a) Outliers in the last SVL bin are brushed. A traditional phylogenetic tree view, shown on the right, can be used to de\ufb01ne subtrees. (b) Leaf nodes can be color-coded by trait category. This detail view shows all leaf nodes color-coded by island of origin. These categories can be used to de\ufb01ne subgroups by trait category or value, independent of the topology of the tree. ","img_size":{"width":2007,"height":687},"subfigures":[{"x":3.8855008477093502,"y":6.265327582891941,"width":1991.9402993439285,"height":670.0993134122148,"type":"interface","id":"interface-0"}],"visualizations":[{"x":80.25372668276567,"y":499.56158756907416,"width":966.6543448549156,"height":89.56536390261103,"type":"area_chart","id":"area_chart-13"},{"x":84.39561572048142,"y":98.53752403678708,"width":949.5190758159051,"height":277.578587675803,"type":"area_chart","id":"area_chart-3"},{"x":1063.7327637451795,"y":181.00853168656963,"width":269.0000749070271,"height":482.4731567794048,"type":"bar_chart","id":"bar_chart-2"},{"x":64.46439596398648,"y":583.7665141653255,"width":985.8409189434657,"height":87.49349603976259,"type":"scatterplot","id":"scatterplot-10"},{"x":75.66006061753339,"y":375.008800859826,"width":974.0713787926633,"height":124.55502003506403,"type":"scatterplot","id":"scatterplot-9"},{"x":76.74990192008964,"y":494.36267767619375,"width":968.3510998021217,"height":96.4240776175287,"type":"stripe_graph","id":"stripe_graph-14"},{"x":79.13207720822189,"y":98.53752403678713,"width":958.2758546477104,"height":277.57858767580296,"type":"stripe_graph","id":"stripe_graph-4"},{"x":1710.8845787008215,"y":13.04399164936385,"width":282.94680941242547,"height":657.3729106304281,"type":"tree","id":"tree-0"},{"x":1348.7296284415995,"y":105.75846912327529,"width":348.7057822407408,"height":563.9607135245412,"type":"tree","id":"tree-1"}],"relations":[{"vislist":[{"vislist":["bar_chart-2"],"relation":null,"id":"group-1"}],"relation":"repeated","id":"relation-0"},{"vislist":[{"vislist":[{"vislist":[{"vislist":["stripe_graph-4",{"vislist":[{"vislist":["area_chart-3"],"relation":null,"id":"group-2"}],"relation":"mirrored","id":"relation-1"}],"relation":null,"id":"group-3"}],"relation":"stacked","id":"relation-2"}],"relation":null,"id":"group-4"}],"relation":"repeated","id":"relation-3"},{"vislist":[{"vislist":["scatterplot-9"],"relation":null,"id":"group-5"}],"relation":"repeated","id":"relation-4"},{"vislist":[{"vislist":["scatterplot-10"],"relation":null,"id":"group-6"}],"relation":"repeated","id":"relation-5"},{"vislist":[{"vislist":[{"vislist":[{"vislist":["stripe_graph-14",{"vislist":[{"vislist":["area_chart-13"],"relation":null,"id":"group-7"}],"relation":"mirrored","id":"relation-6"}],"relation":null,"id":"group-8"}],"relation":"stacked","id":"relation-7"}],"relation":null,"id":"group-9"}],"relation":"repeated","id":"relation-8"}]},"3286_7":{"comp":[["comb","comb",["repeated"]],["scatterplot","line_chart",["accompanied"]],["line_chart","scatterplot",["accompanied"]],["unit_visualization","bar_chart",["nested"]]],"visType":["comb","scatterplot","line_chart","unit_visualization","bar_chart"],"compType":["repeated","accompanied","nested"],"compressed_tree":[{"composite_pattern":"nested","visualization_type":[["unit_visualization"],["bar_chart"]]},{"composite_pattern":"repeated","visualization_type":[[{"composite_pattern":"accompanied","visualization_type":[["scatterplot","line_chart"]]}]]}],"coOccurrence":[["unit_visualization","bar_chart",["coOccurrence"]],["unit_visualization","scatterplot",["coOccurrence"]],["unit_visualization","line_chart",["coOccurrence"]],["bar_chart","scatterplot",["coOccurrence"]],["bar_chart","line_chart",["coOccurrence"]],["scatterplot","line_chart",["coOccurrence"]]],"year":2020,"conference":["InfoVis"],"authors":["Danqing Shi","Xinyue Xu","Fuling Sun","Yang Shi","Nan Cao"],"title":"Calliope: A System for Automatic Visual Data Story Generation from a Spreadsheet","doi":"10.1109/TVCG.2020.3030403","abstract":"Visual data stories shown in the form of narrative visualizations such as a poster or a data video, are frequently used in data-oriented storytelling to facilitate the understanding and memorization of the story content. Although useful, technique barriers, such as data analysis, visualization, and scripting, make the generation of a visual data story difficult. Existing authoring tools rely on users\' skills and experiences, which are usually inefficient and still difficult. In this paper, we introduce a novel visual data story generating system, Calliope, which creates visual data stories from an input spreadsheet through an automatic process and facilities the easy revision of the generated story based on an online story editor. Particularly, Calliope incorporates a new logic-oriented Monte Carlo tree search algorithm that explores the data space given by the input spreadsheet to progressively generate story pieces (i.e., data facts) and organize them in a logical order. The importance of data facts is measured based on information theory, and each data fact is visualized in a chart and captioned by an automatically generated description. We evaluate the proposed technique through three example stories, two controlled experiments, and a series of interviews with 10 domain experts. Our evaluation shows that Calliope is beneficial to efficient visual data story generation.","keywords":"Information Visualization, Visual Storytelling, Data Story","caption":"Fig. 5. The story editor of Calliope system consists of three major views: (1) the storyline view for story con\ufb01guration, generation, and storyline editing, (2) the fact view for fact editing, and (3) the story visualization view for the visual data story preview and sharing (factsheet mode). ","img_size":{"width":984,"height":686},"subfigures":[{"x":11.191410615978699,"y":11.61677337088604,"width":964.4282750490213,"height":665.5774849453871,"type":"interface","id":"interface-0"}],"visualizations":[{"x":696.3583023098086,"y":75.31503745671321,"width":173.18032554304378,"height":222.40839724941455,"type":"bar_chart","id":"bar_chart-0"},{"x":511.04697267054684,"y":70.68788204841505,"width":173.67530782599357,"height":227.91466581646458,"type":"bar_chart","id":"bar_chart-2"},{"x":10.981073134764005,"y":10.825417055177239,"width":187.1123122739175,"height":191.1588318843606,"type":"bar_chart","id":"bar_chart-4"},{"x":327.9076926976272,"y":310.9766937235222,"width":535.2687073035336,"height":143.6925103558255,"type":"line_chart","id":"line_chart-6"},{"x":326.9297509185701,"y":310.1918096444518,"width":536.2875587679889,"height":145.26227851396524,"type":"scatterplot","id":"scatterplot-5"},{"x":510.10705409098335,"y":73.45592877539453,"width":173.68108079780185,"height":223.3155829248923,"type":"unit_visualization","id":"unit_visualization-1"},{"x":14.711904070146977,"y":11.756913964005786,"width":187.14690715242943,"height":191.16985919147658,"type":"unit_visualization","id":"unit_visualization-3"}],"relations":[{"vislist":[{"vislist":["unit_visualization-1"],"relation":null,"id":"group-0"},{"vislist":["bar_chart-2"],"relation":null,"id":"group-1"}],"relation":"nested","id":"relation-0"},{"vislist":[{"vislist":[{"vislist":[{"vislist":["scatterplot-5","line_chart-6"],"relation":null,"id":"group-2"}],"relation":"accompanied","id":"relation-1"}],"relation":null,"id":"group-3"}],"relation":"repeated","id":"relation-2"}]},"3287_8":{"comp":[["bar_chart","bar_chart",["repeated"]]],"visType":["bar_chart"],"compType":["repeated"],"compressed_tree":[{"composite_pattern":"repeated","visualization_type":[["bar_chart"]]}],"coOccurrence":[["bar_chart","bar_chart",["coOccurrence"]]],"year":2020,"conference":["InfoVis"],"authors":["Theophanis Tsandilas"],"title":"StructGraphics: Flexible Visualization Design through Data-Agnostic and Reusable Graphical Structures","doi":"10.1109/TVCG.2020.3030476","abstract":"Information visualization research has developed powerful systems that enable users to author custom data visualizations without textual programming. These systems can support graphics-driven practices by bridging lazy data-binding mechanisms with vector-graphics editing tools. Yet, despite their expressive power, visualization authoring systems often assume that users want to generate visual representations that they already have in mind rather than explore designs. They also impose a data-to-graphics workflow, where binding data dimensions to graphical properties is a necessary step for generating visualization layouts. In this paper, we introduce StructGraphics, an approach for creating data-agnostic and fully reusable visualization designs. StructGraphics enables designers to construct visualization designs by drawing graphics on a canvas and then structuring their visual properties without relying on a concrete dataset or data schema. In StructGraphics, tabular data structures are derived directly from the structure of the graphics. Later, designers can link these structures with real datasets through a spreadsheet user interface. StructGraphics supports the design and reuse of complex data visualizations by combining graphical property sharing, by-example design specification, and persistent layout constraints. We demonstrate the power of the approach through a gallery of visualization examples and reflect on its strengths and limitations in interaction with graphic designers and data visualization experts.","keywords":"Visualization design, graphical structures, visualization grammars, layout constraints, infographics, \ufb02exible data binding.","caption":"Fig. 9. Recreating the Wall Street Journal\u2019s A Field Guide to Red and Blue America visualization [58] with StructGraphics. ","img_size":{"width":987,"height":516},"subfigures":[{"x":9.042916859996815,"y":8.09592707073526,"width":968.197280791798,"height":501.24213315321225,"type":"interface","id":"interface-0"}],"visualizations":[{"x":12.169016361993249,"y":42.851971388416324,"width":758.942719646137,"height":466.86983252881333,"type":"bar_chart","id":"bar_chart-1"},{"x":772.8168293486403,"y":15.17711719449973,"width":204.00762730174415,"height":491.74139482860824,"type":"table","id":"table-0"}],"relations":[{"vislist":[{"vislist":["bar_chart-1"],"relation":null,"id":"group-0"}],"relation":"repeated","id":"relation-0"}]},"3288_2":{"comp":[["scatterplot","scatterplot",["repeated"]]],"visType":["scatterplot"],"compType":["repeated"],"compressed_tree":[{"composite_pattern":"repeated","visualization_type":[["scatterplot"]]}],"coOccurrence":[["scatterplot","scatterplot",["coOccurrence"]]],"year":2020,"conference":["InfoVis"],"authors":["Benjamin Lee","Xiaoyun Hu","Maxime Cordeil","Arnaud Prouzeau","Bernhard Jenny","Tim Dwyer"],"title":"Shared Surfaces and Spaces: Collaborative Data Visualisation in a Co-located Immersive Environment","doi":"10.1109/TVCG.2020.3030450","abstract":"Immersive technologies offer new opportunities to support collaborative visual data analysis by providing each collaborator a personal, high-resolution view of a flexible shared visualisation space through a head mounted display. However, most prior studies of collaborative immersive analytics have focused on how groups interact with surface interfaces such as tabletops and wall displays. This paper reports on a study in which teams of three co-located participants are given flexible visualisation authoring tools to allow a great deal of control in how they structure their shared workspace. They do so using a prototype system we call FIESTA: the Free-roaming Immersive Environment to Support Team-based Analysis. Unlike traditional visualisation tools, FIESTA allows users to freely position authoring interfaces and visualisation artefacts anywhere in the virtual environment, either on virtual surfaces or suspended within the interaction space. Our participants solved visual analytics tasks on a multivariate data set, doing so individually and collaboratively by creating a large number of 2D and 3D visualisations. Their behaviours suggest that the usage of surfaces is coupled with the type of visualisation used, often using walls to organise 2D visualisations, but positioning 3D visualisations in the space around them. Outside of tightly-coupled collaboration, participants followed social protocols and did not interact with visualisations that did not belong to them even if outside of its owner\'s personal workspace.","keywords":"Immersive analytics, collaboration, virtual reality, qualitative study, multivariate data","caption":"Fig. 2. Visualisation styles available with FIESTA: 2D scatterplot (top left), 3D scatterplot (top right), time series (bottom left), faceted 2D scatterplots on the panel (bottom right). ","img_size":{"width":976,"height":912},"subfigures":[{"x":403.52565167448523,"y":477.60682212096185,"width":562.404999740894,"height":422.6800273373117,"type":"interface","id":"interface-0"}],"visualizations":[{"x":12.967922916800132,"y":473.7553178954755,"width":369.8406185971675,"height":421.663100758726,"type":"line_chart","id":"line_chart-2"},{"x":489.8251862336991,"y":5.596483720230201,"width":479.45420221256404,"height":454.84464104786457,"type":"scatterplot","id":"scatterplot-0"},{"x":10.357318664807691,"y":8.070249199951343,"width":463.46498380805224,"height":453.6342251010909,"type":"scatterplot","id":"scatterplot-1"},{"x":583.7208554175469,"y":530.5452703381296,"width":361.3892973038318,"height":347.9457560085394,"type":"scatterplot","id":"scatterplot-3"}],"relations":[{"vislist":[{"vislist":["scatterplot-3"],"relation":null,"id":"group-0"}],"relation":"repeated","id":"relation-0"}]},"3290_16":{"comp":[["area_chart","area_chart",["repeated"]],["area_chart","map",["coordinated"]]],"visType":["area_chart","map"],"compType":["repeated","coordinated"],"compressed_tree":[{"composite_pattern":"repeated","visualization_type":[["area_chart"]]},{"composite_pattern":"coordinated","visualization_type":[["area_chart"],["map"]]}],"coOccurrence":[["area_chart","area_chart",["coOccurrence"]]],"year":2020,"conference":["InfoVis"],"authors":["Fritz Lekschas","Xinyi Zhou","Wei Chen","Nils Gehlenborg","Benjamin Bach","Hanspeter Pfister"],"title":"A Generic Framework and Library for Exploration of Small Multiples through Interactive Piling","doi":"10.1109/TVCG.2020.3028948","abstract":"Small multiples are miniature representations of visual information used generically across many domains. Handling large numbers of small multiples imposes challenges on many analytic tasks like inspection, comparison, navigation, or annotation. To address these challenges, we developed a framework and implemented a library called PILlNG.JS for designing interactive piling interfaces. Based on the piling metaphor, such interfaces afford flexible organization, exploration, and comparison of large numbers of small multiples by interactively aggregating visual objects into piles. Based on a systematic analysis of previous work, we present a structured design space to guide the design of visual piling interfaces. To enable designers to efficiently build their own visual piling interfaces, PILlNG.JS provides a declarative interface to avoid having to write low-level code and implements common aspects of the design space. An accompanying GUI additionally supports the dynamic configuration of the piling interface. We demonstrate the expressiveness of PILlNG.JS with examples from machine learning, immunofluorescence microscopy, genomics, and public health.","keywords":"Information visualization, small multiples, interactive piling, visual aggregation, spatial organization.","caption":"Fig. 17. Worldmap of COVID-19 Infection Rates. Small multiples of area charts (1) show the number of infected people over time. Arranging the charts geographically (2) and grouping them by overlap (3) highlights infection hot spots without overplotting issues. Upon zooming in, piles are automatically split (3-5). ","img_size":{"width":972,"height":456},"subfigures":[{"x":294.04573780328093,"y":9.66187318311588,"width":670.540696614695,"height":205.11011693553561,"type":"single","id":"single-0"},{"x":7.556441024812255,"y":11.836463198207639,"width":255.83847998064917,"height":434.44505656119037,"type":"single","id":"single-1"}],"visualizations":[{"x":6.800681875139354,"y":17.300656300087763,"width":255.3600355910862,"height":426.54285116458186,"type":"area_chart","id":"area_chart-0"},{"x":293.7710778331105,"y":9.651775081843601,"width":667.388012891523,"height":202.6369985398586,"type":"area_chart","id":"area_chart-3"},{"x":297.18360499012715,"y":12.119305619416478,"width":663.1350510189226,"height":202.84610122947046,"type":"map","id":"map-2"}],"relations":[{"vislist":[{"vislist":["area_chart-0"],"relation":null,"id":"group-0"}],"relation":"repeated","id":"relation-0"},{"vislist":[{"vislist":["area_chart-3"],"relation":null,"id":"group-1"},{"vislist":["map-2"],"relation":null,"id":"group-2"}],"relation":"coordinated","id":"relation-1"}]},"3294_2":{"comp":[["scatterplot","scatterplot",["repeated"]]],"visType":["scatterplot"],"compType":["repeated"],"compressed_tree":[{"composite_pattern":"repeated","visualization_type":[["scatterplot"]]}],"coOccurrence":[["scatterplot","scatterplot",["coOccurrence"]]],"year":2020,"conference":["InfoVis"],"authors":["Takanori Fujiwara","Jian Zhao","Francine Chen","Kwan-Liu Ma"],"title":"A Visual Analytics Framework for Contrastive Network Analysis","doi":"10.1109/VAST50239.2020.00010","abstract":"A common network analysis task is comparison of two networks to identify unique characteristics in one network with respect to the other. For example, when comparing protein interaction networks derived from normal and cancer tissues, one essential task is to discover protein-protein interactions unique to cancer tissues. However, this task is challenging when the networks contain complex structural (and semantic) relations. To address this problem, we design ContraNA, a visual analytics framework leveraging both the power of machine learning for uncovering unique characteristics in networks and also the effectiveness of visualization for understanding such uniqueness. The basis of ContraNA is cNRL, which integrates two machine learning schemes, network representation learning (NRL) and contrastive learning (CL), to generate a low-dimensional embedding that reveals the uniqueness of one network when compared to another. ContraNA provides an interactive visualization interface to help analyze the uniqueness by relating embedding results and network structures as well as explaining the learned features by cNRL. We demonstrate the usefulness of ContraNA with two case studies using real-world datasets. We also evaluate ContraNA through a controlled user study with 12 participants on network comparison tasks. The results show that participants were able to both effectively identify unique characteristics from complex networks and interpret the results obtained from cNRL.","keywords":" Contrastive learning, network representation learning,interpretability, network comparison, visual analytics.","caption":"Figure 2: The analyst is using ContraNA to conduct a contrastive analysis of the Dolphin social network [69] (the target network) and the Zachary\u2019s karate club network [94] (the background network). (a) A contrastive representation view shows contrastive representations of target and background networks. (b) A feature contribution view visualizes network features generated by DeepGL and their contributions to each cPC (i.e., scaled cPC loadings). (c) A probability distribution view depicts target and background networks\u2019 probability distributions of the selected network feature in (b). (d)(e) A network layout view draws laid-out target and background networks, respectively. (f) The analyst can change several settings of the algorithm and visualizations from the drop-down menu. ","img_size":{"width":2010,"height":1050},"subfigures":[{"x":9.690039821194883,"y":12.106691067782398,"width":1981.8604077053462,"height":1028.705148593554,"type":"interface","id":"interface-0"}],"visualizations":[{"x":394.3099715979945,"y":58.03331233522275,"width":99.1062653054669,"height":591.9776792667767,"type":"heatmap","id":"heatmap-1"},{"x":17.251588655332448,"y":718.9877949333942,"width":491.2814829593601,"height":318.96908748579034,"type":"line_chart","id":"line_chart-0"},{"x":390.0790917486374,"y":59.81880402251175,"width":100.47624749076148,"height":595.4938605774383,"type":"matrix","id":"matrix-2"},{"x":514.789243726954,"y":25.662418088285467,"width":982.1944569244455,"height":1009.3059108512873,"type":"scatterplot","id":"scatterplot-3"},{"x":1497.865949067805,"y":22.134202984142767,"width":492.9037134122403,"height":504.3146925510616,"type":"scatterplot","id":"scatterplot-4"},{"x":1496.090185823683,"y":525.4618439091126,"width":492.90935114377345,"height":514.6675430329054,"type":"scatterplot","id":"scatterplot-5"}],"relations":[{"vislist":[{"vislist":["scatterplot-4","scatterplot-5"],"relation":null,"id":"group-0"}],"relation":"repeated","id":"relation-0"}]},"3295_0":{"comp":[["bar_chart","bar_chart",["repeated"]],["bar_chart","comb",["stacked"]],["graph","matrix",["coordinated"]],["comb","bar_chart",["stacked"]]],"visType":["bar_chart","comb","graph","matrix"],"compType":["repeated","stacked","coordinated"],"compressed_tree":[{"composite_pattern":"repeated","visualization_type":[["bar_chart"]]},{"composite_pattern":"repeated","visualization_type":[["bar_chart"]]},{"composite_pattern":"repeated","visualization_type":[["bar_chart"]]},{"composite_pattern":"coordinated","visualization_type":[["graph"],["matrix"]]},{"composite_pattern":"stacked","visualization_type":[["bar_chart",{"composite_pattern":"coordinated","visualization_type":[["graph"],["matrix"]]}]]}],"coOccurrence":[["bar_chart","graph",["coOccurrence"]],["bar_chart","matrix",["coOccurrence"]],["graph","matrix",["coOccurrence"]]],"year":2020,"conference":["VAST"],"authors":["Wenbo Tao","Xinli Hou","Adam Sah","Leilani Battle","Remco Chang","Michael Stonebraker"],"title":"Kyrix-S: Authoring Scalable Scatterplot Visualizations of Big Data","doi":"10.1109/TVCG.2020.3030372","abstract":"Static scatterplots often suffer from the overdraw problem on big datasets where object overlap causes undesirable visual clutter. The use of zooming in scatterplots can help alleviate this problem. With multiple zoom levels, more screen real estate is available, allowing objects to be placed in a less crowded way. We call this type of visualization scalable scatterplot visualizations, or SSV for short. Despite the potential of SSVs, existing systems and toolkits fall short in supporting the authoring of SSVs due to three limitations. First, many systems have limited scalability, assuming that data fits in the memory of one computer. Second, too much developer work, e.g., using custom code to generate mark layouts or render objects, is required. Third, many systems focus on only a small subset of the SSV design space (e.g. supporting a specific type of visual marks). To address these limitations, we have developed Kyrix-S, a system for easy authoring of SSVs at scale. Kyrix-S derives a declarative grammar that enables specification of a variety of SSVs in a few tens of lines of code, based on an existing survey of scatterplot tasks and designs. The declarative grammar is supported by a distributed layout algorithm which automatically places visual marks onto zoom levels. We store data in a multi-node database and use multi-node spatial indexes to achieve interactive browsing of large SSVs. Extensive experiments show that 1) Kyrix-S enables interactive browsing of SSVs of billions of objects, with response times under 500ms and 2) Kyrix-S achieves 4X-9X reduction in specification compared to a state-of-the-art authoring system.","keywords":"Traf\ufb01c light detection, representation learning, semantic adversarial learning, model diagnosing, autonomous driving","caption":"Fig. 1. The VATLD user interface: (a) Summary and navigation of key performance statistics; (b) Visual landscapes of traf\ufb01c lights (upper) and performance scores (lower) over the \ufb01rst two PCA components of semantic dimensions; (c) A live view to detect a traf\ufb01c light from either real data or adversarial; (d) Ranked latent dimensions with information of semantics, performance and gradients. ","img_size":{"width":1452,"height":928},"subfigures":[{"x":8.448229678178047,"y":6.953373715582025,"width":1436.371841932069,"height":919.1634904807574,"type":"interface","id":"interface-0"}],"visualizations":[{"x":8.784586962694844,"y":100.46773100207564,"width":1429.307810676855,"height":118.93168053357572,"type":"bar_chart","id":"bar_chart-0"},{"x":870.8978588216016,"y":275.04663626891653,"width":49.60405245795864,"height":270.4368541910971,"type":"bar_chart","id":"bar_chart-1"},{"x":54.21405927679099,"y":535.462947838407,"width":814.620541628379,"height":34.9111565217431,"type":"bar_chart","id":"bar_chart-2"},{"x":696.8101845010212,"y":763.116055476482,"width":395.2178934002416,"height":159.17461495743558,"type":"bar_chart","id":"bar_chart-7"},{"x":937.833986520407,"y":615.5420638485678,"width":499.75555240423165,"height":307.1912240921553,"type":"bar_chart","id":"bar_chart-9"},{"x":18.225125781384765,"y":230.6557658516983,"width":850.7373008349199,"height":301.6454486303164,"type":"graph","id":"graph-3"},{"x":14.493921863808776,"y":575.2218860125845,"width":873.568754863332,"height":320.0232073430906,"type":"graph","id":"graph-4"},{"x":17.354977181651478,"y":574.562014822306,"width":866.5658903782106,"height":323.90175623009986,"type":"heatmap","id":"heatmap-8"},{"x":16.95199841408975,"y":228.1353006789708,"width":852.0028017200721,"height":305.4069757225447,"type":"matrix","id":"matrix-5"},{"x":16.08346900723966,"y":575.8199595412565,"width":867.8281528775948,"height":321.38586679219964,"type":"matrix","id":"matrix-6"}],"relations":[{"vislist":[{"vislist":["bar_chart-0"],"relation":null,"id":"group-0"}],"relation":"repeated","id":"relation-0"},{"vislist":[{"vislist":["bar_chart-9"],"relation":null,"id":"group-1"}],"relation":"repeated","id":"relation-1"},{"vislist":[{"vislist":["bar_chart-7"],"relation":null,"id":"group-2"}],"relation":"repeated","id":"relation-2"},{"vislist":[{"vislist":["graph-4"],"relation":null,"id":"group-3"},{"vislist":["matrix-6"],"relation":null,"id":"group-4"}],"relation":"coordinated","id":"relation-3"},{"vislist":[{"vislist":["bar_chart-1","bar_chart-2",{"vislist":[{"vislist":["graph-3"],"relation":null,"id":"group-5"},{"vislist":["matrix-5"],"relation":null,"id":"group-6"}],"relation":"coordinated","id":"relation-4"}],"relation":null,"id":"group-7"}],"relation":"stacked","id":"relation-5"}]},"3296_10":{"comp":[["bar_chart","bar_chart",["repeated"]],["proportional_area_chart","unit_visualization",["nested"]]],"visType":["bar_chart","proportional_area_chart","unit_visualization"],"compType":["repeated","nested"],"compressed_tree":[{"composite_pattern":"repeated","visualization_type":[["bar_chart"]]},{"composite_pattern":"nested","visualization_type":[["proportional_area_chart"],["unit_visualization"]]}],"coOccurrence":[["bar_chart","proportional_area_chart",["coOccurrence"]],["bar_chart","unit_visualization",["coOccurrence"]],["proportional_area_chart","unit_visualization",["coOccurrence"]]],"year":2020,"conference":["VAST"],"authors":["Zhibin Niu","Runlin Li","Junqi Wu","Dawei Cheng","Jiawan Zhang"],"title":"iConViz: Interactive Visual Exploration of the Default Contagion Risk of Networked-Guarantee Loans","doi":"10.1109/VAST50239.2020.00013","abstract":"Groups of enterprises can serve as guarantees for one another and form complex networks when obtaining loans from commercial banks. During economic slowdowns, corporate default may spread like a virus and lead to large-scale defaults or even systemic financial crises. To help financial regulatory authorities and banks manage the risk associated with networked loans, we identified the default contagion risk, a pivotal issue in developing preventive measures, and established iConViz, an interactive visual analysis tool that facilitates the closed-loop analysis process. A novel financial metric, the contagion effect, was formulated to quantify the infectious consequences of guarantee chains in this type of network. Based on this metric, we designed and implemented a series of novel and coordinated views that address the analysis of financial problems. Experts evaluated the system using real-world financial data. The proposed approach grants practitioners the ability to avoid previous ad hoc analysis methodologies and extend coverage of the conventional Capital Accord to the banking industry.","keywords":" Visualization analytics, Regulatory visualization","caption":"Figure 11: Node Instance Explorer is composed of the (a) node projection view; (b) \ufb01nancial distribution view; (c) overall picture view, consisting of bubbles alongside exposures to give an overview; (d) detailed view by business size and type, which is similar to the overall picture view but omitted due to space limitations. ","img_size":{"width":984,"height":750},"subfigures":[{"x":8.600433730071567,"y":11.688237361841479,"width":963.7238805480603,"height":729.6968106485771,"type":"interface","id":"interface-0"}],"visualizations":[{"x":57.37457942159517,"y":351.59223916207947,"width":871.3010091513404,"height":168.7225081088048,"type":"bar_chart","id":"bar_chart-1"},{"x":25.90659005464321,"y":602.5707580389219,"width":937.3122398770407,"height":140.051417683097,"type":"proportional_area_chart","id":"proportional_area_chart-3"},{"x":8.56895951913362,"y":10.5382369332824,"width":957.636324986344,"height":260.7597210925574,"type":"scatterplot","id":"scatterplot-0"},{"x":25.916597762263947,"y":600.508395090639,"width":939.3423924563282,"height":140.0784297499823,"type":"unit_visualization","id":"unit_visualization-2"}],"relations":[{"vislist":[{"vislist":["bar_chart-1"],"relation":null,"id":"group-0"}],"relation":"repeated","id":"relation-0"},{"vislist":[{"vislist":["proportional_area_chart-3"],"relation":null,"id":"group-1"},{"vislist":["unit_visualization-2"],"relation":null,"id":"group-2"}],"relation":"nested","id":"relation-1"}]},"3297_6":{"comp":[["donut_chart","donut_chart",["repeated"]],["bar_chart","bar_chart",["repeated"]]],"visType":["donut_chart","bar_chart"],"compType":["repeated"],"compressed_tree":[{"composite_pattern":"repeated","visualization_type":[["donut_chart"]]},{"composite_pattern":"repeated","visualization_type":[["bar_chart"]]}],"coOccurrence":[["donut_chart","bar_chart",["coOccurrence"]]],"year":2020,"conference":["VAST"],"authors":["Zengsheng Zhong","Shuirun Wei","Yeting Xu","Ying Zhao","Fangfang Zhou","Feng Luo","Ronghua Shi"],"title":"SilkViser: A Visual Explorer of Blockchain-based Cryptocurrency Transaction Data","doi":"10.1109/VAST50239.2020.00014","abstract":"Many blockchain-based cryptocurrencies provide users with online blockchain explorers for viewing online transaction data. However, traditional blockchain explorers mostly present transaction information in textual and tabular forms. Such forms make understanding cryptocurrency transaction mechanisms difficult for novice users (NUsers). They are also insufficiently informative for experienced users (EUsers) to recognize advanced transaction information. This study introduces a new online cryptocurrency transaction data viewing tool called SilkViser. Guided by detailed scenario and requirement analyses, we create a series of appreciating visualization designs, such as paper ledger-inspired block and blockchain visualizations and ancient copper coin-inspired transaction visualizations, to help users understand cryptocurrency transaction mechanisms and recognize advanced transaction information. We also provide a set of lightweight interactions to facilitate easy and free data exploration. Moreover, a controlled user study is conducted to quantitatively evaluate the usability and effectiveness of SilkViser. Results indicate that SilkViser can satisfy the requirements of NUsers and EUsers. Our visualization designs can compensate for the inexperience of NUsers in data viewing and attract potential users to participate in cryptocurrency transactions.","keywords":" visualization, visual analytics, blockchain, cryptocur-rency, interactive interface","caption":"Figure 4: Visualization design of the block page.","img_size":{"width":968,"height":770},"subfigures":[{"x":7.9725993334369285,"y":7.8367678899794955,"width":953.1062943091532,"height":756.4299573192759,"type":"interface","id":"interface-0"}],"visualizations":[{"x":27.77332269701896,"y":383.76853574373206,"width":916.6593265100706,"height":99.22361107736559,"type":"bar_chart","id":"bar_chart-0"},{"x":119.5832506314623,"y":303.89236100806,"width":771.9447107541732,"height":71.76507471675545,"type":"donut_chart","id":"donut_chart-1"}],"relations":[{"vislist":[{"vislist":["donut_chart-1"],"relation":null,"id":"group-0"}],"relation":"repeated","id":"relation-0"},{"vislist":[{"vislist":["bar_chart-0"],"relation":null,"id":"group-1"}],"relation":"repeated","id":"relation-1"}]},"3298_3":{"comp":[["scatterplot","scatterplot",["repeated"]]],"visType":["scatterplot"],"compType":["repeated"],"compressed_tree":[{"composite_pattern":"repeated","visualization_type":[["scatterplot"]]}],"coOccurrence":[["scatterplot","scatterplot",["coOccurrence"]]],"year":2020,"conference":["VAST"],"authors":["Jun Yuan","Shouxing Xiang","Jiazhi Xia","Lingyun Yu","Shixia Liu"],"title":"Evaluation of Sampling Methods for Scatterplots","doi":"10.1109/TVCG.2020.3030432","abstract":"Given a scatterplot with tens of thousands of points or even more, a natural question is which sampling method should be used to create a small but \u201cgood\u201d scatterplot for a better abstraction. We present the results of a user study that investigates the influence of different sampling strategies on multi-class scatterplots. The main goal of this study is to understand the capability of sampling methods in preserving the density, outliers, and overall shape of a scatterplot. To this end, we comprehensively review the literature and select seven typical sampling strategies as well as eight representative datasets. We then design four experiments to understand the performance of different strategies in maintaining: 1) region density; 2) class density; 3) outliers; and 4) overall shape in the sampling results. The results show that: 1) random sampling is preferred for preserving region density; 2) blue noise sampling and random sampling have comparable performance with the three multi-class sampling strategies in preserving class density; 3) outlier biased density based sampling, recursive subdivision based sampling, and blue noise sampling perform the best in keeping outliers; and 4) blue noise sampling outperforms the others in maintaining the overall shape of a scatterplot.","keywords":"Scatterplot, data sampling, empirical evaluation.","caption":"Fig. 3: Interface of Experiment 1 in the pre-study: the original scatter- plot is located at the top-left, with the sampling results of increasing sampling number at the following positions. ","img_size":{"width":984,"height":558},"subfigures":[{"x":7.739675322607488,"y":5.645680296342899,"width":968.5206493547853,"height":542.1355907733918,"type":"interface","id":"interface-0"}],"visualizations":[{"x":8.908962471067811,"y":38.634418268939704,"width":824.7064060364356,"height":467.71312110420877,"type":"scatterplot","id":"scatterplot-0"}],"relations":[{"vislist":[{"vislist":["scatterplot-0"],"relation":null,"id":"group-0"}],"relation":"repeated","id":"relation-0"}]},"3299_0":{"comp":[["bar_chart","bar_chart",["repeated"]],["bar_chart","table",["nested"]],["pie_chart","graph",["nested"]]],"visType":["bar_chart","table","pie_chart","graph"],"compType":["repeated","nested"],"compressed_tree":[{"composite_pattern":"repeated","visualization_type":[["bar_chart"]]},{"composite_pattern":"nested","visualization_type":[["bar_chart"],["table"]]},{"composite_pattern":"nested","visualization_type":[["pie_chart"],["graph"]]}],"coOccurrence":[["bar_chart","table",["coOccurrence"]],["bar_chart","pie_chart",["coOccurrence"]],["bar_chart","graph",["coOccurrence"]],["table","pie_chart",["coOccurrence"]],["table","graph",["coOccurrence"]],["pie_chart","graph",["coOccurrence"]]],"year":2020,"conference":["VAST"],"authors":["Xiao Xie","Fan Du","Yingcai Wu"],"title":"A Visual Analytics Approach for Exploratory Causal Analysis: Exploration, Validation, and Applications","doi":"10.1109/TVCG.2020.3028957","abstract":"Using causal relations to guide decision making has become an essential analytical task across various domains, from marketing and medicine to education and social science. While powerful statistical models have been developed for inferring causal relations from data, domain practitioners still lack effective visual interface for interpreting the causal relations and applying them in their decision-making process. Through interview studies with domain experts, we characterize their current decision-making workflows, challenges, and needs. Through an iterative design process, we developed a visualization tool that allows analysts to explore, validate, and apply causal relations in real-world decision-making scenarios. The tool provides an uncertainty-aware causal graph visualization for presenting a large set of causal relations inferred from high-dimensional data. On top of the causal graph, it supports a set of intuitive user controls for performing what-if analyses and making action plans. We report on two case studies in marketing and student advising to demonstrate that users can effectively explore causal relations and design action plans for reaching their goals.","keywords":"Exploratory causal analysis, correlation and causation, causal graph","caption":"Fig. 1. The user interface of Causality Explorer demonstrated with a real-world audiology dataset that consists of 200 rows and 24 dimensions [18]. (a) A scalable causal graph layout that can handle high-dimensional data. (b) Histograms of all dimensions for comparative analyses of the distributions. (c) Clicking on a histogram will display the detailed data in the table view. (b) and (c) are coordinated to support what-if analyses. In the causal graph, each node is represented by a pie chart (d) and the causal direction (e) is from the upper node (cause) to the lower node (result). The thickness of a link encodes the uncertainty (f). Nodes without descendants are placed on the left side of each layer to improve readability (g). Users can double-click on a node to show its causality subgraph (h). ","img_size":{"width":1814,"height":1139},"subfigures":[{"x":13.840340287376126,"y":8.474869251027703,"width":1795.6555092625767,"height":1117.3829654459378,"type":"interface","id":"interface-0"}],"visualizations":[{"x":20.866240198014538,"y":121.48002217257797,"width":533.8208861673209,"height":513.6397492759593,"type":"bar_chart","id":"bar_chart-0"},{"x":20.88909443572267,"y":716.4279692735754,"width":540.1754186915758,"height":398.9444353526678,"type":"bar_chart","id":"bar_chart-2"},{"x":608.8464903567802,"y":129.1674906347037,"width":1186.729251506237,"height":952.6650575885419,"type":"graph","id":"graph-3"},{"x":607.4360657378472,"y":129.1674906347036,"width":1186.3499802442673,"height":952.6650575885404,"type":"pie_chart","id":"pie_chart-4"},{"x":22.465966608136274,"y":714.7148166849876,"width":535.4216140968331,"height":399.17073880282356,"type":"table","id":"table-1"}],"relations":[{"vislist":[{"vislist":["bar_chart-0"],"relation":null,"id":"group-0"}],"relation":"repeated","id":"relation-0"},{"vislist":[{"vislist":["bar_chart-2"],"relation":null,"id":"group-1"},{"vislist":["table-1"],"relation":null,"id":"group-2"}],"relation":"nested","id":"relation-1"},{"vislist":[{"vislist":["pie_chart-4"],"relation":null,"id":"group-3"},{"vislist":["graph-3"],"relation":null,"id":"group-4"}],"relation":"nested","id":"relation-2"}]},"3303_2":{"comp":[["line_chart","line_chart",["repeated"]]],"visType":["line_chart"],"compType":["repeated"],"compressed_tree":[{"composite_pattern":"repeated","visualization_type":[["line_chart"]]}],"coOccurrence":[["line_chart","line_chart",["coOccurrence"]]],"year":2020,"conference":["VAST"],"authors":["Xiaoyi Wang","Alexander Eiselmayer","Wendy E. Mackay","Kasper Hornbaek","Chat Wacharamanotham"],"title":"Argus: Interactive a priori Power Analysis","doi":"10.1109/TVCG.2020.3028894","abstract":"A key challenge HCl researchers face when designing a controlled experiment is choosing the appropriate number of participants, or sample size. A priori power analysis examines the relationships among multiple parameters, including the complexity associated with human participants, e.g., order and fatigue effects, to calculate the statistical power of a given experiment design. We created Argus, a tool that supports interactive exploration of statistical power: Researchers specify experiment design scenarios with varying confounds and effect sizes. Argus then simulates data and visualizes statistical power across these scenarios, which lets researchers interactively weigh various trade-offs and make informed decisions about sample size. We describe the design and implementation of Argus, a usage scenario designing a visualization experiment, and a think-aloud study.","keywords":"Experiment design, power analysis, simulation","caption":"Fig. 3: Argus interface: (Left:) Users estimate effect size by specifying: (A) the expected average for each condition; (B) the relevant confounding effects, and (C\u2013E) the experimental design elements. (Right:) The simulation output includes: (F) pairwise differences, with expected results shown as differences between means; (G) the relationship between power and sample size for making trade-off decisions; and (H) the history view with automatically saved parameter changes. Hovering the mouse over a historical point reveals its settings and results (in orange). ","img_size":{"width":1875,"height":1001},"subfigures":[{"x":66.94644988030504,"y":16.988829790574233,"width":1798.5688132277467,"height":977.9605045348756,"type":"interface","id":"interface-0"}],"visualizations":[{"x":74.76444660168987,"y":49.55620248960284,"width":686.8432433574654,"height":349.8622163358627,"type":"bar_chart","id":"bar_chart-0"},{"x":1145.697621931005,"y":89.25481207895376,"width":561.0395766675094,"height":212.33377236518106,"type":"error_bar","id":"error_bar-2"},{"x":896.1572146591211,"y":313.32476715741956,"width":939.3881714165992,"height":675.1547139506007,"type":"line_chart","id":"line_chart-1"}],"relations":[{"vislist":[{"vislist":["line_chart-1"],"relation":null,"id":"group-0"}],"relation":"repeated","id":"relation-0"}]},"3305_0":{"comp":[["comb","comb",["repeated"]],["scatterplot","scatterplot",["repeated"]],["scatterplot","map",["coordinated"]],["area_chart","stripe_graph",["stacked"]],["stripe_graph","area_chart",["stacked"]]],"visType":["comb","scatterplot","map","area_chart","stripe_graph"],"compType":["repeated","coordinated","stacked"],"compressed_tree":[{"composite_pattern":"repeated","visualization_type":[[{"composite_pattern":"stacked","visualization_type":[["area_chart","stripe_graph"]]}]]},{"composite_pattern":"repeated","visualization_type":[["scatterplot"]]},{"composite_pattern":"coordinated","visualization_type":[["scatterplot"],["map"]]},{"composite_pattern":"repeated","visualization_type":[[{"composite_pattern":"stacked","visualization_type":[["stripe_graph","area_chart"]]}]]}],"coOccurrence":[["area_chart","stripe_graph",["coOccurrence"]],["area_chart","scatterplot",["coOccurrence"]],["area_chart","map",["coOccurrence"]],["stripe_graph","scatterplot",["coOccurrence"]],["stripe_graph","map",["coOccurrence"]],["scatterplot","map",["coOccurrence"]]],"year":2020,"conference":["VAST"],"authors":["Antonios Somarakis","Marieke E. Ijsselsteijn","Sietse J. Luk","Boyd Kenkhuis","Noel F.C.C. de Miranda","Boudewijn P.F. Lelieveldt","Thomas H\xf6llt"],"title":"Visual cohort comparison for spatial single-cell omics-data","doi":"10.1109/TVCG.2020.3030336","abstract":"Spatially-resolved omics-data enable researchers to precisely distinguish cell types in tissue and explore their spatial interactions, enabling deep understanding of tissue functionality. To understand what causes or deteriorates a disease and identify related biomarkers, clinical researchers regularly perform large-scale cohort studies, requiring the comparison of such data at cellular level. In such studies, with little a-priori knowledge of what to expect in the data, explorative data analysis is a necessity. Here, we present an interactive visual analysis workflow for the comparison of cohorts of spatially-resolved omics-data. Our workflow allows the comparative analysis of two cohorts based on multiple levels-of-detail, from simple abundance of contained cell types over complex co-localization patterns to individual comparison of complete tissue images. As a result, the workflow enables the identification of cohort-differentiating features, as well as outlier samples at any stage of the workflow. During the development of the workflow, we continuously consulted with domain experts. To show the effectiveness of the workflow, we conducted multiple case studies with domain experts from different application areas and with different data modalities.","keywords":"Visual analytics, Imaging Mass Cytometry, Vectra, spatially-resolved data, single-cell omics-data, Visual comparison","caption":"Fig. 1. Screenshot of our integrated system including the view for the comparison based on the cell abundance using raincloud plots (a), the tissue view, showing selected samples of the two cohorts (b), and the multi-cellular microenvironment comparison view using a difference heatmap and raincloud plots (c). ","img_size":{"width":1624,"height":873},"subfigures":[{"x":8.169139678803628,"y":8.845834116121607,"width":1602.8909386879939,"height":850.5385928700086,"type":"interface","id":"interface-0"}],"visualizations":[{"x":1285.8138708722302,"y":187.17273344649973,"width":315.80946887007536,"height":637.6960617883831,"type":"area_chart","id":"area_chart-0"},{"x":5.306020526999748,"y":19.20941436435338,"width":328.46372094006415,"height":800.1791435563119,"type":"area_chart","id":"area_chart-7"},{"x":943.7426136789359,"y":172.84833777588332,"width":339.58400809419055,"height":484.30078980450634,"type":"heatmap","id":"heatmap-3"},{"x":350.55892331665825,"y":112.15272673414121,"width":594.8468685245871,"height":261.67173473818394,"type":"map","id":"map-4"},{"x":946.5818599121881,"y":174.25550880558777,"width":335.3379841204444,"height":481.48644774509796,"type":"matrix","id":"matrix-2"},{"x":410.02367913485955,"y":444.99625026594936,"width":493.10697880130857,"height":397.2652498693294,"type":"scatterplot","id":"scatterplot-5"},{"x":351.9866336751478,"y":112.18956333520381,"width":594.8563847931284,"height":255.86439025022838,"type":"scatterplot","id":"scatterplot-6"},{"x":1285.8250992123287,"y":185.70950293961943,"width":317.21948068263674,"height":634.8888515163112,"type":"stripe_graph","id":"stripe_graph-1"},{"x":8.153720207626915,"y":24.87829446091298,"width":327.06572705709056,"height":791.7082190061085,"type":"stripe_graph","id":"stripe_graph-8"}],"relations":[{"vislist":[{"vislist":[{"vislist":[{"vislist":["area_chart-7","stripe_graph-8"],"relation":null,"id":"group-0"}],"relation":"stacked","id":"relation-0"}],"relation":null,"id":"group-1"}],"relation":"repeated","id":"relation-1"},{"vislist":[{"vislist":["scatterplot-5"],"relation":null,"id":"group-2"}],"relation":"repeated","id":"relation-2"},{"vislist":[{"vislist":["scatterplot-6"],"relation":null,"id":"group-3"},{"vislist":["map-4"],"relation":null,"id":"group-4"}],"relation":"coordinated","id":"relation-3"},{"vislist":[{"vislist":[{"vislist":[{"vislist":["stripe_graph-1","area_chart-0"],"relation":null,"id":"group-5"}],"relation":"stacked","id":"relation-4"}],"relation":null,"id":"group-6"}],"relation":"repeated","id":"relation-5"}]},"3307_0":{"comp":[["donut_chart","donut_chart",["repeated"]],["donut_chart","pie_chart",["accompanied"]],["line_chart","comb",["accompanied"]],["comb","line_chart",["accompanied"]],["comb","proportional_area_chart",["nested"]],["comb","scatterplot",["coordinated"]],["pie_chart","donut_chart",["accompanied"]],["bar_chart","bar_chart",["mirrored"]]],"visType":["donut_chart","pie_chart","line_chart","comb","proportional_area_chart","scatterplot","bar_chart"],"compType":["repeated","accompanied","nested","coordinated","mirrored"],"compressed_tree":[{"composite_pattern":"accompanied","visualization_type":[["line_chart",{"composite_pattern":"mirrored","visualization_type":[["bar_chart"]]}]]},{"composite_pattern":"repeated","visualization_type":[["donut_chart"]]},{"composite_pattern":"repeated","visualization_type":[["donut_chart"]]},{"composite_pattern":"coordinated","visualization_type":[[{"composite_pattern":"nested","visualization_type":[[{"composite_pattern":"accompanied","visualization_type":[["donut_chart","pie_chart"]]}],["proportional_area_chart"]]}],["scatterplot"]]}],"coOccurrence":[["bar_chart","line_chart",["coOccurrence"]],["bar_chart","donut_chart",["coOccurrence"]],["bar_chart","pie_chart",["coOccurrence"]],["bar_chart","proportional_area_chart",["coOccurrence"]],["bar_chart","scatterplot",["coOccurrence"]],["line_chart","donut_chart",["coOccurrence"]],["line_chart","pie_chart",["coOccurrence"]],["line_chart","proportional_area_chart",["coOccurrence"]],["line_chart","scatterplot",["coOccurrence"]],["donut_chart","pie_chart",["coOccurrence"]],["donut_chart","proportional_area_chart",["coOccurrence"]],["donut_chart","scatterplot",["coOccurrence"]],["pie_chart","proportional_area_chart",["coOccurrence"]],["pie_chart","scatterplot",["coOccurrence"]],["proportional_area_chart","scatterplot",["coOccurrence"]]],"year":2020,"conference":["VAST"],"authors":["Jiang Wu","Ziyang Guo","Zuobin Wang","Qingyang Xu","Yingcai Wu"],"title":"Visual Analytics of Multivariate Event Sequence Data in Racquet Sports","doi":"10.1109/VAST50239.2020.00009","abstract":"In this work, we propose a generic visual analytics framework to support tactic analysis based on data collected from racquet sports (such as tennis and badminton). The proposed approach models each rally in a game as a sequence of hits (i.e., events) until one athlete scores a point. Each hit can be described with a set of attributes, such as the positions of the ball and the techniques used to hit the ball (such as drive and volley in tennis). Thus, the mentioned sequence of hits can be viewed as a multivariate event sequence. By detecting and analyzing the multivariate subsequences that frequently occur in the rallies (namely, tactical patterns), athletes can gain insights into the playing styles adopted by their opponents, and therefore help them identify systematic weaknesses of the opponents and develop counter strategies in matches. To support such analysis effectively, we propose a steerable multivariate sequential pattern mining algorithm with adjustable weights over event attributes, such that the domain expert can obtain frequent tactical patterns according to the attributes specified by himself. We also propose a re-configurable glyph design to help users simultaneously analyze multiple attributes of the hits. The framework further supports comparative analysis of the tactical patterns, e.g., for different athletes or the same athlete playing under different conditions. By applying the framework on two datasets collected in tennis and badminton matches, we demonstrate that the system is generic and effective for tactic analysis in sports and can help identify signature techniques used by individual athletes. Finally, we discuss the strengths and limitations of the proposed approach based on the feedback from the domain experts.","keywords":": Sports Analytics; Event Sequence; MultivariateData; Sequential Pattern Mining; Comparative Analysis","caption":"Figure 1: System Interface. (A) Attribute Editor is used to adjust the focus of the analysis and import domain knowledge. (B) Glyph Editor can \ufb01ne-tune the glyph design, where a glyph is used to encode an event to show multiple attributes simultaneously. (C) Pattern Comparator provides a one-to-one comparison on patterns. (D) Scatterplot provides a coarse-level overview and \ufb01lters patterns. (E) Instance View shows the detailed information of sequences. ","img_size":{"width":1837,"height":1034},"subfigures":[{"x":20.764209969368107,"y":9.081551592036405,"width":1803.9425845705846,"height":1010.1875153494086,"type":"interface","id":"interface-0"}],"visualizations":[{"x":47.14922191844999,"y":175.1917382123875,"width":318.1775115603408,"height":119.99549583310954,"type":"bar_chart","id":"bar_chart-0"},{"x":844.1569702190781,"y":99.62163323152753,"width":161.6488409470653,"height":902.7799610230596,"type":"bar_chart","id":"bar_chart-2"},{"x":398.0278035612922,"y":142.91549059290554,"width":334.4728073826811,"height":835.627454153483,"type":"donut_chart","id":"donut_chart-1"},{"x":1473.934656088216,"y":63.347646347165565,"width":350.6842890076287,"height":340.4444782546906,"type":"donut_chart","id":"donut_chart-11"},{"x":1007.9750970415114,"y":99.65198085814498,"width":457.84644146612743,"height":896.240863152101,"type":"donut_chart","id":"donut_chart-6"},{"x":846.0341813621083,"y":99.64167316443297,"width":165.99615702677323,"height":899.5006798483888,"type":"line_chart","id":"line_chart-4"},{"x":1472.3581203805002,"y":66.7086871890591,"width":357.0780557693627,"height":328.86359460760883,"type":"pie_chart","id":"pie_chart-12"},{"x":1469.1668208936992,"y":66.61811697883664,"width":365.08100241611515,"height":332.2839363369178,"type":"proportional_area_chart","id":"proportional_area_chart-13"},{"x":1470.6927654116948,"y":66.4910049314047,"width":352.3070273412087,"height":337.39696239507504,"type":"scatterplot","id":"scatterplot-10"},{"x":1472.2819118067623,"y":413.4904181637608,"width":347.50838687792213,"height":590.8645187727111,"type":"unit_visualization","id":"unit_visualization-9"}],"relations":[{"vislist":[{"vislist":["line_chart-4",{"vislist":[{"vislist":["bar_chart-2"],"relation":null,"id":"group-0"}],"relation":"mirrored","id":"relation-0"}],"relation":null,"id":"group-1"}],"relation":"accompanied","id":"relation-1"},{"vislist":[{"vislist":["donut_chart-1"],"relation":null,"id":"group-2"}],"relation":"repeated","id":"relation-2"},{"vislist":[{"vislist":["donut_chart-6"],"relation":null,"id":"group-3"}],"relation":"repeated","id":"relation-3"},{"vislist":[{"vislist":[{"vislist":[{"vislist":[{"vislist":[{"vislist":["donut_chart-11","pie_chart-12"],"relation":null,"id":"group-4"}],"relation":"accompanied","id":"relation-4"}],"relation":null,"id":"group-5"},{"vislist":["proportional_area_chart-13"],"relation":null,"id":"group-6"}],"relation":"nested","id":"relation-5"}],"relation":null,"id":"group-7"},{"vislist":["scatterplot-10"],"relation":null,"id":"group-8"}],"relation":"coordinated","id":"relation-6"}]},"3307_7":{"comp":[["pie_chart","pie_chart",["repeated"]],["donut_chart","proportional_area_chart",["nested"]],["comb","scatterplot",["coordinated"]],["comb","comb",["stacked"]],["bar_chart","bar_chart",["mirrored"]]],"visType":["pie_chart","donut_chart","proportional_area_chart","comb","scatterplot","bar_chart"],"compType":["repeated","nested","coordinated","stacked","mirrored"],"compressed_tree":[{"composite_pattern":"stacked","visualization_type":[[{"composite_pattern":"mirrored","visualization_type":[["bar_chart"]]},{"composite_pattern":"repeated","visualization_type":[["pie_chart"]]}]]},{"composite_pattern":"coordinated","visualization_type":[[{"composite_pattern":"nested","visualization_type":[["donut_chart"],["proportional_area_chart"]]}],["scatterplot"]]}],"coOccurrence":[["pie_chart","bar_chart",["coOccurrence"]],["pie_chart","donut_chart",["coOccurrence"]],["pie_chart","proportional_area_chart",["coOccurrence"]],["pie_chart","scatterplot",["coOccurrence"]],["bar_chart","donut_chart",["coOccurrence"]],["bar_chart","proportional_area_chart",["coOccurrence"]],["bar_chart","scatterplot",["coOccurrence"]],["donut_chart","proportional_area_chart",["coOccurrence"]],["donut_chart","scatterplot",["coOccurrence"]],["proportional_area_chart","scatterplot",["coOccurrence"]]],"year":2020,"conference":["VAST"],"authors":["Jiang Wu","Ziyang Guo","Zuobin Wang","Qingyang Xu","Yingcai Wu"],"title":"Visual Analytics of Multivariate Event Sequence Data in Racquet Sports","doi":"10.1109/VAST50239.2020.00009","abstract":"In this work, we propose a generic visual analytics framework to support tactic analysis based on data collected from racquet sports (such as tennis and badminton). The proposed approach models each rally in a game as a sequence of hits (i.e., events) until one athlete scores a point. Each hit can be described with a set of attributes, such as the positions of the ball and the techniques used to hit the ball (such as drive and volley in tennis). Thus, the mentioned sequence of hits can be viewed as a multivariate event sequence. By detecting and analyzing the multivariate subsequences that frequently occur in the rallies (namely, tactical patterns), athletes can gain insights into the playing styles adopted by their opponents, and therefore help them identify systematic weaknesses of the opponents and develop counter strategies in matches. To support such analysis effectively, we propose a steerable multivariate sequential pattern mining algorithm with adjustable weights over event attributes, such that the domain expert can obtain frequent tactical patterns according to the attributes specified by himself. We also propose a re-configurable glyph design to help users simultaneously analyze multiple attributes of the hits. The framework further supports comparative analysis of the tactical patterns, e.g., for different athletes or the same athlete playing under different conditions. By applying the framework on two datasets collected in tennis and badminton matches, we demonstrate that the system is generic and effective for tactic analysis in sports and can help identify signature techniques used by individual athletes. Finally, we discuss the strengths and limitations of the proposed approach based on the feedback from the domain experts.","keywords":": Sports Analytics; Event Sequence; MultivariateData; Sequential Pattern Mining; Comparative Analysis","caption":"Figure 8: Screenshot for the usage scenario in tennis. Blue and orange encode rallies before and after deuces, respectively. (A) is the original scat- terplot. (B) and (C) showcases the result when \ufb01ltering the patterns in the area with dense points and the unusual patterns after deuces, respectively. ","img_size":{"width":1818,"height":786},"subfigures":[{"x":401.09372216520745,"y":13.134482473250365,"width":1405.3493907057257,"height":365.7963828604502,"type":"single","id":"single-0"}],"visualizations":[{"x":1237.6612324795428,"y":12.592654212716747,"width":122.02154479542617,"height":358.5392252621213,"type":"bar_chart","id":"bar_chart-0"},{"x":413.3290129089097,"y":17.26195973779217,"width":378.77116816114324,"height":345.99523201027733,"type":"donut_chart","id":"donut_chart-4"},{"x":1362.7428502876494,"y":14.15808179009842,"width":433.1142832822582,"height":355.40837010735726,"type":"pie_chart","id":"pie_chart-1"},{"x":810.8368285665388,"y":14.295856887313043,"width":425.63949800044975,"height":351.9274377112364,"type":"pie_chart","id":"pie_chart-2"},{"x":414.9436370704883,"y":12.526484331158066,"width":381.95627382773597,"height":350.65810952100696,"type":"proportional_area_chart","id":"proportional_area_chart-5"},{"x":419.86867747682936,"y":18.840396682469127,"width":373.70978151249057,"height":344.44104922177036,"type":"scatterplot","id":"scatterplot-3"}],"relations":[{"vislist":[{"vislist":[{"vislist":[{"vislist":["bar_chart-0"],"relation":null,"id":"group-2"}],"relation":"mirrored","id":"relation-2"},{"vislist":[{"vislist":["pie_chart-2"],"relation":null,"id":"group-1"}],"relation":"repeated","id":"relation-1"},{"vislist":[{"vislist":["pie_chart-1"],"relation":null,"id":"group-0"}],"relation":"repeated","id":"relation-0"}],"relation":null,"id":"group-3"}],"relation":"stacked","id":"relation-3"},{"vislist":[{"vislist":[{"vislist":[{"vislist":["donut_chart-4"],"relation":null,"id":"group-4"},{"vislist":["proportional_area_chart-5"],"relation":null,"id":"group-5"}],"relation":"nested","id":"relation-4"}],"relation":null,"id":"group-6"},{"vislist":["scatterplot-3"],"relation":null,"id":"group-7"}],"relation":"coordinated","id":"relation-5"}]},"3308_0":{"comp":[["bar_chart","bar_chart",["repeated"]],["bar_chart","table",["nested"]],["parallel_coordinate","comb",["accompanied"]],["comb","parallel_coordinate",["accompanied"]]],"visType":["bar_chart","table","parallel_coordinate","comb"],"compType":["repeated","nested","accompanied"],"compressed_tree":[{"composite_pattern":"accompanied","visualization_type":[["parallel_coordinate",{"composite_pattern":"repeated","visualization_type":[["bar_chart"]]}]]},{"composite_pattern":"nested","visualization_type":[["bar_chart"],["table"]]}],"coOccurrence":[["bar_chart","parallel_coordinate",["coOccurrence"]],["bar_chart","table",["coOccurrence"]],["parallel_coordinate","table",["coOccurrence"]]],"year":2020,"conference":["VAST"],"authors":["Qianwen Wang","William Alexander","Jack Pegg","Huamin Qu","Min Chen"],"title":"HypoML: Visual Analysis for Hypothesis-based Evaluation of Machine Learning Models","doi":"10.1109/TVCG.2020.3030449","abstract":"In this paper, we present a visual analytics tool for enabling hypothesis-based evaluation of machine learning (ML) models. We describe a novel ML-testing framework that combines the traditional statistical hypothesis testing (commonly used in empirical research) with logical reasoning about the conclusions of multiple hypotheses. The framework defines a controlled configuration for testing a number of hypotheses as to whether and how some extra information about a \u201cconcept\u201d or \u201cfeature\u201d may benefit or hinder an ML model. Because reasoning multiple hypotheses is not always straightforward, we provide HypoML as a visual analysis tool, with which, the multi-thread testing results are first transformed to analytical results using statistical and logical inferences, and then to a visual representation for rapid observation of the conclusions and the logical flow between the testing results and hypotheses. We have applied HypoML to a number of hypothesized concepts, demonstrating the intuitive and explainable nature of the visual analysis.","keywords":"Tabular Data, Explainable Machine Learning, Counterfactual Explanation, Decision Making","caption":"Fig. 1. The DECE interface for exploring a machine learning model\u2019s decisions with counterfactual explanations. The user uses the table view (A) for subgroup level analysis. The table header (A1) supports the exploration of the table with sorting and \ufb01ltering operations. The subgroup list (A2) presents the subgroups in rows and summarizes their counterfactual examples. The user can interactively create, update, and delete a list of subgroups. The instance lens (A3) visualizes each instance in the focused subgroup as a single thin horizontal line. In the instance view (B), the user can customize (B1) and inspect the diverse counterfactual examples of a single instance in an enhanced parallel coordinate view (B2). ","img_size":{"width":1561,"height":904},"subfigures":[{"x":49.76508936870541,"y":31.26068195297175,"width":1473.8175854418146,"height":857.5307470695195,"type":"interface","id":"interface-0"}],"visualizations":[{"x":1204.22788422363,"y":278.54322218572,"width":316.02354376513864,"height":608.6384451295523,"type":"bar_chart","id":"bar_chart-0"},{"x":54.73104384935529,"y":137.35500764519395,"width":1070.1370016707176,"height":747.7549346942707,"type":"bar_chart","id":"bar_chart-5"},{"x":1201.4948850495136,"y":277.1742493925611,"width":320.1126435190367,"height":609.9988912974436,"type":"parallel_coordinate","id":"parallel_coordinate-1"},{"x":50.526792600451195,"y":96.4506658822675,"width":1107.460374649543,"height":793.7486333410408,"type":"table","id":"table-4"}],"relations":[{"vislist":[{"vislist":["parallel_coordinate-1",{"vislist":[{"vislist":["bar_chart-0"],"relation":null,"id":"group-0"}],"relation":"repeated","id":"relation-0"}],"relation":null,"id":"group-1"}],"relation":"accompanied","id":"relation-1"},{"vislist":[{"vislist":["bar_chart-5"],"relation":null,"id":"group-2"},{"vislist":["table-4"],"relation":null,"id":"group-3"}],"relation":"nested","id":"relation-2"}]},"3308_5":{"comp":[["bar_chart","bar_chart",["repeated"]],["bar_chart","table",["nested"]],["parallel_coordinate","comb",["accompanied"]],["comb","parallel_coordinate",["accompanied"]]],"visType":["bar_chart","table","parallel_coordinate","comb"],"compType":["repeated","nested","accompanied"],"compressed_tree":[{"composite_pattern":"accompanied","visualization_type":[["parallel_coordinate",{"composite_pattern":"repeated","visualization_type":[["bar_chart"]]}]]},{"composite_pattern":"nested","visualization_type":[["bar_chart"],["table"]]}],"coOccurrence":[["bar_chart","parallel_coordinate",["coOccurrence"]],["bar_chart","table",["coOccurrence"]],["parallel_coordinate","table",["coOccurrence"]]],"year":2020,"conference":["VAST"],"authors":["Qianwen Wang","William Alexander","Jack Pegg","Huamin Qu","Min Chen"],"title":"HypoML: Visual Analysis for Hypothesis-based Evaluation of Machine Learning Models","doi":"10.1109/TVCG.2020.3030449","abstract":"In this paper, we present a visual analytics tool for enabling hypothesis-based evaluation of machine learning (ML) models. We describe a novel ML-testing framework that combines the traditional statistical hypothesis testing (commonly used in empirical research) with logical reasoning about the conclusions of multiple hypotheses. The framework defines a controlled configuration for testing a number of hypotheses as to whether and how some extra information about a \u201cconcept\u201d or \u201cfeature\u201d may benefit or hinder an ML model. Because reasoning multiple hypotheses is not always straightforward, we provide HypoML as a visual analysis tool, with which, the multi-thread testing results are first transformed to analytical results using statistical and logical inferences, and then to a visual representation for rapid observation of the conclusions and the logical flow between the testing results and hypotheses. We have applied HypoML to a number of hypothesized concepts, demonstrating the intuitive and explainable nature of the visual analysis.","keywords":"Tabular Data, Explainable Machine Learning, Counterfactual Explanation, Decision Making","caption":"Fig. 6. Subgroup comparison on a neural network trained on German Credit Dataset. A. The whole dataset with CF examples where the distribution of the credit duration (A1) suggests that a long duration of debt will lead to a \u201cbad\u201d risk for all loan applicants. B. The male subgroup covers a majority of male instances, where the gender column (B1) suggests that a few CF examples are generated by changing the gender from male to female (B2). B3. Diverse CF examples against a sample male instance from B2, where all valid CF examples (orange lines) suggest either to change the gender from male to female or to degrade the job rank. C. The narrowed male subgroup, where a larger portion of the instances have CF examples that change their gender to female (C1). The CF examples are found far from the subgroup (C2). D. The contrast female subgroup against the male subgroup C, where CF examples can be found within the subgroup (D1). ","img_size":{"width":1824,"height":855},"subfigures":[{"x":33.78204561437913,"y":11.713161818436614,"width":1740.5380470023583,"height":832.8975360542069,"type":"interface","id":"interface-0"}],"visualizations":[{"x":33.21800068555143,"y":151.90123143714516,"width":375.5353324019074,"height":678.4048782930832,"type":"bar_chart","id":"bar_chart-0"},{"x":437.03970735767786,"y":95.85623376432336,"width":1289.3944485837062,"height":719.6452152670245,"type":"table","id":"table-2"},{"x":438.62678027611685,"y":145.3550196892294,"width":1284.6114218781115,"height":668.9542286706452,"type":"bar_chart","id":"bar_chart-3"},{"x":30.042661139903977,"y":150.3184737658004,"width":383.4948923619185,"height":681.570393635772,"type":"parallel_coordinate","id":"parallel_coordinate-1"}],"relations":[{"vislist":[{"vislist":["parallel_coordinate-1",{"vislist":[{"vislist":["bar_chart-0"],"relation":null,"id":"group-0"}],"relation":"repeated","id":"relation-0"}],"relation":null,"id":"group-1"}],"relation":"accompanied","id":"relation-1"},{"vislist":[{"vislist":["bar_chart-3"],"relation":null,"id":"group-2"},{"vislist":["table-2"],"relation":null,"id":"group-3"}],"relation":"nested","id":"relation-2"}]},"3309_0":{"comp":[["stripe_graph","stripe_graph",["repeated"]],["line_chart","scatterplot",["accompanied"]],["scatterplot","line_chart",["accompanied"]],["bar_chart","matrix",["nested"]]],"visType":["stripe_graph","line_chart","scatterplot","bar_chart","matrix"],"compType":["repeated","accompanied","nested"],"compressed_tree":[{"composite_pattern":"repeated","visualization_type":[["stripe_graph"]]},{"composite_pattern":"accompanied","visualization_type":[["line_chart","scatterplot"]]},{"composite_pattern":"nested","visualization_type":[["bar_chart"],["matrix"]]}],"coOccurrence":[["stripe_graph","line_chart",["coOccurrence"]],["stripe_graph","scatterplot",["coOccurrence"]],["stripe_graph","bar_chart",["coOccurrence"]],["stripe_graph","matrix",["coOccurrence"]],["line_chart","scatterplot",["coOccurrence"]],["line_chart","bar_chart",["coOccurrence"]],["line_chart","matrix",["coOccurrence"]],["scatterplot","bar_chart",["coOccurrence"]],["scatterplot","matrix",["coOccurrence"]],["bar_chart","matrix",["coOccurrence"]]],"year":2020,"conference":["VAST"],"authors":["Xumeng Wang","Wei Chen","Jiazhi Xia","Zexian Chen","Dongshi Xu","Xiangyang Wu","Mingliang Xu","Tobias Schreck"],"title":"ConceptExplorer: Visual Analysis of Concept Drifts in Multi-source Time-series Data","doi":"10.1109/VAST50239.2020.00006","abstract":"Time-series data is widely studied in various scenarios, like weather forecast, stock market, customer behavior analysis. To comprehensively learn about the dynamic environments, it is necessary to comprehend features from multiple data sources. This paper proposes a novel visual analysis approach for detecting and analyzing concept drifts from multi-sourced time-series. We propose a visual detection scheme for discovering concept drifts from multiple sourced time-series based on prediction models. We design a drift level index to depict the dynamics, and a consistency judgment model to justify whether the concept drifts from various sources are consistent. Our integrated visual interface, ConceptExplorer, facilitates visual exploration, extraction, understanding, and comparison of concepts and concept drifts from multi-source time-series data. We conduct three case studies and expert interviews to verify the effectiveness of our approach.","keywords":": Temporal data; data analysis, reasoning, problemsolving, and decision making; machine learning techniques.","caption":"Figure 1: ConceptExplorer contains \ufb01ve main views. (a) The data entrance introduces the applied data sources and attributes. (b) The timeline navigator view is used to select interested time segments; (c) The prediction model view presents the training process of prediction models to explain concept drift detection model; (d) The concept-time view shows the time segments recommended for analyzing concepts based on the moment selected by analysts in prediction model view. (e) The explanation view compares concepts pairwise through a correlation matrix. ","img_size":{"width":1864,"height":1048},"subfigures":[{"x":11.404205733677209,"y":12.072890360809934,"width":1836.897041793459,"height":1025.2856873095466,"type":"interface","id":"interface-0"}],"visualizations":[{"x":1084.7548319899267,"y":543.9584118514321,"width":43.742187938483745,"height":38.4641918841346,"type":"bar_chart","id":"bar_chart-10"},{"x":1027.1392907923266,"y":489.0088431821479,"width":61.27841003312903,"height":55.19811922652985,"type":"bar_chart","id":"bar_chart-11"},{"x":878.4839025858753,"y":337.4495193634671,"width":57.70729451103602,"height":51.13406080661102,"type":"bar_chart","id":"bar_chart-12"},{"x":772.8864052999428,"y":236.4519312707838,"width":55.16105437498075,"height":42.86513872817033,"type":"bar_chart","id":"bar_chart-13"},{"x":815.34585939333,"y":284.71548633826416,"width":37.65284328839696,"height":25.187065442137534,"type":"bar_chart","id":"bar_chart-14"},{"x":853.2769738111637,"y":310.70209938793334,"width":29.201311552920387,"height":32.35061697949467,"type":"bar_chart","id":"bar_chart-15"},{"x":927.0850109490253,"y":386.3484086875214,"width":113.41226876809489,"height":106.10629105329963,"type":"bar_chart","id":"bar_chart-8"},{"x":684.15931086847,"y":145.46949629055734,"width":94.50552234973422,"height":90.12957073837256,"type":"bar_chart","id":"bar_chart-9"},{"x":11.768771137405675,"y":638.3745097038399,"width":1531.3597490706597,"height":291.9831614487796,"type":"line_chart","id":"line_chart-1"},{"x":1556.1901364594444,"y":675.7446200594763,"width":292.2007803220424,"height":245.16864128816925,"type":"line_chart","id":"line_chart-3"},{"x":570.8031715442536,"y":75.6333416730209,"width":579.3514459915757,"height":517.272326818494,"type":"matrix","id":"matrix-7"},{"x":9.629377532274278,"y":930.351692303434,"width":1834.8762648720096,"height":112.1301101003459,"type":"others","id":"others-2"},{"x":1557.854780040062,"y":674.1818545875371,"width":293.80398319252834,"height":251.57954876741854,"type":"scatterplot","id":"scatterplot-4"},{"x":1385.680581056255,"y":41.66836542902559,"width":445.7852699230151,"height":586.8449675741701,"type":"stripe_graph","id":"stripe_graph-0"}],"relations":[{"vislist":[{"vislist":["stripe_graph-0"],"relation":null,"id":"group-0"}],"relation":"repeated","id":"relation-0"},{"vislist":[{"vislist":["line_chart-3","scatterplot-4"],"relation":null,"id":"group-1"}],"relation":"accompanied","id":"relation-1"},{"vislist":[{"vislist":["bar_chart-9","bar_chart-13","bar_chart-14","bar_chart-15","bar_chart-12","bar_chart-8","bar_chart-11","bar_chart-10"],"relation":null,"id":"group-2"},{"vislist":["matrix-7"],"relation":null,"id":"group-3"}],"relation":"nested","id":"relation-2"}]},"3310_5":{"comp":[["scivis","scivis",["repeated"]],["heatmap","heatmap",["repeated"]]],"visType":["scivis","heatmap"],"compType":["repeated"],"compressed_tree":[{"composite_pattern":"repeated","visualization_type":[["scivis"]]},{"composite_pattern":"repeated","visualization_type":[["heatmap"]]}],"coOccurrence":[["scivis","heatmap",["coOccurrence"]]],"year":2020,"conference":["VAST"],"authors":["Mohammad Raji","Jeremiah Duncan","Tanner Hobson","Jian Huang"],"title":"Dataless Sharing of Interactive Visualization","doi":"10.1109/TVCG.2020.2984708","abstract":"Interactive visualization has become a powerful insight-revealing medium. However, the close dependency of interactive visualization on its data inhibits its shareability. Users have to choose between the two extremes of (i) sharing non-interactive dataless formats such as images and videos, or (ii) giving access to their data and software to others with no control over how the data will be used. In this work, we fill the gap between the two extremes and present a new system, called Loom. Loom captures interactive visualizations as standalone dataless objects. Users can interact with Loom objects as if they still have the original software and data that created those visualizations. Yet, Loom objects are completely independent and can therefore be shared online without requiring the data or the visualization software. Loom objects are efficient to store and use, and provide privacy preserving mechanisms. We demonstrate Loom\'s efficacy with examples of scientific visualization using Paraview, information visualization using Tableau, and journalistic visualization from New York Times.","keywords":": High-Dimensional Data Visualization\u2014SecureVisualization\u2014Dimensionality Reduction\u2014Secure Multi-PartyComputation;","caption":"Figure 4: The user interface for participants. (a): the task list; (b): the task description view; (c): the global projection view; (d): the individual projection view; (e): the bar chart of contributions; and (f): the parallel coordinates/snapshot list. ","img_size":{"width":2025,"height":1008},"subfigures":[{"x":12.715453646787115,"y":13.009993227062452,"width":2001.039906398039,"height":986.3895950779339,"type":"interface","id":"interface-0"}],"visualizations":[{"x":1142.4311174441782,"y":368.7676266256723,"width":865.4282082390298,"height":274.03406732212363,"type":"bar_chart","id":"bar_chart-0"},{"x":13.600564995817532,"y":366.40624419562675,"width":1110.0697426523166,"height":624.9809278086744,"type":"heatmap","id":"heatmap-2"},{"x":1138.8474755916916,"y":644.3808349407708,"width":865.4507907178005,"height":356.36205248261354,"type":"scivis","id":"scivis-1"},{"x":17.60964049562136,"y":44.18884749339075,"width":1993.3530696218613,"height":318.19178838374813,"type":"table","id":"table-3"}],"relations":[{"vislist":[{"vislist":["scivis-1"],"relation":null,"id":"group-0"}],"relation":"repeated","id":"relation-0"},{"vislist":[{"vislist":["heatmap-2"],"relation":null,"id":"group-1"}],"relation":"repeated","id":"relation-1"}]},"3312_0":{"comp":[["graph","graph",["repeated"]]],"visType":["graph"],"compType":["repeated"],"compressed_tree":[{"composite_pattern":"repeated","visualization_type":[["graph"]]}],"coOccurrence":[["graph","graph",["coOccurrence"]]],"year":2020,"conference":["VAST"],"authors":["Krist\xedna Z\xe1kop\u010danov\xe1","Marko \u0158eh\xe1\u010dek","Jozef B\xe1trna","Daniel Plakinger","Sergej Stoppel","Barbora Kozl\xedkov\xe1"],"title":"Visilant: Visual Support for the Exploration and Analytical Process Tracking in Criminal Investigations","doi":"10.1109/TVCG.2020.3030356","abstract":"The daily routine of criminal investigators consists of a thorough analysis of highly complex and heterogeneous data of crime cases. Such data can consist of case descriptions, testimonies, criminal networks, spatial and temporal information, and virtually any other data that is relevant for the case. Criminal investigators work under heavy time pressure to analyze the data for relationships, propose and verify several hypotheses, and derive conclusions, while the data can be incomplete or inconsistent and is changed and updated throughout the investigation, as new findings are added to the case. Based on a four-year intense collaboration with criminalists, we present a conceptual design for a visual tool supporting the investigation workflow and Visilant, a web-based tool for the exploration and analysis of criminal data guided by the proposed design. Visilant aims to support namely the exploratory part of the investigation pipeline, from case overview, through exploration and hypothesis generation, to the case presentation. Visilant tracks the reasoning process and as the data is changing, it informs investigators which hypotheses are affected by the data change and should be revised. The tool was evaluated by senior criminology experts within two sessions and their feedback is summarized in the paper. Additional supplementary material contains the technical details and exemplary case study.","keywords":"Criminal investigation, visualization, network, exploration, interaction, tracking, diagram","caption":"Fig. 1. Overview of the core parts of the proposed Visilant tool. The top part shows two states within the investigation process that need to be compared, the bottom part enables users to track the investigation progress, trace it back, and perform required operations. ","img_size":{"width":1965,"height":1232},"subfigures":[{"x":15.560094291704159,"y":14.192558134081938,"width":1937.2467768651156,"height":1205.2976782112235,"type":"interface","id":"interface-0"}],"visualizations":[{"x":985.957813233803,"y":63.531863683684264,"width":961.9720144468648,"height":794.6775437333283,"type":"graph","id":"graph-0"},{"x":13.619782017978766,"y":61.80335665205157,"width":963.6730402682799,"height":794.6679798200652,"type":"graph","id":"graph-1"},{"x":14.874158798197127,"y":922.1246581772408,"width":1143.1557040531363,"height":285.59437956640176,"type":"others","id":"others-2"}],"relations":[{"vislist":[{"vislist":["graph-1","graph-0"],"relation":null,"id":"group-0"}],"relation":"repeated","id":"relation-0"}]},"3314_2":{"comp":[["line_chart","line_chart",["repeated"]],["scatterplot","scatterplot",["repeated"]]],"visType":["line_chart","scatterplot"],"compType":["repeated"],"compressed_tree":[{"composite_pattern":"repeated","visualization_type":[["line_chart"]]},{"composite_pattern":"repeated","visualization_type":[["scatterplot"]]}],"coOccurrence":[],"year":2020,"conference":["VAST"],"authors":["Hiroaki Natsukawa","Ethan R. Deyle","Gerald M. Pao","Koji Koyamada","George Sugihara"],"title":"A Visual Analytics Approach for Ecosystem Dynamics based on Empirical Dynamic Modeling","doi":"10.1109/TVCG.2020.3028956","abstract":"An important approach for scientific inquiry across many disciplines involves using observational time series data to understand the relationships between key variables to gain mechanistic insights into the underlying rules that govern the given system. In real systems, such as those found in ecology, the relationships between time series variables are generally not static; instead, these relationships are dynamical and change in a nonlinear or state-dependent manner. To further understand such systems, we investigate integrating methods that appropriately characterize these dynamics (i.e., methods that measure interactions as they change with time-varying system states) with visualization techniques that can help analyze the behavior of the system. Here, we focus on empirical dynamic modeling (EDM) as a state-of-the-art method that specifically identifies causal variables and measures changing state-dependent relationships between time series variables. Instead of using approaches centered on parametric equations, EDM is an equation-free approach that studies systems based on their dynamic attractors. We propose a visual analytics system to support the identification and mechanistic interpretation of system states using an EDM-constructed dynamic graph. This work, as detailed in four analysis tasks and demonstrated with a GUI, provides a novel synthesis of EDM and visualization techniques such as brush-link visualization and visual summarization to interpret dynamic graphs representing ecosystem dynamics. We applied our proposed system to ecological simulation data and real data from a marine mesocosm study as two key use cases. Our case studies show that our visual analytics tools support the identification and interpretation of the system state by the user, and enable us to discover both confirmatory and new findings in ecosystem dynamics. Overall, we demonstrated that our system can facilitate an understanding of how systems function beyond the intuitive analysi...","keywords":"Visual analytics, empirical dynamic modeling, dynamic network, exploratory data analysis","caption":"Fig. 3. Graphical user interface (GUI) screenshots of our proposed visual analytics system. GUI of our prototype consists of four tabs of views: (a) EDM view enabling con\ufb01rmation of the input and output of EDM; (b) detail view with multiple scatterplots enabling exploration of the relation- ships between the variables; (c) setting view supporting the determination of the value of \u03b8 ; and (d) dynamic network view with dynamic graph, two-dimensional mapping, and state transition graph for identi\ufb01cation and interpretation of the system state. ","img_size":{"width":1521,"height":1026},"subfigures":[{"x":9.163136990279337,"y":11.722974794609925,"width":646.5285654832104,"height":484.0293424031412,"type":"interface","id":"interface-0"},{"x":713.9964969487498,"y":10.335576057602612,"width":643.6862992133659,"height":485.4027217474054,"type":"interface","id":"interface-1"},{"x":7.756228123623385,"y":516.1994503226796,"width":643.737504915139,"height":500.9144623242759,"type":"interface","id":"interface-2"},{"x":716.8638684874735,"y":513.3356973139398,"width":792.0857094239477,"height":501.03629582275363,"type":"interface","id":"interface-3"}],"visualizations":[{"x":1074.6376347914384,"y":551.8048622035765,"width":428.24429022779015,"height":391.86534905922144,"type":"graph","id":"graph-10"},{"x":741.9584148951784,"y":551.1340478348524,"width":327.13562230620545,"height":215.22687531837278,"type":"graph","id":"graph-11"},{"x":385.77632943026026,"y":314.3335568875272,"width":254.81683104244294,"height":139.47195035087697,"type":"graph","id":"graph-2"},{"x":1098.453407737007,"y":98.95575941318157,"width":246.09566510346463,"height":152.604942633956,"type":"graph","id":"graph-5"},{"x":771.2555992514369,"y":769.1509382076267,"width":303.5717429773322,"height":179.99867968143045,"type":"graph","id":"graph-9"},{"x":35.66034869684742,"y":114.16277974755099,"width":345.1578771603338,"height":352.0234752442768,"type":"line_chart","id":"line_chart-0"},{"x":750.47141519292,"y":101.81041044652251,"width":336.7327936422915,"height":163.71265812427893,"type":"line_chart","id":"line_chart-4"},{"x":19.246610683734563,"y":596.4849773742925,"width":357.32745962992334,"height":210.0115221542645,"type":"line_chart","id":"line_chart-8"},{"x":389.90619267798627,"y":103.50167635384837,"width":249.3595436976816,"height":210.78117898064076,"type":"scatterplot","id":"scatterplot-1"},{"x":721.7763932767612,"y":269.3531484780179,"width":622.5216282559609,"height":218.22142213189272,"type":"scatterplot","id":"scatterplot-6"}],"relations":[{"vislist":[{"vislist":["line_chart-0"],"relation":null,"id":"group-0"}],"relation":"repeated","id":"relation-0"},{"vislist":[{"vislist":["scatterplot-6"],"relation":null,"id":"group-1"}],"relation":"repeated","id":"relation-1"}]},"3315_0":{"comp":[["graph","graph",["repeated"]],["graph","matrix",["coordinated"]],["bar_chart","bar_chart",["repeated"]],["bar_chart","area_chart",["stacked"]],["area_chart","bar_chart",["stacked"]]],"visType":["graph","matrix","bar_chart","area_chart"],"compType":["repeated","coordinated","stacked"],"compressed_tree":[{"composite_pattern":"stacked","visualization_type":[["area_chart","bar_chart"]]},{"composite_pattern":"repeated","visualization_type":[["graph"]]},{"composite_pattern":"repeated","visualization_type":[["bar_chart"]]},{"composite_pattern":"coordinated","visualization_type":[["graph"],["matrix"]]}],"coOccurrence":[["area_chart","bar_chart",["coOccurrence"]],["area_chart","graph",["coOccurrence"]],["area_chart","matrix",["coOccurrence"]],["bar_chart","graph",["coOccurrence"]],["bar_chart","matrix",["coOccurrence"]],["graph","matrix",["coOccurrence"]]],"year":2020,"conference":["VAST"],"authors":["Wenbo Tao","Xinli Hou","Adam Sah","Leilani Battle","Remco Chang","Michael Stonebraker"],"title":"Kyrix-S: Authoring Scalable Scatterplot Visualizations of Big Data","doi":"10.1109/TVCG.2020.3030372","abstract":"Static scatterplots often suffer from the overdraw problem on big datasets where object overlap causes undesirable visual clutter. The use of zooming in scatterplots can help alleviate this problem. With multiple zoom levels, more screen real estate is available, allowing objects to be placed in a less crowded way. We call this type of visualization scalable scatterplot visualizations, or SSV for short. Despite the potential of SSVs, existing systems and toolkits fall short in supporting the authoring of SSVs due to three limitations. First, many systems have limited scalability, assuming that data fits in the memory of one computer. Second, too much developer work, e.g., using custom code to generate mark layouts or render objects, is required. Third, many systems focus on only a small subset of the SSV design space (e.g. supporting a specific type of visual marks). To address these limitations, we have developed Kyrix-S, a system for easy authoring of SSVs at scale. Kyrix-S derives a declarative grammar that enables specification of a variety of SSVs in a few tens of lines of code, based on an existing survey of scatterplot tasks and designs. The declarative grammar is supported by a distributed layout algorithm which automatically places visual marks onto zoom levels. We store data in a multi-node database and use multi-node spatial indexes to achieve interactive browsing of large SSVs. Extensive experiments show that 1) Kyrix-S enables interactive browsing of SSVs of billions of objects, with response times under 500ms and 2) Kyrix-S achieves 4X-9X reduction in specification compared to a state-of-the-art authoring system.","keywords":"Visual Analytics, Tax Network, Tax Evasion Detection, Anomaly detection, Multidimensional data","caption":"Fig. 1. The system interface of TaxThemis: (A) The Control Panel consists of a bar chart to show the temporal summary of the daily related party\u2019s daily transaction amounts, together with a parameter selector to support network fusion through interactively setting the preferred period or relevant thresholds. (B) The Group Overview visualizes the topology of related party transactions in each suspicious group, and ranks the groups by their group features. This helps users focus on the most suspicious groups. (C) The Graph View shows the hierarchical investment relationships and related party transactions within the selected suspicious group. It supports group assessment in revealing the common bene\ufb01cial owners and former tax evaders. (D) The Detail View presents the pro\ufb01t status of the traders who conducted the selected related party transactions, revealing their suspicious behavior of transferring revenue transfers. ","img_size":{"width":1821,"height":1042},"subfigures":[{"x":13.324886819579165,"y":9.17518442811694,"width":1795.7732205689158,"height":1022.2263585402552,"type":"interface","id":"interface-0"}],"visualizations":[{"x":495.7613147872024,"y":26.790593877234155,"width":1269.5856735885864,"height":53.43596903699323,"type":"area_chart","id":"area_chart-1"},{"x":474.9651143387374,"y":79.62669289614843,"width":1291.9032582885966,"height":124.47874136504112,"type":"bar_chart","id":"bar_chart-0"},{"x":175.19367108064094,"y":241.67297597187783,"width":291.63640046049204,"height":751.4340157281073,"type":"bar_chart","id":"bar_chart-4"},{"x":471.9931296154702,"y":202.77480457396817,"width":1338.003094812047,"height":336.0349412300765,"type":"graph","id":"graph-3"},{"x":10.04169599192362,"y":249.65965758425332,"width":170.58840469340146,"height":743.4931511563503,"type":"graph","id":"graph-5"},{"x":478.3528534052843,"y":548.5551426692174,"width":1323.6774125493398,"height":483.06712441218383,"type":"graph","id":"graph-9"},{"x":473.53433982478344,"y":546.9222010227019,"width":1325.2832662949575,"height":481.51350851342033,"type":"heatmap","id":"heatmap-10"},{"x":475.21968481344123,"y":545.3075020051596,"width":1339.5811578314867,"height":481.5299070873052,"type":"matrix","id":"matrix-8"}],"relations":[{"vislist":[{"vislist":["area_chart-1","bar_chart-0"],"relation":null,"id":"group-0"}],"relation":"stacked","id":"relation-0"},{"vislist":[{"vislist":["graph-5"],"relation":null,"id":"group-1"}],"relation":"repeated","id":"relation-1"},{"vislist":[{"vislist":["bar_chart-4"],"relation":null,"id":"group-2"}],"relation":"repeated","id":"relation-2"},{"vislist":[{"vislist":["graph-9"],"relation":null,"id":"group-3"},{"vislist":["matrix-8"],"relation":null,"id":"group-4"}],"relation":"coordinated","id":"relation-3"}]},"3317_0":{"comp":[["bar_chart","bar_chart",["repeated"]],["stripe_graph","stripe_graph",["repeated"]],["others","others",["repeated"]],["others","graph",["nested"]],["line_chart","line_chart",["mirrored"]]],"visType":["bar_chart","stripe_graph","others","graph","line_chart"],"compType":["repeated","nested","mirrored"],"compressed_tree":[{"composite_pattern":"repeated","visualization_type":[["bar_chart"]]},{"composite_pattern":"repeated","visualization_type":[["stripe_graph"]]},{"composite_pattern":"repeated","visualization_type":[["others"]]},{"composite_pattern":"mirrored","visualization_type":[["line_chart"]]},{"composite_pattern":"nested","visualization_type":[["others"],["graph"]]}],"coOccurrence":[["bar_chart","stripe_graph",["coOccurrence"]],["bar_chart","others",["coOccurrence"]],["bar_chart","line_chart",["coOccurrence"]],["bar_chart","graph",["coOccurrence"]],["stripe_graph","others",["coOccurrence"]],["stripe_graph","line_chart",["coOccurrence"]],["stripe_graph","graph",["coOccurrence"]],["others","line_chart",["coOccurrence"]],["others","graph",["coOccurrence"]],["line_chart","graph",["coOccurrence"]]],"year":2020,"conference":["VAST"],"authors":["Meng Xia","Reshika Palaniyappan Velumani","Yong Wang","Huamin Qu","Xiaojuan Ma"],"title":"QLens: Visual Analytics of Multi-step Problem-solving Behaviors for Improving Question Design","doi":"10.1109/TVCG.2020.3030337","abstract":"With the rapid development of online education in recent years, there has been an increasing number of learning platforms that provide students with multi-step questions to cultivate their problem-solving skills. To guarantee the high quality of such learning materials, question designers need to inspect how students\' problem-solving processes unfold step by step to infer whether students\' problem-solving logic matches their design intent. They also need to compare the behaviors of different groups (e.g., students from different grades) to distribute questions to students with the right level of knowledge. The availability of fine-grained interaction data, such as mouse movement trajectories from the online platforms, provides the opportunity to analyze problem-solving behaviors. However, it is still challenging to interpret, summarize, and compare the high dimensional problem-solving sequence data. In this paper, we present a visual analytics system, QLens, to help question designers inspect detailed problem-solving trajectories, compare different student groups, distill insights for design improvements. In particular, QLens models problem-solving behavior as a hybrid state transition graph and visualizes it through a novel glyph-embedded Sankey diagram, which reflects students\' problem-solving logic, engagement, and encountered difficulties. We conduct three case studies and three expert interviews to demonstrate the usefulness of QLens on real-world datasets that consist of thousands of problem-solving traces.","keywords":"Learning Behavior Analysis, Visual Analytics, Time Series Data","caption":"Fig. 1. QLens enables question designers to analyze students\u2019 multi-step problem-solving behaviors for design improvements from levels of detail. (1) Macro-level: Overview (a) shows the question\u2019s preview (a1), students\u2019 overall performance (a2) and the ranking of common wrong answers based on the frequency of occurence(a3). (2) Meso-level: Transition View (b) visualizes the problem-solving processes to re\ufb02ect how a group of students proceed step by step (problem-solving logic) using a novel glyph-embedded Sankey diagram (b2) and the amount of efforts (engagement) using a contextual axis (b3). In addition, Comparison View (c) enables users to compare the problem-solving logic, engagement, and encountered dif\ufb01culties of different groups (c1, c2, c3). (3) Micro-level (the highlighted path in b): typical incorrect paths and the corresponding data-driven recommended paths are demonstrated for question designers to evaluate the feasibility of the data-driven feedback. Rich interactions are also provided for exploration (e.g., \ufb01lters in b1). ","img_size":{"width":1823,"height":883},"subfigures":[{"x":15.382747169777474,"y":8.092553211532504,"width":1789.5863146877962,"height":862.8424313778798,"type":"interface","id":"interface-0"}],"visualizations":[{"x":12.412279667120416,"y":298.75310529637636,"width":383.13649064993854,"height":250.13510374636303,"type":"bar_chart","id":"bar_chart-0"},{"x":1500.7030743705982,"y":712.2147430448786,"width":254.320788149822,"height":127.17111549786502,"type":"bar_chart","id":"bar_chart-3"},{"x":413.06883441479295,"y":149.71851464581493,"width":1056.3582870233517,"height":567.4908408625133,"type":"graph","id":"graph-5"},{"x":424.31327151266504,"y":750.9508489949078,"width":1051.5573997028027,"height":115.59463596581755,"type":"line_chart","id":"line_chart-4"},{"x":1499.1141664257423,"y":138.43210502458777,"width":257.4986040395338,"height":562.7410393670111,"type":"others","id":"others-2"},{"x":413.06140892795673,"y":154.47649754476868,"width":1053.157140383352,"height":561.1893010337777,"type":"others","id":"others-6"},{"x":9.238276387874238,"y":568.1710932714954,"width":391.0924960152674,"height":299.539080154467,"type":"stripe_graph","id":"stripe_graph-1"}],"relations":[{"vislist":[{"vislist":["bar_chart-0"],"relation":null,"id":"group-0"}],"relation":"repeated","id":"relation-0"},{"vislist":[{"vislist":["stripe_graph-1"],"relation":null,"id":"group-1"}],"relation":"repeated","id":"relation-1"},{"vislist":[{"vislist":["others-2"],"relation":null,"id":"group-2"}],"relation":"repeated","id":"relation-2"},{"vislist":[{"vislist":["line_chart-4"],"relation":null,"id":"group-3"}],"relation":"mirrored","id":"relation-3"},{"vislist":[{"vislist":["others-6"],"relation":null,"id":"group-4"},{"vislist":["graph-5"],"relation":null,"id":"group-5"}],"relation":"nested","id":"relation-4"}]},"3320_2":{"comp":[["bar_chart","bar_chart",["repeated"]],["proportional_area_chart","map",["coordinated"]]],"visType":["bar_chart","proportional_area_chart","map"],"compType":["repeated","coordinated"],"compressed_tree":[{"composite_pattern":"repeated","visualization_type":[["bar_chart"]]},{"composite_pattern":"coordinated","visualization_type":[["proportional_area_chart"],["map"]]}],"coOccurrence":[["bar_chart","proportional_area_chart",["coOccurrence"]],["bar_chart","map",["coOccurrence"]],["proportional_area_chart","map",["coOccurrence"]]],"year":2020,"conference":["VAST"],"authors":["Michael Oppermann","Robert Kincaid","Tamara Munzner"],"title":"VizCommender: Computing Text-Based Similarity in Visualization Repositories for Content-Based Recommendations","doi":"10.1109/TVCG.2020.3030387","abstract":"Cloud-based visualization services have made visual analytics accessible to a much wider audience than ever before. Systems such as Tableau have started to amass increasingly large repositories of analytical knowledge in the form of interactive visualization workbooks. When shared, these collections can form a visual analytic knowledge base. However, as the size of a collection increases, so does the difficulty in finding relevant information. Content-based recommendation (CBR) systems could help analysts in finding and managing workbooks relevant to their interests. Toward this goal, we focus on text-based content that is representative of the subject matter of visualizations rather than the visual encodings and style. We discuss the challenges associated with creating a CBR based on visualization specifications and explore more concretely how to implement the relevance measures required using Tableau workbook specifications as the source of content data. We also demonstrate what information can be extracted from these visualization specifications and how various natural language processing techniques can be used to compute similarity between workbooks as one way to measure relevance. We report on a crowd-sourced user study to determine if our similarity measure mimics human judgement. Finally, we choose latent Dirichl et al.ocation (LDA) as a specific model and instantiate it in a proof-of-concept recommender tool to demonstrate the basic function of our similarity measure.","keywords":"visualization recommendation, content-based \ufb01ltering, recommender systems, visualization workbook repositories","caption":"Fig. 3. VizCommender interface that allows users to browse through a VizRepo. Workbook thumbnails are arranged in a grid view. Users can search for content or further drill down by selecting one of the tags at the top. The quick view sidebar on the right provides further details including recommendations when a workbook is selected. ","img_size":{"width":987,"height":509},"subfigures":[{"x":11.907097193771335,"y":12.790255712114345,"width":967.487118541703,"height":487.0032762619921,"type":"interface","id":"interface-0"}],"visualizations":[{"x":27.97086925209249,"y":85.73671599511361,"width":92.67520394209049,"height":84.97408555105041,"type":"bar_chart","id":"bar_chart-0"},{"x":26.714323161090284,"y":343.5111965238954,"width":222.29517712393368,"height":82.3679250734426,"type":"bar_chart","id":"bar_chart-1"},{"x":29.258115847497734,"y":467.3787329920426,"width":206.76045084702312,"height":29.70787307078175,"type":"bar_chart","id":"bar_chart-2"},{"x":508.124051539653,"y":88.34539070015757,"width":212.77732786559014,"height":86.723701174307,"type":"bar_chart","id":"bar_chart-5"},{"x":504.6961434501523,"y":216.15306196214962,"width":220.5037391199337,"height":39.24643902147573,"type":"bar_chart","id":"bar_chart-6"},{"x":604.2483812892327,"y":368.18423628743705,"width":118.90591188000387,"height":37.37619869219929,"type":"bar_chart","id":"bar_chart-7"},{"x":267.81519723625075,"y":342.8008846633834,"width":219.79131548669804,"height":92.49725508614675,"type":"map","id":"map-4"},{"x":267.8151972362506,"y":345.4191286028568,"width":219.7913154866988,"height":91.61512035304031,"type":"proportional_area_chart","id":"proportional_area_chart-8"},{"x":266.93769450668765,"y":218.2392210799776,"width":218.063940644459,"height":82.97200539006054,"type":"scatterplot","id":"scatterplot-3"}],"relations":[{"vislist":[{"vislist":["bar_chart-5"],"relation":null,"id":"group-0"}],"relation":"repeated","id":"relation-0"},{"vislist":[{"vislist":["proportional_area_chart-8"],"relation":null,"id":"group-1"},{"vislist":["map-4"],"relation":null,"id":"group-2"}],"relation":"coordinated","id":"relation-1"}]},"3322_0":{"comp":[["bar_chart","bar_chart",["repeated"]],["bar_chart","area_chart",["accompanied"]],["bar_chart","line_chart",["accompanied"]],["area_chart","bar_chart",["accompanied"]],["line_chart","bar_chart",["accompanied"]]],"visType":["bar_chart","area_chart","line_chart"],"compType":["repeated","accompanied"],"compressed_tree":[{"composite_pattern":"accompanied","visualization_type":[["bar_chart","area_chart"]]},{"composite_pattern":"repeated","visualization_type":[["bar_chart"]]},{"composite_pattern":"accompanied","visualization_type":[["line_chart","bar_chart"]]}],"coOccurrence":[["bar_chart","area_chart",["coOccurrence"]],["bar_chart","line_chart",["coOccurrence"]],["area_chart","line_chart",["coOccurrence"]]],"year":2020,"conference":["VAST"],"authors":["Yang Liu","Alex Kale","Tim Althoff","Jeffrey Heer"],"title":"Boba: Authoring and Visualizing Multiverse Analyses","doi":"10.1109/TVCG.2020.3028985","abstract":"Multiverse analysis is an approach to data analysis in which all \u201creasonable\u201d analytic decisions are evaluated in parallel and interpreted collectively, in order to foster robustness and transparency. However, specifying a multiverse is demanding because analysts must manage myriad variants from a cross-product of analytic decisions, and the results require nuanced interpretation. We contribute Baba: an integrated domain-specific language (DSL) and visual analysis system for authoring and reviewing multiverse analyses. With the Boba DSL, analysts write the shared portion of analysis code only once, alongside local variations defining alternative decisions, from which the compiler generates a multiplex of scripts representing all possible analysis paths. The Boba Visualizer provides linked views of model results and the multiverse decision space to enable rapid, systematic assessment of consequential decisions and robustness, including sampling uncertainty and model fit. We demonstrate Boba\'s utility through two data analysis case studies, and reflect on challenges and design opportunities for multiverse analysis software.","keywords":"Multiverse Analysis, Statistical Analysis, Analytic Decisions, Reproducibility","caption":"Fig. 1. Authoring and visualizing multiverse analyses with Boba. Users start by annotating a script with analytic decisions (a), from which Boba synthesizes a multiplex of possible analysis variants (b). To interpret the results from all analyses, users start with a graph of analytic decisions (c), where sensitive decisions are highlighted in darker blues. Clicking a decision node allows users to compare point estimates (d, blue dots) and uncertainty distributions (d, gray area) between different alternatives. Users may further drill down to assess the \ufb01t quality of individual models (e) by comparing observed data (pink) with model predictions (teal). ","img_size":{"width":1783,"height":726},"subfigures":[{"x":9.916509790785586,"y":10.970447455839313,"width":1767.052107547531,"height":709.2421927647868,"type":"interface","id":"interface-0"}],"visualizations":[{"x":709.1966735389548,"y":102.23351661467974,"width":721.613260205509,"height":421.04103193534564,"type":"area_chart","id":"area_chart-1"},{"x":712.3169293922612,"y":105.37829787324014,"width":716.945464830542,"height":422.6024018272322,"type":"bar_chart","id":"bar_chart-2"},{"x":705.9025090832718,"y":528.9698546568142,"width":699.892695147266,"height":175.2305243082509,"type":"bar_chart","id":"bar_chart-3"},{"x":1436.9004709116748,"y":82.4120609190748,"width":337.2254873103307,"height":622.4131509521088,"type":"bar_chart","id":"bar_chart-5"},{"x":363.60485013972254,"y":66.84953791730895,"width":341.7770851537155,"height":637.8363321376254,"type":"graph","id":"graph-0"},{"x":1440.0100353823148,"y":83.96831321925143,"width":331.0063583690486,"height":620.8708328335575,"type":"line_chart","id":"line_chart-4"}],"relations":[{"vislist":[{"vislist":["bar_chart-2","area_chart-1"],"relation":null,"id":"group-0"}],"relation":"accompanied","id":"relation-0"},{"vislist":[{"vislist":["bar_chart-3"],"relation":null,"id":"group-1"}],"relation":"repeated","id":"relation-1"},{"vislist":[{"vislist":["line_chart-4","bar_chart-5"],"relation":null,"id":"group-2"}],"relation":"accompanied","id":"relation-2"}]},"3326_1":{"comp":[["scatterplot","scatterplot",["repeated"]],["scatterplot","map",["coordinated"]],["area_chart","line_chart",["annotated"]]],"visType":["scatterplot","map","area_chart","line_chart"],"compType":["repeated","coordinated","annotated"],"compressed_tree":[{"composite_pattern":"repeated","visualization_type":[["scatterplot"]]},{"composite_pattern":"coordinated","visualization_type":[["scatterplot"],["map"]]},{"composite_pattern":"annotated","visualization_type":[["area_chart"],["line_chart"]]}],"coOccurrence":[["scatterplot","map",["coOccurrence"]],["scatterplot","area_chart",["coOccurrence"]],["scatterplot","line_chart",["coOccurrence"]],["map","area_chart",["coOccurrence"]],["map","line_chart",["coOccurrence"]],["area_chart","line_chart",["coOccurrence"]]],"year":2020,"conference":["VAST"],"authors":["Takanori Fujiwara","Shilpika","Naohisa Sakamoto","Jorji Nonaka","Keiji Yamamoto","Kwan-Liu Ma"],"title":"A Visual Analytics Framework for Reviewing Multivariate Time-Series Data with Dimensionality Reduction","doi":"10.1109/TVCG.2020.3028889","abstract":"Data-driven problem solving in many real-world applications involves analysis of time-dependent multivariate data, for which dimensionality reduction (DR) methods are often used to uncover the intrinsic structure and features of the data. However, DR is usually applied to a subset of data that is either single-time-point multivariate or univariate time-series, resulting in the need to manually examine and correlate the DR results out of different data subsets. When the number of dimensions is large either in terms of the number of time points or attributes, this manual task becomes too tedious and infeasible. In this paper, we present MulTiDR, a new DR framework that enables processing of time-dependent multivariate data as a whole to provide a comprehensive overview of the data. With the framework, we employ DR in two steps. When treating the instances, time points, and attributes of the data as a 3D array, the first DR step reduces the three axes of the array to two, and the second DR step visualizes the data in a lower-dimensional space. In addition, by coupling with a contrastive learning method and interactive visualizations, our framework enhances analysts\' ability to interpret DR results. We demonstrate the effectiveness of our framework with four case studies using real-world datasets.","keywords":"Multivariate time-series, tensor, data cube, dimensionality reduction, interpretability, visual analytics.","caption":"Fig. 2: A screenshot of MulTiDR visual interface. Here we visualize the AirData [50], air quality data at outdoor monitors across the US, collected in 2018. (a) A two-step DR (TDR) view draws the DR results obtained through the two-step DR. (b) A supplemental information (SI) view supports understanding selected points in the TDR view with the auxiliary information. (c) A feature contribution (FC) view visualizes features (either instances, variables, or time points) and their contributions to characteristics of each of the selected clusters. (d) A histogram comparison (HC) view shows the feature values in the \ufb01rst DR result Y of the selected element in (c). (e) A parametric mapping (PM) view depicts parametric mappings generated in the \ufb01rst DR, speci\ufb01cally the mappings to the \ufb01rst principal component in this example. (f) The analyst can select a type of DR results. ","img_size":{"width":1902,"height":1122},"subfigures":[{"x":11.77669892507077,"y":9.888001033373426,"width":1878.446602149857,"height":1102.2239979332523,"type":"interface","id":"interface-0"}],"visualizations":[{"x":744.0448089712021,"y":489.8338320697724,"width":247.81989421906988,"height":234.47362029452503,"type":"area_chart","id":"area_chart-3"},{"x":893.0010576791345,"y":652.9348627241521,"width":812.235788207276,"height":224.9025182228426,"type":"bar_chart","id":"bar_chart-2"},{"x":17.13697373994635,"y":890.5909469358435,"width":822.5303563241215,"height":215.32266021166836,"type":"bar_chart","id":"bar_chart-8"},{"x":887.7887811671517,"y":878.8910000758916,"width":787.429025629126,"height":223.64488920599587,"type":"line_chart","id":"line_chart-6"},{"x":16.117424975648238,"y":676.3356073288909,"width":817.8587270713653,"height":211.60695062575485,"type":"line_chart","id":"line_chart-7"},{"x":1328.8366904858306,"y":15.9421104682272,"width":561.3067498691839,"height":627.7340608125762,"type":"map","id":"map-4"},{"x":642.3258583716214,"y":88.63445120980703,"width":520.0427449271153,"height":532.6082617479997,"type":"scatterplot","id":"scatterplot-0"},{"x":45.1985142612456,"y":81.4454949517037,"width":538.2425647154674,"height":538.6096938611082,"type":"scatterplot","id":"scatterplot-1"},{"x":1320.4657296573623,"y":22.554201105884687,"width":567.9825813540907,"height":621.2110638597381,"type":"scatterplot","id":"scatterplot-5"}],"relations":[{"vislist":[{"vislist":["scatterplot-0","scatterplot-1"],"relation":null,"id":"group-0"}],"relation":"repeated","id":"relation-0"},{"vislist":[{"vislist":["scatterplot-5"],"relation":null,"id":"group-1"},{"vislist":["map-4"],"relation":null,"id":"group-2"}],"relation":"coordinated","id":"relation-1"},{"vislist":[{"vislist":["area_chart-3"],"relation":null,"id":"group-3"},{"vislist":["line_chart-7"],"relation":null,"id":"group-4"}],"relation":"annotated","id":"relation-2"}]},"3326_4":{"comp":[["matrix","matrix",["repeated"]],["area_chart","area_chart",["repeated"]]],"visType":["matrix","area_chart"],"compType":["repeated"],"compressed_tree":[{"composite_pattern":"repeated","visualization_type":[["matrix"]]},{"composite_pattern":"repeated","visualization_type":[["area_chart"]]}],"coOccurrence":[["matrix","area_chart",["coOccurrence"]]],"year":2020,"conference":["VAST"],"authors":["Takanori Fujiwara","Shilpika","Naohisa Sakamoto","Jorji Nonaka","Keiji Yamamoto","Kwan-Liu Ma"],"title":"A Visual Analytics Framework for Reviewing Multivariate Time-Series Data with Dimensionality Reduction","doi":"10.1109/TVCG.2020.3028889","abstract":"Data-driven problem solving in many real-world applications involves analysis of time-dependent multivariate data, for which dimensionality reduction (DR) methods are often used to uncover the intrinsic structure and features of the data. However, DR is usually applied to a subset of data that is either single-time-point multivariate or univariate time-series, resulting in the need to manually examine and correlate the DR results out of different data subsets. When the number of dimensions is large either in terms of the number of time points or attributes, this manual task becomes too tedious and infeasible. In this paper, we present MulTiDR, a new DR framework that enables processing of time-dependent multivariate data as a whole to provide a comprehensive overview of the data. With the framework, we employ DR in two steps. When treating the instances, time points, and attributes of the data as a 3D array, the first DR step reduces the three axes of the array to two, and the second DR step visualizes the data in a lower-dimensional space. In addition, by coupling with a contrastive learning method and interactive visualizations, our framework enhances analysts\' ability to interpret DR results. We demonstrate the effectiveness of our framework with four case studies using real-world datasets.","keywords":"Multivariate time-series, tensor, data cube, dimensionality reduction, interpretability, visual analytics.","caption":"Fig. 5: Case study 1. (TDR) shows similarity of each week\u2019s air quality measures. (SI, FC, PM) are the SI, FC, PM views after selecting Clusters 1 and 2 in the TDR view, respectively. (HC) shows the HC views when selecting \u201cNO2\u201d and \u201cOzone\u201d form (FC). ","img_size":{"width":984,"height":654},"subfigures":[{"x":8.833746611770072,"y":10.206943338320135,"width":965.4394978754731,"height":638.9459230125808,"type":"interface","id":"interface-0"}],"visualizations":[{"x":596.0584206079111,"y":431.313150736516,"width":379.48301563269183,"height":219.2651720497557,"type":"area_chart","id":"area_chart-3"},{"x":5.930812723147554,"y":544.1305728073173,"width":579.2144581200487,"height":106.18633138178744,"type":"bar_chart","id":"bar_chart-4"},{"x":10.36138912512709,"y":433.5364570041009,"width":574.8183498210176,"height":106.72906411530226,"type":"bar_chart","id":"bar_chart-5"},{"x":408.31205637238907,"y":9.971006749380336,"width":564.7648481938058,"height":411.62588439857916,"type":"heatmap","id":"heatmap-1"},{"x":407.4278477592896,"y":9.975158124625183,"width":566.5332654200042,"height":413.4041848778297,"type":"matrix","id":"matrix-0"},{"x":12.054398756041211,"y":10.714812651097306,"width":389.25851475812965,"height":411.0315742100151,"type":"scatterplot","id":"scatterplot-2"}],"relations":[{"vislist":[{"vislist":["matrix-0"],"relation":null,"id":"group-0"}],"relation":"repeated","id":"relation-0"},{"vislist":[{"vislist":["area_chart-3"],"relation":null,"id":"group-1"}],"relation":"repeated","id":"relation-1"}]},"3326_7":{"comp":[["area_chart","area_chart",["repeated"]],["bar_chart","bar_chart",["mirrored"]]],"visType":["area_chart","bar_chart"],"compType":["repeated","mirrored"],"compressed_tree":[{"composite_pattern":"repeated","visualization_type":[["area_chart"]]},{"composite_pattern":"mirrored","visualization_type":[["bar_chart"]]}],"coOccurrence":[["area_chart","bar_chart",["coOccurrence"]]],"year":2020,"conference":["VAST"],"authors":["Takanori Fujiwara","Shilpika","Naohisa Sakamoto","Jorji Nonaka","Keiji Yamamoto","Kwan-Liu Ma"],"title":"A Visual Analytics Framework for Reviewing Multivariate Time-Series Data with Dimensionality Reduction","doi":"10.1109/TVCG.2020.3028889","abstract":"Data-driven problem solving in many real-world applications involves analysis of time-dependent multivariate data, for which dimensionality reduction (DR) methods are often used to uncover the intrinsic structure and features of the data. However, DR is usually applied to a subset of data that is either single-time-point multivariate or univariate time-series, resulting in the need to manually examine and correlate the DR results out of different data subsets. When the number of dimensions is large either in terms of the number of time points or attributes, this manual task becomes too tedious and infeasible. In this paper, we present MulTiDR, a new DR framework that enables processing of time-dependent multivariate data as a whole to provide a comprehensive overview of the data. With the framework, we employ DR in two steps. When treating the instances, time points, and attributes of the data as a 3D array, the first DR step reduces the three axes of the array to two, and the second DR step visualizes the data in a lower-dimensional space. In addition, by coupling with a contrastive learning method and interactive visualizations, our framework enhances analysts\' ability to interpret DR results. We demonstrate the effectiveness of our framework with four case studies using real-world datasets.","keywords":"Multivariate time-series, tensor, data cube, dimensionality reduction, interpretability, visual analytics.","caption":"Fig. 8: Case study 3-1. (TDR) shows similarities of the students based on their node features obtained with DeepGL [44]. (SI) draws a node-link diagram of the entire contact network. (FC, PM) are the FC and PM views after selecting four clusters from (TDR). (HC) shows the HC views after selecting two different node features from (FC). ","img_size":{"width":984,"height":825},"subfigures":[{"x":7.584977771958703,"y":10.63611961136335,"width":963.1961569136366,"height":808.2352459899213,"type":"single","id":"single-0"}],"visualizations":[{"x":756.7425459748509,"y":505.9596781445373,"width":213.06128614471112,"height":312.2846310116251,"type":"area_chart","id":"area_chart-2"},{"x":7.635371230045502,"y":506.39827631427715,"width":732.1059807571675,"height":158.15293744213338,"type":"bar_chart","id":"bar_chart-3"},{"x":514.4719343750241,"y":14.747663670939215,"width":451.96501249370925,"height":479.9807077728031,"type":"graph","id":"graph-1"},{"x":6.52429972399245,"y":695.3548585981364,"width":735.454901277763,"height":123.93552033878015,"type":"line_chart","id":"line_chart-4"},{"x":11.026380852339958,"y":17.7701330282891,"width":494.33457227228376,"height":476.18951166442673,"type":"scatterplot","id":"scatterplot-0"}],"relations":[{"vislist":[{"vislist":["area_chart-2"],"relation":null,"id":"group-0"}],"relation":"repeated","id":"relation-0"},{"vislist":[{"vislist":["bar_chart-3"],"relation":null,"id":"group-1"}],"relation":"mirrored","id":"relation-1"}]},"3326_9":{"comp":[["area_chart","area_chart",["repeated"]],["matrix","matrix",["repeated"]]],"visType":["area_chart","matrix"],"compType":["repeated"],"compressed_tree":[{"composite_pattern":"repeated","visualization_type":[["area_chart"]]},{"composite_pattern":"repeated","visualization_type":[["matrix"]]}],"coOccurrence":[["area_chart","matrix",["coOccurrence"]]],"year":2020,"conference":["VAST"],"authors":["Takanori Fujiwara","Shilpika","Naohisa Sakamoto","Jorji Nonaka","Keiji Yamamoto","Kwan-Liu Ma"],"title":"A Visual Analytics Framework for Reviewing Multivariate Time-Series Data with Dimensionality Reduction","doi":"10.1109/TVCG.2020.3028889","abstract":"Data-driven problem solving in many real-world applications involves analysis of time-dependent multivariate data, for which dimensionality reduction (DR) methods are often used to uncover the intrinsic structure and features of the data. However, DR is usually applied to a subset of data that is either single-time-point multivariate or univariate time-series, resulting in the need to manually examine and correlate the DR results out of different data subsets. When the number of dimensions is large either in terms of the number of time points or attributes, this manual task becomes too tedious and infeasible. In this paper, we present MulTiDR, a new DR framework that enables processing of time-dependent multivariate data as a whole to provide a comprehensive overview of the data. With the framework, we employ DR in two steps. When treating the instances, time points, and attributes of the data as a 3D array, the first DR step reduces the three axes of the array to two, and the second DR step visualizes the data in a lower-dimensional space. In addition, by coupling with a contrastive learning method and interactive visualizations, our framework enhances analysts\' ability to interpret DR results. We demonstrate the effectiveness of our framework with four case studies using real-world datasets.","keywords":"Multivariate time-series, tensor, data cube, dimensionality reduction, interpretability, visual analytics.","caption":"Fig. 10: Case study 4-1. (TDR) shows similarities of racks based on their temporal behaviors. (SI) visualizes the racks\u2019 physical coordinates in the K computer. (FC, PM) are the FC and PM views after selecting three outliers from (TDR). (HC) shows the HC views after selecting three different timestamps from (FC). ","img_size":{"width":981,"height":897},"subfigures":[{"x":12.8122152431285,"y":16.427740978156187,"width":957.8273785753621,"height":872.7210330892063,"type":"single","id":"single-0"}],"visualizations":[{"x":126.76873580020529,"y":496.0317564098987,"width":736.0438601152542,"height":145.0789084547373,"type":"area_chart","id":"area_chart-2"},{"x":6.708259588109345,"y":771.8806977137292,"width":962.6798627005438,"height":118.99887649388951,"type":"area_chart","id":"area_chart-4"},{"x":12.792778903365909,"y":637.5443864607728,"width":954.1885376624581,"height":129.15083119915448,"type":"line_chart","id":"line_chart-3"},{"x":514.0520848061935,"y":15.4137463515239,"width":450.613069896203,"height":474.103248073221,"type":"matrix","id":"matrix-1"},{"x":16.206901829197207,"y":10.02390715125018,"width":487.6460927572951,"height":472.6307621230266,"type":"scatterplot","id":"scatterplot-0"}],"relations":[{"vislist":[{"vislist":["area_chart-2"],"relation":null,"id":"group-0"}],"relation":"repeated","id":"relation-0"},{"vislist":[{"vislist":["matrix-1"],"relation":null,"id":"group-1"}],"relation":"repeated","id":"relation-1"}]},"3326_10":{"comp":[["donut_chart","donut_chart",["repeated"]]],"visType":["donut_chart"],"compType":["repeated"],"compressed_tree":[{"composite_pattern":"repeated","visualization_type":[["donut_chart"]]}],"coOccurrence":[["donut_chart","donut_chart",["coOccurrence"]]],"year":2020,"conference":["VAST"],"authors":["Takanori Fujiwara","Shilpika","Naohisa Sakamoto","Jorji Nonaka","Keiji Yamamoto","Kwan-Liu Ma"],"title":"A Visual Analytics Framework for Reviewing Multivariate Time-Series Data with Dimensionality Reduction","doi":"10.1109/TVCG.2020.3028889","abstract":"Data-driven problem solving in many real-world applications involves analysis of time-dependent multivariate data, for which dimensionality reduction (DR) methods are often used to uncover the intrinsic structure and features of the data. However, DR is usually applied to a subset of data that is either single-time-point multivariate or univariate time-series, resulting in the need to manually examine and correlate the DR results out of different data subsets. When the number of dimensions is large either in terms of the number of time points or attributes, this manual task becomes too tedious and infeasible. In this paper, we present MulTiDR, a new DR framework that enables processing of time-dependent multivariate data as a whole to provide a comprehensive overview of the data. With the framework, we employ DR in two steps. When treating the instances, time points, and attributes of the data as a 3D array, the first DR step reduces the three axes of the array to two, and the second DR step visualizes the data in a lower-dimensional space. In addition, by coupling with a contrastive learning method and interactive visualizations, our framework enhances analysts\' ability to interpret DR results. We demonstrate the effectiveness of our framework with four case studies using real-world datasets.","keywords":"Multivariate time-series, tensor, data cube, dimensionality reduction, interpretability, visual analytics.","caption":"Fig. 11: Case study 4-2. (TDR) shows similarities of timestamps based on behaviors of racks at the corresponding time. (SI) informs the selected timestamps with a clock-based visualization. We show more information on Cluster 8 in the FC, PM, and HC views (FC, PM, HC). ","img_size":{"width":984,"height":635},"subfigures":[{"x":8.77632571272069,"y":8.18658903420089,"width":965.5802413587929,"height":622.0962196407261,"type":"single","id":"single-0"}],"visualizations":[{"x":728.1162755023809,"y":355.95653442403324,"width":249.03297633761574,"height":271.2262925580541,"type":"area_chart","id":"area_chart-2"},{"x":8.511051402890878,"y":508.77522101952263,"width":708.3291280630165,"height":119.25641804259408,"type":"area_chart","id":"area_chart-4"},{"x":427.1211098979353,"y":10.794949969441936,"width":545.5052983713969,"height":339.93404309620854,"type":"donut_chart","id":"donut_chart-1"},{"x":8.522173551500195,"y":358.06347065045,"width":712.6466282143086,"height":149.80839569168873,"type":"line_chart","id":"line_chart-3"},{"x":6.561773160980508,"y":9.935039070693549,"width":410.1814709305355,"height":340.7856869350861,"type":"scatterplot","id":"scatterplot-0"}],"relations":[{"vislist":[{"vislist":["donut_chart-1"],"relation":null,"id":"group-0"}],"relation":"repeated","id":"relation-0"}]},"3327_0":{"comp":[["donut_chart","donut_chart",["repeated"]],["bar_chart","bar_chart",["mirrored"]]],"visType":["donut_chart","bar_chart"],"compType":["repeated","mirrored"],"compressed_tree":[{"composite_pattern":"repeated","visualization_type":[["donut_chart"]]},{"composite_pattern":"mirrored","visualization_type":[["bar_chart"]]}],"coOccurrence":[["donut_chart","bar_chart",["coOccurrence"]]],"year":2020,"conference":["VAST"],"authors":["Tiankai Xie","Yuxin Ma","Hanghang Tong","My T. Thai","Ross Maciejewski"],"title":"Auditing the Sensitivity of Graph-based Ranking with Visual Analytics","doi":"10.1109/TVCG.2020.3028958","abstract":"Graph mining plays a pivotal role across a number of disciplines, and a variety of algorithms have been developed to answer who/what type questions. For example, what items shall we recommend to a given user on an e-commerce platform? The answers to such questions are typically returned in the form of a ranked list, and graph-based ranking methods are widely used in industrial information retrieval settings. However, these ranking algorithms have a variety of sensitivities, and even small changes in rank can lead to vast reductions in product sales and page hits. As such, there is a need for tools and methods that can help model developers and analysts explore the sensitivities of graph ranking algorithms with respect to perturbations within the graph structure. In this paper, we present a visual analytics framework for explaining and exploring the sensitivity of any graph-based ranking algorithm by performing perturbation-based what-if analysis. We demonstrate our framework through three case studies inspecting the sensitivity of two classic graph-based ranking algorithms (PageRank and HITS) as applied to rankings in political news media and social networks.","keywords":"Graph-based ranking, sensitivity analysis, visual analytics","caption":"Fig. 1. Sensitivity analysis of HITS on political blogs. (1) A prede\ufb01ned rule is set to exclude all perturbations that would cause the rankings of the top-5 blogs to decrease. (2) The blog liberaloasis.com has the largest in\ufb02uence under this constraint, and its removal can increase the rankings of the conservative blogs while decreasing the rankings of the liberal blogs. (3) The in\ufb02uence overview indicates that nearly 2/3 of the in\ufb02uenced nodes see a ranking increase. (4) The ranking change distribution view further shows that most of the ranking-increased nodes are conservative blogs and most of the ranking-decreased nodes are liberal blogs, from which the top-3 heavily in\ufb02uenced nodes are ranked 200th or below. (5) The top-k proportional view shows that the proportion of liberal blogs decreased from 82% to 77% in the top-100 due to the perturbation.(6, 7) The in\ufb02uence graph view implies that the removal of liberaloasis.com has a direct in\ufb02uence on the majority of the liberal nodes (including the top-3 in\ufb02uenced nodes), and as the in\ufb02uence distance increases, more conservative nodes are indirectly in\ufb02uenced. ","img_size":{"width":1820,"height":1031},"subfigures":[{"x":10.679516314525697,"y":9.078325475420899,"width":1795.8248639336753,"height":1011.4351013963562,"type":"interface","id":"interface-0"}],"visualizations":[{"x":1098.772799415783,"y":101.85120228220022,"width":707.6727730974882,"height":244.00309455419182,"type":"bar_chart","id":"bar_chart-2"},{"x":1405.8567865376592,"y":350.99048067532266,"width":395.3110916387372,"height":230.99985255082632,"type":"donut_chart","id":"donut_chart-3"},{"x":609.6501134194501,"y":111.33750262262635,"width":473.87691608655075,"height":231.45798148635797,"type":"polar_plot","id":"polar_plot-1"},{"x":9.882600270304449,"y":173.67170591338848,"width":575.3507494862145,"height":437.8051869752731,"type":"table","id":"table-0"},{"x":1410.6928883405817,"y":593.6925673407628,"width":395.27100376007184,"height":422.08875049011925,"type":"table","id":"table-4"},{"x":606.9628075781088,"y":349.40802988406114,"width":800.3220520085974,"height":666.4132961088275,"type":"table","id":"table-5"}],"relations":[{"vislist":[{"vislist":["donut_chart-3"],"relation":null,"id":"group-0"}],"relation":"repeated","id":"relation-0"},{"vislist":[{"vislist":["bar_chart-2"],"relation":null,"id":"group-1"}],"relation":"mirrored","id":"relation-1"}]},"3328_7":{"comp":[["scatterplot","scatterplot",["repeated"]]],"visType":["scatterplot"],"compType":["repeated"],"compressed_tree":[{"composite_pattern":"repeated","visualization_type":[["scatterplot"]]}],"coOccurrence":[["scatterplot","scatterplot",["coOccurrence"]]],"year":2020,"conference":["VAST"],"authors":["Jianping Kelvin Li","Kwan-Liu Ma"],"title":"P6: A Declarative Language for Integrating Machine Learning in Visual Analytics","doi":"10.1109/TVCG.2020.3030453","abstract":"We present P6, a declarative language for building high performance visual analytics systems through its support for specifying and integrating machine learning and interactive visualization methods. As data analysis methods based on machine learning and artificial intelligence continue to advance, a visual analytics solution can leverage these methods for better exploiting large and complex data. However, integrating machine learning methods with interactive visual analysis is challenging. Existing declarative programming libraries and toolkits for visualization lack support for coupling machine learning methods. By providing a declarative language for visual analytics, P6 can empower more developers to create visual analytics applications that combine machine learning and visualization methods for data analysis and problem solving. Through a variety of example applications, we demonstrate P6\'s capabilities and show the benefits of using declarative specifications to build visual analytics systems. We also identify and discuss the research opportunities and challenges for declarative visual analytics.","keywords":"visual analytics, interactive visualization, machine learning, toolkits, declarative speci\ufb01cation","caption":"Fig. 8. A visual analytics application for exploratory data analysis developed using P6\u2019s declarative language (A). The dashboard with the speci\ufb01ed visualizations and visual interface is shown in (B). A reactive programming approach (C) is used to allow the visual interface to automatically update the analysis results and visualizations. The speci\ufb01cation of interactions (D) allows users directly select data on the visualizations to better interpret and understand analysis results based on machine learning. ","img_size":{"width":1995,"height":768},"subfigures":[{"x":437.0414125238952,"y":10.044339668052368,"width":1139.7544851210698,"height":752.257699695349,"type":"interface","id":"interface-0"}],"visualizations":[{"x":661.7699190599714,"y":437.6766661858092,"width":872.0674951980761,"height":289.84549831958486,"type":"parallel_coordinate","id":"parallel_coordinate-1"},{"x":642.3854266317903,"y":54.10240922891568,"width":870.3630707008023,"height":373.3199186985124,"type":"scatterplot","id":"scatterplot-0"}],"relations":[{"vislist":[{"vislist":["scatterplot-0"],"relation":null,"id":"group-0"}],"relation":"repeated","id":"relation-0"}]},"3328_10":{"comp":[["line_chart","line_chart",["repeated"]]],"visType":["line_chart"],"compType":["repeated"],"compressed_tree":[{"composite_pattern":"repeated","visualization_type":[["line_chart"]]}],"coOccurrence":[["line_chart","line_chart",["coOccurrence"]]],"year":2020,"conference":["VAST"],"authors":["Jianping Kelvin Li","Kwan-Liu Ma"],"title":"P6: A Declarative Language for Integrating Machine Learning in Visual Analytics","doi":"10.1109/TVCG.2020.3030453","abstract":"We present P6, a declarative language for building high performance visual analytics systems through its support for specifying and integrating machine learning and interactive visualization methods. As data analysis methods based on machine learning and artificial intelligence continue to advance, a visual analytics solution can leverage these methods for better exploiting large and complex data. However, integrating machine learning methods with interactive visual analysis is challenging. Existing declarative programming libraries and toolkits for visualization lack support for coupling machine learning methods. By providing a declarative language for visual analytics, P6 can empower more developers to create visual analytics applications that combine machine learning and visualization methods for data analysis and problem solving. Through a variety of example applications, we demonstrate P6\'s capabilities and show the benefits of using declarative specifications to build visual analytics systems. We also identify and discuss the research opportunities and challenges for declarative visual analytics.","keywords":"visual analytics, interactive visualization, machine learning, toolkits, declarative speci\ufb01cation","caption":"Fig. 11. A visual analytics application developed by P6 for analyzing HPC time-series data. Clustering methods are applied to analyze the computing entities of an HPC application, in which the results are used for color encoding in the line charts to analyze the performance and temporal behaviors of each entity. ","img_size":{"width":981,"height":525},"subfigures":[{"x":5.298217097981362,"y":6.740817420542569,"width":966.1003341591917,"height":509.36706539833307,"type":"interface","id":"interface-0"}],"visualizations":[{"x":407.7227820252474,"y":32.32984807832129,"width":563.5936798183395,"height":432.64547384898,"type":"line_chart","id":"line_chart-1"},{"x":13.61548290676868,"y":29.13085215531249,"width":381.80394680102887,"height":466.7382956893748,"type":"scatterplot","id":"scatterplot-0"}],"relations":[{"vislist":[{"vislist":["line_chart-1"],"relation":null,"id":"group-0"}],"relation":"repeated","id":"relation-0"}]},"3330_3":{"comp":[["line_chart","line_chart",["repeated"]],["heatmap","heatmap",["repeated"]],["matrix","bar_chart",["stacked"]],["bar_chart","matrix",["stacked"]],["bar_chart","comb",["stacked"]],["comb","bar_chart",["stacked"]]],"visType":["line_chart","heatmap","matrix","bar_chart","comb"],"compType":["repeated","stacked"],"compressed_tree":[{"composite_pattern":"stacked","visualization_type":[["matrix","bar_chart"]]},{"composite_pattern":"repeated","visualization_type":[["line_chart"]]},{"composite_pattern":"stacked","visualization_type":[["bar_chart",{"composite_pattern":"repeated","visualization_type":[["heatmap"]]}]]}],"coOccurrence":[["matrix","bar_chart",["coOccurrence"]],["matrix","line_chart",["coOccurrence"]],["matrix","heatmap",["coOccurrence"]],["bar_chart","line_chart",["coOccurrence"]],["bar_chart","heatmap",["coOccurrence"]],["line_chart","heatmap",["coOccurrence"]]],"year":2020,"conference":["VAST"],"authors":["Xiao Xie","Jiachen Wang","Hongye Liang","Dazhen Deng","Shoubin Cheng","Hui Zhang","Wei Chen","Yingcai Wu"],"title":"PassVizor: Toward Better Understanding of the Dynamics of Soccer Passes","doi":"10.1109/TVCG.2020.3030359","abstract":"In soccer, passing is the most frequent interaction between players and plays a significant role in creating scoring chances. Experts are interested in analyzing players\' passing behavior to learn passing tactics, i.e., how players build up an attack with passing. Various approaches have been proposed to facilitate the analysis of passing tactics. However, the dynamic changes of a team\'s employed tactics over a match have not been comprehensively investigated. To address the problem, we closely collaborate with domain experts and characterize requirements to analyze the dynamic changes of a team\'s passing tactics. To characterize the passing tactic employed for each attack, we propose a topic-based approach that provides a high-level abstraction of complex passing behaviors. Based on the model, we propose a glyph-based design to reveal the multi-variate information of passing tactics within different phases of attacks, including player identity, spatial context, and formation. We further design and develop PassVizor, a visual analytics system, to support the comprehensive analysis of passing dynamics. With the system, users can detect the changing patterns of passing tactics and examine the detailed passing process for evaluating passing tactics. We invite experts to conduct analysis with PassVizor and demonstrate the usability of the system through an expert interview.","keywords":"Soccer Analysis, Passing Analysis","caption":"Fig. 4. System interface. The system comprises two views, namely, an evolution view (A) and a phase view (D). The evolution view provides a diagram to show a summarization of passing patterns (B) and a \ufb02ow (C) to show the temporal distribution of passing patterns over phases. Users can select a phase (C3) and the detailed information, including the passing process (D1) and statistics (D3, D4), can be seen in the phase view (D). ","img_size":{"width":2004,"height":1110},"subfigures":[{"x":43.52063906808165,"y":11.28884583715982,"width":1944.2587359186919,"height":1088.9384624426602,"type":"interface","id":"interface-0"}],"visualizations":[{"x":1718.7660411385184,"y":818.9294129733104,"width":256.343236487681,"height":269.20962549461944,"type":"bar_chart","id":"bar_chart-1"},{"x":300.9449798953636,"y":62.72065649093125,"width":1676.0961013060617,"height":88.51943007642942,"type":"bar_chart","id":"bar_chart-2"},{"x":60.538785916445335,"y":131.65987899045314,"width":92.77990494933975,"height":397.77694564198634,"type":"bar_chart","id":"bar_chart-4"},{"x":154.93509534838896,"y":143.86204847068106,"width":92.63709089231071,"height":383.9766215565794,"type":"heatmap","id":"heatmap-3"},{"x":968.4580978874421,"y":578.3582591831091,"width":740.5592189210934,"height":506.4595909488786,"type":"line_chart","id":"line_chart-0"},{"x":286.8125804410962,"y":149.20536739445876,"width":1681.3814241226064,"height":392.73067764661516,"type":"matrix","id":"matrix-5"},{"x":208.01122533435776,"y":616.8795934241919,"width":744.8075419560012,"height":459.4616312793527,"type":"others","id":"others-6"}],"relations":[{"vislist":[{"vislist":["matrix-5","bar_chart-2"],"relation":null,"id":"group-0"}],"relation":"stacked","id":"relation-0"},{"vislist":[{"vislist":["line_chart-0"],"relation":null,"id":"group-1"}],"relation":"repeated","id":"relation-1"},{"vislist":[{"vislist":["bar_chart-4",{"vislist":[{"vislist":["heatmap-3"],"relation":null,"id":"group-2"}],"relation":"repeated","id":"relation-2"}],"relation":null,"id":"group-3"}],"relation":"stacked","id":"relation-3"}]},"3332_0":{"comp":[["line_chart","line_chart",["repeated"]],["bar_chart","bar_chart",["repeated"]],["heatmap","scatterplot",["large_view"]]],"visType":["line_chart","bar_chart","heatmap","scatterplot"],"compType":["repeated","large_view"],"compressed_tree":[{"composite_pattern":"repeated","visualization_type":[["line_chart"]]},{"composite_pattern":"repeated","visualization_type":[["bar_chart"]]},{"composite_pattern":"large_view","visualization_type":[["heatmap"],["scatterplot"]]}],"coOccurrence":[["line_chart","bar_chart",["coOccurrence"]],["line_chart","heatmap",["coOccurrence"]],["line_chart","scatterplot",["coOccurrence"]],["bar_chart","heatmap",["coOccurrence"]],["bar_chart","scatterplot",["coOccurrence"]],["heatmap","scatterplot",["coOccurrence"]]],"year":2020,"conference":["VAST"],"authors":["Weikai Yang","Zhen Li","Mengchen Liu","Yafeng Lu","Kelei Cao","Ross Maciejewski","Shixia Liu"],"title":"Diagnosing Concept Drift with Visual Analytics","doi":"10.1109/VAST50239.2020.00007","abstract":"Concept drift is a phenomenon in which the distribution of a data stream changes over time in unforeseen ways, causing prediction models built on historical data to become inaccurate. While a variety of automated methods have been developed to identify when concept drift occurs, there is limited support for analysts who need to understand and correct their models when drift is detected. In this paper, we present a visual analytics method, DriftVis, to support model builders and analysts in the identification and correction of concept drift in streaming data. DriftVis combines a distribution-based drift detection method with a streaming scatterplot to support the analysis of drift caused by the distribution changes of data streams and to explore the impact of these changes on the model\'s accuracy. A quantitative experiment and two case studies on weather prediction and text classification have been conducted to demonstrate our proposed tool and illustrate how visual analytics can be used to support the detection, examination, and correction of concept drift.","keywords":" Concept drift, streaming data, change detection, scat-terplot, t-SNE.","caption":"Figure 1: DriftVis: A visual analytics system for detecting, explaining, and correcting for concept drift: (a) The stream-level visualization consists of a line chart for drift degree (A), a feature selection list (B), and a streaming scatterplot (C) to visualize the drift and data distribution change over time (e.g., density increases in G, H, and I); (b) The prediction-level visualization consists of a base learner view (D), a samples of interest view (E), and a performance view (F) to explore the impact of drift adaptation on the model\u2019s accuracy. ","img_size":{"width":2105,"height":925},"subfigures":[{"x":274.22205968344934,"y":9.923110919542102,"width":1821.0590253272821,"height":862.3504234734871,"type":"interface","id":"interface-0"}],"visualizations":[{"x":1420.6819933739368,"y":533.6020520551368,"width":667.3316474939959,"height":326.3356492070988,"type":"bar_chart","id":"bar_chart-5"},{"x":283.7415263184168,"y":695.8180828122441,"width":499.5991437372349,"height":167.3799291422751,"type":"heatmap","id":"heatmap-3"},{"x":274.7639324500231,"y":90.44215961350669,"width":827.629954381947,"height":349.9473168710695,"type":"line_chart","id":"line_chart-0"},{"x":1117.298610550886,"y":145.66893783390933,"width":260.31823285430187,"height":144.67023892555684,"type":"line_chart","id":"line_chart-1"},{"x":277.99836977980516,"y":447.1719829053622,"width":1099.672118262439,"height":424.8243980911928,"type":"scatterplot","id":"scatterplot-2"},{"x":1428.109505763348,"y":58.951455805775694,"width":663.6170642567749,"height":470.5665512835089,"type":"table","id":"table-4"}],"relations":[{"vislist":[{"vislist":["line_chart-1"],"relation":null,"id":"group-0"}],"relation":"repeated","id":"relation-0"},{"vislist":[{"vislist":["bar_chart-5"],"relation":null,"id":"group-1"}],"relation":"repeated","id":"relation-1"},{"vislist":[{"vislist":["heatmap-3"],"relation":null,"id":"group-2"},{"vislist":["scatterplot-2"],"relation":null,"id":"group-3"}],"relation":"large_view","id":"relation-2"}]},"3386_0":{"comp":[["scatterplot","scatterplot",["repeated"]],["glyph_based","glyph_based",["repeated"]]],"visType":["scatterplot","glyph_based"],"compType":["repeated"],"compressed_tree":[{"composite_pattern":"repeated","visualization_type":[["scatterplot"]]},{"composite_pattern":"repeated","visualization_type":[["glyph_based"]]}],"coOccurrence":[["scatterplot","glyph_based",["coOccurrence"]]],"year":2020,"conference":["SciVis"],"authors":["Xinyi Huang","Suphanut Jamonnak","Ye Zhao","Boyu Wang","Minh Hoai","Kevin Yager","Wei Xu"],"title":"Interactive Visual Study of Multiple Attributes Learning Model of X-Ray Scattering Images","doi":"10.1109/TVCG.2020.3030384","abstract":"Existing interactive visualization tools for deep learning are mostly applied to the training, debugging, and refinement of neural network models working on natural images. However, visual analytics tools are lacking for the specific application of x-ray image classification with multiple structural attributes. In this paper, we present an interactive system for domain scientists to visually study the multiple attributes learning models applied to x-ray scattering images. It allows domain scientists to interactively explore this important type of scientific images in embedded spaces that are defined on the model prediction output, the actual labels, and the discovered feature space of neural networks. Users are allowed to flexibly select instance images, their clusters, and compare them regarding the specified visual representation of attributes. The exploration is guided by the manifestation of model performance related to mutual relationships among attributes, which often affect the learning accuracy and effectiveness. The system thus supports domain scientists to improve the training dataset and model, find questionable attributes labels, and identify outlier images or spurious data clusters. Case studies and scientists feedback demonstrate its functionalities and usefulness.","keywords":"","caption":"Fig. 1. System interface: (A) Control panel. (B) Attribute panel. (C1) Embedded view in ACT (Actual attribute vector) space with a highlighted image group in red. (C2) Embedded view in FEA (Feature vector) space. (C3) Embedded view in PRD (Prediction vector) space. (D1) Group panel 1: a cluster view showing selected images as attribute \ufb02owers in two spatial clusters of PRD (C3). (D2) Group panel 2: a cluster view showing the images in two spatial clusters of FEA (C2). (E) Detail image view with ACT/PRD values. ","img_size":{"width":1825,"height":1295},"subfigures":[{"x":16.39691572878572,"y":20.201227525349097,"width":1797.5148254881467,"height":1263.44177729836,"type":"interface","id":"interface-0"}],"visualizations":[{"x":1068.1694172158268,"y":548.049678608598,"width":460.1859750126714,"height":253.73488334696304,"type":"glyph_based","id":"glyph_based-0"},{"x":1068.073724991445,"y":109.00856631675506,"width":456.83825483095325,"height":243.85618008521058,"type":"glyph_based","id":"glyph_based-1"},{"x":19.161554916916522,"y":56.74819858144859,"width":259.55324211466774,"height":859.5735453313839,"type":"scatterplot","id":"scatterplot-2"},{"x":274.6504330472154,"y":58.51239794047775,"width":288.288942002047,"height":859.5828395529487,"type":"scatterplot","id":"scatterplot-3"},{"x":563.4519613279413,"y":56.758372800646626,"width":252.16889390381996,"height":861.3220433628039,"type":"scatterplot","id":"scatterplot-4"}],"relations":[{"vislist":[{"vislist":["scatterplot-2","scatterplot-3","scatterplot-4"],"relation":null,"id":"group-0"}],"relation":"repeated","id":"relation-0"},{"vislist":[{"vislist":["glyph_based-0","glyph_based-1"],"relation":null,"id":"group-1"}],"relation":"repeated","id":"relation-1"}]},"3386_6":{"comp":[["parallel_coordinate","parallel_coordinate",["repeated"]]],"visType":["parallel_coordinate"],"compType":["repeated"],"compressed_tree":[{"composite_pattern":"repeated","visualization_type":[["parallel_coordinate"]]}],"coOccurrence":[["parallel_coordinate","parallel_coordinate",["coOccurrence"]]],"year":2020,"conference":["SciVis"],"authors":["Xinyi Huang","Suphanut Jamonnak","Ye Zhao","Boyu Wang","Minh Hoai","Kevin Yager","Wei Xu"],"title":"Interactive Visual Study of Multiple Attributes Learning Model of X-Ray Scattering Images","doi":"10.1109/TVCG.2020.3030384","abstract":"Existing interactive visualization tools for deep learning are mostly applied to the training, debugging, and refinement of neural network models working on natural images. However, visual analytics tools are lacking for the specific application of x-ray image classification with multiple structural attributes. In this paper, we present an interactive system for domain scientists to visually study the multiple attributes learning models applied to x-ray scattering images. It allows domain scientists to interactively explore this important type of scientific images in embedded spaces that are defined on the model prediction output, the actual labels, and the discovered feature space of neural networks. Users are allowed to flexibly select instance images, their clusters, and compare them regarding the specified visual representation of attributes. The exploration is guided by the manifestation of model performance related to mutual relationships among attributes, which often affect the learning accuracy and effectiveness. The system thus supports domain scientists to improve the training dataset and model, find questionable attributes labels, and identify outlier images or spurious data clusters. Case studies and scientists feedback demonstrate its functionalities and usefulness.","keywords":"","caption":"Fig. 6. Two parallel coordinates plots showing attribute measures of model performance with various metrics. ","img_size":{"width":984,"height":471},"subfigures":[{"x":9.021702646147656,"y":8.669132835759722,"width":967.3860077176265,"height":455.0909115719565,"type":"single","id":"single-0"}],"visualizations":[{"x":15.237889064903493,"y":34.840453096631244,"width":903.1831862674752,"height":205.0886786839648,"type":"parallel_coordinate","id":"parallel_coordinate-0"},{"x":10.914819720046081,"y":252.38936847894905,"width":907.4895805086809,"height":201.5241059548069,"type":"parallel_coordinate","id":"parallel_coordinate-1"}],"relations":[{"vislist":[{"vislist":["parallel_coordinate-0","parallel_coordinate-1"],"relation":null,"id":"group-0"}],"relation":"repeated","id":"relation-0"}]},"3386_8":{"comp":[["others","others",["repeated"]],["matrix","matrix",["repeated"]]],"visType":["others","matrix"],"compType":["repeated"],"compressed_tree":[{"composite_pattern":"repeated","visualization_type":[["others"]]},{"composite_pattern":"repeated","visualization_type":[["others"]]},{"composite_pattern":"repeated","visualization_type":[["matrix"]]}],"coOccurrence":[["others","matrix",["coOccurrence"]]],"year":2020,"conference":["SciVis"],"authors":["Xinyi Huang","Suphanut Jamonnak","Ye Zhao","Boyu Wang","Minh Hoai","Kevin Yager","Wei Xu"],"title":"Interactive Visual Study of Multiple Attributes Learning Model of X-Ray Scattering Images","doi":"10.1109/TVCG.2020.3030384","abstract":"Existing interactive visualization tools for deep learning are mostly applied to the training, debugging, and refinement of neural network models working on natural images. However, visual analytics tools are lacking for the specific application of x-ray image classification with multiple structural attributes. In this paper, we present an interactive system for domain scientists to visually study the multiple attributes learning models applied to x-ray scattering images. It allows domain scientists to interactively explore this important type of scientific images in embedded spaces that are defined on the model prediction output, the actual labels, and the discovered feature space of neural networks. Users are allowed to flexibly select instance images, their clusters, and compare them regarding the specified visual representation of attributes. The exploration is guided by the manifestation of model performance related to mutual relationships among attributes, which often affect the learning accuracy and effectiveness. The system thus supports domain scientists to improve the training dataset and model, find questionable attributes labels, and identify outlier images or spurious data clusters. Case studies and scientists feedback demonstrate its functionalities and usefulness.","keywords":"","caption":"Fig. 8. Studying two groups of images where attributes \u201cMany rings\u201d, \u201cRing\u201d, and \u201cStrong scattering\u201d co-exist. (G1) \u201cMany rings\u201d not detected; (G2) \u201cStrong scattering\u201d not detected. The image galleries and the FEA space are shown, together with the detail view of several images. ","img_size":{"width":1662,"height":1158},"subfigures":[{"x":11.106517488786672,"y":13.279265826014663,"width":1636.6222860872344,"height":1121.951163118432,"type":"interface","id":"interface-0"}],"visualizations":[{"x":37.88028778367291,"y":986.7786780490753,"width":1605.2274980437983,"height":142.96347208514877,"type":"matrix","id":"matrix-4"},{"x":689.3750266886167,"y":17.286149343295037,"width":424.0781592387618,"height":267.7185131167649,"type":"others","id":"others-1"},{"x":687.25738147237,"y":429.2501592505926,"width":317.5496869395731,"height":180.8708661295939,"type":"others","id":"others-2"},{"x":39.43530626911329,"y":843.390186822189,"width":1598.9527821377292,"height":140.28614503802402,"type":"others","id":"others-3"},{"x":16.830759481306185,"y":19.2877163576126,"width":664.6937452717506,"height":784.1004491744441,"type":"scatterplot","id":"scatterplot-0"}],"relations":[{"vislist":[{"vislist":["others-1","others-2"],"relation":null,"id":"group-0"}],"relation":"repeated","id":"relation-0"},{"vislist":[{"vislist":["others-3"],"relation":null,"id":"group-1"}],"relation":"repeated","id":"relation-1"},{"vislist":[{"vislist":["matrix-4"],"relation":null,"id":"group-2"}],"relation":"repeated","id":"relation-2"}]},"3386_9":{"comp":[["scatterplot","scatterplot",["repeated"]],["parallel_coordinate","parallel_coordinate",["repeated"]],["matrix","matrix",["repeated"]],["others","others",["repeated"]]],"visType":["scatterplot","parallel_coordinate","matrix","others"],"compType":["repeated"],"compressed_tree":[{"composite_pattern":"repeated","visualization_type":[["scatterplot"]]},{"composite_pattern":"repeated","visualization_type":[["parallel_coordinate"]]},{"composite_pattern":"repeated","visualization_type":[["matrix"]]},{"composite_pattern":"repeated","visualization_type":[["others"]]}],"coOccurrence":[["parallel_coordinate","parallel_coordinate",["coOccurrence"]]],"year":2020,"conference":["SciVis"],"authors":["Xinyi Huang","Suphanut Jamonnak","Ye Zhao","Boyu Wang","Minh Hoai","Kevin Yager","Wei Xu"],"title":"Interactive Visual Study of Multiple Attributes Learning Model of X-Ray Scattering Images","doi":"10.1109/TVCG.2020.3030384","abstract":"Existing interactive visualization tools for deep learning are mostly applied to the training, debugging, and refinement of neural network models working on natural images. However, visual analytics tools are lacking for the specific application of x-ray image classification with multiple structural attributes. In this paper, we present an interactive system for domain scientists to visually study the multiple attributes learning models applied to x-ray scattering images. It allows domain scientists to interactively explore this important type of scientific images in embedded spaces that are defined on the model prediction output, the actual labels, and the discovered feature space of neural networks. Users are allowed to flexibly select instance images, their clusters, and compare them regarding the specified visual representation of attributes. The exploration is guided by the manifestation of model performance related to mutual relationships among attributes, which often affect the learning accuracy and effectiveness. The system thus supports domain scientists to improve the training dataset and model, find questionable attributes labels, and identify outlier images or spurious data clusters. Case studies and scientists feedback demonstrate its functionalities and usefulness.","keywords":"","caption":"Fig. 9. Debugging the issue of the pre-trained ResNet model for two attributes BCC and FCC through the entire visualization elements.","img_size":{"width":1668,"height":1212},"subfigures":[{"x":730.8877833537007,"y":38.31795587690938,"width":662.9500937824718,"height":815.8571455184133,"type":"single","id":"single-0"}],"visualizations":[{"x":45.23706149989943,"y":1047.8192995793097,"width":1605.6575300013883,"height":151.03414283544453,"type":"matrix","id":"matrix-5"},{"x":53.39244247041805,"y":897.7392580450382,"width":1579.417949354051,"height":148.24204704812485,"type":"others","id":"others-4"},{"x":758.6411758059872,"y":41.59169595125577,"width":633.9201587613691,"height":810.965141756912,"type":"parallel_coordinate","id":"parallel_coordinate-3"},{"x":9.983772525445698,"y":31.74236078291312,"width":246.41421424286904,"height":820.7309537704538,"type":"scatterplot","id":"scatterplot-0"},{"x":263.5321653590061,"y":35.006823802929716,"width":237.41316700854443,"height":814.2020277304201,"type":"scatterplot","id":"scatterplot-1"},{"x":504.01207779337,"y":38.31795587690943,"width":224.7626244537085,"height":815.8571455184149,"type":"scatterplot","id":"scatterplot-2"}],"relations":[{"vislist":[{"vislist":["scatterplot-0","scatterplot-1","scatterplot-2"],"relation":null,"id":"group-0"}],"relation":"repeated","id":"relation-0"},{"vislist":[{"vislist":["parallel_coordinate-3"],"relation":null,"id":"group-1"}],"relation":"repeated","id":"relation-1"},{"vislist":[{"vislist":["matrix-5"],"relation":null,"id":"group-2"}],"relation":"repeated","id":"relation-2"},{"vislist":[{"vislist":["others-4"],"relation":null,"id":"group-3"}],"relation":"repeated","id":"relation-3"}]},"3382_0":{"comp":[["bar_chart","bar_chart",["repeated"]],["bar_chart","table",["nested"]],["others","scatterplot",["accompanied"]],["scatterplot","others",["accompanied"]]],"visType":["bar_chart","table","others","scatterplot"],"compType":["repeated","nested","accompanied"],"compressed_tree":[{"composite_pattern":"accompanied","visualization_type":[["others","scatterplot"]]},{"composite_pattern":"repeated","visualization_type":[["bar_chart"]]},{"composite_pattern":"nested","visualization_type":[["bar_chart"],["table"]]}],"coOccurrence":[["others","scatterplot",["coOccurrence"]],["others","bar_chart",["coOccurrence"]],["others","table",["coOccurrence"]],["scatterplot","bar_chart",["coOccurrence"]],["scatterplot","table",["coOccurrence"]],["bar_chart","table",["coOccurrence"]]],"year":2020,"conference":["SciVis"],"authors":["Mar\xeda Virginia Sabando","Pavol Ulbrich","Mat\xedas Selzer","Jan By\u0161ka","Jan Mi\u010dan","Ignacio Ponzoni","Axel J. Soto","Mar\xeda Luj\xe1n Ganuza"],"title":"ChemVA: Interactive Visual Analysis of Chemical Compound Similarity in Virtual Screening","doi":"10.1109/TVCG.2020.3030438","abstract":"In the modern drug discovery process, medicinal chemists deal with the complexity of analysis of large ensembles of candidate molecules. Computational tools, such as dimensionality reduction (DR) and classification, are commonly used to efficiently process the multidimensional space of features. These underlying calculations often hinder interpretability of results and prevent experts from assessing the impact of individual molecular features on the resulting representations. To provide a solution for scrutinizing such complex data, we introduce ChemVA, an interactive application for the visual exploration of large molecular ensembles and their features. Our tool consists of multiple coordinated views: Hexagonal view, Detail view, 3D view, Table view, and a newly proposed Difference view designed for the comparison of DR projections. These views display DR projections combined with biological activity, selected molecular features, and confidence scores for each of these projections. This conjunction of views allows the user to drill down through the dataset and to efficiently select candidate compounds. Our approach was evaluated on two case studies of finding structurally similar ligands with similar binding affinity to a target protein, as well as on an external qualitative evaluation. The results suggest that our system allows effective visual inspection and comparison of different high-dimensional molecular representations. Furthermore, ChemVA assists in the identification of candidate compounds while providing information on the certainty behind different molecular representations.","keywords":"Virtual screening, visual analysis, dimensionality reduction, coordinated views, cheminformatics.","caption":"Fig. 1: Overview of the ChemVA interface: a) Hexagonal view with an overview of a selected 2D projection, b) Detail view showing all data items, which are colored according to a selected feature, c) 3D view enabling the user to observe the structural similarities of selected compounds, d) Table view listing other important features of the compounds. All views are interactively linked. ","img_size":{"width":1601,"height":751},"subfigures":[{"x":13.536663658278798,"y":9.122839555563047,"width":1580.9037770397963,"height":735.0802847947167,"type":"interface","id":"interface-0"}],"visualizations":[{"x":22.503779944974124,"y":578.0418622269268,"width":1215.6568023544457,"height":87.82975224824293,"type":"bar_chart","id":"bar_chart-5"},{"x":16.852969659721058,"y":677.4085445056259,"width":1219.897517577326,"height":61.40425060676493,"type":"bar_chart","id":"bar_chart-6"},{"x":11.577520612457954,"y":46.572521233070304,"width":525.7700619787076,"height":502.49540900311274,"type":"others","id":"others-0"},{"x":539.9331251657015,"y":43.77950437558576,"width":536.6677414333757,"height":505.2567236538861,"type":"others","id":"others-1"},{"x":541.3183326548099,"y":42.40567210467327,"width":532.4851453856314,"height":509.41674772780914,"type":"scatterplot","id":"scatterplot-2"},{"x":1080.9509993897184,"y":31.221966525753924,"width":376.78623138538757,"height":519.072923096769,"type":"scivis","id":"scivis-4"},{"x":14.038554852224879,"y":676.1063311708155,"width":1221.2898039837419,"height":68.24575587267718,"type":"table","id":"table-7"}],"relations":[{"vislist":[{"vislist":["others-1","scatterplot-2"],"relation":null,"id":"group-0"}],"relation":"accompanied","id":"relation-0"},{"vislist":[{"vislist":["bar_chart-5"],"relation":null,"id":"group-1"}],"relation":"repeated","id":"relation-1"},{"vislist":[{"vislist":["bar_chart-6"],"relation":null,"id":"group-2"},{"vislist":["table-7"],"relation":null,"id":"group-3"}],"relation":"nested","id":"relation-2"}]},"3382_4":{"comp":[["bar_chart","bar_chart",["repeated"]],["bar_chart","table",["nested"]],["box_plot","table",["nested"]]],"visType":["bar_chart","table","box_plot"],"compType":["repeated","nested"],"compressed_tree":[{"composite_pattern":"nested","visualization_type":[["bar_chart","box_plot"],["table"]]},{"composite_pattern":"repeated","visualization_type":[["bar_chart"]]}],"coOccurrence":[["bar_chart","box_plot",["coOccurrence"]],["bar_chart","table",["coOccurrence"]],["box_plot","table",["coOccurrence"]]],"year":2020,"conference":["SciVis"],"authors":["Mar\xeda Virginia Sabando","Pavol Ulbrich","Mat\xedas Selzer","Jan By\u0161ka","Jan Mi\u010dan","Ignacio Ponzoni","Axel J. Soto","Mar\xeda Luj\xe1n Ganuza"],"title":"ChemVA: Interactive Visual Analysis of Chemical Compound Similarity in Virtual Screening","doi":"10.1109/TVCG.2020.3030438","abstract":"In the modern drug discovery process, medicinal chemists deal with the complexity of analysis of large ensembles of candidate molecules. Computational tools, such as dimensionality reduction (DR) and classification, are commonly used to efficiently process the multidimensional space of features. These underlying calculations often hinder interpretability of results and prevent experts from assessing the impact of individual molecular features on the resulting representations. To provide a solution for scrutinizing such complex data, we introduce ChemVA, an interactive application for the visual exploration of large molecular ensembles and their features. Our tool consists of multiple coordinated views: Hexagonal view, Detail view, 3D view, Table view, and a newly proposed Difference view designed for the comparison of DR projections. These views display DR projections combined with biological activity, selected molecular features, and confidence scores for each of these projections. This conjunction of views allows the user to drill down through the dataset and to efficiently select candidate compounds. Our approach was evaluated on two case studies of finding structurally similar ligands with similar binding affinity to a target protein, as well as on an external qualitative evaluation. The results suggest that our system allows effective visual inspection and comparison of different high-dimensional molecular representations. Furthermore, ChemVA assists in the identification of candidate compounds while providing information on the certainty behind different molecular representations.","keywords":"Virtual screening, visual analysis, dimensionality reduction, coordinated views, cheminformatics.","caption":"Fig. 5: The Table view. Each row corresponds to one compound and its selected features. The right side panel shows the statistical overview of the distribution of values across the dataset. ","img_size":{"width":984,"height":372},"subfigures":[{"x":3.323359898353339,"y":5.955801479504828,"width":973.0650411735277,"height":355.79661392004016,"type":"single","id":"single-0"}],"visualizations":[{"x":760.1030024957314,"y":7.443205270982898,"width":215.4377334904854,"height":351.91452684605747,"type":"bar_chart","id":"bar_chart-0"},{"x":7.780484979521255,"y":14.357807963230368,"width":751.4518076154529,"height":34.5148549333744,"type":"bar_chart","id":"bar_chart-1"},{"x":9.513650352137025,"y":48.341790223000665,"width":751.4572724290289,"height":49.731892205451864,"type":"bar_chart","id":"bar_chart-2"},{"x":10.34268985517142,"y":217.27265844433938,"width":744.59150008475,"height":121.15489540114442,"type":"bar_chart","id":"bar_chart-4"},{"x":9.507480808836245,"y":96.3325343453811,"width":749.7337137362275,"height":116.07966953019465,"type":"box_plot","id":"box_plot-3"},{"x":11.206253044694337,"y":338.72545292924286,"width":743.7323225954042,"height":24.689570001998472,"type":"box_plot","id":"box_plot-5"},{"x":7.768174759131941,"y":4.943191572313431,"width":748.0046324974237,"height":361.2471064200436,"type":"table","id":"table-6"}],"relations":[{"vislist":[{"vislist":["bar_chart-1","bar_chart-2","bar_chart-4","box_plot-3","box_plot-5"],"relation":null,"id":"group-0"},{"vislist":["table-6"],"relation":null,"id":"group-1"}],"relation":"nested","id":"relation-0"},{"vislist":[{"vislist":["bar_chart-0"],"relation":null,"id":"group-2"}],"relation":"repeated","id":"relation-1"}]},"3380_0":{"comp":[["matrix","matrix",["repeated"]],["area_chart","area_chart",["repeated"]],["area_chart","line_chart",["accompanied"]],["line_chart","area_chart",["accompanied"]],["others","map",["coordinated"]]],"visType":["matrix","area_chart","line_chart","others","map"],"compType":["repeated","accompanied","coordinated"],"compressed_tree":[{"composite_pattern":"repeated","visualization_type":[["matrix"]]},{"composite_pattern":"repeated","visualization_type":[["area_chart"]]},{"composite_pattern":"accompanied","visualization_type":[["area_chart","line_chart"]]},{"composite_pattern":"accompanied","visualization_type":[["line_chart","area_chart"]]},{"composite_pattern":"coordinated","visualization_type":[["others"],["map"]]}],"coOccurrence":[["matrix","area_chart",["coOccurrence"]],["matrix","line_chart",["coOccurrence"]],["matrix","others",["coOccurrence"]],["matrix","map",["coOccurrence"]],["area_chart","line_chart",["coOccurrence"]],["area_chart","others",["coOccurrence"]],["area_chart","map",["coOccurrence"]],["line_chart","others",["coOccurrence"]],["line_chart","map",["coOccurrence"]],["others","map",["coOccurrence"]]],"year":2020,"conference":["SciVis"],"authors":["Mingdong Zhang","Li Chen","Quan Li","Xiaoru Yuan","Junhai Yong"],"title":"Uncertainty-Oriented Ensemble Data Visualization and Exploration using Variable Spatial Spreading","doi":"10.1109/TVCG.2020.3030377","abstract":"As an important method of handling potential uncertainties in numerical simulations, ensemble simulation has been widely applied in many disciplines. Visualization is a promising and powerful ensemble simulation analysis method. However, conventional visualization methods mainly aim at data simplification and highlighting important information based on domain expertise instead of providing a flexible data exploration and intervention mechanism. Trial-and-error procedures have to be repeatedly conducted by such approaches. To resolve this issue, we propose a new perspective of ensemble data analysis using the attribute variable dimension as the primary analysis dimension. Particularly, we propose a variable uncertainty calculation method based on variable spatial spreading. Based on this method, we design an interactive ensemble analysis framework that provides a flexible interactive exploration of the ensemble data. Particularly, the proposed spreading curve view, the region stability heat map view, and the temporal analysis view, together with the commonly used 2D map view, jointly support uncertainty distribution perception, region selection, and temporal analysis, as well as other analysis requirements. We verify our approach by analyzing a real-world ensemble simulation dataset. Feedback collected from domain experts confirms the efficacy of our framework.","keywords":"Uncertainty visualization, ensemble visualization, spatial spreading, temporal analysis.","caption":"Fig. 1: Uncertainty-oriented ensemble data visualization framework interface: (A) The parameter setting panel provides control of the visualization parameters. (B) The region stability heat map view shows the stability of the selected region and provides region adjustment through direct clicking. (C) The 2D map view shows the features of the selected isovalues and integrates up-to-date visualization methods. (D) The temporal analysis view shows the temporal relationships of the features and supports temporal selection. (E) The spatial spreading curve view shows the spatial spreading of the variable bins globally (top) and locally (bottom). (F) The display control toolbar enables switching between different visualization methods. ","img_size":{"width":1826,"height":941},"subfigures":[{"x":23.34665078560771,"y":15.779748114808937,"width":1787.264345246213,"height":914.7410204235325,"type":"interface","id":"interface-0"}],"visualizations":[{"x":1367.1714231746487,"y":59.11375308639933,"width":441.3776573451665,"height":315.7529105812403,"type":"area_chart","id":"area_chart-0"},{"x":1362.2462654620847,"y":400.7655660401096,"width":431.9002328605903,"height":292.3795358828476,"type":"area_chart","id":"area_chart-1"},{"x":18.45187239813318,"y":459.70776253486235,"width":273.47931728429336,"height":470.6589629481257,"type":"heatmap","id":"heatmap-4"},{"x":1360.6414196443789,"y":400.7213460509571,"width":433.4992795035231,"height":289.24880390403536,"type":"line_chart","id":"line_chart-2"},{"x":323.91887722194303,"y":720.2144646926807,"width":1468.0783442017043,"height":208.78890118042463,"type":"line_chart","id":"line_chart-5"},{"x":327.1285826171535,"y":724.938001487631,"width":1464.8802233962324,"height":199.34182759052337,"type":"line_chart","id":"line_chart-6"},{"x":323.3836934958477,"y":64.79314582177281,"width":1016.5574687682796,"height":644.0167665863594,"type":"map","id":"map-7"},{"x":24.8540611615985,"y":458.05028032109806,"width":270.3388097122135,"height":467.53558346141995,"type":"matrix","id":"matrix-3"},{"x":328.18972279368967,"y":64.82909634454651,"width":1011.7773451500212,"height":648.7736234764875,"type":"others","id":"others-8"}],"relations":[{"vislist":[{"vislist":["matrix-3"],"relation":null,"id":"group-0"}],"relation":"repeated","id":"relation-0"},{"vislist":[{"vislist":["area_chart-0","area_chart-1"],"relation":null,"id":"group-1"}],"relation":"repeated","id":"relation-1"},{"vislist":[{"vislist":["area_chart-1","line_chart-2"],"relation":null,"id":"group-2"}],"relation":"accompanied","id":"relation-2"},{"vislist":[{"vislist":["line_chart-6","area_chart-1"],"relation":null,"id":"group-3"}],"relation":"accompanied","id":"relation-3"},{"vislist":[{"vislist":["others-8"],"relation":null,"id":"group-4"},{"vislist":["map-7"],"relation":null,"id":"group-5"}],"relation":"coordinated","id":"relation-4"}]},"3375_4":{"comp":[["bar_chart","bar_chart",["repeated"]],["bar_chart","glyph_based",["large_view"]]],"visType":["bar_chart","glyph_based"],"compType":["repeated","large_view"],"compressed_tree":[{"composite_pattern":"repeated","visualization_type":[["bar_chart"]]},{"composite_pattern":"large_view","visualization_type":[["bar_chart"],["glyph_based"]]}],"coOccurrence":[["bar_chart","glyph_based",["coOccurrence"]]],"year":2020,"conference":["SciVis"],"authors":["Keshav Dasu","Kwan-Liu Ma","Joyce Ma","Jennifer Frazier"],"title":"Sea of Genes:A Re\ufb02ection on Visualising Metagenomic Data for Museums","doi":"10.1109/TVCG.2020.3030412","abstract":"We examine the process of designing an exhibit to communicate scientific findings from a complex dataset and unfamiliar domain to the public in a science museum. Our exhibit sought to communicate new lessons based on scientific findings from the domain of metagenomics. This multi-user exhibit had three goals: (1) to inform the public about microbial communities and their daily cycles; (2) to link microbes\' activity to the concept of gene expression; (3) and to highlight scientists\' use of gene expression data to understand the role of microbes. To address these three goals, we derived visualization designs with three corresponding stories, each corresponding to a goal. We present three successive rounds of design and evaluation of our attempts to convey these goals. We could successfully present one story but had limited success with our second and third goals. This work presents a detailed account of an attempt to explain tightly coupled relationships through storytelling and animation in a multi-user, informal learning environment to a public with varying prior knowledge on the domain and identify lessons for future design.","keywords":"Narrative visualization, storytelling, animation, evaluation, user studies, informal learning environments","caption":"Fig. 5. (a) Final design of the Sea of Genes exhibit. (b) Legend containing information about Sun Harvesters and in the center is the activity gene showing the genes responsible for making sugar are being expressed.(c) Annotation showing what the Sun Harvester is doing. ","img_size":{"width":2006,"height":732},"subfigures":[{"x":6.161281623705386,"y":11.747911059529503,"width":1275.369798812458,"height":707.0485304846983,"type":"interface","id":"interface-0"}],"visualizations":[{"x":955.233795970888,"y":576.9391051639817,"width":297.2458469734858,"height":136.16858893001074,"type":"bar_chart","id":"bar_chart-1"},{"x":596.2520574115896,"y":574.9645313357222,"width":319.828784673684,"height":127.75594040043579,"type":"bar_chart","id":"bar_chart-2"},{"x":240.60383709820732,"y":581.7938945724635,"width":330.43643748954196,"height":138.35753741728513,"type":"bar_chart","id":"bar_chart-3"},{"x":243.5264719930051,"y":26.23266077762041,"width":1023.5105393800173,"height":686.5985619796694,"type":"glyph_based","id":"glyph_based-0"}],"relations":[{"vislist":[{"vislist":["bar_chart-1","bar_chart-2","bar_chart-3"],"relation":null,"id":"group-0"}],"relation":"repeated","id":"relation-0"},{"vislist":[{"vislist":["bar_chart-1","bar_chart-2","bar_chart-3"],"relation":null,"id":"group-3"},{"vislist":["glyph_based-0"],"relation":null,"id":"group-4"}],"relation":"large_view","id":"relation-1"}]},"3374_3":{"comp":[["area_chart","area_chart",["repeated"]],["scivis","scivis",["repeated"]]],"visType":["area_chart","scivis"],"compType":["repeated"],"compressed_tree":[{"composite_pattern":"repeated","visualization_type":[["area_chart"]]},{"composite_pattern":"repeated","visualization_type":[["scivis"]]}],"coOccurrence":[["area_chart","scivis",["coOccurrence"]]],"year":2020,"conference":["SciVis"],"authors":["Pepe Eulzer","Sabine Bauer","Francis Kilian","Kai Lawonn"],"title":"Visualization of Human Spine Biomechanics for Spinal Surgery","doi":"10.1109/TVCG.2020.3030388","abstract":"We propose a visualization application, designed for the exploration of human spine simulation data. Our goal is to support research in biomechanical spine simulation and advance efforts to implement simulation-backed analysis in surgical applications. Biomechanical simulation is a state-of-the-art technique for analyzing load distributions of spinal structures. Through the inclusion of patient-specific data, such simulations may facilitate personalized treatment and customized surgical interventions. Difficulties in spine modelling and simulation can be partly attributed to poor result representation, which may also be a hindrance when introducing such techniques into a clinical environment. Comparisons of measurements across multiple similar anatomical structures and the integration of temporal data make commonly available diagrams and charts insufficient for an intuitive and systematic display of results. Therefore, we facilitate methods such as multiple coordinated views, abstraction and focus and context to display simulation outcomes in a dedicated tool. By linking the result data with patient-specific anatomy, we make relevant parameters tangible for clinicians. Furthermore, we introduce new concepts to show the directions of impact force vectors, which were not accessible before. We integrated our toolset into a spine segmentation and simulation pipeline and evaluated our methods with both surgeons and biomechanical researchers. When comparing our methods against standard representations that are currently in use, we found increases in accuracy and speed in data exploration tasks. In a qualitative review, domain experts deemed the tool highly useful when dealing with simulation result data, which typically combines time-dependent patient movement and the resulting force distributions on spinal structures.","keywords":"Medical visualization, bioinformatics, coordinated views, focus and context, biomechanical simulation.","caption":"Fig. 3. Superposed line plots (1), a typical representation that has been used to analyze simulation results. Meaningful comparisons are hardly possible, even with only \ufb01ve spinal discs displayed. The same data set can be visualized with our proposed tool (3). In this example, the main window (B) shows area charts of computed parameters over time for eight spinal discs. Each chart is associated with corresponding patient anatomy. The black line highlights the selected time step and shows the plot values. Options, such as spacing between plots, can be chosen from the control panel (A). The animation window (C) links the chosen point in time with the performed movement (2). ","img_size":{"width":2002,"height":847},"subfigures":[{"x":689.8875269775708,"y":8.620957391837099,"width":1304.201669982813,"height":778.9145116238413,"type":"interface","id":"interface-0"}],"visualizations":[{"x":1185.0614815498132,"y":106.15498351348522,"width":700.2392063068613,"height":615.256073672627,"type":"area_chart","id":"area_chart-0"},{"x":1031.5666801779942,"y":19.10440255453821,"width":156.07084929194144,"height":745.189146271427,"type":"scivis","id":"scivis-1"},{"x":690.2517224632152,"y":472.72922824686054,"width":328.35916644302955,"height":316.721583105771,"type":"scivis","id":"scivis-2"}],"relations":[{"vislist":[{"vislist":["area_chart-0"],"relation":null,"id":"group-0"}],"relation":"repeated","id":"relation-0"},{"vislist":[{"vislist":["scivis-1"],"relation":null,"id":"group-1"}],"relation":"repeated","id":"relation-1"}]},"3360_0":{"comp":[["scatterplot","scatterplot",["repeated"]]],"visType":["scatterplot"],"compType":["repeated"],"compressed_tree":[{"composite_pattern":"repeated","visualization_type":[["scatterplot"]]}],"coOccurrence":[["scatterplot","scatterplot",["coOccurrence"]]],"year":2020,"conference":["SciVis"],"authors":["Juraj Palenik","Thomas Spengler","Helwig Hauser"],"title":"IsoTrotter: Visually Guided Empirical Modelling of Atmospheric Convection","doi":"10.1109/TVCG.2020.3030389","abstract":"Empirical models, fitted to data from observations, are often used in natural sciences to describe physical behaviour and support discoveries. However, with more complex models, the regression of parameters quickly becomes insufficient, requiring a visual parameter space analysis to understand and optimize the models. In this work, we present a design study for building a model describing atmospheric convection. We present a mixed-initiative approach to visually guided modelling, integrating an interactive visual parameter space analysis with partial automatic parameter optimization. Our approach includes a new, semi-automatic technique called IsoTrotting, where we optimize the procedure by navigating along isocontours of the model. We evaluate the model with unique observational data of atmospheric convection based on flight trajectories of paragliders.","keywords":"visual parameter space exploration, scienti\ufb01c modelling, atmospheric convection","caption":"Fig. 1: The convection analysis is enabled by two main views. In the left view we provide a tool for analysing the parameter-space of the model, as well as for comparing the model results to data from observations. We allow adjustment of the model parameters on the far left; the greyed-out parameter is under automatic control by the anchor point. A gallery of segmented thermals is at the bottom. On the right, a 3D view showing tracks of paragliding \ufb02ights presents an instance of a thermal in its environment. ","img_size":{"width":1816,"height":594},"subfigures":[{"x":5.144653590127927,"y":6.3408068932653485,"width":1006.3899104179,"height":576.0352830379634,"type":"interface","id":"interface-0"}],"visualizations":[{"x":203.68276366133514,"y":33.375971638528924,"width":353.0322104237214,"height":410.2912182928179,"type":"line_chart","id":"line_chart-1"},{"x":580.7377314434796,"y":20.774504992620383,"width":422.2600029297729,"height":424.2791122831173,"type":"line_chart","id":"line_chart-2"},{"x":193.26255393229903,"y":467.4399042917607,"width":815.9761570168387,"height":110.92606042051597,"type":"scatterplot","id":"scatterplot-0"}],"relations":[{"vislist":[{"vislist":["scatterplot-0"],"relation":null,"id":"group-0"}],"relation":"repeated","id":"relation-0"}]},"3360_5":{"comp":[["scatterplot","scatterplot",["repeated"]]],"visType":["scatterplot"],"compType":["repeated"],"compressed_tree":[{"composite_pattern":"repeated","visualization_type":[["scatterplot"]]}],"coOccurrence":[["scatterplot","scatterplot",["coOccurrence"]]],"year":2020,"conference":["SciVis"],"authors":["Juraj Palenik","Thomas Spengler","Helwig Hauser"],"title":"IsoTrotter: Visually Guided Empirical Modelling of Atmospheric Convection","doi":"10.1109/TVCG.2020.3030389","abstract":"Empirical models, fitted to data from observations, are often used in natural sciences to describe physical behaviour and support discoveries. However, with more complex models, the regression of parameters quickly becomes insufficient, requiring a visual parameter space analysis to understand and optimize the models. In this work, we present a design study for building a model describing atmospheric convection. We present a mixed-initiative approach to visually guided modelling, integrating an interactive visual parameter space analysis with partial automatic parameter optimization. Our approach includes a new, semi-automatic technique called IsoTrotting, where we optimize the procedure by navigating along isocontours of the model. We evaluate the model with unique observational data of atmospheric convection based on flight trajectories of paragliders.","keywords":"visual parameter space exploration, scienti\ufb01c modelling, atmospheric convection","caption":"Fig. 6: Variation of the model with respect to changing a selected parameter. On left the variation of temperature anomaly is shown as opposed to the variation of the surface temperature on the right. The increase of the parameter is depicted in red, the decrease in blue. ","img_size":{"width":984,"height":588},"subfigures":[{"x":7.015258121121414,"y":8.365483386437178,"width":486.4627622431163,"height":572.8753370483598,"type":"single","id":"single-0"}],"visualizations":[{"x":173.1489639182462,"y":37.07163788911073,"width":306.1455962973368,"height":418.4715238188475,"type":"line_chart","id":"line_chart-0"},{"x":169.96822726200833,"y":461.8342538710421,"width":319.4506607274286,"height":109.17338140976214,"type":"scatterplot","id":"scatterplot-1"}],"relations":[{"vislist":[{"vislist":["scatterplot-1"],"relation":null,"id":"group-0"}],"relation":"repeated","id":"relation-0"}]},"3358_0":{"comp":[["line_chart","line_chart",["repeated"]]],"visType":["line_chart"],"compType":["repeated"],"compressed_tree":[{"composite_pattern":"repeated","visualization_type":[["line_chart"]]}],"coOccurrence":[["line_chart","line_chart",["coOccurrence"]]],"year":2020,"conference":["SciVis"],"authors":["Liang Zhou","Chris R. Johnson","Daniel Weiskopf"],"title":"Data-Driven Space-Filling Curves","doi":"10.1109/TVCG.2020.3030473","abstract":"We propose a data-driven space-filling curve method for 2D and 3D visualization. Our flexible curve traverses the data elements in the spatial domain in a way that the resulting linearization better preserves features in space compared to existing methods. We achieve such data coherency by calculating a Hamiltonian path that approximately minimizes an objective function that describes the similarity of data values and location coherency in a neighborhood. Our extended variant even supports multiscale data via quadtrees and octrees. Our method is useful in many areas of visualization including multivariate or comparative visualization ensemble visualization of 2D and 3D data on regular grids or multiscale visual analysis of particle simulations. The effectiveness of our method is evaluated with numerical comparisons to existing techniques and through examples of ensemble and multivariate datasets.","keywords":"Space-\ufb01lling curves, comparative visualization, ensemble visualization, multivariate visualization","caption":"Fig. 1. Visualizations of an ensemble of volumetric data. The key idea is to employ a mapping from 3D space (as in the volume renderings) to 1D space via space-\ufb01lling curves, which then allows us to show boxplots of the data distributions. The ensemble is generated by sampling from Gaussian distributions of data values in the nucleon data with varying extents of uncertainty. The boxplots of the ensemble linearized with the Peano-Hilbert curve (bottom) do not preserve the coherency of 3D features\u2014the small torus structure of high intensity cannot be readily identi\ufb01ed. In contrast, our data-driven space-\ufb01lling curve method (top) preserves features from 3D even in the 1D linearized representation as high intensities are more concentrated. This observation is con\ufb01rmed by brushing-and-linking\u2014the torus could be covered by one brush and its surroundings with two brushes with our method (see the volume rendering on the right and the yellow and purple regions in \u201cData-driven space-\ufb01lling curve\u201d), whereas multiple brushes are required by the Peano-Hilbert curve (yellow and purple regions in \u201cPeano-Hilbert curve\u201d). ","img_size":{"width":1717,"height":444},"subfigures":[{"x":7.410677153454842,"y":21.496075758823093,"width":1396.6379831835716,"height":419.71072210604785,"type":"interface","id":"interface-0"}],"visualizations":[{"x":526.3751275581152,"y":50.28810736308426,"width":883.8522807828178,"height":379.7427922465331,"type":"line_chart","id":"line_chart-1"},{"x":18.198481920439374,"y":44.30291726049482,"width":493.2348420566829,"height":387.1732965801244,"type":"scivis","id":"scivis-0"}],"relations":[{"vislist":[{"vislist":["line_chart-1"],"relation":null,"id":"group-0"}],"relation":"repeated","id":"relation-0"}]},"3357_13":{"comp":[["heatmap","heatmap",["repeated"]]],"visType":["heatmap"],"compType":["repeated"],"compressed_tree":[{"composite_pattern":"repeated","visualization_type":[["heatmap"]]}],"coOccurrence":[["heatmap","heatmap",["coOccurrence"]]],"year":2020,"conference":["SciVis"],"authors":["P. Nardini","M. Chen","R. Bujack","M. Bottinger","G. Scheuermann"],"title":"A Testing Environment for Continuous Colormaps","doi":"10.1109/TVCG.2020.3028955","abstract":"Many computer science disciplines (e.g., combinatorial optimization, natural language processing, and information retrieval) use standard or established test suites for evaluating algorithms. In visualization, similar approaches have been adopted in some areas (e.g., volume visualization), while user testimonies and empirical studies have been the dominant means of evaluation in most other areas, such as designing colormaps. In this paper, we propose to establish a test suite for evaluating the design of colormaps. With such a suite, the users can observe the effects when different continuous colormaps are applied to planar scalar fields that may exhibit various characteristic features, such as jumps, local extrema, ridge or valley lines, different distributions of scalar values, different gradients, different signal frequencies, different levels of noise, and so on. The suite also includes an expansible collection of real-world data sets including the most popular data for colormap testing in the visualization literature. The test suite has been integrated into a web-based application for creating continuous colormaps (https://ccctool.com/), facilitating close inter-operation between design and evaluation processes. This new facility complements traditional evaluation methods such as user testimonies and empirical studies.","keywords":"Testing Environment, Color Perception, Scalar Analysis","caption":"Fig. 13. This \ufb01gure shows a screenshot of the test evaluation in the CCC-Tool. We present statistics of the Value Difference Field, Color Difference Field, and Subtraction Field. On the right side are two visualizations of the test-function. One color mapping is done with a grey-scaled colormap and the other one with the se- lected colormap for the analysis. Below are three color mapping im- ages of the Value Difference Field, Color Difference Field, and Subtraction Field. All \ufb01ve images are zoomable and change interac- tively. As a sixth part, the pixel observer shows in combination with the table the pixel-neighborhood-information of the three \ufb01elds. ","img_size":{"width":931,"height":489},"subfigures":[{"x":8.54566767570024,"y":6.749579273705777,"width":918.6421425884676,"height":474.8239317208728,"type":"interface","id":"interface-0"}],"visualizations":[{"x":444.1031478999043,"y":56.53967935828259,"width":306.3987790338682,"height":334.8345957066823,"type":"heatmap","id":"heatmap-1"},{"x":29.876569599069008,"y":347.5172250400704,"width":366.2091006064996,"height":113.6149845069885,"type":"table","id":"table-0"}],"relations":[{"vislist":[{"vislist":["heatmap-1"],"relation":null,"id":"group-0"}],"relation":"repeated","id":"relation-0"}]},"3353_0":{"comp":[["bar_chart","bar_chart",["repeated"]]],"visType":["bar_chart"],"compType":["repeated"],"compressed_tree":[{"composite_pattern":"repeated","visualization_type":[["bar_chart"]]},{"composite_pattern":"repeated","visualization_type":[["bar_chart"]]}],"coOccurrence":[["bar_chart","bar_chart",["coOccurrence"]]],"year":2020,"conference":["VAST"],"authors":["Johannes Knittel","Andres Lalama","Steffen Koch","Thomas Ertl"],"title":"Visual Neural Decomposition to Explain Multivariate Data Sets","doi":"10.1109/TVCG.2020.3030420","abstract":"Investigating relationships between variables in multi-dimensional data sets is a common task for data analysts and engineers. More specifically, it is often valuable to understand which ranges of which input variables lead to particular values of a given target variable. Unfortunately, with an increasing number of independent variables, this process may become cumbersome and time-consuming due to the many possible combinations that have to be explored. In this paper, we propose a novel approach to visualize correlations between input variables and a target output variable that scales to hundreds of variables. We developed a visual model based on neural networks that can be explored in a guided way to help analysts find and understand such correlations. First, we train a neural network to predict the target from the input variables. Then, we visualize the inner workings of the resulting model to help understand relations within the data set. We further introduce a new regularization term for the backpropagation algorithm that encourages the neural network to learn representations that are easier to interpret visually. We apply our method to artificial and real-world data sets to show its utility.","keywords":"Visual Analytics, Multivariate Data Analysis, Machine Learning","caption":"Fig. 1. Visual Neural Decomposition of a chip testing measurement data set with the goal to identify cases in which the target variable (here: jitter) exhibits high values. Each node visualizes parts of the data set depending on its activation.","img_size":{"width":1818,"height":884},"subfigures":[{"x":6.151608765288616,"y":9.1048988493126,"width":1801.7353909266833,"height":861.8321708299893,"type":"interface","id":"interface-0"}],"visualizations":[{"x":148.35347271943158,"y":137.31925581379056,"width":1651.1837228535542,"height":388.2298442010489,"type":"bar_chart","id":"bar_chart-2"},{"x":5.089954648072958,"y":64.97545037811079,"width":128.86293388703473,"height":316.5930205569388,"type":"bar_chart","id":"bar_chart-3"},{"x":148.42943746351452,"y":616.1078995069028,"width":1655.8425588577009,"height":255.89021441087823,"type":"parallel_coordinate","id":"parallel_coordinate-0"},{"x":578.8469188334127,"y":555.883507138323,"width":304.3095159020998,"height":27.015097486018472,"type":"stripe_graph","id":"stripe_graph-1"}],"relations":[{"vislist":[{"vislist":["bar_chart-2"],"relation":null,"id":"group-0"}],"relation":"repeated","id":"relation-0"},{"vislist":[{"vislist":["bar_chart-3"],"relation":null,"id":"group-1"}],"relation":"repeated","id":"relation-1"}]},"3353_4":{"comp":[["bar_chart","bar_chart",["repeated"]]],"visType":["bar_chart"],"compType":["repeated"],"compressed_tree":[{"composite_pattern":"repeated","visualization_type":[["bar_chart"]]},{"composite_pattern":"repeated","visualization_type":[["bar_chart"]]}],"coOccurrence":[["bar_chart","bar_chart",["coOccurrence"]]],"year":2020,"conference":["VAST"],"authors":["Johannes Knittel","Andres Lalama","Steffen Koch","Thomas Ertl"],"title":"Visual Neural Decomposition to Explain Multivariate Data Sets","doi":"10.1109/TVCG.2020.3030420","abstract":"Investigating relationships between variables in multi-dimensional data sets is a common task for data analysts and engineers. More specifically, it is often valuable to understand which ranges of which input variables lead to particular values of a given target variable. Unfortunately, with an increasing number of independent variables, this process may become cumbersome and time-consuming due to the many possible combinations that have to be explored. In this paper, we propose a novel approach to visualize correlations between input variables and a target output variable that scales to hundreds of variables. We developed a visual model based on neural networks that can be explored in a guided way to help analysts find and understand such correlations. First, we train a neural network to predict the target from the input variables. Then, we visualize the inner workings of the resulting model to help understand relations within the data set. We further introduce a new regularization term for the backpropagation algorithm that encourages the neural network to learn representations that are easier to interpret visually. We apply our method to artificial and real-world data sets to show its utility.","keywords":"Visual Analytics, Multivariate Data Analysis, Machine Learning","caption":"Fig. 5. Visualization of the resulting model. Each card represents one hidden node and visualizes the data set filtered by the contribution of the respective node. A compact overview of the nodes is shown on the left.","img_size":{"width":982,"height":537},"subfigures":[{"x":5.905724112693209,"y":10.547276906623543,"width":970.9222656289769,"height":518.839409288803,"type":"interface","id":"interface-0"}],"visualizations":[{"x":87.7584534419102,"y":79.81789407135057,"width":848.9261466473597,"height":380.82825143040884,"type":"bar_chart","id":"bar_chart-0"},{"x":8.77082483052635,"y":38.12209116936957,"width":66.2247480566146,"height":115.21787024356033,"type":"bar_chart","id":"bar_chart-1"},{"x":413.7304918415271,"y":9.967585185292394,"width":235.96038431553737,"height":18.243131101607478,"type":"stripe_graph","id":"stripe_graph-4"},{"x":413.73728531617985,"y":52.02592943670425,"width":236.81298213217443,"height":19.861422033250435,"type":"stripe_graph","id":"stripe_graph-5"},{"x":411.1281212760065,"y":278.84440547903887,"width":235.96801685092493,"height":20.01365402596192,"type":"stripe_graph","id":"stripe_graph-6"}],"relations":[{"vislist":[{"vislist":["bar_chart-0"],"relation":null,"id":"group-0"}],"relation":"repeated","id":"relation-0"},{"vislist":[{"vislist":["bar_chart-1"],"relation":null,"id":"group-1"}],"relation":"repeated","id":"relation-1"}]},"3339_0":{"comp":[["line_chart","line_chart",["repeated"]]],"visType":["line_chart"],"compType":["repeated"],"compressed_tree":[{"composite_pattern":"repeated","visualization_type":[["line_chart"]]}],"coOccurrence":[["line_chart","line_chart",["coOccurrence"]]],"year":2020,"conference":["VAST"],"authors":["Philipp Meschenmoser","Juri F. Buchm\xfcller","Daniel Seebacher","Martin Wikelski","Daniel A. Keim"],"title":"MultiSegVA: Using Visual Analytics to Segment Biologging Time Series on Multiple Scales","doi":"10.1109/TVCG.2020.3030386","abstract":"Segmenting biologging time series of animals on multiple temporal scales is an essential step that requires complex techniques with careful parameterization and possibly cross-domain expertise. Yet, there is a lack of visual-interactive tools that strongly support such multi-scale segmentation. To close this gap, we present our MultiSegVA platform for interactively defining segmentation techniques and parameters on multiple temporal scales. MultiSegVA primarily contributes tailored, visual-interactive means and visual analytics paradigms for segmenting unlabeled time series on multiple scales. Further, to flexibly compose the multi-scale segmentation, the platform contributes a new visual query language that links a variety of segmentation techniques. To illustrate our approach, we present a domain-oriented set of segmentation techniques derived in collaboration with movement ecologists. We demonstrate the applicability and usefulness of MultiSegVA in two real-world use cases from movement ecology, related to behavior analysis after environment-aware segmentation, and after progressive clustering. Expert feedback from movement ecologists shows the effectiveness of tailored visual-interactive means and visual analytics paradigms at segmenting multi-scale data, enabling them to perform semantically meaningful analyses. A third use case demonstrates that MultiSegVA is generalizable to other domains.","keywords":"Visual analytics, time series segmentation, multi-scale analyses, movement ecology.","caption":"Fig. 1. The main window of our MultiSegVA platform for the visual-interactive multi-scale segmentation of biologging time series. After arranging scale-wise segmentation techniques by a new visual query language, the analyst can explore results in tailored visualizations and re\ufb01ne parameters. Here the tree relies on segmentation by geographical area, then recursively by acceleration change points. ","img_size":{"width":1731,"height":832},"subfigures":[{"x":18.383942522303354,"y":11.066679664138286,"width":1701.7757549559274,"height":813.6393435601221,"type":"interface","id":"interface-0"}],"visualizations":[{"x":20.308175766911845,"y":434.2500364039621,"width":1511.7423021402828,"height":194.0289563421815,"type":"line_chart","id":"line_chart-1"},{"x":18.86415169467838,"y":629.8296724312513,"width":1508.5229538291617,"height":189.12030928745185,"type":"line_chart","id":"line_chart-2"},{"x":65.9825026843378,"y":92.41225585039103,"width":1457.0380270389476,"height":256.3448163626138,"type":"others","id":"others-0"}],"relations":[{"vislist":[{"vislist":["line_chart-1","line_chart-2"],"relation":null,"id":"group-0"}],"relation":"repeated","id":"relation-0"}]},"3338_0":{"comp":[["bar_chart","bar_chart",["repeated"]],["bar_chart","table",["nested"]]],"visType":["bar_chart","table"],"compType":["repeated","nested"],"compressed_tree":[{"composite_pattern":"nested","visualization_type":[["bar_chart"],["table"]]},{"composite_pattern":"repeated","visualization_type":[["bar_chart"]]}],"coOccurrence":[],"year":2020,"conference":["VAST"],"authors":["Zhuochen Jin","Shunan Guo","Nan Chen","Daniel Weiskopf","David Gotz","Nan Cao"],"title":"Visual Causality Analysis of Event Sequence Data","doi":"10.1109/TVCG.2020.3030465","abstract":"Causality is crucial to understanding the mechanisms behind complex systems and making decisions that lead to intended outcomes. Event sequence data is widely collected from many real-world processes, such as electronic health records, web clickstreams, and financial transactions, which transmit a great deal of information reflecting the causal relations among event types. Unfortunately, recovering causalities from observational event sequences is challenging, as the heterogeneous and high-dimensional event variables are often connected to rather complex underlying event excitation mechanisms that are hard to infer from limited observations. Many existing automated causal analysis techniques suffer from poor explainability and fail to include an adequate amount of human knowledge. In this paper, we introduce a visual analytics method for recovering causalities in event sequence data. We extend the Granger causality analysis algorithm on Hawkes processes to incorporate user feedback into causal model refinement. The visualization system includes an interactive causal analysis framework that supports bottom-up causal exploration, iterative causal verification and refinement, and causal comparison through a set of novel visualizations and interactions. We report two forms of evaluation: a quantitative evaluation of the model improvements resulting from the user-feedback mechanism, and a qualitative evaluation through case studies in different application domains to demonstrate the usefulness of the system.","keywords":"Event sequence data, causality analysis, visual analytics","caption":"Fig. 1. An overview of the SeqCausal interface. The query view (1) provides a set of \ufb01lters for the user to select sequences for analysis. The sequence list view (2) displays individual records retrieved from the query. The causal model view (3) displays the causal relations of events calculated from the back-end causality analysis model. Users can modify the graph, for example, con\ufb01rm or delete a causal link, by examining causal relations from the causal sequence view (4), which summarizes causal patterns in raw event sequences. The analysis history view (5) stores causalities of different queried subsets, from which users can select any two items to compare their causal relations in the causal comparison view (6). ","img_size":{"width":1820,"height":829},"subfigures":[{"x":304.6828204856888,"y":26.280904585443167,"width":1340.1821763302705,"height":787.0267199839765,"type":"interface","id":"interface-0"},{"x":4.352895977798916,"y":28.90872392985396,"width":283.15873048620193,"height":784.4182135838691,"type":"single","id":"single-1"}],"visualizations":[{"x":467.03717800769994,"y":197.06604737032475,"width":31.87804950788903,"height":229.59276746372365,"type":"bar_chart","id":"bar_chart-0"},{"x":317.17137163468976,"y":607.935304692865,"width":244.9206207092821,"height":156.78776336987283,"type":"bar_chart","id":"bar_chart-4"},{"x":314.0105192252771,"y":479.6850986739878,"width":252.8476781493045,"height":131.03486093864268,"type":"bar_chart","id":"bar_chart-5"},{"x":605.573115311271,"y":622.7308476842961,"width":189.85673524508715,"height":173.7043257938313,"type":"error_bar","id":"error_bar-7"},{"x":796.6192648991815,"y":422.4383111314273,"width":552.6480523045914,"height":377.0328211740857,"type":"graph","id":"graph-6"},{"x":612.9296348657444,"y":74.9638954625976,"width":725.7796452066513,"height":284.55905362383567,"type":"heatmap","id":"heatmap-2"},{"x":1369.428408444178,"y":506.4538400739475,"width":277.1308859032764,"height":274.7539558642077,"type":"matrix","id":"matrix-3"},{"x":317.1933942247257,"y":198.73691918320594,"width":249.69263339280212,"height":231.0621598800464,"type":"table","id":"table-1"}],"relations":[{"vislist":[{"vislist":["bar_chart-0"],"relation":null,"id":"group-0"},{"vislist":["table-1"],"relation":null,"id":"group-1"}],"relation":"nested","id":"relation-0"},{"vislist":[{"vislist":["bar_chart-4","bar_chart-5"],"relation":null,"id":"group-2"}],"relation":"repeated","id":"relation-1"}]},"3336_2":{"comp":[["map","map",["repeated"]],["line_chart","line_chart",["repeated"]]],"visType":["map","line_chart"],"compType":["repeated"],"compressed_tree":[{"composite_pattern":"repeated","visualization_type":[["map"]]},{"composite_pattern":"repeated","visualization_type":[["line_chart"]]},{"composite_pattern":"repeated","visualization_type":[["line_chart"]]},{"composite_pattern":"repeated","visualization_type":[["map"]]}],"coOccurrence":[["map","line_chart",["coOccurrence"]]],"year":2020,"conference":["VAST"],"authors":["Jie Liu","Tim Dwyer","Guido Tack","Samuel Gratzl","Kim Marriott"],"title":"Supporting the Problem-Solving Loop: Designing Highly Interactive Optimisation Systems","doi":"10.1109/TVCG.2020.3030364","abstract":"Efficient optimisation algorithms have become important tools for finding high-quality solutions to hard, real-world problems such as production scheduling, timetabling, or vehicle routing. These algorithms are typically \u201cblack boxes\u201d that work on mathematical models of the problem to solve. However, many problems are difficult to fully specify, and require a \u201chuman in the loop\u201d who collaborates with the algorithm by refining the model and guiding the search to produce acceptable solutions. Recently, the Problem-Solving Loop was introduced as a high-level model of such interactive optimisation. Here, we present and evaluate nine recommendations for the design of interactive visualisation tools supporting the Problem-Solving Loop. They range from the choice of visual representation for solutions and constraints to the use of a solution gallery to support exploration of alternate solutions. We first examined the applicability of the recommendations by investigating how well they had been supported in previous interactive optimisation tools. We then evaluated the recommendations in the context of the vehicle routing problem with time windows (VRPTW). To do so we built a sophisticated interactive visual system for solving VRPTW that was informed by the recommendations. Ten participants then used this system to solve a variety of routing problems. We report on participant comments and interaction patterns with the tool. These showed the tool was regarded as highly usable and the results generally supported the usefulness of the underlying recommendations.","keywords":"Interactive optimisation, Interface design, Usability, Interactive systems and tools, Vehicle routing","caption":"Fig. 3. An overview of the interactive optimisation tool showing its three main components: Solution window, Solution history and Solution gallery (highlighted in blue). Sub-components are highlighted in orange. Interactions are highlighted in red (the rest of interactions in Fig. 4). ","img_size":{"width":1998,"height":978},"subfigures":[{"x":11.103826020831717,"y":7.093145573921896,"width":1977.2435508007263,"height":955.106835466278,"type":"interface","id":"interface-0"}],"visualizations":[{"x":16.25638638398955,"y":741.9077329529131,"width":1676.4602469612487,"height":218.41680262820725,"type":"bar_chart","id":"bar_chart-2"},{"x":1295.2504866910376,"y":76.81821090621884,"width":387.3709841212721,"height":616.433145859056,"type":"line_chart","id":"line_chart-3"},{"x":20.567087823717845,"y":68.13242548325762,"width":404.2269852150647,"height":628.5183497813734,"type":"line_chart","id":"line_chart-4"},{"x":1724.2426549046913,"y":387.936714781567,"width":255.47881764249087,"height":381.8630458394726,"type":"map","id":"map-0"},{"x":1729.625599182352,"y":10.023661836884052,"width":264.09888508094383,"height":365.87958088234956,"type":"map","id":"map-1"},{"x":436.56392839142114,"y":66.4172356068887,"width":391.73053472544274,"height":633.710851841979,"type":"map","id":"map-5"},{"x":879.8324010972816,"y":76.63615157158374,"width":402.23464393459415,"height":593.8896745260338,"type":"map","id":"map-6"}],"relations":[{"vislist":[{"vislist":["map-1","map-0"],"relation":null,"id":"group-0"}],"relation":"repeated","id":"relation-0"},{"vislist":[{"vislist":["line_chart-3"],"relation":null,"id":"group-1"}],"relation":"repeated","id":"relation-1"},{"vislist":[{"vislist":["line_chart-4"],"relation":null,"id":"group-2"}],"relation":"repeated","id":"relation-2"},{"vislist":[{"vislist":["map-5","map-6"],"relation":null,"id":"group-3"}],"relation":"repeated","id":"relation-3"}]},"3335_6":{"comp":[["matrix","matrix",["repeated","mirrored"]]],"visType":["matrix"],"compType":["repeated","mirrored"],"compressed_tree":[{"composite_pattern":"mirrored","visualization_type":[["matrix"]]},{"composite_pattern":"repeated","visualization_type":[["matrix"]]}],"coOccurrence":[["matrix","matrix",["coOccurrence"]]],"year":2020,"conference":["VAST"],"authors":["Karen B. Schloss","Zachary Leggon","Laurent Lessard"],"title":"Semantic Discriminability for Visual Communication","doi":"10.1109/TVCG.2020.3030434","abstract":"To interpret information visualizations, observers must determine how visual features map onto concepts. First and foremost, this ability depends on perceptual discriminability; observers must be able to see the difference between different colors for those colors to communicate different meanings. However, the ability to interpret visualizations also depends on semantic discriminability, the degree to which observers can infer a unique mapping between visual features and concepts, based on the visual features and concepts alone (i.e., without help from verbal cues such as legends or labels). Previous evidence suggested that observers were better at interpreting encoding systems that maximized semantic discriminability (maximizing association strength between assigned colors and concepts while minimizing association strength between unassigned colors and concepts), compared to a system that only maximized color-concept association strength. However, increasing semantic discriminability also resulted in increased perceptual distance, so it is unclear which factor was responsible for improved performance. In the present study, we conducted two experiments that tested for independent effects of semantic distance and perceptual distance on semantic discriminability of bar graph data visualizations. Perceptual distance was large enough to ensure colors were more than just noticeably different. We found that increasing semantic distance improved performance, independent of variation in perceptual distance, and when these two factors were uncorrelated, responses were dominated by semantic distance. These results have implications for navigating trade-offs in color palette design optimization for visual communication.","keywords":" Multi-Robot Systems, Human-Subjects QualitativeStudies, Debugging","caption":"Figure 4: Differential Worldview Comparison: (BT) Battery Level Panel, (SZ) Science Zone Panel, and (CN) Communication Network Panel.","img_size":{"width":2034,"height":984},"subfigures":[{"x":9.818910780950558,"y":8.752603844965906,"width":2012.8848277967465,"height":954.6786656445994,"type":"interface","id":"interface-0"}],"visualizations":[{"x":12.288024564600333,"y":13.838639317703349,"width":1998.6592676899838,"height":495.74113027997186,"type":"matrix","id":"matrix-0"},{"x":12.309957654043956,"y":520.5765740645792,"width":2003.9977431015045,"height":442.8556608693219,"type":"matrix","id":"matrix-2"}],"relations":[{"vislist":[{"vislist":["matrix-0"],"relation":null,"id":"group-0"}],"relation":"mirrored","id":"relation-0"},{"vislist":[{"vislist":["matrix-2"],"relation":null,"id":"group-1"}],"relation":"repeated","id":"relation-1"}]},"3334_0":{"comp":[["line_chart","line_chart",["repeated"]],["proportional_area_chart","parallel_coordinate",["nested"]],["graph","scatterplot",["coordinated"]],["area_chart","comb",["stacked"]],["comb","area_chart",["stacked"]]],"visType":["line_chart","proportional_area_chart","parallel_coordinate","graph","scatterplot","area_chart","comb"],"compType":["repeated","nested","coordinated","stacked"],"compressed_tree":[{"composite_pattern":"repeated","visualization_type":[["line_chart"]]},{"composite_pattern":"stacked","visualization_type":[["area_chart",{"composite_pattern":"coordinated","visualization_type":[["graph"],["scatterplot"]]}]]},{"composite_pattern":"nested","visualization_type":[["proportional_area_chart"],["parallel_coordinate"]]}],"coOccurrence":[["line_chart","graph",["coOccurrence"]],["line_chart","scatterplot",["coOccurrence"]],["line_chart","area_chart",["coOccurrence"]],["line_chart","proportional_area_chart",["coOccurrence"]],["line_chart","parallel_coordinate",["coOccurrence"]],["graph","scatterplot",["coOccurrence"]],["graph","area_chart",["coOccurrence"]],["graph","proportional_area_chart",["coOccurrence"]],["graph","parallel_coordinate",["coOccurrence"]],["scatterplot","area_chart",["coOccurrence"]],["scatterplot","proportional_area_chart",["coOccurrence"]],["scatterplot","parallel_coordinate",["coOccurrence"]],["area_chart","proportional_area_chart",["coOccurrence"]],["area_chart","parallel_coordinate",["coOccurrence"]],["proportional_area_chart","parallel_coordinate",["coOccurrence"]]],"year":2020,"conference":["VAST"],"authors":["Heungseok Park","Yoonsoo Nam","Ji-Hoon Kim","Jaegul Choo"],"title":"HyperTendril: Visual Analytics for User-Driven Hyperparameter Optimization of Deep Neural Networks","doi":"10.1109/TVCG.2020.3030380","abstract":"To mitigate the pain of manually tuning hyperparameters of deep neural networks, automated machine learning (AutoML) methods have been developed to search for an optimal set of hyperparameters in large combinatorial search spaces. However, the search results of AutoML methods significantly depend on initial configurations, making it a non-trivial task to find a proper configuration. Therefore, human intervention via a visual analytic approach bears huge potential in this task. In response, we propose HyperTendril, a web-based visual analytics system that supports user-driven hyperparameter tuning processes in a model-agnostic environment. HyperTendril takes a novel approach to effectively steering hyperparameter optimization through an iterative, interactive tuning procedure that allows users to refine the search spaces and the configuration of the AutoML method based on their own insights from given results. Using HyperTendril, users can obtain insights into the complex behaviors of various hyperparameter search algorithms and diagnose their configurations. In addition, HyperTendril supports variable importance analysis to help the users refine their search spaces based on the analysis of relative importance of different hyperparameters and their interaction effects. We present the evaluation demonstrating how HyperTendril helps users steer their tuning processes via a longitudinal user study based on the analysis of interaction logs and in-depth interviews while we deploy our system in a professional industrial environment.","keywords":"Visual analytics, deep learning, machine learning, automated machine learning, human-centered computing","caption":"Fig. 1. Overview of HyperTendril that supports user-driven AutoML processes. This example involves the three hyperparameters, e.g., the number of layers, learning rate, and weight decay in the ResNet architecture, using a Bayesian Optimization and HyperBand (BOHB) search method. (C) Search space overview, (D) Model analysis view, and (E1) Exploration overview components shows the model details selected in (B2) Selected experiments panel. The weight decay hyperparameter is activated in (C) Search space overview, and its effective range is highlighted in the parallel coordinates. ","img_size":{"width":1699,"height":911},"subfigures":[{"x":38.251241736603845,"y":12.93336960195654,"width":1643.648581218583,"height":882.6445825968598,"type":"interface","id":"interface-0"}],"visualizations":[{"x":1164.3464797228935,"y":160.33864591042527,"width":488.27989832695846,"height":103.31353395434249,"type":"area_chart","id":"area_chart-1"},{"x":1124.0748921945644,"y":277.22763628481334,"width":534.3547413075132,"height":596.3030901256619,"type":"graph","id":"graph-3"},{"x":746.1650882696131,"y":589.2935809516014,"width":272.60924134549396,"height":253.88727695905214,"type":"line_chart","id":"line_chart-5"},{"x":489.9796650132064,"y":589.3142949289562,"width":257.46474478055,"height":255.344338771188,"type":"line_chart","id":"line_chart-6"},{"x":491.93228262179474,"y":216.65434769064686,"width":544.292397509636,"height":237.93294192341622,"type":"parallel_coordinate","id":"parallel_coordinate-4"},{"x":777.3067080390883,"y":225.45866174837766,"width":99.42788990951283,"height":223.32129334164512,"type":"proportional_area_chart","id":"proportional_area_chart-10"},{"x":40.0153767558749,"y":364.42643478894666,"width":382.6051611497568,"height":221.10786436009096,"type":"scatterplot","id":"scatterplot-0"},{"x":1121.0558627355947,"y":280.3366347292618,"width":532.8996845567254,"height":596.0790523041466,"type":"scatterplot","id":"scatterplot-2"}],"relations":[{"vislist":[{"vislist":["line_chart-6","line_chart-5"],"relation":null,"id":"group-0"}],"relation":"repeated","id":"relation-0"},{"vislist":[{"vislist":["area_chart-1",{"vislist":[{"vislist":["graph-3"],"relation":null,"id":"group-1"},{"vislist":["scatterplot-2"],"relation":null,"id":"group-2"}],"relation":"coordinated","id":"relation-1"}],"relation":null,"id":"group-3"}],"relation":"stacked","id":"relation-2"},{"vislist":[{"vislist":["proportional_area_chart-10"],"relation":null,"id":"group-4"},{"vislist":["parallel_coordinate-4"],"relation":null,"id":"group-5"}],"relation":"nested","id":"relation-3"}]},"3333_5":{"comp":[["graph","graph",["repeated"]]],"visType":["graph"],"compType":["repeated"],"compressed_tree":[{"composite_pattern":"repeated","visualization_type":[["graph"]]}],"coOccurrence":[["graph","graph",["coOccurrence"]]],"year":2020,"conference":["VAST"],"authors":["Eren Cakmak","Udo Schlegel","Dominik J\xe4ckle","Daniel Keim","Tobias Schreck"],"title":"Multiscale Snapshots: Visual Analysis of Temporal Summaries in Dynamic Graphs","doi":"10.1109/TVCG.2020.3030398","abstract":"The overview-driven visual analysis of large-scale dynamic graphs poses a major challenge. We propose Multiscale Snapshots, a visual analytics approach to analyze temporal summaries of dynamic graphs at multiple temporal scales. First, we recursively generate temporal summaries to abstract overlapping sequences of graphs into compact snapshots. Second, we apply graph embeddings to the snapshots to learn low-dimensional representations of each sequence of graphs to speed up specific analytical tasks (e.g., similarity search). Third, we visualize the evolving data from a coarse to fine-granular snapshots to semi-automatically analyze temporal states, trends, and outliers. The approach enables us to discover similar temporal summaries (e.g., reoccurring states), reduces the temporal data to speed up automatic analysis, and to explore both structural and temporal properties of a dynamic graph. We demonstrate the usefulness of our approach by a quantitative evaluation and the application to a real-world dataset.","keywords":"Dynamic Graph, Dynamic Network, Unsupervised Graph Learning, Graph Embedding, Multiscale Visualization.","caption":"Fig. 4. The prototype implementation consists of two primary components the Multiscale Snapshots visualization (A) and the query interface (B). The \ufb01gures present the visual analysis of the Reddit hyperlink dataset (see Sec. 5.1). The displayed nodes are subreddits, and the edges are timestamped hyperlinks between subreddits with either positive (blue) or negative (red) sentiment. The displayed nodes are subreddits, and the edges are timestamped hyperlinks between subreddits with either positive (blue) or negative (red) sentiment. The example illustrates by the case of the 2016 US election how the approach allows searching for similar temporal states in the dynamic graph. The intermediate steps of the visual analysis and the resulting interfaces are presented in the sub-\ufb01gures C-D. In D, the results of the visual analysis by similarity search are displayed, which are signi\ufb01cant events in the timeline of the presidential election. ","img_size":{"width":1980,"height":1056},"subfigures":[{"x":5.457931035566343,"y":6.440666769766368,"width":987.1757671027163,"height":519.529184159343,"type":"interface","id":"interface-0"},{"x":1001.7093318001596,"y":9.289038805961859,"width":970.0246073236392,"height":515.2748353549991,"type":"interface","id":"interface-1"},{"x":8.23174824283164,"y":529.944548321589,"width":978.744407663734,"height":511.04601404966047,"type":"interface","id":"interface-2"},{"x":998.7765504275709,"y":528.3455130248731,"width":968.680857507688,"height":515.6864799111398,"type":"interface","id":"interface-3"}],"visualizations":[{"x":18.898453258498535,"y":66.84172641415125,"width":957.1869510967857,"height":447.90454784394,"type":"graph","id":"graph-0"},{"x":1002.1630646241914,"y":735.137285966406,"width":957.1970480939119,"height":138.6247066954927,"type":"graph","id":"graph-5"},{"x":998.7162733269204,"y":876.1599224508002,"width":965.8371132104156,"height":160.06358035548885,"type":"graph","id":"graph-6"},{"x":1009.0902008369103,"y":568.6854062269476,"width":945.0892581904358,"height":162.81183425892044,"type":"line_chart","id":"line_chart-2"},{"x":18.88602436131535,"y":585.4187581093497,"width":953.7188438472293,"height":220.0415421303048,"type":"line_chart","id":"line_chart-3"},{"x":10.256567794362915,"y":810.3792560532811,"width":487.2020983978324,"height":228.8350897100887,"type":"matrix","id":"matrix-4"},{"x":995.3253260501077,"y":128.79737395236737,"width":983.0979028958096,"height":381.55059092124253,"type":"scatterplot","id":"scatterplot-1"}],"relations":[{"vislist":[{"vislist":["graph-5"],"relation":null,"id":"group-0"}],"relation":"repeated","id":"relation-0"}]},"3349_0":{"comp":[["others","others",["repeated"]],["matrix","matrix",["repeated"]]],"visType":["others","matrix"],"compType":["repeated"],"compressed_tree":[{"composite_pattern":"repeated","visualization_type":[["others"]]},{"composite_pattern":"repeated","visualization_type":[["matrix"]]}],"coOccurrence":[["others","matrix",["coOccurrence"]]],"year":2020,"conference":["VAST"],"authors":["Angelos Chatzimparmpas","Rafael M. Martins","Kostiantyn Kucher","Andreas Kerren"],"title":"StackGenVis: Alignment of Data, Algorithms, and Models for Stacking Ensemble Learning Using Performance Metrics","doi":"10.1109/TVCG.2020.3030352","abstract":"In machine learning (ML), ensemble methods-such as bagging, boosting, and stacking-are widely-established approaches that regularly achieve top-notch predictive performance. Stacking (also called \u201cstacked generalization\u201d) is an ensemble method that combines heterogeneous base models, arranged in at least one layer, and then employs another metamodel to summarize the predictions of those models. Although it may be a highly-effective approach for increasing the predictive performance of ML, generating a stack of models from scratch can be a cumbersome trial-and-error process. This challenge stems from the enormous space of available solutions, with different sets of data instances and features that could be used for training, several algorithms to choose from, and instantiations of these algorithms using diverse parameters (i.e., models) that perform differently according to various metrics. In this work, we present a knowledge generation model, which supports ensemble learning with the use of visualization, and a visual analytics system for stacked generalization. Our system, StackGenVis, assists users in dynamically adapting performance metrics, managing data instances, selecting the most important features for a given data set, choosing a set of top-performant and diverse algorithms, and measuring the predictive performance. In consequence, our proposed tool helps users to decide between distinct models and to reduce the complexity of the resulting stack by removing overpromising and underperforming models. The applicability and effectiveness of StackGenVis are demonstrated with two use cases: a real-world healthcare data set and a collection of data related to sentiment/stance detection in texts. Finally, the tool has been evaluated through interviews with three ML experts.","keywords":"Stacking, stacked generalization, ensemble learning, visual analytics, visualization","caption":"Fig. 1. Constructing performant stacking ensembles from scratch with StackGenVis: (a) a panel for uploading data sets and choosing weights for performance metrics; (b) the history preservation panel with the composition and performance achieved by the user-built stored stacking ensembles; (c) the comparison of the metamodel\u2019s performance for both the active and stored stackings, based on four performance metrics (linked to view (a) with a dice glyph showing four); (d) the three exploration modes for the algorithms, data, and models; (e) the projection-based models\u2019 space visualization, which summarizes the results of all the selected performance metrics for all models; and (f) the predictions\u2019 space visual embedding, which arranges the data instances based on the collective outcome of the models in the current stored stack S6\xa9 (marked in bold typeface in (b)).","img_size":{"width":1804,"height":1011},"subfigures":[{"x":14.953455988975529,"y":7.537558550788019,"width":1779.6203382572928,"height":994.5439533378207,"type":"interface","id":"interface-0"}],"visualizations":[{"x":914.6469236617072,"y":794.5532230163158,"width":867.3915857351138,"height":205.37953786982888,"type":"bar_chart","id":"bar_chart-1"},{"x":12.357164153813201,"y":846.8604174704175,"width":843.636768593601,"height":159.68584287298864,"type":"box_plot","id":"box_plot-2"},{"x":1374.4952403066652,"y":36.98720595789206,"width":413.9281643634638,"height":261.826284883722,"type":"line_chart","id":"line_chart-0"},{"x":473.02407578854724,"y":146.61295127361146,"width":854.7693691606643,"height":150.8614749542477,"type":"matrix","id":"matrix-6"},{"x":473.032626132682,"y":40.43772020422775,"width":856.3435081035146,"height":106.82729601924336,"type":"others","id":"others-5"},{"x":914.6572012412475,"y":415.65340442961053,"width":868.9622702071507,"height":377.15713830318765,"type":"scatterplot","id":"scatterplot-3"},{"x":15.748932051742425,"y":400.41207647632723,"width":843.2181913222211,"height":439.48881794562686,"type":"scatterplot","id":"scatterplot-4"}],"relations":[{"vislist":[{"vislist":["others-5"],"relation":null,"id":"group-0"}],"relation":"repeated","id":"relation-0"},{"vislist":[{"vislist":["matrix-6"],"relation":null,"id":"group-1"}],"relation":"repeated","id":"relation-1"}]},"3348_3":{"comp":[["bar_chart","bar_chart",["repeated"]]],"visType":["bar_chart"],"compType":["repeated"],"compressed_tree":[{"composite_pattern":"repeated","visualization_type":[["bar_chart"]]}],"coOccurrence":[["bar_chart","bar_chart",["coOccurrence"]]],"year":2020,"conference":["VAST"],"authors":["Siming Chen","Natalia Andrienko","Gennady Andrienko","Jie Li","Xiaoru Yuan"],"title":"Co-Bridges: Pair-wise Visual Connection and Comparison for Multi-item Data Streams","doi":"10.1109/TVCG.2020.3030411","abstract":"In various domains, there are abundant streams or sequences of multi-item data of various kinds, e.g. streams of news and social media texts, sequences of genes and sports events, etc. Comparison is an important and general task in data analysis. For comparing data streams involving multiple items (e.g., words in texts, actors or action types in action sequences, visited places in itineraries, etc.), we propose Co-Bridges, a visual design involving connection and comparison techniques that reveal similarities and differences between two streams. Co-Bridges use river and bridge metaphors, where two sides of a river represent data streams, and bridges connect temporally or sequentially aligned segments of streams. Commonalities and differences between these segments in terms of involvement of various items are shown on the bridges. Interactive query tools support the selection of particular stream subsets for focused exploration. The visualization supports both qualitative (common and distinct items) and quantitative (stream volume, amount of item involvement) comparisons. We further propose Comparison-of-Comparisons, in which two or more Co-Bridges corresponding to different selections are juxtaposed. We test the applicability of the Co-Bridges in different domains, including social media text streams and sports event sequences. We perform an evaluation of the users\' capability to understand and use Co-Bridges. The results confirm that Co-Bridges is effective for supporting pair-wise visual comparisons in a wide range of applications.","keywords":"Visual Comparison, Pair-wise Analysis, Multi-item Data Stream, Social Media","caption":"Fig. 4. An alternative for the overall layout. The positions along the X-axis correspond to items, and the Y-axis represents time.","img_size":{"width":975,"height":624},"subfigures":[{"x":0.3334636781824351,"y":3.8099677547688646,"width":968.3654794122709,"height":615.5277400138878,"type":"single","id":"single-0"}],"visualizations":[{"x":121.10151375226518,"y":3.430976006536779,"width":738.8170448249581,"height":611.1243163865842,"type":"bar_chart","id":"bar_chart-0"}],"relations":[{"vislist":[{"vislist":["bar_chart-0"],"relation":null,"id":"group-0"}],"relation":"repeated","id":"relation-0"}]},"3345_0":{"comp":[["bar_chart","bar_chart",["repeated"]],["bar_chart","scatterplot",["accompanied"]],["scatterplot","bar_chart",["accompanied"]]],"visType":["bar_chart","scatterplot"],"compType":["repeated","accompanied"],"compressed_tree":[{"composite_pattern":"repeated","visualization_type":[["bar_chart"]]},{"composite_pattern":"accompanied","visualization_type":[["bar_chart","scatterplot"]]}],"coOccurrence":[["bar_chart","scatterplot",["coOccurrence"]]],"year":2020,"conference":["VAST"],"authors":["T. Baumgartl","M. Petzold","M. Wunderlich","M. Hohn","D. Archambault","M. Lieser","A. Dalpke","S. Scheithauer","M. Marschollek"],"title":"In Search of Patient Zero: Visual Analytics of Pathogen Transmission Pathways in Hospitals","doi":"10.1109/TVCG.2020.3030437","abstract":"Pathogen outbreaks (i.e., outbreaks of bacteria and viruses) in hospitals can cause high mortality rates and increase costs for hospitals significantly. An outbreak is generally noticed when the number of infected patients rises above an endemic level or the usual prevalence of a pathogen in a defined population. Reconstructing transmission pathways back to the source of an outbreak - the patient zero or index patient - requires the analysis of microbiological data and patient contacts. This is often manually completed by infection control experts. We present a novel visual analytics approach to support the analysis of transmission pathways, patient contacts, the progression of the outbreak, and patient timelines during hospitalization. Infection control experts applied our solution to a real outbreak of Klebsiella pneumoniae in a large German hospital. Using our system, our experts were able to scale the analysis of transmission pathways to longer time intervals (i.e., several years of data instead of days) and across a larger number of wards. Also, the system is able to reduce the analysis time from days to hours. In our final study, feedback from twenty-five experts from seven German hospitals provides evidence that our solution brings significant benefits for analyzing outbreaks.","keywords":"dynamic networks, visualization applications, health, medicine, outbreak, Klebsiella, infection control","caption":"Figure 1: Transmission pathway tracing interface.  1. The Epidemic Curve Viewshows the number of infected patients.  2. The Contact Network View shows patient contacts as a network. 3. The Transmission Pathway View shows contacts and infection status. Tracing interaction shows potential infection transmission events. 4. Patient event details are shown in Patient Timeline View.","img_size":{"width":1809,"height":598},"subfigures":[{"x":6.132597041431142,"y":9.455957266756695,"width":1796.7348059171386,"height":580.4014653875051,"type":"interface","id":"interface-0"}],"visualizations":[{"x":1364.0921226964297,"y":63.16483175879956,"width":441.90515387006906,"height":516.3656915818129,"type":"bar_chart","id":"bar_chart-0"},{"x":10.422491329884032,"y":166.07042491481644,"width":294.62667301420424,"height":77.50015367998598,"type":"bar_chart","id":"bar_chart-4"},{"x":5.662388857992413,"y":47.10818369876668,"width":296.16862825539306,"height":115.89180084685111,"type":"bar_chart","id":"bar_chart-5"},{"x":11.971199447068994,"y":303.1794035240682,"width":297.911856541913,"height":282.1610010980441,"type":"graph","id":"graph-3"},{"x":328.37610567647266,"y":59.98597087967104,"width":1013.4262438218801,"height":517.9346252937046,"type":"others","id":"others-2"},{"x":1365.6336642599083,"y":64.59461297478343,"width":434.03512092155364,"height":503.92855305711487,"type":"scatterplot","id":"scatterplot-1"}],"relations":[{"vislist":[{"vislist":["bar_chart-4","bar_chart-5"],"relation":null,"id":"group-0"}],"relation":"repeated","id":"relation-0"},{"vislist":[{"vislist":["bar_chart-0","scatterplot-1"],"relation":null,"id":"group-1"}],"relation":"accompanied","id":"relation-1"}]},"3341_0":{"comp":[["bar_chart","bar_chart",["repeated"]],["word_cloud","word_cloud",["repeated"]],["table","table",["repeated"]],["area_chart","area_chart",["repeated"]]],"visType":["bar_chart","word_cloud","table","area_chart"],"compType":["repeated"],"compressed_tree":[{"composite_pattern":"repeated","visualization_type":[["bar_chart"]]},{"composite_pattern":"repeated","visualization_type":[["bar_chart"]]},{"composite_pattern":"repeated","visualization_type":[["word_cloud"]]},{"composite_pattern":"repeated","visualization_type":[["table"]]},{"composite_pattern":"repeated","visualization_type":[["area_chart"]]}],"coOccurrence":[["bar_chart","word_cloud",["coOccurrence"]],["bar_chart","table",["coOccurrence"]],["bar_chart","area_chart",["coOccurrence"]],["word_cloud","table",["coOccurrence"]],["word_cloud","area_chart",["coOccurrence"]],["table","area_chart",["coOccurrence"]]],"year":2020,"conference":["VAST"],"authors":["Di Weng","Chengbo Zheng","Zikun Deng","Mingze Ma","Jie Bao","Yu Zheng","Mingliang Xu","Yingcai Wu"],"title":"Towards Better Bus Networks: A Visual Analytics Approach","doi":"10.1109/TVCG.2020.3030458","abstract":"Bus routes are typically updated every 3-5 years to meet constantly changing travel demands. However, identifying deficient bus routes and finding their optimal replacements remain challenging due to the difficulties in analyzing a complex bus network and the large solution space comprising alternative routes. Most of the automated approaches cannot produce satisfactory results in real-world settings without laborious inspection and evaluation of the candidates. The limitations observed in these approaches motivate us to collaborate with domain experts and propose a visual analytics solution for the performance analysis and incremental planning of bus routes based on an existing bus network. Developing such a solution involves three major challenges, namely, a) the in-depth analysis of complex bus route networks, b) the interactive generation of improved route candidates, and c) the effective evaluation of alternative bus routes. For challenge a, we employ an overview-to-detail approach by dividing the analysis of a complex bus network into three levels to facilitate the efficient identification of deficient routes. For challenge b, we improve a route generation model and interpret the performance of the generation with tailored visualizations. For challenge c, we incorporate a conflict resolution strategy in the progressive decision-making process to assist users in evaluating the alternative routes and finding the most optimal one. The proposed system is evaluated with two usage scenarios based on real-world data and received positive feedback from the experts.","keywords":"git, history, exploration, overview, repository, visualization, cluster, DAG","caption":"Fig. 1. Githru system. (a) The Global Temporal Filter shows commit trends by number of commits and CLOC (changed lines of code). (b) The Clustering Step controls the granularity of clustering. (c) The stem graph visualizes a cluster information of each commit at a single glance. (d) The Grouped Summary View provides a rough summary of the selected clusters. (e) A file icicle tree allows users to interactively observe the modified file hierarchy. (f) The commit list shows all the commits in a selected cluster. (g) Comparison View enables a comparison between selected groups.","img_size":{"width":1876,"height":1020},"subfigures":[{"x":6.852393466737921,"y":7.6122701427227755,"width":1859.5073202735148,"height":1004.775459714553,"type":"interface","id":"interface-0"}],"visualizations":[{"x":5.674734501805484,"y":34.06381268243418,"width":1179.5848232001224,"height":75.89898205188682,"type":"area_chart","id":"area_chart-0"},{"x":1062.9003199343795,"y":813.3578370994651,"width":139.06516045037836,"height":196.3979276968619,"type":"bar_chart","id":"bar_chart-10"},{"x":1221.679263167041,"y":132.2865342216589,"width":648.8813172172667,"height":250.37610974592644,"type":"bar_chart","id":"bar_chart-4"},{"x":1226.555183331745,"y":421.20087093933,"width":634.1652326284656,"height":263.7052834792392,"type":"bar_chart","id":"bar_chart-5"},{"x":20.473805590926617,"y":193.87647380504214,"width":1169.8436580594484,"height":282.85123795690106,"type":"others","id":"others-2"},{"x":12.5966938835322,"y":138.18636625753427,"width":1170.7051486960615,"height":26.62069094703836,"type":"stripe_graph","id":"stripe_graph-1"},{"x":33.95796400300977,"y":509.92205027882915,"width":1146.1848374082144,"height":195.5526108314205,"type":"table","id":"table-3"},{"x":396.51267758388207,"y":752.4674048953584,"width":641.1569057462359,"height":255.25442742045536,"type":"table","id":"table-9"},{"x":29.07893021854692,"y":755.7346192515839,"width":346.7710906960386,"height":250.37590304181074,"type":"treemap","id":"treemap-8"},{"x":1053.1593552538716,"y":724.9014695833008,"width":160.2018378978597,"height":91.80692598221142,"type":"word_cloud","id":"word_cloud-11"},{"x":1312.6561745331428,"y":739.3821914939484,"width":188.92981595904016,"height":160.54383785545645,"type":"word_cloud","id":"word_cloud-6"},{"x":1617.2827341172288,"y":732.8341167425274,"width":238.26643520370564,"height":168.67227435688005,"type":"word_cloud","id":"word_cloud-7"}],"relations":[{"vislist":[{"vislist":["bar_chart-4"],"relation":null,"id":"group-0"}],"relation":"repeated","id":"relation-0"},{"vislist":[{"vislist":["bar_chart-5"],"relation":null,"id":"group-1"}],"relation":"repeated","id":"relation-1"},{"vislist":[{"vislist":["word_cloud-7","word_cloud-6"],"relation":null,"id":"group-2"}],"relation":"repeated","id":"relation-2"},{"vislist":[{"vislist":["table-3"],"relation":null,"id":"group-3"}],"relation":"repeated","id":"relation-3"},{"vislist":[{"vislist":["area_chart-0"],"relation":null,"id":"group-4"}],"relation":"repeated","id":"relation-4"}]},"3342_0":{"comp":[["bar_chart","bar_chart",["repeated"]],["bar_chart","box_plot",["stacked"]],["bar_chart","matrix",["stacked"]],["heatmap","heatmap",["repeated"]],["box_plot","matrix",["stacked"]],["box_plot","bar_chart",["stacked"]],["matrix","box_plot",["stacked"]],["matrix","bar_chart",["stacked"]]],"visType":["bar_chart","box_plot","matrix","heatmap"],"compType":["repeated","stacked"],"compressed_tree":[{"composite_pattern":"repeated","visualization_type":[["bar_chart"]]},{"composite_pattern":"stacked","visualization_type":[["box_plot","matrix","bar_chart"]]},{"composite_pattern":"stacked","visualization_type":[["matrix","bar_chart"]]},{"composite_pattern":"repeated","visualization_type":[["bar_chart"]]},{"composite_pattern":"stacked","visualization_type":[["matrix","box_plot"]]},{"composite_pattern":"repeated","visualization_type":[["heatmap"]]}],"coOccurrence":[["bar_chart","box_plot",["coOccurrence"]],["bar_chart","matrix",["coOccurrence"]],["bar_chart","heatmap",["coOccurrence"]],["box_plot","matrix",["coOccurrence"]],["box_plot","heatmap",["coOccurrence"]],["matrix","heatmap",["coOccurrence"]]],"year":2020,"conference":["VAST"],"authors":["Yuxin Ma","Arlen Fan","Jingrui He","Arun Reddy Nelakurthi","Ross Maciejewski"],"title":"A Visual Analytics Framework for Explaining and Diagnosing Transfer Learning Processes","doi":"10.1109/TVCG.2020.3028888","abstract":"Many statistical learning models hold an assumption that the training data and the future unlabeled data are drawn from the same distribution. However, this assumption is difficult to fulfill in real-world scenarios and creates barriers in reusing existing labels from similar application domains. Transfer Learning is intended to relax this assumption by modeling relationships between domains, and is often applied in deep learning applications to reduce the demand for labeled data and training time. Despite recent advances in exploring deep learning models with visual analytics tools, little work has explored the issue of explaining and diagnosing the knowledge transfer process between deep learning models. In this paper, we present a visual analytics framework for the multi-level exploration of the transfer learning processes when training deep neural networks. Our framework establishes a multi-aspect design to explain how the learned knowledge from the existing model is transferred into the new learning task when training deep neural networks. Based on a comprehensive requirement and task analysis, we employ descriptive visualization with performance measures and detailed inspections of model behaviors from the statistical, instance, feature, and model structure levels. We demonstrate our framework through two case studies on image classification by fine-tuning AlexNets to illustrate how analysts can utilize our framework.","keywords":"Transfer learning, deep learning, visual analytics","caption":"Fig. 1. The visual analytics for transfer learning interface consists of four components: (A) statistical information summary, (B) the instance view, (C) the network relation view, and (D) the feature view. For the Office-31 dataset, (1) the prediction accuracy of the target model on the source dataset is lower than the source model; (2) for the target dataset, classes such as filec_abinet and phone have a large performance gap between the source and the target models; (3) the neuron similarity matrices and the weights are presented; (4) some neurons have high domain discriminability, while Neuron #173 in Layer 5 is domain-invariant.","img_size":{"width":1751,"height":1016},"subfigures":[{"x":38.23896813337667,"y":45.57870738842218,"width":1526.0957785358423,"height":862.3934264588393,"type":"interface","id":"interface-0"}],"visualizations":[{"x":1030.3805344984896,"y":409.6692125154865,"width":105.53764515765704,"height":102.44642918340993,"type":"bar_chart","id":"bar_chart-12"},{"x":464.7696583464005,"y":398.6707561881425,"width":219.10944622527725,"height":99.73117245170776,"type":"bar_chart","id":"bar_chart-14"},{"x":569.4042224441285,"y":285.5564742488134,"width":114.86566193128311,"height":100.4611906795439,"type":"bar_chart","id":"bar_chart-16"},{"x":1301.9613716360523,"y":563.4348078346941,"width":262.19929050519863,"height":333.9494332856562,"type":"bar_chart","id":"bar_chart-4"},{"x":1021.4256946906237,"y":554.1203173409926,"width":118.98304411565276,"height":334.0442872332646,"type":"bar_chart","id":"bar_chart-5"},{"x":1019.7759325824915,"y":283.9780865958412,"width":109.92664551997947,"height":95.89541305224118,"type":"box_plot","id":"box_plot-10"},{"x":728.9117519918807,"y":407.7994975473439,"width":294.7209863677311,"height":92.28526383985054,"type":"box_plot","id":"box_plot-11"},{"x":570.9665422596196,"y":551.7130124436624,"width":116.37449335477821,"height":161.24017956323794,"type":"box_plot","id":"box_plot-9"},{"x":742.4264966457032,"y":736.4308403644318,"width":252.24659354516473,"height":142.4084268911251,"type":"heatmap","id":"heatmap-7"},{"x":420.9041981012568,"y":65.03062187139986,"width":309.929347418547,"height":130.67307938561584,"type":"line_chart","id":"line_chart-1"},{"x":736.5028461949934,"y":283.93372482613427,"width":279.5387979615038,"height":91.35060483170635,"type":"matrix","id":"matrix-13"},{"x":467.4399409436186,"y":286.9028910947545,"width":94.84312396594771,"height":100.85737816096145,"type":"matrix","id":"matrix-15"},{"x":730.4301583391583,"y":548.51261213028,"width":291.68417367317363,"height":155.28489549680558,"type":"matrix","id":"matrix-6"},{"x":458.29029187237796,"y":556.2528332737069,"width":108.50895105395291,"height":153.70504848979814,"type":"matrix","id":"matrix-8"},{"x":59.52230691320056,"y":410.0750623128737,"width":346.93941373216614,"height":348.75642345254784,"type":"scatterplot","id":"scatterplot-0"},{"x":1306.5370694685896,"y":335.8211914480448,"width":253.04789484012144,"height":220.79677017195306,"type":"scatterplot","id":"scatterplot-3"},{"x":867.282921958952,"y":61.95496340108634,"width":564.7282308617953,"height":129.10184339299545,"type":"table","id":"table-2"}],"relations":[{"vislist":[{"vislist":["bar_chart-4"],"relation":null,"id":"group-0"}],"relation":"repeated","id":"relation-0"},{"vislist":[{"vislist":["box_plot-10","matrix-13","box_plot-11","bar_chart-12"],"relation":null,"id":"group-1"}],"relation":"stacked","id":"relation-1"},{"vislist":[{"vislist":["matrix-15","bar_chart-16"],"relation":null,"id":"group-2"}],"relation":"stacked","id":"relation-2"},{"vislist":[{"vislist":["bar_chart-14"],"relation":null,"id":"group-3"}],"relation":"repeated","id":"relation-3"},{"vislist":[{"vislist":["matrix-8","box_plot-9"],"relation":null,"id":"group-4"}],"relation":"stacked","id":"relation-4"},{"vislist":[{"vislist":["heatmap-7"],"relation":null,"id":"group-5"}],"relation":"repeated","id":"relation-5"}]},"3343_0":{"comp":[["bar_chart","bar_chart",["repeated"]],["bar_chart","tree",["nested"]]],"visType":["bar_chart","tree"],"compType":["repeated","nested"],"compressed_tree":[{"composite_pattern":"nested","visualization_type":[["bar_chart"],["tree"]]},{"composite_pattern":"repeated","visualization_type":[["bar_chart"]]}],"coOccurrence":[["bar_chart","tree",["coOccurrence"]]],"year":2020,"conference":["VAST"],"authors":["Dora Kiesel","Patrick Riehmann","Henning Wachsmuth","Benno Stein","Bernd Froehlich"],"title":"Visual Analysis of Argumentation in Essays","doi":"10.1109/TVCG.2020.3030425","abstract":"This paper presents a visual analytics system for exploring, analyzing and comparing argument structures in essay corpora. We provide an overview of the corpus by a list of ArguLines which represent the argument units of each essay by a sequence of glyphs. Each glyph encodes the stance, the depth and the relative position of an argument unit. The overview can be ordered in various ways to reveal patterns and outliers. Subsets of essays can be selected and analyzed in detail using the Argument Unit Occurrence Tree which aggregates the argument structures using hierarchical histograms. This hierarchical view facilitates the estimation of statistics and trends concerning the progression of the argumentation in the essays. It also provides insights into the commonalities and differences between selected subsets. The text view is the necessary textual basis to verify conclusions from the other views and the annotation process. Linking the views and interaction techniques for visual filtering, studying the evolution of stance within a subset of essays and scrutinizing the order of argumentative units enable a deep analysis of essay corpora. Our expert reviews confirmed the utility of the system and revealed detailed and previously unknown information about the argumentation in our sample corpus.","keywords":"Information Visualization, Text Analysis, User Interfaces, Visual Analytics, Argumentation Visualization, Glyph-basedTechniques, Text and Document Data, Tree-based Visualization, Coordinated and Multiple Views, Close and Distant Reading","caption":"Fig. 1. An extract from the visual analysis system for essay corpora: On the right, the ArguLines view represents each document\u2019s structure as an ArguLine in overview and detail (see Sect. 4 for more details). Currently, all documents of the filtered dataset are selected (highlighted by orange markings in the list). The filter excludes all essays with more than one major claim. Essay 108 has been opened in text view on the bottom left. The structure view called AUOT (argument unit occurrence tree) on the top left provides an aggregation of all essay structures currently selected for further analysis of argumentation patterns. Each node of the AUOT shows the fraction of essays with a major claim at the node\u2019s position in blue or the fraction of pro and con claims or premises in green and red. ","img_size":{"width":2134,"height":684},"subfigures":[{"x":10.328403312890803,"y":13.593809200145817,"width":2117.9931436229567,"height":663.0073275245444,"type":"interface","id":"interface-0"}],"visualizations":[{"x":72.28028546782264,"y":123.21994791994702,"width":1040.7501231349345,"height":420.59431580099096,"type":"bar_chart","id":"bar_chart-1"},{"x":1132.1657503179074,"y":76.6773563990248,"width":910.5914878145244,"height":596.6233530429533,"type":"bar_chart","id":"bar_chart-3"},{"x":2046.1956927636709,"y":71.12229203036848,"width":85.8081903443844,"height":172.27824722964579,"type":"bar_chart","id":"bar_chart-4"},{"x":33.12005860485467,"y":115.8428151008009,"width":1081.4241758319233,"height":431.57840624836825,"type":"tree","id":"tree-0"}],"relations":[{"vislist":[{"vislist":["bar_chart-1"],"relation":null,"id":"group-0"},{"vislist":["tree-0"],"relation":null,"id":"group-1"}],"relation":"nested","id":"relation-0"},{"vislist":[{"vislist":["bar_chart-3"],"relation":null,"id":"group-2"}],"relation":"repeated","id":"relation-1"}]},"1494_10":{"comp":[["scivis","scivis",["repeated"]],["comb","comb",["repeated"]],["line_chart","scivis",["large_view"]]],"visType":["scivis","comb","line_chart"],"compType":["repeated","large_view"],"compressed_tree":[{"composite_pattern":"repeated","visualization_type":[["scivis"]]},{"composite_pattern":"repeated","visualization_type":[[{"composite_pattern":"large_view","visualization_type":[["line_chart"],["scivis"]]}]]}],"coOccurrence":[["scivis","line_chart",["coOccurrence"]]],"year":2006,"conference":["Vis"],"authors":["Laurent Castanie","Christophe Mion","Xavier Cavin","Bruno L\xe9vy"],"title":"Distributed Shared Memory for Roaming Large Volumes","doi":"10.1109/TVCG.2006.135","abstract":"We present a cluster-based volume rendering system for roaming very large volumes. This system allows to move a gigabyte-sized probe inside a total volume of several tens or hundreds of gigabytes in real-time. While the size of the probe is limited by the total amount of texture memory on the cluster, the size of the total data set has no theoretical limit. The cluster is used as a distributed graphics processing unit that both aggregates graphics power and graphics memory. A hardware-accelerated volume renderer runs in parallel on the cluster nodes and the final image compositing is implemented using a pipelined sort-last rendering algorithm. Meanwhile, volume bricking and volume paging allow efficient data caching. On each rendering node, a distributed hierarchical cache system implements a global software-based distributed shared memory on the cluster. In case of a cache miss, this system first checks page residency on the other cluster nodes instead of directly accessing local disks. Using two gigabit Ethernet network interfaces per node, we accelerate data fetching by a factor of 4 compared to directly accessing local disks. The system also implements asynchronous disk access and texture loading, which makes it possible to overlap data loading, volume slicing and rendering for optimal volume roaming","keywords":"Large volumes, volume roaming, out-of-core, hierarchical caching, distributed shared memory, hardware-accelerated volume visualization, graphics hardware, parallel rendering, graphics cluster","caption":"Fig. 10. Roaming a gigabyte-sized probe (1024x1024x1024, 8 bits per voxel) inside a 107 GB data set (30 copies of the Visible Human: 5580x5400x3840, 8 bits per voxel) on a 16-node PC cluster. Interactive roaming along the main axes of the volume at 12 fps on average (top). Zooming in high-quality pre-integrated volume rendering (middle) enhanced with accurate lighting on the vertebrae (bottom). The rendered bricks are shown in blue (middle and bottom, left). Transparent bricks are discarded using bit-wise AND operations between encoded transfer functions and encoded brick histograms. ","img_size":{"width":2135,"height":2258},"subfigures":[{"x":26.234074509009194,"y":35.24048632710529,"width":2094.866419427704,"height":2206.024303000621,"type":"interface","id":"interface-0"}],"visualizations":[{"x":56.11626767496517,"y":1019.6088933392325,"width":406.9389982604928,"height":397.6665446515788,"type":"line_chart","id":"line_chart-2"},{"x":1106.8767267044148,"y":1019.320341428826,"width":408.4620001971864,"height":376.6541602084218,"type":"line_chart","id":"line_chart-3"},{"x":30.932577429528035,"y":1821.5299945389338,"width":417.7836878595836,"height":388.18267199616747,"type":"line_chart","id":"line_chart-4"},{"x":1106.7661643623626,"y":1830.4822313704622,"width":402.5158406584258,"height":367.19398572397523,"type":"line_chart","id":"line_chart-5"},{"x":23.045674308672254,"y":41.47229123374564,"width":2076.5740829369342,"height":577.4332859986425,"type":"scivis","id":"scivis-0"},{"x":28.99387455624945,"y":657.6923526223528,"width":2043.0921876617685,"height":1544.0367535373477,"type":"scivis","id":"scivis-1"}],"relations":[{"vislist":[{"vislist":["scivis-0"],"relation":null,"id":"group-0"}],"relation":"repeated","id":"relation-0"},{"vislist":[{"vislist":[{"vislist":[{"vislist":["line_chart-2","line_chart-3","line_chart-4","line_chart-5"],"relation":null,"id":"group-1"},{"vislist":["scivis-1"],"relation":null,"id":"group-2"}],"relation":"large_view","id":"relation-1"}],"relation":null,"id":"group-3"}],"relation":"repeated","id":"relation-2"}]},"1521_6":{"comp":[["scivis","scivis",["repeated"]]],"visType":["scivis"],"compType":["repeated"],"compressed_tree":[{"composite_pattern":"repeated","visualization_type":[["scivis"]]}],"coOccurrence":[["scivis","scivis",["coOccurrence"]]],"year":2006,"conference":["Vis"],"authors":["Steven P. Callahan","Louis Bavoil","Valerio Pascucci","Cl\xe1udio T. Silva"],"title":"Progressive Volume Rendering of Large Unstructured Grids","doi":"10.1109/TVCG.2006.171","abstract":"We describe a new progressive technique that allows real-time rendering of extremely large tetrahedral meshes. Our approach uses a client-server architecture to incrementally stream portions of the mesh from a server to a client which refines the quality of the approximate rendering until it converges to a full quality rendering. The results of previous steps are re-used in each subsequent refinement, thus leading to an efficient rendering. Our novel approach keeps very little geometry on the client and works by refining a set of rendered images at each step. Our interactive representation of the dataset is efficient, light-weight, and high quality. We present a framework for the exploration of large datasets stored on a remote server with a thin client that is capable of rendering and managing full quality volume visualizations","keywords":"Volume Rendering, Large Unstructured Grids, Client-Server, Progressive Rendering, Level-of-Detail","caption":"Fig. 4. A snapshot of the interaction with the Completed Modefor the SF1 dataset. Upon completion of a full quality rendering, the image is automatically stored for future browsing by selecting the icons at the bottom of the window. The user may also save intermediate steps with a keystroke.","img_size":{"width":930,"height":969},"subfigures":[{"x":9.517144693502694,"y":8.503416958562378,"width":908.3205845382508,"height":945.3753582479442,"type":"interface","id":"interface-0"}],"visualizations":[{"x":22.617569861784744,"y":55.2658950655734,"width":888.7325493885461,"height":798.9079393544615,"type":"scivis","id":"scivis-0"},{"x":20.00519593823412,"y":861.1792545173821,"width":893.9572972356484,"height":92.32026321903894,"type":"scivis","id":"scivis-1"}],"relations":[{"vislist":[{"vislist":["scivis-1"],"relation":null,"id":"group-0"}],"relation":"repeated","id":"relation-0"}]},"1534_5":{"comp":[["scivis","scivis",["repeated"]]],"visType":["scivis"],"compType":["repeated"],"compressed_tree":[{"composite_pattern":"repeated","visualization_type":[["scivis"]]},{"composite_pattern":"repeated","visualization_type":[["scivis"]]}],"coOccurrence":[["scivis","scivis",["coOccurrence"]]],"year":2006,"conference":["Vis"],"authors":["Min Chen","Ralf P. Botchen","Rudy Hashim","Daniel Weiskopf","Thomas Ertl","Ian M. Thornton"],"title":"Visual Signatures in Video Visualization","doi":"10.1109/TVCG.2006.194","abstract":"Video visualization is a computation process that extracts meaningful information from original video data sets and conveys the extracted information to users in appropriate visual representations. This paper presents a broad treatment of the subject, following a typical research pipeline involving concept formulation, system development, a path-finding user study, and a field trial with real application data. In particular, we have conducted a fundamental study on the visualization of motion events in videos. We have, for the first time, deployed flow visualization techniques in video visualization. We have compared the effectiveness of different abstract visual representations of videos. We have conducted a user study to examine whether users are able to learn to recognize visual signatures of motions, and to assist in the evaluation of different visualization techniques. We have applied our understanding and the developed techniques to a set of application video clips. Our study has demonstrated that video visualization is both technically feasible and cost-effective. It has provided the first set of evidence confirming that ordinary users can be accustomed to the visual features depicted in video visualizations, and can learn to recognize visual signatures of a variety of motion events","keywords":"Video visualization, volume visualization, flow visualization, human factors, user study, visual signatures, video processing, optical flow, GPU rendering","caption":"Fig. 4. Example screenshots of the main two tasks for each trial.","img_size":{"width":1053,"height":459},"subfigures":[{"x":8.121828533544418,"y":9.946875256024802,"width":514.3821522201548,"height":395.5279613663381,"type":"interface","id":"interface-0"},{"x":536.6217744697041,"y":10.710054535461829,"width":510.543696089366,"height":395.53066554857367,"type":"interface","id":"interface-1"}],"visualizations":[{"x":17.39297009582704,"y":31.99412446410514,"width":490.6493212653214,"height":288.26387344114954,"type":"scivis","id":"scivis-0"},{"x":553.3801994805128,"y":91.71863261262837,"width":238.81511625209535,"height":243.0742502784611,"type":"scivis","id":"scivis-1"},{"x":888.3458481831534,"y":74.42902203561013,"width":131.88005930030874,"height":273.0122593615998,"type":"scivis","id":"scivis-2"}],"relations":[{"vislist":[{"vislist":["scivis-0"],"relation":null,"id":"group-0"}],"relation":"repeated","id":"relation-0"},{"vislist":[{"vislist":["scivis-2"],"relation":null,"id":"group-1"}],"relation":"repeated","id":"relation-1"}]},"2592_1":{"comp":[["bar_chart","bar_chart",["repeated"]],["bar_chart","scatterplot",["accompanied"]],["scatterplot","bar_chart",["accompanied"]]],"visType":["bar_chart","scatterplot"],"compType":["repeated","accompanied"],"compressed_tree":[{"composite_pattern":"accompanied","visualization_type":[["scatterplot","bar_chart"]]},{"composite_pattern":"repeated","visualization_type":[["bar_chart"]]}],"coOccurrence":[],"year":2015,"conference":["InfoVis"],"authors":["Matthew Brehmer","Jocelyn Ng","Kevin Tate","Tamara Munzner"],"title":"Matches, Mismatches, and Methods: Multiple-View Workflows for Energy Portfolio Analysis","doi":"10.1109/TVCG.2015.2466971","abstract":"The energy performance of large building portfolios is challenging to analyze and monitor, as current analysis tools are not scalable or they present derived and aggregated data at too coarse of a level. We conducted a visualization design study, beginning with a thorough work domain analysis and a characterization of data and task abstractions. We describe generalizable visual encoding design choices for time-oriented data framed in terms of matches and mismatches, as well as considerations for workflow design. Our designs address several research questions pertaining to scalability, view coordination, and the inappropriateness of line charts for derived and aggregated data due to a combination of data semantics and domain convention. We also present guidelines relating to familiarity and trust, as well as methodological considerations for visualization design studies. Our designs were adopted by our collaborators and incorporated into the design of an energy analysis software application that will be deployed to tens of thousands of energy workers in their client base.","keywords":"Design study, design methodologies, time series data, task and requirements analysis, coordinated and multiple views","caption":"Fig. 1. Energy Manager, our collaborators\u2019 existing energy analysis tool. (a) A dashboard for a portfolio of buildings. (b) A superimposed line chart of energy demand and (c) a grouped bar chart of energy consumption (bottom) for a group of three restaurant buildings within this portfolio.","img_size":{"width":2154,"height":1101},"subfigures":[{"x":13.42269767450586,"y":25.380585486717152,"width":1058.5942943040975,"height":1058.0632177247116,"type":"interface","id":"interface-0"},{"x":1091.3972807702874,"y":22.276426754725264,"width":1042.894768748766,"height":529.0833482354974,"type":"interface","id":"interface-1"},{"x":1089.853993884801,"y":563.6912614495731,"width":1047.5458524909666,"height":519.7598082314556,"type":"interface","id":"interface-2"}],"visualizations":[{"x":187.06126482213438,"y":106.61857707509881,"width":857.300395256917,"height":211.0612648221344,"type":"bar_chart","id":"bar_chart-0"},{"x":187.06126482213438,"y":352.49407114624506,"width":850.7727272727271,"height":217.58893280632415,"type":"bar_chart","id":"bar_chart-1"},{"x":1268.4782608695652,"y":624.4802371541502,"width":837.7173913043479,"height":435.1778656126483,"type":"bar_chart","id":"bar_chart-2"},{"x":1322.8308931185945,"y":117.49802371541504,"width":781.1888697272551,"height":403.17986793905067,"type":"line_chart","id":"line_chart-3"},{"x":185.4371203380853,"y":350.2062204221314,"width":858.3160492097118,"height":224.7998862927213,"type":"scatterplot","id":"scatterplot-6"},{"x":169.65415019762847,"y":644.0632411067194,"width":889.9387351778657,"height":213.23715415019763,"type":"table","id":"table-4"},{"x":165.30237154150197,"y":883.4110671936761,"width":894.2905138339921,"height":191.4782608695654,"type":"table","id":"table-5"}],"relations":[{"vislist":[{"vislist":["scatterplot-6","bar_chart-1"],"relation":null,"id":"group-0"}],"relation":"accompanied","id":"relation-0"},{"vislist":[{"vislist":["bar_chart-1","bar_chart-0"],"relation":null,"id":"group-1"}],"relation":"repeated","id":"relation-1"}]},"2592_9":{"comp":[["bar_chart","bar_chart",["repeated"]],["bar_chart","line_chart",["repeated"]],["line_chart","bar_chart",["repeated"]],["heatmap","box_plot",["stacked"]],["box_plot","heatmap",["stacked"]]],"visType":["bar_chart","line_chart","heatmap","box_plot"],"compType":["repeated","stacked"],"compressed_tree":[{"composite_pattern":"repeated","visualization_type":[["bar_chart"]]},{"composite_pattern":"repeated","visualization_type":[["line_chart","bar_chart"]]},{"composite_pattern":"stacked","visualization_type":[["heatmap","box_plot"]]},{"composite_pattern":"stacked","visualization_type":[["heatmap","box_plot"]]}],"coOccurrence":[["line_chart","bar_chart",["coOccurrence"]]],"year":2015,"conference":["InfoVis"],"authors":["Matthew Brehmer","Jocelyn Ng","Kevin Tate","Tamara Munzner"],"title":"Matches, Mismatches, and Methods: Multiple-View Workflows for Energy Portfolio Analysis","doi":"10.1109/TVCG.2015.2466971","abstract":"The energy performance of large building portfolios is challenging to analyze and monitor, as current analysis tools are not scalable or they present derived and aggregated data at too coarse of a level. We conducted a visualization design study, beginning with a thorough work domain analysis and a characterization of data and task abstractions. We describe generalizable visual encoding design choices for time-oriented data framed in terms of matches and mismatches, as well as considerations for workflow design. Our designs address several research questions pertaining to scalability, view coordination, and the inappropriateness of line charts for derived and aggregated data due to a combination of data semantics and domain convention. We also present guidelines relating to familiarity and trust, as well as methodological considerations for visualization design studies. Our designs were adopted by our collaborators and incorporated into the design of an energy analysis software application that will be deployed to tens of thousands of energy workers in their client base.","keywords":"Design study, design methodologies, time series data, task and requirements analysis, coordinated and multiple views","caption":"Fig. 8. The redesigned Energy Manager that incorporates many aspects of our prototype designs. On the left, the Site Overview (a time series matrix) is juxtaposed with coordinated Value Range (boxplot) views. An energy worker can easily switch between units such as energy consumption or energy demand and filter or aggregate the set of buildings to those that share a common categorical tag; by selecting a column of the matrix, she can drill down to faceted or stacked visualizations of consumption (top middle, top right) or demand (bottom middle, bottom right).","img_size":{"width":2091,"height":1281},"subfigures":[{"x":8.840238833698482,"y":54.36340047825511,"width":624.3709379092014,"height":545.8720767557095,"type":"interface","id":"interface-0"},{"x":732.1151462181668,"y":57.83688053896821,"width":625.0197696597729,"height":544.1742880501034,"type":"interface","id":"interface-1"},{"x":1456.6406222128,"y":57.84698287734635,"width":626.6673399977992,"height":545.9038071786204,"type":"interface","id":"interface-2"},{"x":1449.6521992003072,"y":684.1714894382912,"width":631.8944965033251,"height":535.5586958006493,"type":"interface","id":"interface-3"},{"x":730.3988156216465,"y":682.4499978976922,"width":630.2023687567063,"height":539.001678881848,"type":"interface","id":"interface-4"}],"visualizations":[{"x":1485.5235632555732,"y":802.4750347198166,"width":567.9101047077393,"height":210.27282548474898,"type":"area_chart","id":"area_chart-0"},{"x":764.332475476544,"y":195.06882337870962,"width":245.17515465425095,"height":197.30184730975049,"type":"bar_chart","id":"bar_chart-1"},{"x":1057.701083015493,"y":196.99180764238727,"width":247.47989319169233,"height":193.425074415612,"type":"bar_chart","id":"bar_chart-2"},{"x":763.4519569187023,"y":447.8766110653955,"width":244.2235788075909,"height":149.13919879183555,"type":"bar_chart","id":"bar_chart-3"},{"x":1481.7714855105048,"y":175.99884178856308,"width":558.8638549112945,"height":217.54947859683122,"type":"bar_chart","id":"bar_chart-4"},{"x":1059.334827555743,"y":446.6556731119466,"width":243.6861650713622,"height":151.43903633772345,"type":"bar_chart","id":"bar_chart-5"},{"x":1061.8981964448872,"y":1071.801478911654,"width":254.06505250245067,"height":152.4390315014705,"type":"bar_chart","id":"bar_chart-6"},{"x":465.32568373333174,"y":198.90334028164767,"width":146.56643585767353,"height":402.47045776829725,"type":"box_plot","id":"box_plot-20"},{"x":464.0035198600352,"y":832.5345563209124,"width":145.2455138128374,"height":391.6427777776497,"type":"box_plot","id":"box_plot-21"},{"x":35.543185146835384,"y":213.63804506283577,"width":412.01172996784044,"height":385.5774245504239,"type":"heatmap","id":"heatmap-7"},{"x":31.399038252029413,"y":829.7017900035202,"width":410.16726009051206,"height":392.32030944399366,"type":"heatmap","id":"heatmap-8"},{"x":1061.2171242359025,"y":822.2678364573544,"width":253.15767731494225,"height":185.10453825178558,"type":"line_chart","id":"line_chart-10"},{"x":766.0938853170335,"y":1073.6162292866716,"width":250.14500225434404,"height":144.7387797140384,"type":"line_chart","id":"line_chart-11"},{"x":769.9496890455929,"y":821.3604612698457,"width":253.15767731494213,"height":183.28978787676817,"type":"line_chart","id":"line_chart-9"},{"x":16.040311182085627,"y":66.23735911541736,"width":616.8902034857045,"height":543.5246348398925,"type":"others","id":"others-14"},{"x":733.7613006360305,"y":62.18570788148767,"width":626.120898588889,"height":550.2622473598295,"type":"others","id":"others-15"},{"x":1458.624726106677,"y":60.800079944337746,"width":615.7839487644073,"height":544.8393635466005,"type":"others","id":"others-16"},{"x":18.6765806712253,"y":679.4942304182925,"width":616.9046642293305,"height":547.4975353115119,"type":"others","id":"others-17"},{"x":735.0640668316562,"y":690.5695638540242,"width":622.1936162671614,"height":540.3694578671867,"type":"others","id":"others-18"},{"x":1450.7922044983643,"y":683.9467422898433,"width":620.8749925372282,"height":537.2355170325072,"type":"others","id":"others-19"}],"relations":[{"vislist":[{"vislist":["bar_chart-2","bar_chart-3","bar_chart-1","bar_chart-5"],"relation":null,"id":"group-0"}],"relation":"repeated","id":"relation-0"},{"vislist":[{"vislist":["line_chart-9","line_chart-10","bar_chart-6","line_chart-11"],"relation":null,"id":"group-1"}],"relation":"repeated","id":"relation-1"},{"vislist":[{"vislist":["heatmap-7","box_plot-20"],"relation":null,"id":"group-3"}],"relation":"stacked","id":"relation-3"},{"vislist":[{"vislist":["heatmap-8","box_plot-21"],"relation":null,"id":"group-4"}],"relation":"stacked","id":"relation-4"}]},"2595_0":{"comp":[["bar_chart","bar_chart",["repeated"]],["pie_chart","matrix",["nested"]]],"visType":["bar_chart","pie_chart","matrix"],"compType":["repeated","nested"],"compressed_tree":[{"composite_pattern":"nested","visualization_type":[["pie_chart"],["matrix"]]},{"composite_pattern":"repeated","visualization_type":[["bar_chart"]]}],"coOccurrence":[["pie_chart","matrix",["coOccurrence"]],["pie_chart","bar_chart",["coOccurrence"]],["matrix","bar_chart",["coOccurrence"]]],"year":2015,"conference":["InfoVis"],"authors":["Mehmet Adil Yal\xe7in","Niklas Elmqvist","Benjamin B. Bederson"],"title":"AggreSet: Rich and Scalable Set Exploration using Visualizations of Element Aggregations","doi":"10.1109/TVCG.2015.2467051","abstract":"Datasets commonly include multi-value (set-typed) attributes that describe set memberships over elements, such as genres per movie or courses taken per student. Set-typed attributes describe rich relations across elements, sets, and the set intersections. Increasing the number of sets results in a combinatorial growth of relations and creates scalability challenges. Exploratory tasks (e.g. selection, comparison) have commonly been designed in separation for set-typed attributes, which reduces interface consistency. To improve on scalability and to support rich, contextual exploration of set-typed data, we present AggreSet. AggreSet creates aggregations for each data dimension: sets, set-degrees, set-pair intersections, and other attributes. It visualizes the element count per aggregate using a matrix plot for set-pair intersections, and histograms for set lists, set-degrees and other attributes. Its non-overlapping visual design is scalable to numerous and large sets. AggreSet supports selection, filtering, and comparison as core exploratory tasks. It allows analysis of set relations inluding subsets, disjoint sets and set intersection strength, and also features perceptual set ordering for detecting patterns in set matrices. Its interaction is designed for rich and rapid data exploration. We demonstrate results on a wide range of datasets from different domains with varying characteristics, and report on expert reviews and a case study using student enrollment and degree data with assistant deans at a major public university.","keywords":"Multi-valued attributes, sets, visualization, set visualization, data exploration, interaction, design, scalability","caption":"Fig. 1. Exploration of a movie dataset with multiple genres (sets) and ratings  using AggreSet.  Aggregate  histograms  are used for set-list  and  set-degrees,  whereas  the aggregate matrix (left)  is  used  for  set-pair intersections.  The  gray distributions visualize the number of elements per aggregate. The Action genre is selected by mouse-over.  Mouse  click  will  filter.  We  compare  Romance(black  lines)  to  Action  (orange  areas).  Most  movies  (+2k)  have  one  genre.  7    movies  have  maximum (5) genres. The Godfather  is  the  only  Action  movie  in  the  rating-sorted  movie  list.  Of Thrillers,  133  have  Action  (orange  bar) and  few  have  Romance (black line). More than 50% of SciFiand Adventure movies have Action, while very few have Romance. Thrilleris more common with Action than with Children movies (circle size). There is no Childrenmovie with Crime (empty intersection). ","img_size":{"width":1976,"height":628},"subfigures":[{"x":20.941337670374935,"y":19.83338224718302,"width":1928.3764301316014,"height":596.9321308729727,"type":"interface","id":"interface-0"}],"visualizations":[{"x":1560.0000000000005,"y":25.483870967741915,"width":380.7741935483872,"height":271.74193548387103,"type":"bar_chart","id":"bar_chart-0"},{"x":1561.6774193548395,"y":300.5806451612903,"width":380.7741935483872,"height":280.12903225806446,"type":"bar_chart","id":"bar_chart-1"},{"x":617.2903225806456,"y":27.161290322580637,"width":236.51612903225816,"height":550.1935483870968,"type":"bar_chart","id":"bar_chart-2"},{"x":15.646764146798906,"y":28.83870967741928,"width":582.4257714671402,"height":573.6774193548387,"type":"matrix","id":"matrix-3"},{"x":11.945630703627593,"y":27.16129032258062,"width":581.0486097543583,"height":573.6774193548381,"type":"pie_chart","id":"pie_chart-4"}],"relations":[{"vislist":[{"vislist":["pie_chart-4"],"relation":null,"id":"group-2"},{"vislist":["matrix-3"],"relation":null,"id":"group-1"}],"relation":"nested","id":"relation-1"},{"vislist":[{"vislist":["bar_chart-0","bar_chart-1"],"relation":null,"id":"group-5"}],"relation":"repeated","id":"relation-4"}]},"2599_0":{"comp":[["scatterplot","scatterplot",["repeated"]]],"visType":["scatterplot"],"compType":["repeated"],"compressed_tree":[{"composite_pattern":"repeated","visualization_type":[["scatterplot"]]}],"coOccurrence":[["scatterplot","scatterplot",["coOccurrence"]]],"year":2015,"conference":["InfoVis"],"authors":["Kanit Wongsuphasawat","Dominik Moritz","Anushka Anand","Jock D. Mackinlay","Bill Howe","Jeffrey Heer"],"title":"Voyager: Exploratory Analysis via Faceted Browsing of Visualization Recommendations","doi":"10.1109/TVCG.2015.2467191","abstract":"General visualization tools typically require manual specification of views: analysts must select data variables and then choose which transformations and visual encodings to apply. These decisions often involve both domain and visualization design expertise, and may impose a tedious specification process that impedes exploration. In this paper, we seek to complement manual chart construction with interactive navigation of a gallery of automatically-generated visualizations. We contribute Voyager, a mixed-initiative system that supports faceted browsing of recommended charts chosen according to statistical and perceptual measures. We describe Voyager\'s architecture, motivating design principles, and methods for generating and interacting with visualization recommendations. In a study comparing Voyager to a manual visualization specification tool, we find that Voyager facilitates exploration of previously unseen data and leads to increased data variable coverage. We then distill design implications for visualization tools, in particular the need to balance rapid exploration and targeted question-answering.","keywords":"User interfaces, information visualization, exploratory analysis, visualization recommendation, mixed-initiative systems","caption":"Fig. 1. Voyager: a recommendation-powered visualization browser. The schema panel (left) lists data variables selectable by users. The main gallery (right) presents suggested visualizations of different variable subsets and transformations.","img_size":{"width":1904,"height":1106},"subfigures":[{"x":24.93723231093554,"y":14.233907392446824,"width":1852.615029956322,"height":1079.0428757136474,"type":"interface","id":"interface-0"}],"visualizations":[{"x":1321.070021881838,"y":210.55142231947485,"width":326.71772428884015,"height":242.0131291028447,"type":"bar_chart","id":"bar_chart-0"},{"x":382.05908096280086,"y":597.7724288840262,"width":430.7833698030635,"height":353.33916849015316,"type":"scatterplot","id":"scatterplot-1"},{"x":897.5470459518601,"y":602.6126914660831,"width":428.36323851203497,"height":346.0787746170678,"type":"scatterplot","id":"scatterplot-2"},{"x":1413.0350109409196,"y":595.3522975929978,"width":438.0437636761488,"height":353.33916849015316,"type":"scatterplot","id":"scatterplot-3"},{"x":563.7773797043048,"y":201.34154324392594,"width":349.1868890811842,"height":255.13387717781035,"type":"stripe_graph","id":"stripe_graph-4"}],"relations":[{"vislist":[{"vislist":["scatterplot-1","scatterplot-2","scatterplot-3"],"relation":null,"id":"group-1"}],"relation":"repeated","id":"relation-1"}]},"2599_1":{"comp":[["bar_chart","bar_chart",["repeated"]]],"visType":["bar_chart"],"compType":["repeated"],"compressed_tree":[{"composite_pattern":"repeated","visualization_type":[["bar_chart"]]}],"coOccurrence":[["bar_chart","bar_chart",["coOccurrence"]]],"year":2015,"conference":["InfoVis"],"authors":["Kanit Wongsuphasawat","Dominik Moritz","Anushka Anand","Jock D. Mackinlay","Bill Howe","Jeffrey Heer"],"title":"Voyager: Exploratory Analysis via Faceted Browsing of Visualization Recommendations","doi":"10.1109/TVCG.2015.2467191","abstract":"General visualization tools typically require manual specification of views: analysts must select data variables and then choose which transformations and visual encodings to apply. These decisions often involve both domain and visualization design expertise, and may impose a tedious specification process that impedes exploration. In this paper, we seek to complement manual chart construction with interactive navigation of a gallery of automatically-generated visualizations. We contribute Voyager, a mixed-initiative system that supports faceted browsing of recommended charts chosen according to statistical and perceptual measures. We describe Voyager\'s architecture, motivating design principles, and methods for generating and interacting with visualization recommendations. In a study comparing Voyager to a manual visualization specification tool, we find that Voyager facilitates exploration of previously unseen data and leads to increased data variable coverage. We then distill design implications for visualization tools, in particular the need to balance rapid exploration and targeted question-answering.","keywords":"User interfaces, information visualization, exploratory analysis, visualization recommendation, mixed-initiative systems","caption":"Fig. 2. The main gallery shows univariate summaries upon loading.","img_size":{"width":1072,"height":1043},"subfigures":[{"x":23.43763429309041,"y":63.107184529085636,"width":1010.8848922131375,"height":976.6204482828081,"type":"single","id":"single-0"}],"visualizations":[{"x":44.16958424507665,"y":116.39606126914663,"width":246.48577680525173,"height":184.86433260393878,"type":"bar_chart","id":"bar_chart-0"},{"x":386.5109409190373,"y":107.26695842450764,"width":358.31728665207874,"height":273.8730853391685,"type":"bar_chart","id":"bar_chart-1"},{"x":779.0623632385123,"y":118.67833698030633,"width":235.07439824945297,"height":143.78336980306347,"type":"bar_chart","id":"bar_chart-2"},{"x":370.5350109409191,"y":435.91466083150976,"width":273.8730853391684,"height":260.1794310722101,"type":"bar_chart","id":"bar_chart-3"},{"x":717.4409190371994,"y":440.4792122538294,"width":280.7199124726476,"height":246.48577680525173,"type":"bar_chart","id":"bar_chart-4"},{"x":35.04048140043766,"y":764.5623632385123,"width":298.97811816192575,"height":248.76805251641136,"type":"bar_chart","id":"bar_chart-5"},{"x":391.0754923413567,"y":762.2800875273522,"width":276.1553610503283,"height":257.8971553610503,"type":"bar_chart","id":"bar_chart-6"},{"x":744.8282275711159,"y":762.2800875273522,"width":251.05032822757133,"height":260.1794310722101,"type":"bar_chart","id":"bar_chart-7"},{"x":44.16958424507665,"y":438.1969365426697,"width":262.46170678337,"height":255.61487964989055,"type":"line_chart","id":"line_chart-8"}],"relations":[{"vislist":[{"vislist":["bar_chart-0","bar_chart-1","bar_chart-2","bar_chart-3","bar_chart-4","bar_chart-5","bar_chart-6","bar_chart-7"],"relation":null,"id":"group-0"}],"relation":"repeated","id":"relation-0"}]},"2599_3":{"comp":[["scatterplot","scatterplot",["repeated"]]],"visType":["scatterplot"],"compType":["repeated"],"compressed_tree":[{"composite_pattern":"repeated","visualization_type":[["scatterplot"]]}],"coOccurrence":[["scatterplot","scatterplot",["coOccurrence"]]],"year":2015,"conference":["InfoVis"],"authors":["Kanit Wongsuphasawat","Dominik Moritz","Anushka Anand","Jock D. Mackinlay","Bill Howe","Jeffrey Heer"],"title":"Voyager: Exploratory Analysis via Faceted Browsing of Visualization Recommendations","doi":"10.1109/TVCG.2015.2467191","abstract":"General visualization tools typically require manual specification of views: analysts must select data variables and then choose which transformations and visual encodings to apply. These decisions often involve both domain and visualization design expertise, and may impose a tedious specification process that impedes exploration. In this paper, we seek to complement manual chart construction with interactive navigation of a gallery of automatically-generated visualizations. We contribute Voyager, a mixed-initiative system that supports faceted browsing of recommended charts chosen according to statistical and perceptual measures. We describe Voyager\'s architecture, motivating design principles, and methods for generating and interacting with visualization recommendations. In a study comparing Voyager to a manual visualization specification tool, we find that Voyager facilitates exploration of previously unseen data and leads to increased data variable coverage. We then distill design implications for visualization tools, in particular the need to balance rapid exploration and targeted question-answering.","keywords":"User interfaces, information visualization, exploratory analysis, visualization recommendation, mixed-initiative systems","caption":"Fig. 4. The expanded gallery for cylinder, horsepower, and acceleration.(a) The main panel presents the selected chart in an enlarged view. (b)The sidebar shows alternative encodings for the expanded data. ","img_size":{"width":1059,"height":624},"subfigures":[{"x":13.471454989538035,"y":24.12375471087984,"width":1022.6761975513853,"height":592.7989801097067,"type":"single","id":"single-0"}],"visualizations":[{"x":46.821663019693624,"y":102.40700218818378,"width":596.6914660831509,"height":519.9181493231338,"type":"scatterplot","id":"scatterplot-0"},{"x":717.246170678337,"y":84.6564551422319,"width":259.43107221006574,"height":200.71772428884023,"type":"scatterplot","id":"scatterplot-1"},{"x":713.1498905908096,"y":476.5339168490152,"width":263.5273522975931,"height":145.79123466230226,"type":"scatterplot","id":"scatterplot-2"},{"x":674.3771981580136,"y":344.6202686046015,"width":92.84984200983956,"height":101.99414463202073,"type":"scatterplot","id":"scatterplot-3"},{"x":768.633855955881,"y":347.4339001806572,"width":78.78168412956096,"height":98.47710516195104,"type":"scatterplot","id":"scatterplot-4"},{"x":850.2291716614977,"y":347.4339001806572,"width":77.37486834153299,"height":99.88392094997891,"type":"scatterplot","id":"scatterplot-5"},{"x":929.7142636850725,"y":346.73049228664337,"width":80.89190781160265,"height":99.88392094997891,"type":"scatterplot","id":"scatterplot-6"}],"relations":[{"vislist":[{"vislist":["scatterplot-3","scatterplot-4","scatterplot-5","scatterplot-6","scatterplot-0","scatterplot-1","scatterplot-2"],"relation":null,"id":"group-1"}],"relation":"repeated","id":"relation-0"}]},"2611_0":{"comp":[["word_cloud","word_cloud",["repeated"]]],"visType":["word_cloud"],"compType":["repeated"],"compressed_tree":[{"composite_pattern":"repeated","visualization_type":[["word_cloud"]]}],"coOccurrence":[["word_cloud","word_cloud",["coOccurrence"]]],"year":2015,"conference":["InfoVis"],"authors":["Uta Hinrichs","Stefania Forlini","Bridget Moynihan"],"title":"Speculative Practices: Utilizing InfoVis to Explore Untapped Literary Collections","doi":"10.1109/TVCG.2015.2467452","abstract":"In this paper we exemplify how information visualization supports speculative thinking, hypotheses testing, and preliminary interpretation processes as part of literary research. While InfoVis has become a buzz topic in the digital humanities, skepticism remains about how effectively it integrates into and expands on traditional humanities research approaches. From an InfoVis perspective, we lack case studies that show the specific design challenges that make literary studies and humanities research at large a unique application area for information visualization. We examine these questions through our case study of the Speculative W@nderverse, a visualization tool that was designed to enable the analysis and exploration of an untapped literary collection consisting of thousands of science fiction short stories. We present the results of two empirical studies that involved general-interest readers and literary scholars who used the evolving visualization prototype as part of their research for over a year. Our findings suggest a design space for visualizing literary collections that is defined by (1) their academic and public relevance, (2) the tension between qualitative vs. quantitative methods of interpretation, (3) result-vs. process-driven approaches to InfoVis, and (4) the unique material and visual qualities of cultural collections. Through the Speculative W@nderverse we demonstrate how visualization can bridge these sometimes contradictory perspectives by cultivating curiosity and providing entry points into literary collections while, at the same time, supporting multiple aspects of humanities research processes.","keywords":"Digital Humanities, Interlinked Visualization, Literary Studies, Cultural Collections, Science Fiction","caption":"Fig. 1: The Speculative W@nderverse of the B. Gibson Anthologies.","img_size":{"width":1932,"height":893},"subfigures":[{"x":14.872380527041017,"y":16.2314145387588,"width":1888.2225868363198,"height":866.1461041600033,"type":"interface","id":"interface-0"}],"visualizations":[{"x":29.082375478927126,"y":755.2654572213177,"width":1863.1691250226097,"height":127.48712446351931,"type":"bar_chart","id":"bar_chart-0"},{"x":12.527377521613834,"y":63.71902017291068,"width":723.8040345821325,"height":719.628242074928,"type":"proportional_area_chart","id":"proportional_area_chart-1"},{"x":15.690613026819968,"y":66.7183908045977,"width":716.7950191570881,"height":715.0842911877396,"type":"tree","id":"tree-2"},{"x":15.690613026819968,"y":65.00766283524901,"width":718.5057471264369,"height":718.5057471264369,"type":"unit_visualization","id":"unit_visualization-3"},{"x":1430.462643678161,"y":699.6877394636016,"width":446.49999999999983,"height":70.13984674329504,"type":"word_cloud","id":"word_cloud-10"},{"x":735.9070881226053,"y":261.7413793103449,"width":679.1590038314177,"height":348.9885057471264,"type":"word_cloud","id":"word_cloud-4"},{"x":1428.7519157088122,"y":85.53639846743297,"width":448.2107279693485,"height":114.61877394636018,"type":"word_cloud","id":"word_cloud-5"},{"x":1432.1733716475094,"y":206.99808429118772,"width":439.6570881226054,"height":118.04022988505747,"type":"word_cloud","id":"word_cloud-6"},{"x":1428.7519157088122,"y":330.17049808429124,"width":446.49999999999983,"height":118.04022988505747,"type":"word_cloud","id":"word_cloud-7"},{"x":1428.7519157088122,"y":448.21072796934874,"width":441.367816091954,"height":123.1724137931034,"type":"word_cloud","id":"word_cloud-8"},{"x":1435.594827586207,"y":569.6724137931035,"width":434.52490421455934,"height":126.59386973180081,"type":"word_cloud","id":"word_cloud-9"}],"relations":[{"vislist":[{"vislist":["word_cloud-5","word_cloud-6","word_cloud-7","word_cloud-8"],"relation":null,"id":"group-2"}],"relation":"repeated","id":"relation-0"}]},"2614_0":{"comp":[["scatterplot","scatterplot",["repeated"]]],"visType":["scatterplot"],"compType":["repeated"],"compressed_tree":[{"composite_pattern":"repeated","visualization_type":[["scatterplot"]]}],"coOccurrence":[["scatterplot","scatterplot",["coOccurrence"]]],"year":2015,"conference":["InfoVis"],"authors":["Yong Wan","Qiaomu Shen","Daniel W. Archambault","Zhiguang Zhou","Min Zhu","Sixiao Yang","Huamin Qu"],"title":"AmbiguityVis: Visualization of Ambiguity in Graph Layouts","doi":"10.1109/TVCG.2015.2467691","abstract":"Node-link diagrams provide an intuitive way to explore networks and have inspired a large number of automated graph layout strategies that optimize aesthetic criteria. However, any particular drawing approach cannot fully satisfy all these criteria simultaneously, producing drawings with visual ambiguities that can impede the understanding of network structure. To bring attention to these potentially problematic areas present in the drawing, this paper presents a technique that highlights common types of visual ambiguities: ambiguous spatial relationships between nodes and edges, visual overlap between community structures, and ambiguity in edge bundling and metanodes. Metrics, including newly proposed metrics for abnormal edge lengths, visual overlap in community structures and node/edge aggregation, are proposed to quantify areas of ambiguity in the drawing. These metrics and others are then displayed using a heatmap-based visualization that provides visual feedback to developers of graph drawing and visualization approaches, allowing them to quickly identify misleading areas. The novel metrics and the heatmap-based visualization allow a user to explore ambiguities in graph layouts from multiple perspectives in order to make reasonable graph layout choices. The effectiveness of the technique is demonstrated through case studies and expert reviews.","keywords":"Visual Ambiguity, Visualization, Node-link diagram, Graph layout, Graph visualization","caption":"Fig. 1: User interface of AmbiguityVis showing the ambiguities existing in graph layouts. It consists of eight parts: (a) Ambiguity control panel allowing users to select the type of detected ambiguity. (b) Heatmap control panel enabling users to adapt the parameters of the heatmap such as hotspot range and local region size used in entropy and autocorrelation. (c) The node-link diagram layout. (d) Heatmap view for the selected type of ambiguity in the graph layout. (e) Edge bundling view. (f) Node aggregation view. (g) Bar chart view used to inform users of the underlying information in each metanode. (h) Scatterplot view generated by MDS to show the consistency of the bundled edges.","img_size":{"width":1709,"height":888},"subfigures":[{"x":14.38089607320616,"y":10.00554318061203,"width":1664.101384255299,"height":854.324912364263,"type":"interface","id":"interface-0"}],"visualizations":[{"x":1315.4019033674965,"y":127.41434846266475,"width":332.83748169838964,"height":293.8330893118595,"type":"bar_chart","id":"bar_chart-0"},{"x":349.39311859443626,"y":130.0146412884334,"width":406.9458272327965,"height":339.33821376281116,"type":"graph","id":"graph-1"},{"x":350.69326500732075,"y":523.9590043923866,"width":413.44655929721813,"height":336.73792093704265,"type":"graph","id":"graph-2"},{"x":814.845534407028,"y":518.7584187408493,"width":390.04392386530026,"height":344.5387994143486,"type":"graph","id":"graph-3"},{"x":790.1427525622256,"y":89.71010248901906,"width":410.8462664714496,"height":382.2430453879943,"type":"heatmap","id":"heatmap-4"},{"x":346.7928257686678,"y":128.71449487554912,"width":409.5461200585652,"height":335.4377745241584,"type":"scatterplot","id":"scatterplot-5"},{"x":792.7430453879944,"y":97.51098096632508,"width":406.94582723279643,"height":371.84187408491954,"type":"scatterplot","id":"scatterplot-6"},{"x":813.5453879941437,"y":521.358711566618,"width":397.84480234260616,"height":343.23865300146423,"type":"scatterplot","id":"scatterplot-7"},{"x":346.7928257686678,"y":523.9590043923866,"width":410.84626647144955,"height":335.43777452415804,"type":"scatterplot","id":"scatterplot-8"},{"x":1272.4970717423137,"y":492.75549048316265,"width":371.8418740849195,"height":339.3382137628113,"type":"scatterplot","id":"scatterplot-9"}],"relations":[{"vislist":[{"vislist":["scatterplot-6","scatterplot-7","scatterplot-8","scatterplot-5"],"relation":null,"id":"group-11"}],"relation":"repeated","id":"relation-8"}]},"2615_0":{"comp":[["scatterplot","scatterplot",["repeated"]],["area_chart","area_chart",["repeated"]],["area_chart","table",["nested"]],["area_chart","scatterplot",["annotated"]]],"visType":["scatterplot","area_chart","table"],"compType":["repeated","nested","annotated"],"compressed_tree":[{"composite_pattern":"annotated","visualization_type":[["area_chart"],["scatterplot"]]},{"composite_pattern":"repeated","visualization_type":[["scatterplot"]]},{"composite_pattern":"repeated","visualization_type":[["area_chart"]]},{"composite_pattern":"nested","visualization_type":[["area_chart"],["table"]]}],"coOccurrence":[["area_chart","scatterplot",["coOccurrence"]],["area_chart","table",["coOccurrence"]],["scatterplot","table",["coOccurrence"]]],"year":2015,"conference":["InfoVis"],"authors":["Julian Stahnke","Marian D\xf6rk","Boris M\xfcller","Andreas Thom"],"title":"Probing Projections: Interaction Techniques for Interpreting Arrangements and Errors of Dimensionality Reductions","doi":"10.1109/TVCG.2015.2467717","abstract":"We introduce a set of integrated interaction techniques to interpret and interrogate dimensionality-reduced data. Projection techniques generally aim to make a high-dimensional information space visible in form of a planar layout. However, the meaning of the resulting data projections can be hard to grasp. It is seldom clear why elements are placed far apart or close together and the inevitable approximation errors of any projection technique are not exposed to the viewer. Previous research on dimensionality reduction focuses on the efficient generation of data projections, interactive customisation of the model, and comparison of different projection techniques. There has been only little research on how the visualization resulting from data projection is interacted with. We contribute the concept of probing as an integrated approach to interpreting the meaning and quality of visualizations and propose a set of interactive methods to examine dimensionality-reduced data as well as the projection itself. The methods let viewers see approximation errors, question the positioning of elements, compare them to each other, and visualize the influence of data dimensions on the projection space. We created a web-based system implementing these methods, and report on findings from an evaluation with data analysts using the prototype to examine multidimensional datasets.","keywords":"Information visualization, interactivity, dimensionality reduction, multidimensional scaling","caption":null,"img_size":{"width":1976,"height":1246},"subfigures":[{"x":18.130694718862692,"y":19.371062294688308,"width":1943.1428659818448,"height":1203.8540411227707,"type":"interface","id":"interface-0"}],"visualizations":[{"x":1232.0891089108914,"y":674.9900990099009,"width":722.5742574257432,"height":493.4653465346534,"type":"area_chart","id":"area_chart-0"},{"x":509.5148514851486,"y":498.75247524752467,"width":394.7722772277228,"height":343.6633663366336,"type":"area_chart","id":"area_chart-1"},{"x":123.55445544554466,"y":40.53465346534662,"width":1083.8613861386136,"height":1168.455445544554,"type":"scatterplot","id":"scatterplot-2"},{"x":1226.8019801980204,"y":378.9108910891091,"width":354.23762376237613,"height":215.00990099009906,"type":"scatterplot","id":"scatterplot-3"},{"x":507.9496238268113,"y":586.2793697899785,"width":394.2780016205101,"height":252.77202243401078,"type":"table","id":"table-6"}],"relations":[{"vislist":[{"vislist":["area_chart-1"],"relation":null,"id":"group-1"},{"vislist":["scatterplot-2"],"relation":null,"id":"group-0"}],"relation":"annotated","id":"relation-0"},{"vislist":[{"vislist":["scatterplot-3"],"relation":null,"id":"group-2"}],"relation":"repeated","id":"relation-1"},{"vislist":[{"vislist":["area_chart-0"],"relation":null,"id":"group-3"}],"relation":"repeated","id":"relation-2"},{"vislist":[{"vislist":["area_chart-1"],"relation":null,"id":"group-6"},{"vislist":["table-6"],"relation":null,"id":"group-5"}],"relation":"nested","id":"relation-3"}]},"2623_0":{"comp":[["map","map",["repeated"]]],"visType":["map"],"compType":["repeated"],"compressed_tree":[{"composite_pattern":"repeated","visualization_type":[["map"]]},{"composite_pattern":"repeated","visualization_type":[["map"]]}],"coOccurrence":[["map","map",["coOccurrence"]]],"year":2015,"conference":["InfoVis"],"authors":["Alice Thudt","Dominikus Baur","Samuel Huron","Sheelagh Carpendale"],"title":"Visual Mementos: Reflecting Memories with Personal Data","doi":"10.1109/TVCG.2015.2467831","abstract":"In this paper we discuss the creation of visual mementos as a new application area for visualization. We define visual mementos as visualizations of personally relevant data for the purpose of reminiscing, and sharing of life experiences. Today more people collect digital information about their life than ever before. The shift from physical to digital archives poses new challenges and opportunities for self-reflection and self-representation. Drawing on research on autobiographical memory and on the role of artifacts in reminiscing, we identified design challenges for visual mementos: mapping data to evoke familiarity, expressing subjectivity, and obscuring sensitive details for sharing. Visual mementos can make use of the known strengths of visualization in revealing patterns to show the familiar instead of the unexpected, and extend representational mappings beyond the objective to include the more subjective. To understand whether people\'s subjective views on their past can be reflected in a visual representation, we developed, deployed and studied a technology probe that exemplifies our concept of visual mementos. Our results show how reminiscing has been supported and reveal promising new directions for self-reflection and sharing through visual mementos of personal experiences.","keywords":"Visual Memento, Memories, Personal Visualization, Movement Data, World Wide Web","caption":"Fig. 1. The visits system: 1. Landing page with A) header, B) sys-tem description, C) teaser and demo link, D) third party data sources,E) data loading drop box. 2. Visualization with F) header with title,and share button, G) map-timeline, H) controls for timeframe and place adjustment, I) overview map and photo box. 3. Share screen with:J) sharing description, K) textfields for title and description, L) sharing terms and conditions, M) privacy slider for limiting the shared details. N) shows possible settings of the privacy slider for sharing all locations andlocations from street to country level,","img_size":{"width":1065,"height":2090},"subfigures":[{"x":58.322652835115484,"y":718.1531648385068,"width":985.4663754223221,"height":667.9673734963653,"type":"interface","id":"interface-0"}],"visualizations":[{"x":49.16902404526172,"y":245.36067892503533,"width":1002.1357850070722,"height":159.6322489391796,"type":"map","id":"map-0"},{"x":108.29207920792079,"y":848.4158415841582,"width":877.9773691654877,"height":304.4837340876944,"type":"map","id":"map-1"},{"x":522.1534653465346,"y":1203.1541725601128,"width":280.83451202263086,"height":156.67609618104666,"type":"map","id":"map-2"}],"relations":[{"vislist":[{"vislist":["map-0"],"relation":null,"id":"group-2"}],"relation":"repeated","id":"relation-0"},{"vislist":[{"vislist":["map-1","map-2"],"relation":null,"id":"group-3"}],"relation":"repeated","id":"relation-1"}]},"2686_3":{"comp":[["heatmap","heatmap",["repeated"]],["bar_chart","graph",["nested"]],["scatterplot","contour_graph",["coordinated"]]],"visType":["heatmap","bar_chart","graph","scatterplot","contour_graph"],"compType":["repeated","nested","coordinated"],"compressed_tree":[{"composite_pattern":"repeated","visualization_type":[["heatmap"]]},{"composite_pattern":"coordinated","visualization_type":[["scatterplot"],["contour_graph"]]},{"composite_pattern":"nested","visualization_type":[["bar_chart"],["graph"]]}],"coOccurrence":[],"year":2015,"conference":["VAST"],"authors":["Nan Cao","Conglei Shi","Wan-Yi Sabrina Lin","Jie Lu","Yu-Ru Lin","Ching-Yung Lin"],"title":"TargetVue: Visual Analysis of Anomalous User Behaviors in Online Communication Systems","doi":"10.1109/TVCG.2015.2467196","abstract":"Users with anomalous behaviors in online communication systems (e.g. email and social medial platforms) are potential threats to society. Automated anomaly detection based on advanced machine learning techniques has been developed to combat this issue; challenges remain, though, due to the difficulty of obtaining proper ground truth for model training and evaluation. Therefore, substantial human judgment on the automated analysis results is often required to better adjust the performance of anomaly detection. Unfortunately, techniques that allow users to understand the analysis results more efficiently, to make a confident judgment about anomalies, and to explore data in their context, are still lacking. In this paper, we propose a novel visual analysis system, TargetVue, which detects anomalous users via an unsupervised learning model and visualizes the behaviors of suspicious users in behavior-rich context through novel visualization designs and multiple coordinated contextual views. Particularly, TargetVue incorporates three new ego-centric glyphs to visually summarize a user\'s behaviors which effectively present the user\'s communication activities, features, and social interactions. An efficient layout method is proposed to place these glyphs on a triangle grid, which captures similarities among users and facilitates comparisons of behaviors of different users. We demonstrate the power of TargetVue through its application in a social bot detection challenge using Twitter data, a case study based on email records, and an interview with expert users. Our evaluation shows that TargetVue is beneficial to the detection of users with anomalous communication behaviors.","keywords":"Anomaly Detection, Social Media, Visual Analysis","caption":"Fig. 4. The user interface of TargetVue system consists of six major views labeled by the numbers 1-6.","img_size":{"width":2114,"height":1179},"subfigures":[{"x":404.31587292090205,"y":23.915023708931148,"width":1411.6943143949673,"height":987.8442159614369,"type":"interface","id":"interface-0"},{"x":1008.7540300359658,"y":867.7428232059661,"width":1059.8704857097587,"height":298.54379738550404,"type":"single","id":"single-1"}],"visualizations":[{"x":746.5806311982245,"y":62.63705774608025,"width":1068.495401048947,"height":652.2445588302662,"type":"bar_chart","id":"bar_chart-22"},{"x":405.81912400835824,"y":61.058837072108574,"width":334.888843522188,"height":330.20112637937626,"type":"contour_graph","id":"contour_graph-20"},{"x":747.2755658636376,"y":58.703338513096725,"width":1071.2529749249384,"height":652.3655937042895,"type":"glyph_based","id":"glyph_based-0"},{"x":739.9472341936065,"y":58.659582975578665,"width":1081.7621950581824,"height":657.5229662000853,"type":"graph","id":"graph-23"},{"x":1004.7445845051805,"y":912.0411196521743,"width":1021.8105299284031,"height":255.4526324821006,"type":"heatmap","id":"heatmap-1"},{"x":66.78232343091838,"y":131.84103966438914,"width":303.6845220499927,"height":181.64307860934147,"type":"heatmap","id":"heatmap-10"},{"x":1503.9296036858684,"y":791.968700400323,"width":111.11976661494647,"height":67.74406824332267,"type":"heatmap","id":"heatmap-11"},{"x":1629.122421376357,"y":773.0267223972426,"width":110.60669710262528,"height":88.96625636515502,"type":"heatmap","id":"heatmap-12"},{"x":407.7066284432541,"y":61.039924139196806,"width":333.2795399062138,"height":335.5911646635313,"type":"heatmap","id":"heatmap-2"},{"x":756.5367396101846,"y":760.8348578765823,"width":122.76340036901207,"height":233.83504832192753,"type":"heatmap","id":"heatmap-3"},{"x":891.8270175678715,"y":783.383237536197,"width":108.56627243518099,"height":208.7812931445785,"type":"heatmap","id":"heatmap-4"},{"x":1007.074291383679,"y":765.0104837394741,"width":118.58777450612071,"height":105.22577174486763,"type":"heatmap","id":"heatmap-5"},{"x":1134.848442788161,"y":793.4047396071368,"width":112.74189829807231,"height":71.82076484173501,"type":"heatmap","id":"heatmap-6"},{"x":1255.9415928120166,"y":795.0749899522935,"width":110.2365227803373,"height":72.65589001431329,"type":"heatmap","id":"heatmap-7"},{"x":1381.2103686987637,"y":779.2076116733055,"width":119.42289967869874,"height":90.19351863845795,"type":"heatmap","id":"heatmap-8"},{"x":504.2126334519573,"y":1048.932384341637,"width":367.1263345195729,"height":104.89323843416378,"type":"heatmap","id":"heatmap-9"},{"x":407.2877929367856,"y":64.00668593859666,"width":332.37981868616924,"height":331.5446935135909,"type":"scatterplot","id":"scatterplot-13"},{"x":745.8568572451463,"y":58.680822561776424,"width":1071.4099777435242,"height":654.2547966084124,"type":"scatterplot","id":"scatterplot-14"},{"x":1006.3427001351613,"y":913.1447927002408,"width":1020.4265357771792,"height":255.97929061685218,"type":"scatterplot","id":"scatterplot-15"},{"x":57.16472917347289,"y":400.19897680531125,"width":324.12269497728875,"height":608.4167537073685,"type":"table","id":"table-16"},{"x":415.7571660762407,"y":680.3018036702168,"width":318.4754700209786,"height":320.1371451975295,"type":"table","id":"table-17"},{"x":428.84152202671584,"y":459.950346754758,"width":285.128961781908,"height":206.59468198589857,"type":"word_cloud","id":"word_cloud-18"}],"relations":[{"vislist":[{"vislist":["heatmap-4","heatmap-5","heatmap-6","heatmap-7","heatmap-8","heatmap-11","heatmap-12","heatmap-3"],"relation":null,"id":"group-0"}],"relation":"repeated","id":"relation-0"},{"vislist":[{"vislist":["scatterplot-13"],"relation":null,"id":"group-2"},{"vislist":["contour_graph-20"],"relation":null,"id":"group-1"}],"relation":"coordinated","id":"relation-1"},{"vislist":[{"vislist":["bar_chart-22"],"relation":null,"id":"group-5"},{"vislist":["graph-23"],"relation":null,"id":"group-4"}],"relation":"nested","id":"relation-3"}]},"2692_0":{"comp":[["bar_chart","bar_chart",["repeated"]],["glyph_based","bar_chart",["nested"]],["word_cloud","bar_chart",["annotated"]]],"visType":["bar_chart","glyph_based","word_cloud"],"compType":["repeated","nested","annotated"],"compressed_tree":[{"composite_pattern":"repeated","visualization_type":[["bar_chart"]]},{"composite_pattern":"annotated","visualization_type":[["word_cloud"],["bar_chart"]]},{"composite_pattern":"nested","visualization_type":[["glyph_based"],["bar_chart"]]}],"coOccurrence":[["bar_chart","word_cloud",["coOccurrence"]],["bar_chart","glyph_based",["coOccurrence"]],["word_cloud","glyph_based",["coOccurrence"]]],"year":2015,"conference":["VAST"],"authors":["Bum Chul Kwon","Sung-Hee Kim","Sukwon Lee","Jaegul Choo","Jina Huh","Ji Soo Yi"],"title":"VisOHC: Designing Visual Analytics for Online Health Communities","doi":"10.1109/TVCG.2015.2467555","abstract":"Through online health communities (OHCs), patients and caregivers exchange their illness experiences and strategies for overcoming the illness, and provide emotional support. To facilitate healthy and lively conversations in these communities, their members should be continuously monitored and nurtured by OHC administrators. The main challenge of OHC administrators\' tasks lies in understanding the diverse dimensions of conversation threads that lead to productive discussions in their communities. In this paper, we present a design study in which three domain expert groups participated, an OHC researcher and two OHC administrators of online health communities, which was conducted to find with a visual analytic solution. Through our design study, we characterized the domain goals of OHC administrators and derived tasks to achieve these goals. As a result of this study, we propose a system called VisOHC, which visualizes individual OHC conversation threads as collapsed boxes-a visual metaphor of conversation threads. In addition, we augmented the posters\' reply authorship network with marks and/or beams to show conversation dynamics within threads. We also developed unique measures tailored to the characteristics of OHCs, which can be encoded for thread visualizations at the users\' requests. Our observation of the two administrators while using VisOHC showed that it supports their tasks and reveals interesting insights into online health communities. Finally, we share our methodological lessons on probing visual designs together with domain experts by allowing them to freely encode measurements into visual variables.","keywords":"Online health communities, visual analytics, conversation analysis, thread visualization, healthcare, design study","caption":"Fig. 1: The VisOHC system includes (A) Dashboard for manipulating visual encoding schemes and measures; (B) Similarity View displaying the cosine distances of the discussion threads with respect to user-selected measures, where users can find similar threads and filter threads by drawing an orange rectangle; (C) Histogram View displaying the distribution of eight measures of the discussion threads, where users can view the distribution of measures of selected threads and filter threads by specifying the range per measure; (D) Thread View displaying the threads as boxes where a color, a width, and a vertical order represent the sentiment, the question length, and the recency, respectively; (E) Word Cloud displaying medical keywords of a thread over which the user hovers the mouse; (F) Replier Marks displaying the unique number of participants as well as the sequence of replies; and (G) Text View displaying text with highlights related to food, medications, and the body.","img_size":{"width":1776,"height":860},"subfigures":[{"x":12.414963131004967,"y":18.044843636838586,"width":1746.0102414094908,"height":834.2332284728259,"type":"interface","id":"interface-0"}],"visualizations":[{"x":411.0651985117453,"y":170.48702200165633,"width":398.5930712447471,"height":686.0224331015219,"type":"bar_chart","id":"bar_chart-0"},{"x":21.30975954738322,"y":571.7114568599717,"width":148.0909869300771,"height":58.19582659037325,"type":"bar_chart","id":"bar_chart-1"},{"x":813.37954304801,"y":171.2903099538908,"width":363.6181539071138,"height":677.9335990092428,"type":"bar_chart","id":"bar_chart-15"},{"x":209.0507752502629,"y":568.0532385647731,"width":155.42811278938592,"height":58.682042583747716,"type":"bar_chart","id":"bar_chart-2"},{"x":18.730637140810703,"y":641.0092915067298,"width":177.63212890215542,"height":61.85404488557198,"type":"bar_chart","id":"bar_chart-3"},{"x":215.39477985391122,"y":642.5952926576421,"width":158.60011509121014,"height":63.440046036483984,"type":"bar_chart","id":"bar_chart-4"},{"x":210.63677640117498,"y":718.7233479014232,"width":153.8421116384738,"height":58.682042583747716,"type":"bar_chart","id":"bar_chart-5"},{"x":15.558634838986563,"y":713.9653444486862,"width":188.73413695854,"height":60.26804373465984,"type":"bar_chart","id":"bar_chart-6"},{"x":21.902639442634946,"y":788.5073985415552,"width":160.18611624212213,"height":57.09604143283571,"type":"bar_chart","id":"bar_chart-7"},{"x":212.22277755208702,"y":791.6794008433794,"width":158.60011509121014,"height":55.51004028192358,"type":"bar_chart","id":"bar_chart-8"},{"x":1153.6451915778757,"y":565.8423652194209,"width":329.888239389717,"height":76.12805524378088,"type":"bar_chart","id":"bar_chart-9"},{"x":807.6932621000352,"y":169.57651899215676,"width":364.9995289555522,"height":679.3816245099813,"type":"glyph_based","id":"glyph_based-13"},{"x":32.25742574257416,"y":173.94625176803402,"width":353.97454031117405,"height":368.5714285714286,"type":"scatterplot","id":"scatterplot-10"},{"x":515.6032504637562,"y":345.2387423244733,"width":274.25637669772954,"height":274.08793103877935,"type":"word_cloud","id":"word_cloud-11"}],"relations":[{"vislist":[{"vislist":["bar_chart-4","bar_chart-5","bar_chart-6","bar_chart-7","bar_chart-1","bar_chart-2","bar_chart-3","bar_chart-8"],"relation":null,"id":"group-0"}],"relation":"repeated","id":"relation-0"},{"vislist":[{"vislist":["word_cloud-11"],"relation":null,"id":"group-8"},{"vislist":["bar_chart-0"],"relation":null,"id":"group-9"}],"relation":"annotated","id":"relation-5"},{"vislist":[{"vislist":["glyph_based-13"],"relation":null,"id":"group-11"},{"vislist":["bar_chart-15"],"relation":null,"id":"group-12"}],"relation":"nested","id":"relation-6"}]},"2694_7":{"comp":[["bar_chart","bar_chart",["repeated"]],["heatmap","heatmap",["repeated"]]],"visType":["bar_chart","heatmap"],"compType":["repeated"],"compressed_tree":[{"composite_pattern":"repeated","visualization_type":[["bar_chart"]]},{"composite_pattern":"repeated","visualization_type":[["heatmap"]]}],"coOccurrence":[["heatmap","heatmap",["coOccurrence"]]],"year":2015,"conference":["VAST"],"authors":["Cesar Palomo","Zhan Guo","Cl\xe1udio T. Silva","Juliana Freire"],"title":"Visually Exploring Transportation Schedules","doi":"10.1109/TVCG.2015.2467592","abstract":"Public transportation schedules are designed by agencies to optimize service quality under multiple constraints. However, real service usually deviates from the plan. Therefore, transportation analysts need to identify, compare and explain both eventual and systemic performance issues that must be addressed so that better timetables can be created. The purely statistical tools commonly used by analysts pose many difficulties due to the large number of attributes at tripand station-level for planned and real service. Also challenging is the need for models at multiple scales to search for patterns at different times and stations, since analysts do not know exactly where or when relevant patterns might emerge and need to compute statistical summaries for multiple attributes at different granularities. To aid in this analysis, we worked in close collaboration with a transportation expert to design TR-EX, a visual exploration tool developed to identify, inspect and compare spatio-temporal patterns for planned and real transportation service. TR-EX combines two new visual encodings inspired by Marey\'s Train Schedule: Trips Explorer for trip-level analysis of frequency, deviation and speed; and Stops Explorer for station-level study of delay, wait time, reliability and performance deficiencies such as bunching. To tackle overplotting and to provide a robust representation for a large numbers of trips and stops at multiple scales, the system supports variable kernel bandwidths to achieve the level of detail required by users for different tasks. We justify our design decisions based on specific analysis needs of transportation analysts. We provide anecdotal evidence of the efficacy of TR-EX through a series of case studies that explore NYC subway service, which illustrate how TR-EX can be used to confirm hypotheses and derive new insights through visual exploration.","keywords":"Transportation, schedules, kernel density estimation, visual exploration","caption":"Fig. 8: Overview of the TR-EX proof-of-concept prototype. Routes, directions and real/planned service can be selected in (1). Users can choose between Trips Explorer and Stops Explorer (2) for the main plot (3). The Subway Station list (4) shows the stations in the line and allows users to filter through brushing. The filters panel (5) provides controls for setting visibility for specific days of the week and filtering of speed ranges for trips and segments. TR-EX allows users to perform analyses based on different service attributes (6), in this case, frequency of stops is selected for line 4 uptown trips on weekends. Users can also adjust the bandwidth size and the mapping of KDE result to specific color scales (7). TR-EX provides additional summary plots for specific attributes (9), and users can save the current visualization state (8) to a gallery (10) for further comparison.","img_size":{"width":2154,"height":1447},"subfigures":[{"x":58.45538844013776,"y":52.54832772634686,"width":2007.4328334915401,"height":800.352216626086,"type":"interface","id":"interface-0"},{"x":50.84908690706914,"y":986.5573582173922,"width":2081.9582158140447,"height":444.3290930882727,"type":"single","id":"single-1"}],"visualizations":[{"x":64.91867043847242,"y":165.7807637906648,"width":421.61527581329574,"height":161.6874115983027,"type":"bar_chart","id":"bar_chart-0"},{"x":73.10537482319671,"y":337.7015558698727,"width":392.9618104667609,"height":159.6407355021217,"type":"bar_chart","id":"bar_chart-1"},{"x":71.05869872701555,"y":509.6223479490807,"width":415.47524752475255,"height":161.68741159830267,"type":"bar_chart","id":"bar_chart-2"},{"x":73.10537482319671,"y":677.4497878359265,"width":409.3352192362093,"height":161.68741159830267,"type":"bar_chart","id":"bar_chart-3"},{"x":517.2340876944829,"y":93.09167923905189,"width":1264.8458274398874,"height":719.6086496122665,"type":"heatmap","id":"heatmap-4"},{"x":62.87199434229137,"y":1041.7581329561528,"width":395.0084865629421,"height":247.64780763790668,"type":"heatmap","id":"heatmap-5"},{"x":488.5806223479492,"y":1041.7581329561528,"width":378.63507779349356,"height":243.5544554455446,"type":"heatmap","id":"heatmap-6"},{"x":902.0091937765205,"y":1035.6181046676097,"width":380.6817538896748,"height":255.83451202263086,"type":"heatmap","id":"heatmap-7"},{"x":1317.484441301273,"y":1039.7114568599718,"width":380.6817538896748,"height":251.74115983026874,"type":"heatmap","id":"heatmap-8"},{"x":1735.0063649222066,"y":1045.851485148515,"width":376.5884016973129,"height":243.5544554455446,"type":"heatmap","id":"heatmap-9"},{"x":2001.3867975417609,"y":105.66970875756667,"width":73.76762086512804,"height":635.5640524646016,"type":"scatterplot","id":"scatterplot-10"}],"relations":[{"vislist":[{"vislist":["bar_chart-0","bar_chart-1","bar_chart-2","bar_chart-3"],"relation":null,"id":"group-0"}],"relation":"repeated","id":"relation-0"},{"vislist":[{"vislist":["heatmap-5","heatmap-6","heatmap-7","heatmap-8","heatmap-9"],"relation":null,"id":"group-1"}],"relation":"repeated","id":"relation-1"}]},"2696_0":{"comp":[["line_chart","line_chart",["repeated"]],["comb","comb",["repeated"]],["area_chart","scatterplot",["accompanied"]],["scatterplot","area_chart",["accompanied"]]],"visType":["line_chart","comb","area_chart","scatterplot"],"compType":["repeated","accompanied"],"compressed_tree":[{"composite_pattern":"repeated","visualization_type":[["line_chart"]]},{"composite_pattern":"repeated","visualization_type":[[{"composite_pattern":"accompanied","visualization_type":[["area_chart","scatterplot"]]}]]}],"coOccurrence":[["area_chart","scatterplot",["coOccurrence"]],["area_chart","line_chart",["coOccurrence"]],["scatterplot","line_chart",["coOccurrence"]]],"year":2015,"conference":["VAST"],"authors":["Thomas L\xf6we","Emmy-Charlotte F\xf6rster","Georgia Albuquerque","Jens-Peter Kreiss","Marcus A. Magnor"],"title":"Visual Analytics for Development and Evaluation of Order Selection Criteria for Autoregressive Processes","doi":"10.1109/TVCG.2015.2467612","abstract":"Order selection of autoregressive processes is an active research topic in time series analysis, and the development and evaluation of automatic order selection criteria remains a challenging task for domain experts. We propose a visual analytics approach, to guide the analysis and development of such criteria. A flexible synthetic model generator-combined with specialized responsive visualizations-allows comprehensive interactive evaluation. Our fast framework allows feedback-driven development and fine-tuning of new order selection criteria in real-time. We demonstrate the applicability of our approach in three use-cases for two general as well as a real-world example.","keywords":"Visual analytics, time series analysis, order selection","caption":"Fig. 1: Our proposed framework helps domain experts evaluate and develop order selection criteria for autoregressive processes. (1) A customizable evaluation thread is constantly running in the background, creating synthetic autoregressive processes to test user-defined selection criteria in real-time. (2) A scripting interface enables users to input existing, or to define new, order selection criteria to be evaluated. (3) Interactive visualizations give responsive feedback of the current evaluation status and allow insight into the quality of the selection criteria.","img_size":{"width":1844,"height":764},"subfigures":[{"x":228.4644852548562,"y":10.502933867656218,"width":1395.1071197046033,"height":737.6322149951154,"type":"interface","id":"interface-0"}],"visualizations":[{"x":437.07066916823015,"y":339.90744215134464,"width":291.7648530331457,"height":251.40212632895555,"type":"area_chart","id":"area_chart-0"},{"x":728.8355222013759,"y":337.6010006253909,"width":296.377736085053,"height":254.8617886178862,"type":"area_chart","id":"area_chart-1"},{"x":1034.439024390244,"y":337.6010006253909,"width":577.763602251407,"height":256.015009380863,"type":"bar_chart","id":"bar_chart-2"},{"x":1621.4283927454655,"y":409.1006879299562,"width":81.87867417135726,"height":144.15259537210756,"type":"bar_chart","id":"bar_chart-3"},{"x":1706.7667292057536,"y":494.4390243902439,"width":64.58036272670415,"height":43.82238899312068,"type":"bar_chart","id":"bar_chart-4"},{"x":437.07066916823015,"y":46.98936835522203,"width":595.06191369606,"height":266.3939962476548,"type":"line_chart","id":"line_chart-5"},{"x":1029.8261413383364,"y":51.60225140712947,"width":593.908692933083,"height":258.3214509068168,"type":"line_chart","id":"line_chart-6"},{"x":725.375859912445,"y":336.44777986241405,"width":299.8373983739837,"height":253.70856785490918,"type":"scatterplot","id":"scatterplot-10"},{"x":40.362726704190116,"y":119.64227642276425,"width":144.15259537210756,"height":144.15259537210756,"type":"scatterplot","id":"scatterplot-7"},{"x":257.1682301438399,"y":89.65853658536587,"width":160.2976860537836,"height":156.83802376485298,"type":"scatterplot","id":"scatterplot-8"},{"x":439.3771106941837,"y":336.44777986241405,"width":288.3051907442151,"height":253.70856785490918,"type":"scatterplot","id":"scatterplot-9"}],"relations":[{"vislist":[{"vislist":["line_chart-6","line_chart-5"],"relation":null,"id":"group-3"}],"relation":"repeated","id":"relation-3"},{"vislist":[{"vislist":[{"vislist":[{"vislist":["area_chart-0","scatterplot-9"],"relation":null,"id":"group-0"}],"relation":"accompanied","id":"relation-0"},{"vislist":[{"vislist":["scatterplot-10","area_chart-1"],"relation":null,"id":"group-1"}],"relation":"accompanied","id":"relation-1"}],"relation":null,"id":"group-4"}],"relation":"repeated","id":"relation-4"}]},"2700_0":{"comp":[["comb","comb",["repeated"]],["comb","map",["coordinated"]],["bar_chart","line_chart",["accompanied"]],["bar_chart","comb",["large_view"]],["line_chart","bar_chart",["accompanied"]],["sankey_diagram","stripe_graph",["accompanied"]],["stripe_graph","sankey_diagram",["accompanied"]],["word_cloud","donut_chart",["nested"]]],"visType":["comb","map","bar_chart","line_chart","sankey_diagram","stripe_graph","word_cloud","donut_chart"],"compType":["repeated","coordinated","accompanied","large_view","nested"],"compressed_tree":[{"composite_pattern":"repeated","visualization_type":[[{"composite_pattern":"accompanied","visualization_type":[["bar_chart","line_chart"]]}]]},{"composite_pattern":"accompanied","visualization_type":[["sankey_diagram","stripe_graph"]]},{"composite_pattern":"large_view","visualization_type":[["bar_chart"],[{"composite_pattern":"coordinated","visualization_type":[[{"composite_pattern":"nested","visualization_type":[["word_cloud"],["donut_chart"]]}],["map"]]}]]}],"coOccurrence":[["bar_chart","line_chart",["coOccurrence"]],["bar_chart","sankey_diagram",["coOccurrence"]],["bar_chart","stripe_graph",["coOccurrence"]],["bar_chart","word_cloud",["coOccurrence"]],["bar_chart","donut_chart",["coOccurrence"]],["bar_chart","map",["coOccurrence"]],["line_chart","sankey_diagram",["coOccurrence"]],["line_chart","stripe_graph",["coOccurrence"]],["line_chart","word_cloud",["coOccurrence"]],["line_chart","donut_chart",["coOccurrence"]],["line_chart","map",["coOccurrence"]],["sankey_diagram","stripe_graph",["coOccurrence"]],["sankey_diagram","word_cloud",["coOccurrence"]],["sankey_diagram","donut_chart",["coOccurrence"]],["sankey_diagram","map",["coOccurrence"]],["stripe_graph","word_cloud",["coOccurrence"]],["stripe_graph","donut_chart",["coOccurrence"]],["stripe_graph","map",["coOccurrence"]],["word_cloud","donut_chart",["coOccurrence"]],["word_cloud","map",["coOccurrence"]],["donut_chart","map",["coOccurrence"]]],"year":2015,"conference":["VAST"],"authors":["Siming Chen","Xiaoru Yuan","Zhenhuang Wang","Cong Guo","Jie Liang","Zuchao Wang","Xiaolong Zhan","Jiawan Zhang"],"title":"Interactive Visual Discovering of Movement Patterns from Sparsely Sampled Geo-tagged Social Media Data","doi":"10.1109/TVCG.2015.2467619","abstract":"Social media data with geotags can be used to track people\'s movements in their daily lives. By providing both rich text and movement information, visual analysis on social media data can be both interesting and challenging. In contrast to traditional movement data, the sparseness and irregularity of social media data increase the difficulty of extracting movement patterns. To facilitate the understanding of people\'s movements, we present an interactive visual analytics system to support the exploration of sparsely sampled trajectory data from social media. We propose a heuristic model to reduce the uncertainty caused by the nature of social media data. In the proposed system, users can filter and select reliable data from each derived movement category, based on the guidance of uncertainty model and interactive selection tools. By iteratively analyzing filtered movements, users can explore the semantics of movements, including the transportation methods, frequent visiting sequences and keyword descriptions. We provide two cases to demonstrate how our system can help users to explore the movement patterns.","keywords":"Spatial temporal visual analytics, Geo-tagged social media, Sparsely sampling, Uncertainty, Movement","caption":"Fig. 1. System Interface: (a) Time line view, for selecting time range of the social media data. (b) Spatial temporal view, for aggregating movements based on spatial, temporal domain. (c) ST Matrix View, showing the distribution of movement in geo distance and time interval attributes. (d) ST Detail View, for analyzing pair-wised detail movement. (e) ST Model View, showing the output of uncertainty model and guiding users to filter reliable data for each derived movement category. (f) Parameter Control Bar.","img_size":{"width":1899,"height":810},"subfigures":[{"x":22.897248866275792,"y":19.22681100436531,"width":1857.3433914531806,"height":768.7846809605524,"type":"interface","id":"interface-0"}],"visualizations":[{"x":525.5297113752124,"y":45.51188455008491,"width":340.1434634974534,"height":554.5466893039049,"type":"bar_chart","id":"bar_chart-0"},{"x":1637.453708812943,"y":108.30707497973768,"width":222.4958512543708,"height":209.62419043800227,"type":"bar_chart","id":"bar_chart-1"},{"x":1631.977420737475,"y":473.8446079680114,"width":197.80713718634618,"height":146.4445469916408,"type":"bar_chart","id":"bar_chart-17"},{"x":931.8913142664524,"y":19.85931981373628,"width":625.6200446655422,"height":627.2592205076274,"type":"donut_chart","id":"donut_chart-5"},{"x":894.6901528013582,"y":13.270797962648567,"width":976.9049235993208,"height":631.9252971137523,"type":"graph","id":"graph-2"},{"x":33.674533908572386,"y":22.137234474002287,"width":408.21552874768867,"height":297.8870074645295,"type":"heatmap","id":"heatmap-3"},{"x":41.44669313800717,"y":340.3397435223485,"width":464.5672970909502,"height":287.71497376655446,"type":"heatmap","id":"heatmap-4"},{"x":527.1417657045843,"y":45.51188455008491,"width":336.9193548387096,"height":556.1587436332769,"type":"line_chart","id":"line_chart-6"},{"x":16.120543293718164,"y":667.7648556876062,"width":1858.698641765705,"height":119.29202037351445,"type":"line_chart","id":"line_chart-7"},{"x":899.9140189591348,"y":21.6507289379431,"width":973.0515746527691,"height":621.2804122995643,"type":"map","id":"map-16"},{"x":38.6893039049236,"y":22.94312393887947,"width":403.01358234295424,"height":295.00594227504257,"type":"matrix","id":"matrix-8"},{"x":38.6893039049236,"y":342.12988115449923,"width":465.8837011884551,"height":285.3336162988116,"type":"sankey_diagram","id":"sankey_diagram-9"},{"x":29.91339389365763,"y":342.30795870291394,"width":476.73727777844067,"height":298.44367511264426,"type":"stripe_graph","id":"stripe_graph-10"},{"x":1073.8546890436173,"y":159.61060656248205,"width":350.2822794305516,"height":298.49035074339986,"type":"word_cloud","id":"word_cloud-14"}],"relations":[{"vislist":[{"vislist":[{"vislist":[{"vislist":["bar_chart-0","line_chart-6"],"relation":null,"id":"group-0"}],"relation":"accompanied","id":"relation-0"}],"relation":null,"id":"group-1"}],"relation":"repeated","id":"relation-1"},{"vislist":[{"vislist":["sankey_diagram-9","stripe_graph-10"],"relation":null,"id":"group-2"}],"relation":"accompanied","id":"relation-2"},{"vislist":[{"vislist":["bar_chart-1","bar_chart-17"],"relation":null,"id":"group-15"},{"vislist":[{"vislist":[{"vislist":[{"vislist":[{"vislist":["word_cloud-14"],"relation":null,"id":"group-11"},{"vislist":["donut_chart-5"],"relation":null,"id":"group-12"}],"relation":"nested","id":"relation-6"}],"relation":null,"id":"group-13"},{"vislist":["map-16"],"relation":null,"id":"group-14"}],"relation":"coordinated","id":"relation-7"}],"relation":null,"id":"group-16"}],"relation":"large_view","id":"relation-8"}]},"2703_0":{"comp":[["treemap","treemap",["repeated"]],["bar_chart","bar_chart",["repeated"]]],"visType":["treemap","bar_chart"],"compType":["repeated"],"compressed_tree":[{"composite_pattern":"repeated","visualization_type":[["treemap"]]},{"composite_pattern":"repeated","visualization_type":[["bar_chart"]]}],"coOccurrence":[["treemap","bar_chart",["coOccurrence"]]],"year":2015,"conference":["VAST"],"authors":["Josua Krause","Adam Perer","Harry Stavropoulos"],"title":"Supporting Iterative Cohort Construction with Visual Temporal Queries","doi":"10.1109/TVCG.2015.2467622","abstract":"Many researchers across diverse disciplines aim to analyze the behavior of cohorts whose behaviors are recorded in large event databases. However, extracting cohorts from databases is a difficult yet important step, often overlooked in many analytical solutions. This is especially true when researchers wish to restrict their cohorts to exhibit a particular temporal pattern of interest. In order to fill this gap, we designed COQUITO, a visual interface that assists users defining cohorts with temporal constraints. COQUITO was designed to be comprehensible to domain experts with no preknowledge of database queries and also to encourage exploration. We then demonstrate the utility of COQUITO via two case studies, involving medical and social media researchers.","keywords":"Visual temporal queries, cohort definition, electronic medical records, information visualization","caption":"Fig. 1. As a part of a case study with a clinical researcher, COQUITO is utilized for medical cohort analysis. The researcher visually applies a series of temporal constraints to a patient population and generates a cohort to statistically analyze.","img_size":{"width":2074,"height":952},"subfigures":[{"x":20.503352033516784,"y":8.174251890664856,"width":2032.9932959329667,"height":934.1452471565917,"type":"interface","id":"interface-0"}],"visualizations":[{"x":1469.7906295754024,"y":646.7467057101024,"width":572.8726207906292,"height":291.31478770131764,"type":"bar_chart","id":"bar_chart-0"},{"x":1477.10154236208,"y":495.31962007008906,"width":275.5444722347799,"height":142.07761849605845,"type":"bar_chart","id":"bar_chart-1"},{"x":1762.734121616198,"y":486.7737436890129,"width":269.88419608727526,"height":153.09830002029318,"type":"bar_chart","id":"bar_chart-6"},{"x":25.761346998535906,"y":500.3923865300145,"width":648.1405563689603,"height":426.5183016105417,"type":"treemap","id":"treemap-2"},{"x":671.1142020497803,"y":505.96778916544656,"width":643.9590043923864,"height":416.76134699853577,"type":"treemap","id":"treemap-3"}],"relations":[{"vislist":[{"vislist":["treemap-2","treemap-3"],"relation":null,"id":"group-0"}],"relation":"repeated","id":"relation-0"},{"vislist":[{"vislist":["bar_chart-0","bar_chart-1","bar_chart-6"],"relation":null,"id":"group-2"}],"relation":"repeated","id":"relation-1"}]},"2704_4":{"comp":[["sunburst_icicle","sunburst_icicle",["repeated"]]],"visType":["sunburst_icicle"],"compType":["repeated"],"compressed_tree":[{"composite_pattern":"repeated","visualization_type":[["sunburst_icicle"]]}],"coOccurrence":[["sunburst_icicle","sunburst_icicle",["coOccurrence"]]],"year":2015,"conference":["VAST"],"authors":["Michael Glueck","Peter Hamilton","Fanny Chevalier","Simon Breslav","Azam Khan","Daniel J. Wigdor","Michael Brudno"],"title":"PhenoBlocks: Phenotype Comparison Visualizations","doi":"10.1109/TVCG.2015.2467733","abstract":"The differential diagnosis of hereditary disorders is a challenging task for clinicians due to the heterogeneity of phenotypes that can be observed in patients. Existing clinical tools are often text-based and do not emphasize consistency, completeness, or granularity of phenotype reporting. This can impede clinical diagnosis and limit their utility to genetics researchers. Herein, we present PhenoBlocks, a novel visual analytics tool that supports the comparison of phenotypes between patients, or between a patient and the hallmark features of a disorder. An informal evaluation of PhenoBlocks with expert clinicians suggested that the visualization effectively guides the process of differential diagnosis and could reinforce the importance of complete, granular phenotypic reporting.","keywords":"Clinical diagnosis, differential hierarchy comparison, ontology, genomics, phenomics, phenotype","caption":"Fig. 5.  PhenoBlocks  user  interface.  (A)  Overview  of  differential  views  using  small-multiples.  (B)  Detail  View  of  highlighted  comparison  in  Overview. Hovering over a phenotype displays details under small multiples and indented list. (C) Details under small multiples include hard handle score and phenotype frequency. (D) Indented list of ancestors and descendants. (E) Interactive legend. (F) Toolbar. (G) Advanced panel.","img_size":{"width":2131,"height":983},"subfigures":[{"x":10.291376335072627,"y":13.87187069376155,"width":2107.3216384638577,"height":956.8060364354546,"type":"interface","id":"interface-0"}],"visualizations":[{"x":304.86237188872605,"y":50.373352855051245,"width":522.4436310395314,"height":529.6398243045387,"type":"sunburst_icicle","id":"sunburst_icicle-1"},{"x":830.1844802342604,"y":59.008784773060036,"width":988.7569546120055,"height":857.7862371888725,"type":"sunburst_icicle","id":"sunburst_icicle-2"}],"relations":[{"vislist":[{"vislist":["sunburst_icicle-2"],"relation":null,"id":"group-1"}],"relation":"repeated","id":"relation-1"}]},"2708_0":{"comp":[["bar_chart","bar_chart",["repeated"]],["line_chart","line_chart",["repeated"]]],"visType":["bar_chart","line_chart"],"compType":["repeated"],"compressed_tree":[{"composite_pattern":"repeated","visualization_type":[["bar_chart"]]},{"composite_pattern":"repeated","visualization_type":[["line_chart"]]}],"coOccurrence":[["bar_chart","line_chart",["coOccurrence"]]],"year":2015,"conference":["VAST"],"authors":["Tanja Blascheck","Markus John","Kuno Kurzhals","Steffen Koch","Thomas Ertl"],"title":"VA2: A Visual Analytics Approach for Evaluating Visual Analytics Applications","doi":"10.1109/TVCG.2015.2467871","abstract":"Evaluation has become a fundamental part of visualization research and researchers have employed many approaches from the field of human-computer interaction like measures of task performance, thinking aloud protocols, and analysis of interaction logs. Recently, eye tracking has also become popular to analyze visual strategies of users in this context. This has added another modality and more data, which requires special visualization techniques to analyze this data. However, only few approaches exist that aim at an integrated analysis of multiple concurrent evaluation procedures. The variety, complexity, and sheer amount of such coupled multi-source data streams require a visual analytics approach. Our approach provides a highly interactive visualization environment to display and analyze thinking aloud, interaction, and eye movement data in close relation. Automatic pattern finding algorithms allow an efficient exploratory search and support the reasoning process to derive common eye-interaction-thinking patterns between participants. In addition, our tool equips researchers with mechanisms for searching and verifying expected usage patterns. We apply our approach to a user study involving a visual analytics application and we discuss insights gained from this joint analysis. We anticipate our approach to be applicable to other combinations of evaluation techniques and a broad class of visualization applications.","keywords":"visual analytics, qualitative evaluation, thinking aloud, interaction logs, eye tracking, time series data","caption":"Fig. 1. Our interactive visualization approach for finding patterns in eye movements and interactions consists of a) an Area of Interest (AOI) Sequence Chart View for individual AOI timelines of participants, b) an Options panel, c) a Participant List View represented with a dendrogram, d) an AOI List View containing AOIs and histograms, e) a Legend, and f) a Pattern Editor to search for patterns.","img_size":{"width":1785,"height":896},"subfigures":[{"x":4.755348476796172,"y":5.200906326516701,"width":1772.8963129826757,"height":883.0021761391414,"type":"interface","id":"interface-0"}],"visualizations":[{"x":120.47071742313325,"y":574.5944363103953,"width":163.98243045387997,"height":148.2401171303076,"type":"bar_chart","id":"bar_chart-0"},{"x":116.53513909224012,"y":724.1464128843339,"width":153.48755490483165,"height":73.46412884333826,"type":"bar_chart","id":"bar_chart-1"},{"x":0,"y":791.051244509517,"width":246.4092240117131,"height":81.33528550512438,"type":"bar_chart","id":"bar_chart-2"},{"x":283.1412884333822,"y":95.7657393850659,"width":1133.446559297218,"height":205.96193265007324,"type":"line_chart","id":"line_chart-3"},{"x":283.1412884333822,"y":305.6632503660323,"width":1137.3821376281114,"height":208.58565153733528,"type":"line_chart","id":"line_chart-4"},{"x":283.1412884333822,"y":518.1844802342606,"width":1134.7584187408493,"height":203.3382137628112,"type":"line_chart","id":"line_chart-5"},{"x":277.893850658858,"y":725.458272327965,"width":1138.6939970717424,"height":165.29428989751105,"type":"line_chart","id":"line_chart-6"},{"x":3.7152269399707056,"y":274.17862371888725,"width":195.46705710102495,"height":255.81259150805278,"type":"tree","id":"tree-7"}],"relations":[{"vislist":[{"vislist":["bar_chart-0","bar_chart-1","bar_chart-2"],"relation":null,"id":"group-0"}],"relation":"repeated","id":"relation-0"},{"vislist":[{"vislist":["line_chart-3","line_chart-4","line_chart-5","line_chart-6"],"relation":null,"id":"group-1"}],"relation":"repeated","id":"relation-1"}]},"2708_5":{"comp":[["bar_chart","bar_chart",["repeated"]]],"visType":["bar_chart"],"compType":["repeated"],"compressed_tree":[{"composite_pattern":"repeated","visualization_type":[["bar_chart"]]},{"composite_pattern":"repeated","visualization_type":[["bar_chart"]]},{"composite_pattern":"repeated","visualization_type":[["bar_chart"]]}],"coOccurrence":[["bar_chart","bar_chart",["coOccurrence"]]],"year":2015,"conference":["VAST"],"authors":["Tanja Blascheck","Markus John","Kuno Kurzhals","Steffen Koch","Thomas Ertl"],"title":"VA2: A Visual Analytics Approach for Evaluating Visual Analytics Applications","doi":"10.1109/TVCG.2015.2467871","abstract":"Evaluation has become a fundamental part of visualization research and researchers have employed many approaches from the field of human-computer interaction like measures of task performance, thinking aloud protocols, and analysis of interaction logs. Recently, eye tracking has also become popular to analyze visual strategies of users in this context. This has added another modality and more data, which requires special visualization techniques to analyze this data. However, only few approaches exist that aim at an integrated analysis of multiple concurrent evaluation procedures. The variety, complexity, and sheer amount of such coupled multi-source data streams require a visual analytics approach. Our approach provides a highly interactive visualization environment to display and analyze thinking aloud, interaction, and eye movement data in close relation. Automatic pattern finding algorithms allow an efficient exploratory search and support the reasoning process to derive common eye-interaction-thinking patterns between participants. In addition, our tool equips researchers with mechanisms for searching and verifying expected usage patterns. We apply our approach to a user study involving a visual analytics application and we discuss insights gained from this joint analysis. We anticipate our approach to be applicable to other combinations of evaluation techniques and a broad class of visualization applications.","keywords":"visual analytics, qualitative evaluation, thinking aloud, interaction logs, eye tracking, time series data","caption":"Fig. 5. Homer\u2019s \u201cIliad\u201d divided into layers showing chapters (A), sub-chapters (B) (with word clouds), pages (C) (with bar charts), paragraphs(D) (with bar charts and pictograms), and lines of text (E).","img_size":{"width":1057,"height":493},"subfigures":[{"x":9.690995627010247,"y":9.18593273444675,"width":1039.1534656072479,"height":478.4653047609289,"type":"interface","id":"interface-0"}],"visualizations":[{"x":419.1449487554904,"y":13.714494875549049,"width":39.69985358711568,"height":475.67642752562216,"type":"bar_chart","id":"bar_chart-0"},{"x":628.4714494875549,"y":18.045387994143482,"width":28.150805270863884,"height":473.2829265926956,"type":"bar_chart","id":"bar_chart-1"},{"x":748.2928257686676,"y":21.654465592972205,"width":64.96339677891649,"height":469.67384899386684,"type":"bar_chart","id":"bar_chart-2"}],"relations":[{"vislist":[{"vislist":["bar_chart-0"],"relation":null,"id":"group-0"}],"relation":"repeated","id":"relation-0"},{"vislist":[{"vislist":["bar_chart-1"],"relation":null,"id":"group-1"}],"relation":"repeated","id":"relation-1"},{"vislist":[{"vislist":["bar_chart-2"],"relation":null,"id":"group-2"}],"relation":"repeated","id":"relation-2"}]},"2709_0":{"comp":[["table","table",["repeated"]]],"visType":["table"],"compType":["repeated"],"compressed_tree":[{"composite_pattern":"repeated","visualization_type":[["table"]]}],"coOccurrence":[["table","table",["coOccurrence"]]],"year":2015,"conference":["VAST"],"authors":["Jun Wang","Klaus Mueller"],"title":"The Visual Causality Analyst: An Interactive Interface for Causal Reasoning","doi":"10.1109/TVCG.2015.2467931","abstract":"Uncovering the causal relations that exist among variables in multivariate datasets is one of the ultimate goals in data analytics. Causation is related to correlation but correlation does not imply causation. While a number of casual discovery algorithms have been devised that eliminate spurious correlations from a network, there are no guarantees that all of the inferred causations are indeed true. Hence, bringing a domain expert into the casual reasoning loop can be of great benefit in identifying erroneous casual relationships suggested by the discovery algorithm. To address this need we present the Visual Causal Analyst - a novel visual causal reasoning framework that allows users to apply their expertise, verify and edit causal links, and collaborate with the causal discovery algorithm to identify a valid causal network. Its interface consists of both an interactive 2D graph view and a numerical presentation of salient statistical parameters, such as regression coefficients, p-values, and others. Both help users in gaining a good understanding of the landscape of causal structures particularly when the number of variables is large. Our framework is also novel in that it can handle both numerical and categorical variables within one unified model and return plausible results. We demonstrate its use via a set of case studies using multiple practical datasets.","keywords":"Visual knowledge discovery, Causality, Hypothesis testing, Visual evidence, High-dimensional data","caption":"Fig. 1. An overview of the Visual Causality Analyst framework running on the auto MPG dataset [29].","img_size":{"width":1819,"height":982},"subfigures":[{"x":324.2156677541292,"y":13.941349011110129,"width":1476.4093090837757,"height":951.4346653239486,"type":"interface","id":"interface-0"}],"visualizations":[{"x":616.1892778993434,"y":109.58862144420131,"width":687.6148796498906,"height":633.8949671772427,"type":"graph","id":"graph-0"},{"x":1323.6489252156,"y":113.00141588364012,"width":331.16746041961636,"height":235.10361693911705,"type":"table","id":"table-1"},{"x":1322.2328167271248,"y":399.1992470367535,"width":348.94059492434417,"height":167.25376447711875,"type":"table","id":"table-2"},{"x":1323.074938829862,"y":593.9774435829875,"width":347.5872072170023,"height":185.97022551737692,"type":"table","id":"table-3"}],"relations":[{"vislist":[{"vislist":["table-1","table-2","table-3"],"relation":null,"id":"group-0"}],"relation":"repeated","id":"relation-0"}]},"2710_4":{"comp":[["matrix","matrix",["repeated"]]],"visType":["matrix"],"compType":["repeated"],"compressed_tree":[{"composite_pattern":"repeated","visualization_type":[["matrix"]]}],"coOccurrence":[["matrix","matrix",["coOccurrence"]]],"year":2015,"conference":["VAST"],"authors":["Charilaos Papadopoulos","Ievgeniia Gutenko","Arie E. Kaufman"],"title":"VEEVVIE: Visual Explorer for Empirical Visualization, VR and Interaction Experiments","doi":"10.1109/TVCG.2015.2467954","abstract":"Empirical, hypothesis-driven, experimentation is at the heart of the scientific discovery process and has become commonplace in human-factors related fields. To enable the integration of visual analytics in such experiments, we introduce VEEVVIE, the Visual Explorer for Empirical Visualization, VR and Interaction Experiments. VEEVVIE is comprised of a back-end ontology which can model several experimental designs encountered in these fields. This formalization allows VEEVVIE to capture experimental data in a query-able form and makes it accessible through a front-end interface. This front-end offers several multi-dimensional visualization widgets with built-in filtering and highlighting functionality. VEEVVIE is also expandable to support custom experimental measurements and data types through a plug-in visualization widget architecture. We demonstrate VEEVVIE through several case studies of visual analysis, performed on the design and data collected during an experiment on the scalability of high-resolution, immersive, tiled-display walls.","keywords":"Visual Analytics, Evaluation, User Studies, Ontology, Experiments, Interaction, Virtual Reality, Visualization","caption":"Fig. 3. Sample view of the VEEVVIE front-end during a visual exploration session. The data filtering controls are visible in the sidebar on the left- hand side (a). These enable researchers to drill down data by toggling on/off factors of independent variables, grouping factors, and/or individual subjects. Visualizations can be generated through the toolbar at the top of the interface (b) by selecting a widget and then binding experimental measurements to dimensions. Widgets appear in the main workspace (c) and are moveable, resizeable and responsive. The four widgets visible in this image are: the statistical-effect explorer, the subject-centric visualizer, a parallel coordinates visualization of the experiment and a presence heatmap visualization.","img_size":{"width":2164,"height":1151},"subfigures":[{"x":29.146291873698726,"y":28.85604322412775,"width":2097.8480224102873,"height":1105.865163199641,"type":"interface","id":"interface-0"}],"visualizations":[{"x":1418.9703947368423,"y":113.58552631578945,"width":661.3201754385966,"height":555.3070175438596,"type":"heatmap","id":"heatmap-0"},{"x":1643.6173245614038,"y":762.2850877192982,"width":209.5021929824564,"height":156.49561403508767,"type":"heatmap","id":"heatmap-1"},{"x":1421.4945175438597,"y":103.48903508771929,"width":658.7960526315787,"height":565.4035087719299,"type":"matrix","id":"matrix-2"},{"x":462.327850877193,"y":156.4956140350877,"width":252.41228070175447,"height":254.93640350877197,"type":"matrix","id":"matrix-3"},{"x":787.9396929824563,"y":156.4956140350877,"width":242.31578947368425,"height":257.4605263157895,"type":"matrix","id":"matrix-4"},{"x":424.46600877192986,"y":449.2938596491228,"width":994.5043859649126,"height":545.2105263157894,"type":"parallel_coordinate","id":"parallel_coordinate-5"},{"x":1090.8344298245613,"y":159.01973684210526,"width":275.12938596491244,"height":242.31578947368416,"type":"polar_plot","id":"polar_plot-6"}],"relations":[{"vislist":[{"vislist":["matrix-3","matrix-4"],"relation":null,"id":"group-0"}],"relation":"repeated","id":"relation-0"}]},"2714_5":{"comp":[["graph","graph",["repeated"]]],"visType":["graph"],"compType":["repeated"],"compressed_tree":[{"composite_pattern":"repeated","visualization_type":[["graph"]]}],"coOccurrence":[["graph","graph",["coOccurrence"]]],"year":2015,"conference":["VAST"],"authors":["Stef van den Elzen","Danny Holten","Jorik Blaas","Jarke J. van Wijk"],"title":"Reducing Snapshots to Points: A Visual Analytics Approach to Dynamic Network Exploration","doi":"10.1109/TVCG.2015.2468078","abstract":"We propose a visual analytics approach for the exploration and analysis of dynamic networks. We consider snapshots of the network as points in high-dimensional space and project these to two dimensions for visualization and interaction using two juxtaposed views: one for showing a snapshot and one for showing the evolution of the network. With this approach users are enabled to detect stable states, recurring states, outlier topologies, and gain knowledge about the transitions between states and the network evolution in general. The components of our approach are discretization, vectorization and normalization, dimensionality reduction, and visualization and interaction, which are discussed in detail. The effectiveness of the approach is shown by applying it to artificial and real-world dynamic networks.","keywords":"Dynamic Networks, Exploration, Dimensionality Reduction","caption":"Fig. 6. Graphical user interface of the prototype implementing the different components of the visual analytics approach with a) the projection view with snapshots of the dynamic network reduced to points, b) the linked network view with a node-link diagram of a selected snapshot in the projection view, and c) linked time control, and d) auxiliary degree distribution view for a selected snapshot.","img_size":{"width":2157,"height":1198},"subfigures":[{"x":9.782679880955383,"y":18.64289978537648,"width":2127.616290354759,"height":1160.7142004292468,"type":"interface","id":"interface-0"}],"visualizations":[{"x":460.5592885375495,"y":97.0711462450593,"width":736.3201581027669,"height":958.8735177865615,"type":"graph","id":"graph-0"},{"x":1272.6422924901187,"y":99.43873517786562,"width":807.3478260869564,"height":918.6245059288538,"type":"graph","id":"graph-1"}],"relations":[{"vislist":[{"vislist":["graph-0","graph-1"],"relation":null,"id":"group-0"}],"relation":"repeated","id":"relation-0"}]},"2715_2":{"comp":[["comb","comb",["repeated"]],["graph","map",["coordinated"]]],"visType":["comb","graph","map"],"compType":["repeated","coordinated"],"compressed_tree":[{"composite_pattern":"repeated","visualization_type":[[{"composite_pattern":"coordinated","visualization_type":[["graph"],["map"]]}]]}],"coOccurrence":[["graph","map",["coOccurrence"]]],"year":2015,"conference":["VAST"],"authors":["Tatiana von Landesberger","Felix Brodkorb","Philipp Roskosch","Natalia V. Andrienko","Gennady L. Andrienko","Andreas Kerren"],"title":"MobilityGraphs: Visual Analysis of Mass Mobility Dynamics via Spatio-Temporal Graphs and Clustering","doi":"10.1109/TVCG.2015.2468111","abstract":"Learning more about people mobility is an important task for official decision makers and urban planners. Mobility data sets characterize the variation of the presence of people in different places over time as well as movements (or flows) of people between the places. The analysis of mobility data is challenging due to the need to analyze and compare spatial situations (i.e., presence and flows of people at certain time moments) and to gain an understanding of the spatio-temporal changes (variations of situations over time). Traditional flow visualizations usually fail due to massive clutter. Modern approaches offer limited support for investigating the complex variation of the movements over longer time periods. We propose a visual analytics methodology that solves these issues by combined spatial and temporal simplifications. We have developed a graph-based method, called MobilityGraphs, which reveals movement patterns that were occluded in flow maps. Our method enables the visual representation of the spatio-temporal variation of movements for long time series of spatial situations originally containing a large number of intersecting flows. The interactive system supports data exploration from various perspectives and at various levels of detail by interactive setting of clustering parameters. The feasibility our approach was tested on aggregated mobility data derived from a set of geolocated Twitter posts within the Greater London city area and mobile phone call data records in Abidjan, Ivory Coast. We could show that MobilityGraphs support the identification of regular daily and weekly movement patterns of resident population.","keywords":"Visual analytics, movement data, networks, graphs, temporal aggregation, spatial aggregation, flows, clustering","caption":"Fig. 3. Cluster result window with several views contained: (a) calen- dar view of temporal clusters, (b) interactive parameter setting, and (c) cluster overview.","img_size":{"width":1059,"height":810},"subfigures":[{"x":11.835626387204405,"y":11.523880175194122,"width":1034.2223929455881,"height":789.1650051176384,"type":"interface","id":"interface-0"}],"visualizations":[{"x":20.44861660079043,"y":265.73121766327864,"width":241.7193675889327,"height":232.11462450592887,"type":"graph","id":"graph-0"},{"x":292.5830039525689,"y":256.1264745802747,"width":227.3122529644267,"height":240.1185770750988,"type":"graph","id":"graph-1"},{"x":547.1086956521738,"y":259.3280556079427,"width":232.11462450592876,"height":236.9169960474308,"type":"graph","id":"graph-2"},{"x":811.2391304347824,"y":259.3280556079427,"width":235.31620553359699,"height":236.9169960474308,"type":"graph","id":"graph-3"},{"x":548.7094861660078,"y":534.6640239873893,"width":233.71541501976276,"height":240.11857707509878,"type":"graph","id":"graph-4"},{"x":290.9822134387349,"y":541.0671860427253,"width":232.11462450592862,"height":227.31225296442688,"type":"graph","id":"graph-5"},{"x":23.650197628458443,"y":542.6679765565593,"width":236.9169960474306,"height":228.91304347826076,"type":"graph","id":"graph-6"},{"x":12.444664031620498,"y":8.003944936005965,"width":525.0592885375489,"height":244.92094861660078,"type":"heatmap","id":"heatmap-7"},{"x":290.9977884667544,"y":261.1242175956873,"width":230.76898263376222,"height":237.75156104102211,"type":"map","id":"map-10"},{"x":546.2205917770274,"y":262.1142847019211,"width":231.81244130234055,"height":236.7714269039071,"type":"map","id":"map-11"},{"x":809.6155334248965,"y":257.1806658730102,"width":239.533636019112,"height":243.638664335672,"type":"map","id":"map-12"},{"x":19.824176256012244,"y":548.8962498690186,"width":241.60800026752534,"height":224.20753884221233,"type":"map","id":"map-13"},{"x":288.03883825987333,"y":547.6929281071626,"width":236.68688304752376,"height":222.6141820645159,"type":"map","id":"map-14"},{"x":550.2823073073776,"y":544.6694008062391,"width":234.69953806586753,"height":230.6612677867603,"type":"map","id":"map-15"},{"x":13.875427351121825,"y":261.1242175956877,"width":249.50166977758684,"height":237.7515610410212,"type":"map","id":"map-9"},{"x":15.646245059288447,"y":11.20552596367395,"width":520.256916996047,"height":243.32015810276678,"type":"matrix","id":"matrix-8"}],"relations":[{"vislist":[{"vislist":[{"vislist":[{"vislist":["graph-4"],"relation":null,"id":"group-14"},{"vislist":["map-15"],"relation":null,"id":"group-13"}],"relation":"coordinated","id":"relation-7"},{"vislist":[{"vislist":["graph-5"],"relation":null,"id":"group-12"},{"vislist":["map-14"],"relation":null,"id":"group-11"}],"relation":"coordinated","id":"relation-6"},{"vislist":[{"vislist":["graph-6"],"relation":null,"id":"group-10"},{"vislist":["map-13"],"relation":null,"id":"group-9"}],"relation":"coordinated","id":"relation-5"},{"vislist":[{"vislist":["graph-3"],"relation":null,"id":"group-8"},{"vislist":["map-12"],"relation":null,"id":"group-7"}],"relation":"coordinated","id":"relation-4"},{"vislist":[{"vislist":["graph-2"],"relation":null,"id":"group-6"},{"vislist":["map-11"],"relation":null,"id":"group-5"}],"relation":"coordinated","id":"relation-3"},{"vislist":[{"vislist":["graph-1"],"relation":null,"id":"group-4"},{"vislist":["map-10"],"relation":null,"id":"group-3"}],"relation":"coordinated","id":"relation-2"},{"vislist":[{"vislist":["graph-0"],"relation":null,"id":"group-2"},{"vislist":["map-9"],"relation":null,"id":"group-1"}],"relation":"coordinated","id":"relation-1"}],"relation":null,"id":"group-15"}],"relation":"repeated","id":"relation-8"}]},"2716_8":{"comp":[["bar_chart","bar_chart",["repeated"]],["area_chart","sankey_diagram",["accompanied"]],["sankey_diagram","area_chart",["accompanied"]],["comb","comb",["stacked"]]],"visType":["bar_chart","area_chart","sankey_diagram","comb"],"compType":["repeated","accompanied","stacked"],"compressed_tree":[{"composite_pattern":"stacked","visualization_type":[[{"composite_pattern":"repeated","visualization_type":[["bar_chart"]]},{"composite_pattern":"accompanied","visualization_type":[["area_chart","sankey_diagram"]]}]]}],"coOccurrence":[["area_chart","sankey_diagram",["coOccurrence"]],["area_chart","bar_chart",["coOccurrence"]],["sankey_diagram","bar_chart",["coOccurrence"]]],"year":2015,"conference":["VAST"],"authors":["Yanhong Wu","Naveen Pitipornvivat","Jian Zhao","Sixiao Yang","Guowei Huang","Huamin Qu"],"title":"egoSlider: Visual Analysis of Egocentric Network Evolution","doi":"10.1109/TVCG.2015.2468151","abstract":"Ego-network, which represents relationships between a specific individual, i.e., the ego, and people connected to it, i.e., alters, is a critical target to study in social network analysis. Evolutionary patterns of ego-networks along time provide huge insights to many domains such as sociology, anthropology, and psychology. However, the analysis of dynamic ego-networks remains challenging due to its complicated time-varying graph structures, for example: alters come and leave, ties grow stronger and fade away, and alter communities merge and split. Most of the existing dynamic graph visualization techniques mainly focus on topological changes of the entire network, which is not adequate for egocentric analytical tasks. In this paper, we present egoSlider, a visual analysis system for exploring and comparing dynamic ego-networks. egoSlider provides a holistic picture of the data through multiple interactively coordinated views, revealing ego-network evolutionary patterns at three different layers: a macroscopic level for summarizing the entire ego-network data, a mesoscopic level for overviewing specific individuals\' ego-network evolutions, and a microscopic level for displaying detailed temporal information of egos and their alters. We demonstrate the effectiveness of egoSlider with a usage scenario with the DBLP publication records. Also, a controlled user study indicates that in general egoSlider outperforms a baseline visualization of dynamic networks for completing egocentric analytical tasks.","keywords":"Egocentric network, dynamic graph, network visualization, glyph-based design, visual analytics","caption":"Fig. 10. Alter Timeline Views of a) Jian Sun and b) Xiaoou Tang, where alters are ordered by tie strength and colored with alter types. The highlighted alters are Xiaoou Tang and Xiaogang Wang respectively.","img_size":{"width":1065,"height":720},"subfigures":[{"x":5.017400441264686,"y":3.4498548460546283,"width":1049.0631354069678,"height":361.0247180618319,"type":"single","id":"single-0"}],"visualizations":[{"x":24.732344689969604,"y":271.3913725339435,"width":1012.3012497582071,"height":76.19411999152571,"type":"area_chart","id":"area_chart-3"},{"x":10.207543950167336,"y":2.686474232556136,"width":1042.0347521845663,"height":55.61901101959668,"type":"bar_chart","id":"bar_chart-0"},{"x":22.331902488352082,"y":58.6189753693655,"width":1019.5276798078324,"height":289.18623840568614,"type":"sankey_diagram","id":"sankey_diagram-2"}],"relations":[{"vislist":[{"vislist":[{"vislist":[{"vislist":["bar_chart-0"],"relation":null,"id":"group-1"}],"relation":"repeated","id":"relation-1"},{"vislist":[{"vislist":["area_chart-3","sankey_diagram-2"],"relation":null,"id":"group-0"}],"relation":"accompanied","id":"relation-0"}],"relation":null,"id":"group-2"}],"relation":"stacked","id":"relation-2"}]},"2718_0":{"comp":[["comb","comb",["repeated"]],["glyph_based","graph",["nested"]]],"visType":["comb","glyph_based","graph"],"compType":["repeated","nested"],"compressed_tree":[{"composite_pattern":"repeated","visualization_type":[[{"composite_pattern":"nested","visualization_type":[["glyph_based"],["graph"]]}]]}],"coOccurrence":[["glyph_based","graph",["coOccurrence"]],["glyph_based","tree",["coOccurrence"]],["graph","tree",["coOccurrence"]]],"year":2015,"conference":["VAST"],"authors":["Sujin Jang","Niklas Elmqvist","Karthik Ramani"],"title":"MotionFlow: Visual Abstraction and Aggregation of Sequential Patterns in Human Motion Tracking Data","doi":"10.1109/TVCG.2015.2468292","abstract":"Pattern analysis of human motions, which is useful in many research areas, requires understanding and comparison of different styles of motion patterns. However, working with human motion tracking data to support such analysis poses great challenges. In this paper, we propose MotionFlow, a visual analytics system that provides an effective overview of various motion patterns based on an interactive flow visualization. This visualization formulates a motion sequence as transitions between static poses, and aggregates these sequences into a tree diagram to construct a set of motion patterns. The system also allows the users to directly reflect the context of data and their perception of pose similarities in generating representative pose states. We provide local and global controls over the partition-based clustering process. To support the users in organizing unstructured motion data into pattern groups, we designed a set of interactions that enables searching for similar motion sequences from the data, detailed exploration of data subsets, and creating and modifying the group of motion patterns. To evaluate the usability of MotionFlow, we conducted a user study with six researchers with expertise in gesture-based interaction design. They used MotionFlow to explore and organize unstructured motion tracking data. Results show that the researchers were able to easily learn how to use MotionFlow, and the system effectively supported their pattern analysis activities, including leveraging their perception and domain knowledge.","keywords":"Human motion visualization, interactive clustering, motion tracking data, expert reviews, user study","caption":"Fig. 1. MotionFlow for pattern analysis of human motion data. (a) Pose tree: a simplified representation of multiple motion sequences aggregating the same transitions into a tree diagram. (b) A window dedicated to show a subtree structure based on a query. (c)Space-filling treemap [32] representation of the motion sequence data using slice-and-dice layout. (d) Node-link diagram of poseclusters (nodes) and transitions (links) between them. This view supports interactive partition-based pose clustering. (e) Multi-tab interface for storing unique motion patterns. (f) Animations of single or multiple selected human motions.","img_size":{"width":1923,"height":836},"subfigures":[{"x":9.258433981062904,"y":11.370611179354867,"width":1891.912577686898,"height":807.6777592456989,"type":"interface","id":"interface-0"}],"visualizations":[{"x":395.91666666666663,"y":98.99999999999996,"width":836.0000000000003,"height":452.83333333333337,"type":"glyph_based","id":"glyph_based-0"},{"x":395.91666666666663,"y":595.8333333333335,"width":836.0000000000003,"height":207.16666666666674,"type":"glyph_based","id":"glyph_based-1"},{"x":1259.4166666666672,"y":64.16666666666661,"width":601.3333333333333,"height":724.1666666666667,"type":"glyph_based","id":"glyph_based-2"},{"x":1268.5833333333333,"y":62.333333333333286,"width":586.6666666666667,"height":726.0000000000001,"type":"graph","id":"graph-3"},{"x":386.75,"y":98.99999999999996,"width":845.1666666666669,"height":454.6666666666668,"type":"graph","id":"graph-4"},{"x":390.41666666666663,"y":597.6666666666667,"width":837.8333333333335,"height":203.5,"type":"graph","id":"graph-5"},{"x":390.41666666666663,"y":98.99999999999996,"width":837.8333333333335,"height":447.3333333333334,"type":"tree","id":"tree-6"},{"x":390.41666666666663,"y":599.5,"width":841.5000000000003,"height":209.0000000000001,"type":"tree","id":"tree-7"},{"x":25.583333333333204,"y":38.49999999999995,"width":341.0000000000001,"height":302.50000000000006,"type":"treemap","id":"treemap-8"}],"relations":[{"vislist":[{"vislist":[{"vislist":[{"vislist":["glyph_based-2"],"relation":null,"id":"group-3"},{"vislist":["graph-3"],"relation":null,"id":"group-2"}],"relation":"nested","id":"relation-0"},{"vislist":[{"vislist":["glyph_based-1"],"relation":null,"id":"group-5"},{"vislist":["tree-7"],"relation":null,"id":"group-4"}],"relation":"nested","id":"relation-1"},{"vislist":[{"vislist":["glyph_based-0"],"relation":null,"id":"group-7"},{"vislist":["tree-6"],"relation":null,"id":"group-6"}],"relation":"nested","id":"relation-2"}],"relation":null,"id":"group-8"}],"relation":"repeated","id":"relation-3"}]},"2719_6":{"comp":[["scatterplot","scatterplot",["repeated"]],["bar_chart","bar_chart",["repeated"]]],"visType":["scatterplot","bar_chart"],"compType":["repeated"],"compressed_tree":[{"composite_pattern":"repeated","visualization_type":[["scatterplot"]]},{"composite_pattern":"repeated","visualization_type":[["bar_chart"]]}],"coOccurrence":[["scatterplot","bar_chart",["coOccurrence"]]],"year":2015,"conference":["VAST"],"authors":["Paola Valdivia","Fabio Dias","Fabiano Petronetto","Cl\xe1udio T. Silva","Luis Gustavo Nonato"],"title":"Wavelet-based visualization of time-varying data on graphs","doi":"10.1109/VAST.2015.7347624","abstract":"Visualizing time-varying data defined on the nodes of a graph is a challenging problem that has been faced with different approaches. Although techniques based on aggregation, topology, and topic modeling have proven their usefulness, the visual analysis of smooth and/or abrupt data variations as well as the evolution of such variations over time are aspects not properly tackled by existing methods. In this work we propose a novel visualization methodology that relies on graph wavelet theory and stacked graph metaphor to enable the visual analysis of time-varying data defined on the nodes of a graph. The proposed method is able to identify regions where data presents abrupt and mild spacial and/or temporal variation while still been able to show how such changes evolve over time, making the identification of events an easier task. The usefulness of our approach is shown through a set of results using synthetic as well as a real data set involving taxi trips in downtown Manhattan. The methodology was able to reveal interesting phenomena and events such as the identification of specific locations with abrupt variation in the number of taxi pickups.","keywords":"Time-varying data, graph wavelets, stacked graph visualization","caption":"Figure 6:  Screenshot of our prototype interface which comprises astacked graph visualization (top left), threshold slide bar for waveletscoefficients (middle left), average feature vector in each class (bot-tom left), graph map depicting node labels and function intensity inspecific time slice (top right), and time series of a node (bottom right).","img_size":{"width":982,"height":401},"subfigures":[{"x":11.08779658374833,"y":9.052616685366333,"width":946.9858375421688,"height":382.89476662926756,"type":"interface","id":"interface-0"}],"visualizations":[{"x":9.99259944495837,"y":56.06151711378356,"width":475.1026827012025,"height":205.30249768732654,"type":"area_chart","id":"area_chart-0"},{"x":12.717853839037927,"y":310.41859389454214,"width":375.1766882516189,"height":72.67345050878811,"type":"bar_chart","id":"bar_chart-1"},{"x":492.3626271970397,"y":312.2354301572618,"width":84.48288621646623,"height":32.703052728954674,"type":"bar_chart","id":"bar_chart-2"},{"x":9.99259944495837,"y":56.969935245143404,"width":475.1026827012025,"height":204.3940795559667,"type":"line_chart","id":"line_chart-3"},{"x":610.4569842738205,"y":290.43339500462537,"width":326.12210915818684,"height":80.84921369102682,"type":"line_chart","id":"line_chart-4"},{"x":491.4542090656799,"y":55.1530989824237,"width":218.02035152636444,"height":208.02775208140613,"type":"scatterplot","id":"scatterplot-5"},{"x":734.0018501387603,"y":54.24468085106385,"width":218.9287696577244,"height":204.3940795559667,"type":"scatterplot","id":"scatterplot-6"}],"relations":[{"vislist":[{"vislist":["scatterplot-5","scatterplot-6"],"relation":null,"id":"group-0"}],"relation":"repeated","id":"relation-0"},{"vislist":[{"vislist":["bar_chart-1"],"relation":null,"id":"group-1"}],"relation":"repeated","id":"relation-1"}]},"2721_4":{"comp":[["map","map",["repeated"]],["scatterplot","scatterplot",["repeated"]]],"visType":["map","scatterplot"],"compType":["repeated"],"compressed_tree":[{"composite_pattern":"repeated","visualization_type":[["map"]]},{"composite_pattern":"repeated","visualization_type":[["scatterplot"]]}],"coOccurrence":[["map","scatterplot",["coOccurrence"]]],"year":2015,"conference":["VAST"],"authors":["Chris Bryan","Xue Wu","Susan M. Mniszewski","Kwan-Liu Ma"],"title":"Integrating predictive analytics into a spatiotemporal epidemic simulation","doi":"10.1109/VAST.2015.7347626","abstract":"The Epidemic Simulation System (EpiSimS) is a scalable, complex modeling tool for analyzing disease within the United States. Due to its high input dimensionality, time requirements, and resource constraints, simulating over the entire parameter space is unfeasible. One solution is to take a granular sampling of the input space and use simpler predictive models (emulators) in between. The quality of the implemented emulator depends on many factors: robustness, sophistication, configuration, and suitability to the input data. Visual analytics can be leveraged to provide guidance and understanding of these things to the user. In this paper, we have implemented a novel interface and workflow for emulator building and use. We introduce a workflow to build emulators, make predictions, and then analyze the results. Our prediction process first predicts temporal time series, and uses these to derive predicted spatial densities. Integrated into the EpiSimS framework, we target users who are non-experts at statistical modeling. This approach allows for a high level of analysis into the state of the built emulators and their resultant predictions. We present our workflow, models, the associated system, and evaluate the overall utility with feedback from EpiSimS scientists.","keywords":"Predictive Modeling, Visual Analytics, Epidemic Visualization, Spatial-Temporal Systems","caption":"Figure 6: The spatial analysis panel compares two runs (included predicted runs) to each other, spatially and via scatterplot views. The line chart at left shows the time series of the two runs and the left scatterplot aggregates the daily statistical views together.","img_size":{"width":750,"height":315},"subfigures":[{"x":5.22901279115373,"y":6.338217550188522,"width":733.549770488904,"height":295.7791364502359,"type":"interface","id":"interface-0"}],"visualizations":[{"x":172.06290471785383,"y":72.16234967622572,"width":550.1850138760407,"height":141.53561517113786,"type":"heatmap","id":"heatmap-0"},{"x":20.120259019426456,"y":75.6313598519889,"width":145.00462534690098,"height":92.9694727104533,"type":"line_chart","id":"line_chart-1"},{"x":18.732654949121184,"y":75.6313598519889,"width":146.39222941720627,"height":91.581868640148,"type":"scatterplot","id":"scatterplot-2"},{"x":33.996299722479186,"y":172.06984273820535,"width":124.88436632747454,"height":99.90749306197962,"type":"scatterplot","id":"scatterplot-3"},{"x":172.06290471785383,"y":219.9421831637373,"width":79.7872340425532,"height":67.99259944495837,"type":"scatterplot","id":"scatterplot-4"},{"x":265.0323774283071,"y":223.4111933395005,"width":81.17483811285848,"height":65.91119333950044,"type":"scatterplot","id":"scatterplot-5"},{"x":361.4708603145236,"y":221.32978723404253,"width":80.48103607770582,"height":68.68640148011102,"type":"scatterplot","id":"scatterplot-6"},{"x":457.21554116558735,"y":224.10499537465313,"width":79.09343200740062,"height":64.52358926919514,"type":"scatterplot","id":"scatterplot-7"},{"x":550.8788159111933,"y":222.71739130434787,"width":79.78723404255311,"height":65.91119333950041,"type":"scatterplot","id":"scatterplot-8"},{"x":643.1544865864939,"y":221.32978723404253,"width":81.86864014801108,"height":67.99259944495837,"type":"scatterplot","id":"scatterplot-9"},{"x":171.3691026827012,"y":71.46854764107309,"width":552.2664199814985,"height":142.92321924144315,"type":"map","id":"map-10"}],"relations":[{"vislist":[{"vislist":["map-10"],"relation":null,"id":"group-0"}],"relation":"repeated","id":"relation-0"},{"vislist":[{"vislist":["scatterplot-5","scatterplot-4","scatterplot-6","scatterplot-7","scatterplot-8","scatterplot-9"],"relation":null,"id":"group-1"}],"relation":"repeated","id":"relation-1"}]},"2721_5":{"comp":[["comb","comb",["repeated"]],["heatmap","map",["coordinated"]]],"visType":["comb","heatmap","map"],"compType":["repeated","coordinated"],"compressed_tree":[{"composite_pattern":"repeated","visualization_type":[[{"composite_pattern":"coordinated","visualization_type":[["heatmap"],["map"]]}]]}],"coOccurrence":[["heatmap","map",["coOccurrence"]]],"year":2015,"conference":["VAST"],"authors":["Chris Bryan","Xue Wu","Susan M. Mniszewski","Kwan-Liu Ma"],"title":"Integrating predictive analytics into a spatiotemporal epidemic simulation","doi":"10.1109/VAST.2015.7347626","abstract":"The Epidemic Simulation System (EpiSimS) is a scalable, complex modeling tool for analyzing disease within the United States. Due to its high input dimensionality, time requirements, and resource constraints, simulating over the entire parameter space is unfeasible. One solution is to take a granular sampling of the input space and use simpler predictive models (emulators) in between. The quality of the implemented emulator depends on many factors: robustness, sophistication, configuration, and suitability to the input data. Visual analytics can be leveraged to provide guidance and understanding of these things to the user. In this paper, we have implemented a novel interface and workflow for emulator building and use. We introduce a workflow to build emulators, make predictions, and then analyze the results. Our prediction process first predicts temporal time series, and uses these to derive predicted spatial densities. Integrated into the EpiSimS framework, we target users who are non-experts at statistical modeling. This approach allows for a high level of analysis into the state of the built emulators and their resultant predictions. We present our workflow, models, the associated system, and evaluate the overall utility with feedback from EpiSimS scientists.","keywords":"Predictive Modeling, Visual Analytics, Epidemic Visualization, Spatial-Temporal Systems","caption":"Figure S:  The  prediction panel allows analysis of  a  single pre\xaddiction. Its main components are (A)  temporal mean squared er\xadror bars, (B)  time series lines for the  prediction  (red), other runs (blue), and  confidence and  prediction  intervals (dotted lines and green bounds) (C)  map snapshots based on time series segmenta\xadtion, (D)  a  star  coordinates plot  for  dimensional investigation of runs in the  input parameter space, and  (E)  the  run  influence bar with closest runs highlighted dark blue.","img_size":{"width":757,"height":470},"subfigures":[{"x":5.876225692496029,"y":5.957048612920416,"width":733.691935979497,"height":443.96244910786424,"type":"interface","id":"interface-0"}],"visualizations":[{"x":27.54605263157896,"y":373.11403508771934,"width":693.6622807017545,"height":51.535087719298254,"type":"bar_chart","id":"bar_chart-0"},{"x":233.68640350877195,"y":71.11842105263159,"width":415.37280701754383,"height":210.26315789473685,"type":"heatmap","id":"heatmap-1"},{"x":140.92324561403512,"y":304.0570175438596,"width":81.42543859649118,"height":64.93421052631584,"type":"heatmap","id":"heatmap-2"},{"x":232.65570175438603,"y":305.0877192982456,"width":83.48684210526311,"height":64.93421052631584,"type":"heatmap","id":"heatmap-3"},{"x":329.54166666666663,"y":305.08771929824564,"width":80.39473684210526,"height":62.87280701754389,"type":"heatmap","id":"heatmap-4"},{"x":423.3355263157895,"y":306.11842105263156,"width":82.45614035087716,"height":65.96491228070175,"type":"heatmap","id":"heatmap-5"},{"x":521.2521929824561,"y":308.1798245614035,"width":81.42543859649129,"height":61.84210526315792,"type":"heatmap","id":"heatmap-6"},{"x":616.076754385965,"y":306.11842105263156,"width":82.45614035087716,"height":63.903508771929864,"type":"heatmap","id":"heatmap-7"},{"x":232.65570175438603,"y":68.02631578947368,"width":417.4342105263158,"height":213.35526315789474,"type":"line_chart","id":"line_chart-8"},{"x":139.89254385964918,"y":304.0570175438597,"width":82.45614035087716,"height":64.93421052631578,"type":"map","id":"map-10"},{"x":233.68640350877195,"y":306.11842105263156,"width":80.39473684210526,"height":60.811403508771946,"type":"map","id":"map-11"},{"x":329.54166666666663,"y":305.0877192982456,"width":81.42543859649125,"height":62.87280701754389,"type":"map","id":"map-12"},{"x":422.30482456140345,"y":307.1491228070176,"width":84.5175438596491,"height":64.93421052631578,"type":"map","id":"map-13"},{"x":521.2521929824561,"y":309.21052631578954,"width":81.42543859649129,"height":59.78070175438597,"type":"map","id":"map-14"},{"x":615.046052631579,"y":307.1491228070176,"width":82.45614035087716,"height":61.84210526315792,"type":"map","id":"map-15"},{"x":30.63815789473685,"y":78.33333333333333,"width":204.07894736842104,"height":193.77192982456143,"type":"scatterplot","id":"scatterplot-9"}],"relations":[{"vislist":[{"vislist":[{"vislist":[{"vislist":["heatmap-7"],"relation":null,"id":"group-11"},{"vislist":["map-15"],"relation":null,"id":"group-10"}],"relation":"coordinated","id":"relation-5"},{"vislist":[{"vislist":["heatmap-6"],"relation":null,"id":"group-9"},{"vislist":["map-14"],"relation":null,"id":"group-8"}],"relation":"coordinated","id":"relation-4"},{"vislist":[{"vislist":["heatmap-5"],"relation":null,"id":"group-7"},{"vislist":["map-13"],"relation":null,"id":"group-6"}],"relation":"coordinated","id":"relation-3"},{"vislist":[{"vislist":["heatmap-4"],"relation":null,"id":"group-5"},{"vislist":["map-12"],"relation":null,"id":"group-4"}],"relation":"coordinated","id":"relation-2"},{"vislist":[{"vislist":["heatmap-3"],"relation":null,"id":"group-3"},{"vislist":["map-11"],"relation":null,"id":"group-2"}],"relation":"coordinated","id":"relation-1"},{"vislist":[{"vislist":["heatmap-2"],"relation":null,"id":"group-1"},{"vislist":["map-10"],"relation":null,"id":"group-0"}],"relation":"coordinated","id":"relation-0"}],"relation":null,"id":"group-12"}],"relation":"repeated","id":"relation-6"}]},"2726_0":{"comp":[["area_chart","area_chart",["repeated"]]],"visType":["area_chart"],"compType":["repeated"],"compressed_tree":[{"composite_pattern":"repeated","visualization_type":[["area_chart"]]}],"coOccurrence":[["area_chart","area_chart",["coOccurrence"]]],"year":2015,"conference":["VAST"],"authors":["Wenwen Dou","Isaac Cho","Omar ElTayeby","Jaegul Choo","Xiaoyu Wang","William Ribarsky"],"title":"DemographicVis: Analyzing demographic information based on user generated content","doi":"10.1109/VAST.2015.7347631","abstract":"The wide-spread of social media provides unprecedented sources of written language that can be used to model and infer online demographics. In this paper, we introduce a novel visual text analytics system, DemographicVis, to aid interactive analysis of such demographic information based on user-generated content. Our approach connects categorical data (demographic information) with textual data, allowing users to understand the characteristics of different demographic groups in a transparent and exploratory manner. The modeling and visualization are based on ground truth demographic information collected via a survey conducted on Reddit.com. Detailed user information is taken into our modeling process that connects the demographic groups with features that best describe the distinguishing characteristics of each group. Features including topical and linguistic are generated from the user-generated contents. Such features are then analyzed and ranked based on their ability to predict the users\' demographic information. To enable interactive demographic analysis, we introduce a web-based visual interface that presents the relationship of the demographic groups, their topic interests, as well as the predictive power of various features. We present multiple case studies to showcase the utility of our visual analytics approach in exploring and understanding the interests of different demographic groups. We also report results from a comparative evaluation, showing that the DemographicVis is quantitatively superior or competitive and subjectively preferred when compared to a commercial text analysis tool.","keywords":"Visual Text Analysis, User Interface, Social Media, Demographic Analysis","caption":"Figure 1: DemographicVis interface: A) Parallel Sets with word cloud view that connects demographic groups to user generated content, B) user cluster view that groups users based on topic interests, C) feature ranking view that presents the predicative power of various features, D) posts view showing details on demand.","img_size":{"width":1924,"height":982},"subfigures":[{"x":17.611381545353705,"y":13.990430675920486,"width":1881.7899639644515,"height":955.4169776008274,"type":"interface","id":"interface-0"}],"visualizations":[{"x":349.32675438596493,"y":64.60526315789473,"width":228.27192982456143,"height":508.2280701754386,"type":"area_chart","id":"area_chart-0"},{"x":1079.3662280701753,"y":49.53070175438597,"width":816.1798245614034,"height":579.2938596491227,"type":"glyph_based","id":"glyph_based-1"},{"x":62.91008771929827,"y":53.83771929824562,"width":264.8815789473684,"height":473.7719298245614,"type":"parallel_coordinate","id":"parallel_coordinate-2"},{"x":49.704698045932844,"y":640.7175357219409,"width":676.8700014558716,"height":271.8426690483151,"type":"table","id":"table-3"},{"x":756.7217894833138,"y":629.2868124430257,"width":1128.6126225521532,"height":261.8177930695311,"type":"table","id":"table-4"},{"x":584.0592105263158,"y":79.67982456140352,"width":430.70175438596493,"height":439.31578947368416,"type":"word_cloud","id":"word_cloud-5"},{"x":28.45394736842107,"y":536.2236842105264,"width":118.44298245614031,"height":34.45614035087727,"type":"word_cloud","id":"word_cloud-6"}],"relations":[{"vislist":[{"vislist":["area_chart-0"],"relation":null,"id":"group-0"}],"relation":"repeated","id":"relation-0"}]},"2728_0":{"comp":[["map","map",["repeated"]],["area_chart","area_chart",["repeated"]],["area_chart","line_chart",["accompanied"]],["bar_chart","line_chart",["accompanied"]],["line_chart","bar_chart",["accompanied"]],["line_chart","area_chart",["accompanied"]]],"visType":["map","area_chart","line_chart","bar_chart"],"compType":["repeated","accompanied"],"compressed_tree":[{"composite_pattern":"accompanied","visualization_type":[["bar_chart","line_chart"]]},{"composite_pattern":"accompanied","visualization_type":[["area_chart","line_chart"]]},{"composite_pattern":"repeated","visualization_type":[["map"]]},{"composite_pattern":"accompanied","visualization_type":[["line_chart","bar_chart"]]},{"composite_pattern":"repeated","visualization_type":[["area_chart"]]}],"coOccurrence":[["area_chart","area_chart",["coOccurrence"]]],"year":2015,"conference":["VAST"],"authors":["Quan Li","Peng Xu","Huamin Qu"],"title":"FPSSeer: Visual analysis of game frame rate data","doi":"10.1109/VAST.2015.7347633","abstract":"The rate at which frames are rendered in a computer game directly influences both game playability and enjoyability. Players frequently have to deal with the trade-off between high frame rates and good resolution. Analyzing patterns in frame rate data and their correlation with the overall game performance is important in designing games (e.g., graphic card/display setting suggestion and game performance measurement). However, this task is challenging because game frame rates vary both temporally and spatially. In addition, players may adjust their display settings based on their gaming experience and hardware conditions, which further contributes to the unpredictability of frame rates. In this paper, we present a comprehensive visual analytics system FPSSeer, to help game designers gain insight into frame rate data. Our system consists of four major views: 1) a frame rate view to show the overall distribution in a geographic scale, 2) a grid view to show the frame rate distribution and grid element clusters based on their similarity, 3) a FootRiver view to reveal the temporal patterns in game condition changes and potential spatiotemporal correlations, and 4) a comparison view to evaluate game performance discrepancy under different game tests. The real-world case studies demonstrate the effectiveness of our system. The system has been applied to an online commercial game to monitor its performance and to provide feedbacks to designers and developers.","keywords":"frame rate data, game performance evaluation, visual analytics","caption":"Figure 1: The interface of FPSSeer: (a) frame rate view to show the overall distribution; (b) grid view to visualize the f ps distribution in a grid element and similarities among grid elements; (c) FootRiver view to depict major migration changes from one gaming condition to another on adjacent time frames; (d) comparison view to quantitatively measure the game performance difference between tests.","img_size":{"width":1787,"height":702},"subfigures":[{"x":22.880995809942238,"y":241.83411477430298,"width":1187.7380271263503,"height":686.6586198897585,"type":"interface","id":"interface-0"},{"x":1217.9531878036385,"y":241.49520790617413,"width":581.9063704051966,"height":336.40308817122377,"type":"single","id":"single-1"},{"x":1217.987093871265,"y":601.2124586446087,"width":588.4081927591437,"height":325.4070630993501,"type":"single","id":"single-2"}],"visualizations":[{"x":28.050115913825945,"y":377.71477190265864,"width":861.2964833733894,"height":308.53775935853855,"type":"area_chart","id":"area_chart-26"},{"x":1208.766339530015,"y":379.0207248583752,"width":559.2365577085909,"height":304.5701706637204,"type":"area_chart","id":"area_chart-32"},{"x":563.4703951333233,"y":240.2363395812199,"width":628.8565957702085,"height":125.27384321720902,"type":"bar_chart","id":"bar_chart-24"},{"x":1207.4053728647282,"y":195.82654828991204,"width":559.245220259763,"height":130.04109322993983,"type":"bar_chart","id":"bar_chart-31"},{"x":564.7772829472643,"y":16.396829883917018,"width":619.4596431938161,"height":221.83102171504055,"type":"heatmap","id":"heatmap-22"},{"x":560.7650031306525,"y":242.87715241154254,"width":630.1974736064444,"height":121.3479003399487,"type":"line_chart","id":"line_chart-23"},{"x":24.007011572500392,"y":376.42800912637966,"width":866.6694212766319,"height":313.82265047786575,"type":"line_chart","id":"line_chart-25"},{"x":1203.3564661291266,"y":196.95788303009095,"width":564.6297629515637,"height":127.77842374958256,"type":"line_chart","id":"line_chart-30"},{"x":13.409464051912712,"y":10.582549190150463,"width":501.22343025275336,"height":336.49147463985037,"type":"map","id":"map-21"},{"x":1209.3778791920588,"y":6.643973351907899,"width":252.7705157015656,"height":178.97532674333794,"type":"map","id":"map-28"},{"x":1475.0030592717292,"y":10.510044563664618,"width":269.6008529818119,"height":171.24318431982408,"type":"map","id":"map-29"},{"x":903.4605744435825,"y":385.6862198081044,"width":286.678449185479,"height":293.9505463310318,"type":"scatterplot","id":"scatterplot-27"}],"relations":[{"vislist":[{"vislist":["bar_chart-24","line_chart-23"],"relation":null,"id":"group-13"}],"relation":"accompanied","id":"relation-10"},{"vislist":[{"vislist":["area_chart-26","line_chart-25"],"relation":null,"id":"group-14"}],"relation":"accompanied","id":"relation-11"},{"vislist":[{"vislist":["map-28","map-29"],"relation":null,"id":"group-15"}],"relation":"repeated","id":"relation-12"},{"vislist":[{"vislist":["line_chart-30","bar_chart-31"],"relation":null,"id":"group-16"}],"relation":"accompanied","id":"relation-13"},{"vislist":[{"vislist":["area_chart-32"],"relation":null,"id":"group-17"}],"relation":"repeated","id":"relation-14"}]},"2730_6":{"comp":[["bar_chart","bar_chart",["repeated"]],["line_chart","line_chart",["repeated"]]],"visType":["bar_chart","line_chart"],"compType":["repeated"],"compressed_tree":[{"composite_pattern":"repeated","visualization_type":[["bar_chart"]]},{"composite_pattern":"repeated","visualization_type":[["line_chart"]]}],"coOccurrence":[["bar_chart","line_chart",["coOccurrence"]]],"year":2015,"conference":["VAST"],"authors":["Rainer Splechtna","Kresimir Matkovic","Denis Gracanin","Mario Jelovic","Helwig Hauser"],"title":"Interactive visual steering of hierarchical simulation ensembles","doi":"10.1109/VAST.2015.7347635","abstract":"Multi-level simulation models, i.e., models where different components are simulated using sub-models of varying levels of complexity, belong to the current state-of-the-art in simulation. The existing analysis practice for multi-level simulation results is to manually compare results from different levels of complexity, amounting to a very tedious and error-prone, trial-and-error exploration process. In this paper, we introduce hierarchical visual steering, a new approach to the exploration and design of complex systems. Hierarchical visual steering makes it possible to explore and analyze hierarchical simulation ensembles at different levels of complexity. At each level, we deal with a dynamic simulation ensemble - the ensemble grows during the exploration process. There is at least one such ensemble per simulation level, resulting in a collection of dynamic ensembles, analyzed simultaneously. The key challenge is to map the multi-dimensional parameter space of one ensemble to the multi-dimensional parameter space of another ensemble (from another level). In order to support the interactive visual analysis of such complex data we propose a novel approach to interactive and semi-automatic parameter space segmentation and comparison. The approach combines a novel interaction technique and automatic, computational methods - clustering, concave hull computation, and concave polygon overlapping - to support the analysts in the cross-ensemble parameter space mapping. In addition to the novel parameter space segmentation we also deploy coordinated multiple views with standard plots. We describe the abstract analysis tasks, identified during a case study, i.e., the design of a variable valve actuation system of a car engine. The study is conducted in cooperation with experts from the automotive industry. Very positive feedback indicates the usefulness and efficiency of the newly proposed approach.","keywords":"Interactive Visual Analysis, Simulation-Ensemble Steering, Multi-resolution simulation","caption":"Figure 6: a.The initial, low resolution model of the VVA system (left) and the two refined models were designed with AVL Boost-Hydsim [1]. Each model and the corresponding ensemble has an assigned color (bar underneath). The control parameters under investigation in our case study are depicted in red, and three main state variables are shown in blue. b. A snapshot form a single-level analysis. The newly introduced interactive segmentation view is shown in top left. Different other views show various control parameters and output values of the ensemble. The data table in the bottom provides details on demand for selected runs.","img_size":{"width":2055,"height":888},"subfigures":[{"x":651.5024090304171,"y":10.274451337982741,"width":1393.8146972935078,"height":812.2266445541153,"type":"interface","id":"interface-0"}],"visualizations":[{"x":1813.4385065885801,"y":81.90922401171305,"width":201.52269399707188,"height":270.4304538799416,"type":"bar_chart","id":"bar_chart-0"},{"x":1812.138360175696,"y":371.84187408491954,"width":230.1259150805272,"height":227.5256222547585,"type":"bar_chart","id":"bar_chart-1"},{"x":687.5117130307468,"y":375.74231332357255,"width":426.4480234260615,"height":224.92532942898976,"type":"line_chart","id":"line_chart-2"},{"x":1121.7606149341143,"y":369.2415812591509,"width":375.7423133235727,"height":230.12591508052714,"type":"line_chart","id":"line_chart-3"},{"x":1247.8748169838948,"y":81.90922401171305,"width":552.5622254758422,"height":269.13030746705715,"type":"parallel_coordinate","id":"parallel_coordinate-4"}],"relations":[{"vislist":[{"vislist":["bar_chart-1","bar_chart-0"],"relation":null,"id":"group-0"}],"relation":"repeated","id":"relation-0"},{"vislist":[{"vislist":["line_chart-2","line_chart-3"],"relation":null,"id":"group-1"}],"relation":"repeated","id":"relation-1"}]},"2732_0":{"comp":[["bar_chart","bar_chart",["repeated"]]],"visType":["bar_chart"],"compType":["repeated"],"compressed_tree":[{"composite_pattern":"repeated","visualization_type":[["bar_chart"]]},{"composite_pattern":"repeated","visualization_type":[["bar_chart"]]}],"coOccurrence":[["bar_chart","bar_chart",["coOccurrence"]]],"year":2015,"conference":["VAST"],"authors":["Michael Brooks","Saleema Amershi","Bongshin Lee","Steven M. Drucker","Ashish Kapoor","Patrice Y. Simard"],"title":"FeatureInsight: Visual support for error-driven feature ideation in text classification","doi":"10.1109/VAST.2015.7347637","abstract":"Machine learning requires an effective combination of data, features, and algorithms. While many tools exist for working with machine learning data and algorithms, support for thinking of new features, or feature ideation, remains poor. In this paper, we investigate two general approaches to support feature ideation: visual summaries and sets of errors. We present FeatureInsight, an interactive visual analytics tool for building new dictionary features (semantically related groups of words) for text classification problems. FeatureInsight supports an error-driven feature ideation process and provides interactive visual summaries of sets of misclassified documents. We conducted a controlled experiment evaluating both visual summaries and sets of errors in FeatureInsight. Our results show that visual summaries significantly improve feature ideation, especially in combination with sets of errors. Users preferred visual summaries over viewing raw data, and only preferred examining sets when visual summaries were provided. We discuss extensions of both approaches to data types other than text, and point to areas for future research.","keywords":"","caption":"Figure 1. A screenshot of FeatureInsight being used to train a classifier for bicycling web pages: A) the featuring area; B) focus selection controls; C) key words for Errors; D) key words for Contrasts; E) words related to the selected word (brands).","img_size":{"width":2118,"height":1299},"subfigures":[{"x":11.991653105254287,"y":7.931327104879389,"width":2094.016693789491,"height":1281.3630357019904,"type":"interface","id":"interface-0"}],"visualizations":[{"x":441.83235724743787,"y":159.75988286969246,"width":460.26061493411424,"height":1105.0058565153736,"type":"bar_chart","id":"bar_chart-0"},{"x":1609.6010248901905,"y":165.46559297218147,"width":475.47584187408484,"height":1114.5153733528555,"type":"bar_chart","id":"bar_chart-1"}],"relations":[{"vislist":[{"vislist":["bar_chart-0"],"relation":null,"id":"group-0"}],"relation":"repeated","id":"relation-0"},{"vislist":[{"vislist":["bar_chart-1"],"relation":null,"id":"group-1"}],"relation":"repeated","id":"relation-1"}]},"2741_1":{"comp":[["bar_chart","bar_chart",["repeated"]],["bar_chart","parallel_coordinate",["nested"]],["box_plot","scatterplot",["accompanied"]],["scatterplot","box_plot",["accompanied"]],["comb","parallel_coordinate",["nested"]],["graph","map",["coordinated"]]],"visType":["bar_chart","parallel_coordinate","box_plot","scatterplot","comb","graph","map"],"compType":["repeated","nested","accompanied","coordinated"],"compressed_tree":[{"composite_pattern":"coordinated","visualization_type":[["graph"],["map"]]},{"composite_pattern":"repeated","visualization_type":[["bar_chart"]]},{"composite_pattern":"accompanied","visualization_type":[["box_plot","scatterplot"]]},{"composite_pattern":"nested","visualization_type":[["bar_chart",{"composite_pattern":"accompanied","visualization_type":[["box_plot","scatterplot"]]}],["parallel_coordinate"]]}],"coOccurrence":[["box_plot","scatterplot",["coOccurrence"]],["box_plot","bar_chart",["coOccurrence"]],["box_plot","parallel_coordinate",["coOccurrence"]],["scatterplot","bar_chart",["coOccurrence"]],["scatterplot","parallel_coordinate",["coOccurrence"]],["bar_chart","parallel_coordinate",["coOccurrence"]]],"year":2015,"conference":["VAST"],"authors":["Min Lu","Chufan Lai","Tangzhi Ye","Jie Liang","Xiaoru Yuan"],"title":"Visual analysis of route choice behaviour based on GPS trajectories","doi":"10.1109/VAST.2015.7347679","abstract":"There are often multiple routes between regions. Many factors potentially affect driver\'s route choice, such as expected time cost, length etc. In this work, we present a visual analysis system to explore driver\'s route choice behaviour based on taxi GPS trajectory data. With interactive trajectory filtering, the system constructs feasible routes between regions of interest. Using a rank-based visualization, the attributes of multiple routes are explored and compared. Based on a statistical model, the system supports to verify trajectory-related factors\' impact on route choice behaviour. The effectiveness of the system is demonstrated by applying to real trajectory dataset.","keywords":"","caption":"Figure 2: Case Study: (a) route spatial view shows three major routes travelling between selected regions; (b) trajectory-related factor view shows the route choices distribution over the three factors, integrated with MNL model analysis result; (c) a selected departure time range; (d) route-related view with selected three routes; (e) travel time cost distribution of the selected three routes during departure time range in (c).","img_size":{"width":1992,"height":858},"subfigures":[{"x":29.575031250947873,"y":18.60899883281405,"width":977.9323194064851,"height":463.473613918021,"type":"single","id":"single-0"},{"x":1123.2641723285635,"y":20.038755391850056,"width":847.9674507759256,"height":462.0606934656045,"type":"single","id":"single-1"},{"x":15.721046356334769,"y":523.4839246637288,"width":1604.6340678168199,"height":286.96113767245794,"type":"single","id":"single-2"}],"visualizations":[{"x":1133.5563689604685,"y":21.355783308931183,"width":677.1039531478772,"height":450.9838945827233,"type":"bar_chart","id":"bar_chart-0"},{"x":1028.0336749633966,"y":103.0102489019034,"width":249.98828696925338,"height":135.6720351390923,"type":"bar_chart","id":"bar_chart-1"},{"x":20.54319180087838,"y":531.3821376281111,"width":1576.5592972181557,"height":275.112737920937,"type":"bar_chart","id":"bar_chart-2"},{"x":1309.427525622255,"y":540.1756954612006,"width":286.4187408491948,"height":200.99560761347004,"type":"box_plot","id":"box_plot-4"},{"x":1690.0629575402638,"y":545.2005856515375,"width":262.55051244509514,"height":234.91361639824314,"type":"box_plot","id":"box_plot-3"},{"x":25.097553757916213,"y":13.997497496548643,"width":986.0943573881144,"height":468.9371605835489,"type":"graph","id":"graph-9"},{"x":20.54319180087838,"y":13.81844802342606,"width":992.415812591508,"height":468.5710102489019,"type":"map","id":"map-6"},{"x":23.055636896046742,"y":530.125915080527,"width":1569.0219619326508,"height":271.3440702781846,"type":"parallel_coordinate","id":"parallel_coordinate-7"},{"x":1307.9611240707338,"y":541.8265342904622,"width":283.9438283717454,"height":197.06452948310258,"type":"scatterplot","id":"scatterplot-12"},{"x":1692.5754026354327,"y":543.9443631039533,"width":262.55051244509514,"height":184.66471449487562,"type":"scatterplot","id":"scatterplot-5"}],"relations":[{"vislist":[{"vislist":["graph-9"],"relation":null,"id":"group-4"},{"vislist":["map-6"],"relation":null,"id":"group-3"}],"relation":"coordinated","id":"relation-1"},{"vislist":[{"vislist":["bar_chart-0"],"relation":null,"id":"group-9"}],"relation":"repeated","id":"relation-5"},{"vislist":[{"vislist":["box_plot-3","scatterplot-5"],"relation":null,"id":"group-11"}],"relation":"accompanied","id":"relation-7"},{"vislist":[{"vislist":["bar_chart-2",{"vislist":[{"vislist":["box_plot-4","scatterplot-12"],"relation":null,"id":"group-10"}],"relation":"accompanied","id":"relation-6"}],"relation":null,"id":"group-12"},{"vislist":["parallel_coordinate-7"],"relation":null,"id":"group-13"}],"relation":"nested","id":"relation-8"}]},"2622_0":{"comp":[["proportional_area_chart","proportional_area_chart",["repeated"]]],"visType":["proportional_area_chart"],"compType":["repeated"],"compressed_tree":[{"composite_pattern":"repeated","visualization_type":[["proportional_area_chart"]]}],"coOccurrence":[["proportional_area_chart","proportional_area_chart",["coOccurrence"]]],"year":2015,"conference":["InfoVis"],"authors":["Nina McCurdy","Julie Lein","Katherine Coles","Miriah D. Meyer"],"title":"Poemage: Visualizing the Sonic Topology of a Poem","doi":"10.1109/TVCG.2015.2467811","abstract":"The digital humanities have experienced tremendous growth within the last decade, mostly in the context of developing computational tools that support what is called distant reading - collecting and analyzing huge amounts of textual data for synoptic evaluation. On the other end of the spectrum is a practice at the heart of the traditional humanities, close reading - the careful, in-depth analysis of a single text in order to extract, engage, and even generate as much productive meaning as possible. The true value of computation to close reading is still very much an open question. During a two-year design study, we explored this question with several poetry scholars, focusing on an investigation of sound and linguistic devices in poetry. The contributions of our design study include a problem characterization and data abstraction of the use of sound in poetry as well as Poemage, a visualization tool for interactively exploring the sonic topology of a poem. The design of Poemage is grounded in the evaluation of a series of technology probes we deployed to our poetry collaborators, and we validate the final design with several case studies that illustrate the disruptive impact technology can have on poetry scholarship. Finally, we also contribute a reflection on the challenges we faced conducting visualization research in literary studies.","keywords":"Visualization in the humanities, design studies, text and document data, graph/network data","caption":"Fig. 1. The Poemage interface comprises three linked views: (left) the set view allows users to browse sets of words linked through sonic and linguistic resemblances; (middle) the poem view allows users to explore sonically linked words directly via the text; (right) the path view shows the sonic topology of a poem.","img_size":{"width":1619,"height":927},"subfigures":[{"x":38.01448385214298,"y":31.89043089108129,"width":1531.579130476388,"height":854.3557832042405,"type":"interface","id":"interface-0"}],"visualizations":[{"x":61.41005410393915,"y":121.57298004053396,"width":477.90463031214324,"height":712.5351013707892,"type":"proportional_area_chart","id":"proportional_area_chart-0"}],"relations":[{"vislist":[{"vislist":["proportional_area_chart-0"],"relation":null,"id":"group-0"}],"relation":"repeated","id":"relation-0"}]},"2745_1":{"comp":[["bar_chart","bar_chart",["repeated"]]],"visType":["bar_chart"],"compType":["repeated"],"compressed_tree":[{"composite_pattern":"repeated","visualization_type":[["bar_chart"]]},{"composite_pattern":"repeated","visualization_type":[["bar_chart"]]}],"coOccurrence":[["bar_chart","bar_chart",["coOccurrence"]]],"year":2015,"conference":["VAST"],"authors":["Khairi Reda","Alberto Gonzalez","Jason Leigh","Michael E. Papka"],"title":"Tell me what do you see: Detecting perceptually-separable visual patterns via clustering of image-space features in visualizations","doi":"10.1109/VAST.2015.7347683","abstract":"Visualization helps users infer structures and relationships in the data by encoding information as visual features that can be processed by the human visual-perceptual system. However, users would typically need to expend significant effort to scan and analyze a large number of views before they can begin to recognize relationships in a visualization. We propose a technique to partially automate the process of analyzing visualizations. By deriving and analyzing image-space features from visualizations, we can detect perceptually-separable patterns in the information space. We summarize these patterns with a tree-based meta-visualization and present it to the user to aid exploration. We illustrate this technique with an example scenario involving the analysis of census data.","keywords":"","caption":"Figure 2: A tool for exploring demographic patterns in the US census.","img_size":{"width":1005,"height":762},"subfigures":[{"x":10.332232931099393,"y":7.738226495940768,"width":988.4969711009497,"height":745.4827276953785,"type":"interface","id":"interface-0"}],"visualizations":[{"x":756.7778993435448,"y":6.669584245076588,"width":230.10065645514237,"height":326.8096280087528,"type":"bar_chart","id":"bar_chart-0"},{"x":744.8316774838174,"y":354.16181394070423,"width":254.27050667346998,"height":128.5478672626988,"type":"bar_chart","id":"bar_chart-1"},{"x":2.4975149105367795,"y":481.87746170678344,"width":300.1312910284465,"height":275.12035010940923,"type":"heatmap","id":"heatmap-2"},{"x":331.59190371991247,"y":478.54266958424523,"width":405.1772428884025,"height":255.11159737417944,"type":"heatmap","id":"heatmap-3"},{"x":331.5919037199124,"y":476.875273522976,"width":408.5120350109409,"height":253.44420131291025,"type":"map","id":"map-4"},{"x":19.788840262582024,"y":71.69803063457331,"width":718.6477024070022,"height":290.1269146608315,"type":"tree","id":"tree-5"}],"relations":[{"vislist":[{"vislist":["bar_chart-0"],"relation":null,"id":"group-0"}],"relation":"repeated","id":"relation-0"},{"vislist":[{"vislist":["bar_chart-1"],"relation":null,"id":"group-1"}],"relation":"repeated","id":"relation-1"}]},"2758_0":{"comp":[["line_chart","line_chart",["repeated"]],["line_chart","area_chart",["stacked"]],["line_chart","comb",["stacked"]],["matrix","matrix",["repeated"]],["scivis","scivis",["repeated"]],["area_chart","area_chart",["repeated"]],["area_chart","line_chart",["stacked"]],["scatterplot","matrix",["nested"]],["comb","line_chart",["stacked"]]],"visType":["line_chart","area_chart","comb","matrix","scivis","scatterplot"],"compType":["repeated","stacked","nested"],"compressed_tree":[{"composite_pattern":"nested","visualization_type":[["scatterplot"],["matrix"]]},{"composite_pattern":"repeated","visualization_type":[["line_chart"]]},{"composite_pattern":"repeated","visualization_type":[["matrix"]]},{"composite_pattern":"stacked","visualization_type":[["line_chart","area_chart"]]},{"composite_pattern":"repeated","visualization_type":[["scivis"]]},{"composite_pattern":"repeated","visualization_type":[["scivis"]]},{"composite_pattern":"stacked","visualization_type":[["line_chart",{"composite_pattern":"repeated","visualization_type":[["area_chart"]]}]]}],"coOccurrence":[["area_chart","scatterplot",["coOccurrence"]],["area_chart","matrix",["coOccurrence"]],["area_chart","line_chart",["coOccurrence"]],["area_chart","scivis",["coOccurrence"]],["scatterplot","matrix",["coOccurrence"]],["scatterplot","line_chart",["coOccurrence"]],["scatterplot","scivis",["coOccurrence"]],["matrix","line_chart",["coOccurrence"]],["matrix","scivis",["coOccurrence"]],["line_chart","scivis",["coOccurrence"]]],"year":2016,"conference":["InfoVis"],"authors":["Kasper Dinkla","Hendrik Strobelt","Bryan Genest","Stephan Reiling","Mark Borowsky","Hanspeter Pfister"],"title":"Screenit: Visual Analysis of Cellular Screens","doi":"10.1109/TVCG.2016.2598587","abstract":"High-throughput and high-content screening enables large scale, cost-effective experiments in which cell cultures are exposed to a wide spectrum of drugs. The resulting multivariate data sets have a large but shallow hierarchical structure. The deepest level of this structure describes cells in terms of numeric features that are derived from image data. The subsequent level describes enveloping cell cultures in terms of imposed experiment conditions (exposure to drugs). We present Screenit, a visual analysis approach designed in close collaboration with screening experts. Screenit enables the navigation and analysis of multivariate data at multiple hierarchy levels and at multiple levels of detail. Screenit integrates the interactive modeling of cell physical states (phenotypes) and the effects of drugs on cell cultures (hits). In addition, quality control is enabled via the detection of anomalies that indicate low-quality data, while providing an interface that is designed to match workflows of screening experts. We demonstrate analyses for a real-world data set, CellMorph, with 6 million cells across 20,000 cell cultures.","keywords":"High-content screening;visual analysis;feature selection;image classification;biology;multivariate;hierarchy","caption":"Fig. 1. An overview of Screenit with all columns opened: (a) The screens column shows the available screen data sets; (b) The plates column shows an overview of all plates in the selected CellMorph screen, where well score is shown with a color map that has dark colors for high scores and bright colors for low scores; (c) The wells column shows a hit list of top scoring wells at the left, and conditions and images of the selected well at the right; (d) The phenotypes column shows the cell phenotypes that are being modeled; (e) The features column depicts all cell image features as a list and provides information about feature value distributions.","img_size":{"width":1899,"height":687},"subfigures":[{"x":10.563579529673614,"y":8.931056891983484,"width":1882.0107301263859,"height":590.541870493719,"type":"interface","id":"interface-0"}],"visualizations":[{"x":385.5929456625357,"y":83.72259294566256,"width":181.02955195424212,"height":463.4356530028598,"type":"area_chart","id":"area_chart-0"},{"x":1375.8245948522401,"y":29.413727359389917,"width":128.5309818875119,"height":579.2945662535748,"type":"area_chart","id":"area_chart-1"},{"x":402.51228191548404,"y":27.96435851486737,"width":318.29064559819193,"height":57.93605009764841,"type":"line_chart","id":"line_chart-4"},{"x":383.38680907332633,"y":83.72259294566268,"width":214.20983494078715,"height":461.62535748331777,"type":"line_chart","id":"line_chart-5"},{"x":1507.976167778837,"y":34.844613918017174,"width":77.84270734032407,"height":561.1916110581507,"type":"line_chart","id":"line_chart-6"},{"x":1582.1982840800756,"y":5.836399269960769,"width":309.56053384175397,"height":329.65934721852267,"type":"matrix","id":"matrix-13"},{"x":152.06482364156338,"y":4.187024853156474,"width":220.8560533841753,"height":537.6577693040991,"type":"matrix","id":"matrix-8"},{"x":1585.8188751191608,"y":4.187024853156474,"width":304.1296472831268,"height":331.2840800762631,"type":"scatterplot","id":"scatterplot-9"},{"x":1183.9332697807436,"y":4.187024853156474,"width":177.40896091515742,"height":383.78265014299325,"type":"scivis","id":"scivis-10"},{"x":613.6901811248807,"y":85.53288846520498,"width":550.3298379408959,"height":416.3679694947569,"type":"scivis","id":"scivis-11"}],"relations":[{"vislist":[{"vislist":["scatterplot-9"],"relation":null,"id":"group-2"},{"vislist":["matrix-13"],"relation":null,"id":"group-3"}],"relation":"nested","id":"relation-1"},{"vislist":[{"vislist":["line_chart-4"],"relation":null,"id":"group-6"}],"relation":"repeated","id":"relation-4"},{"vislist":[{"vislist":["matrix-8"],"relation":null,"id":"group-7"}],"relation":"repeated","id":"relation-5"},{"vislist":[{"vislist":["line_chart-5","area_chart-0"],"relation":null,"id":"group-11"}],"relation":"stacked","id":"relation-6"},{"vislist":[{"vislist":["scivis-11"],"relation":null,"id":"group-10"}],"relation":"repeated","id":"relation-8"},{"vislist":[{"vislist":["scivis-10"],"relation":null,"id":"group-12"}],"relation":"repeated","id":"relation-9"},{"vislist":[{"vislist":["line_chart-6",{"vislist":[{"vislist":["area_chart-1"],"relation":null,"id":"group-1"}],"relation":"repeated","id":"relation-0"}],"relation":null,"id":"group-13"}],"relation":"stacked","id":"relation-10"}]},"2759_2":{"comp":[["bar_chart","bar_chart",["repeated"]],["pie_chart","pie_chart",["repeated"]]],"visType":["bar_chart","pie_chart"],"compType":["repeated"],"compressed_tree":[{"composite_pattern":"repeated","visualization_type":[["bar_chart"]]},{"composite_pattern":"repeated","visualization_type":[["pie_chart"]]}],"coOccurrence":[["bar_chart","pie_chart",["coOccurrence"]]],"year":2016,"conference":["InfoVis"],"authors":["Anzu Hakone","Lane Harrison","Alvitta Ottley","Nathan Winters","Caitlin Gutheil","Paul K. J. Han","Remco Chang"],"title":"PROACT: Iterative Design of a Patient-Centered Visualization for Effective Prostate Cancer Health Risk Communication","doi":"10.1109/TVCG.2016.2598588","abstract":"Prostate cancer is the most common cancer among men in the US, and yet most cases represent localized cancer for which the optimal treatment is unclear. Accumulating evidence suggests that the available treatment options, including surgery and conservative treatment, result in a similar prognosis for most men with localized prostate cancer. However, approximately 90% of patients choose surgery over conservative treatment, despite the risk of severe side effects like erectile dysfunction and incontinence. Recent medical research suggests that a key reason is the lack of patient-centered tools that can effectively communicate personalized risk information and enable them to make better health decisions. In this paper, we report the iterative design process and results of developing the PROgnosis Assessment for Conservative Treatment (PROACT) tool, a personalized health risk communication tool for localized prostate cancer patients. PROACT utilizes two published clinical prediction models to communicate the patients\' personalized risk estimates and compare treatment options. In collaboration with the Maine Medical Center, we conducted two rounds of evaluations with prostate cancer survivors and urologists to identify the design elements and narrative structure that effectively facilitate patient comprehension under emotional distress. Our results indicate that visualization can be an effective means to communicate complex risk information to patients with low numeracy and visual literacy. However, the visualizations need to be carefully chosen to balance readability with ease of comprehension. In addition, due to patients\' charged emotional state, an intuitive narrative structure that considers the patients\' information need is critical to aid the patients\' comprehension of their risk information.","keywords":"Design studies;task and requirement analysis;presentation;production;and dissemination;medical visualization","caption":"Fig. 3. Page 9. This is a summary page in the revised prototype showing all the information in the tool in a condensed form. The purpose is for the page to be printed and given to the patient to take home.","img_size":{"width":1012,"height":864},"subfigures":[{"x":7.771408638509211,"y":11.082208342677573,"width":992.6041403081954,"height":844.7271895650491,"type":"interface","id":"interface-0"}],"visualizations":[{"x":124.60029282576876,"y":647.683748169839,"width":161.92093704245974,"height":201.13616398243047,"type":"bar_chart","id":"bar_chart-0"},{"x":458.562225475842,"y":646.4187408491947,"width":163.18594436310403,"height":202.4011713030748,"type":"bar_chart","id":"bar_chart-1"},{"x":793.7891654465594,"y":648.9487554904832,"width":161.92093704245963,"height":197.34114202049776,"type":"bar_chart","id":"bar_chart-2"},{"x":56.28989751098106,"y":191.01610541727672,"width":213.78623718887263,"height":201.13616398243042,"type":"pie_chart","id":"pie_chart-3"},{"x":370.0117130307469,"y":191.01610541727672,"width":250.47144948755502,"height":189.7510980966325,"type":"pie_chart","id":"pie_chart-4"},{"x":702.7086383601758,"y":197.3411420204978,"width":255.5314787701318,"height":207.46120058565154,"type":"pie_chart","id":"pie_chart-5"}],"relations":[{"vislist":[{"vislist":["bar_chart-0","bar_chart-1","bar_chart-2"],"relation":null,"id":"group-0"}],"relation":"repeated","id":"relation-0"},{"vislist":[{"vislist":["pie_chart-3","pie_chart-4","pie_chart-5"],"relation":null,"id":"group-1"}],"relation":"repeated","id":"relation-1"}]},"2763_3":{"comp":[["bar_chart","bar_chart",["repeated"]],["bar_chart","table",["nested"]]],"visType":["bar_chart","table"],"compType":["repeated","nested"],"compressed_tree":[{"composite_pattern":"repeated","visualization_type":[["bar_chart"]]},{"composite_pattern":"nested","visualization_type":[["bar_chart"],["table"]]}],"coOccurrence":[["bar_chart","table",["coOccurrence"]]],"year":2016,"conference":["InfoVis"],"authors":["Clemens Arbesser","Florian Spechtenhauser","Thomas M\xfchlbacher","Harald Piringer"],"title":"Visplause: Visual Data Quality Assessment of Many Time Series Using Plausibility Checks","doi":"10.1109/TVCG.2016.2598592","abstract":"Trends like decentralized energy production lead to an exploding number of time series from sensors and other sources that need to be assessed regarding their data quality (DQ). While the identification of DQ problems for such routinely collected data is typically based on existing automated plausibility checks, an efficient inspection and validation of check results for hundreds or thousands of time series is challenging. The main contribution of this paper is the validated design of Visplause, a system to support an efficient inspection of DQ problems for many time series. The key idea of Visplause is to utilize meta-information concerning the semantics of both the time series and the plausibility checks for structuring and summarizing results of DQ checks in a flexible way. Linked views enable users to inspect anomalies in detail and to generate hypotheses about possible causes. The design of Visplause was guided by goals derived from a comprehensive task analysis with domain experts in the energy sector. We reflect on the design process by discussing design decisions at four stages and we identify lessons learned. We also report feedback from domain experts after using Visplause for a period of one month. This feedback suggests significant efficiency gains for DQ assessment, increased confidence in the DQ, and the applicability of Visplause to summarize indicators also outside the context of DQ.","keywords":"Data Quality Assessment;High-Dimensional Data;Hierarchical Aggregation;Linked Views","caption":"Fig. 4. Visplause as used for hypothesis generation regarding miss- ing data of power plant production (a). Five power plants have missing values. Ranking meteorological quantities by their relevance for the se- lected missing values of PV 02 suggests air humidity as possible cause (b). Adding air humidity as column to the DQ Overview (c) shows a re- lationship between high air humidity and missing values of power plants.","img_size":{"width":1038,"height":495},"subfigures":[{"x":14.765441457798577,"y":51.263134060576725,"width":1011.4848298980165,"height":429.43510978588324,"type":"interface","id":"interface-0"}],"visualizations":[{"x":222.21742313323574,"y":118.85797950219619,"width":147.84773060029283,"height":364.54612005856524,"type":"bar_chart","id":"bar_chart-0"},{"x":153.36676427525623,"y":118.13323572474377,"width":68.85065885797951,"height":368.1698389458273,"type":"bar_chart","id":"bar_chart-1"},{"x":576.617130307467,"y":406.5812591508053,"width":82.62079062957537,"height":73.92386530014636,"type":"bar_chart","id":"bar_chart-2"},{"x":576.617130307467,"y":331.93265007320645,"width":82.62079062957537,"height":70.30014641288435,"type":"bar_chart","id":"bar_chart-3"},{"x":577.3418740849195,"y":266.70571010248904,"width":80.44655929721819,"height":67.40117130307465,"type":"bar_chart","id":"bar_chart-4"},{"x":580.2408491947291,"y":192.7818448023426,"width":75.37335285505127,"height":70.30014641288436,"type":"bar_chart","id":"bar_chart-5"},{"x":370.04739236732564,"y":120.37911435169562,"width":188.03558752014263,"height":357.5528926807141,"type":"bar_chart","id":"bar_chart-8"},{"x":824.4795021961933,"y":78.27232796486093,"width":204.37774524158147,"height":402.9575402635432,"type":"table","id":"table-6"},{"x":17.35568769575339,"y":121.32660439260958,"width":541.8361880786257,"height":360.2292011557055,"type":"table","id":"table-9"}],"relations":[{"vislist":[{"vislist":["bar_chart-3","bar_chart-4","bar_chart-5","bar_chart-2"],"relation":null,"id":"group-0"}],"relation":"repeated","id":"relation-0"},{"vislist":[{"vislist":["bar_chart-1","bar_chart-8","bar_chart-0"],"relation":null,"id":"group-2"},{"vislist":["table-9"],"relation":null,"id":"group-3"}],"relation":"nested","id":"relation-2"}]},"2771_1":{"comp":[["line_chart","line_chart",["repeated"]],["donut_chart","donut_chart",["repeated"]],["map","map",["repeated"]],["unit_visualization","unit_visualization",["repeated"]]],"visType":["line_chart","donut_chart","map","unit_visualization"],"compType":["repeated"],"compressed_tree":[{"composite_pattern":"repeated","visualization_type":[["line_chart"]]},{"composite_pattern":"repeated","visualization_type":[["donut_chart"]]},{"composite_pattern":"repeated","visualization_type":[["map"]]},{"composite_pattern":"repeated","visualization_type":[["unit_visualization"]]},{"composite_pattern":"repeated","visualization_type":[["unit_visualization"]]},{"composite_pattern":"repeated","visualization_type":[["unit_visualization"]]}],"coOccurrence":[["line_chart","donut_chart",["coOccurrence"]],["line_chart","map",["coOccurrence"]],["line_chart","unit_visualization",["coOccurrence"]],["donut_chart","map",["coOccurrence"]],["donut_chart","unit_visualization",["coOccurrence"]],["map","unit_visualization",["coOccurrence"]]],"year":2016,"conference":["InfoVis"],"authors":["Fereshteh Amini","Nathalie Henry Riche","Bongshin Lee","Andr\xe9s Monroy-Hern\xe1ndez","Pourang Irani"],"title":"Authoring Data-Driven Videos with DataClips","doi":"10.1109/TVCG.2016.2598647","abstract":"Data videos, or short data-driven motion graphics, are an increasingly popular medium for storytelling. However, creating data videos is difficult as it involves pulling together a unique combination of skills. We introduce DataClips, an authoring tool aimed at lowering the barriers to crafting data videos. DataClips allows non-experts to assemble data-driven \u201cclips\u201d together to form longer sequences. We constructed the library of data clips by analyzing the composition of over 70 data videos produced by reputable sources such as The New York Times and The Guardian. We demonstrate that DataClips can reproduce over 90% of our data videos corpus. We also report on a qualitative study comparing the authoring process and outcome achieved by (1) non-experts using DataClips, and (2) experts using Adobe Illustrator and After Effects to create data-driven clips. Results indicated that non-experts are able to learn and use DataClips with a short training period. In the span of one hour, they were able to produce more videos than experts using a professional editing tool, and their clips were rated similarly by an independent audience.","keywords":"data video;narrative visualization;data storytelling;authoring tools;visualization systems","caption":"Fig. 2. Annotated screenshot of DataClips tool interface: a) saved clip sequences, b) clip preview and sequencing panel, c) the clip library panel, d) clip configuration panel, e) import new data, f) clear all clips in preview/sequencing panel, g) category of clips for filling pictographs, h) data configuration options and corresponding input boxes, and i) helper images including numbered items corresponding to the input boxes, j) visual and animation configuration options and corresponding input fields.","img_size":{"width":2016,"height":996},"subfigures":[{"x":44.74773515628245,"y":12.440406253096052,"width":1954.325787782986,"height":966.728325929597,"type":"interface","id":"interface-0"}],"visualizations":[{"x":237.48612561810896,"y":609.2372147403086,"width":105.45835900333049,"height":90.24801876246545,"type":"bar_chart","id":"bar_chart-0"},{"x":122.90156247025946,"y":609.2372147403086,"width":103.43031363788182,"height":91.26204144518977,"type":"bar_chart","id":"bar_chart-1"},{"x":1820.9407114624503,"y":190.93279693814603,"width":167.31225296442676,"height":238.17391304347822,"type":"donut_chart","id":"donut_chart-2"},{"x":350.17894741868145,"y":348.0409843425161,"width":109.19983130287234,"height":85.9658246426867,"type":"donut_chart","id":"donut_chart-3"},{"x":229.3621127857164,"y":345.7175836764976,"width":111.52323196889097,"height":92.9360266407424,"type":"donut_chart","id":"donut_chart-4"},{"x":129.45588414691838,"y":345.7175836764976,"width":99.90622863879798,"height":97.58282797277946,"type":"donut_chart","id":"donut_chart-5"},{"x":120.16228148284428,"y":124.99452040473449,"width":106.87643063685368,"height":83.64242397666811,"type":"line_chart","id":"line_chart-6"},{"x":236.3323147837721,"y":129.6413217367716,"width":111.52323196889097,"height":78.995622644631,"type":"line_chart","id":"line_chart-7"},{"x":350.17894741868145,"y":129.6413217367716,"width":113.84663263490962,"height":78.995622644631,"type":"line_chart","id":"line_chart-8"},{"x":122.4856821488627,"y":222.577348377514,"width":104.55302997083527,"height":88.28922530870523,"type":"line_chart","id":"line_chart-9"},{"x":523.9535390456381,"y":160.65409250720677,"width":500.5428579335092,"height":294.21221420519237,"type":"line_chart","id":"line_chart-10"},{"x":354.4980237154151,"y":480.2845755942726,"width":104.32411067193677,"height":90.54545454545456,"type":"map","id":"map-11"},{"x":238.36363636363643,"y":482.25295504091287,"width":100.38735177865615,"height":88.57707509881423,"type":"map","id":"map-12"},{"x":122.22924901185777,"y":486.1897139341935,"width":98.4189723320158,"height":74.798418972332,"type":"map","id":"map-13"},{"x":121.88753978753513,"y":610.2512374230329,"width":104.44433632060613,"height":89.23399607974113,"type":"unit_visualization","id":"unit_visualization-14"},{"x":239.51417098355762,"y":609.2372147403086,"width":103.4303136378818,"height":89.23399607974113,"type":"unit_visualization","id":"unit_visualization-15"},{"x":141.1539707592974,"y":762.3546398316826,"width":70.98158779070326,"height":54.75722486711402,"type":"unit_visualization","id":"unit_visualization-16"},{"x":253.71048854169823,"y":768.4387759280286,"width":70.98158779070326,"height":48.673088770768,"type":"unit_visualization","id":"unit_visualization-17"},{"x":393.6456187576561,"y":771.4808439762016,"width":24.33654438538394,"height":43.6029753571463,"type":"unit_visualization","id":"unit_visualization-18"},{"x":123.9155851529838,"y":895.1916112685701,"width":98.36020022426017,"height":33.46274852990291,"type":"unit_visualization","id":"unit_visualization-19"},{"x":237.48612561810896,"y":882.0093163931538,"width":102.41629095515755,"height":59.8273382807356,"type":"unit_visualization","id":"unit_visualization-20"},{"x":356.1267794968558,"y":901.2757473649159,"width":96.33215485881146,"height":27.37861243355701,"type":"unit_visualization","id":"unit_visualization-21"},{"x":266.5365234420135,"y":238.8411530396439,"width":53.43821531842673,"height":48.79141398638967,"type":"unit_visualization","id":"unit_visualization-22"},{"x":829.6285667912923,"y":554.2106907297368,"width":187.22595449421348,"height":141.37470033236514,"type":"unit_visualization","id":"unit_visualization-23"},{"x":1055.0638997537123,"y":160.65409250720677,"width":466.15441731212326,"height":298.03315205201307,"type":"unit_visualization","id":"unit_visualization-24"}],"relations":[{"vislist":[{"vislist":["line_chart-9","line_chart-8","line_chart-7","line_chart-6"],"relation":null,"id":"group-0"}],"relation":"repeated","id":"relation-0"},{"vislist":[{"vislist":["donut_chart-5","donut_chart-4","donut_chart-3"],"relation":null,"id":"group-1"}],"relation":"repeated","id":"relation-1"},{"vislist":[{"vislist":["map-13","map-12","map-11"],"relation":null,"id":"group-2"}],"relation":"repeated","id":"relation-2"},{"vislist":[{"vislist":["unit_visualization-14","unit_visualization-15"],"relation":null,"id":"group-3"}],"relation":"repeated","id":"relation-3"},{"vislist":[{"vislist":["unit_visualization-16","unit_visualization-17","unit_visualization-18"],"relation":null,"id":"group-4"}],"relation":"repeated","id":"relation-4"},{"vislist":[{"vislist":["unit_visualization-19","unit_visualization-20","unit_visualization-21"],"relation":null,"id":"group-5"}],"relation":"repeated","id":"relation-5"}]},"2774_2":{"comp":[["bar_chart","bar_chart",["repeated"]]],"visType":["bar_chart"],"compType":["repeated"],"compressed_tree":[{"composite_pattern":"repeated","visualization_type":[["bar_chart"]]}],"coOccurrence":[["bar_chart","bar_chart",["coOccurrence"]]],"year":2016,"conference":["InfoVis"],"authors":["Bahador Saket","Hannah Kim","Eli T. Brown","Alex Endert"],"title":"Visualization by Demonstration: An Interaction Paradigm for Visual Data Exploration","doi":"10.1109/TVCG.2016.2598839","abstract":"Although data visualization tools continue to improve, during the data exploration process many of them require users to manually specify visualization techniques, mappings, and parameters. In response, we present the Visualization by Demonstration paradigm, a novel interaction method for visual data exploration. A system which adopts this paradigm allows users to provide visual demonstrations of incremental changes to the visual representation. The system then recommends potential transformations (Visual Representation, Data Mapping, Axes, and View Specification transformations) from the given demonstrations. The user and the system continue to collaborate, incrementally producing more demonstrations and refining the transformations, until the most effective possible visualization is created. As a proof of concept, we present VisExemplar, a mixed-initiative prototype that allows users to explore their data by recommending appropriate transformations in response to the given demonstrations.","keywords":"Visual Data Exploration;Visualization by Demonstration;Visualization Tools","caption":"Figure 3: The VisExemplar user interface consists of a ThinkBoard, Recommendation Gallery, and a Detail View panel. ThinkBoard shows each data point as a circle. The Recommendation Gallery shows visualization technique transformations. The Detail View shows data details, and also recommended data mapping transformations.","img_size":{"width":2151,"height":1111},"subfigures":[{"x":18.145894691808728,"y":11.309443640522732,"width":2110.021217652448,"height":1086.8192739236626,"type":"interface","id":"interface-0"}],"visualizations":[{"x":15.194582991355846,"y":826.4621085176266,"width":347.9764670884675,"height":253.0737942461582,"type":"bar_chart","id":"bar_chart-0"},{"x":371.7985657927604,"y":829.3379470886056,"width":330.72143566259297,"height":253.07379424615797,"type":"bar_chart","id":"bar_chart-1"},{"x":705.3958400263325,"y":826.4621085176266,"width":336.4731128045512,"height":247.32211710419995,"type":"bar_chart","id":"bar_chart-2"},{"x":1053.3723071148,"y":832.2137856595845,"width":324.9697585206348,"height":247.32211710420006,"type":"bar_chart","id":"bar_chart-3"},{"x":12.318744420376788,"y":26.97898578544519,"width":1754.2615282972322,"height":756.3455441674953,"type":"scatterplot","id":"scatterplot-4"}],"relations":[{"vislist":[{"vislist":["bar_chart-0","bar_chart-1","bar_chart-2","bar_chart-3"],"relation":null,"id":"group-0"}],"relation":"repeated","id":"relation-0"}]},"2776_4":{"comp":[["graph","graph",["repeated"]]],"visType":["graph"],"compType":["repeated"],"compressed_tree":[{"composite_pattern":"repeated","visualization_type":[["graph"]]}],"coOccurrence":[["graph","graph",["coOccurrence"]]],"year":2016,"conference":["InfoVis"],"authors":["Yanhong Wu","Nan Cao","Daniel W. Archambault","Qiaomu Shen","Huamin Qu","Weiwei Cui"],"title":"Evaluation of Graph Sampling: A Visualization Perspective","doi":"10.1109/TVCG.2016.2598867","abstract":"Graph sampling is frequently used to address scalability issues when analyzing large graphs. Many algorithms have been proposed to sample graphs, and the performance of these algorithms has been quantified through metrics based on graph structural properties preserved by the sampling: degree distribution, clustering coefficient, and others. However, a perspective that is missing is the impact of these sampling strategies on the resultant visualizations. In this paper, we present the results of three user studies that investigate how sampling strategies influence node-link visualizations of graphs. In particular, five sampling strategies widely used in the graph mining literature are tested to determine how well they preserve visual features in node-link diagrams. Our results show that depending on the sampling strategy used different visual features are preserved. These results provide a complimentary view to metric evaluations conducted in the graph mining literature and provide an impetus to conduct future visualization studies.","keywords":"Graph visualization;graph sampling;empirical evaluation","caption":"Figure 2.Pilot study interface. Original unsampled PG is visualized(top-left) with sampled versions at the following rates: 5%, 10%, 20%,30%, and 40%. In this figure, PG is sampled with Random Walk","img_size":{"width":1059,"height":525},"subfigures":[{"x":8.178402734238311,"y":8.408071752406634,"width":1043.4123756176552,"height":510.4925750730064,"type":"interface","id":"interface-0"}],"visualizations":[{"x":20.06324110671936,"y":40.46442687747036,"width":246.93675889328063,"height":219.9604743083004,"type":"graph","id":"graph-0"},{"x":400.8438735177865,"y":56.02766798418973,"width":53.952569169960505,"height":57.06521739130435,"type":"graph","id":"graph-1"},{"x":22.13833992094861,"y":292.5889328063241,"width":239.67391304347825,"height":176.38339920948616,"type":"graph","id":"graph-2"},{"x":308.501976284585,"y":292.5889328063241,"width":242.78656126482213,"height":178.45849802371538,"type":"graph","id":"graph-3"},{"x":600.0533596837944,"y":41.501976284584984,"width":145.2569169960475,"height":158.74505928853756,"type":"graph","id":"graph-4"},{"x":599.0158102766798,"y":292.5889328063241,"width":233.44861660079061,"height":187.79644268774703,"type":"graph","id":"graph-5"},{"x":882.2667984189723,"y":68.47826086956522,"width":159.78260869565224,"height":33.201581027667984,"type":"table","id":"table-6"}],"relations":[{"vislist":[{"vislist":["graph-1","graph-2","graph-3","graph-4","graph-5","graph-0"],"relation":null,"id":"group-2"}],"relation":"repeated","id":"relation-0"}]},"2777_6":{"comp":[["map","map",["repeated"]]],"visType":["map"],"compType":["repeated"],"compressed_tree":[{"composite_pattern":"repeated","visualization_type":[["map"]]}],"coOccurrence":[],"year":2016,"conference":["InfoVis"],"authors":["Chris Bryan","Kwan-Liu Ma","Jonathan Woodring"],"title":"Temporal Summary Images: An Approach to Narrative Visualization via Interactive Annotation Generation and Placement","doi":"10.1109/TVCG.2016.2598876","abstract":"Visualization is a powerful technique for analysis and communication of complex, multidimensional, and time-varying data. However, it can be difficult to manually synthesize a coherent narrative in a chart or graph due to the quantity of visualized attributes, a variety of salient features, and the awareness required to interpret points of interest (POls). We present Temporal Summary Images (TSIs) as an approach for both exploring this data and creating stories from it. As a visualization, a TSI is composed of three common components: (1) a temporal layout, (2) comic strip-style data snapshots, and (3) textual annotations. To augment user analysis and exploration, we have developed a number of interactive techniques that recommend relevant data features and design choices, including an automatic annotations workflow. As the analysis and visual design processes converge, the resultant image becomes appropriate for data storytelling. For validation, we use a prototype implementation for TSIs to conduct two case studies with large-scale, scientific simulation datasets.","keywords":"Narrative visualization;storytelling;annotations;comic strip visualization;time-varying data","caption":"Fig. 8: Our TSI implementation\u2019s interface (viewer window and Helper panel) showing EpiSimS data with a streamgraph. The Helper panel\u2019s currently selected tab is used for interacting with annotations.","img_size":{"width":977,"height":418},"subfigures":[{"x":7.29844624399252,"y":13.013847093079853,"width":637.39613500305,"height":374.2356905067051,"type":"interface","id":"interface-0"},{"x":676.0356030701877,"y":8.826703455751424,"width":272.10425003467776,"height":383.3194423936469,"type":"interface","id":"interface-1"}],"visualizations":[{"x":2.154146014499145,"y":111.38506588579791,"width":647.3155197657394,"height":277.2386530014641,"type":"area_chart","id":"area_chart-0"},{"x":255.01976573938504,"y":11.016105417276718,"width":123.01317715959004,"height":91.800878477306,"type":"heatmap","id":"heatmap-1"},{"x":129.5585651537335,"y":11.016105417276718,"width":121.17715959004396,"height":96.08491947291361,"type":"heatmap","id":"heatmap-2"},{"x":517.5702781844802,"y":11.016105417276718,"width":115.6691068814056,"height":91.800878477306,"type":"heatmap","id":"heatmap-3"},{"x":391.4970717423134,"y":10.404099560761347,"width":122.40117130307468,"height":92.41288433382135,"type":"heatmap","id":"heatmap-4"},{"x":5.933382137628101,"y":9.792093704245971,"width":123.6251830161054,"height":94.86090775988286,"type":"heatmap","id":"heatmap-5"},{"x":8.381405563689594,"y":11.628111273792094,"width":118.72913616398243,"height":95.47291361639824,"type":"map","id":"map-6"},{"x":128.94655929721813,"y":9.792093704245971,"width":122.4011713030747,"height":99.14494875549047,"type":"map","id":"map-7"},{"x":251.95973645680814,"y":9.792093704245971,"width":127.90922401171304,"height":94.86090775988286,"type":"map","id":"map-8"},{"x":390.2730600292826,"y":9.180087847730599,"width":124.23718887262072,"height":96.08491947291361,"type":"map","id":"map-9"},{"x":516.3462664714494,"y":12.240117130307464,"width":115.05710102489026,"height":89.96486090775987,"type":"map","id":"map-10"},{"x":710.9641288433381,"y":240.5183016105417,"width":208.6939970717424,"height":135.86530014641286,"type":"table","id":"table-11"}],"relations":[{"vislist":[{"vislist":["map-6","map-7","map-8","map-9","map-10"],"relation":null,"id":"group-0"}],"relation":"repeated","id":"relation-0"}]},"2821_0":{"comp":[["bar_chart","bar_chart",["repeated"]],["bar_chart","table",["nested"]],["box_plot","table",["nested"]]],"visType":["bar_chart","table","box_plot"],"compType":["repeated","nested"],"compressed_tree":[{"composite_pattern":"repeated","visualization_type":[["bar_chart"]]},{"composite_pattern":"nested","visualization_type":[["bar_chart","box_plot"],["table"]]}],"coOccurrence":[["bar_chart","box_plot",["coOccurrence"]],["bar_chart","table",["coOccurrence"]],["box_plot","table",["coOccurrence"]]],"year":2016,"conference":["VAST"],"authors":["Dongyu Liu","Di Weng","Yuhong Li","Jie Ba","Yu Zhen","Huamin Qu","Yingcai Wu"],"title":"SmartAdP: Visual Analytics of Large-scale Taxi Trajectories for Selecting Billboard Locations","doi":"10.1109/TVCG.2016.2598432","abstract":"The problem of formulating solutions immediately and comparing them rapidly for billboard placements has plagued advertising planners for a long time, owing to the lack of efficient tools for in-depth analyses to make informed decisions. In this study, we attempt to employ visual analytics that combines the state-of-the-art mining and visualization techniques to tackle this problem using large-scale GPS trajectory data. In particular, we present SmartAdP, an interactive visual analytics system that deals with the two major challenges including finding good solutions in a huge solution space and comparing the solutions in a visual and intuitive manner. An interactive framework that integrates a novel visualization-driven data mining model enables advertising planners to effectively and efficiently formulate good candidate solutions. In addition, we propose a set of coupled visualizations: a solution view with metaphor-based glyphs to visualize the correlation between different solutions; a location view to display billboard locations in a compact manner; and a ranking view to present multi-typed rankings of the solutions. This system has been demonstrated using case studies with a real-world dataset and domain-expert interviews. Our approach can be adapted for other location selection problems such as selecting locations of retail stores or restaurants using trajectory data.","keywords":"optimal billboard locations;taxi trajectory;visual analytics;comparative analysis","caption":"Fig. 1. SmartAdP system. (A) Dashboard View shows the information of the current solution for billboard placements. (B) Map View provides a visual summary of the geospatial environment. (C) Solution Preview lists the parameters and statistics of the candidate solutions. (D) Solution View lays out all the solutions as glyphs to reveal the relationships among the solutions. (E) Location View supports in-depth analysis at the fine-grained location level. (F) Ranking View displays multi-typed ranks of the solutions.","img_size":{"width":1984,"height":748},"subfigures":[{"x":40.44365649784395,"y":21.78626364042404,"width":972.2045589817843,"height":717.3929581691365,"type":"interface","id":"interface-0"},{"x":1021.02731721808,"y":23.19148353325989,"width":937.7000350120846,"height":713.1419088890224,"type":"interface","id":"interface-1"}],"visualizations":[{"x":264.4380403458213,"y":572.6858789625359,"width":127.21613832853025,"height":150.08645533141203,"type":"bar_chart","id":"bar_chart-0"},{"x":407.37752161383287,"y":571.2564841498559,"width":134.36311239193083,"height":152.94524495677229,"type":"bar_chart","id":"bar_chart-1"},{"x":557.4639769452449,"y":575.5446685878961,"width":128.64553314121042,"height":145.79827089337175,"type":"bar_chart","id":"bar_chart-2"},{"x":701.3902872200775,"y":571.390922834856,"width":132.11432975997525,"height":149.49779420207722,"type":"bar_chart","id":"bar_chart-3"},{"x":847.4113885337342,"y":575.7367889453816,"width":132.98350298208038,"height":146.0211013136568,"type":"bar_chart","id":"bar_chart-4"},{"x":1053.405442172643,"y":428.84651440961966,"width":359.8377139515115,"height":219.90082519259033,"type":"bar_chart","id":"bar_chart-5"},{"x":1777.3255547881479,"y":428.1471884217625,"width":169.27996869926028,"height":223.65474652387138,"type":"bar_chart","id":"bar_chart-6"},{"x":1414.4725985605953,"y":425.9719457859802,"width":386.7790799977038,"height":275.9776459400063,"type":"box_plot","id":"box_plot-7"},{"x":1047.796666052056,"y":23.68877085903856,"width":481.9457374692506,"height":388.3447058119992,"type":"glyph_based","id":"glyph_based-8"},{"x":1535.7169374568755,"y":21.697259547182156,"width":418.2173754898449,"height":390.33621712385553,"type":"glyph_based","id":"glyph_based-9"},{"x":244.4265129682997,"y":28.08645533141207,"width":759.0086455331412,"height":501.7175792507203,"type":"heatmap","id":"heatmap-10"},{"x":1049.2334741796901,"y":27.217282109306936,"width":478.84726224783844,"height":385.93659942363104,"type":"heatmap","id":"heatmap-11"},{"x":1527.7508922094498,"y":21.697259547182156,"width":426.1834207372708,"height":388.3447058119992,"type":"heatmap","id":"heatmap-12"},{"x":244.4265129682997,"y":29.515850144092184,"width":759.0086455331412,"height":497.42939481268013,"type":"map","id":"map-13"},{"x":1051.7796886757692,"y":427.965567165889,"width":899.2591137012693,"height":275.0099637643355,"type":"table","id":"table-14"}],"relations":[{"vislist":[{"vislist":["bar_chart-0","bar_chart-1","bar_chart-2","bar_chart-3","bar_chart-4"],"relation":null,"id":"group-0"}],"relation":"repeated","id":"relation-0"},{"vislist":[{"vislist":["bar_chart-5","box_plot-7","bar_chart-6"],"relation":null,"id":"group-2"},{"vislist":["table-14"],"relation":null,"id":"group-3"}],"relation":"nested","id":"relation-2"}]},"2822_0":{"comp":[["graph","graph",["repeated"]],["graph","proportional_area_chart",["accompanied"]],["proportional_area_chart","graph",["accompanied"]],["proportional_area_chart","proportional_area_chart",["nested"]],["scatterplot","box_plot",["accompanied"]],["box_plot","scatterplot",["accompanied"]],["pie_chart","graph",["nested"]],["comb","matrix",["coordinated"]],["comb","bar_chart",["stacked"]],["comb","area_chart",["stacked"]],["bar_chart","comb",["stacked"]],["area_chart","comb",["stacked"]]],"visType":["graph","proportional_area_chart","scatterplot","box_plot","pie_chart","comb","matrix","bar_chart","area_chart"],"compType":["repeated","accompanied","nested","coordinated","stacked"],"compressed_tree":[{"composite_pattern":"repeated","visualization_type":[["graph"]]},{"composite_pattern":"accompanied","visualization_type":[["proportional_area_chart","graph"]]},{"composite_pattern":"stacked","visualization_type":[["bar_chart",{"composite_pattern":"accompanied","visualization_type":[["scatterplot","box_plot"]]}]]},{"composite_pattern":"stacked","visualization_type":[["area_chart",{"composite_pattern":"accompanied","visualization_type":[["scatterplot","box_plot"]]}]]},{"composite_pattern":"nested","visualization_type":[["proportional_area_chart"],["proportional_area_chart"]]},{"composite_pattern":"stacked","visualization_type":[["bar_chart",{"composite_pattern":"coordinated","visualization_type":[[{"composite_pattern":"nested","visualization_type":[["pie_chart"],["graph"]]}],["matrix"]]}]]}],"coOccurrence":[["graph","proportional_area_chart",["coOccurrence"]],["graph","pie_chart",["coOccurrence"]],["graph","matrix",["coOccurrence"]],["graph","scatterplot",["coOccurrence"]],["graph","box_plot",["coOccurrence"]],["graph","bar_chart",["coOccurrence"]],["graph","area_chart",["coOccurrence"]],["proportional_area_chart","pie_chart",["coOccurrence"]],["proportional_area_chart","matrix",["coOccurrence"]],["proportional_area_chart","scatterplot",["coOccurrence"]],["proportional_area_chart","box_plot",["coOccurrence"]],["proportional_area_chart","bar_chart",["coOccurrence"]],["proportional_area_chart","area_chart",["coOccurrence"]],["pie_chart","matrix",["coOccurrence"]],["pie_chart","scatterplot",["coOccurrence"]],["pie_chart","box_plot",["coOccurrence"]],["pie_chart","bar_chart",["coOccurrence"]],["pie_chart","area_chart",["coOccurrence"]],["matrix","scatterplot",["coOccurrence"]],["matrix","box_plot",["coOccurrence"]],["matrix","bar_chart",["coOccurrence"]],["matrix","area_chart",["coOccurrence"]],["scatterplot","box_plot",["coOccurrence"]],["scatterplot","bar_chart",["coOccurrence"]],["scatterplot","area_chart",["coOccurrence"]],["box_plot","bar_chart",["coOccurrence"]],["box_plot","area_chart",["coOccurrence"]],["bar_chart","area_chart",["coOccurrence"]]],"year":2016,"conference":["VAST"],"authors":["Siwei Fu","Jian Zhao","Weiwei Cui","Huamin Qu"],"title":"Visual Analysis of MOOC Forums with iForum","doi":"10.1109/TVCG.2016.2598444","abstract":"Discussion forums of Massive Open Online Courses (MOOC) provide great opportunities for students to interact with instructional staff as well as other students. Exploration of MOOC forum data can offer valuable insights for these staff to enhance the course and prepare the next release. However, it is challenging due to the large, complicated, and heterogeneous nature of relevant datasets, which contain multiple dynamically interacting objects such as users, posts, and threads, each one including multiple attributes. In this paper, we present a design study for developing an interactive visual analytics system, called iForum, that allows for effectively discovering and understanding temporal patterns in MOOC forums. The design study was conducted with three domain experts in an iterative manner over one year, including a MOOC instructor and two official teaching assistants. iForum offers a set of novel visualization designs for presenting the three interleaving aspects of MOOC forums (i.e., posts, users, and threads) at three different scales. To demonstrate the effectiveness and usefulness of iForum, we describe a case study involving field experts, in which they use iForum to investigate real MOOC forum data for a course on JAVA programming.","keywords":"Discussion forum;MOOC;temporal visualization;visual analytics","caption":"Fig. 1. Using iForum to explore the MOOC forum of a JAVA programming course that has attracted more than ten thousand students during a ten-week course period. (a) The Overview shows the overall changes of posts, threads, and users on the forum. (b) The Matrix View further enables the comparison of dynamic patterns of different user groups along time. After a cell of interest is selected, orange lines are shown on top of the matrix to indicate the threads passing through that cell. (c) Meanwhile, the Thread View presents all selected threads in a compact layout, and (d) the Social Network View reveals the interactions among corresponding users based on their replying relationships. (e) When a specific thread is selected, the Text View displays discussions in traditional indented form.","img_size":{"width":1971,"height":1001},"subfigures":[{"x":6.6734738879637545,"y":10.091835532100887,"width":1954.7898682377365,"height":979.3833739711249,"type":"interface","id":"interface-0"}],"visualizations":[{"x":19.18811881188105,"y":256.524249838597,"width":96.27722772277227,"height":387.17798263176576,"type":"area_chart","id":"area_chart-0"},{"x":114.0495049504949,"y":154.32673267326734,"width":434.66336633663377,"height":65.12871287128712,"type":"bar_chart","id":"bar_chart-1"},{"x":609.5940594059404,"y":165.65346534653466,"width":700.8415841584158,"height":70.7920792079208,"type":"bar_chart","id":"bar_chart-2"},{"x":109.80198019801969,"y":222.28712871287135,"width":417.6732673267325,"height":421.92079207920784,"type":"box_plot","id":"box_plot-3"},{"x":536.8095500539238,"y":237.1095929527848,"width":777.4213663041598,"height":405.0639016838074,"type":"graph","id":"graph-10"},{"x":1316.4229355294644,"y":116.82412909821852,"width":643.8006466886422,"height":522.1791039478785,"type":"graph","id":"graph-15"},{"x":17.772277227722633,"y":642.7920792079209,"width":1294.079207920792,"height":349.7128712871287,"type":"graph","id":"graph-4"},{"x":536.8004286276201,"y":240.52744822354992,"width":775.7010651917233,"height":399.9670041767138,"type":"matrix","id":"matrix-9"},{"x":540.2178217821781,"y":242.10891089108912,"width":773.0495049504951,"height":397.8514851485148,"type":"pie_chart","id":"pie_chart-6"},{"x":1314.665520701949,"y":118.5711103884672,"width":642.0998444485458,"height":523.9015804706943,"type":"proportional_area_chart","id":"proportional_area_chart-14"},{"x":1314.6831683168316,"y":116.0990099009901,"width":642.7920792079208,"height":526.6930693069307,"type":"proportional_area_chart","id":"proportional_area_chart-7"},{"x":112.77003334212489,"y":228.5814542995035,"width":415.2292081292991,"height":416.62128666884814,"type":"scatterplot","id":"scatterplot-18"}],"relations":[{"vislist":[{"vislist":["graph-4"],"relation":null,"id":"group-0"}],"relation":"repeated","id":"relation-0"},{"vislist":[{"vislist":["proportional_area_chart-14","graph-15"],"relation":null,"id":"group-7"}],"relation":"accompanied","id":"relation-4"},{"vislist":[{"vislist":["bar_chart-1",{"vislist":[{"vislist":["scatterplot-18","box_plot-3"],"relation":null,"id":"group-16"}],"relation":"accompanied","id":"relation-9"}],"relation":null,"id":"group-17"}],"relation":"stacked","id":"relation-10"},{"vislist":[{"vislist":["area_chart-0",{"vislist":[{"vislist":["scatterplot-18","box_plot-3"],"relation":null,"id":"group-16"}],"relation":"accompanied","id":"relation-9"}],"relation":null,"id":"group-18"}],"relation":"stacked","id":"relation-11"},{"vislist":[{"vislist":["proportional_area_chart-14"],"relation":null,"id":"group-19"},{"vislist":["proportional_area_chart-7"],"relation":null,"id":"group-20"}],"relation":"nested","id":"relation-12"},{"vislist":[{"vislist":["bar_chart-2",{"vislist":[{"vislist":[{"vislist":[{"vislist":["pie_chart-6"],"relation":null,"id":"group-12"},{"vislist":["graph-10"],"relation":null,"id":"group-13"}],"relation":"nested","id":"relation-7"}],"relation":null,"id":"group-14"},{"vislist":["matrix-9"],"relation":null,"id":"group-15"}],"relation":"coordinated","id":"relation-8"}],"relation":null,"id":"group-21"}],"relation":"stacked","id":"relation-13"}]},"2819_0":{"comp":[["comb","comb",["repeated","mirrored"]],["comb","area_chart",["stacked"]],["comb","line_chart",["stacked"]],["proportional_area_chart","line_chart",["accompanied"]],["line_chart","proportional_area_chart",["accompanied"]],["line_chart","glyph_based",["accompanied"]],["line_chart","comb",["stacked"]],["glyph_based","line_chart",["accompanied","coordinated"]],["glyph_based","matrix",["nested"]],["glyph_based","bar_chart",["annotated"]],["area_chart","comb",["stacked"]]],"visType":["comb","area_chart","line_chart","proportional_area_chart","glyph_based","matrix","bar_chart"],"compType":["repeated","mirrored","stacked","accompanied","coordinated","nested","annotated"],"compressed_tree":[{"composite_pattern":"stacked","visualization_type":[["area_chart",{"composite_pattern":"repeated","visualization_type":[[{"composite_pattern":"accompanied","visualization_type":[["proportional_area_chart","line_chart"]]}]]}]]},{"composite_pattern":"repeated","visualization_type":[[{"composite_pattern":"accompanied","visualization_type":[["glyph_based","line_chart"]]}]]},{"composite_pattern":"nested","visualization_type":[["glyph_based"],["matrix"]]},{"composite_pattern":"stacked","visualization_type":[["line_chart",{"composite_pattern":"mirrored","visualization_type":[[{"composite_pattern":"annotated","visualization_type":[["glyph_based"],["bar_chart"]]}]]}]]},{"composite_pattern":"coordinated","visualization_type":[["glyph_based"],["line_chart"]]}],"coOccurrence":[["glyph_based","bar_chart",["coOccurrence"]],["glyph_based","area_chart",["coOccurrence"]],["glyph_based","line_chart",["coOccurrence"]],["bar_chart","area_chart",["coOccurrence"]],["bar_chart","line_chart",["coOccurrence"]],["area_chart","line_chart",["coOccurrence"]]],"year":2016,"conference":["VAST"],"authors":["Quan Li","Peng Xu","Yeukyin Chan","Yun Wang","Zhipeng Wang","Huamin Qu","Xiaojuan Ma"],"title":"A Visual Analytics Approach for Understanding Reasons behind Snowballing and Comeback in MOBA Games","doi":"10.1109/TVCG.2016.2598415","abstract":"To design a successful Multiplayer Online Battle Arena (MOBA) game, the ratio of snowballing and comeback occurrences to all matches played must be maintained at a certain level to ensure its fairness and engagement. Although it is easy to identify these two types of occurrences, game developers often find it difficult to determine their causes and triggers with so many game design choices and game parameters involved. In addition, the huge amounts of MOBA game data are often heterogeneous, multi-dimensional and highly dynamic in terms of space and time, which poses special challenges for analysts. In this paper, we present a visual analytics system to help game designers find key events and game parameters resulting in snowballing or comeback occurrences in MOBA game data. We follow a user-centered design process developing the system with game analysts and testing with real data of a trial version MOBA game from NetEase Inc. We apply novel visualization techniques in conjunction with well-established ones to depict the evolution of players\' positions, status and the occurrences of events. Our system can reveal players\' strategies and performance throughout a single match and suggest patterns, e.g., specific player\' actions and game events, that have led to the final occurrences. We further demonstrate a workflow of leveraging human analyzed patterns to improve the scalability and generality of match data analysis. Finally, we validate the usability of our system by proving the identified patterns are representative in snowballing or comeback matches in a one-month-long MOBA tournament dataset.","keywords":"Game play data visualization;visual knowledge discovery;visual knowledge representation;and game reconstruction","caption":"Figure 1. A match with comeback occurrence. (a) Trend View discloses the trend of game play during a match. (b) Trajectory View simulates the game replay. (c) Tactic Geographical Timeline View presents details of players\u2019 behavior in the time period of interest. (d) Resource Time Sequence View displays the accumulated resources and changes in resources of each player. (e) Tactic Comparison View (Left) unfolds the temporal dynamics of all the tactical actions in two camps while Equipment Evolution View (Right) shows the equipment evolution hierarchies. (f) Player Billing Radar View represents the statistical information of each player. ","img_size":{"width":1948,"height":975},"subfigures":[{"x":11.889293346046163,"y":7.117557059480107,"width":365.0165399608777,"height":544.9140314049738,"type":"single","id":"single-0"},{"x":404.97410243679315,"y":5.733600902869432,"width":975.3398528079844,"height":549.0964024068898,"type":"single","id":"single-1"},{"x":1407.3245041192936,"y":9.951341378802677,"width":508.6206259658693,"height":547.7332148984922,"type":"single","id":"single-2"},{"x":1569.5359099750133,"y":579.0757297770297,"width":344.07998366297284,"height":391.1187680557453,"type":"single","id":"single-3"},{"x":557.8230756283408,"y":577.7010376793941,"width":986.5764723320902,"height":395.2826109397108,"type":"single","id":"single-4"},{"x":22.20369677421497,"y":579.0599164650895,"width":515.5889941526252,"height":389.73593599093203,"type":"single","id":"single-5"}],"visualizations":[{"x":1407.4833795013853,"y":386.218836565097,"width":496.95290858725747,"height":170.1523545706371,"type":"area_chart","id":"area_chart-0"},{"x":20.96557762576117,"y":860.2167835385633,"width":447.6031512962586,"height":104.09375611540906,"type":"area_chart","id":"area_chart-1"},{"x":1408.7219009515547,"y":182.72480558468803,"width":501.7249184600478,"height":199.3041464327206,"type":"bar_chart","id":"bar_chart-16"},{"x":19.256232686980695,"y":707.617728531856,"width":453.7396121883657,"height":145.84487534626044,"type":"bar_chart","id":"bar_chart-3"},{"x":1094.4741379310344,"y":586.4942439671221,"width":446.4080459770117,"height":367.95977011494244,"type":"glyph_based","id":"glyph_based-10"},{"x":564.855453328773,"y":576.5612981240738,"width":510.0594049655039,"height":390.3515854327837,"type":"glyph_based","id":"glyph_based-4"},{"x":23.567921528646366,"y":714.4855249769906,"width":447.6031512962586,"height":132.71953904714644,"type":"glyph_based","id":"glyph_based-6"},{"x":408.15199930806216,"y":8.90130487921408,"width":966.9774881758274,"height":548.0244407823616,"type":"glyph_based","id":"glyph_based-7"},{"x":1097.8629562276797,"y":587.2581022541804,"width":451.10762697622124,"height":372.69050872156083,"type":"line_chart","id":"line_chart-13"},{"x":1408.0148778635853,"y":3.9367478844755848,"width":497.04768545107726,"height":177.6116390436915,"type":"line_chart","id":"line_chart-15"},{"x":404.5567519537788,"y":9.783302466202226,"width":973.9338680788289,"height":545.1871526696942,"type":"line_chart","id":"line_chart-34"},{"x":21.957063711911417,"y":577.9778393351801,"width":515.858725761773,"height":137.74238227146816,"type":"line_chart","id":"line_chart-8"},{"x":562.1465517241379,"y":579.0229795993059,"width":509.91379310344837,"height":381.0344827586207,"type":"matrix","id":"matrix-9"},{"x":22.244467672510496,"y":7.780614012572301,"width":357.84456855141167,"height":542.7572450826493,"type":"others","id":"others-2"},{"x":1569.53324099723,"y":572.5761772853186,"width":345.70637119113604,"height":397.02216066482,"type":"polar_plot","id":"polar_plot-11"},{"x":1407.0098457746342,"y":7.074422863978072,"width":503.43077227208255,"height":172.9723874911339,"type":"proportional_area_chart","id":"proportional_area_chart-17"},{"x":1407.022795734549,"y":181.05182862614703,"width":505.12312889405973,"height":202.6501003498023,"type":"proportional_area_chart","id":"proportional_area_chart-18"}],"relations":[{"vislist":[{"vislist":["area_chart-0",{"vislist":[{"vislist":[{"vislist":[{"vislist":["proportional_area_chart-17","line_chart-15"],"relation":null,"id":"group-14"}],"relation":"accompanied","id":"relation-2"}],"relation":null,"id":"group-7"}],"relation":"repeated","id":"relation-4"},{"vislist":[{"vislist":[{"vislist":[{"vislist":["proportional_area_chart-18","bar_chart-16"],"relation":null,"id":"group-15"}],"relation":"accompanied","id":"relation-3"}],"relation":null,"id":"group-8"}],"relation":"repeated","id":"relation-5"}],"relation":null,"id":"group-9"}],"relation":"stacked","id":"relation-6"},{"vislist":[{"vislist":[{"vislist":[{"vislist":["glyph_based-10","line_chart-13"],"relation":null,"id":"group-10"}],"relation":"accompanied","id":"relation-7"}],"relation":null,"id":"group-11"}],"relation":"repeated","id":"relation-8"},{"vislist":[{"vislist":["glyph_based-4"],"relation":null,"id":"group-16"},{"vislist":["matrix-9"],"relation":null,"id":"group-17"}],"relation":"nested","id":"relation-10"},{"vislist":[{"vislist":["line_chart-8",{"vislist":[{"vislist":[{"vislist":[{"vislist":["glyph_based-6"],"relation":null,"id":"group-18"},{"vislist":["bar_chart-3"],"relation":null,"id":"group-19"}],"relation":"annotated","id":"relation-11"}],"relation":null,"id":"group-21"}],"relation":"mirrored","id":"relation-13"},{"vislist":[{"vislist":["area_chart-1"],"relation":null,"id":"group-20"}],"relation":"mirrored","id":"relation-12"}],"relation":null,"id":"group-22"}],"relation":"stacked","id":"relation-14"},{"vislist":[{"vislist":["glyph_based-7"],"relation":null,"id":"group-23"},{"vislist":["line_chart-34"],"relation":null,"id":"group-24"}],"relation":"coordinated","id":"relation-15"}]},"2825_0":{"comp":[["bar_chart","bar_chart",["repeated"]],["bar_chart","table",["nested"]],["comb","comb",["repeated"]],["proportional_area_chart","map",["coordinated"]]],"visType":["bar_chart","table","comb","proportional_area_chart","map"],"compType":["repeated","nested","coordinated"],"compressed_tree":[{"composite_pattern":"repeated","visualization_type":[["bar_chart"]]},{"composite_pattern":"nested","visualization_type":[["bar_chart"],["table"]]},{"composite_pattern":"repeated","visualization_type":[[{"composite_pattern":"coordinated","visualization_type":[["proportional_area_chart"],["map"]]}]]}],"coOccurrence":[["bar_chart","table",["coOccurrence"]],["bar_chart","proportional_area_chart",["coOccurrence"]],["bar_chart","map",["coOccurrence"]],["table","proportional_area_chart",["coOccurrence"]],["table","map",["coOccurrence"]],["proportional_area_chart","map",["coOccurrence"]]],"year":2016,"conference":["VAST"],"authors":["Cristian Felix","Anshul Vikram Pandey","Enrico Bertini"],"title":"TextTile: An Interactive Visualization Tool for Seamless Exploratory Analysis of Structured Data and Unstructured Text","doi":"10.1109/TVCG.2016.2598447","abstract":"We describe TextTile, a data visualization tool for investigation of datasets and questions that require seamless and flexible analysis of structured data and unstructured text. TextTile is based on real-world data analysis problems gathered through our interaction with a number of domain experts and provides a general purpose solution to such problems. The system integrates a set of operations that can interchangeably be applied to the structured as well as to unstructured text part of the data to generate useful data summaries. Such summaries are then organized in visual tiles in a grid layout to allow their analysis and comparison. We validate TextTile with task analysis, use cases and a user study showing the system can be easily learned and proficiently used to carry out nontrivial tasks.","keywords":"Exploratory Text Analysis;Knowledge Discovery;Text Visualization","caption":"Fig. 1. TextTile interface showing data from the Yelp-Heathcare reviews dataset with: a) fields panel showing all the fields present in the data; b) filter panel with filter specification to select only reviews from New York; c) split panel with three segments generated using the business category field; d) summarize panel having three segments (Medical Centers, Chiropractors, and General Dentistry ) with keywords charts to show relevant words, bar charts to show rating distribution and maps for location distribution by zip code. ","img_size":{"width":1935,"height":982},"subfigures":[{"x":30.325524237793534,"y":18.306247813584292,"width":1881.3761724954463,"height":958.0397549517562,"type":"interface","id":"interface-0"}],"visualizations":[{"x":498.72347949080614,"y":440.3026874115983,"width":458.3592644978783,"height":129.17397454031118,"type":"bar_chart","id":"bar_chart-0"},{"x":975.1393210749646,"y":441.69165487977364,"width":455.5813295615275,"height":137.5077793493635,"type":"bar_chart","id":"bar_chart-1"},{"x":267.16715787801195,"y":200.40533137346318,"width":176.89744254872133,"height":765.3643390078832,"type":"bar_chart","id":"bar_chart-13"},{"x":450.42366206983235,"y":134.96169649268091,"width":1459.1433204658006,"height":304.5041494276045,"type":"bar_chart","id":"bar_chart-15"},{"x":1454.3330975954739,"y":441.69165487977364,"width":447.2475247524754,"height":129.17397454031112,"type":"bar_chart","id":"bar_chart-2"},{"x":1454.3330975954739,"y":583.3663366336633,"width":448.63649222065055,"height":115.28429985855736,"type":"bar_chart","id":"bar_chart-3"},{"x":973.7503536067894,"y":581.977369165488,"width":455.5813295615275,"height":118.06223479490802,"type":"bar_chart","id":"bar_chart-4"},{"x":495.94554455445547,"y":581.977369165488,"width":462.5261669024045,"height":116.67326732673268,"type":"bar_chart","id":"bar_chart-5"},{"x":964.0275813295615,"y":705.5954738330976,"width":470.85997171145686,"height":261.12588401697315,"type":"map","id":"map-10"},{"x":1440.44342291372,"y":706.9844413012729,"width":473.63790664780754,"height":256.9589816124469,"type":"map","id":"map-11"},{"x":489.0007072135785,"y":705.5954738330976,"width":470.859971711457,"height":262.5148514851485,"type":"map","id":"map-9"},{"x":622.3415841584159,"y":725.0410183875531,"width":134.72984441301264,"height":220.84582743988676,"type":"proportional_area_chart","id":"proportional_area_chart-6"},{"x":1095.9794908062236,"y":726.4299858557284,"width":191.67751060820365,"height":241.68033946251762,"type":"proportional_area_chart","id":"proportional_area_chart-7"},{"x":1548.7828854314,"y":709.7623762376238,"width":351.40876944837345,"height":250.01414427156996,"type":"proportional_area_chart","id":"proportional_area_chart-8"},{"x":447.01162407412613,"y":138.3236300319248,"width":1460.847027245099,"height":301.19093052976206,"type":"table","id":"table-14"}],"relations":[{"vislist":[{"vislist":["bar_chart-0","bar_chart-1","bar_chart-2","bar_chart-3","bar_chart-4","bar_chart-5"],"relation":null,"id":"group-0"}],"relation":"repeated","id":"relation-0"},{"vislist":[{"vislist":["bar_chart-15"],"relation":null,"id":"group-1"},{"vislist":["table-14"],"relation":null,"id":"group-2"}],"relation":"nested","id":"relation-1"},{"vislist":[{"vislist":[{"vislist":[{"vislist":["proportional_area_chart-8"],"relation":null,"id":"group-7"},{"vislist":["map-11"],"relation":null,"id":"group-8"}],"relation":"coordinated","id":"relation-4"},{"vislist":[{"vislist":["proportional_area_chart-7"],"relation":null,"id":"group-5"},{"vislist":["map-10"],"relation":null,"id":"group-6"}],"relation":"coordinated","id":"relation-3"},{"vislist":[{"vislist":["proportional_area_chart-6"],"relation":null,"id":"group-3"},{"vislist":["map-9"],"relation":null,"id":"group-4"}],"relation":"coordinated","id":"relation-2"}],"relation":null,"id":"group-9"}],"relation":"repeated","id":"relation-5"}]},"2829_0":{"comp":[["bar_chart","bar_chart",["repeated"]]],"visType":["bar_chart"],"compType":["repeated"],"compressed_tree":[{"composite_pattern":"repeated","visualization_type":[["bar_chart"]]}],"coOccurrence":[["bar_chart","bar_chart",["coOccurrence"]]],"year":2016,"conference":["VAST"],"authors":["Ali Sarvghad","Melanie Tory","Narges Mahyar"],"title":"Visualizing Dimension Coverage to Support Exploratory Analysis","doi":"10.1109/TVCG.2016.2598466","abstract":"Data analysis involves constantly formulating and testing new hypotheses and questions about data. When dealing with a new dataset, especially one with many dimensions, it can be cumbersome for the analyst to clearly remember which aspects of the data have been investigated (i.e., visually examined for patterns, trends, outliers etc.) and which combinations have not. Yet this information is critical to help the analyst formulate new questions that they have not already answered. We observe that for tabular data, questions are typically comprised of varying combinations of data dimensions (e.g., what are the trends of Sales and Profit for different Regions?). We propose representing analysis history from the angle of dimension coverage (i.e., which data dimensions have been investigated and in which combinations). We use scented widgets to incorporate dimension coverage of the analysts\' past work into interaction widgets of a visualization tool. We demonstrate how this approach can assist analysts with the question formation process. Our approach extends the concept of scented widgets to reveal aspects of one\'s own analysis history, and offers a different perspective on one\'s past work than typical visualization history tools. Results of our empirical study showed that participants with access to embedded dimension coverage information relied on this information when formulating questions, asked more questions about the data, generated more top-level findings, and showed greater breadth of their analysis without sacrificing depth.","keywords":"Dimension coverage;Tabular data;History;Empirical laboratory study;Exploratory data analysis;Scented widgets","caption":"Fig. 1: Re-implemented HomeFinder with scented widgets that pro- vide social navigation cues [30]. Bar charts embedded in the controls reveal information about the frequency of other people\u2019s investigation of data values. For example, few people looked at 4+ Bedrooms.","img_size":{"width":1062,"height":675},"subfigures":[{"x":11.335245957883524,"y":15.090126896594308,"width":1039.3295080842322,"height":650.3516598768781,"type":"interface","id":"interface-0"}],"visualizations":[{"x":702.3362068965517,"y":63.36206896551725,"width":316.8103448275863,"height":192.6724137931035,"type":"bar_chart","id":"bar_chart-0"},{"x":701.043103448276,"y":265.08620689655174,"width":131.8965517241379,"height":137.06896551724137,"type":"bar_chart","id":"bar_chart-1"},{"x":701.043103448276,"y":417.6724137931035,"width":337.5,"height":133.18965517241375,"type":"bar_chart","id":"bar_chart-2"},{"x":9.854969574036446,"y":48.054766734279895,"width":680.8433062880326,"height":617.8935091277892,"type":"map","id":"map-3"}],"relations":[{"vislist":[{"vislist":["bar_chart-0","bar_chart-1","bar_chart-2"],"relation":null,"id":"group-0"}],"relation":"repeated","id":"relation-0"}]},"2830_12":{"comp":[["matrix","matrix",["repeated"]]],"visType":["matrix"],"compType":["repeated"],"compressed_tree":[{"composite_pattern":"repeated","visualization_type":[["matrix"]]}],"coOccurrence":[["matrix","matrix",["coOccurrence"]]],"year":2016,"conference":["VAST"],"authors":["Michael Behrisch","Benjamin Bach","Michael Blumenschein","Michael Delz","Laura von R\xfcden","Jean-Daniel Fekete","Tobias Schreck"],"title":"Magnostics: Image-Based Search of Interesting Matrix Views for Guided Network Exploration","doi":"10.1109/TVCG.2016.2598467","abstract":"In this work we address the problem of retrieving potentially interesting matrix views to support the exploration of networks. We introduce Matrix Diagnostics (or Magnostics), following in spirit related approaches for rating and ranking other visualization techniques, such as Scagnostics for scatter plots. Our approach ranks matrix views according to the appearance of specific visual patterns, such as blocks and lines, indicating the existence of topological motifs in the data, such as clusters, bi-graphs, or central nodes. Magnostics can be used to analyze, query, or search for visually similar matrices in large collections, or to assess the quality of matrix reordering algorithms. While many feature descriptors for image analyzes exist, there is no evidence how they perform for detecting patterns in matrices. In order to make an informed choice of feature descriptors for matrix diagnostics, we evaluate 30 feature descriptors-27 existing ones and three new descriptors that we designed specifically for MAGNOSTICS-with respect to four criteria: pattern response, pattern variability, pattern sensibility, and pattern discrimination. We conclude with an informed set of six descriptors as most appropriate for Magnostics and demonstrate their application in two scenarios; exploring a large collection of matrices and analyzing temporal networks.","keywords":"Matrix Visualization;Visual Quality Measures;Quality Metrics;Feature Detection/Selection;Relational Data","caption":"Fig. 10: Query-By-Sketch interface for exploring large collections of matrix plots. The user can sketch in the canvas (1) an approximated matrix pattern and retrieve a ranked result list (2) according to a selected M AGNOSTICS FD (3).","img_size":{"width":1055,"height":501},"subfigures":[{"x":78.40886689642731,"y":19.686468300530162,"width":967.9133617445108,"height":473.8890901716392,"type":"interface","id":"interface-0"}],"visualizations":[{"x":89.21669106881407,"y":21.27232796486091,"width":291.2108345534407,"height":292.67789165446555,"type":"matrix","id":"matrix-0"},{"x":101.68667642752563,"y":335.95607613469986,"width":935.9824304538798,"height":125.43338213762814,"type":"matrix","id":"matrix-1"}],"relations":[{"vislist":[{"vislist":["matrix-1"],"relation":null,"id":"group-0"}],"relation":"repeated","id":"relation-0"}]},"2833_0":{"comp":[["scatterplot","scatterplot",["repeated"]]],"visType":["scatterplot"],"compType":["repeated"],"compressed_tree":[{"composite_pattern":"repeated","visualization_type":[["scatterplot"]]}],"coOccurrence":[["scatterplot","scatterplot",["coOccurrence"]]],"year":2016,"conference":["VAST"],"authors":["Cagatay Turkay","Erdem Kaya","Selim Balcisoy","Helwig Hauser"],"title":"Designing Progressive and Interactive Analytics Processes for High-Dimensional Data Analysis","doi":"10.1109/TVCG.2016.2598470","abstract":"In interactive data analysis processes, the dialogue between the human and the computer is the enabling mechanism that can lead to actionable observations about the phenomena being investigated. It is of paramount importance that this dialogue is not interrupted by slow computational mechanisms that do not consider any known temporal human-computer interaction characteristics that prioritize the perceptual and cognitive capabilities of the users. In cases where the analysis involves an integrated computational method, for instance to reduce the dimensionality of the data or to perform clustering, such non-optimal processes are often likely. To remedy this, progressive computations, where results are iteratively improved, are getting increasing interest in visual analytics. In this paper, we present techniques and design considerations to incorporate progressive methods within interactive analysis processes that involve high-dimensional data. We define methodologies to facilitate processes that adhere to the perceptual characteristics of users and describe how online algorithms can be incorporated within these. A set of design recommendations and according methods to support analysts in accomplishing high-dimensional data analysis tasks are then presented. Our arguments and decisions here are informed by observations gathered over a series of analysis sessions with analysts from finance. We document observations and recommendations from this study and present evidence on how our approach contribute to the efficiency and productivity of interactive visual analysis sessions involving high-dimensional data.","keywords":"Progressive analytics;high dimensional data;iterative refinement;visual analytics","caption":"Fig. 1. Iteratively refining a credit card transaction segment (details in Section 4.1) using progressive computations that are real- ized through a prototype built according to our design recommendations for temporally optimized analytical processes. Transaction segments are generated either through clustering (a) or through selections on a plot showing principal component analysis (PCA) results (b). Both the clustering and PCA computations are done \u201conline\u201d and the visualizations continuously update (according to the three levels of operation) either until the user changes the conditions to re-initiate the computations or until all the data is consumed. Subsegments are further refined through accompanying views (c, middle views), and the difference view (d) describing the segment.","img_size":{"width":1953,"height":708},"subfigures":[{"x":27.798161681997776,"y":21.005133979831655,"width":1907.3333032918165,"height":661.7271799683375,"type":"interface","id":"interface-0"}],"visualizations":[{"x":374.6842105263158,"y":355.6578947368421,"width":291.7894736842106,"height":328.2631578947369,"type":"bar_chart","id":"bar_chart-0"},{"x":674.7631578947369,"y":354,"width":311.68421052631584,"height":331.57894736842115,"type":"bar_chart","id":"bar_chart-1"},{"x":1331.2894736842106,"y":350.6842105263158,"width":275.2105263157893,"height":331.5789473684211,"type":"bar_chart","id":"bar_chart-2"},{"x":1613.3278348286976,"y":18.939088901475024,"width":323.25650141182626,"height":663.2327809549287,"type":"bar_chart","id":"bar_chart-8"},{"x":359.7631578947369,"y":14.13157894736841,"width":1250.0526315789473,"height":341.52631578947364,"type":"map","id":"map-7"},{"x":31.499999999999996,"y":24.07894736842104,"width":328.2631578947369,"height":324.9473684210526,"type":"scatterplot","id":"scatterplot-3"},{"x":28.18421052631579,"y":342.39473684210526,"width":339.8684210526316,"height":351.47368421052636,"type":"scatterplot","id":"scatterplot-4"},{"x":986.4473684210527,"y":354,"width":341.52631578947353,"height":336.5526315789474,"type":"scatterplot","id":"scatterplot-5"},{"x":361.4210526315789,"y":19.105263157894726,"width":1248.3947368421052,"height":336.55263157894734,"type":"scatterplot","id":"scatterplot-6"}],"relations":[{"vislist":[{"vislist":["scatterplot-3"],"relation":null,"id":"group-0"}],"relation":"repeated","id":"relation-0"}]},"2835_11":{"comp":[["comb","comb",["repeated"]],["matrix","graph",["nested"]]],"visType":["comb","matrix","graph"],"compType":["repeated","nested"],"compressed_tree":[{"composite_pattern":"repeated","visualization_type":[[{"composite_pattern":"nested","visualization_type":[["matrix"],["graph"]]}]]}],"coOccurrence":[["matrix","graph",["coOccurrence"]]],"year":2016,"conference":["VAST"],"authors":["Xinsong Yang","Lei Shi","Madelaine Daianu","Hanghang Tong","Qingsong Liu","Paul M. Thompson"],"title":"Blockwise Human Brain Network Visual Comparison Using NodeTrix Representation","doi":"10.1109/TVCG.2016.2598472","abstract":"Visually comparing human brain networks from multiple population groups serves as an important task in the field of brain connectomics. The commonly used brain network representation, consisting of nodes and edges, may not be able to reveal the most compelling network differences when the reconstructed networks are dense and homogeneous. In this paper, we leveraged the block information on the Region Of Interest (ROI) based brain networks and studied the problem of blockwise brain network visual comparison. An integrated visual analytics framework was proposed. In the first stage, a two-level ROI block hierarchy was detected by optimizing the anatomical structure and the predictive comparison performance simultaneously. In the second stage, the NodeTrix representation was adopted and customized to visualize the brain network with block information. We conducted controlled user experiments and case studies to evaluate our proposed solution. Results indicated that our visual analytics method outperformed the commonly used node-link graph and adjacency matrix design in the blockwise network comparison tasks. We have shown compelling findings from two real-world brain network data sets, which are consistent with the prior connectomics studies.","keywords":"Brain Network;Visual Comparison;Hybrid Representation","caption":"Fig. 10: CCI case using the contrast interaction.","img_size":{"width":909,"height":468},"subfigures":[{"x":4.373759723354591,"y":2.3849835396525068,"width":894.3103932391797,"height":458.60805812812157,"type":"single","id":"single-0"}],"visualizations":[{"x":26.27075098814228,"y":120.23715415019761,"width":292.2687747035573,"height":321.8656126482214,"type":"graph","id":"graph-0"},{"x":589.5355731225296,"y":122.0869565217391,"width":291.34387351778656,"height":318.16600790513843,"type":"graph","id":"graph-1"},{"x":24.42094861660078,"y":120.23715415019761,"width":293.1936758893281,"height":320.9407114624506,"type":"heatmap","id":"heatmap-2"},{"x":589.5355731225296,"y":123.01185770750988,"width":292.2687747035573,"height":319.0909090909091,"type":"heatmap","id":"heatmap-3"},{"x":26.27075098814228,"y":119.31225296442686,"width":292.2687747035573,"height":322.7905138339921,"type":"matrix","id":"matrix-4"},{"x":589.5355731225296,"y":123.93675889328063,"width":293.1936758893281,"height":318.16600790513843,"type":"matrix","id":"matrix-5"}],"relations":[{"vislist":[{"vislist":[{"vislist":[{"vislist":["matrix-4"],"relation":null,"id":"group-0"},{"vislist":["graph-0"],"relation":null,"id":"group-1"}],"relation":"nested","id":"relation-0"},{"vislist":[{"vislist":["matrix-5"],"relation":null,"id":"group-2"},{"vislist":["graph-1"],"relation":null,"id":"group-3"}],"relation":"nested","id":"relation-1"}],"relation":null,"id":"group-4"}],"relation":"repeated","id":"relation-2"}]},"2836_0":{"comp":[["line_chart","line_chart",["repeated"]],["parallel_coordinate","comb",["stacked"]],["comb","parallel_coordinate",["stacked"]]],"visType":["line_chart","parallel_coordinate","comb"],"compType":["repeated","stacked"],"compressed_tree":[{"composite_pattern":"stacked","visualization_type":[["parallel_coordinate",{"composite_pattern":"repeated","visualization_type":[["line_chart"]]}]]}],"coOccurrence":[["line_chart","parallel_coordinate",["coOccurrence"]]],"year":2016,"conference":["VAST"],"authors":["Cong Xie","Wen Zhong","Klaus Mueller"],"title":"A Visual Analytics Approach for Categorical Joint Distribution Reconstruction from Marginal Projections","doi":"10.1109/TVCG.2016.2598479","abstract":"Oftentimes multivariate data are not available as sets of equally multivariate tuples, but only as sets of projections into subspaces spanned by subsets of these attributes. For example, one may find data with five attributes stored in six tables of two attributes each, instead of a single table of five attributes. This prohibits the visualization of these data with standard high-dimensional methods, such as parallel coordinates or MDS, and there is hence the need to reconstruct the full multivariate (joint) distribution from these marginal ones. Most of the existing methods designed for this purpose use an iterative procedure to estimate the joint distribution. With insufficient marginal distributions and domain knowledge, they lead to results whose joint errors can be large. Moreover, enforcing smoothness for regularizations in the joint space is not applicable if the attributes are not numerical but categorical. We propose a visual analytics approach that integrates both anecdotal data and human experts to iteratively narrow down a large set of plausible solutions. The solution space is populated using a Monte Carlo procedure which uniformly samples the solution space. A level-of-detail high dimensional visualization system helps the user understand the patterns and the uncertainties. Constraints that narrow the solution space can then be added by the user interactively during the iterative exploration, and eventually a subset of solutions with narrow uncertainty intervals emerges.","keywords":"Parallel Coordinates;Joint Distribution Reconstruction;Solution Space;High-dimensional Data;Multivariate Data","caption":"Fig. 1. The interface of our visual analytics framework for joint distribution reconstruction. (a) The features of the joint reconstruction solution space are defined. The user selects a subset of features (highlighted in purple) and visualizes it with (b) augmented parallel coordinates. Box plots and heat maps integrated into the axes bars show the distributions of the features. (c) Constraints can be added by filtering the range in each axis. (d) The probability density functions of the features before and after filtering are visualized as line charts. The bars below the line charts show the ranges of features after filtering. (e) The control panel for visualization.","img_size":{"width":2148,"height":1018},"subfigures":[{"x":15.028336260748649,"y":10.460429821014495,"width":2116.3831754737676,"height":1003.3140649136557,"type":"interface","id":"interface-0"}],"visualizations":[{"x":281.80819912152276,"y":101.3528550512445,"width":1807.9560761346995,"height":192.2723279648609,"type":"line_chart","id":"line_chart-0"},{"x":283.29868228404104,"y":299.5871156661786,"width":1858.6325036603218,"height":700.5270863836017,"type":"parallel_coordinate","id":"parallel_coordinate-1"},{"x":277.3367496339678,"y":98.37188872620789,"width":1813.9180087847726,"height":192.2723279648609,"type":"small_multiple","id":"small_multiple-2"},{"x":286.2796486090777,"y":305.5490483162518,"width":1854.161054172767,"height":696.0556368960467,"type":"small_multiple","id":"small_multiple-3"}],"relations":[{"vislist":[{"vislist":["parallel_coordinate-1",{"vislist":[{"vislist":["line_chart-0"],"relation":null,"id":"group-0"}],"relation":"repeated","id":"relation-0"}],"relation":null,"id":"group-1"}],"relation":"stacked","id":"relation-1"}]},"2839_3":{"comp":[["area_chart","area_chart",["repeated"]],["line_chart","table",["nested"]]],"visType":["area_chart","line_chart","table"],"compType":["repeated","nested"],"compressed_tree":[{"composite_pattern":"nested","visualization_type":[["line_chart"],["table"]]},{"composite_pattern":"repeated","visualization_type":[["area_chart"]]}],"coOccurrence":[["line_chart","table",["coOccurrence"]],["line_chart","area_chart",["coOccurrence"]],["table","area_chart",["coOccurrence"]]],"year":2016,"conference":["VAST"],"authors":["Jian Zhao","Michael Glueck","Simon Breslav","Fanny Chevalier","Azam Khan"],"title":"Annotation Graphs: A Graph-Based Visualization for Meta-Analysis of Data Based on User-Authored Annotations","doi":"10.1109/TVCG.2016.2598543","abstract":"User-authored annotations of data can support analysts in the activity of hypothesis generation and sensemaking, where it is not only critical to document key observations, but also to communicate insights between analysts. We present annotation graphs, a dynamic graph visualization that enables meta-analysis of data based on user-authored annotations. The annotation graph topology encodes annotation semantics, which describe the content of and relations between data selections, comments, and tags. We present a mixed-initiative approach to graph layout that integrates an analyst\'s manual manipulations with an automatic method based on similarity inferred from the annotation semantics. Various visual graph layout styles reveal different perspectives on the annotation semantics. Annotation graphs are implemented within C8, a system that supports authoring annotations during exploratory analysis of a dataset. We apply principles of Exploratory Sequential Data Analysis (ESDA) in designing C8, and further link these to an existing task typology in the visualization literature. We develop and evaluate the system through an iterative user-centered design process with three experts, situated in the domain of analyzing HCI experiment data. The results suggest that annotation graphs are effective as a method of visually extending user-authored annotations to data meta-analysis for discovery and organization of ideas.","keywords":"Externalization user-authored annotation;exploratory sequential data analysis;graph-based visualization","caption":"Fig. 3. The front-end interface of the C8 data annotation system: a) Grid View, b) Timeline View, c) Context View, d) Comments View, and e) Annotation Graph View. This particular snapshot features the use of C8 to analyze the results of an HCI user study that records participants pointing at a target on a tabletop display with different experimental conditions.","img_size":{"width":2154,"height":1283},"subfigures":[{"x":15.275794442531756,"y":20.00435636520275,"width":2128.7060578067544,"height":1250.0011097275637,"type":"interface","id":"interface-0"}],"visualizations":[{"x":1177.4985358711565,"y":834.0439238653003,"width":969.2942898975107,"height":439.56368960468524,"type":"area_chart","id":"area_chart-0"},{"x":491.85431918008766,"y":101.43777452415813,"width":892.276720351391,"height":554.1508052708638,"type":"graph","id":"graph-1"},{"x":1234.5036403130719,"y":711.94289897511,"width":906.8435860342921,"height":122.10102489019036,"type":"line_chart","id":"line_chart-4"},{"x":1446.1207906295754,"y":95.80234260614934,"width":691.2796486090779,"height":550.3938506588581,"type":"line_chart","id":"line_chart-5"},{"x":780.8816214876185,"y":816.0175938713253,"width":381.3410539410071,"height":449.59584092795626,"type":"line_chart","id":"line_chart-7"},{"x":377.2672035139092,"y":666.8594436310395,"width":796.4743777452417,"height":601.112737920937,"type":"table","id":"table-6"}],"relations":[{"vislist":[{"vislist":["line_chart-7"],"relation":null,"id":"group-0"},{"vislist":["table-6"],"relation":null,"id":"group-1"}],"relation":"nested","id":"relation-0"},{"vislist":[{"vislist":["area_chart-0"],"relation":null,"id":"group-2"}],"relation":"repeated","id":"relation-1"}]},"2840_0":{"comp":[["bar_chart","bar_chart",["repeated"]],["proportional_area_chart","flow_diagram",["nested"]]],"visType":["bar_chart","proportional_area_chart","flow_diagram"],"compType":["repeated","nested"],"compressed_tree":[{"composite_pattern":"repeated","visualization_type":[["bar_chart"]]},{"composite_pattern":"nested","visualization_type":[["proportional_area_chart"],["flow_diagram"]]}],"coOccurrence":[],"year":2016,"conference":["VAST"],"authors":["Aritra Dasgupta","Joon-Yong Lee","Ryan Wilson","Robert A. Lafrance","Nick Cramer","Kristin A. Cook","Samuel H. Payne"],"title":"Familiarity Vs Trust: A Comparative Study of Domain Scientists\' Trust in Visual Analytics and Conventional Analysis Methods","doi":"10.1109/TVCG.2016.2598544","abstract":"Combining interactive visualization with automated analytical methods like statistics and data mining facilitates data-driven discovery. These visual analytic methods are beginning to be instantiated within mixed-initiative systems, where humans and machines collaboratively influence evidence-gathering and decision-making. But an open research question is that, when domain experts analyze their data, can they completely trust the outputs and operations on the machine-side? Visualization potentially leads to a transparent analysis process, but do domain experts always trust what they see? To address these questions, we present results from the design and evaluation of a mixed-initiative, visual analytics system for biologists, focusing on analyzing the relationships between familiarity of an analysis medium and domain experts\' trust. We propose a trust-augmented design of the visual analytics system, that explicitly takes into account domain-specific tasks, conventions, and preferences. For evaluating the system, we present the results of a controlled user study with 34 biologists where we compare the variation of the level of trust across conventional and visual analytic mediums and explore the influence of familiarity and task complexity on trust. We find that despite being unfamiliar with a visual analytic medium, scientists seem to have an average level of trust that is comparable with the same in conventional analysis medium. In fact, for complex sense-making tasks, we find that the visual analytic system is able to inspire greater trust than other mediums. We summarize the implications of our findings with directions for future research on trustworthiness of visual analytic systems.","keywords":"trust;transparency;familiarity;uncertainty;biological data analysis","caption":"Fig. 1. Representing the different stages in the visual analytic work\ufb02ow. The Active Data Biology system provides an end-to-end, transparent visual analytic work\ufb02ow for biologists to seamlessly shift between veri\ufb01cation of alternative hypotheses and generation of scienti\ufb01c knowledge. There are main views (Heatmap, Pathway, and Canvas viewers) to display data in different visual contexts integrated in a work\ufb02ow that seamlessly connects hypotheses, reasoning, and evidences of \ufb01ndings for inspiring a high level of trust in domain experts. Tutorials online at https: //adbio.pnnl.gov demonstrate the tool\u2019s use.","img_size":{"width":1724,"height":1801},"subfigures":[{"x":418.1840469921576,"y":36.01824737659635,"width":799.1601862023289,"height":548.1662880863734,"type":"single","id":"single-0"},{"x":1235.9424178212546,"y":14.193867869947471,"width":473.5164073363043,"height":581.97507029,"type":"single","id":"single-1"},{"x":415.769399003733,"y":592.1509032228754,"width":803.9894821791788,"height":545.3583616841397,"type":"single","id":"single-2"},{"x":414.29395337735394,"y":1170.43203675536,"width":1212.4357559098119,"height":608.9532190182836,"type":"single","id":"single-3"},{"x":1382.2993057035662,"y":803.7663978879406,"width":308.5951157465237,"height":343.52685057159096,"type":"single","id":"single-4"}],"visualizations":[{"x":1413.5084865629422,"y":891.5841584158418,"width":254.7383309759548,"height":226.71711456859987,"type":"bar_chart","id":"bar_chart-0"},{"x":1258.1181046676102,"y":300.59123055162667,"width":422.86562942008504,"height":267.47524752475255,"type":"bar_chart","id":"bar_chart-1"},{"x":1258.1181046676102,"y":669.9618104667612,"width":257.2857142857142,"height":234.35926449787837,"type":"bar_chart","id":"bar_chart-2"},{"x":412.38684582744014,"y":598.6350777934938,"width":771.8571428571429,"height":522.2135785007073,"type":"flow_diagram","id":"flow_diagram-3"},{"x":524.4717114568602,"y":1159.0594059405942,"width":1026.595473833098,"height":616.4667609618108,"type":"flow_diagram","id":"flow_diagram-4"},{"x":180.57496463932128,"y":152.84299858557287,"width":203.7906647807638,"height":1490.2192362093356,"type":"flow_diagram","id":"flow_diagram-5"},{"x":195.8592644978785,"y":799.878359264498,"width":152.842998585573,"height":152.84299858557281,"type":"graph","id":"graph-6"},{"x":417.48161244695916,"y":38.21074964639322,"width":789.6888260254601,"height":527.3083451202264,"type":"heatmap","id":"heatmap-7"},{"x":523.5517029521324,"y":1163.2139634892653,"width":1030.7834733491536,"height":620.9293713480537,"type":"proportional_area_chart","id":"proportional_area_chart-9"}],"relations":[{"vislist":[{"vislist":["bar_chart-1"],"relation":null,"id":"group-0"}],"relation":"repeated","id":"relation-0"},{"vislist":[{"vislist":["proportional_area_chart-9"],"relation":null,"id":"group-1"},{"vislist":["flow_diagram-4"],"relation":null,"id":"group-2"}],"relation":"nested","id":"relation-1"}]},"2842_0":{"comp":[["matrix","matrix",["repeated"]],["line_chart","area_chart",["accompanied"]],["area_chart","line_chart",["accompanied"]],["area_chart","bar_chart",["nested"]],["bar_chart","others",["nested"]],["comb","comb",["stacked"]]],"visType":["matrix","line_chart","area_chart","bar_chart","others","comb"],"compType":["repeated","accompanied","nested","stacked"],"compressed_tree":[{"composite_pattern":"repeated","visualization_type":[["matrix"]]},{"composite_pattern":"stacked","visualization_type":[[{"composite_pattern":"nested","visualization_type":[["area_chart"],["bar_chart"]]},{"composite_pattern":"accompanied","visualization_type":[["line_chart","area_chart"]]}]]},{"composite_pattern":"nested","visualization_type":[["bar_chart"],["others"]]}],"coOccurrence":[["area_chart","bar_chart",["coOccurrence"]],["area_chart","matrix",["coOccurrence"]],["area_chart","line_chart",["coOccurrence"]],["area_chart","others",["coOccurrence"]],["bar_chart","matrix",["coOccurrence"]],["bar_chart","line_chart",["coOccurrence"]],["bar_chart","others",["coOccurrence"]],["matrix","line_chart",["coOccurrence"]],["matrix","others",["coOccurrence"]],["line_chart","others",["coOccurrence"]]],"year":2016,"conference":["VAST"],"authors":["Panpan Xu","Honghui Mei","Liu Ren","Wei Che"],"title":"ViDX: Visual Diagnostics of Assembly Line Performance in Smart Factories","doi":"10.1109/TVCG.2016.2598664","abstract":"Visual analytics plays a key role in the era of connected industry (or industry 4.0, industrial internet) as modern machines and assembly lines generate large amounts of data and effective visual exploration techniques are needed for troubleshooting, process optimization, and decision making. However, developing effective visual analytics solutions for this application domain is a challenging task due to the sheer volume and the complexity of the data collected in the manufacturing processes. We report the design and implementation of a comprehensive visual analytics system, ViDX. It supports both real-time tracking of assembly line performance and historical data exploration to identify inefficiencies, locate anomalies, and form hypotheses about their causes and effects. The system is designed based on a set of requirements gathered through discussions with the managers and operators from manufacturing sites. It features interlinked views displaying data at different levels of detail. In particular, we apply and extend the Marey\'s graph by introducing a time-aware outlier-preserving visual aggregation technique to support effective troubleshooting in manufacturing processes. We also introduce two novel interaction techniques, namely the quantiles brush and samples brush, for the users to interactively steer the outlier detection algorithms. We evaluate the system with example use cases and an in-depth user interview, both conducted together with the managers and operators from manufacturing plants. The result demonstrates its effectiveness and reports a successful pilot application of visual analytics for manufacturing in smart factories.","keywords":"Temporal Data;Marey\'s Graph;Visual Analytics;Manufacturing;Smart Factory;Connected Industry;Industry 4.0","caption":"Fig. 1. A screenshot of the ViDX system for historical analysis and real-time tracking of assembly line performance. The historical data analysis panel consists of an extended Marey\u2019s graph (A) for troubleshooting inefficiencies and faults on the assembly lines. It is linked with a calendar based visualization (B) and a timeline (C) for multi-scale temporal exploration. Supplementary views include small multi- ples of histograms (D) showing the distribution of the cycle times on each station and a map (E) showing the assembly line schema. The real-time monitoring panel consists of a radial graph (F) and an explorable 3D station model visualization (G). (H) shows the fault codes.","img_size":{"width":1986,"height":1293},"subfigures":[{"x":6.469551416873139,"y":11.414328286909251,"width":1965.998520260298,"height":1273.7035727473626,"type":"interface","id":"interface-0"}],"visualizations":[{"x":379.55323203087784,"y":195.6769616009187,"width":1602.0311462987659,"height":1092.9327370189126,"type":"area_chart","id":"area_chart-0"},{"x":107.08982719128619,"y":142.81296488603525,"width":268.63168005842795,"height":1141.0903223720834,"type":"area_chart","id":"area_chart-1"},{"x":1129.2596895193346,"y":961.4807906379122,"width":770.9468088158553,"height":316.675876801404,"type":"bar_chart","id":"bar_chart-13"},{"x":392.58415435139585,"y":129.45266830870287,"width":1548.607142857143,"height":49.64999999999998,"type":"bar_chart","id":"bar_chart-2"},{"x":1141.7619353136479,"y":548.1908951996389,"width":389.33140809913874,"height":354.1315821614085,"type":"bar_chart","id":"bar_chart-3"},{"x":114.89942528735627,"y":148.6206778438612,"width":255.13218390804602,"height":1131.9942528735633,"type":"bar_chart","id":"bar_chart-4"},{"x":379.721748396217,"y":203.05970339616428,"width":1601.8626299334278,"height":1085.524674933481,"type":"heatmap","id":"heatmap-5"},{"x":380.83744851689846,"y":191.04604615234186,"width":1600.7469298127462,"height":1097.5383321773033,"type":"line_chart","id":"line_chart-7"},{"x":371.19285714285724,"y":9.324999999999989,"width":1144.314285714286,"height":113.48571428571431,"type":"matrix","id":"matrix-8"},{"x":1143.1695074154793,"y":548.4951881981156,"width":391.7739219524169,"height":356.7260577176271,"type":"others","id":"others-12"}],"relations":[{"vislist":[{"vislist":["matrix-8"],"relation":null,"id":"group-2"}],"relation":"repeated","id":"relation-1"},{"vislist":[{"vislist":[{"vislist":[{"vislist":["area_chart-1"],"relation":null,"id":"group-0"},{"vislist":["bar_chart-4"],"relation":null,"id":"group-1"}],"relation":"nested","id":"relation-0"},{"vislist":[{"vislist":["line_chart-7","area_chart-0"],"relation":null,"id":"group-3"}],"relation":"accompanied","id":"relation-2"}],"relation":null,"id":"group-6"}],"relation":"stacked","id":"relation-4"},{"vislist":[{"vislist":["bar_chart-3"],"relation":null,"id":"group-8"},{"vislist":["others-12"],"relation":null,"id":"group-9"}],"relation":"nested","id":"relation-5"}]},"2843_4":{"comp":[["bar_chart","bar_chart",["repeated"]],["others","others",["repeated"]]],"visType":["bar_chart","others"],"compType":["repeated"],"compressed_tree":[{"composite_pattern":"repeated","visualization_type":[["bar_chart"]]},{"composite_pattern":"repeated","visualization_type":[["others"]]}],"coOccurrence":[["bar_chart","others",["coOccurrence"]]],"year":2016,"conference":["VAST"],"authors":["Kuno Kurzhals","Marcel Hlawatsch","Christof Seeger","Daniel Weiskopf"],"title":"Visual Analytics for Mobile Eye Tracking","doi":"10.1109/TVCG.2016.2598695","abstract":"The analysis of eye tracking data often requires the annotation of areas of interest (AOIs) to derive semantic interpretations of human viewing behavior during experiments. This annotation is typically the most time-consuming step of the analysis process. Especially for data from wearable eye tracking glasses, every independently recorded video has to be annotated individually and corresponding AOIs between videos have to be identified. We provide a novel visual analytics approach to ease this annotation process by image-based, automatic clustering of eye tracking data integrated in an interactive labeling and analysis system. The annotation and analysis are tightly coupled by multiple linked views that allow for a direct interpretation of the labeled data in the context of the recorded video stimuli. The components of our analytics environment were developed with a user-centered design approach in close cooperation with an eye tracking expert. We demonstrate our approach with eye tracking data from a real experiment and compare it to an analysis of the data by manual annotation of dynamic AOIs. Furthermore, we conducted an expert user study with 6 external eye tracking researchers to collect feedback and identify analysis strategies they used while working with our application.","keywords":"Eye tracking;visual analytics;video visualization","caption":"Fig. 5: Overview: Our implementation consists of a main view with four different elements: a the cluster view lists all clusters in the data sorted by their accumulated duration. a1 To the left of each cluster representative, the cluster elements are shown. a2 To the right, attention histograms for the clusters are shown. a3 The total attention of the labeled clusters is shown in the histogram on the left. b The timeline overview at the top shows the clusters that are viewed by the majority of the participants. c The scarf plot at the bottom displays for each participant over time which cluster was investigated. d A tooltip shows additional information when hovering over scarf plot segments.","img_size":{"width":2151,"height":1340},"subfigures":[{"x":18.756484769352156,"y":19.064196833037222,"width":2120.808142550272,"height":1305.5322306884389,"type":"interface","id":"interface-0"}],"visualizations":[{"x":701.8862928348909,"y":281.77570093457945,"width":509.28348909657313,"height":135.66978193146417,"type":"bar_chart","id":"bar_chart-0"},{"x":1344.7523364485983,"y":217.07165109034267,"width":515.5451713395637,"height":212.89719626168224,"type":"others","id":"others-1"},{"x":1363.53738317757,"y":432.0560747663552,"width":492.58566978193136,"height":158.62928348909654,"type":"others","id":"others-2"},{"x":1363.53738317757,"y":596.9470404984423,"width":488.4112149532707,"height":154.4548286604362,"type":"others","id":"others-3"},{"x":1371.8862928348906,"y":768.0996884735202,"width":484.23676012461056,"height":146.10591900311522,"type":"others","id":"others-4"},{"x":1371.8862928348906,"y":891.2461059190032,"width":519.7196261682243,"height":179.5015576323989,"type":"others","id":"others-5"},{"x":683.101246105919,"y":928.8161993769471,"width":525.981308411215,"height":133.58255451713399,"type":"bar_chart","id":"bar_chart-6"},{"x":724.8457943925233,"y":763.9252336448599,"width":484.23676012461044,"height":133.58255451713387,"type":"bar_chart","id":"bar_chart-7"},{"x":714.4096573208724,"y":613.6448598130843,"width":494.67289719626154,"height":102.27414330218063,"type":"bar_chart","id":"bar_chart-8"},{"x":658.0545171339564,"y":411.18380062305295,"width":546.8535825545172,"height":164.8909657320873,"type":"bar_chart","id":"bar_chart-9"},{"x":46.49688473520241,"y":496.76012461059184,"width":379.8753894080997,"height":327.6947040498443,"type":"bar_chart","id":"bar_chart-10"}],"relations":[{"vislist":[{"vislist":["bar_chart-0","bar_chart-6","bar_chart-7","bar_chart-8","bar_chart-9"],"relation":null,"id":"group-0"}],"relation":"repeated","id":"relation-0"},{"vislist":[{"vislist":["others-1","others-2","others-3","others-4","others-5"],"relation":null,"id":"group-1"}],"relation":"repeated","id":"relation-1"}]},"2844_2":{"comp":[["line_chart","line_chart",["repeated"]],["matrix","matrix",["repeated"]],["scivis","scivis",["repeated"]]],"visType":["line_chart","matrix","scivis"],"compType":["repeated"],"compressed_tree":[{"composite_pattern":"repeated","visualization_type":[["line_chart"]]},{"composite_pattern":"repeated","visualization_type":[["matrix"]]},{"composite_pattern":"repeated","visualization_type":[["scivis"]]}],"coOccurrence":[["line_chart","matrix",["coOccurrence"]],["line_chart","scivis",["coOccurrence"]],["matrix","scivis",["coOccurrence"]]],"year":2016,"conference":["VAST"],"authors":["Hyunjoo Song","Jeongjin Lee","Tae Jung Kim","Kyoung Ho Lee","Bo Hyoung Kim","Jinwook Seo"],"title":"GazeDx: Interactive Visual Analytics Framework for Comparative Gaze Analysis with Volumetric Medical Images","doi":"10.1109/TVCG.2016.2598796","abstract":"We present an interactive visual analytics framework, GazeDx (abbr. of GazeDiagnosis), for the comparative analysis of gaze data from multiple readers examining volumetric images while integrating important contextual information with the gaze data. Gaze pattern comparison is essential to understanding how radiologists examine medical images, and to identifying factors influencing the examination. Most prior work depended upon comparisons with manually juxtaposed static images of gaze tracking results. Comparative gaze analysis with volumetric images is more challenging due to the additional cognitive load on 3D perception. A recent study proposed a visualization design based on direct volume rendering (DVR) for visualizing gaze patterns in volumetric images; however, effective and comprehensive gaze pattern comparison is still challenging due to a lack of interactive visualization tools for comparative gaze analysis. We take the challenge with GazeDx while integrating crucial contextual information such as pupil size and windowing into the analysis process for more in-depth and ecologically valid findings. Among the interactive visualization components in GazeDx, a context-embedded interactive scatterplot is especially designed to help users examine abstract gaze data in diverse contexts by embedding medical imaging representations well known to radiologists in it. We present the results from two case studies with two experienced radiologists, where they compared the gaze patterns of 14 radiologists reading two patients\' volumetric CT images.","keywords":"Eye tracking;gaze visualization;gaze pattern comparison;volumetric medical images;context-embedded interactive scatterplot;interactive temporal chart","caption":"Fig. 2. GazeDx interface for chest normal case (Overview tab). (A) Similarity matrix showing pairwise similarity between readers computed with SSIM (Structural Similarity). (B) Correlation matrix showing correlation between each pair of dimensions. Background of each cell in both matrices is color coded by its magnitude. (C) Multi-temporal view with interactive temporal charts. (D) Spatial view showing gaze data superimposed on 2D MPR (axial, coronal, and sagittal) or 3D VR images.","img_size":{"width":2157,"height":1149},"subfigures":[{"x":4.845221029724141,"y":16.39009653009782,"width":2131.617296220875,"height":1127.2057777171744,"type":"interface","id":"interface-0"}],"visualizations":[{"x":8.2476635514019,"y":68.00934579439252,"width":406.26635514018693,"height":474.2757009345794,"type":"heatmap","id":"heatmap-0"},{"x":11.827102803738342,"y":538.7056074766355,"width":408.05607476635504,"height":424.163551401869,"type":"heatmap","id":"heatmap-1"},{"x":447.3110331528621,"y":66.03269127741464,"width":323.6412335831512,"height":1078.2114305718435,"type":"line_chart","id":"line_chart-2"},{"x":6.457943925233678,"y":71.58878504672896,"width":409.5914046809009,"height":471.6120013149076,"type":"matrix","id":"matrix-3"},{"x":14.671048340200457,"y":536.8632342521745,"width":403.4908176357549,"height":422.5034739641411,"type":"matrix","id":"matrix-4"},{"x":781.5148535851168,"y":69.99689552179838,"width":1358.3486687947138,"height":1054.1461675405321,"type":"scivis","id":"scivis-5"}],"relations":[{"vislist":[{"vislist":["line_chart-2"],"relation":null,"id":"group-1"}],"relation":"repeated","id":"relation-1"},{"vislist":[{"vislist":["matrix-3","matrix-4"],"relation":null,"id":"group-2"}],"relation":"repeated","id":"relation-2"},{"vislist":[{"vislist":["scivis-5"],"relation":null,"id":"group-3"}],"relation":"repeated","id":"relation-3"}]},"2844_5":{"comp":[["comb","comb",["repeated"]],["comb","bar_chart",["stacked"]],["scatterplot","matrix",["nested"]],["scatterplot","bar_chart",["stacked"]],["others","scatterplot",["nested"]],["scivis","comb",["large_view"]],["bar_chart","scatterplot",["stacked"]],["bar_chart","comb",["stacked"]]],"visType":["comb","bar_chart","scatterplot","matrix","others","scivis"],"compType":["repeated","stacked","nested","large_view"],"compressed_tree":[{"composite_pattern":"repeated","visualization_type":[[{"composite_pattern":"stacked","visualization_type":[["bar_chart","scatterplot"]]}]]},{"composite_pattern":"repeated","visualization_type":[[{"composite_pattern":"stacked","visualization_type":[["bar_chart","scatterplot"]]}]]},{"composite_pattern":"repeated","visualization_type":[[{"composite_pattern":"nested","visualization_type":[["scatterplot"],["matrix"]]}]]},{"composite_pattern":"large_view","visualization_type":[["scivis"],[{"composite_pattern":"stacked","visualization_type":[["bar_chart",{"composite_pattern":"nested","visualization_type":[["others"],["scatterplot"]]}]]}]]}],"coOccurrence":[["bar_chart","scatterplot",["coOccurrence"]],["bar_chart","others",["coOccurrence"]],["bar_chart","matrix",["coOccurrence"]],["bar_chart","scivis",["coOccurrence"]],["scatterplot","others",["coOccurrence"]],["scatterplot","matrix",["coOccurrence"]],["scatterplot","scivis",["coOccurrence"]],["others","matrix",["coOccurrence"]],["others","scivis",["coOccurrence"]],["matrix","scivis",["coOccurrence"]]],"year":2016,"conference":["VAST"],"authors":["Hyunjoo Song","Jeongjin Lee","Tae Jung Kim","Kyoung Ho Lee","Bo Hyoung Kim","Jinwook Seo"],"title":"GazeDx: Interactive Visual Analytics Framework for Comparative Gaze Analysis with Volumetric Medical Images","doi":"10.1109/TVCG.2016.2598796","abstract":"We present an interactive visual analytics framework, GazeDx (abbr. of GazeDiagnosis), for the comparative analysis of gaze data from multiple readers examining volumetric images while integrating important contextual information with the gaze data. Gaze pattern comparison is essential to understanding how radiologists examine medical images, and to identifying factors influencing the examination. Most prior work depended upon comparisons with manually juxtaposed static images of gaze tracking results. Comparative gaze analysis with volumetric images is more challenging due to the additional cognitive load on 3D perception. A recent study proposed a visualization design based on direct volume rendering (DVR) for visualizing gaze patterns in volumetric images; however, effective and comprehensive gaze pattern comparison is still challenging due to a lack of interactive visualization tools for comparative gaze analysis. We take the challenge with GazeDx while integrating crucial contextual information such as pupil size and windowing into the analysis process for more in-depth and ecologically valid findings. Among the interactive visualization components in GazeDx, a context-embedded interactive scatterplot is especially designed to help users examine abstract gaze data in diverse contexts by embedding medical imaging representations well known to radiologists in it. We present the results from two case studies with two experienced radiologists, where they compared the gaze patterns of 14 radiologists reading two patients\' volumetric CT images.","keywords":"Eye tracking;gaze visualization;gaze pattern comparison;volumetric medical images;context-embedded interactive scatterplot;interactive temporal chart","caption":"Fig. 5. GazeDx interface for chest normal case (Comparison tab). (A) Scatter plot matrix. (B) CIS: context-embedded interactive scatter plot with gaze points grouped to five clusters. (C) Interactive temporal chart. (D) Aggregation pane showing aggregated gaze data for the readers in individual view panes. (E) ROI selection pane with \u201cSegmentation ROI\u201d filter and \u201cWindow preset\u201d filter. Interactive temporal charts in (C) and (F) clearly show the difference in gaze pattern between scanner and driller strategy (frequently changing color in (C), scanner; relatively consistent color in (F), driller). (G) CIS with horizontal axis of pupil diameter and vertical axis of slice index, where the gaze data is color-coded by window preset (left-shifted green cluster for lung, and right-shifted orange cluster for mediastinum setting). (H) CIS with embedded coronal plane image. ","img_size":{"width":2151,"height":1154},"subfigures":[{"x":5.86126155854918,"y":17.984301220753423,"width":2131.398577819247,"height":1122.7601593179425,"type":"interface","id":"interface-0"}],"visualizations":[{"x":487.6798776195113,"y":973.3911386520498,"width":300.80939549548583,"height":35.14892393017909,"type":"bar_chart","id":"bar_chart-0"},{"x":929.8710147919072,"y":974.3657646788745,"width":294.80386620991527,"height":35.79332993514526,"type":"bar_chart","id":"bar_chart-1"},{"x":955.1498934884007,"y":566.1232075063112,"width":228.66895768447353,"height":31.83998144973679,"type":"bar_chart","id":"bar_chart-10"},{"x":499.64543145743073,"y":560.4505453897934,"width":252.98426345064405,"height":34.055573926048275,"type":"bar_chart","id":"bar_chart-11"},{"x":796.0839357569178,"y":705.9080224562418,"width":33.79951697923581,"height":122.39522057632371,"type":"bar_chart","id":"bar_chart-12"},{"x":1788.8629550315031,"y":258.1901301413887,"width":270.06171301322837,"height":33.177991162787634,"type":"bar_chart","id":"bar_chart-13"},{"x":796.7844020862972,"y":1011.6277885914345,"width":32.54813796679093,"height":85.87168314642702,"type":"bar_chart","id":"bar_chart-14"},{"x":1358.9807293748645,"y":973.4449710797816,"width":294.52130729506706,"height":37.548533200964684,"type":"bar_chart","id":"bar_chart-2"},{"x":1788.4420778608992,"y":974.6183627423117,"width":292.3362631418336,"height":35.95323096410083,"type":"bar_chart","id":"bar_chart-3"},{"x":2071.5387658100935,"y":588.9426375156341,"width":30.46036860794381,"height":279.4918032876339,"type":"bar_chart","id":"bar_chart-39"},{"x":2080.1867539565806,"y":1008.9136597309993,"width":33.89149634908426,"height":86.33412754187766,"type":"bar_chart","id":"bar_chart-4"},{"x":1652.9268684300798,"y":1010.2508138929275,"width":33.534743755936006,"height":85.97737494872933,"type":"bar_chart","id":"bar_chart-5"},{"x":1223.236492552433,"y":1010.2736441587771,"width":34.56768781967298,"height":86.29119107577638,"type":"bar_chart","id":"bar_chart-6"},{"x":1652.734941614453,"y":596.0334931106094,"width":34.734525217894785,"height":310.68103111561373,"type":"bar_chart","id":"bar_chart-7"},{"x":1363.2805647986636,"y":566.1232075063112,"width":273.05196212956133,"height":30.875133527017507,"type":"bar_chart","id":"bar_chart-8"},{"x":1223.3776160043658,"y":663.5728477009602,"width":35.69937314061417,"height":173.67262608947362,"type":"bar_chart","id":"bar_chart-9"},{"x":446.10235790576587,"y":216.3953990837548,"width":386.03033662285844,"height":347.67617415234173,"type":"matrix","id":"matrix-42"},{"x":869.0026868314862,"y":208.94620742051643,"width":380.74026957916993,"height":358.782343999832,"type":"matrix","id":"matrix-43"},{"x":1298.8109102839803,"y":197.72196084163886,"width":369.22367389554387,"height":369.8541967206277,"type":"matrix","id":"matrix-44"},{"x":470.9437131063284,"y":594.7527544941863,"width":326.11859787912266,"height":332.8725333381578,"type":"scatterplot","id":"scatterplot-15"},{"x":444.33716475095775,"y":218.86205842394483,"width":383.32217958158986,"height":337.8306686790635,"type":"scatterplot","id":"scatterplot-16"},{"x":869.4102063857824,"y":208.76887665938443,"width":377.497377731332,"height":354.8823274524963,"type":"scatterplot","id":"scatterplot-17"},{"x":1296.8807591015832,"y":203.38696263850417,"width":367.5354455478798,"height":360.2642414733766,"type":"scatterplot","id":"scatterplot-18"},{"x":1327.9273082900493,"y":598.1990796059242,"width":322.87965005629553,"height":331.0538184121514,"type":"scatterplot","id":"scatterplot-20"},{"x":898.8332772276448,"y":598.6480106433363,"width":324.18890203368386,"height":328.0482937245612,"type":"scatterplot","id":"scatterplot-21"},{"x":914.8464103432735,"y":1007.7044912481923,"width":312.25323119368335,"height":111.16868963963587,"type":"scatterplot","id":"scatterplot-22"},{"x":485.1532938936186,"y":1010.935275017673,"width":312.32362176644006,"height":104.56954963798773,"type":"scatterplot","id":"scatterplot-23"},{"x":1770.7813653513394,"y":1011.1910090754118,"width":308.9477456663885,"height":105.59876757188327,"type":"scatterplot","id":"scatterplot-25"},{"x":1343.4239755274166,"y":1010.9414136164293,"width":309.1634173416891,"height":106.86516837373493,"type":"scatterplot","id":"scatterplot-26"},{"x":1740.4228769574431,"y":297.9447365380014,"width":332.2022766665821,"height":573.2793808399407,"type":"scatterplot","id":"scatterplot-38"},{"x":1788.1834209599815,"y":411.7013106291978,"width":289.2729807558376,"height":309.77264080940097,"type":"scivis","id":"scivis-19"},{"x":4.742649004286245,"y":342.94767712188764,"width":404.29885105638726,"height":396.32676103555707,"type":"scivis","id":"scivis-24"},{"x":444.33716475095775,"y":223.2835143626421,"width":1253.4827586206895,"height":707.4329501915707,"type":"small_multiple","id":"small_multiple-27"},{"x":480.7525088295268,"y":976.7569035357486,"width":1633.5217709451647,"height":146.12974308774642,"type":"small_multiple","id":"small_multiple-28"}],"relations":[{"vislist":[{"vislist":[{"vislist":[{"vislist":["bar_chart-3","scatterplot-25","bar_chart-4"],"relation":null,"id":"group-6"}],"relation":"stacked","id":"relation-6"},{"vislist":[{"vislist":["bar_chart-2","scatterplot-26","bar_chart-5"],"relation":null,"id":"group-5"}],"relation":"stacked","id":"relation-5"},{"vislist":[{"vislist":["bar_chart-1","scatterplot-22","bar_chart-6"],"relation":null,"id":"group-4"}],"relation":"stacked","id":"relation-4"},{"vislist":[{"vislist":["bar_chart-0","scatterplot-23","bar_chart-14"],"relation":null,"id":"group-3"}],"relation":"stacked","id":"relation-3"}],"relation":null,"id":"group-7"}],"relation":"repeated","id":"relation-7"},{"vislist":[{"vislist":[{"vislist":[{"vislist":["bar_chart-8","scatterplot-20","bar_chart-7"],"relation":null,"id":"group-2"}],"relation":"stacked","id":"relation-2"},{"vislist":[{"vislist":["bar_chart-10","scatterplot-21","bar_chart-9"],"relation":null,"id":"group-1"}],"relation":"stacked","id":"relation-1"},{"vislist":[{"vislist":["bar_chart-11","scatterplot-15","bar_chart-12"],"relation":null,"id":"group-0"}],"relation":"stacked","id":"relation-0"}],"relation":null,"id":"group-8"}],"relation":"repeated","id":"relation-8"},{"vislist":[{"vislist":[{"vislist":[{"vislist":["scatterplot-18"],"relation":null,"id":"group-16"},{"vislist":["matrix-44"],"relation":null,"id":"group-17"}],"relation":"nested","id":"relation-13"},{"vislist":[{"vislist":["scatterplot-17"],"relation":null,"id":"group-14"},{"vislist":["matrix-43"],"relation":null,"id":"group-15"}],"relation":"nested","id":"relation-12"},{"vislist":[{"vislist":["scatterplot-16"],"relation":null,"id":"group-12"},{"vislist":["matrix-42"],"relation":null,"id":"group-13"}],"relation":"nested","id":"relation-11"}],"relation":null,"id":"group-18"}],"relation":"repeated","id":"relation-14"},{"vislist":[{"vislist":["scivis-19"],"relation":null,"id":"group-22"},{"vislist":[{"vislist":[{"vislist":["bar_chart-13","bar_chart-39",{"vislist":[{"vislist":["others-19"],"relation":null,"id":"group-9"},{"vislist":["scatterplot-38"],"relation":null,"id":"group-10"}],"relation":"nested","id":"relation-9"}],"relation":null,"id":"group-11"}],"relation":"stacked","id":"relation-10"}],"relation":null,"id":"group-23"}],"relation":"large_view","id":"relation-15"}]},"2848_0":{"comp":[["comb","comb",["repeated"]],["scatterplot","map",["coordinated"]],["tree","matrix",["stacked"]],["matrix","tree",["stacked"]]],"visType":["comb","scatterplot","map","tree","matrix"],"compType":["repeated","coordinated","stacked"],"compressed_tree":[{"composite_pattern":"repeated","visualization_type":[[{"composite_pattern":"stacked","visualization_type":[["tree","matrix"]]}]]},{"composite_pattern":"repeated","visualization_type":[[{"composite_pattern":"coordinated","visualization_type":[["scatterplot"],["map"]]}]]}],"coOccurrence":[["tree","matrix",["coOccurrence"]],["tree","scatterplot",["coOccurrence"]],["tree","map",["coOccurrence"]],["matrix","scatterplot",["coOccurrence"]],["matrix","map",["coOccurrence"]],["scatterplot","map",["coOccurrence"]]],"year":2016,"conference":["VAST"],"authors":["Junpeng Wang","Xiaotong Liu","Han-Wei Shen","Guang Lin"],"title":"Multi-Resolution Climate Ensemble Parameter Analysis with Nested Parallel Coordinates Plots","doi":"10.1109/TVCG.2016.2598830","abstract":"Due to the uncertain nature of weather prediction, climate simulations are usually performed multiple times with different spatial resolutions. The outputs of simulations are multi-resolution spatial temporal ensembles. Each simulation run uses a unique set of values for multiple convective parameters. Distinct parameter settings from different simulation runs in different resolutions constitute a multi-resolution high-dimensional parameter space. Understanding the correlation between the different convective parameters, and establishing a connection between the parameter settings and the ensemble outputs are crucial to domain scientists. The multi-resolution high-dimensional parameter space, however, presents a unique challenge to the existing correlation visualization techniques. We present Nested Parallel Coordinates Plot (NPCP), a new type of parallel coordinates plots that enables visualization of intra-resolution and inter-resolution parameter correlations. With flexible user control, NPCP integrates superimposition, juxtaposition and explicit encodings in a single view for comparative data visualization and analysis. We develop an integrated visual analytics system to help domain scientists understand the connection between multi-resolution convective parameters and the large spatial temporal ensembles. Our system presents intricate climate ensembles with a comprehensive overview and on-demand geographic details. We demonstrate NPCP, along with the climate ensemble visualization system, based on real-world use-cases from our collaborators in computational and predictive science.","keywords":"Parallel coordinates plots;parameter analysis;multi-resolution climate ensembles","caption":"Fig. 1. The proposed visual analytics system: (A1) the nested parallel coordinates plot (NPCP) for analyzing multi-dimensional parameter correlations across resolutions; (A2) high-dimensional range query in NPCP with a set expression; (B1, B2) heat maps for ensemble quality overview and color legends for different quality levels; (B3) dendrograms for grouping similar ensemble members; (C1, C2, C3) geographic views for one ensemble item, one observation item and the difference between them; (C4) equation for calculating the difference between an ensemble item and an observation item; (C5) control widgets for ensemble exploration.","img_size":{"width":2148,"height":982},"subfigures":[{"x":27.42236709122543,"y":10.715997588469433,"width":2088.474809803353,"height":955.8914373729363,"type":"interface","id":"interface-0"}],"visualizations":[{"x":58.21229868228411,"y":716.0117130307466,"width":513.2855051244509,"height":244.42166910688138,"type":"heatmap","id":"heatmap-0"},{"x":575.8111273792094,"y":721.7628111273791,"width":504.6588579795021,"height":242.9838945827232,"type":"heatmap","id":"heatmap-1"},{"x":1087.6588579795023,"y":717.4494875549046,"width":513.2855051244509,"height":245.85944363103937,"type":"heatmap","id":"heatmap-2"},{"x":1642.6398243045385,"y":648.4363103953146,"width":304.8081991215227,"height":307.6837481698389,"type":"heatmap","id":"heatmap-3"},{"x":1636.8887262079063,"y":337.8770131771594,"width":303.3704245973645,"height":304.8081991215226,"type":"heatmap","id":"heatmap-4"},{"x":1632.575402635432,"y":7.1888726207906295,"width":313.43484626647137,"height":332.125915080527,"type":"heatmap","id":"heatmap-5"},{"x":1635.450951683748,"y":7.1888726207906295,"width":306.2459736456808,"height":329.25036603221076,"type":"map","id":"map-10"},{"x":1642.6398243045385,"y":346.5036603221083,"width":296.1815519765739,"height":296.1815519765739,"type":"map","id":"map-11"},{"x":1642.6398243045385,"y":646.9985358711567,"width":303.3704245973645,"height":306.24597364568064,"type":"map","id":"map-12"},{"x":61.087847730600345,"y":716.0117130307466,"width":513.2855051244509,"height":248.73499267935577,"type":"matrix","id":"matrix-6"},{"x":574.3733528550512,"y":723.2005856515372,"width":510.40995607613473,"height":240.1083455344069,"type":"matrix","id":"matrix-7"},{"x":1087.6588579795023,"y":717.4494875549046,"width":511.8477306002929,"height":244.42166910688138,"type":"matrix","id":"matrix-8"},{"x":30.8945827232797,"y":8.626647144948754,"width":1492.4099560761344,"height":467.2767203513908,"type":"parallel_coordinate","id":"parallel_coordinate-9"},{"x":1635.144254470269,"y":6.611379953060658,"width":313.87053072469644,"height":334.5907755272754,"type":"scatterplot","id":"scatterplot-20"},{"x":1644.547956190071,"y":339.61069763003525,"width":300.74713403838643,"height":302.77860473992814,"type":"scatterplot","id":"scatterplot-21"},{"x":1638.9341695606968,"y":640.4752547598566,"width":311.9747072971347,"height":314.41192188201694,"type":"scatterplot","id":"scatterplot-22"},{"x":190.48755490483168,"y":563.6076134699853,"width":376.69692532942884,"height":163.90629575402636,"type":"tree","id":"tree-13"},{"x":574.3733528550512,"y":590.9253294289897,"width":508.97218155197663,"height":135.15080527086374,"type":"tree","id":"tree-14"},{"x":1087.6588579795023,"y":599.5519765739384,"width":508.9721815519766,"height":126.52415812591505,"type":"tree","id":"tree-15"}],"relations":[{"vislist":[{"vislist":[{"vislist":[{"vislist":["tree-15","matrix-8"],"relation":null,"id":"group-2"}],"relation":"stacked","id":"relation-2"},{"vislist":[{"vislist":["tree-14","matrix-7"],"relation":null,"id":"group-1"}],"relation":"stacked","id":"relation-1"},{"vislist":[{"vislist":["tree-13","matrix-6"],"relation":null,"id":"group-0"}],"relation":"stacked","id":"relation-0"}],"relation":null,"id":"group-3"}],"relation":"repeated","id":"relation-3"},{"vislist":[{"vislist":[{"vislist":[{"vislist":["scatterplot-22"],"relation":null,"id":"group-8"},{"vislist":["map-12"],"relation":null,"id":"group-9"}],"relation":"coordinated","id":"relation-6"},{"vislist":[{"vislist":["scatterplot-21"],"relation":null,"id":"group-6"},{"vislist":["map-11"],"relation":null,"id":"group-7"}],"relation":"coordinated","id":"relation-5"},{"vislist":[{"vislist":["scatterplot-20"],"relation":null,"id":"group-4"},{"vislist":["map-10"],"relation":null,"id":"group-5"}],"relation":"coordinated","id":"relation-4"}],"relation":null,"id":"group-10"}],"relation":"repeated","id":"relation-7"}]},"2854_0":{"comp":[["bar_chart","bar_chart",["repeated"]],["bar_chart","matrix",["stacked"]],["others","others",["repeated"]],["matrix","bar_chart",["stacked"]]],"visType":["bar_chart","matrix","others"],"compType":["repeated","stacked"],"compressed_tree":[{"composite_pattern":"repeated","visualization_type":[["bar_chart"]]},{"composite_pattern":"stacked","visualization_type":[["bar_chart","matrix"]]},{"composite_pattern":"repeated","visualization_type":[["others"]]}],"coOccurrence":[["bar_chart","matrix",["coOccurrence"]]],"year":2016,"conference":["VAST"],"authors":["Ji Hwan Park","Saad Nadeem","Seyedkoosha Mirhosseini","Arie E. Kaufman"],"title":"C2A: Crowd consensus analytics for virtual colonoscopy","doi":"10.1109/VAST.2016.7883508","abstract":"We present a medical crowdsourcing visual analytics platform called C<sup>2</sup>A to visualize, classify and filter crowdsourced clinical data. More specifically, C<sup>2</sup>A is used to build consensus on a clinical diagnosis by visualizing crowd responses and filtering out anomalous activity. Crowdsourcing medical applications have recently shown promise where the non-expert users (the crowd) were able to achieve accuracy similar to the medical experts. This has the potential to reduce interpretation/reading time and possibly improve accuracy by building a consensus on the findings beforehand and letting the medical experts make the final diagnosis. In this paper, we focus on a virtual colonoscopy (VC) application with the clinical technicians as our target users, and the radiologists acting as consultants and classifying segments as benign or malignant. In particular, C<sup>2</sup>A is used to analyze and explore crowd responses on video segments, created from fly-throughs in the virtual colon. C<sup>2</sup>A provides several interactive visualization components to build crowd consensus on video segments, to detect anomalies in the crowd data and in the VC video segments, and finally, to improve the non-expert user\'s work quality and performance by A/B testing for the optimal crowdsourcing platform and application-specific parameters. Case studies and domain experts feedback demonstrate the effectiveness of our framework in improving workers\' output quality, the potential to reduce the radiologists\' interpretation time, and hence, the potential to improve the traditional clinical workflow by marking the majority of the video segments as benign based on the crowd consensus.","keywords":"","caption":"Figure 1: The C2 A system includes (A) Timeline Filtering View for selecting datasets within a specified time interval, (B) Aggregated Textual Information for displaying a textual summary of the crowd statistics and application specific performance, (C) Similarity View for displaying the overlap and Euclidean distance metric of the crowd demographics and video segment statistics, (D) Consensus Map for displaying the crowd consensus on polyp and polyp-free (benign) video segments along with aggregated crowd accuracy and timing, (E) Crowd View for displaying crowd demographics and rewards, (F) Video Segments View for displaying selected video segments, and (G) Word Cloud displaying keywords from user comments.","img_size":{"width":1893,"height":974},"subfigures":[{"x":10.480266171949411,"y":22.77907838981752,"width":1859.6650217973433,"height":942.1814930523178,"type":"interface","id":"interface-0"}],"visualizations":[{"x":18.846998535871194,"y":48.48609077598829,"width":1853.8799414348466,"height":52.76427525622255,"type":"bar_chart","id":"bar_chart-0"},{"x":24.551244509516867,"y":292.3426061493411,"width":242.43045387994147,"height":122.64128843338216,"type":"bar_chart","id":"bar_chart-1"},{"x":857.3711566617861,"y":138.32796486090777,"width":985.4084919472914,"height":49.912152269399684,"type":"bar_chart","id":"bar_chart-2"},{"x":788.9202049780382,"y":189.66617862371888,"width":58.468521229868195,"height":636.0234260614934,"type":"bar_chart","id":"bar_chart-3"},{"x":860.2232796486092,"y":186.81405563689603,"width":982.5563689604686,"height":636.0234260614934,"type":"matrix","id":"matrix-4"},{"x":804.5075690614034,"y":842.230520329669,"width":978.5980074601814,"height":117.06798759733807,"type":"scivis","id":"scivis-11"},{"x":322.5980966325037,"y":539.0512445095168,"width":406.42752562225473,"height":410.7057101024891,"type":"parallel_coordinate","id":"parallel_coordinate-5"},{"x":321.1720351390924,"y":541.9033674963398,"width":413.55783308931177,"height":405.0014641288433,"type":"sankey_diagram","id":"sankey_diagram-6"},{"x":335.43265007320645,"y":155.4407027818448,"width":383.61054172767206,"height":349.385065885798,"type":"scatterplot","id":"scatterplot-7"},{"x":14.56881405563692,"y":797.1683748169837,"width":290.9165446559297,"height":152.58857979502193,"type":"word_cloud","id":"word_cloud-8"}],"relations":[{"vislist":[{"vislist":["bar_chart-1"],"relation":null,"id":"group-0"}],"relation":"repeated","id":"relation-0"},{"vislist":[{"vislist":["bar_chart-2","matrix-4","bar_chart-3"],"relation":null,"id":"group-1"}],"relation":"stacked","id":"relation-1"},{"vislist":[{"vislist":["others-11"],"relation":null,"id":"group-2"}],"relation":"repeated","id":"relation-2"}]},"2856_0":{"comp":[["graph","graph",["repeated"]]],"visType":["graph"],"compType":["repeated"],"compressed_tree":[{"composite_pattern":"repeated","visualization_type":[["graph"]]}],"coOccurrence":[["graph","graph",["coOccurrence"]]],"year":2016,"conference":["VAST"],"authors":["Siming Chen","Shuai Chen","Zhenhuang Wang","Jie Liang","Xiaoru Yuan","Nan Cao","Yadong Wu"],"title":"D-Map: Visual Analysis of Ego-centric Information Diffusion Patterns in Social Media","doi":"10.1109/VAST.2016.7883510","abstract":"Popular social media platforms could rapidly propagate vital information over social networks among a significant number of people. In this work we present D-Map (Diffusion Map), a novel visualization method to support exploration and analysis of social behaviors during such information diffusion and propagation on typical social media through a map metaphor. In D-Map, users who participated in reposting (i.e., resending a message initially posted by others) one central user\'s posts (i.e., a series of original tweets) are collected and mapped to a hexagonal grid based on their behavior similarities and in chronological order of the repostings. With additional interaction and linking, D-Map is capable of providing visual portraits of the influential users and describing their social behaviors. A comprehensive visual analysis system is developed to support interactive exploration with D-Map. We evaluate our work with real world social media data and find interesting patterns among users. Key players, important information diffusion paths, and interactions among social communities can be identified.","keywords":"","caption":"Figure 1: System Interface: Source Weibo Table View (a), for selecting different groups of source weibos; Source Weibo Distribution View (b), including Documents View (b1) and Keywords View (b2); D-Map View (c), summarizing the social interaction among participating people of a central user; Community Radar View (d), showing the high dimensional features of communities with a Radar View (d1) and a Statistics Information Window (d2); Hierarchical View (e), illustrating the reposting structures; Timeline View (f), highlighting the temporal trends of the diffusion; Small Multiple View (g), identifying key time frames of D-Map\u2019s snapshots.","img_size":{"width":1950,"height":807},"subfigures":[{"x":24.88628076319155,"y":16.65778145532812,"width":1893.1457429214122,"height":779.3511313717225,"type":"interface","id":"interface-0"}],"visualizations":[{"x":791.5289562455418,"y":650.581060719103,"width":850.2678945335308,"height":145.27748011839788,"type":"matrix","id":"matrix-15"},{"x":544.6095076400679,"y":438.2623089983022,"width":216.8505942275042,"height":177.12224108658754,"type":"polar_plot","id":"polar_plot-0"},{"x":506.53650254668935,"y":47.600169779286944,"width":286.3752122241086,"height":283.06451612903226,"type":"scatterplot","id":"scatterplot-1"},{"x":849.1935483870967,"y":60.84295415959255,"width":776.3582342954161,"height":582.6825127334465,"type":"scatterplot","id":"scatterplot-2"},{"x":1666.935483870968,"y":60.84295415959256,"width":226.78268251273334,"height":158.9134125636672,"type":"scatterplot","id":"scatterplot-3"},{"x":1663.6247877758915,"y":247.8972835314092,"width":230.09337860780988,"height":163.8794567062819,"type":"scatterplot","id":"scatterplot-4"},{"x":1666.935483870968,"y":431.6409168081494,"width":226.78268251273334,"height":160.56876061120548,"type":"scatterplot","id":"scatterplot-5"},{"x":1665.2801358234296,"y":618.695246179966,"width":225.12733446519542,"height":160.56876061120548,"type":"scatterplot","id":"scatterplot-6"},{"x":44.694397283531416,"y":79.05178268251281,"width":448.59932088285234,"height":266.51103565365025,"type":"table","id":"table-7"},{"x":1665.2801358234296,"y":246.241935483871,"width":230.09337860780988,"height":165.53480475382005,"type":"graph","id":"graph-10"},{"x":1666.935483870968,"y":429.9855687606113,"width":223.47198641765704,"height":165.53480475382008,"type":"graph","id":"graph-11"},{"x":1665.2801358234296,"y":618.695246179966,"width":225.12733446519542,"height":162.22410865874372,"type":"graph","id":"graph-12"},{"x":847.5382003395586,"y":60.84295415959255,"width":776.3582342954159,"height":584.3378607809848,"type":"graph","id":"graph-13"},{"x":51.31578947368421,"y":438.2623089983022,"width":453.56536502546686,"height":364.43821840366985,"type":"tree","id":"tree-8"},{"x":1668.590831918506,"y":60.84295415959255,"width":226.78268251273334,"height":162.22410865874363,"type":"graph","id":"graph-9"},{"x":551.2308998302206,"y":332.3200339558574,"width":192.0203735144313,"height":74.49066213921901,"type":"word_cloud","id":"word_cloud-14"}],"relations":[{"vislist":[{"vislist":["graph-12","graph-11","graph-10","graph-9"],"relation":null,"id":"group-0"}],"relation":"repeated","id":"relation-0"}]},"2858_0":{"comp":[["comb","comb",["repeated"]],["line_chart","matrix",["nested"]],["proportional_area_chart","matrix",["nested"]]],"visType":["comb","line_chart","matrix","proportional_area_chart"],"compType":["repeated","nested"],"compressed_tree":[{"composite_pattern":"nested","visualization_type":[["line_chart"],["matrix"]]},{"composite_pattern":"repeated","visualization_type":[[{"composite_pattern":"nested","visualization_type":[["proportional_area_chart"],["matrix"]]}]]}],"coOccurrence":[["line_chart","matrix",["coOccurrence"]],["line_chart","proportional_area_chart",["coOccurrence"]],["matrix","proportional_area_chart",["coOccurrence"]]],"year":2016,"conference":["VAST"],"authors":["Fan Du","Catherine Plaisant","Neil Spring","Ben Shneiderman"],"title":"EventAction: Visual analytics for temporal event sequence recommendation","doi":"10.1109/VAST.2016.7883512","abstract":"Recommender systems are being widely used to assist people in making decisions, for example, recommending films to watch or books to buy. Despite its ubiquity, the problem of presenting the recommendations of temporal event sequences has not been studied. We propose EventAction, which to our knowledge, is the first attempt at a prescriptive analytics interface designed to present and explain recommendations of temporal event sequences. EventAction provides a visual analytics approach to (1) identify similar records, (2) explore potential outcomes, (3) review recommended temporal event sequences that might help achieve the users\' goals, and (4) interactively assist users as they define a personalized action plan associated with a probability of success. Following the design study framework, we designed and deployed EventAction in the context of student advising and reported on the evaluation with a student review manager and three graduate students.","keywords":"","caption":"Figure 1: EventAction provides a visual analytics approach for helping data analysts recommend actions to improve the outcome. The user interface consists of seven coordinated views, opening progressively as the analysis progresses: (a) workflow control panel, (b) current record timeline, (c) activity summary view, (d) outcome distribution view, (e) similarity distribution view, (f) similar archived record timelines, and (g) correlation view. Figures in this paper illustrate a synthetic dataset.","img_size":{"width":2115,"height":1146},"subfigures":[{"x":17.54869683969846,"y":22.50871384542008,"width":2084.5987979910155,"height":1107.2438790409092,"type":"interface","id":"interface-0"}],"visualizations":[{"x":24.741106719367565,"y":575.2648113348738,"width":371.4308300395257,"height":341.9881422924901,"type":"bar_chart","id":"bar_chart-0"},{"x":1592.9467982009053,"y":112.24535661573032,"width":514.8331479699395,"height":380.8996650905461,"type":"bar_chart","id":"bar_chart-9"},{"x":1594.2628458498023,"y":554.8814121253877,"width":495.9960474308303,"height":582.0592885375493,"type":"line_chart","id":"line_chart-1"},{"x":425.6146245059288,"y":104.18180738230465,"width":1139.2055335968378,"height":385.01976284584975,"type":"matrix","id":"matrix-2"},{"x":1594.2628458498023,"y":557.1462342597749,"width":491.46640316205526,"height":575.2648221343873,"type":"matrix","id":"matrix-3"},{"x":425.6146245059288,"y":559.4110563941623,"width":1143.7351778656125,"height":579.7944664031621,"type":"matrix","id":"matrix-4"},{"x":424.7375586816704,"y":99.14854928387578,"width":1142.3978648383832,"height":388.45156866190956,"type":"proportional_area_chart","id":"proportional_area_chart-10"},{"x":412.02569169960475,"y":557.1462342597749,"width":1159.588932806324,"height":584.1904916146717,"type":"proportional_area_chart","id":"proportional_area_chart-6"},{"x":1594.2628458498023,"y":552.6165899910003,"width":493.73122529644274,"height":575.2648221343874,"type":"small_multiple","id":"small_multiple-7"}],"relations":[{"vislist":[{"vislist":["line_chart-1"],"relation":null,"id":"group-0"},{"vislist":["matrix-3"],"relation":null,"id":"group-1"}],"relation":"nested","id":"relation-0"},{"vislist":[{"vislist":[{"vislist":[{"vislist":["proportional_area_chart-6"],"relation":null,"id":"group-4"},{"vislist":["matrix-4"],"relation":null,"id":"group-5"}],"relation":"nested","id":"relation-2"},{"vislist":[{"vislist":["proportional_area_chart-10"],"relation":null,"id":"group-2"},{"vislist":["matrix-2"],"relation":null,"id":"group-3"}],"relation":"nested","id":"relation-1"}],"relation":null,"id":"group-6"}],"relation":"repeated","id":"relation-3"}]},"2859_0":{"comp":[["comb","comb",["repeated"]],["proportional_area_chart","scatterplot",["nested"]],["others","pie_chart",["nested"]],["others","donut_chart",["nested"]]],"visType":["comb","proportional_area_chart","scatterplot","others","pie_chart","donut_chart"],"compType":["repeated","nested"],"compressed_tree":[{"composite_pattern":"repeated","visualization_type":[[{"composite_pattern":"nested","visualization_type":[["proportional_area_chart"],["scatterplot"]]}]]},{"composite_pattern":"nested","visualization_type":[["others"],["pie_chart"]]},{"composite_pattern":"repeated","visualization_type":[[{"composite_pattern":"nested","visualization_type":[["others"],["donut_chart"]]}]]}],"coOccurrence":[["proportional_area_chart","scatterplot",["coOccurrence"]]],"year":2016,"conference":["VAST"],"authors":["Xiaotong Liu","Anbang Xu","Liang Gou","Haibin Liu","Rama Akkiraju","Han-Wei Shen"],"title":"SocialBrands: Visual analysis of public perceptions of brands on social media","doi":"10.1109/VAST.2016.7883513","abstract":"Public perceptions of a brand is critical to its performance. While social media has demonstrated a huge potential to shape public perceptions of brands, existing tools are not intuitive and explanatory for domain users to use as they fail to provide a comprehensive analysis framework for perceptions of brands. In this paper, we present SocialBrands, a novel visual analysis tool for brand managers to understand public perceptions of brands on social media. Social-Brands leverages brand personality framework in marketing literature and social computing approaches to compute the personality of brands from three driving factors (user imagery, employee imagery, and official announcement) on social media, and construct an evidence network explaining the association between brand personality and driving factors. These computational results are then integrated with new interactive visualizations to help brand managers understand personality traits and their driving factors. We demonstrate the usefulness and effectiveness of SocialBrands through a series of user studies with brand managers in an enterprise context. Design lessons are also derived from our studies.","keywords":"","caption":"Figure 1: SocialBrands illustrates brand perceptions on social media with our designed visualizations. (a,b) The BrandWheels of two brands \u201cDisney\u201d and \u201cBoeing\u201d, each illustrates a brand\u2019s perceived personality (in 5 broad traits or 42 subtraits) with visual evidence and related details from three social media factors. (c) The Comparative BrandWheel highlights the similarities and differences of two brands in their perceived personalities and topic discussions on social media. (d) The Overview of brand perceptions: (1) BrandSediments visually summarize the distribution of brands over personality traits and the clusters of brands; (2) search and \ufb01ltering widgets; (3) MDS embedding of brand perceptions.","img_size":{"width":2097,"height":907},"subfigures":[{"x":1105.0630309052865,"y":45.45352447973142,"width":977.4201894968513,"height":816.0929510405361,"type":"interface","id":"interface-0"}],"visualizations":[{"x":5.322243291759177,"y":88.90248502899445,"width":515.9739995672373,"height":521.8119603175523,"type":"donut_chart","id":"donut_chart-15"},{"x":539.9396842362939,"y":74.41493240866424,"width":526.9544346251145,"height":550.7870655582125,"type":"donut_chart","id":"donut_chart-16"},{"x":5.270750988142242,"y":87.83200726301774,"width":512.6521739130435,"height":525.199604743083,"type":"heatmap","id":"heatmap-1"},{"x":544.8102766798421,"y":73.49208631440115,"width":521.6146245059289,"height":548.501976284585,"type":"heatmap","id":"heatmap-2"},{"x":356.59881422924894,"y":534.1620467887095,"width":354.913043478261,"height":365.66798418972326,"type":"heatmap","id":"heatmap-3"},{"x":7.063241106719315,"y":87.83200726301774,"width":510.85968379446643,"height":525.199604743083,"type":"others","id":"others-10"},{"x":28.57312252964422,"y":620.201572480409,"width":241.98616600790513,"height":245.5711462450594,"type":"others","id":"others-6"},{"x":356.59881422924894,"y":532.3695566701322,"width":354.913043478261,"height":369.25296442687755,"type":"others","id":"others-7"},{"x":790.3814229249015,"y":625.5790428361403,"width":245.57114624505925,"height":249.15612648221352,"type":"others","id":"others-8"},{"x":541.225296442688,"y":73.49208631440115,"width":526.99209486166,"height":546.7094861660079,"type":"others","id":"others-9"},{"x":352.9182159363296,"y":537.692198961597,"width":362.7393965134633,"height":353.7765452383881,"type":"donut_chart","id":"donut_chart-17"},{"x":1109.4446640316205,"y":98.5869479744802,"width":734.9209486166012,"height":772.5632411067195,"type":"proportional_area_chart","id":"proportional_area_chart-5"},{"x":1851.5355731225297,"y":596.899200938907,"width":222.26877470355726,"height":236.60869565217385,"type":"scatterplot","id":"scatterplot-11"},{"x":1113.029644268775,"y":95.00196773732604,"width":733.1284584980236,"height":772.5632411067193,"type":"scatterplot","id":"scatterplot-12"}],"relations":[{"vislist":[{"vislist":[{"vislist":[{"vislist":["proportional_area_chart-5"],"relation":null,"id":"group-0"},{"vislist":["scatterplot-12"],"relation":null,"id":"group-1"}],"relation":"nested","id":"relation-0"}],"relation":null,"id":"group-2"}],"relation":"repeated","id":"relation-1"},{"vislist":[{"vislist":["others-7"],"relation":null,"id":"group-5"},{"vislist":["pie_chart-17"],"relation":null,"id":"group-6"}],"relation":"nested","id":"relation-3"},{"vislist":[{"vislist":[{"vislist":[{"vislist":["others-9"],"relation":null,"id":"group-8"},{"vislist":["donut_chart-16"],"relation":null,"id":"group-9"}],"relation":"nested","id":"relation-4"},{"vislist":[{"vislist":["others-10"],"relation":null,"id":"group-3"},{"vislist":["donut_chart-15"],"relation":null,"id":"group-4"}],"relation":"nested","id":"relation-2"}],"relation":null,"id":"group-10"}],"relation":"repeated","id":"relation-5"}]},"2860_0":{"comp":[["comb","comb",["repeated"]],["scatterplot","graph",["nested"]],["bar_chart","graph",["nested"]],["line_chart","graph",["nested"]]],"visType":["comb","scatterplot","graph","bar_chart","line_chart"],"compType":["repeated","nested"],"compressed_tree":[{"composite_pattern":"nested","visualization_type":[["scatterplot","bar_chart","line_chart"],["graph"]]},{"composite_pattern":"repeated","visualization_type":[[{"composite_pattern":"nested","visualization_type":[["scatterplot","line_chart","bar_chart"],["graph"]]}]]}],"coOccurrence":[["scatterplot","bar_chart",["coOccurrence"]],["scatterplot","line_chart",["coOccurrence"]],["scatterplot","graph",["coOccurrence"]],["bar_chart","line_chart",["coOccurrence"]],["bar_chart","graph",["coOccurrence"]],["line_chart","graph",["coOccurrence"]]],"year":2016,"conference":["VAST"],"authors":["Jing Xia","Wei Che","Yumeng Hou","Wanqi Hu","Xinxin Huang","David S. Ebert"],"title":"DimScanner: A Relation-based Visual Exploration Approach Towards Data Dimension Inspection","doi":"10.1109/VAST.2016.7883514","abstract":"Exploring multi-dimensional datasets can be cumbersome if data analysts have little knowledge about the data. Various dimension relation inspection tools and dimension exploration tools have been proposed for efficient data examining and understanding. However, the needed workload varies largely with respect to data complexity and user expertise, which can only be reduced with rich background knowledge over the data. In this paper we address the workload challenge with a data structuring and exploration scheme that affords dimension relation detection and that serves as the background knowledge for further investigation. We contribute a novel data structuring scheme that leverages an information-theoretic view structuring algorithm to uncover information-aware relations among different data views, and thereby discloses redundancy and other relation patterns among dimensions. The integrated system, DimScanner, empowers analysts with rich user controls and assistance widgets to interactively detect the relations of multi-dimensional data.","keywords":"","caption":"Figure 1: The DimScanner interface on the Seattle 911 calls and responses dataset whose time span ranges from October 28, 2013 to February 14, 2014. (a) The categorization tree is structured with 16 1D views and 120 2D views contributed by 16 dimensions of the data. The tree structure indicates the clustering hierarchy of pair-wise view relations such that views on the same branch are more likely to be related than those far apart. (b) The dimension summary column summarizes the data types (by icons) of the dimensions. It indicates that the dataset contains eight categorical dimensions, six numeric dimensions and two time-related dimensions. (c) The view selector widget displays a matrix of all views. It highlights three groups of views selected by analysts with colors. (d) The view summary snapshots keep track of analysts\u2019 observations (three highlighted groups are shown in this case).","img_size":{"width":1998,"height":1034},"subfigures":[{"x":12.49094215029532,"y":16.444061728270043,"width":1955.6036815907285,"height":983.688326138624,"type":"interface","id":"interface-0"}],"visualizations":[{"x":1711.527177939276,"y":162.9604249750841,"width":64.32213722233473,"height":34.91773163498174,"type":"bar_chart","id":"bar_chart-0"},{"x":1703.7166327051355,"y":225.90423068551166,"width":65.7004687342419,"height":33.53940012307456,"type":"bar_chart","id":"bar_chart-1"},{"x":1896.7937841425903,"y":890.9332114421512,"width":65.10531468343197,"height":33.890437780416725,"type":"bar_chart","id":"bar_chart-2"},{"x":1824.553640452755,"y":956.0385261255834,"width":66.88902193503303,"height":31.21487690301535,"type":"bar_chart","id":"bar_chart-3"},{"x":674.1386215079782,"y":380.24507358835916,"width":72.06960664446899,"height":33.54964447242526,"type":"bar_chart","id":"bar_chart-4"},{"x":1097.388478563908,"y":708.1322622137311,"width":70.82702721956412,"height":39.76254159694838,"type":"bar_chart","id":"bar_chart-5"},{"x":1648.1452649743594,"y":426.1684282332293,"width":259.6353880961756,"height":243.35931888245923,"type":"bar_chart","id":"bar_chart-50"},{"x":1285.5627679559725,"y":423.51501221722197,"width":87.6468441991451,"height":90.6691491715295,"type":"bar_chart","id":"bar_chart-6"},{"x":1448.5652173913045,"y":73.56521739130436,"width":51.08695652173901,"height":49.04347826086956,"type":"bar_chart","id":"bar_chart-7"},{"x":975.4547045902495,"y":796.1983764869166,"width":32.489778453131294,"height":37.02323591170784,"type":"bar_chart","id":"bar_chart-8"},{"x":715.3031430247123,"y":287.4669994084079,"width":65.57709772879184,"height":30.446509659796217,"type":"bar_chart","id":"bar_chart-9"},{"x":1602.3903896144357,"y":120.63080094644596,"width":342.4920530255285,"height":216.8627201082263,"type":"graph","id":"graph-10"},{"x":1646.3829353836177,"y":433.78173278599877,"width":252.84833725313138,"height":234.2847884421419,"type":"graph","id":"graph-11"},{"x":1540.944187448215,"y":693.833560140254,"width":432.5490085132133,"height":306.79764727535127,"type":"graph","id":"graph-12"},{"x":536.6415872688011,"y":102.20813708857979,"width":840.3120232743852,"height":862.9397354446758,"type":"graph","id":"graph-13"},{"x":1792.5394410692268,"y":301.55269882360574,"width":65.1053146834322,"height":35.67414503201758,"type":"line_chart","id":"line_chart-14"},{"x":1896.7937841425903,"y":926.6073564741689,"width":65.99716830923262,"height":16.945218890208253,"type":"line_chart","id":"line_chart-15"},{"x":1643.5073544152656,"y":883.7983824357477,"width":64.21346105763178,"height":32.10673052881589,"type":"line_chart","id":"line_chart-16"},{"x":1003.4221691077067,"y":239.83359857413535,"width":173.96111948664907,"height":64.61413009504105,"type":"line_chart","id":"line_chart-17"},{"x":761.1191812513027,"y":454.7998390826374,"width":69.58444779465971,"height":33.54964447242526,"type":"line_chart","id":"line_chart-18"},{"x":665.4405655336458,"y":693.3750886643276,"width":70.82702721956423,"height":39.76254159694838,"type":"line_chart","id":"line_chart-19"},{"x":1097.388478563908,"y":746.6522243857747,"width":69.58444779465958,"height":24.851588498092724,"type":"line_chart","id":"line_chart-20"},{"x":1450.608695652174,"y":132.82608695652175,"width":47,"height":49.04347826086956,"type":"line_chart","id":"line_chart-21"},{"x":28.347826086956506,"y":447.52173913043475,"width":463.8695652173912,"height":427.0869565217392,"type":"matrix","id":"matrix-22"},{"x":1449.064300942271,"y":350.71119809517535,"width":49.112455801245005,"height":46.845727071956844,"type":"matrix","id":"matrix-23"},{"x":1448.4158986995471,"y":403.33986211533556,"width":52.80097557407089,"height":51.33428180812416,"type":"parallel_coordinate","id":"parallel_coordinate-24"},{"x":1615.0439721057737,"y":201.09426347118256,"width":65.70046873424212,"height":34.91773163498174,"type":"scatterplot","id":"scatterplot-25"},{"x":1604.9362076851212,"y":251.17364173714319,"width":66.15991257154428,"height":33.53940012307453,"type":"scatterplot","id":"scatterplot-26"},{"x":1762.914188694391,"y":123.8846617386072,"width":67.24645637133268,"height":33.623228185666306,"type":"scatterplot","id":"scatterplot-27"},{"x":1878.4262468161155,"y":228.00820708776735,"width":66.70414623930583,"height":34.70784844972002,"type":"scatterplot","id":"scatterplot-28"},{"x":1859.4453921951747,"y":271.93532778194424,"width":65.61952597525192,"height":35.250158581746966,"type":"scatterplot","id":"scatterplot-29"},{"x":1748.8141252616922,"y":290.37387227085804,"width":65.61952597525192,"height":33.62322818566628,"type":"scatterplot","id":"scatterplot-30"},{"x":1581.9694542350353,"y":728.6158515464713,"width":66.88902193503282,"height":32.10673052881589,"type":"scatterplot","id":"scatterplot-31"},{"x":1565.9160889706272,"y":759.8307284494866,"width":67.78087556083346,"height":32.9985841546162,"type":"scatterplot","id":"scatterplot-32"},{"x":1609.6169166348488,"y":806.2071169911095,"width":68.6727291866339,"height":35.67414503201758,"type":"scatterplot","id":"scatterplot-33"},{"x":1797.7980316787416,"y":926.6073564741689,"width":64.21346105763178,"height":32.10673052881589,"type":"scatterplot","id":"scatterplot-34"},{"x":585.915482339749,"y":350.4231673906479,"width":72.06960664446899,"height":41.005121021852965,"type":"scatterplot","id":"scatterplot-35"},{"x":577.2174263654166,"y":403.85408266154724,"width":69.58444779465958,"height":38.519962172043726,"type":"scatterplot","id":"scatterplot-36"},{"x":849.2168074425539,"y":381.00649224772224,"width":70.95254019654239,"height":36.51596408777607,"type":"scatterplot","id":"scatterplot-37"},{"x":830.7036290459624,"y":423.73535346002154,"width":70.82702721956423,"height":37.277382747139086,"type":"scatterplot","id":"scatterplot-38"},{"x":721.3566396543544,"y":443.6166242584957,"width":67.0992889448504,"height":36.03480332223444,"type":"scatterplot","id":"scatterplot-39"},{"x":674.1386215079782,"y":331.78447601707836,"width":72.06960664446899,"height":42.247700446757676,"type":"scatterplot","id":"scatterplot-40"},{"x":562.3064732665609,"y":478.40884815582547,"width":69.58444779465971,"height":37.277382747139086,"type":"scatterplot","id":"scatterplot-41"},{"x":536.2123053435636,"y":521.8991280274878,"width":73.31218606937354,"height":38.519962172043726,"type":"scatterplot","id":"scatterplot-42"},{"x":610.7670708378419,"y":587.7558375474335,"width":70.82702721956434,"height":41.005121021852915,"type":"scatterplot","id":"scatterplot-43"},{"x":927.4919584973175,"y":754.4583792704054,"width":67.60772841343011,"height":35.695387271742675,"type":"scatterplot","id":"scatterplot-44"},{"x":1451.331029671559,"y":243.41937517840054,"width":43.82342209957278,"height":46.845727071956844,"type":"scatterplot","id":"scatterplot-45"},{"x":1007.1889068002849,"y":803.7541389178774,"width":68.00186187864699,"height":37.02323591170784,"type":"scatterplot","id":"scatterplot-46"},{"x":1280.2737342542998,"y":524.7622287920965,"width":83.11338674056854,"height":64.9795569062627,"type":"scatterplot","id":"scatterplot-47"}],"relations":[{"vislist":[{"vislist":["scatterplot-43","scatterplot-42","scatterplot-41","scatterplot-36","scatterplot-35","scatterplot-40","bar_chart-9","bar_chart-4","scatterplot-39","line_chart-18","scatterplot-38","scatterplot-37","line_chart-17","bar_chart-6","scatterplot-47","bar_chart-5","line_chart-20","scatterplot-46","bar_chart-8","scatterplot-44","line_chart-19"],"relation":null,"id":"group-0"},{"vislist":["graph-13"],"relation":null,"id":"group-1"}],"relation":"nested","id":"relation-0"},{"vislist":[{"vislist":[{"vislist":[{"vislist":["scatterplot-31","scatterplot-32","scatterplot-33","line_chart-16","scatterplot-34","line_chart-15","bar_chart-2","bar_chart-3"],"relation":null,"id":"group-6"},{"vislist":["graph-12"],"relation":null,"id":"group-7"}],"relation":"nested","id":"relation-3"},{"vislist":[{"vislist":["bar_chart-50"],"relation":null,"id":"group-4"},{"vislist":["graph-11"],"relation":null,"id":"group-5"}],"relation":"nested","id":"relation-2"},{"vislist":[{"vislist":["line_chart-14","scatterplot-30","scatterplot-29","scatterplot-28","scatterplot-27","bar_chart-0","bar_chart-1","scatterplot-25","scatterplot-26"],"relation":null,"id":"group-2"},{"vislist":["graph-10"],"relation":null,"id":"group-3"}],"relation":"nested","id":"relation-1"}],"relation":null,"id":"group-8"}],"relation":"repeated","id":"relation-4"}]},"2862_8":{"comp":[["heatmap","heatmap",["repeated"]]],"visType":["heatmap"],"compType":["repeated"],"compressed_tree":[{"composite_pattern":"repeated","visualization_type":[["heatmap"]]}],"coOccurrence":[["heatmap","heatmap",["coOccurrence"]]],"year":2016,"conference":["VAST"],"authors":["Johannes Weissenb\xf6ck","Artem Amirkhanov","M. Eduard Gr\xf6ller","Johann Kastner","Christoph Heinzl"],"title":"PorosityAnalyzer: Visual Analysis and Evaluation of Segmentation Pipelines to Determine the Porosity in Fiber-Reinforced Polymers","doi":"10.1109/VAST.2016.7883516","abstract":"In this paper we present PorosityAnalyzer, a novel tool for detailed evaluation and visual analysis of pore segmentation pipelines to determine the porosity in fiber-reinforced polymers (FRPs). The presented tool consists of two modules: the computation module and the analysis module. The computation module enables a convenient setup and execution of distributed off-line-computations on industrial 3D X-ray computed tomography datasets. It allows the user to assemble individual segmentation pipelines in the form of single pipeline steps, and to specify the parameter ranges as well as the sampling of the parameter-space of each pipeline segment. The result of a single segmentation run consists of the input parameters, the calculated 3D binary-segmentation mask, the resulting porosity value, and other derived results (e.g., segmentation pipeline run-time). The analysis module presents the data at different levels of detail by drill-down filtering in order to determine accurate and robust segmentation pipelines. Overview visualizations allow to initially compare and evaluate the segmentation pipelines. With a scatter plot matrix (SPLOM), the segmentation pipelines are examined in more detail based on their input and output parameters. Individual segmentation-pipeline runs are selected in the SPLOM and visually examined and compared in 2D slice views and 3D renderings by using aggregated segmentation masks and statistical contour renderings. PorosityAnalyzer has been thoroughly evaluated with the help of twelve domain experts. Two case studies demonstrate the applicability of our proposed concepts and visualization techniques, and show that our tool helps domain experts to gain new insights and improve their workflow efficiency.","keywords":"","caption":"Figure 8: Side-by-side comparison of three selections of aggregated segmentation masks (left: under-segmentation, middle: close to op- timal segmentation, right: over-segmentation).","img_size":{"width":1008,"height":606},"subfigures":[{"x":19.60232060929853,"y":44.76362510850155,"width":969.6233769545854,"height":545.4435865588305,"type":"interface","id":"interface-0"}],"visualizations":[{"x":19.998535871156747,"y":86.06442166910689,"width":322.0761346998536,"height":269.7276720351391,"type":"heatmap","id":"heatmap-0"},{"x":339.41288433382135,"y":89.6134699853587,"width":321.18887262079073,"height":256.4187408491947,"type":"heatmap","id":"heatmap-1"},{"x":664.1508052708637,"y":86.95168374816984,"width":318.5270863836017,"height":265.2913616398243,"type":"heatmap","id":"heatmap-2"},{"x":20.885797950219654,"y":361.1156661786237,"width":318.5270863836017,"height":240.44802342606152,"type":"heatmap","id":"heatmap-3"},{"x":341.1874084919473,"y":354.904831625183,"width":325.6251830161054,"height":243.10980966325036,"type":"heatmap","id":"heatmap-4"},{"x":664.1508052708637,"y":358.4538799414348,"width":329.1742313323573,"height":236.8989751098096,"type":"heatmap","id":"heatmap-5"}],"relations":[{"vislist":[{"vislist":["heatmap-0","heatmap-1","heatmap-2","heatmap-3","heatmap-4","heatmap-5"],"relation":null,"id":"group-0"}],"relation":"repeated","id":"relation-0"}]},"2862_9":{"comp":[["bar_chart","bar_chart",["repeated"]],["scatterplot","scatterplot",["repeated"]]],"visType":["bar_chart","scatterplot"],"compType":["repeated"],"compressed_tree":[{"composite_pattern":"repeated","visualization_type":[["bar_chart"]]},{"composite_pattern":"repeated","visualization_type":[["scatterplot"]]}],"coOccurrence":[["bar_chart","scatterplot",["coOccurrence"]]],"year":2016,"conference":["VAST"],"authors":["Johannes Weissenb\xf6ck","Artem Amirkhanov","M. Eduard Gr\xf6ller","Johann Kastner","Christoph Heinzl"],"title":"PorosityAnalyzer: Visual Analysis and Evaluation of Segmentation Pipelines to Determine the Porosity in Fiber-Reinforced Polymers","doi":"10.1109/VAST.2016.7883516","abstract":"In this paper we present PorosityAnalyzer, a novel tool for detailed evaluation and visual analysis of pore segmentation pipelines to determine the porosity in fiber-reinforced polymers (FRPs). The presented tool consists of two modules: the computation module and the analysis module. The computation module enables a convenient setup and execution of distributed off-line-computations on industrial 3D X-ray computed tomography datasets. It allows the user to assemble individual segmentation pipelines in the form of single pipeline steps, and to specify the parameter ranges as well as the sampling of the parameter-space of each pipeline segment. The result of a single segmentation run consists of the input parameters, the calculated 3D binary-segmentation mask, the resulting porosity value, and other derived results (e.g., segmentation pipeline run-time). The analysis module presents the data at different levels of detail by drill-down filtering in order to determine accurate and robust segmentation pipelines. Overview visualizations allow to initially compare and evaluate the segmentation pipelines. With a scatter plot matrix (SPLOM), the segmentation pipelines are examined in more detail based on their input and output parameters. Individual segmentation-pipeline runs are selected in the SPLOM and visually examined and compared in 2D slice views and 3D renderings by using aggregated segmentation masks and statistical contour renderings. PorosityAnalyzer has been thoroughly evaluated with the help of twelve domain experts. Two case studies demonstrate the applicability of our proposed concepts and visualization techniques, and show that our tool helps domain experts to gain new insights and improve their workflow efficiency.","keywords":"","caption":"Figure 7: A SPLOM with the parameters of a segmentation pipeline (1). A parameter of choice (Deviat. from. Ref.) is color-coded (2). The porosity frequency histogram with a selected porosity range (3). A parameter-range slider with a selected range of the parameter Bi- naryThr (4). The SPLOM popup preview, which compares two differ- ent segmentation results (5) and (6).","img_size":{"width":1014,"height":1065},"subfigures":[{"x":12.489087698146825,"y":48.359545378609916,"width":974.4738367338588,"height":997.3746774335042,"type":"interface","id":"interface-0"}],"visualizations":[{"x":15.041727672035108,"y":227.65739385065885,"width":979.2386530014641,"height":151.2518301610542,"type":"bar_chart","id":"bar_chart-0"},{"x":11.923133235724775,"y":82.64275256222547,"width":966.7642752562224,"height":140.3367496339678,"type":"bar_chart","id":"bar_chart-1"},{"x":693.3360175695461,"y":665.8199121522694,"width":291.5885797950218,"height":246.3689604685212,"type":"heatmap","id":"heatmap-2"},{"x":320.66398243045387,"y":997.9502196193265,"width":333.6896046852123,"height":59.25329428989755,"type":"heatmap","id":"heatmap-3"},{"x":77.41361639824298,"y":406.97657393850653,"width":918.4260614934115,"height":592.5329428989751,"type":"heatmap","id":"heatmap-4"},{"x":80.53221083455344,"y":408.5358711566617,"width":910.6295754026354,"height":590.9736456808199,"type":"scatterplot","id":"scatterplot-5"},{"x":78.97291361639827,"y":406.97657393850653,"width":910.6295754026352,"height":587.8550512445095,"type":"small_multiple","id":"small_multiple-6"}],"relations":[{"vislist":[{"vislist":["bar_chart-1","bar_chart-0"],"relation":null,"id":"group-0"}],"relation":"repeated","id":"relation-0"},{"vislist":[{"vislist":["scatterplot-5"],"relation":null,"id":"group-1"}],"relation":"repeated","id":"relation-1"}]},"2863_0":{"comp":[["scatterplot","scatterplot",["repeated"]],["bar_chart","parallel_coordinate",["nested"]],["glyph_based","matrix",["nested"]]],"visType":["scatterplot","bar_chart","parallel_coordinate","glyph_based","matrix"],"compType":["repeated","nested"],"compressed_tree":[{"composite_pattern":"repeated","visualization_type":[["scatterplot"]]},{"composite_pattern":"nested","visualization_type":[["bar_chart"],["parallel_coordinate"]]},{"composite_pattern":"nested","visualization_type":[["glyph_based"],["matrix"]]}],"coOccurrence":[["scatterplot","bar_chart",["coOccurrence"]],["scatterplot","parallel_coordinate",["coOccurrence"]],["scatterplot","glyph_based",["coOccurrence"]],["scatterplot","matrix",["coOccurrence"]],["bar_chart","parallel_coordinate",["coOccurrence"]],["bar_chart","glyph_based",["coOccurrence"]],["bar_chart","matrix",["coOccurrence"]],["parallel_coordinate","glyph_based",["coOccurrence"]],["parallel_coordinate","matrix",["coOccurrence"]],["glyph_based","matrix",["coOccurrence"]]],"year":2016,"conference":["VAST"],"authors":["Yuanzhe Chen","Qing Chen","Mingqian Zhao","Sebastien Boyer","Kalyan Veeramachaneni","Huamin Qu"],"title":"DropoutSeer: Visualizing learning patterns in Massive Open Online Courses for dropout reasoning and prediction","doi":"10.1109/VAST.2016.7883517","abstract":"Aiming at massive participation and open access education, Massive Open Online Courses (MOOCs) have attracted millions of learners over the past few years. However, the high dropout rate of learners is considered to be one of the most crucial factors that may hinder the development of MOOCs. To tackle this problem, statistical models have been developed to predict dropout behavior based on learner activity logs. Although predictive models can foresee the dropout behavior, it is still difficult for users to understand the reasons behind the predicted results and further design interventions to prevent dropout. In addition, with a better understanding of dropout, researchers in the area of predictive modeling in turn can improve the models. In this paper, we introduce DropoutSeer, a visual analytics system which not only helps instructors and education experts understand the reasons for dropout, but also allows researchers to identify crucial features which can further improve the performance of the models. Both the heterogeneous data extracted from three different kinds of learner activity logs (i.e., clickstream, forum posts and assignment records) and the predicted results are visualized in the proposed system. Case studies and expert interviews have been conducted to demonstrate the usefulness and effectiveness of DropoutSeer.","keywords":"","caption":"Figure 1: The figure shows the DropoutSeer system for the analysis of a JAVA programming course: (A) shows the learner groups clustered by their learning activity. (B) displays the clickstream behavior and the assignment performance of different learner groups along the timeline. (C) presents the posts of learners on the course forum. (D) lists general information including the overall distribution at the top, the dashboard in the middle, and the forum content at the bottom.","img_size":{"width":1947,"height":977},"subfigures":[{"x":30.493797467630223,"y":15.572607620880516,"width":1887.4265651919316,"height":931.712619200738,"type":"interface","id":"interface-0"}],"visualizations":[{"x":1605.0453879941435,"y":101.56222547584187,"width":253.19033674963384,"height":168.7935578330893,"type":"bar_chart","id":"bar_chart-0"},{"x":1276.0409956076135,"y":143.04538799414348,"width":264.63396778916535,"height":822.5109809663248,"type":"bar_chart","id":"bar_chart-1"},{"x":1041.446559297218,"y":130.17130307467056,"width":80.10541727672056,"height":803.9150805270862,"type":"bar_chart","id":"bar_chart-2"},{"x":1575.0058565153734,"y":334.7262079062957,"width":301.8257686676427,"height":323.28257686676426,"type":"bar_chart","id":"bar_chart-3"},{"x":384.8682284040997,"y":170.2240117130307,"width":662.3001464128843,"height":750.9882869692533,"type":"glyph_based","id":"glyph_based-4"},{"x":1046.3621550097546,"y":130.6294045558017,"width":496.57374547381903,"height":830.798215449583,"type":"parallel_coordinate","id":"parallel_coordinate-11"},{"x":383.43777452415827,"y":171.65446559297217,"width":662.3001464128841,"height":752.4187408491947,"type":"graph","id":"graph-5"},{"x":384.8682284040997,"y":173.0849194729136,"width":663.7306002928258,"height":752.4187408491947,"type":"matrix","id":"matrix-10"},{"x":75.89019033674978,"y":141.61493411420204,"width":238.88579795021968,"height":193.11127379209373,"type":"scatterplot","id":"scatterplot-6"},{"x":75.89019033674978,"y":339.01756954612006,"width":250.329428989751,"height":200.26354319180086,"type":"scatterplot","id":"scatterplot-7"},{"x":77.32064421669122,"y":536.4202049780381,"width":278.93850658857974,"height":195.97218155197652,"type":"scatterplot","id":"scatterplot-8"},{"x":78.75109809663265,"y":730.9619326500731,"width":286.09077598828696,"height":197.4026354319179,"type":"scatterplot","id":"scatterplot-9"}],"relations":[{"vislist":[{"vislist":["scatterplot-6","scatterplot-7","scatterplot-8","scatterplot-9"],"relation":null,"id":"group-0"}],"relation":"repeated","id":"relation-0"},{"vislist":[{"vislist":["bar_chart-1","bar_chart-2"],"relation":null,"id":"group-1"},{"vislist":["parallel_coordinate-11"],"relation":null,"id":"group-2"}],"relation":"nested","id":"relation-1"},{"vislist":[{"vislist":["glyph_based-4"],"relation":null,"id":"group-3"},{"vislist":["matrix-10"],"relation":null,"id":"group-4"}],"relation":"nested","id":"relation-2"}]},"2865_1":{"comp":[["area_chart","area_chart",["repeated"]]],"visType":["area_chart"],"compType":["repeated"],"compressed_tree":[{"composite_pattern":"repeated","visualization_type":[["area_chart"]]},{"composite_pattern":"repeated","visualization_type":[["area_chart"]]}],"coOccurrence":[["area_chart","area_chart",["coOccurrence"]]],"year":2016,"conference":["VAST"],"authors":["Michael Correll","Michael Gleicher"],"title":"The semantics of sketch: Flexibility in visual query systems for time series data","doi":"10.1109/VAST.2016.7883519","abstract":"Sketching allows analysts to specify complex and free-form patterns of interest. Visual query systems can make use of sketches to locate these patterns of interest in large datasets. However, sketching is ambiguous: the same drawing could represent a multitude of potential queries. In this work, we investigate these ambiguities as they apply to visual query systems for time series data. We define a class of \u201cinvariants\u201d - the properties of a time series that the analyst wishes to ignore when performing a sketch-based query. We present the results of a crowd-sourced study, showing that these invariants are key components of how people rate the strength of match between sketch and target. We adapt a number of algorithms for time series matching to support invariants in sketches. Lastly, we present a web-deployed prototype sketch-based visual query system that relies on these invariants. We apply the prototype to data from finance, the digital humanities, and political science.","keywords":"","caption":"Figure 1: An overview of the elements of our sketch-based visual query prototype, on the Google N-Grams dataset.  Here the analyst wanted to know \u201cwhat words have patterns ofusage that are most dissimilar to the word \u2018virtual?\u201d\u2019 \u201cVirtual\u201d is used as a query by example, and the analyst jumps to the bottom of the list of results to find a group of five strong\u201canti-matches,\u201d indicated by their bright red color (including words like \u201cfurnish\u201d and \u201ccross\u201d). The components of the system are:1: The scrollable Small Multiples Pane of the entire dataset.  Each small multiple is colored according to relative match strength.  Here, the analyst has jumped to the bottom of thescroll bar to examine \u201canti-matches.\u201d2: The Results Pane, showing the topkresults for a query. The analyst selects how many results they wish to consider, and whether these results are superimposed in the same plot,or drawn as separate line graphs.3: The Drawing Interface. The analyst can sketch their own queries here, or, as in this example, use an existing time series as a base for sketching.4:  The Query Specification interface and general UI. The large top buttons allow users to execute queries, clear the canvas, draw on the canvas, or erase portions of the canvas,respectively. The lower levels control how results are displayed and what invariants are active.","img_size":{"width":1317,"height":936},"subfigures":[{"x":12.690771262276833,"y":10.768612670445517,"width":1287.7828613176403,"height":913.1842879442469,"type":"interface","id":"interface-0"}],"visualizations":[{"x":341.2467057101025,"y":4.111273792093704,"width":960.6676427525623,"height":496.09370424597364,"type":"area_chart","id":"area_chart-0"},{"x":5.492679355783309,"y":4.111273792093704,"width":328.9019033674964,"height":915.4436310395315,"type":"area_chart","id":"area_chart-1"},{"x":338.50585651537335,"y":549.5402635431918,"width":956.5563689604686,"height":194.60029282576863,"type":"area_chart","id":"area_chart-2"},{"x":3.1964593066142126,"y":3.196459306614212,"width":334.3945827232797,"height":923.6661786237189,"type":"small_multiple","id":"small_multiple-3"},{"x":334.3945827232797,"y":3.196459306614212,"width":967.5197657393851,"height":494.7232796486091,"type":"small_multiple","id":"small_multiple-4"}],"relations":[{"vislist":[{"vislist":["area_chart-0"],"relation":null,"id":"group-0"}],"relation":"repeated","id":"relation-0"},{"vislist":[{"vislist":["area_chart-1"],"relation":null,"id":"group-1"}],"relation":"repeated","id":"relation-1"}]},"2878_0":{"comp":[["matrix","matrix",["repeated"]],["matrix","line_chart",["stacked"]],["heatmap","matrix",["coordinated"]],["line_chart","matrix",["stacked"]]],"visType":["matrix","line_chart","heatmap"],"compType":["repeated","stacked","coordinated"],"compressed_tree":[{"composite_pattern":"coordinated","visualization_type":[["heatmap"],["matrix"]]},{"composite_pattern":"coordinated","visualization_type":[["heatmap"],["matrix"]]},{"composite_pattern":"stacked","visualization_type":[["matrix","line_chart"]]},{"composite_pattern":"repeated","visualization_type":[["matrix"]]}],"coOccurrence":[["heatmap","matrix",["coOccurrence"]],["heatmap","line_chart",["coOccurrence"]],["matrix","line_chart",["coOccurrence"]]],"year":2017,"conference":["InfoVis"],"authors":["Hendrik Strobelt","Sebastian Gehrmann","Hanspeter Pfister","Alexander M. Rush"],"title":"LSTMVis: A Tool for Visual Analysis of Hidden State Dynamics in Recurrent Neural Networks","doi":"10.1109/TVCG.2017.2744158","abstract":"Recurrent neural networks, and in particular long short-term memory (LSTM) networks, are a remarkably effective tool for sequence modeling that learn a dense black-box hidden representation of their sequential input. Researchers interested in better understanding these models have studied the changes in hidden state representations over time and noticed some interpretable patterns but also significant noise. In this work, we present LSTMVis, a visual analysis tool for recurrent neural networks with a focus on understanding these hidden state dynamics. The tool allows users to select a hypothesis input range to focus on local state changes, to match these states changes to similar patterns in a large data set, and to align these results with structural annotations from their domain. We show several use cases of the tool for analyzing specific hidden state properties on dataset containing nesting, phrase structure, and chord progressions, and demonstrate how the tool can be used to isolate patterns for further statistical analysis. We characterize the domain, the different stakeholders, and their goals and tasks. Long-term usage data after putting the tool online revealed great interest in the machine learning community.","keywords":"Visualization,Machine Learning,Recurrent Neural Networks,LSTM","caption":"Fig. 1. The LSTMV IS user interface. The user interactively selects a range of text specifying a hypothesis about the model in the Select View (a). This range is then used to match similar hidden state patterns displayed in the Match View (b). The selection is made by specifying a start-stop range in the text (c) and an activation threshold (t) which leads to a selection of hidden states (blue lines). The start-stop range can be further constrained using the pattern plot (d). The meta-tracks below depict extra information per word position like POS (e1) or the top K predictions (e2). The tool can then match this selection with similar hidden state patterns in the data set of varying lengths (f), providing insight into the representations learned by the model. The match view additionally includes user-defined meta-data encoded as heatmaps (g1,g2). The color of one heatmap (g2) can be mapped (h) to the word matrix (f) which allows the user to see patterns that lead to further refinement of the selection hypothesis. Navigation aids provide convenience (i1, i2).","img_size":{"width":1571,"height":885},"subfigures":[{"x":8.696476317501492,"y":6.565138372057301,"width":1548.769517569172,"height":864.6167697773521,"type":"interface","id":"interface-0"}],"visualizations":[{"x":85.13578500707206,"y":340.4809052333805,"width":1479.589816124469,"height":128.93210749646389,"type":"heatmap","id":"heatmap-0"},{"x":1069.0254596888258,"y":562.0438472418671,"width":245.3465346534654,"height":316.69731258840164,"type":"heatmap","id":"heatmap-1"},{"x":63.85572842998579,"y":72.6025459688826,"width":1492.1074964639322,"height":235.3323903818953,"type":"line_chart","id":"line_chart-4"},{"x":50.086280056577,"y":589.5827439886846,"width":733.5360678925034,"height":285.40311173974544,"type":"matrix","id":"matrix-5"},{"x":1070.277227722772,"y":560.7920792079208,"width":245.3465346534654,"height":315.4455445544555,"type":"matrix","id":"matrix-6"},{"x":1318.1272984441302,"y":565.7991513437057,"width":232.82885431400268,"height":310.4384724186704,"type":"matrix","id":"matrix-7"},{"x":86.3875530410183,"y":339.2291371994342,"width":1474.5827439886848,"height":130.18387553041015,"type":"matrix","id":"matrix-8"}],"relations":[{"vislist":[{"vislist":["heatmap-1"],"relation":null,"id":"group-0"},{"vislist":["matrix-6"],"relation":null,"id":"group-1"}],"relation":"coordinated","id":"relation-0"},{"vislist":[{"vislist":["heatmap-0"],"relation":null,"id":"group-2"},{"vislist":["matrix-8"],"relation":null,"id":"group-3"}],"relation":"coordinated","id":"relation-1"},{"vislist":[{"vislist":["matrix-8","line_chart-4"],"relation":null,"id":"group-4"}],"relation":"stacked","id":"relation-2"},{"vislist":[{"vislist":["matrix-7","matrix-6"],"relation":null,"id":"group-5"}],"relation":"repeated","id":"relation-3"}]},"2882_3":{"comp":[["matrix","matrix",["stacked","repeated"]],["line_chart","proportional_area_chart",["stacked"]],["proportional_area_chart","line_chart",["stacked"]]],"visType":["matrix","line_chart","proportional_area_chart"],"compType":["stacked","repeated"],"compressed_tree":[{"composite_pattern":"stacked","visualization_type":[["line_chart","proportional_area_chart"]]},{"composite_pattern":"stacked","visualization_type":[["matrix"]]},{"composite_pattern":"repeated","visualization_type":[["matrix"]]}],"coOccurrence":[["line_chart","proportional_area_chart",["coOccurrence"]],["line_chart","matrix",["coOccurrence"]],["proportional_area_chart","matrix",["coOccurrence"]]],"year":2017,"conference":["InfoVis"],"authors":["Yingcai Wu","Ji Lan","Xinhuan Shu","Chenyang Ji","Kejian Zhao","Jiachen Wang","Hui Zhang"],"title":"iTTVis: Interactive Visualization of Table Tennis Data","doi":"10.1109/TVCG.2017.2744218","abstract":"The rapid development of information technology paved the way for the recording of fine-grained data, such as stroke techniques and stroke placements, during a table tennis match. This data recording creates opportunities to analyze and evaluate matches from new perspectives. Nevertheless, the increasingly complex data poses a significant challenge to make sense of and gain insights into. Analysts usually employ tedious and cumbersome methods which are limited to watching videos and reading statistical tables. However, existing sports visualization methods cannot be applied to visualizing table tennis competitions due to different competition rules and particular data attributes. In this work, we collaborate with data analysts to understand and characterize the sophisticated domain problem of analysis of table tennis data. We propose iTTVis, a novel interactive table tennis visualization system, which to our knowledge, is the first visual analysis system for analyzing and exploring table tennis data. iTTVis provides a holistic visualization of an entire match from three main perspectives, namely, time-oriented, statistical, and tactical analyses. The proposed system with several well-coordinated views not only supports correlation identification through statistics and pattern detection of tactics with a score timeline but also allows cross analysis to gain insights. Data analysts have obtained several new insights by using iTTVis. The effectiveness and usability of the proposed system are demonstrated with four case studies.","keywords":"Sports visualization,visual knowledge discovery,sports analytics,visual knowledge representation","caption":"Fig. 3. Interface of iTTVis with a unified color encoding (A-1). The interface comprises five well-coordinated views: the match view (including a tailored step chart (B-1), a point outcome bar (B-2), and a selection panel (B-3)), the stroke view (collapsed and minimized in (C)), the stat view (D), the tactic view (E), and the history view (F).","img_size":{"width":2151,"height":1211},"subfigures":[{"x":7.620581897096217,"y":9.010594085157647,"width":2130.797241254107,"height":1188.0164803819425,"type":"interface","id":"interface-0"}],"visualizations":[{"x":38.17858948237967,"y":99.68944457900604,"width":1838.0001806710547,"height":161.30979008726837,"type":"line_chart","id":"line_chart-2"},{"x":5.81188118811872,"y":299.7524752475248,"width":1473.0693069306928,"height":906.1089108910895,"type":"matrix","id":"matrix-0"},{"x":1497.722772277228,"y":292.90099009900996,"width":436.7821782178219,"height":471.0396039603961,"type":"matrix","id":"matrix-1"},{"x":15.347631286571678,"y":260.4556306223813,"width":1860.8138421309536,"height":27.4660972458018,"type":"proportional_area_chart","id":"proportional_area_chart-3"}],"relations":[{"vislist":[{"vislist":["line_chart-2","proportional_area_chart-3"],"relation":null,"id":"group-0"}],"relation":"stacked","id":"relation-0"},{"vislist":[{"vislist":["matrix-0"],"relation":null,"id":"group-1"}],"relation":"stacked","id":"relation-1"},{"vislist":[{"vislist":["matrix-1"],"relation":null,"id":"group-2"}],"relation":"repeated","id":"relation-2"}]},"2886_2":{"comp":[["area_chart","area_chart",["repeated"]],["line_chart","bar_chart",["accompanied"]],["bar_chart","line_chart",["accompanied"]],["bar_chart","error_bar",["accompanied"]],["error_bar","bar_chart",["accompanied"]],["heatmap","map",["coordinated"]],["heatmap","surface_graph",["coordinated"]],["heatmap","contour_graph",["coordinated"]],["heatmap","matrix",["coordinated"]],["map","map",["coordinated"]]],"visType":["area_chart","line_chart","bar_chart","error_bar","heatmap","map","surface_graph","contour_graph","matrix"],"compType":["repeated","accompanied","coordinated"],"compressed_tree":[{"composite_pattern":"accompanied","visualization_type":[["line_chart","bar_chart"]]},{"composite_pattern":"coordinated","visualization_type":[["heatmap"],["map"]]},{"composite_pattern":"coordinated","visualization_type":[["heatmap"],["surface_graph"]]},{"composite_pattern":"accompanied","visualization_type":[["line_chart","bar_chart"]]},{"composite_pattern":"accompanied","visualization_type":[["bar_chart","error_bar"]]},{"composite_pattern":"coordinated","visualization_type":[["heatmap"],["map"]]},{"composite_pattern":"coordinated","visualization_type":[["heatmap"],["surface_graph"]]},{"composite_pattern":"coordinated","visualization_type":[["map","heatmap"],["map"]]},{"composite_pattern":"coordinated","visualization_type":[["map","heatmap"],["map"]]},{"composite_pattern":"coordinated","visualization_type":[["heatmap"],["map"]]},{"composite_pattern":"coordinated","visualization_type":[["heatmap"],["contour_graph"]]},{"composite_pattern":"repeated","visualization_type":[["area_chart"]]},{"composite_pattern":"coordinated","visualization_type":[["heatmap"],["matrix"]]}],"coOccurrence":[["line_chart","bar_chart",["coOccurrence"]],["line_chart","heatmap",["coOccurrence"]],["line_chart","map",["coOccurrence"]],["line_chart","surface_graph",["coOccurrence"]],["line_chart","error_bar",["coOccurrence"]],["line_chart","contour_graph",["coOccurrence"]],["line_chart","area_chart",["coOccurrence"]],["line_chart","matrix",["coOccurrence"]],["bar_chart","heatmap",["coOccurrence"]],["bar_chart","map",["coOccurrence"]],["bar_chart","surface_graph",["coOccurrence"]],["bar_chart","error_bar",["coOccurrence"]],["bar_chart","contour_graph",["coOccurrence"]],["bar_chart","area_chart",["coOccurrence"]],["bar_chart","matrix",["coOccurrence"]],["heatmap","map",["coOccurrence"]],["heatmap","surface_graph",["coOccurrence"]],["heatmap","error_bar",["coOccurrence"]],["heatmap","contour_graph",["coOccurrence"]],["heatmap","area_chart",["coOccurrence"]],["heatmap","matrix",["coOccurrence"]],["map","surface_graph",["coOccurrence"]],["map","error_bar",["coOccurrence"]],["map","contour_graph",["coOccurrence"]],["map","area_chart",["coOccurrence"]],["map","matrix",["coOccurrence"]],["surface_graph","error_bar",["coOccurrence"]],["surface_graph","contour_graph",["coOccurrence"]],["surface_graph","area_chart",["coOccurrence"]],["surface_graph","matrix",["coOccurrence"]],["error_bar","contour_graph",["coOccurrence"]],["error_bar","area_chart",["coOccurrence"]],["error_bar","matrix",["coOccurrence"]],["contour_graph","area_chart",["coOccurrence"]],["contour_graph","matrix",["coOccurrence"]],["area_chart","matrix",["coOccurrence"]]],"year":2017,"conference":["InfoVis"],"authors":["Jorge Poco","Angela Mayhua","Jeffrey Heer"],"title":"Extracting and Retargeting Color Mappings from Bitmap Images of Visualizations","doi":"10.1109/TVCG.2017.2744320","abstract":"Visualization designers regularly use color to encode quantitative or categorical data. However, visualizations \u201cin the wild\u201d often violate perceptual color design principles and may only be available as bitmap images. In this work, we contribute a method to semi-automatically extract color encodings from a bitmap visualization image. Given an image and a legend location, we classify the legend as describing either a discrete or continuous color encoding, identify the colors used, and extract legend text using OCR methods. We then combine this information to recover the specific color mapping. Users can also correct interpretation errors using an annotation interface. We evaluate our techniques using a corpus of images extracted from scientific papers and demonstrate accurate automatic inference of color mappings across a variety of chart types. In addition, we present two applications of our method: automatic recoloring to improve perceptual effectiveness, and interactive overlays to enable improved reading of static visualizations.","keywords":"Visualization,color,chart understanding,information extraction,redesign,computer vision","caption":"Fig. 3.  Graphical user interface for legend annotation.  The bottom panelshows chart images in our corpus.  Outline colors represent the colorlegend type:  orange for continuous and blue for discrete.","img_size":{"width":1007,"height":1236},"subfigures":[{"x":14.47647160338763,"y":15.925550894614492,"width":976.3598501877862,"height":1209.2136725042546,"type":"interface","id":"interface-0"}],"visualizations":[{"x":25.156654783635688,"y":1114.3542623592934,"width":110.20244112136506,"height":98.80897273717052,"type":"area_chart","id":"area_chart-0"},{"x":147.14367816091965,"y":120.75862068965519,"width":684.2988505747128,"height":518.551724137931,"type":"bar_chart","id":"bar_chart-1"},{"x":701.4210126950238,"y":686.3253931001507,"width":91.67914872345011,"height":74.07675216854773,"type":"bar_chart","id":"bar_chart-2"},{"x":194.6687208697465,"y":833.7518555009926,"width":104.3632262056442,"height":64.49412855404967,"type":"bar_chart","id":"bar_chart-3"},{"x":192.32347983141744,"y":965.0853536474212,"width":110.22632880146682,"height":89.11915945650503,"type":"bar_chart","id":"bar_chart-4"},{"x":865.4076578318642,"y":677.7933264521087,"width":99.6727441289861,"height":87.94653893734063,"type":"bar_chart","id":"bar_chart-5"},{"x":528.9980521485371,"y":679.901880589088,"width":107.11732206694842,"height":46.86382840428996,"type":"bar_chart","id":"bar_chart-6"},{"x":25.29502986305145,"y":833.5347720867306,"width":108.14997868645158,"height":41.03009500681878,"type":"heatmap","id":"heatmap-7"},{"x":361.1793705854375,"y":680.4239967983439,"width":106.74552893332327,"height":102.52395434273966,"type":"heatmap","id":"heatmap-8"},{"x":863.3449389984717,"y":969.7945397755509,"width":106.30529536214522,"height":38.99925664015724,"type":"heatmap","id":"heatmap-10"},{"x":360.28826989309374,"y":835.5940271573317,"width":107.11732206694847,"height":80.93289893371158,"type":"heatmap","id":"heatmap-11"},{"x":527.0134910792443,"y":834.7291623744243,"width":107.245959107526,"height":49.51766846269777,"type":"heatmap","id":"heatmap-12"},{"x":525.5854157890423,"y":967.5682966049928,"width":110.54758968456099,"height":75.01443585738059,"type":"heatmap","id":"heatmap-13"},{"x":193.5225511308395,"y":676.8055042921294,"width":109.15785727079944,"height":110.96710352390666,"type":"heatmap","id":"heatmap-14"},{"x":862.3821049943335,"y":836.7355689752127,"width":107.38908712214493,"height":42.1133674988804,"type":"heatmap","id":"heatmap-15"},{"x":695.1147954261697,"y":839.3799295195174,"width":103.88601635977236,"height":73.82699274173993,"type":"heatmap","id":"heatmap-16"},{"x":32.468860817590176,"y":971.9087908953996,"width":93.70224268500883,"height":53.16812646733649,"type":"heatmap","id":"heatmap-17"},{"x":193.97467371118626,"y":1116.7665772672062,"width":104.699637087116,"height":78.60239816925923,"type":"heatmap","id":"heatmap-18"},{"x":25.48895027624326,"y":678.3204419889504,"width":106.98342541436455,"height":77.39226519337012,"type":"line_chart","id":"line_chart-19"},{"x":149.51149425287383,"y":118.39080459770118,"width":677.1954022988505,"height":520.9195402298852,"type":"line_chart","id":"line_chart-21"},{"x":701.4210126950238,"y":686.6921096950445,"width":91.31243212855634,"height":72.9766023838664,"type":"line_chart","id":"line_chart-22"},{"x":696.3688678781439,"y":966.5019106512493,"width":107.11732206694812,"height":89.53178994225787,"type":"scatterplot","id":"scatterplot-23"},{"x":862.9085220880695,"y":837.2619860689487,"width":106.60951706079265,"height":42.14590686983058,"type":"map","id":"map-25"},{"x":193.9309392265195,"y":678.320433305772,"width":109.25966850828718,"height":109.25966850828729,"type":"map","id":"map-26"},{"x":526.7023729205912,"y":834.3064245864248,"width":107.18508841262621,"height":49.70902651020333,"type":"map","id":"map-28"},{"x":25.37402782548217,"y":830.8050878978737,"width":110.76899311481395,"height":43.308970816642294,"type":"map","id":"map-29"},{"x":362.7631840578579,"y":971.6540249058311,"width":103.02121681059919,"height":90.08781729758027,"type":"map","id":"map-30"},{"x":525.3222072421743,"y":967.8315051518606,"width":110.81079823142898,"height":74.48801876364473,"type":"map","id":"map-31"},{"x":190.69340593390152,"y":674.7747188628414,"width":111.61318813219737,"height":109.31339413272461,"type":"heatmap","id":"heatmap-32"},{"x":356.95405056431576,"y":674.7747188628415,"width":111.0918988713669,"height":109.31339413272437,"type":"surface_graph","id":"surface_graph-33"},{"x":866.4091975286755,"y":677.9441025424243,"width":100.18160494265042,"height":93.40383031338214,"type":"error_bar","id":"error_bar-34"},{"x":360.54768411876773,"y":834.5132657173158,"width":108.90463176246371,"height":83.79647741492671,"type":"surface_graph","id":"surface_graph-35"},{"x":863.4781130231902,"y":971.5780242249956,"width":109.04377395361917,"height":44.83510199248618,"type":"contour_graph","id":"contour_graph-36"},{"x":194.26204738330253,"y":1117.8192838784553,"width":99.47590523339485,"height":80.49417560592092,"type":"matrix","id":"matrix-37"}],"relations":[{"vislist":[{"id":"group-4","relation":null,"vislist":["line_chart-21","bar_chart-1"]}],"relation":"accompanied","id":"relation-0"},{"vislist":[{"id":"group-5","relation":null,"vislist":["heatmap-32"]},{"id":"group-6","relation":null,"vislist":["map-26"]}],"relation":"coordinated","id":"relation-1"},{"vislist":[{"id":"group-7","relation":null,"vislist":["heatmap-8"]},{"id":"group-8","relation":null,"vislist":["surface_graph-33"]}],"relation":"coordinated","id":"relation-2"},{"vislist":[{"id":"group-9","relation":null,"vislist":["line_chart-22","bar_chart-2"]}],"relation":"accompanied","id":"relation-3"},{"vislist":[{"id":"group-10","relation":null,"vislist":["bar_chart-5","error_bar-34"]}],"relation":"accompanied","id":"relation-4"},{"vislist":[{"id":"group-11","relation":null,"vislist":["heatmap-7"]},{"id":"group-12","relation":null,"vislist":["map-29"]}],"relation":"coordinated","id":"relation-5"},{"vislist":[{"id":"group-13","relation":null,"vislist":["heatmap-11"]},{"id":"group-14","relation":null,"vislist":["surface_graph-35"]}],"relation":"coordinated","id":"relation-6"},{"vislist":[{"vislist":["map-28","map-28","map-28","heatmap-12"],"relation":null,"id":"group-3"},{"id":"group-15","relation":null,"vislist":["map-28"]}],"relation":"coordinated","id":"relation-7"},{"vislist":[{"vislist":["map-25","map-25","map-25","heatmap-15"],"relation":null,"id":"group-4"},{"id":"group-16","relation":null,"vislist":["map-25"]}],"relation":"coordinated","id":"relation-8"},{"vislist":[{"id":"group-17","relation":null,"vislist":["heatmap-13"]},{"id":"group-18","relation":null,"vislist":["map-31"]}],"relation":"coordinated","id":"relation-9"},{"vislist":[{"id":"group-19","relation":null,"vislist":["heatmap-10"]},{"id":"group-20","relation":null,"vislist":["contour_graph-36"]}],"relation":"coordinated","id":"relation-10"},{"vislist":[{"id":"group-21","relation":null,"vislist":["area_chart-0"]}],"relation":"repeated","id":"relation-11"},{"vislist":[{"id":"group-22","relation":null,"vislist":["heatmap-18"]},{"id":"group-23","relation":null,"vislist":["matrix-37"]}],"relation":"coordinated","id":"relation-12"}]},"2892_2":{"comp":[["bar_chart","bar_chart",["repeated"]],["scatterplot","matrix",["nested"]]],"visType":["bar_chart","scatterplot","matrix"],"compType":["repeated","nested"],"compressed_tree":[{"composite_pattern":"nested","visualization_type":[["scatterplot"],["matrix"]]},{"composite_pattern":"repeated","visualization_type":[["bar_chart"]]}],"coOccurrence":[["bar_chart","bar_chart",["coOccurrence"]]],"year":2017,"conference":["InfoVis"],"authors":["Evanthia Dimara","Anastasia Bezerianos","Pierre Dragicevic"],"title":"Conceptual and Methodological Issues in Evaluating Multidimensional Visualizations for Decision Support","doi":"10.1109/TVCG.2017.2745138","abstract":"We explore how to rigorously evaluate multidimensional visualizations for their ability to support decision making. We first define multi-attribute choice tasks, a type of decision task commonly performed with such visualizations. We then identify which of the existing multidimensional visualizations are compatible with such tasks, and set out to evaluate three elementary visualizations: parallel coordinates, scatterplot matrices and tabular visualizations. Our method consists in first giving participants low-level analytic tasks, in order to ensure that they properly understood the visualizations and their interactions. Participants are then given multi-attribute choice tasks consisting of choosing holiday packages. We assess decision support through multiple objective and subjective metrics, including a decision accuracy metric based on the consistency between the choice made and self-reported preferences for attributes. We found the three visualizations to be comparable on most metrics, with a slight advantage for tabular visualizations. In particular, tabular visualizations allow participants to reach decisions faster. Thus, although decision time is typically not central in assessing decision support, it can be used as a tie-breaker when visualizations achieve similar decision accuracy. Our results also suggest that indirect methods for assessing choice confidence may allow to better distinguish between visualizations than direct ones. We finally discuss the limitations of our methods and directions for future work, such as the need for more sensitive metrics of decision support.","keywords":"decision making,multidimensional visualization,parallel coordinates,scatterplot matrix,tabular visualization,evaluation","caption":"Fig. 3: Experiment Stimuli for the decision task (\u201cWhich holiday package would you choose?\u201d). Dataset of 100 holiday packages.","img_size":{"width":1926,"height":279},"subfigures":[{"x":71.97295727086741,"y":12.681040785021297,"width":451.69329597101415,"height":255.03359574445378,"type":"interface","id":"interface-0"},{"x":772.6291403942598,"y":11.334745333707232,"width":452.0859886792505,"height":256.33050933258534,"type":"interface","id":"interface-1"},{"x":1466.9072771898577,"y":11.306289088277488,"width":452.6446088428806,"height":254.9917445089483,"type":"interface","id":"interface-2"}],"visualizations":[{"x":1464.937181663837,"y":7.067062818336183,"width":358.0594227504245,"height":259.96095076400684,"type":"bar_chart","id":"bar_chart-0"},{"x":774.9779286926996,"y":11.971986417657035,"width":266.50084889643483,"height":255.056027164686,"type":"matrix","id":"matrix-3"},{"x":86.65365025466896,"y":8.702037351443153,"width":335.16977928692705,"height":256.6910016977929,"type":"parallel_coordinate","id":"parallel_coordinate-1"},{"x":774.9779286926996,"y":5.432088285229212,"width":266.50084889643483,"height":261.5959252971138,"type":"scatterplot","id":"scatterplot-2"}],"relations":[{"vislist":[{"vislist":["scatterplot-2"],"relation":null,"id":"group-0"},{"vislist":["matrix-3"],"relation":null,"id":"group-1"}],"relation":"nested","id":"relation-0"},{"vislist":[{"vislist":["bar_chart-0"],"relation":null,"id":"group-2"}],"relation":"repeated","id":"relation-1"}]},"2895_0":{"comp":[["bar_chart","bar_chart",["repeated"]],["bar_chart","graph",["large_view"]]],"visType":["bar_chart","graph"],"compType":["repeated","large_view"],"compressed_tree":[{"composite_pattern":"large_view","visualization_type":[["bar_chart"],["graph"]]},{"composite_pattern":"repeated","visualization_type":[["bar_chart"]]}],"coOccurrence":[["bar_chart","graph",["coOccurrence"]]],"year":2017,"conference":["InfoVis"],"authors":["Arjun Srinivasan","John T. Stasko"],"title":"Orko: Facilitating Multimodal Interaction for Visual Exploration and Analysis of Networks","doi":"10.1109/TVCG.2017.2745219","abstract":"Data visualization systems have predominantly been developed for WIMP-based direct manipulation interfaces. Only recently have other forms of interaction begun to appear, such as natural language or touch-based interaction, though usually operating only independently. Prior evaluations of natural language interfaces for visualization have indicated potential value in combining direct manipulation and natural language as complementary interaction techniques. We hypothesize that truly multimodal interfaces for visualization, those providing users with freedom of expression via both natural language and touch-based direct manipulation input, may provide an effective and engaging user experience. Unfortunately, however, little work has been done in exploring such multimodal visualization interfaces. To address this gap, we have created an architecture and a prototype visualization system called Orko that facilitates both natural language and direct manipulation input. Specifically, Orko focuses on the domain of network visualization, one that has largely relied on WIMP-based interfaces and direct manipulation interaction, and has little or no prior research exploring natural language interaction. We report results from an initial evaluation study of Orko, and use our observations to discuss opportunities and challenges for future work in multimodal network visualization interfaces.","keywords":"Multimodal interaction,network visualization,natural language input,direct manipulation,multitouch input","caption":"Fig. 1. Orko\u2019s user interface being used to explore a network of European soccer players. Cristiano Ronaldo, Gareth Bale, and their connections are highlighted. Connected nodes with lower opacity do not meet all the filtering criteria. Interface components: (A) Natural language input and action feedback row (B) Network canvas (C) Quick access icons (D) Details container (E) Summary container (F) Filters and visual encodings row.","img_size":{"width":2151,"height":1080},"subfigures":[{"x":10.406138377858136,"y":11.084095361865126,"width":2133.3123852202393,"height":1062.5230376876555,"type":"interface","id":"interface-0"}],"visualizations":[{"x":1728.5410183875545,"y":564.8555313649528,"width":303.9886845827442,"height":76.24517121890945,"type":"bar_chart","id":"bar_chart-0"},{"x":1222.9115983026877,"y":334.54031117397443,"width":313.15417256011307,"height":242.8854314002828,"type":"bar_chart","id":"bar_chart-1"},{"x":19.177510608203708,"y":116.0961810466761,"width":1683.3946251768034,"height":837.114568599717,"type":"graph","id":"graph-2"},{"x":1723.898862758096,"y":756.9549996234387,"width":314.0042471696936,"height":73.46160196158115,"type":"bar_chart","id":"bar_chart-3"}],"relations":[{"vislist":[{"id":"group-0","relation":null,"vislist":["bar_chart-1"]},{"id":"group-1","relation":null,"vislist":["graph-2"]}],"relation":"large_view","id":"relation-0"},{"vislist":[{"id":"group-2","relation":null,"vislist":["bar_chart-0","bar_chart-3"]}],"relation":"repeated","id":"relation-1"}]},"2897_3":{"comp":[["bar_chart","bar_chart",["repeated"]]],"visType":["bar_chart"],"compType":["repeated"],"compressed_tree":[{"composite_pattern":"repeated","visualization_type":[["bar_chart"]]}],"coOccurrence":[["bar_chart","bar_chart",["coOccurrence"]]],"year":2017,"conference":["InfoVis"],"authors":["Bram C. M. Cappers","Jarke J. van Wijk"],"title":"Exploring Multivariate Event Sequences Using Rules, Aggregations, and Selections","doi":"10.1109/TVCG.2017.2745278","abstract":"Multivariate event sequences are ubiquitous: travel history, telecommunication conversations, and server logs are some examples. Besides standard properties such as type and timestamp, events often have other associated multivariate data. Current exploration and analysis methods either focus on the temporal analysis of a single attribute or the structural analysis of the multivariate data only. We present an approach where users can explore event sequences at multivariate and sequential level simultaneously by interactively defining a set of rewrite rules using multivariate regular expressions. Users can store resulting patterns as new types of events or attributes to interactively enrich or simplify event sequences for further investigation. In Eventpad we provide a bottom-up glyph-oriented approach for multivariate event sequence analysis by searching, clustering, and aligning them according to newly defined domain specific properties. We illustrate the effectiveness of our approach with real-world data sets including telecommunication traffic and hospital treatments.","keywords":"Event Visualization,Multivariate Events,Regular Expressions,Sequence Alignment,Interaction","caption":"Fig. 4. Graphical user interface of the implemented prototype and components: A) Sequence view represents sequences as series of glyphs. Settings with respect to sorting, grouping, and clustering of sequences are set using controls in A) and G). B) The alignment view finds overlap in sequences of interest by aligning them. Alignment parameters, layout and sort settings can be modified in B) and H). C) The attribute view shows trends and patterns in selections on a per-attribute basis. D) Context view enables experts to store selections of interest throughout exploration. E) Rule overview widget to show the coverage of applied rules. F) Rule view shows a list of applied rules along with their settings. The ordering for rewriting is controlled via drag and drop operations. Rules can be toggled on or off along with longest and shortest match settings.","img_size":{"width":2157,"height":1013},"subfigures":[{"x":8.814572271755468,"y":14.418508426452636,"width":2120.570588002823,"height":988.8581283347273,"type":"interface","id":"interface-0"}],"visualizations":[{"x":36.57833089311872,"y":335.19472913616397,"width":320.36310395314797,"height":45.97803806734993,"type":"bar_chart","id":"bar_chart-0"},{"x":30.645680819912272,"y":283.28404099560765,"width":323.32942898975114,"height":48.944363103953094,"type":"bar_chart","id":"bar_chart-1"},{"x":24.71303074670583,"y":229.89019033674967,"width":339.6442166910689,"height":48.94436310395315,"type":"bar_chart","id":"bar_chart-2"},{"x":33.6120058565155,"y":180.9458272327965,"width":320.36310395314797,"height":44.494875549048324,"type":"bar_chart","id":"bar_chart-3"},{"x":42.51098096632518,"y":133.48462664714495,"width":307.0146412884334,"height":37.07906295754026,"type":"bar_chart","id":"bar_chart-4"},{"x":437.03221083455367,"y":84.54026354319181,"width":949.2240117130307,"height":863.2005856515375,"type":"others","id":"others-5"},{"x":1429.2679355783314,"y":166.11420204978043,"width":694.1200585651538,"height":780.1434846266473,"type":"others","id":"others-6"}],"relations":[{"vislist":[{"id":"group-0","relation":null,"vislist":["bar_chart-0","bar_chart-1","bar_chart-2","bar_chart-3","bar_chart-4"]}],"relation":"repeated","id":"relation-1"}]},"2930_4":{"comp":[["line_chart","line_chart",["repeated"]],["comb","comb",["repeated"]],["heatmap","sankey_diagram",["nested"]],["heatmap","treemap",["coordinated"]],["tree","treemap",["nested"]]],"visType":["line_chart","comb","heatmap","sankey_diagram","treemap","tree"],"compType":["repeated","nested","coordinated"],"compressed_tree":[{"composite_pattern":"nested","visualization_type":[["heatmap"],["sankey_diagram"]]},{"composite_pattern":"coordinated","visualization_type":[["heatmap"],["treemap"]]},{"composite_pattern":"repeated","visualization_type":[["line_chart"]]},{"composite_pattern":"repeated","visualization_type":[[{"composite_pattern":"nested","visualization_type":[["tree"],["treemap"]]}]]}],"coOccurrence":[["heatmap","sankey_diagram",["coOccurrence"]],["heatmap","treemap",["coOccurrence"]],["heatmap","tree",["coOccurrence"]],["heatmap","line_chart",["coOccurrence"]],["sankey_diagram","treemap",["coOccurrence"]],["sankey_diagram","tree",["coOccurrence"]],["sankey_diagram","line_chart",["coOccurrence"]],["treemap","tree",["coOccurrence"]],["treemap","line_chart",["coOccurrence"]],["tree","line_chart",["coOccurrence"]]],"year":2017,"conference":["VAST"],"authors":["Siwei Fu","Hao Dong","Weiwei Cui","Jian Zhao","Huamin Qu"],"title":"How Do Ancestral Traits Shape Family Trees Over Generations?","doi":"10.1109/TVCG.2017.2744080","abstract":"Whether and how does the structure of family trees differ by ancestral traits over generations? This is a fundamental question regarding the structural heterogeneity of family trees for the multi-generational transmission research. However, previous work mostly focuses on parent-child scenarios due to the lack of proper tools to handle the complexity of extending the research to multi-generational processes. Through an iterative design study with social scientists and historians, we develop TreeEvo that assists users to generate and test empirical hypotheses for multi-generational research. TreeEvo summarizes and organizes family trees by structural features in a dynamic manner based on a traditional Sankey diagram. A pixel-based technique is further proposed to compactly encode trees with complex structures in each Sankey Node. Detailed information of trees is accessible through a space-efficient visualization with semantic zooming. Moreover, TreeEvo embeds Multinomial Logit Model (MLM) to examine statistical associations between tree structure and ancestral traits. We demonstrate the effectiveness and usefulness of TreeEvo through an in-depth case-study with domain experts using a real-world dataset (containing 54,128 family trees of 126,196 individuals).","keywords":"Quantitative social science,Design study,Multiple tree visualization,Sankey diagram","caption":"Figure 5. TreeEvo interface: (a) The Flow Panel extends the Sankey diagram [36] to organize the entire collection of family trees. (b) The Detail Panel shows the composition of the selected Sankey nodes using a space-filling visualization. (c) The Analysis Panel reports the results of the Multinomial Logit Model [19] estimations for all trees in the selected Sankey nodes, allowing experts to quantitatively analyze the statistical associations between specific ancestral traits and tree structural patterns.","img_size":{"width":2148,"height":915},"subfigures":[{"x":5.717878232328084,"y":10.797758566476334,"width":2131.883787521149,"height":894.965765031,"type":"interface","id":"interface-0"}],"visualizations":[{"x":905.7194421657094,"y":38.120180475799856,"width":1210.5627563576704,"height":325.98851517637416,"type":"heatmap","id":"heatmap-0"},{"x":10.572600492206728,"y":59.265381460213334,"width":851.0943396226417,"height":833.4733388022971,"type":"heatmap","id":"heatmap-1"},{"x":893.3847415914687,"y":374.6812961443808,"width":1217.611156685808,"height":533.9163248564396,"type":"line_chart","id":"line_chart-2"},{"x":11.812779694221048,"y":58.55173154452316,"width":849.3602903950019,"height":837.5523144872323,"type":"sankey_diagram","id":"sankey_diagram-5"},{"x":905.7194421657094,"y":36.3580803937654,"width":1210.5627563576704,"height":327.7506152584086,"type":"tree","id":"tree-3"},{"x":904.864652255161,"y":36.03021955320377,"width":1215.668234994275,"height":333.2893824132218,"type":"treemap","id":"treemap-6"}],"relations":[{"vislist":[{"vislist":["heatmap-1"],"relation":null,"id":"group-0"},{"vislist":["sankey_diagram-5"],"relation":null,"id":"group-1"}],"relation":"nested","id":"relation-0"},{"vislist":[{"vislist":["heatmap-0"],"relation":null,"id":"group-2"},{"vislist":["treemap-6"],"relation":null,"id":"group-3"}],"relation":"coordinated","id":"relation-1"},{"vislist":[{"vislist":["line_chart-2"],"relation":null,"id":"group-6"}],"relation":"repeated","id":"relation-3"},{"vislist":[{"vislist":[{"vislist":[{"vislist":["tree-3"],"relation":null,"id":"group-4"},{"vislist":["treemap-6"],"relation":null,"id":"group-5"}],"relation":"nested","id":"relation-2"}],"relation":null,"id":"group-7"}],"relation":"repeated","id":"relation-4"}]},"2931_0":{"comp":[["scatterplot","scatterplot",["repeated"]],["line_chart","line_chart",["repeated"]]],"visType":["scatterplot","line_chart"],"compType":["repeated"],"compressed_tree":[{"composite_pattern":"repeated","visualization_type":[["scatterplot"]]},{"composite_pattern":"repeated","visualization_type":[["line_chart"]]}],"coOccurrence":[["scatterplot","line_chart",["coOccurrence"]]],"year":2017,"conference":["VAST"],"authors":["Jiazhi Xia","Fenjin Ye","Wei Che","Yusi Wang","Weifeng Che","Yuxin Ma","Anthony K. H. Tung"],"title":"LDSScanner: Exploratory Analysis of Low-Dimensional Structures in High-Dimensional Datasets","doi":"10.1109/TVCG.2017.2744098","abstract":"Many approaches for analyzing a high-dimensional dataset assume that the dataset contains specific structures, e.g., clusters in linear subspaces or non-linear manifolds. This yields a trial-and-error process to verify the appropriate model and parameters. This paper contributes an exploratory interface that supports visual identification of low-dimensional structures in a high-dimensional dataset, and facilitates the optimized selection of data models and configurations. Our key idea is to abstract a set of global and local feature descriptors from the neighborhood graph-based representation of the latent low-dimensional structure, such as pairwise geodesic distance (GD) among points and pairwise local tangent space divergence (LTSD) among pointwise local tangent spaces (LTS). We propose a new LTSD-GD view, which is constructed by mapping LTSD and GD to the<inline-formula><tex-math notation=\\"LaTeX\\">$x$</tex-math><alternatives><inline-graphic xlink:href=\\"24tvcg01-xia-2744098-ieq-1-source.tif\\" xmlns:xlink=\\"http://www.w3.org/1999/xlink\\"/></alternatives></inline-formula>axis and<inline-formula><tex-math notation=\\"LaTeX\\">$y$</tex-math><alternatives><inline-graphic xlink:href=\\"24tvcg01-xia-2744098-ieq-2-source.tif\\" xmlns:xlink=\\"http://www.w3.org/1999/xlink\\"/></alternatives></inline-formula>axis using 1D multidimensional scaling, respectively. Unlike traditional dimensionality reduction methods that preserve various kinds of distances among points, the LTSD-GD view presents the distribution of pointwise LTS (<inline-formula><tex-math notation=\\"LaTeX\\">$x$</tex-math><alternatives><inline-graphic xlink:href=\\"24tvcg01-xia-2744098-ieq-3-source.tif\\" xmlns:xlink=\\"http://www.w3.org/1999/xlink\\"/></alternatives></inline-formula>axis) and the variation of LTS in structures (the combination of<inline-formula><tex-math notation=\\"LaTeX\\">$x$</tex-math><alternatives><inline-graphic xlink:href=\\"24tvcg01-xia-2744098-ieq-4-source.tif\\" xmlns:xlink=\\"http://www.w3.org/1999/xlink\\"/></alternatives></inline-formula>axis and<inline-formula><tex-math notation=\\"LaTeX\\">$y$</tex-math><alternatives><inline-graphic xlink:href=\\"24tvcg01-xia-2744098-ieq-5-source.tif\\" xmlns:xlink=\\"http://www.w3.org/1999/xlink\\"/></alternatives></inline-formula>axis). We design and implement a suite of visual tools for navigating and reasoning about intrinsic structures of a high-dimensional dataset. Three case studies verify the effectiveness of our approach.","keywords":"High-dimensional data,low-dimensional structure,subspace,manifold,visual exploration","caption":"Fig. 1. The exploratory interface of LDSScanner, after the analyst has identified structures. (a)The configuration panel. (b) The identified-structures view. (c) The t-SNE view. (d) The LTSD-GD view. (e) Bar chart of estimated local dimensionality. (f) Scree plot of pointwise LTS. (g) Scree plot of structures.","img_size":{"width":1938,"height":1110},"subfigures":[{"x":6.098606315917928,"y":20.311835219370387,"width":1918.222183028746,"height":1076.957100146165,"type":"interface","id":"interface-0"}],"visualizations":[{"x":11.660668380462655,"y":844.6272493573264,"width":494.4555141921514,"height":256.1611323854123,"type":"bar_chart","id":"bar_chart-0"},{"x":528.1388174807199,"y":801.8251928020566,"width":684.8329048843189,"height":293.90745501285363,"type":"line_chart","id":"line_chart-1"},{"x":1230.0925449871465,"y":801.8251928020566,"width":699.100257069409,"height":296.7609254498716,"type":"line_chart","id":"line_chart-2"},{"x":285.03734439834017,"y":16.887966804979254,"width":802.3816787379064,"height":767.8164033749694,"type":"scatterplot","id":"scatterplot-3"},{"x":1109.4771784232364,"y":24.564315352697104,"width":714.137217463653,"height":754.4331139532154,"type":"scatterplot","id":"scatterplot-4"},{"x":3.1002570694086558,"y":456.55526992287923,"width":253.95886889460158,"height":328.14910025706934,"type":"table","id":"table-6"}],"relations":[{"vislist":[{"vislist":["scatterplot-3","scatterplot-4"],"relation":null,"id":"group-0"}],"relation":"repeated","id":"relation-0"},{"vislist":[{"vislist":["line_chart-1","line_chart-2"],"relation":null,"id":"group-1"}],"relation":"repeated","id":"relation-1"}]},"2933_0":{"comp":[["bar_chart","bar_chart",["repeated"]],["heatmap","matrix",["coordinated"]]],"visType":["bar_chart","heatmap","matrix"],"compType":["repeated","coordinated"],"compressed_tree":[{"composite_pattern":"repeated","visualization_type":[["bar_chart"]]},{"composite_pattern":"coordinated","visualization_type":[["heatmap"],["matrix"]]}],"coOccurrence":[["bar_chart","heatmap",["coOccurrence"]],["bar_chart","matrix",["coOccurrence"]],["heatmap","matrix",["coOccurrence"]]],"year":2017,"conference":["VAST"],"authors":["Nicola Pezzotti","Thomas H\xf6llt","Jan C. van Gemert","Boudewijn P. F. Lelieveldt","Elmar Eisemann","Anna Vilanova"],"title":"DeepEyes: Progressive Visual Analytics for Designing Deep Neural Networks","doi":"10.1109/TVCG.2017.2744358","abstract":"Deep neural networks are now rivaling human accuracy in several pattern recognition problems. Compared to traditional classifiers, where features are handcrafted, neural networks learn increasingly complex features directly from the data. Instead of handcrafting the features, it is now the network architecture that is manually engineered. The network architecture parameters such as the number of layers or the number of filters per layer and their interconnections are essential for good performance. Even though basic design guidelines exist, designing a neural network is an iterative trial-and-error process that takes days or even weeks to perform due to the large datasets used for training. In this paper, we present DeepEyes, a Progressive Visual Analytics system that supports the design of neural networks during training. We present novel visualizations, supporting the identification of layers that learned a stable set of patterns and, therefore, are of interest for a detailed analysis. The system facilitates the identification of problems, such as superfluous filters or layers, and information that is not being captured by the network. We demonstrate the effectiveness of our system through multiple use cases, showing how a trained network can be compressed, reshaped and adapted to different problems.","keywords":"Progressive visual analytics,deep neural networks,machine learning","caption":"Fig. 1. DeepEyes is a Progressive Visual Analytics system for the analysis of deep neural networks during training. The overview on the training is given by the commonly used loss- and accuracy-curves (a) and the Perplexity Histograms (b) a novel visualization that allows the detection of stable layers. A detailed analysis per layer is performed in three tightly linked visualizations. Degenerated filters are detected in the Activation Heatmap (c), and filter activations are visualized on the Input Map (d). Finally, in the Filter Map (e), relationships among the filters in a layer are visualized.","img_size":{"width":1936,"height":1006},"subfigures":[{"x":19.1390981373618,"y":23.933959513321984,"width":1897.7218037252755,"height":953.9107981679294,"type":"interface","id":"interface-0"}],"visualizations":[{"x":59.9487554904831,"y":266.597364568082,"width":312.2576866764276,"height":136.98096632503666,"type":"bar_chart","id":"bar_chart-0"},{"x":68.78623718887258,"y":438.9282576866765,"width":297.5285505124452,"height":147.29136163982434,"type":"bar_chart","id":"bar_chart-1"},{"x":64.36749633967787,"y":612.732064421669,"width":303.42020497803793,"height":153.18301610541732,"type":"bar_chart","id":"bar_chart-2"},{"x":71.73206442166908,"y":788.00878477306,"width":294.58272327964863,"height":141.39970717423137,"type":"bar_chart","id":"bar_chart-3"},{"x":456.1625183016098,"y":271.76240934614884,"width":1416.9428989751082,"height":122.60229843478109,"type":"heatmap","id":"heatmap-4"},{"x":193.98389458272325,"y":73.64568081991216,"width":1673.2298682284045,"height":123.72474377745247,"type":"line_chart","id":"line_chart-5"},{"x":482.6749633967788,"y":540.5592972181554,"width":425.6720351390923,"height":253.34114202049787,"type":"scatterplot","id":"scatterplot-6"},{"x":1451.8521229868227,"y":481.6427525622256,"width":387.376281112738,"height":319.6222547584189,"type":"scatterplot","id":"scatterplot-7"},{"x":458.028526039917,"y":271.92347384024845,"width":1415.343701290958,"height":125.93728984711083,"type":"matrix","id":"matrix-8"}],"relations":[{"vislist":[{"id":"group-0","relation":null,"vislist":["bar_chart-0","bar_chart-1","bar_chart-2","bar_chart-3"]}],"relation":"repeated","id":"relation-0"},{"vislist":[{"id":"group-1","relation":null,"vislist":["heatmap-4"]},{"id":"group-2","relation":null,"vislist":["matrix-8"]}],"relation":"coordinated","id":"relation-1"}]},"2934_0":{"comp":[["tree","tree",["repeated"]],["bar_chart","bar_chart",["repeated"]]],"visType":["tree","bar_chart"],"compType":["repeated"],"compressed_tree":[{"composite_pattern":"repeated","visualization_type":[["tree"]]},{"composite_pattern":"repeated","visualization_type":[["bar_chart"]]}],"coOccurrence":[["tree","bar_chart",["coOccurrence"]]],"year":2017,"conference":["VAST"],"authors":["Shixia Liu","Jiannan Xiao","Junlin Liu","Xiting Wang","Jing Wu","Jun Zh"],"title":"Visual Diagnosis of Tree Boosting Methods","doi":"10.1109/TVCG.2017.2744378","abstract":"Tree boosting, which combines weak learners (typically decision trees) to generate a strong learner, is a highly effective and widely used machine learning method. However, the development of a high performance tree boosting model is a time-consuming process that requires numerous trial-and-error experiments. To tackle this issue, we have developed a visual diagnosis tool, BOOSTVis, to help experts quickly analyze and diagnose the training process of tree boosting. In particular, we have designed a temporal confusion matrix visualization, and combined it with a t-SNE projection and a tree visualization. These visualization components work together to provide a comprehensive overview of a tree boosting model, and enable an effective diagnosis of an unsatisfactory training process. Two case studies that were conducted on the Otto Group Product Classification Challenge dataset demonstrate that BOOSTVis can provide informative feedback and guidance to improve understanding and diagnosis of tree boosting algorithms.","keywords":"tree boosting,model analysis,temporal confusion matrix,tree visualization","caption":"Fig. 1. BOOSTVis: (a) the temporal confusion matrix shows the evolution of model performance at the class-level; (b) the instance view reveals the relationships between instances using the t-SNE projection; (c) the classifier view provides an overview of all the decision trees and displays the selected one; (d) the feature view displays the feature distributions on the selected subsets of instances.","img_size":{"width":1947,"height":1012},"subfigures":[{"x":39.008874846478264,"y":12.903224840360084,"width":1898.6796129781153,"height":960.7288671578447,"type":"interface","id":"interface-0"}],"visualizations":[{"x":46.69765739385069,"y":60.74963396778917,"width":699.3616398243043,"height":471.18008784773065,"type":"area_chart","id":"area_chart-0"},{"x":1590.6273792093707,"y":17.780380673499295,"width":354.12591508052714,"height":960.1405563689613,"type":"bar_chart","id":"bar_chart-1"},{"x":748.5923555799222,"y":309.96146813160095,"width":833.4524949184163,"height":46.42391392819966,"type":"bar_chart","id":"bar_chart-2"},{"x":809.3419895477117,"y":357.37581659426576,"width":711.2152269399701,"height":619.3499267935579,"type":"sankey_diagram","id":"sankey_diagram-5"},{"x":274.8792093704247,"y":573.4172767203511,"width":429.69253294289905,"height":392.65007320644224,"type":"scatterplot","id":"scatterplot-3"},{"x":750.0740539693811,"y":40.29236125019545,"width":835.3329227748047,"height":265.66112712189744,"type":"tree","id":"tree-4"}],"relations":[{"vislist":[{"vislist":["tree-4"],"relation":null,"id":"group-0"}],"relation":"repeated","id":"relation-0"},{"vislist":[{"vislist":["bar_chart-1"],"relation":null,"id":"group-1"}],"relation":"repeated","id":"relation-1"}]},"2935_1":{"comp":[["scivis","scivis",["repeated"]]],"visType":["scivis"],"compType":["repeated"],"compressed_tree":[{"composite_pattern":"repeated","visualization_type":[["scivis"]]}],"coOccurrence":[["scivis","scivis",["coOccurrence"]]],"year":2017,"conference":["VAST"],"authors":["Jie Liu","Tim Dwyer","Kim Marriott","Jeremy Millar","Annette Haworth"],"title":"Understanding the Relationship Between Interactive Optimisation and Visual Analytics in the Context of Prostate Brachytherapy","doi":"10.1109/TVCG.2017.2744418","abstract":"The fields of operations research and computer science have long sought to find automatic solver techniques that can find high-quality solutions to difficult real-world optimisation problems. The traditional workflow is to exactly model the problem and then enter this model into a general-purpose \u201cblack-box\u201d solver. In practice, however, many problems cannot be solved completely automatically, but require a \u201chuman-in-the-loop\u201d to iteratively refine the model and give hints to the solver. In this paper, we explore the parallels between this interactive optimisation workflow and the visual analytics sense-making loop. We assert that interactive optimisation is essentially a visual analytics task and propose a problem-solving loop analogous to the sense-making loop. We explore these ideas through an in-depth analysis of a use-case in prostate brachytherapy, an application where interactive optimisation may be able to provide significant assistance to practitioners in creating prostate cancer treatment plans customised to each patient\'s tumour characteristics. However, current brachytherapy treatment planning is usually a careful, mostly manual process involving multiple professionals. We developed a prototype interactive optimisation tool for brachytherapy that goes beyond current practice in supporting focal therapy - targeting tumour cells directly rather than simply seeking coverage of the whole prostate gland. We conducted semi-structured interviews, in two stages, with seven radiation oncology professionals in order to establish whether they would prefer to use interactive optimisation for treatment planning and whether such a tool could improve their trust in the novel focal therapy approach and in machine generated solutions to the problem.","keywords":"Visual analytics,interactive optimisation,interactive systems and tools,prostate brachytherapy","caption":"Fig. 2. A sample treatment plan shown in presentation mode after Study Fig. 1 & 2 improvements. The white text is not part of the interface but added view for explanation purpose. Bott","img_size":{"width":1057,"height":570},"subfigures":[{"x":6.967912401600656,"y":4.249662090948753,"width":1043.0641751967974,"height":560.7221101904636,"type":"interface","id":"interface-0"}],"visualizations":[{"x":798.5328227571117,"y":255.68927789934352,"width":249.45295404813984,"height":311.81619256017507,"type":"bar_chart","id":"bar_chart-0"},{"x":201.09299781181625,"y":26.192560175054705,"width":278.1400437636762,"height":249.45295404814007,"type":"scivis","id":"scivis-1"},{"x":509.16739606126924,"y":24.945295404814004,"width":279.38730853391684,"height":246.95842450765863,"type":"scivis","id":"scivis-2"},{"x":202.34026258205688,"y":300.59080962800874,"width":276.8927789934355,"height":240.72210065645515,"type":"scivis","id":"scivis-3"},{"x":504.17833698030637,"y":298.09628008752736,"width":286.8708971553612,"height":255.68927789934355,"type":"scivis","id":"scivis-4"}],"relations":[{"vislist":[{"id":"group-0","relation":null,"vislist":["scivis-1","scivis-2","scivis-3","scivis-4"]}],"relation":"repeated","id":"relation-0"}]},"2936_4":{"comp":[["heatmap","heatmap",["repeated"]],["heatmap","map",["coordinated"]],["heatmap","comb",["annotated"]],["comb","comb",["repeated"]],["contour_graph","scatterplot",["accompanied"]],["scatterplot","contour_graph",["accompanied"]],["proportional_area_chart","map",["coordinated"]]],"visType":["heatmap","map","comb","contour_graph","scatterplot","proportional_area_chart"],"compType":["repeated","coordinated","annotated","accompanied"],"compressed_tree":[{"composite_pattern":"repeated","visualization_type":[["heatmap"]]},{"composite_pattern":"coordinated","visualization_type":[["heatmap"],["map"]]},{"composite_pattern":"repeated","visualization_type":[[{"composite_pattern":"coordinated","visualization_type":[["heatmap"],["map"]]}]]},{"composite_pattern":"annotated","visualization_type":[["heatmap"],[{"composite_pattern":"coordinated","visualization_type":[["proportional_area_chart"],["map"]]}]]},{"composite_pattern":"accompanied","visualization_type":[["contour_graph","scatterplot"]]}],"coOccurrence":[["heatmap","map",["coOccurrence"]],["heatmap","proportional_area_chart",["coOccurrence"]],["heatmap","contour_graph",["coOccurrence"]],["heatmap","scatterplot",["coOccurrence"]],["map","proportional_area_chart",["coOccurrence"]],["map","contour_graph",["coOccurrence"]],["map","scatterplot",["coOccurrence"]],["proportional_area_chart","contour_graph",["coOccurrence"]],["proportional_area_chart","scatterplot",["coOccurrence"]],["contour_graph","scatterplot",["coOccurrence"]]],"year":2017,"conference":["VAST"],"authors":["Nan Cao","Chaoguang Lin","Qiuhan Zhu","Yu-Ru Lin","Xian Teng","Xidao Wen"],"title":"Voila: Visual Anomaly Detection and Monitoring with Streaming Spatiotemporal Data","doi":"10.1109/TVCG.2017.2744419","abstract":"The increasing availability of spatiotemporal data continuously collected from various sources provides new opportunities for a timely understanding of the data in their spatial and temporal context. Finding abnormal patterns in such data poses significant challenges. Given that there is often no clear boundary between normal and abnormal patterns, existing solutions are limited in their capacity of identifying anomalies in large, dynamic and heterogeneous data, interpreting anomalies in their multifaceted, spatiotemporal context, and allowing users to provide feedback in the analysis loop. In this work, we introduce a unified visual interactive system and framework, Voila, for interactively detecting anomalies in spatiotemporal data collected from a streaming data source. The system is designed to meet two requirements in real-world applications, i.e., online monitoring and interactivity. We propose a novel tensor-based anomaly analysis algorithm with visualization and interaction design that dynamically produces contextualized, interpretable data summaries and allows for interactively ranking anomalous patterns based on user input. Using the \u201csmart city\u201d as an example scenario, we demonstrate the effectiveness of the proposed framework through quantitative evaluation and qualitative case studies.","keywords":"Anomaly Detection,Visual Analysis","caption":"Fig. 5. The user interface of Voila system consists of eight major views: 1) macro and 2) micro map views; 3) history view; 4) temporal pattern view; 5) feature inspection view; 6) ranking list; 7) snapshot panel; and 8) anomaly panel.","img_size":{"width":1797,"height":1025},"subfigures":[{"x":96.4416058370677,"y":29.85529271951212,"width":1651.7438147798864,"height":977.889884587238,"type":"interface","id":"interface-0"}],"visualizations":[{"x":94.6623798143523,"y":69.25542448815787,"width":320.2711200771984,"height":305.9862676734,"type":"contour_graph","id":"contour_graph-26"},{"x":421.9317343173429,"y":70.67716685724362,"width":661.90036900369,"height":659.5186720195649,"type":"heatmap","id":"heatmap-0"},{"x":1080.6749654218534,"y":59.54356846473029,"width":328.9073305670817,"height":344.50207468879677,"type":"heatmap","id":"heatmap-1"},{"x":116.6362378976487,"y":832.1922544951592,"width":178.63070539419087,"height":72.30290456431544,"type":"heatmap","id":"heatmap-10"},{"x":119.47164591977874,"y":934.2669432918397,"width":174.37759336099592,"height":55.29045643153529,"type":"heatmap","id":"heatmap-11"},{"x":791.8808830226102,"y":364.1333707985746,"width":119.16160269529479,"height":115.20862458127942,"type":"heatmap","id":"heatmap-16"},{"x":775.8885620243989,"y":816.0251188529596,"width":970.5673372562114,"height":191.3851817348265,"type":"heatmap","id":"heatmap-19"},{"x":1240.5605646713855,"y":512.6073724065551,"width":153.860562604245,"height":144.39483982553668,"type":"heatmap","id":"heatmap-2"},{"x":423.6509086535691,"y":74.56741828868043,"width":659.2877122831496,"height":653.3951234759016,"type":"heatmap","id":"heatmap-20"},{"x":1088.9770058632425,"y":509.13525896920146,"width":150.78346930538245,"height":152.7680972413561,"type":"heatmap","id":"heatmap-21"},{"x":120.88934993084374,"y":432.3997233748272,"width":171.54218533886592,"height":79.39142461964042,"type":"heatmap","id":"heatmap-6"},{"x":139.31950207468878,"y":527.3858921161827,"width":158.78284923928084,"height":70.8852005532503,"type":"heatmap","id":"heatmap-7"},{"x":119.3487084870849,"y":616.5129151291512,"width":177.76752767527685,"height":102.12177121771217,"type":"heatmap","id":"heatmap-8"},{"x":119.47164591977874,"y":731.5352697095435,"width":177.21300138312589,"height":75.13831258644541,"type":"heatmap","id":"heatmap-9"},{"x":775.8741331645176,"y":813.2941028752018,"width":967.8693360988854,"height":192.7526730778238,"type":"line_chart","id":"line_chart-18"},{"x":1080.049815498155,"y":408.48708487084855,"width":329.0590405904058,"height":75.64575645756457,"type":"line_chart","id":"line_chart-3"},{"x":421.93173431734317,"y":71.86346863468634,"width":658.1180811808119,"height":658.1180811808117,"type":"map","id":"map-12"},{"x":1083.8321033210332,"y":64.29889298892986,"width":329.0590405904058,"height":340.4059040590405,"type":"map","id":"map-13"},{"x":429.94882434301536,"y":744.2946058091288,"width":313.3125864453668,"height":248.09820193637626,"type":"map","id":"map-14"},{"x":1093.0462730596962,"y":513.2141598942806,"width":146.73522322810513,"height":151.43452974539355,"type":"map","id":"map-22"},{"x":1243.6406434182875,"y":514.7212093418356,"width":153.68153562169314,"height":147.0555839794431,"type":"map","id":"map-23"},{"x":777.254925596284,"y":814.6676793834829,"width":970.5614689895251,"height":192.73521380294167,"type":"proportional_area_chart","id":"proportional_area_chart-17"},{"x":423.63293825320557,"y":75.91309736468848,"width":655.233364768247,"height":650.7037653238846,"type":"proportional_area_chart","id":"proportional_area_chart-24"},{"x":100.43726937269376,"y":70.8091567202131,"width":310.1476014760149,"height":303.2915484411486,"type":"scatterplot","id":"scatterplot-5"},{"x":750.349930843707,"y":771.2309820193636,"width":999.1648293038945,"height":234.85757886624492,"type":"table","id":"table-15"}],"relations":[{"vislist":[{"vislist":["heatmap-11","heatmap-10","heatmap-9","heatmap-8","heatmap-7","heatmap-6"],"relation":null,"id":"group-25"}],"relation":"repeated","id":"relation-11"},{"vislist":[{"vislist":["heatmap-1"],"relation":null,"id":"group-27"},{"vislist":["map-13"],"relation":null,"id":"group-26"}],"relation":"coordinated","id":"relation-12"},{"vislist":[{"vislist":[{"vislist":[{"vislist":["heatmap-2"],"relation":null,"id":"group-33"},{"vislist":["map-23"],"relation":null,"id":"group-32"}],"relation":"coordinated","id":"relation-15"},{"vislist":[{"vislist":["heatmap-21"],"relation":null,"id":"group-31"},{"vislist":["map-22"],"relation":null,"id":"group-30"}],"relation":"coordinated","id":"relation-14"}],"relation":null,"id":"group-34"}],"relation":"repeated","id":"relation-16"},{"vislist":[{"vislist":["heatmap-16"],"relation":null,"id":"group-36"},{"vislist":[{"vislist":[{"vislist":["proportional_area_chart-24"],"relation":null,"id":"group-29"},{"vislist":["map-12"],"relation":null,"id":"group-28"}],"relation":"coordinated","id":"relation-13"}],"relation":null,"id":"group-35"}],"relation":"annotated","id":"relation-17"},{"vislist":[{"vislist":["contour_graph-26","scatterplot-5"],"relation":null,"id":"group-37"}],"relation":"accompanied","id":"relation-18"}]},"2937_5":{"comp":[["stripe_graph","stripe_graph",["stacked","repeated"]],["glyph_based","bar_chart",["nested"]],["comb","comb",["stacked"]],["comb","area_chart",["stacked"]],["area_chart","comb",["stacked"]]],"visType":["stripe_graph","glyph_based","bar_chart","comb","area_chart"],"compType":["stacked","repeated","nested"],"compressed_tree":[{"composite_pattern":"stacked","visualization_type":[[{"composite_pattern":"stacked","visualization_type":[["stripe_graph"]]},{"composite_pattern":"nested","visualization_type":[["glyph_based"],["bar_chart"]]},{"composite_pattern":"repeated","visualization_type":[["stripe_graph"]]}]]},{"composite_pattern":"stacked","visualization_type":[["area_chart",{"composite_pattern":"stacked","visualization_type":[["stripe_graph"]]}]]},{"composite_pattern":"stacked","visualization_type":[["area_chart",{"composite_pattern":"stacked","visualization_type":[["stripe_graph"]]}]]}],"coOccurrence":[["glyph_based","bar_chart",["coOccurrence"]],["glyph_based","stripe_graph",["coOccurrence"]],["glyph_based","area_chart",["coOccurrence"]],["bar_chart","stripe_graph",["coOccurrence"]],["bar_chart","area_chart",["coOccurrence"]],["stripe_graph","area_chart",["coOccurrence"]]],"year":2017,"conference":["VAST"],"authors":["Jian Zhao","Maoyuan Sun","Francine Chen","Patrick Chiu"],"title":"BiDots: Visual Exploration of Weighted Biclusters","doi":"10.1109/TVCG.2017.2744458","abstract":"Discovering and analyzing biclusters, i.e., two sets of related entities with close relationships, is a critical task in many real-world applications, such as exploring entity co-occurrences in intelligence analysis, and studying gene expression in bio-informatics. While the output of biclustering techniques can offer some initial low-level insights, visual approaches are required on top of that due to the algorithmic output complexity. This paper proposes a visualization technique, called BiDots, that allows analysts to interactively explore biclusters over multiple domains. BiDots overcomes several limitations of existing bicluster visualizations by encoding biclusters in a more compact and cluster-driven manner. A set of handy interactions is incorporated to support flexible analysis of biclustering results. More importantly, BiDots addresses the cases of weighted biclusters, which has been underexploited in the literature. The design of BiDots is grounded by a set of analytical tasks derived from previous work. We demonstrate its usefulness and effectiveness for exploring computed biclusters with an investigative document analysis task, in which suspicious people and activities are identified from a text corpus.","keywords":"Biclustering,coordinated relationship analysis,visual analytics","caption":"Fig. 6. The full user interface of BiDots. The visualization displays bicluster chains computed from the results of two biclustering processes on the document-to-topic and topic-to-keyword relationships respectively. The relationships are mined from abstracts of a publication corpus of VIS conferences (from 1990 to 2015) [18] using LDA topic modeling.","img_size":{"width":2151,"height":1555},"subfigures":[{"x":18.551166925445084,"y":9.448057583533467,"width":2109.652060909608,"height":1525.483976491012,"type":"interface","id":"interface-0"}],"visualizations":[{"x":345.4209707060982,"y":398.1532065519495,"width":303.62296220370274,"height":98.43190297309424,"type":"area_chart","id":"area_chart-0"},{"x":1186.9077099327824,"y":399.71852080841245,"width":299.8103613844314,"height":92.85650349693444,"type":"area_chart","id":"area_chart-13"},{"x":2.1659861108654352,"y":495.659212532435,"width":348.8035791432099,"height":934.4471656686208,"type":"bar_chart","id":"bar_chart-1"},{"x":642.2431677652016,"y":494.4494745631624,"width":155.67538321959685,"height":936.590486282518,"type":"bar_chart","id":"bar_chart-10"},{"x":970.9972706691808,"y":495.3372904604102,"width":219.08827116163718,"height":1051.3537848748392,"type":"bar_chart","id":"bar_chart-11"},{"x":1486.9919901115354,"y":493.43639426069524,"width":230.66992602692983,"height":1051.6768032328735,"type":"bar_chart","id":"bar_chart-12"},{"x":3.472468179138559,"y":494.12126787244915,"width":345.19889446068737,"height":937.4242852714037,"type":"glyph_based","id":"glyph_based-2"},{"x":643.9086146774393,"y":494.4627255467017,"width":154.02495814511843,"height":938.3033713361352,"type":"glyph_based","id":"glyph_based-7"},{"x":977.3018781301687,"y":491.7291744698577,"width":214.8813999896643,"height":1056.8306298352513,"type":"glyph_based","id":"glyph_based-8"},{"x":1486.9649687688282,"y":491.7169912165388,"width":227.3630312123407,"height":1055.1156093211878,"type":"glyph_based","id":"glyph_based-9"},{"x":353.1101532567049,"y":494.50191570881236,"width":294.91379310344814,"height":935.3831417624523,"type":"stripe_graph","id":"stripe_graph-3"},{"x":1190.1886973180076,"y":494.50191570881236,"width":294.91379310344894,"height":1057.5191570881227,"type":"stripe_graph","id":"stripe_graph-4"}],"relations":[{"vislist":[{"vislist":[{"vislist":[{"vislist":["stripe_graph-3"],"relation":null,"id":"group-11"}],"relation":"stacked","id":"relation-5"},{"vislist":[{"vislist":["glyph_based-2"],"relation":null,"id":"group-12"},{"vislist":["bar_chart-1"],"relation":null,"id":"group-13"}],"relation":"nested","id":"relation-0"},{"vislist":[{"vislist":["glyph_based-7"],"relation":null,"id":"group-3"},{"vislist":["bar_chart-10"],"relation":null,"id":"group-4"}],"relation":"nested","id":"relation-1"},{"vislist":[{"vislist":["glyph_based-8"],"relation":null,"id":"group-5"},{"vislist":["bar_chart-11"],"relation":null,"id":"group-6"}],"relation":"nested","id":"relation-2"},{"vislist":[{"vislist":["glyph_based-9"],"relation":null,"id":"group-7"},{"vislist":["bar_chart-12"],"relation":null,"id":"group-8"}],"relation":"nested","id":"relation-3"},{"vislist":[{"vislist":["stripe_graph-4"],"relation":null,"id":"group-32"}],"relation":"repeated","id":"relation-6"}],"relation":null,"id":"group-33"}],"relation":"stacked","id":"relation-7"},{"vislist":[{"vislist":["area_chart-0",{"vislist":[{"vislist":["stripe_graph-3"],"relation":null,"id":"group-15"}],"relation":"stacked","id":"relation-5"}],"relation":null,"id":"group-16"}],"relation":"stacked","id":"relation-8"},{"vislist":[{"vislist":["area_chart-13",{"vislist":[{"vislist":["stripe_graph-4"],"relation":null,"id":"group-29"}],"relation":"stacked","id":"relation-6"}],"relation":null,"id":"group-30"}],"relation":"stacked","id":"relation-12"}]},"2942_4":{"comp":[["bar_chart","bar_chart",["repeated"]]],"visType":["bar_chart"],"compType":["repeated"],"compressed_tree":[{"composite_pattern":"repeated","visualization_type":[["bar_chart"]]}],"coOccurrence":[["bar_chart","bar_chart",["coOccurrence"]]],"year":2017,"conference":["VAST"],"authors":["Andrea Unger","Nadine Drager","Mike Sips","Dirk J. Lehmann"],"title":"Understanding a Sequence of Sequences: Visual Exploration of Categorical States in Lake Sediment Cores","doi":"10.1109/TVCG.2017.2744686","abstract":"This design study focuses on the analysis of a time sequence of categorical sequences. Such data is relevant for the geoscientific research field of landscape and climate development. It results from microscopic analysis of lake sediment cores. The goal is to gain hypotheses about landscape evolution and climate conditions in the past. To this end, geoscientists identify which categorical sequences are similar in the sense that they indicate similar conditions. Categorical sequences are similar if they have similar meaning (semantic similarity) and appear in similar time periods (temporal similarity). For data sets with many different categorical sequences, the task to identify similar sequences becomes a challenge. Our contribution is a tailored visual analysis concept that effectively supports the analytical process. Our visual interface comprises coupled visualizations of semantics and temporal context for the exploration and assessment of the similarity of categorical sequences. Integrated automatic methods reduce the analytical effort substantially. They (1) extract unique sequences in the data and (2) rank sequences by a similarity measure during the search for similar sequences. We evaluated our concept by demonstrations of our prototype to a larger audience and hands-on analysis sessions for two different lakes. According to geoscientists, our approach fills an important methodological gap in the application domain.","keywords":"Visualization in Earth Science,Time Series Data,Categorical Data,Design Study","caption":"Fig. 5. Visualization for Step 1: Identify unique sequences and their temporal occurrences. The semantic view (right) shows the unique sequences sorted by frequency from top to bottom (most frequent on top). Each row depicts a unique sequence. Each unique categorical sequence is shown as a series of colored blocks from left to right. A block\u2019s color indicates the state. Frequency is explicitly visualized in small bar charts left to the sequences. The temporal view (left) shows a highly compact representation of the complete time sequence of categorical sequences. The time sequence is split into multiple columns, which are aligned side by side. In a single column, time is mapped from top to bottom. Each row shows the categorical sequence at one time point by diminished visual primitives compared to the semantics view. Small time frames can be shown in detail on the user\u2019s demand (the time subsequence within the black frame is magnified in the detail view on top). Both views are coordinated with a brushing and linking mechanism: The semantic view highlights a selected unique sequence of interest and the temporal view the corresponding time points.","img_size":{"width":2160,"height":1002},"subfigures":[{"x":13.549436099724376,"y":15.645082871341845,"width":2129.7633919251152,"height":969.1404106589843,"type":"interface","id":"interface-0"}],"visualizations":[{"x":0,"y":7.086280056577085,"width":1467.619519094767,"height":960.8995756718526,"type":"bar_chart","id":"bar_chart-0"},{"x":1425.491947291362,"y":10.269399707174228,"width":227.39385065885787,"height":673.3792093704243,"type":"bar_chart","id":"bar_chart-1"},{"x":1796.270599246564,"y":18.62607974537604,"width":345.08530717132805,"height":983.325608298882,"type":"bar_chart","id":"bar_chart-2"}],"relations":[{"vislist":[{"vislist":["bar_chart-0"],"relation":null,"id":"group-0"}],"relation":"repeated","id":"relation-0"}]},"2943_1":{"comp":[["unit_visualization","unit_visualization",["repeated"]],["heatmap","table",["coordinated"]]],"visType":["unit_visualization","heatmap","table"],"compType":["repeated","coordinated"],"compressed_tree":[{"composite_pattern":"coordinated","visualization_type":[["heatmap"],["table"]]},{"composite_pattern":"repeated","visualization_type":[["unit_visualization"]]}],"coOccurrence":[["heatmap","table",["coOccurrence"]],["heatmap","unit_visualization",["coOccurrence"]],["table","unit_visualization",["coOccurrence"]]],"year":2017,"conference":["VAST"],"authors":["Minsuk Kahng","Pierre Y. Andrews","Aditya Kalro","Duen Horng Chau"],"title":"ActiVis: Visual Exploration of Industry-Scale Deep Neural Network Models","doi":"10.1109/TVCG.2017.2744718","abstract":"While deep learning models have achieved state-of-the-art accuracies for many prediction tasks, understanding these models remains a challenge. Despite the recent interest in developing visual tools to help users interpret deep learning models, the complexity and wide variety of models deployed in industry, and the large-scale datasets that they used, pose unique design challenges that are inadequately addressed by existing work. Through participatory design sessions with over 15 researchers and engineers at Facebook, we have developed, deployed, and iteratively improved ActiVis, an interactive visualization system for interpreting large-scale deep learning models and results. By tightly integrating multiple coordinated views, such as a computation graph overview of the model architecture, and a neuron activation view for pattern discovery and comparison, users can explore complex deep neural network models at both the instance-and subset-level. ActiVis has been deployed on Facebook\'s machine learning platform. We present case studies with Facebook researchers and engineers, and usage scenarios of how ActiVis may work with different models.","keywords":"Visual analytics,deep learning,machine learning,information visualization","caption":"Fig. 2. ACTI V IS integrates multiple coordinated views. A. The computation graph summarizes the model architecture. B. The neuron activation panel\u2019s matrix view displays activations for instances, subsets, and classes (at B1), and its projected view shows a 2-D t-SNE projection of the instance activations (at B2). C. The instance selection panel displays instances and their classification results; correctly classified instances shown on the left, misclassified on the right. Clicking an instance adds it to the neuron activation matrix view. The dataset used is from the public TREC question answering data collections [25]. The trained model is a word-level convolutional model based on [19].","img_size":{"width":2157,"height":1323},"subfigures":[{"x":13.938575905172518,"y":13.445175542382882,"width":2129.122848189658,"height":1296.1096489152337,"type":"interface","id":"interface-0"}],"visualizations":[{"x":26.179431072210033,"y":188.17286652078772,"width":1525.647702407002,"height":515.3041575492342,"type":"graph","id":"graph-0"},{"x":1583.6717724288837,"y":321.3413566739606,"width":411.0853391684903,"height":159.22319474835888,"type":"unit_visualization","id":"unit_visualization-1"},{"x":341.730853391685,"y":782.5651537335285,"width":908.1974042949913,"height":462.27073248091364,"type":"heatmap","id":"heatmap-2"},{"x":1586.5667396061274,"y":497.93435448577685,"width":512.4091903719911,"height":107.11378555798692,"type":"unit_visualization","id":"unit_visualization-3"},{"x":1583.6717724288837,"y":622.417943107221,"width":457.4048140043767,"height":75.26914660831515,"type":"unit_visualization","id":"unit_visualization-4"},{"x":1586.5667396061274,"y":697.6870897155361,"width":483.4595185995624,"height":101.32385120350102,"type":"unit_visualization","id":"unit_visualization-5"},{"x":1583.6717724288837,"y":813.4857768052517,"width":518.199124726477,"height":127.3785557986871,"type":"unit_visualization","id":"unit_visualization-6"},{"x":1580.776805251641,"y":961.1291028446391,"width":523.9890590809628,"height":112.90371991247262,"type":"unit_visualization","id":"unit_visualization-7"},{"x":1279.7002188183808,"y":854.0153172866521,"width":248.9671772428885,"height":240.2822757111599,"type":"scatterplot","id":"scatterplot-8"},{"x":347.2664714494876,"y":786.4392386530012,"width":906.379042773707,"height":458.3966475614408,"type":"table","id":"table-9"}],"relations":[{"vislist":[{"id":"group-0","relation":null,"vislist":["heatmap-2"]},{"id":"group-1","relation":null,"vislist":["table-9"]}],"relation":"coordinated","id":"relation-0"},{"vislist":[{"id":"group-2","relation":null,"vislist":["unit_visualization-3","unit_visualization-1","unit_visualization-4","unit_visualization-5","unit_visualization-6","unit_visualization-7"]}],"relation":"repeated","id":"relation-1"}]},"2945_0":{"comp":[["bar_chart","bar_chart",["repeated"]],["bar_chart","area_chart",["stacked"]],["area_chart","bar_chart",["stacked"]]],"visType":["bar_chart","area_chart"],"compType":["repeated","stacked"],"compressed_tree":[{"composite_pattern":"repeated","visualization_type":[["bar_chart"]]},{"composite_pattern":"stacked","visualization_type":[["area_chart","bar_chart"]]}],"coOccurrence":[["bar_chart","area_chart",["coOccurrence"]]],"year":2017,"conference":["VAST"],"authors":["Roger A. Leite","Theresia Gschwandtner","Silvia Miksch","Simone Kriglstein","Margit Pohl","Erich Gstrein","Johannes Kuntner"],"title":"EVA: Visual Analytics to Identify Fraudulent Events","doi":"10.1109/TVCG.2017.2744758","abstract":"Financial institutions are interested in ensuring security and quality for their customers. Banks, for instance, need to identify and stop harmful transactions in a timely manner. In order to detect fraudulent operations, data mining techniques and customer profile analysis are commonly used. However, these approaches are not supported by Visual Analytics techniques yet. Visual Analytics techniques have potential to considerably enhance the knowledge discovery process and increase the detection and prediction accuracy of financial fraud detection systems. Thus, we propose EVA, a Visual Analytics approach for supporting fraud investigation, fine-tuning fraud detection algorithms, and thus, reducing false positive alarms.","keywords":"Visual Knowledge Discovery,Time Series Data,Business and Finance Visualization,Financial Fraud Detection","caption":"Fig. 1. Screenshot of EVA (Event detection with Visual Analytics). (A.1, A.2) Temporal Views: a filter was applied in (A.2) to the period from January 2014 until April 2014. (B) Score Construction View: each line represents a transaction and its scores. (C) Amount vs Overall Score Scatterplot. (D.1, D.2) Ranks of accounts that received the highest amounts of money from the selected account and accounts that received the highest number of transactions from the selected account. (E) Accounts Selector: bars shows amount of transactions from each account. (F) Dynamic Table of raw transaction data. In all views, elements that represents suspicious data are highlighted in red.","img_size":{"width":1959,"height":1080},"subfigures":[{"x":21.198141892246507,"y":22.68650341556479,"width":1928.4071385163702,"height":1043.4780550409773,"type":"interface","id":"interface-0"}],"visualizations":[{"x":77.46322489391801,"y":348.28854314002814,"width":814.2008486562942,"height":85.54455445544555,"type":"area_chart","id":"area_chart-0"},{"x":39.273691654879826,"y":68.74115983026874,"width":860.0282885431399,"height":252.050919377652,"type":"bar_chart","id":"bar_chart-1"},{"x":923.7432814710041,"y":446.05374823196604,"width":320.7920792079208,"height":271.9094766619518,"type":"bar_chart","id":"bar_chart-2"},{"x":929.8536067892502,"y":763.7906647807638,"width":320.7920792079208,"height":271.9094766619518,"type":"bar_chart","id":"bar_chart-3"},{"x":1283.7372999210606,"y":68.0219913224753,"width":655.6925876578784,"height":92.03795736251456,"type":"bar_chart","id":"bar_chart-7"},{"x":14.83239038189538,"y":473.5502121640735,"width":915.0212164073548,"height":603.3946251768032,"type":"parallel_coordinate","id":"parallel_coordinate-4"},{"x":920.6881188118814,"y":76.37906647807634,"width":333.01272984441295,"height":311.6265912305516,"type":"scatterplot","id":"scatterplot-5"},{"x":1270.504243281471,"y":201.64073550212154,"width":672.135785007072,"height":814.200848656294,"type":"table","id":"table-6"}],"relations":[{"vislist":[{"vislist":["bar_chart-2","bar_chart-3"],"relation":null,"id":"group-0"}],"relation":"repeated","id":"relation-0"},{"vislist":[{"vislist":["area_chart-0","bar_chart-1"],"relation":null,"id":"group-1"}],"relation":"stacked","id":"relation-1"}]},"2947_1":{"comp":[["scatterplot","scatterplot",["repeated"]]],"visType":["scatterplot"],"compType":["repeated"],"compressed_tree":[{"composite_pattern":"repeated","visualization_type":[["scatterplot"]]}],"coOccurrence":[["scatterplot","scatterplot",["coOccurrence"]]],"year":2017,"conference":["VAST"],"authors":["J\xfcrgen Bernard","Marco Hutter","Matthias Zeppelzauer","Dieter W. Fellner","Michael Sedlmair"],"title":"Comparing Visual-Interactive Labeling with Active Learning: An Experimental Study","doi":"10.1109/TVCG.2017.2744818","abstract":"Labeling data instances is an important task in machine learning and visual analytics. Both fields provide a broad set of labeling strategies, whereby machine learning (and in particular active learning) follows a rather model-centered approach and visual analytics employs rather user-centered approaches (visual-interactive labeling). Both approaches have individual strengths and weaknesses. In this work, we conduct an experiment with three parts to assess and compare the performance of these different labeling strategies. In our study, we (1) identify different visual labeling strategies for user-centered labeling, (2) investigate strengths and weaknesses of labeling strategies for different labeling tasks and task complexities, and (3) shed light on the effect of using different visual encodings to guide the visual-interactive labeling process. We further compare labeling of single versus multiple instances at a time, and quantify the impact on efficiency. We systematically compare the performance of visual interactive labeling with that of active learning. Our main findings are that visual-interactive labeling can outperform active learning, given the condition that dimension reduction separates well the class distributions. Moreover, using dimension reduction in combination with additional visual encodings that expose the internal state of the learning model turns out to improve the performance of visual-interactive labeling.","keywords":"Labeling,Visual-Interactive Labeling,Information Visualization,Visual Analytics,Active Learning,Machine Learning,Classification,Evaluation,Experiment,Dimensionality Reduction","caption":"Fig. 2: Visual-interactive interface for labeling instances. Four dimen-sionality reduction techniques provide different perspectives on the dataset (default: t-SNE). In the center instances can be selected for labeling.At the right, users can refine selections and label multiple instances atonce (inTR3). Four different VIL-support techniques can be includedto ease the visual-interactive labeling process (see Figure 1)","img_size":{"width":1067,"height":722},"subfigures":[{"x":13.639361856712027,"y":8.317392023382414,"width":1041.6940454808284,"height":706.3513990815777,"type":"interface","id":"interface-0"}],"visualizations":[{"x":185.34189723320162,"y":32.81817501429984,"width":690.6086956521739,"height":683.4743083003954,"type":"scatterplot","id":"scatterplot-0"},{"x":16.97035573122531,"y":29.964420073588382,"width":168.3715415019763,"height":176.93280632411071,"type":"scatterplot","id":"scatterplot-1"},{"x":12.689723320158123,"y":206.89722639769911,"width":172.65217391304353,"height":166.9446640316206,"type":"scatterplot","id":"scatterplot-2"},{"x":14.116600790513814,"y":373.8418904293197,"width":171.2252964426878,"height":169.79841897233206,"type":"scatterplot","id":"scatterplot-3"},{"x":11.262845849802375,"y":543.6403094016517,"width":172.65217391304353,"height":172.6521739130435,"type":"scatterplot","id":"scatterplot-4"}],"relations":[{"vislist":[{"id":"group-0","relation":null,"vislist":["scatterplot-1","scatterplot-2","scatterplot-3","scatterplot-4"]}],"relation":"repeated","id":"relation-0"}]},"2950_0":{"comp":[["area_chart","area_chart",["repeated"]]],"visType":["area_chart"],"compType":["repeated"],"compressed_tree":[{"composite_pattern":"repeated","visualization_type":[["area_chart"]]},{"composite_pattern":"repeated","visualization_type":[["area_chart"]]}],"coOccurrence":[["area_chart","area_chart",["coOccurrence"]]],"year":2017,"conference":["VAST"],"authors":["Robert Pienta","Fred Hohman","Alex Endert","Acar Tamersoy","Kevin A. Roundy","Christopher Gate","Shamkant B. Navathe","Duen Horng Chau"],"title":"VIGOR: Interactive Visual Exploration of Graph Query Results","doi":"10.1109/TVCG.2017.2744898","abstract":"Finding patterns in graphs has become a vital challenge in many domains from biological systems, network security, to finance (e.g., finding money laundering rings of bankers and business owners). While there is significant interest in graph databases and querying techniques, less research has focused on helping analysts make sense of underlying patterns within a group of subgraph results. Visualizing graph query results is challenging, requiring effective summarization of a large number of subgraphs, each having potentially shared node-values, rich node features, and flexible structure across queries. We present VIGOR, a novel interactive visual analytics system, for exploring and making sense of query results. VIGOR uses multiple coordinated views, leveraging different data representations and organizations to streamline analysts sensemaking process. VIGOR contributes: (1) an exemplar-based interaction technique, where an analyst starts with a specific result and relaxes constraints to find other similar results or starts with only the structure (i.e., without node value constraints), and adds constraints to narrow in on specific results; and (2) a novel feature-aware subgraph result summarization. Through a collaboration with Symantec, we demonstrate how VIGOR helps tackle real-world problems through the discovery of security blindspots in a cybersecurity dataset with over 11,000 incidents. We also evaluate VIGOR with a within-subjects study, demonstrating VIGOR\'s ease of use over a leading graph database management system, and its ability to help analysts understand their results at higher speed and make fewer errors.","keywords":"graph querying,subgraph results,query result visualization","caption":"Fig. 1. A screenshot of VIGOR showing an analyst exploring a DBLP co-authorship network, looking for researchers who have co-authored papers at the VAST and KDD conferences. (A) The Exemplar View visualizes the query, and (B) the Fusion Graph shows the induced graph formed by joining all query matches. Picking constant node values (e.g., Shixia) in the Exemplar View filters the Fusion Graph. (C) Hovering over a node shows its details. (D) The Subgraph Embedding embeds each match as a point in lower-dimensional space and clusters them to allow analysts to see patterns and outliers. (E) The Feature Explorer summarizes each cluster\u2019s feature distributions.","img_size":{"width":1954,"height":919},"subfigures":[{"x":17.898441764255168,"y":58.1257732679779,"width":1915.3646276286133,"height":846.7707304141313,"type":"interface","id":"interface-0"}],"visualizations":[{"x":1720.0426695842455,"y":142.77680525164115,"width":195.0612691466083,"height":62.339168490153185,"type":"area_chart","id":"area_chart-0"},{"x":1720.0426695842455,"y":213.15973741794315,"width":203.10503282275704,"height":62.339168490153185,"type":"area_chart","id":"area_chart-1"},{"x":1718.031728665208,"y":279.52078774617064,"width":203.10503282275704,"height":68.37199124726482,"type":"area_chart","id":"area_chart-2"},{"x":1711.9989059080963,"y":731.9824945295405,"width":207.12691466083152,"height":64.35010940919038,"type":"area_chart","id":"area_chart-3"},{"x":1718.031728665208,"y":798.343544857768,"width":209.13785557986876,"height":62.33916849015315,"type":"area_chart","id":"area_chart-4"},{"x":1716.0207877461705,"y":862.6936542669584,"width":209.13785557986876,"height":46.25164113785558,"type":"area_chart","id":"area_chart-5"},{"x":1718.031728665208,"y":349.90371991247264,"width":195.0612691466083,"height":351.91466083150993,"type":"bar_chart","id":"bar_chart-6"},{"x":28.841356673960604,"y":102.55798687089717,"width":321.75054704595186,"height":193.05032822757113,"type":"graph","id":"graph-7"},{"x":282.2199124726477,"y":265.4442013129103,"width":697.7964989059083,"height":424.3085339168491,"type":"graph","id":"graph-8"},{"x":982.027352297593,"y":100.54704595185996,"width":725.9496717724293,"height":772.2013129102845,"type":"scatterplot","id":"scatterplot-9"}],"relations":[{"vislist":[{"id":"group-0","relation":null,"vislist":["area_chart-0","area_chart-1","area_chart-2"]}],"relation":"repeated","id":"relation-0"},{"vislist":[{"id":"group-1","relation":null,"vislist":["area_chart-3","area_chart-4","area_chart-5"]}],"relation":"repeated","id":"relation-1"}]},"2952_0":{"comp":[["bar_chart","bar_chart",["repeated"]],["bar_chart","table",["nested"]],["comb","table",["nested"]]],"visType":["bar_chart","table","comb"],"compType":["repeated","nested"],"compressed_tree":[{"composite_pattern":"nested","visualization_type":[[{"composite_pattern":"repeated","visualization_type":[["bar_chart"]]}],["table"]]},{"composite_pattern":"nested","visualization_type":[["bar_chart"],["table"]]}],"coOccurrence":[["bar_chart","table",["coOccurrence"]]],"year":2017,"conference":["VAST"],"authors":["Emily Wall","Subhajit Das","Ravish Chawla","Bharath Kalidindi","Eli T. Brown","Alex Endert"],"title":"Podium: Ranking Data Using Mixed-Initiative Visual Analytics","doi":"10.1109/TVCG.2017.2745078","abstract":"People often rank and order data points as a vital part of making decisions. Multi-attribute ranking systems are a common tool used to make these data-driven decisions. Such systems often take the form of a table-based visualization in which users assign weights to the attributes representing the quantifiable importance of each attribute to a decision, which the system then uses to compute a ranking of the data. However, these systems assume that users are able to quantify their conceptual understanding of how important particular attributes are to a decision. This is not always easy or even possible for users to do. Rather, people often have a more holistic understanding of the data. They form opinions that data point A is better than data point B but do not necessarily know which attributes are important. To address these challenges, we present a visual analytic application to help people rank multi-variate data points. We developed a prototype system, Podium, that allows users to drag rows in the table to rank order data points based on their perception of the relative value of the data. Podium then infers a weighting model using Ranking SVM that satisfies the user\'s data preferences as closely as possible. Whereas past systems help users understand the relationships between data points based on changes to attribute weights, our approach helps users to understand the attributes that might inform their understanding of the data. We present two usage scenarios to describe some of the potential uses of our proposed technique: (1) understanding which attributes contribute to a user\'s subjective preferences for data, and (2) deconstructing attributes of importance for existing rankings. Our proposed approach makes powerful machine learning techniques more usable to those who may not have expertise in these areas.","keywords":"Mixed-initiative visual analytics,multi-attribute ranking,user interaction","caption":"Fig. 1: The Podium interface contains two primary views: (a) the main table, which displays each data point as a row in the table and each attribute as a column; and (b) the control panel, which has controls for the visual encodings in the table, attribute weights, and the underlying Ranking SVM model. The callout box (c) shows the Relative Rank column, which displays the current relative position of the rows used to train the model as well as the previous user-defined relative rank. The interface is described in detail in Section 4.1.","img_size":{"width":1914,"height":853},"subfigures":[{"x":18.921608385800866,"y":16.55856667154732,"width":1876.1567832283968,"height":825.4375199198987,"type":"interface","id":"interface-0"}],"visualizations":[{"x":207.76532567049804,"y":274.52873563218395,"width":39.21839080459771,"height":331.72222222222223,"type":"bar_chart","id":"bar_chart-0"},{"x":389.1503831417624,"y":11.438697318007666,"width":1505.0057471264374,"height":830.1226053639847,"type":"bar_chart","id":"bar_chart-1"},{"x":389.1503831417624,"y":11.438697318007685,"width":1503.3716475095791,"height":828.4885057471266,"type":"table","id":"table-2"},{"x":16.575670498084197,"y":274.52873563218395,"width":367.6724137931035,"height":331.72222222222223,"type":"table","id":"table-3"}],"relations":[{"vislist":[{"vislist":[{"vislist":[{"vislist":["bar_chart-1"],"relation":null,"id":"group-0"}],"relation":"repeated","id":"relation-0"}],"relation":null,"id":"group-2"},{"vislist":["table-2"],"relation":null,"id":"group-1"}],"relation":"nested","id":"relation-1"},{"vislist":[{"vislist":["bar_chart-0"],"relation":null,"id":"group-4"},{"vislist":["table-3"],"relation":null,"id":"group-3"}],"relation":"nested","id":"relation-2"}]},"2955_0":{"comp":[["bar_chart","bar_chart",["repeated"]],["area_chart","parallel_coordinate",["accompanied"]],["parallel_coordinate","area_chart",["accompanied"]]],"visType":["bar_chart","area_chart","parallel_coordinate"],"compType":["repeated","accompanied"],"compressed_tree":[{"composite_pattern":"accompanied","visualization_type":[["area_chart","parallel_coordinate"]]},{"composite_pattern":"repeated","visualization_type":[["bar_chart"]]},{"composite_pattern":"repeated","visualization_type":[["bar_chart"]]}],"coOccurrence":[["area_chart","parallel_coordinate",["coOccurrence"]],["area_chart","bar_chart",["coOccurrence"]],["parallel_coordinate","bar_chart",["coOccurrence"]]],"year":2017,"conference":["VAST"],"authors":["Bum Chul Kwon","Ben Eysenbach","Janu Verma","Kenney Ng","Christopher deFilippi","Walter F. Stewart","Adam Perer"],"title":"Clustervision: Visual Supervision of Unsupervised Clustering","doi":"10.1109/TVCG.2017.2745085","abstract":"Clustering, the process of grouping together similar items into distinct partitions, is a common type of unsupervised machine learning that can be useful for summarizing and aggregating complex multi-dimensional data. However, data can be clustered in many ways, and there exist a large body of algorithms designed to reveal different patterns. While having access to a wide variety of algorithms is helpful, in practice, it is quite difficult for data scientists to choose and parameterize algorithms to get the clustering results relevant for their dataset and analytical tasks. To alleviate this problem, we built Clustervision, a visual analytics tool that helps ensure data scientists find the right clustering among the large amount of techniques and parameters available. Our system clusters data using a variety of clustering techniques and parameters and then ranks clustering results utilizing five quality metrics. In addition, users can guide the system to produce more relevant results by providing task-relevant constraints on the data. Our visual user interface allows users to find high quality clustering results, explore the clusters using several coordinated visualization techniques, and select the cluster result that best suits their task. We demonstrate this novel approach using a case study with a team of researchers in the medical domain and showcase that our system empowers users to choose an effective representation of their complex data.","keywords":"Unsupervised Clustering,Visual Analytics,Quality Metrics,Interactive Visual Clustering","caption":"Fig. 1. An overview of Clustervision on a dataset describing 400 paintings by the \u201cJoy of Painting\u201d artist Bob Ross. (A) Ranked List of Clustering Results shows 15 different clustering results that are sorted by the aggregated quality measures; (B) Projection shows a selected clustering result (highlighted in yellow in (A)) on a projection of data points colored according to corresponding clusters; (C) Parallel Trends show the trends of feature values of data points within corresponding clusters in areas across parallel coordinates. Cluster 1 (Green Color) is highlighted; (D) Cluster Detail shows quality measures of a selected individual cluster (Cluster 1); (E) Data Point shows the feature value distribution of the selected cluster as well as the selected data point (Data Point 372 within Cluster 2).","img_size":{"width":1964,"height":1006},"subfigures":[{"x":20.78324498357226,"y":16.723512446693984,"width":1905.3154176457429,"height":969.7012574019523,"type":"interface","id":"interface-0"}],"visualizations":[{"x":732.3376034940073,"y":528.1091067274831,"width":661.7496792031857,"height":469.2001841711462,"type":"area_chart","id":"area_chart-7"},{"x":43.31288692844191,"y":152.20328055271176,"width":421.64141993883254,"height":748.6146584336926,"type":"bar_chart","id":"bar_chart-0"},{"x":1479.0703129010724,"y":147.83102854748404,"width":389.2661937606804,"height":229.24982467817514,"type":"bar_chart","id":"bar_chart-1"},{"x":1502.1081178659124,"y":565.1708122513008,"width":381.9341346656007,"height":425.6534666933673,"type":"bar_chart","id":"bar_chart-2"},{"x":493.29530695373785,"y":561.473549733129,"width":181.67645741270601,"height":433.81551180970564,"type":"bar_chart","id":"bar_chart-6"},{"x":731.604634660324,"y":526.1137855579867,"width":662.0988462181144,"height":471.0809628008751,"type":"parallel_coordinate","id":"parallel_coordinate-3"},{"x":388.746170678337,"y":149.68927789934352,"width":77.04595185995628,"height":750.6477024070022,"type":"polar_plot","id":"polar_plot-4"},{"x":527.4288840262584,"y":156.33763359582235,"width":860.7133479212251,"height":368.5494274690567,"type":"scatterplot","id":"scatterplot-5"}],"relations":[{"vislist":[{"vislist":["area_chart-7","parallel_coordinate-3"],"relation":null,"id":"group-1"}],"relation":"accompanied","id":"relation-1"},{"vislist":[{"vislist":["bar_chart-1"],"relation":null,"id":"group-2"}],"relation":"repeated","id":"relation-2"},{"vislist":[{"vislist":["bar_chart-2"],"relation":null,"id":"group-3"}],"relation":"repeated","id":"relation-3"}]},"2956_0":{"comp":[["line_chart","line_chart",["repeated"]],["sunburst_icicle","sunburst_icicle",["repeated"]],["scatterplot","scatterplot",["repeated"]],["bar_chart","bar_chart",["repeated"]]],"visType":["line_chart","sunburst_icicle","scatterplot","bar_chart"],"compType":["repeated"],"compressed_tree":[{"composite_pattern":"repeated","visualization_type":[["line_chart"]]},{"composite_pattern":"repeated","visualization_type":[["sunburst_icicle"]]},{"composite_pattern":"repeated","visualization_type":[["scatterplot"]]},{"composite_pattern":"repeated","visualization_type":[["bar_chart"]]}],"coOccurrence":[["line_chart","sunburst_icicle",["coOccurrence"]],["line_chart","scatterplot",["coOccurrence"]],["line_chart","bar_chart",["coOccurrence"]],["sunburst_icicle","scatterplot",["coOccurrence"]],["sunburst_icicle","bar_chart",["coOccurrence"]],["scatterplot","bar_chart",["coOccurrence"]]],"year":2017,"conference":["VAST"],"authors":["Michael Glueck","Mahdi Pakdaman Naeini","Finale Doshi-Velez","Fanny Chevalier","Azam Khan","Daniel J. Wigdor","Michael Brudno"],"title":"PhenoLines: Phenotype Comparison Visualizations for Disease Subtyping via Topic Models","doi":"10.1109/TVCG.2017.2745118","abstract":"PhenoLines is a visual analysis tool for the interpretation of disease subtypes, derived from the application of topic models to clinical data. Topic models enable one to mine cross-sectional patient comorbidity data (e.g., electronic health records) and construct disease subtypes-each with its own temporally evolving prevalence and co-occurrence of phenotypes-without requiring aligned longitudinal phenotype data for all patients. However, the dimensionality of topic models makes interpretation challenging, and de facto analyses provide little intuition regarding phenotype relevance or phenotype interrelationships. PhenoLines enables one to compare phenotype prevalence within and across disease subtype topics, thus supporting subtype characterization, a task that involves identifying a proposed subtype\'s dominant phenotypes, ages of effect, and clinical validity. We contribute a data transformation workflow that employs the Human Phenotype Ontology to hierarchically organize phenotypes and aggregate the evolving probabilities produced by topic models. We introduce a novel measure of phenotype relevance that can be used to simplify the resulting topology. The design of PhenoLines was motivated by formative interviews with machine learning and clinical experts. We describe the collaborative design process, distill high-level tasks, and report on initial evaluations with machine learning experts and a medical domain expert. These results suggest that PhenoLines demonstrates promising approaches to support the characterization and optimization of topic models.","keywords":"Developmental disorder,Human Phenotype Ontology (HPO),Phenotypes,Topic models,Topology simplification","caption":"Fig. 1. PhenoLines facilitates the visual analysis of topics that describe disease symptoms, in support of topic model optimization and characterization. Hierarchical relationships, temporal trends, correlated measures, and rank-ordered lists enable for comparisons within and between topics. The interface includes (A) Settings Panel, (B) Detail Panel, (C) Topics Panel, and (D) Search Panel.","img_size":{"width":1958,"height":582},"subfigures":[{"x":10.873247240904444,"y":9.231775957893598,"width":1934.8313557857584,"height":528.0084954518239,"type":"interface","id":"interface-0"}],"visualizations":[{"x":16.94224067289813,"y":99.8837126879419,"width":171.86634960216176,"height":148.3873400936697,"type":"bar_chart","id":"bar_chart-0"},{"x":203.8351563604948,"y":6.906835034313405,"width":218.8243686191459,"height":152.14398161502845,"type":"bar_chart","id":"bar_chart-1"},{"x":485.5832704623994,"y":473.6695440631352,"width":212.25024595676808,"height":64.80206624343805,"type":"bar_chart","id":"bar_chart-2"},{"x":747.6090165771707,"y":472.7303836827956,"width":213.18940633710764,"height":62.9237454827587,"type":"bar_chart","id":"bar_chart-3"},{"x":1003.9998004099039,"y":472.7303836827956,"width":217.88520823880626,"height":67.61954738445705,"type":"bar_chart","id":"bar_chart-4"},{"x":1272.5996691870528,"y":474.60870444347495,"width":210.37192519608882,"height":59.16710396140002,"type":"bar_chart","id":"bar_chart-5"},{"x":1534.3176985616008,"y":475.28955597248273,"width":210.61663539712316,"height":67.34834271419633,"type":"bar_chart","id":"bar_chart-6"},{"x":1770.649155722326,"y":43.0356472795497,"width":142.0437773608505,"height":160.41150719199499,"type":"bar_chart","id":"bar_chart-7"},{"x":204.39819870689303,"y":328.177493126893,"width":230.2955594678726,"height":78.95847753184205,"type":"line_chart","id":"line_chart-10"},{"x":203.5757145659363,"y":407.9584547996918,"width":230.2955594678726,"height":77.31350924992864,"type":"line_chart","id":"line_chart-11"},{"x":201.01767521947576,"y":489.63527052890976,"width":232.9117743242411,"height":49.775500158003126,"type":"line_chart","id":"line_chart-12"},{"x":207.68813527071978,"y":167.79308564033894,"width":224.53817048117574,"height":77.31350924992867,"type":"line_chart","id":"line_chart-8"},{"x":208.51061941167643,"y":248.39653145409432,"width":220.42574977639234,"height":78.13599339088537,"type":"line_chart","id":"line_chart-9"},{"x":479.00914780002165,"y":304.6206756019925,"width":226.33765166186328,"height":159.65726465774588,"type":"scatterplot","id":"scatterplot-13"},{"x":740.0957335344531,"y":306.4989963626719,"width":225.39849128152363,"height":150.2656608543491,"type":"scatterplot","id":"scatterplot-14"},{"x":1003.9998004099039,"y":303.68151522165283,"width":225.39849128152363,"height":158.7181042774062,"type":"scatterplot","id":"scatterplot-15"},{"x":1259.4514238622971,"y":302.7423548413132,"width":234.79009508492047,"height":156.8397835167268,"type":"scatterplot","id":"scatterplot-16"},{"x":1519.6235146966853,"y":306.30644152595363,"width":238.78048780487802,"height":154.28893058161356,"type":"scatterplot","id":"scatterplot-17"},{"x":469.61754399662476,"y":14.420118077030857,"width":239.48589698661883,"height":287.38307638394264,"type":"sunburst_icicle","id":"sunburst_icicle-18"},{"x":735.3999316327546,"y":12.541797316351495,"width":232.91177432424112,"height":291.1397179053014,"type":"sunburst_icicle","id":"sunburst_icicle-19"},{"x":997.4256777475262,"y":13.48095769669118,"width":236.66841584559967,"height":289.26139714462204,"type":"sunburst_icicle","id":"sunburst_icicle-20"},{"x":1261.3297446229762,"y":13.48095769669118,"width":234.79009508492027,"height":287.38307638394264,"type":"sunburst_icicle","id":"sunburst_icicle-21"},{"x":1518.3989993746088,"y":7.5247029393370735,"width":237.55597248280174,"height":291.4346466541588,"type":"sunburst_icicle","id":"sunburst_icicle-22"}],"relations":[{"vislist":[{"vislist":["line_chart-12","line_chart-11","line_chart-10","line_chart-9","line_chart-8"],"relation":null,"id":"group-5"}],"relation":"repeated","id":"relation-1"},{"vislist":[{"vislist":["sunburst_icicle-18","sunburst_icicle-19","sunburst_icicle-20","sunburst_icicle-21","sunburst_icicle-22"],"relation":null,"id":"group-6"}],"relation":"repeated","id":"relation-2"},{"vislist":[{"vislist":["scatterplot-14","scatterplot-13","scatterplot-15","scatterplot-16","scatterplot-17"],"relation":null,"id":"group-7"}],"relation":"repeated","id":"relation-3"},{"vislist":[{"vislist":["bar_chart-2","bar_chart-3","bar_chart-4","bar_chart-5","bar_chart-6"],"relation":null,"id":"group-8"}],"relation":"repeated","id":"relation-4"}]},"2958_0":{"comp":[["treemap","treemap",["repeated"]],["scatterplot","line_chart",["accompanied"]],["line_chart","scatterplot",["accompanied"]]],"visType":["treemap","scatterplot","line_chart"],"compType":["repeated","accompanied"],"compressed_tree":[{"composite_pattern":"accompanied","visualization_type":[["scatterplot","line_chart"]]},{"composite_pattern":"repeated","visualization_type":[["treemap"]]},{"composite_pattern":"large_view","visualization_type":[["heatmap_matrix"],["sankey_diagram"]]}],"coOccurrence":[["scatterplot","line_chart",["coOccurrence"]],["scatterplot","treemap",["coOccurrence"]],["scatterplot","sankey_diagram",["coOccurrence"]],["line_chart","treemap",["coOccurrence"]],["line_chart","sankey_diagram",["coOccurrence"]],["treemap","sankey_diagram",["coOccurrence"]]],"year":2017,"conference":["VAST"],"authors":["Thomas M\xfchlbacher","Lorenz Linhardt","Torsten M\xf6ller","Harald Piringer"],"title":"TreePOD: Sensitivity-Aware Selection of Pareto-Optimal Decision Trees","doi":"10.1109/TVCG.2017.2745158","abstract":"Balancing accuracy gains with other objectives such as interpretability is a key challenge when building decision trees. However, this process is difficult to automate because it involves know-how about the domain as well as the purpose of the model. This paper presents TreePOD, a new approach for sensitivity-aware model selection along trade-offs. TreePOD is based on exploring a large set of candidate trees generated by sampling the parameters of tree construction algorithms. Based on this set, visualizations of quantitative and qualitative tree aspects provide a comprehensive overview of possible tree characteristics. Along trade-offs between two objectives, TreePOD provides efficient selection guidance by focusing on Pareto-optimal tree candidates. TreePOD also conveys the sensitivities of tree characteristics on variations of selected parameters by extending the tree generation process with a full-factorial sampling. We demonstrate how TreePOD supports a variety of tasks involved in decision tree selection and describe its integration in a holistic workflow for building and selecting decision trees. For evaluation, we illustrate a case study for predicting critical power grid states, and we report qualitative feedback from domain experts in the energy sector. This feedback suggests that TreePOD enables users with and without statistical background a confident and efficient identification of suitable decision trees.","keywords":"Model selection,classification trees,visual parameter search,sensitivity analysis,Pareto optimality","caption":"Figure 1. Selection of decision trees explaining marital status in the UCI Census Income 1994 dataset [21]. (a) Candidate trees are generated by sampling the parameters of decision tree algorithms. Linked visualizations guide the selection from this set by providing (b) a summary of tree candidates and parameter variations, (c) a sensitivity-aware overview of the trade-off between the conflicting objectives accuracy and number of nodes, (d) a qualitative comparison of Pareto-optimal trees, and (e) details of a selected decision tree. (f) Applying controlled parameter variations to every tree conveys the effect of parameter changes on tree characteristics, e.g., how rounding of decision boundaries affects accuracy (g). Users can extend the set of candidate trees at any time, (h) and validate trees based on data using linked views.","img_size":{"width":2160,"height":742},"subfigures":[{"x":565.9228568426461,"y":66.21440087981907,"width":1263.4844769725562,"height":653.4972462591535,"type":"interface","id":"interface-0"}],"visualizations":[{"x":2024.2206542655551,"y":288.5625400898011,"width":95.59974342527266,"height":37.40859525336748,"type":"bar_chart","id":"bar_chart-0"},{"x":5.888149356017722,"y":4.534316869788258,"width":2149.6365364484354,"height":706.606799230276,"type":"flow_diagram","id":"flow_diagram-1"},{"x":1600.2565747273889,"y":83.50801796023086,"width":206.44002565747292,"height":198.12700449005774,"type":"heatmap_matrix","id":"heatmap_matrix-7"},{"x":615.1635663887107,"y":356.4522129570236,"width":360.23091725465036,"height":351.91789608723536,"type":"line_chart","id":"line_chart-5"},{"x":1925.8499037844772,"y":288.5625400898011,"width":90.05772931366278,"height":38.79409878127001,"type":"line_chart","id":"line_chart-6"},{"x":1201.231558691469,"y":173.56574727389344,"width":514.0218088518282,"height":311.73829377806294,"type":"sankey_diagram","id":"sankey_diagram-8"},{"x":616.6973131722305,"y":355.457579888776,"width":360.44111716257225,"height":356.7241455406978,"type":"scatterplot","id":"scatterplot-9"},{"x":1967.415009621552,"y":637.7094291212317,"width":54.0346375881975,"height":70.66067992302759,"type":"tree","id":"tree-10"},{"x":1047.3198847262247,"y":610.6541786743517,"width":754.7550432276657,"height":62.24783861671471,"type":"treemap","id":"treemap-12"}],"relations":[{"vislist":[{"vislist":["scatterplot-9","line_chart-5"],"relation":null,"id":"group-0"}],"relation":"accompanied","id":"relation-0"},{"vislist":[{"vislist":["treemap-12"],"relation":null,"id":"group-1"}],"relation":"repeated","id":"relation-1"},{"vislist":[{"vislist":["heatmap_matrix-7"],"relation":null,"id":"group-3"},{"vislist":["sankey_diagram-8"],"relation":null,"id":"group-2"}],"relation":"large_view","id":"relation-2"}]},"2964_0":{"comp":[["line_chart","line_chart",["repeated"]]],"visType":["line_chart"],"compType":["repeated"],"compressed_tree":[{"composite_pattern":"repeated","visualization_type":[["line_chart"]]}],"coOccurrence":[["line_chart","line_chart",["coOccurrence"]]],"year":2017,"conference":["VAST"],"authors":["Angus Graeme Forbes","Andrew Burks","Kristine Lee","Xing Li","Pierre Boutillier","Jean Krivine","Walter Fontana"],"title":"Dynamic Influence Networks for Rule-Based Models","doi":"10.1109/TVCG.2017.2745280","abstract":"We introduce the Dynamic Influence Network (DIN), a novel visual analytics technique for representing and analyzing rule-based models of protein-protein interaction networks. Rule-based modeling has proved instrumental in developing biological models that are concise, comprehensible, easily extensible, and that mitigate the combinatorial complexity of multi-state and multi-component biological molecules. Our technique visualizes the dynamics of these rules as they evolve over time. Using the data produced by KaSim, an open source stochastic simulator of rule-based models written in the Kappa language, DINs provide a node-link diagram that represents the influence that each rule has on the other rules. That is, rather than representing individual biological components or types, we instead represent the rules about them (as nodes) and the current influence of these rules (as links). Using our interactive DIN-Viz software tool, researchers are able to query this dynamic network to find meaningful patterns about biological processes, and to identify salient aspects of complex rule-based models. To evaluate the effectiveness of our approach, we investigate a simulation of a circadian clock model that illustrates the oscillatory behavior of the KaiC protein phosphorylation cycle.","keywords":"Dynamic networks,biological data visualization,rule-based modeling,protein-protein interaction networks","caption":"Fig. 1. A screenshot of the DIN-Viz application for analyzing the dynamics of a rule-based model of a protein-protein interaction network (i.e., a Dynamic Influence Network). Our approach emphasizes the influence rules have on each other and enables users to analyze the dynamics of these influences as they change over time. The left panel shows a network of interconnected rules at a specific time step. The right panel provides a global overview of the system as well as detailed information about selected rules.","img_size":{"width":1974,"height":910},"subfigures":[{"x":15.261471609858361,"y":14.342221560860613,"width":1950.6459116623603,"height":885.6183106950348,"type":"interface","id":"interface-0"}],"visualizations":[{"x":16.26695842450762,"y":3.9824945295404817,"width":1375.9518599562361,"height":900.0437636761488,"type":"graph","id":"graph-1"},{"x":1414.1225382932162,"y":601.3566739606125,"width":543.6105032822754,"height":286.7396061269146,"type":"line_chart","id":"line_chart-2"},{"x":1432.0437636761487,"y":302.66958424507663,"width":517.7242888402627,"height":219.03719912472647,"type":"line_chart","id":"line_chart-3"},{"x":1443.9912472647698,"y":7.964989059080963,"width":509.7592997811816,"height":215.054704595186,"type":"line_chart","id":"line_chart-4"}],"relations":[{"vislist":[{"id":"group-0","relation":null,"vislist":["line_chart-2","line_chart-3","line_chart-4"]}],"relation":"repeated","id":"relation-0"}]},"2965_3":{"comp":[["graph","graph",["repeated"]],["unit_visualization","sankey_diagram",["nested"]],["table","graph",["annotated"]]],"visType":["graph","unit_visualization","sankey_diagram","table"],"compType":["repeated","nested","annotated"],"compressed_tree":[{"composite_pattern":"nested","visualization_type":[["unit_visualization"],["sankey_diagram"]]},{"composite_pattern":"annotated","visualization_type":[["table"],["graph"]]},{"composite_pattern":"repeated","visualization_type":[["graph"]]}],"coOccurrence":[],"year":2017,"conference":["VAST"],"authors":["Shunan Guo","Ke Xu","Rongwen Zhao","David Gotz","Hongyuan Zha","Nan Cao"],"title":"EventThread: Visual Summarization and Stage Analysis of Event Sequence Data","doi":"10.1109/TVCG.2017.2745320","abstract":"Event sequence data such as electronic health records, a person\'s academic records, or car service records, are ordered series of events which have occurred over a period of time. Analyzing collections of event sequences can reveal common or semantically important sequential patterns. For example, event sequence analysis might reveal frequently used care plans for treating a disease, typical publishing patterns of professors, and the patterns of service that result in a well-maintained car. It is challenging, however, to visually explore large numbers of event sequences, or sequences with large numbers of event types. Existing methods focus on extracting explicitly matching patterns of events using statistical analysis to create stages of event progression over time. However, these methods fail to capture latent clusters of similar but not identical evolutions of event sequences. In this paper, we introduce a novel visualization system named EventThread which clusters event sequences into threads based on tensor analysis and visualizes the latent stage categories and evolution patterns by interactively grouping the threads by similarity into time-specific clusters. We demonstrate the effectiveness of EventThread through usage scenarios in three different application domains and via interviews with an expert user.","keywords":"Visual Knowledge Representation,Visual Knowledge Discovery,Data Clustering,Time Series Data,Illustrative Visualization","caption":"Fig. 4. The EventThread system contains six interactively coordinated views, including (1) a threads view, (2) an event flow view, (3) an entity list view, (4) an event list view, (5) a thread list view and (6) a global overview. The clustering level of threads can be adjusted through (a) the cluster slider. Users can choose to display and hide stage phases via (b) the stage slider, and (c) domain-specific event types. Entity proportions of latent stage categories and threads can be revealed by (d) adding backgrounds. Event description can be obtained via (g) informative tooltips. Other useful techniques for analysis are also available, including (e) zooming in on the timeline and (f) brushing components across specific stages.","img_size":{"width":1939,"height":938},"subfigures":[{"x":646.9917435700693,"y":40.53014577526378,"width":1267.5069941593053,"height":885.1014892650883,"type":"interface","id":"interface-0"},{"x":327.44049493807205,"y":273.22278674623266,"width":309.54115252382013,"height":537.9956867487404,"type":"single","id":"single-1"},{"x":17.280653043039997,"y":274.64549766597094,"width":304.55365600403616,"height":539.374532031607,"type":"single","id":"single-2"}],"visualizations":[{"x":644.1420664206644,"y":69.22509225092251,"width":308.0516605166051,"height":301.129151291513,"type":"treemap","id":"treemap-0"},{"x":30.026976442600642,"y":317.9444165017771,"width":106.71108655534175,"height":106.7110865553417,"type":"treemap","id":"treemap-1"},{"x":33.9792389076133,"y":448.36907784719466,"width":102.75882409032909,"height":102.75882409032917,"type":"treemap","id":"treemap-2"},{"x":775.586736369738,"y":434.58780423261993,"width":134.78555609208513,"height":104.16505087541894,"type":"graph","id":"graph-3"},{"x":776.5478090586981,"y":610.9722281587434,"width":144.63275821037243,"height":100.38521401218291,"type":"graph","id":"graph-4"},{"x":779.5098617328877,"y":813.8366428057335,"width":146.06449504712234,"height":68.67836274018177,"type":"graph","id":"graph-5"},{"x":700.7224733313126,"y":736.7458196798095,"width":210.95566031764835,"height":77.07978921180947,"type":"table","id":"table-6"},{"x":973.7118132746153,"y":197.9249301890665,"width":933.1241731472785,"height":325.6886011603283,"type":"sankey_diagram","id":"sankey_diagram-7"},{"x":973.7118132746158,"y":197.96300664256879,"width":933.1241731472779,"height":330.0300306709057,"type":"unit_visualization","id":"unit_visualization-8"},{"x":964.9772105711178,"y":723.8153755180513,"width":953.5357154283247,"height":204.54507313972172,"type":"sunburst_icicle","id":"sunburst_icicle-9"}],"relations":[{"vislist":[{"id":"group-0","relation":null,"vislist":["unit_visualization-8"]},{"id":"group-1","relation":null,"vislist":["sankey_diagram-7"]}],"relation":"nested","id":"relation-0"},{"vislist":[{"id":"group-2","relation":null,"vislist":["table-6"]},{"id":"group-3","relation":null,"vislist":["graph-5"]}],"relation":"annotated","id":"relation-1"},{"vislist":[{"id":"group-4","relation":null,"vislist":["graph-3","graph-4","graph-5"]}],"relation":"repeated","id":"relation-2"}]},"2971_12":{"comp":[["graph","graph",["repeated"]],["graph","scatterplot",["accompanied"]],["scatterplot","graph",["accompanied"]]],"visType":["graph","scatterplot"],"compType":["repeated","accompanied"],"compressed_tree":[{"composite_pattern":"repeated","visualization_type":[["graph"]]},{"composite_pattern":"accompanied","visualization_type":[["graph","scatterplot"]]}],"coOccurrence":[["graph","scatterplot",["coOccurrence"]]],"year":2017,"conference":["VAST"],"authors":["Dominik J\xe4ckle","Michael Blumenschein","Michael Behrisch","Daniel A. Keim","Tobias Schreck"],"title":"Pattern Trails: Visual Analysis of Pattern Transitions in Subspaces","doi":"10.1109/VAST.2017.8585613","abstract":"Subspace analysis methods have gained interest for identifying patterns in subspaces of high-dimensional data. Existing techniques allow to visualize and compare patterns in subspaces. However, many subspace analysis methods produce an abundant amount of patterns, which often remain redundant and are difficult to relate. Creating effective layouts for comparison of subspace patterns remains challenging. We introduce Pattern Trails, a novel approach for visually ordering and comparing subspace patterns. Central to our approach is the notion of pattern transitions as an interpretable structure imposed to order and compare patterns between subspaces. The basic idea is to visualize projections of subspaces side-by-side, and indicate changes between adjacent patterns in the subspaces by a linked representation, hence introducing pattern transitions. Our contributions comprise a systematization for how pairs of subspace patterns can be compared, and how changes can be interpreted in terms of pattern transitions. We also contribute a technique for visual subspace analysis based on a data-driven similarity measure between subspace representations. This measure is useful to order the patterns, and interactively group subspaces to reduce redundancy. We demonstrate the usefulness of our approach by application to several use cases, indicating that data can be meaningfully ordered and interpreted in terms of pattern transitions.","keywords":"","caption":"Figure 7: Visualization of the Standardized fertility measure and socio- economic indicators for French-speaking provinces of Switzerland at about 1888 after the application of the subspace analysis algorithm SURFING [5]. The data consists of 6 attributes (Fertility, Agricul- ture, Examination, Education, Catholic, Infant.Mortality), of which the combinations of Fertility, Education, and Infant.Mortality cause the patterns to merge. The pattern is static for multiple clusters with adding the attribute Catholic. This attribute is numeric, but the content is discrete, which causes the pattern to split into two separate clusters: People who are catholic, and people who are not. If this attribute is not considered, then the pattern merges (compare Pattern P6). Top: static pattern development. Bottom: view rotated by 0.5\u03c0, we see converging, diverging and static patterns. The black points indicate the selection and the lines are colored with regarding the point colors. The diverging fan pattern is highlighted via a red-green connector.","img_size":{"width":987,"height":495},"subfigures":[{"x":4.76241323365112,"y":7.097116362257809,"width":974.6076315798673,"height":480.80576727548436,"type":"single","id":"single-0"}],"visualizations":[{"x":1.5609777699052332,"y":2.3604672365474704,"width":979.2056074766351,"height":293.36182959050444,"type":"graph","id":"graph-0"},{"x":1.5609777699052343,"y":6.168224299065421,"width":982.2897196261684,"height":474.9532710280374,"type":"scatterplot","id":"scatterplot-1"}],"relations":[{"vislist":[{"vislist":["graph-0"],"relation":null,"id":"group-0"}],"relation":"repeated","id":"relation-0"},{"vislist":[{"vislist":["graph-0","scatterplot-1"],"relation":null,"id":"group-1"}],"relation":"accompanied","id":"relation-1"}]},"2972_5":{"comp":[["tree","tree",["repeated"]],["tree","map",["large_view"]],["bar_chart","bar_chart",["repeated"]],["bar_chart","matrix",["stacked"]],["matrix","bar_chart",["stacked"]]],"visType":["tree","map","bar_chart","matrix"],"compType":["repeated","large_view","stacked"],"compressed_tree":[{"composite_pattern":"repeated","visualization_type":[["tree"]]},{"composite_pattern":"large_view","visualization_type":[["tree"],["map"]]},{"composite_pattern":"large_view","visualization_type":[["tree"],["map"]]},{"composite_pattern":"large_view","visualization_type":[["tree"],["map"]]},{"composite_pattern":"large_view","visualization_type":[["tree"],["map"]]},{"composite_pattern":"large_view","visualization_type":[["tree"],["map"]]},{"composite_pattern":"stacked","visualization_type":[["bar_chart","matrix"]]},{"composite_pattern":"repeated","visualization_type":[["bar_chart"]]}],"coOccurrence":[["bar_chart","matrix",["coOccurrence"]]],"year":2017,"conference":["VAST"],"authors":["Siming Chen","Shuai Chen","Lijing Lin","Xiaoru Yuan","Jie Liang","Xiaolong Zhan"],"title":"E-Map: A Visual Analytics Approach for Exploring Significant Event Evolutions in Social Media","doi":"10.1109/VAST.2017.8585638","abstract":"Significant events are often discussed and spread through social media, involving many people. Reposting activities and opinions expressed in social media offer good opportunities to understand the evolution of events. However, the dynamics of reposting activities and the diversity of user comments pose challenges to understand event-related social media data. We propose E-Map, a visual analytics approach that uses map-like visualization tools to help multi-faceted analysis of social media data on a significant event and in-depth understanding of the development of the event. E-Map transforms extracted keywords, messages, and reposting behaviors into map features such as cities, towns, and rivers to build a structured and semantic space for users to explore. It also visualizes complex posting and reposting behaviors as simple trajectories and connections that can be easily followed. By supporting multi-level spatial temporal exploration, E-Map helps to reveal the patterns of event development and key players in an event, disclosing the ways they shape and affect the development of the event. Two cases analysing real-world events confirm the capacities of E-Map in facilitating the analysis of event evolution with social media data.","keywords":"Social Media,Event Analysis,Map-like Visual Metaphor,Spatial Temporal Visual Analytics","caption":"Figure 6: Spatial temporal visual analytics system of E-Map, including (a) a map view, (b) a temporal view, (c) a message panel, (d) a key player panel, (e) a detailed keyword relationship view. and (f) a sequence view. (g) Time slicing and animation are provided for analyzing event evolution. In this case, \ufb01ve event stages are identi\ufb01ed and each stage has its key players. We can analyze how they affect and shape the event development.","img_size":{"width":2046,"height":906},"subfigures":[{"x":20.991996564241518,"y":16.579666022899847,"width":962.2833382596187,"height":519.016165111874,"type":"interface","id":"interface-0"},{"x":1004.953761387568,"y":22.331770511248845,"width":982.716885079042,"height":508.99861371014345,"type":"single","id":"single-1"}],"visualizations":[{"x":751.9935774222911,"y":256.67768569483263,"width":242.408899783643,"height":89.60860802714416,"type":"bar_chart","id":"bar_chart-18"},{"x":997.9809043246368,"y":25.13638076184042,"width":1003.182349165596,"height":28.982813090383704,"type":"bar_chart","id":"bar_chart-20"},{"x":213.7510608203677,"y":53.82178217821783,"width":513.8698727015559,"height":449.79632248939186,"type":"map","id":"map-0"},{"x":1586.2065063649222,"y":562.5657708628006,"width":366.5007072135786,"height":316.5233380480906,"type":"map","id":"map-1"},{"x":1195.3578500707213,"y":562.5657708628006,"width":367.78217821782164,"height":310.1159830268741,"type":"map","id":"map-2"},{"x":13.474604436041218,"y":563.3596497178913,"width":372.0052676074346,"height":316.9753832400319,"type":"map","id":"map-21"},{"x":802.1039074549551,"y":565.846124887232,"width":369.63391519850114,"height":307.0216210735377,"type":"map","id":"map-3"},{"x":410.53764557307176,"y":564.8162126662037,"width":364.5992038776059,"height":316.85159988952194,"type":"map","id":"map-4"},{"x":996.4077079079761,"y":53.26982005112435,"width":1000.1193338046825,"height":480.88403056670427,"type":"matrix","id":"matrix-19"},{"x":744.2800565770862,"y":385.72277227722776,"width":246.04243281471008,"height":98.6732673267327,"type":"table","id":"table-5"},{"x":744.2800565770862,"y":47.41442715700142,"width":243.47949080622357,"height":198.62800565770863,"type":"table","id":"table-6"},{"x":77.91513437057986,"y":462.6110325318246,"width":103.79915134370577,"height":17.940594059405953,"type":"tree","id":"tree-10"},{"x":99.70014144271565,"y":480.5516265912306,"width":78.16973125884014,"height":8.970297029702976,"type":"tree","id":"tree-11"},{"x":98.41867043847236,"y":490.803394625177,"width":85.85855728429985,"height":10.251768033946236,"type":"tree","id":"tree-12"},{"x":22.811881188118747,"y":566.4101838755305,"width":102.51768033946253,"height":221.69448373408758,"type":"tree","id":"tree-13"},{"x":413.6605374823197,"y":577.9434229137199,"width":233.22772277227722,"height":51.25884016973135,"type":"tree","id":"tree-14"},{"x":799.3833097595474,"y":562.5657708628006,"width":221.69448373408773,"height":66.63649222065067,"type":"tree","id":"tree-15"},{"x":1203.0466760961808,"y":562.5657708628006,"width":128.1471004243283,"height":92.26591230551628,"type":"tree","id":"tree-16"},{"x":1593.8953323903822,"y":580.5063649222066,"width":119.1768033946253,"height":112.76944837340875,"type":"tree","id":"tree-17"},{"x":86.88543140028283,"y":37.162659123055164,"width":130.7100424328147,"height":246.0424328147101,"type":"tree","id":"tree-7"},{"x":92.01131541725597,"y":285.76803394625176,"width":88.42149929278641,"height":134.5544554455446,"type":"tree","id":"tree-8"},{"x":97.13719943422909,"y":422.88543140028287,"width":84.57708628005655,"height":39.72560113154169,"type":"tree","id":"tree-9"}],"relations":[{"vislist":[{"vislist":["tree-7","tree-8","tree-9","tree-10","tree-12","tree-11"],"relation":null,"id":"group-0"}],"relation":"repeated","id":"relation-0"},{"vislist":[{"vislist":["tree-13"],"relation":null,"id":"group-1"},{"vislist":["map-21"],"relation":null,"id":"group-2"}],"relation":"large_view","id":"relation-1"},{"vislist":[{"vislist":["tree-14"],"relation":null,"id":"group-3"},{"vislist":["map-4"],"relation":null,"id":"group-4"}],"relation":"large_view","id":"relation-2"},{"vislist":[{"vislist":["tree-15"],"relation":null,"id":"group-5"},{"vislist":["map-3"],"relation":null,"id":"group-6"}],"relation":"large_view","id":"relation-3"},{"vislist":[{"vislist":["tree-16"],"relation":null,"id":"group-7"},{"vislist":["map-2"],"relation":null,"id":"group-8"}],"relation":"large_view","id":"relation-4"},{"vislist":[{"vislist":["tree-17"],"relation":null,"id":"group-9"},{"vislist":["map-1"],"relation":null,"id":"group-10"}],"relation":"large_view","id":"relation-5"},{"vislist":[{"vislist":["bar_chart-20","matrix-19"],"relation":null,"id":"group-11"}],"relation":"stacked","id":"relation-6"},{"vislist":[{"vislist":["bar_chart-18"],"relation":null,"id":"group-12"}],"relation":"repeated","id":"relation-7"}]},"2974_0":{"comp":[["table","table",["repeated"]]],"visType":["table"],"compType":["repeated"],"compressed_tree":[{"composite_pattern":"repeated","visualization_type":[["table"]]}],"coOccurrence":[["table","table",["coOccurrence"]]],"year":2017,"conference":["VAST"],"authors":["Jun Wang","Klaus Mueller"],"title":"Visual Causality Analysis Made Practical","doi":"10.1109/VAST.2017.8585647","abstract":"Deriving the exact casual model that governs the relations between variables in a multidimensional dataset is difficult in practice. It is because causal inference algorithms by themselves typically cannot encode an adequate amount of domain knowledge to break all ties. Visual analytic approaches are considered a feasible alternative to fully automated methods. However, their application in real-world scenarios can be tedious. This paper focuses on these practical aspects of visual causality analysis. The most imperative of these aspects is posed by Simpson\' Paradox. It implies the existence of multiple causal models differing in both structure and parameter depending on how the data is subdivided. We propose a comprehensive interface that engages human experts in identifying these subdivisions and allowing them to establish the corresponding causal models via a rich set of interactive facilities. Other features of our interface include: (1) a new causal network visualization that emphasizes the flow of causal dependencies, (2) a model scoring mechanism with visual hints for interactive model refinement, and (3) flexible approaches for handling heterogeneous data. Various real-world data examples are given.","keywords":"Visual knowledge discovery,Causality,Hypothesis testing,Visual evidence,High-dimensional data","caption":"Fig. 1 The Causal Structure Investigator interface (a) Control panel for reading in data and setting inference parameters. (b) Interactive path diagrams for causal network visualization. (c) Parallel coordinates view for exploring data partitions. (d) Statistic coefficients tables of regressions associated with the causal model. (e) Data subdivision control, where a subdivision can be saved as a clickable tag. (f) Model diagnostic controls and the model heatmap, where users can examine learned models by clicking each tile colored by model scores.","img_size":{"width":1665,"height":972},"subfigures":[{"x":7.899925276427371,"y":9.878088153587397,"width":1647.8723746927606,"height":952.2438236928255,"type":"interface","id":"interface-0"}],"visualizations":[{"x":335.50141442715693,"y":82.48939179632248,"width":831.7680339462516,"height":466.0650636492223,"type":"graph","id":"graph-0"},{"x":1178.268033946252,"y":560.9278642149931,"width":391.82461103253183,"height":378.0763790664781,"type":"heatmap","id":"heatmap-1"},{"x":1179.642857142857,"y":560.9278642149931,"width":393.1994342291372,"height":379.4512022630833,"type":"matrix","id":"matrix-2"},{"x":19.292079207920835,"y":670.9137199434228,"width":1120.48090523338,"height":283.2135785007073,"type":"parallel_coordinate","id":"parallel_coordinate-3"},{"x":1181.0176803394622,"y":142.98161244695896,"width":453.69165487977375,"height":53.618104667609614,"type":"table","id":"table-4"},{"x":1183.7673267326734,"y":206.22347949080623,"width":446.8175388967467,"height":85.23903818953323,"type":"table","id":"table-5"}],"relations":[{"vislist":[{"vislist":["table-4","table-5"],"relation":null,"id":"group-0"}],"relation":"repeated","id":"relation-0"}]},"2979_0":{"comp":[["box_plot","box_plot",["repeated"]],["bar_chart","bar_chart",["repeated"]],["bar_chart","sankey_diagram",["nested"]],["heatmap","sankey_diagram",["nested"]]],"visType":["box_plot","bar_chart","sankey_diagram","heatmap"],"compType":["repeated","nested"],"compressed_tree":[{"composite_pattern":"repeated","visualization_type":[["box_plot"]]},{"composite_pattern":"repeated","visualization_type":[["bar_chart"]]},{"composite_pattern":"nested","visualization_type":[["heatmap","bar_chart"],["sankey_diagram"]]}],"coOccurrence":[["box_plot","bar_chart",["coOccurrence"]],["box_plot","heatmap",["coOccurrence"]],["box_plot","sankey_diagram",["coOccurrence"]],["bar_chart","heatmap",["coOccurrence"]],["bar_chart","sankey_diagram",["coOccurrence"]],["heatmap","sankey_diagram",["coOccurrence"]]],"year":2017,"conference":["VAST"],"authors":["Yao Ming","Shaozu Cao","Ruixiang Zhang","Zhen Li","Yuanzhe Chen","Yangqiu Song","Huamin Qu"],"title":"Understanding Hidden Memories of Recurrent Neural Networks","doi":"10.1109/VAST.2017.8585721","abstract":"Recurrent neural networks (RNNs) have been successfully applied to various natural language processing (NLP) tasks and achieved better results than conventional methods. However, the lack of understanding of the mechanisms behind their effectiveness limits further improvements on their architectures. In this paper, we present a visual analytics method for understanding and comparing RNN models for NLP tasks. We propose a technique to explain the function of individual hidden state units based on their expected response to input texts. We then co-cluster hidden state units and words based on the expected response and visualize co-clustering results as memory chips and word clouds to provide more structured knowledge on RNNs\' hidden states. We also propose a glyph-based sequence visualization based on aggregate information to analyze the behavior of an RNN\'s hidden state at the sentence-level. The usability and effectiveness of our method are demonstrated through case studies and reviews from domain experts.","keywords":"recurrent neural networks,visual analytics,understanding neural model,co-clustering","caption":"Figure 1: The interface of RNNVis. The control panel (A) shows parameter settings of an RNN and allows users to adjust visualization style. The main view (B-D) contains glyph-based sentence visualization (B), memory chips visualization for hidden state clusters (C), and word clouds visualization for word clusters (D). The detail view (E) shows the distributions of models responses to selected word \u201cof\u201d and interpretations of selected hidden units.","img_size":{"width":1860,"height":1235},"subfigures":[{"x":8.811653526695691,"y":12.57861071148898,"width":1842.3766929466078,"height":1214.9034551566756,"type":"interface","id":"interface-0"}],"visualizations":[{"x":509.9104935131595,"y":101.71244901052096,"width":165.01680980159853,"height":132.297959582316,"type":"bar_chart","id":"bar_chart-0"},{"x":511.33305221834564,"y":290.9127568002847,"width":160.74913368603995,"height":133.72051828750224,"type":"bar_chart","id":"bar_chart-1"},{"x":514.2426048379123,"y":480.4332469948505,"width":157.90401627566757,"height":132.29795958231603,"type":"bar_chart","id":"bar_chart-2"},{"x":511.3974874275399,"y":666.7884373742419,"width":162.17169239122614,"height":135.1430769926884,"type":"bar_chart","id":"bar_chart-3"},{"x":509.7627674575193,"y":856.2094906741358,"width":163.22244825476866,"height":131.74383323420605,"type":"bar_chart","id":"bar_chart-4"},{"x":510.46222372501626,"y":1044.4963594370279,"width":162.05657362437745,"height":132.90970786459732,"type":"bar_chart","id":"bar_chart-5"},{"x":3.1938373662711403,"y":1002.6412204184019,"width":219.1844305135464,"height":226.1796782958935,"type":"box_plot","id":"box_plot-6"},{"x":227.04176640138235,"y":1000.3094711576193,"width":215.6868066223727,"height":221.51617977432883,"type":"box_plot","id":"box_plot-7"},{"x":793.0003072681734,"y":299.77486506841086,"width":348.59651448697014,"height":33.8103642813449,"type":"heatmap","id":"heatmap-10"},{"x":789.5692532145225,"y":469.8552229387834,"width":353.26001300853477,"height":40.805612063692145,"type":"heatmap","id":"heatmap-11"},{"x":790.7351278449139,"y":557.2958202181237,"width":352.0941383781435,"height":34.97623891173612,"type":"heatmap","id":"heatmap-12"},{"x":789.5692532145225,"y":643.570542867073,"width":352.0941383781437,"height":46.63498521564828,"type":"heatmap","id":"heatmap-13"},{"x":790.7351278449139,"y":736.8405132983694,"width":349.7623891173612,"height":46.63498521564816,"type":"heatmap","id":"heatmap-14"},{"x":789.6118034796659,"y":949.1540705959945,"width":350.62260540178386,"height":170.1040362840338,"type":"heatmap","id":"heatmap-15"},{"x":791.347558951952,"y":834.5942094251146,"width":352.3583608740699,"height":67.69446341915636,"type":"heatmap","id":"heatmap-16"},{"x":787.7757658106667,"y":382.004506870161,"width":356.42115426637474,"height":38.599681911851896,"type":"heatmap","id":"heatmap-38"},{"x":790.6685580073912,"y":145.87941385677195,"width":350.92826374775245,"height":27.980991129388887,"type":"heatmap","id":"heatmap-8"},{"x":793.0003072681734,"y":225.15888872337382,"width":347.4306398565789,"height":20.985743347041677,"type":"heatmap","id":"heatmap-9"},{"x":9.091146022419338,"y":702.6522728655701,"width":444.3534009052311,"height":227.38396686947374,"type":"line_chart","id":"line_chart-17"},{"x":499.3899183294471,"y":71.55459585640638,"width":1343.8605275292641,"height":1135.6951561132737,"type":"sankey_diagram","id":"sankey_diagram-37"},{"x":1538.2890080786387,"y":502.71952274419505,"width":261.15591720762995,"height":100.26521821364352,"type":"word_cloud","id":"word_cloud-28"},{"x":1552.2795036433333,"y":612.3117380009683,"width":258.8241679468472,"height":88.60647190973148,"type":"word_cloud","id":"word_cloud-29"},{"x":1505.9105474477035,"y":404.27998682744965,"width":263.8348317874809,"height":93.73079550344717,"type":"word_cloud","id":"word_cloud-30"},{"x":1455.5736387514082,"y":300.13465849028614,"width":260.3633208429087,"height":102.40957286487755,"type":"word_cloud","id":"word_cloud-31"},{"x":1347.9567994696727,"y":168.2172425965457,"width":263.8348317874809,"height":52.072664168581774,"type":"word_cloud","id":"word_cloud-32"},{"x":1408.7082409996844,"y":225.49717318198563,"width":256.89180989833676,"height":67.6944634191563,"type":"word_cloud","id":"word_cloud-33"},{"x":1546.0048106283982,"y":707.2672697212411,"width":261.7508017542595,"height":183.51007296901892,"type":"word_cloud","id":"word_cloud-34"},{"x":1493.370138536509,"y":896.4675775110047,"width":257.48312563870104,"height":140.8333118134333,"type":"word_cloud","id":"word_cloud-35"},{"x":1389.758566978193,"y":1046.4797507788164,"width":265.4672897196265,"height":84.64174454828664,"type":"word_cloud","id":"word_cloud-36"},{"x":1282.4360265561752,"y":117.58633105988744,"width":268.8760500742936,"height":39.20019095707136,"type":"word_cloud","id":"word_cloud-39"}],"relations":[{"vislist":[{"vislist":["box_plot-6","box_plot-7"],"relation":null,"id":"group-2"}],"relation":"repeated","id":"relation-0"},{"vislist":[{"vislist":["bar_chart-5","bar_chart-4","bar_chart-3","bar_chart-2","bar_chart-1","bar_chart-0"],"relation":null,"id":"group-3"}],"relation":"repeated","id":"relation-1"},{"vislist":[{"vislist":["heatmap-9","heatmap-8","heatmap-38","heatmap-16","heatmap-15","heatmap-14","heatmap-13","heatmap-12","heatmap-11","heatmap-10","bar_chart-2"],"relation":null,"id":"group-5"},{"vislist":["sankey_diagram-37"],"relation":null,"id":"group-6"}],"relation":"nested","id":"relation-3"}]},"2980_0":{"comp":[["proportional_area_chart","proportional_area_chart",["repeated"]],["bar_chart","table",["nested"]]],"visType":["proportional_area_chart","bar_chart","table"],"compType":["repeated","nested"],"compressed_tree":[{"composite_pattern":"nested","visualization_type":[["bar_chart"],["table"]]},{"composite_pattern":"repeated","visualization_type":[["proportional_area_chart"]]}],"coOccurrence":[["bar_chart","table",["coOccurrence"]],["bar_chart","proportional_area_chart",["coOccurrence"]],["table","proportional_area_chart",["coOccurrence"]]],"year":2017,"conference":["VAST"],"authors":["Nan-Chen Chen","Been Kim"],"title":"QSAnglyzer: Visual Analytics for Prismatic Analysis of Question Answering System Evaluations","doi":"10.1109/VAST.2017.8585733","abstract":"Developing sophisticated artificial intelligence (AI) systems requires AI researchers to experiment with different designs and analyze results from evaluations (we refer this task as evaluation analysis). In this paper, we tackle the challenges of evaluation analysis in the domain of question-answering (QA) systems. Through in-depth studies with QA researchers, we identify tasks and goals of evaluation analysis and derive a set of design rationales, based on which we propose a novel approach termed prismatic analysis. Prismatic analysis examines data through multiple ways of categorization (referred as angles). Categories in each angle are measured by aggregate metrics to enable diverse comparison scenarios. To facilitate prismatic analysis of QA evaluations, we design and implement the Question Space Anglyzer (QSAnglyzer), a visual analytics (VA) tool. In QSAnglyzer, the high-dimensional space formed by questions is divided into categories based on several angles (e.g., topic and question type). Each category is aggregated by accuracy, the number of questions, and accuracy variance across evaluations. QSAnglyzer visualizes these angles so that QA researchers can examine and compare evaluations from various aspects both individually and collectively. Furthermore, QA researchers filter questions based on any angle by clicking to construct complex queries. We validate QSAnglyzer through controlled experiments and by expert reviews. The results indicate that when using QSAnglyzer, users perform analysis tasks faster (p &lt;; 0.01) and more accurately (p &lt;; 0.05), and are quick to gain new insight. We discuss how prismatic analysis and QSAnglyzer scaffold evaluation analysis, and provide directions for future research.","keywords":"visual analytics,visualization,interactive visualization,question answering,multi-experiment analysis,visual comparison,visual exploration,prismatic analysis,H.5.2 [Information Interfaces and Presentation]: User Interfaces\u2014","caption":"Figure 1: The QSAnglyzer interface consists of three basic panels: \u2018Evaluations\u2019 (top left), \u2018Question Space Angles\u2019 (top right), and \u2018Question Table\u2019 (bottom) panels, following the well-known visualization mantra: \u201cOverview \ufb01rst, zoom and \ufb01lter, details on demand.","img_size":{"width":1863,"height":813},"subfigures":[{"x":7.668184070381888,"y":7.552409109846319,"width":1850.3699290518034,"height":793.8351254360459,"type":"interface","id":"interface-0"}],"visualizations":[{"x":252.82739212007507,"y":713.5046904315197,"width":55.92495309568485,"height":22.136960600375236,"type":"bar_chart","id":"bar_chart-0"},{"x":343.70544090056285,"y":714.6697936210132,"width":57.09005628517828,"height":22.136960600375236,"type":"bar_chart","id":"bar_chart-1"},{"x":438.0787992495311,"y":713.5046904315197,"width":53.594746716697955,"height":20.971857410881736,"type":"bar_chart","id":"bar_chart-2"},{"x":351.8611632270171,"y":783.4108818011258,"width":51.264540337711026,"height":16.311444652908108,"type":"bar_chart","id":"bar_chart-3"},{"x":441.57410881801127,"y":782.2457786116324,"width":50.099437148217646,"height":16.311444652907994,"type":"bar_chart","id":"bar_chart-4"},{"x":950.7242026266416,"y":82.0187617260788,"width":104.85928705440907,"height":417.1069418386491,"type":"heatmap","id":"heatmap-10"},{"x":1101.0225140712946,"y":77.35834896810506,"width":157.2889305816134,"height":424.09756097560967,"type":"heatmap","id":"heatmap-11"},{"x":1302.5853658536585,"y":79.68855534709192,"width":124.66604127579741,"height":422.93245778611634,"type":"heatmap","id":"heatmap-12"},{"x":11.651031894934334,"y":71.5328330206379,"width":110.68480300187619,"height":129.3264540337711,"type":"heatmap","id":"heatmap-5"},{"x":297.10131332082557,"y":78.52345215759848,"width":114.18011257035647,"height":420.60225140712953,"type":"heatmap","id":"heatmap-6"},{"x":457.8855534709193,"y":77.35834896810506,"width":130.49155722326458,"height":425.26266416510316,"type":"heatmap","id":"heatmap-7"},{"x":637.3114446529082,"y":78.52345215759848,"width":113.01500938086306,"height":426.4277673545967,"type":"heatmap","id":"heatmap-8"},{"x":795.765478424015,"y":77.35834896810506,"width":108.35459662288929,"height":422.93245778611634,"type":"heatmap","id":"heatmap-9"},{"x":293.1188129386879,"y":75.05657357770869,"width":120.51502966131903,"height":426.7633745837132,"type":"proportional_area_chart","id":"proportional_area_chart-14"},{"x":453.6731101030308,"y":77.87344439633132,"width":134.40719405797512,"height":426.7852851203807,"type":"proportional_area_chart","id":"proportional_area_chart-15"},{"x":632.4262318332521,"y":77.88458691150538,"width":117.55573056718221,"height":428.176913133511,"type":"proportional_area_chart","id":"proportional_area_chart-16"},{"x":792.9709466365681,"y":76.4427581187359,"width":111.67798533080982,"height":423.9910055016582,"type":"proportional_area_chart","id":"proportional_area_chart-17"},{"x":946.6097842186812,"y":80.65690045167561,"width":111.13096267037571,"height":422.6322860531706,"type":"proportional_area_chart","id":"proportional_area_chart-18"},{"x":1099.838208738314,"y":79.25960674266713,"width":162.29095733369056,"height":424.01296042770934,"type":"proportional_area_chart","id":"proportional_area_chart-19"},{"x":1303.2522415812525,"y":79.24843548190407,"width":128.62829377224537,"height":422.6213899057576,"type":"proportional_area_chart","id":"proportional_area_chart-20"},{"x":206.22326454033774,"y":635.4427767354597,"width":1610.1726078799252,"height":164.27954971857412,"type":"table","id":"table-13"},{"x":7.368913020900845,"y":71.2930320044163,"width":118.1316731994734,"height":130.2991533824719,"type":"table","id":"table-21"}],"relations":[{"vislist":[{"vislist":["bar_chart-0","bar_chart-1","bar_chart-2","bar_chart-3","bar_chart-4"],"relation":null,"id":"group-0"},{"vislist":["table-13"],"relation":null,"id":"group-0"}],"relation":"nested","id":"relation-0"},{"vislist":[{"vislist":["proportional_area_chart-20","proportional_area_chart-19","proportional_area_chart-18","proportional_area_chart-17","proportional_area_chart-15","proportional_area_chart-14","proportional_area_chart-16"],"relation":null,"id":"group-1"}],"relation":"repeated","id":"relation-1"}]},"2949_0":{"comp":[["graph","graph",["repeated"]]],"visType":["graph"],"compType":["repeated"],"compressed_tree":[{"composite_pattern":"repeated","visualization_type":[["graph"]]}],"coOccurrence":[],"year":2017,"conference":["VAST"],"authors":["Kanit Wongsuphasawat","Daniel Smilkov","James Wexler","Jimbo Wilson","Dan Man\xe9","Doug Fritz","Dilip Krishnan","Fernanda B. Vi\xe9gas","Martin Wattenberg"],"title":"Visualizing Dataflow Graphs of Deep Learning Models in TensorFlow","doi":"10.1109/TVCG.2017.2744878","abstract":"We present a design study of the TensorFlow Graph Visualizer, part of the TensorFlow machine intelligence platform. This tool helps users understand complex machine learning architectures by visualizing their underlying dataflow graphs. The tool works by applying a series of graph transformations that enable standard layout techniques to produce a legible interactive diagram. To declutter the graph, we decouple non-critical nodes from the layout. To provide an overview, we build a clustered graph using the hierarchical structure annotated in the source code. To support exploration of nested structure on demand, we perform edge bundling to enable stable and responsive cluster expansion. Finally, we detect and highlight repeated structures to emphasize a model\'s modular composition. To demonstrate the utility of the visualizer, we describe example usage scenarios and report user feedback. Overall, users find the visualizer useful for understanding, debugging, and sharing the structures of their models.","keywords":"Neural Network,Graph Visualization,Dataflow Graph,Clustered Graph","caption":"Fig. 1. The TensorFlow Graph Visualizer shows a convolutional network for classifying images (tf cifar) . (a) An overview displays a dataflow between groups of operations, with auxiliary nodes extracted to the side. (b) Expanding a group shows its nested structure.","img_size":{"width":2084,"height":1123},"subfigures":[{"x":17.280744984567022,"y":12.734671479073297,"width":1064.9655655147847,"height":1062.250706872921,"type":"interface","id":"interface-0"},{"x":1124.5318963536558,"y":11.244438526841892,"width":935.951120318466,"height":1069.832905408116,"type":"single","id":"single-1"}],"visualizations":[{"x":280.7569169960474,"y":66.58102766798419,"width":452.7509881422924,"height":987.6185770750988,"type":"graph","id":"graph-0"},{"x":1184.0395256916995,"y":4.438735177865612,"width":807.8498023715415,"height":1083.0513833992095,"type":"graph","id":"graph-1"},{"x":735.7272727272726,"y":13.316205533596838,"width":335.1245059288536,"height":949.8893280632411,"type":"graph","id":"graph-2"}],"relations":[{"vislist":[{"vislist":["graph-2"],"relation":null,"id":"group-0"}],"relation":"repeated","id":"relation-0"}]},"1944_0":{"comp":[["scatterplot","scatterplot",["repeated"]],["scatterplot","bar_chart",["stacked"]],["line_chart","line_chart",["repeated"]],["bar_chart","scatterplot",["stacked"]],["comb","comb",["stacked"]]],"visType":["scatterplot","bar_chart","line_chart","comb"],"compType":["repeated","stacked"],"compressed_tree":[{"composite_pattern":"stacked","visualization_type":[["scatterplot","bar_chart"]]},{"composite_pattern":"repeated","visualization_type":[["scatterplot"]]},{"composite_pattern":"stacked","visualization_type":[[{"composite_pattern":"repeated","visualization_type":[["line_chart"]]}]]}],"coOccurrence":[["scatterplot","bar_chart",["coOccurrence"]],["scatterplot","area_chart",["coOccurrence"]],["scatterplot","line_chart",["coOccurrence"]],["bar_chart","area_chart",["coOccurrence"]],["bar_chart","line_chart",["coOccurrence"]],["area_chart","line_chart",["coOccurrence"]]],"year":2010,"conference":["InfoVis"],"authors":["Miriah D. Meyer","Tamara Munzner","Angela H. DePace","Hanspeter Pfister"],"title":"MulteeSum: A Tool for Comparative Spatial and Temporal Gene Expression Data","doi":"10.1109/TVCG.2010.137","abstract":"Cells in an organism share the same genetic information in their DNA, but have very different forms and behavior because of the selective expression of subsets of their genes. The widely used approach of measuring gene expression over time from a tissue sample using techniques such as microarrays or sequencing do not provide information about the spatial position with in the tissue where these genes are expressed. In contrast, we are working with biologists who use techniques that measure gene expression in every individual cell of entire fruitfly embryos over an hour of their development, and do so for multiple closely-related subspecies of Drosophila. These scientists are faced with the challenge of integrating temporal gene expression data with the spatial location of cells and, moreover, comparing this data across multiple related species. We have worked with these biologists over the past two years to develop MulteeSum, a visualization system that supports inspection and curation of data sets showing gene expression over time, in conjunction with the spatial location of the cells where the genes are expressed - it is the first tool to support comparisons across multiple such data sets. MulteeSum is part of a general and flexible framework we developed with our collaborators that is built around multiple summaries for each cell, allowing the biologists to explore the results of computations that mix spatial information, gene expression measurements over time, and data from multiple related species or organisms. We justify our design decisions based on specific descriptions of the analysis needs of our collaborators, and provide anecdotal evidence of the efficacy of MulteeSum through a series of case studies.","keywords":"Spatial data, temporal data, gene expression","caption":"Fig. 1. MulteeSum is a visualization system that supports inspection and curation of data sets showing gene expression over time, in conjunction with the spatial location of the cells where the genes are expressed. It is the \ufb01rst tool to support comparisons across multiple such data sets. This screenshot includes data for four related species of Drosophila.","img_size":{"width":2003,"height":1190},"subfigures":[{"x":47.52509567561084,"y":26.558739450966044,"width":1868.694661167288,"height":1102.6880741215728,"type":"interface","id":"interface-0"}],"visualizations":[{"x":1582.3893280632412,"y":166.97628458498028,"width":204.60474308300422,"height":134.05138339920953,"type":"area_chart","id":"area_chart-0"},{"x":1133.341853489991,"y":343.2232532187378,"width":704.1972210278404,"height":623.7967509104888,"type":"area_chart","id":"area_chart-1"},{"x":976.2458697544569,"y":388.3762748487243,"width":98.21104901138587,"height":651.8620337948017,"type":"bar_chart","id":"bar_chart-13"},{"x":89.00988142292493,"y":336.304347826087,"width":997.1541501976285,"height":721.99604743083,"type":"heatmap","id":"heatmap-3"},{"x":152.31417624521063,"y":143.6206896551724,"width":137.46087175458172,"height":165.15413523748765,"type":"scatterplot","id":"scatterplot-4"},{"x":91.45360402821355,"y":337.5969006315611,"width":995.0112275369095,"height":719.8379889968854,"type":"scatterplot","id":"scatterplot-12"},{"x":1246.0849802371542,"y":171.6798418972332,"width":197.54940711462453,"height":126.99604743083003,"type":"scatterplot","id":"scatterplot-2"},{"x":1222.2398294077088,"y":979.5435457020942,"width":615.8722949343692,"height":52.73219972782147,"type":"line_chart","id":"line_chart-5"},{"x":314.21963638459096,"y":146.09187460762075,"width":133.18086085510993,"height":163.52586712589442,"type":"scatterplot","id":"scatterplot-6"},{"x":471.0021687836445,"y":149.46354197104125,"width":131.49502717339965,"height":158.4683660807637,"type":"scatterplot","id":"scatterplot-7"},{"x":629.4705348644081,"y":147.777708289331,"width":128.1233598099792,"height":162.6829502850393,"type":"scatterplot","id":"scatterplot-8"},{"x":784.5672335817515,"y":149.46354197104125,"width":131.49502717339965,"height":160.99711660332906,"type":"scatterplot","id":"scatterplot-9"},{"x":1137.903162055336,"y":343.3596837944664,"width":696.1264822134387,"height":623.2213438735178,"type":"small_multiple","id":"small_multiple-10"},{"x":1224.2297237370606,"y":980.5384928667703,"width":613.8824006050173,"height":51.73725256314561,"type":"small_multiple","id":"small_multiple-11"}],"relations":[{"vislist":[{"vislist":["scatterplot-12","bar_chart-13"],"relation":null,"id":"group-1"}],"relation":"stacked","id":"relation-1"},{"vislist":[{"vislist":["scatterplot-4","scatterplot-6","scatterplot-7","scatterplot-8","scatterplot-9"],"relation":null,"id":"group-3"}],"relation":"repeated","id":"relation-3"},{"vislist":[{"vislist":[{"vislist":[{"vislist":["line_chart-5"],"relation":null,"id":"group-4"}],"relation":"repeated","id":"relation-4"},{"vislist":[{"vislist":["area_chart-1"],"relation":null,"id":"group-2"}],"relation":"repeated","id":"relation-2"}],"relation":null,"id":"group-5"}],"relation":"stacked","id":"relation-5"}]},"1947_0":{"comp":[["bar_chart","bar_chart",["repeated"]]],"visType":["bar_chart"],"compType":["repeated"],"compressed_tree":[{"composite_pattern":"repeated","visualization_type":[["bar_chart"]]}],"coOccurrence":[["bar_chart","bar_chart",["coOccurrence"]]],"year":2010,"conference":["InfoVis"],"authors":["Hoi Ying Tsang","Melanie Tory","Colin Swindells"],"title":"eSeeTrack\u2014Visualizing Sequential fixation Patterns","doi":"10.1109/TVCG.2010.149","abstract":"We introduce eSeeTrack, an eye-tracking visualization prototype that facilitates exploration and comparison of sequential gaze orderings in a static or a dynamic scene. It extends current eye-tracking data visualizations by extracting patterns of sequential gaze orderings, displaying these patterns in a way that does not depend on the number of fixations on a scene, and enabling users to compare patterns from two or more sets of eye-gaze data. Extracting such patterns was very difficult with previous visualization techniques. eSeeTrack combines a timeline and a tree-structured visual representation to embody three aspects of eye-tracking data that users are interested in: duration, frequency and orderings of fixations. We demonstrate the usefulness of eSeeTrack via two case studies on surgical simulation and retail store chain data. We found that eSeeTrack allows ordering of fixations to be rapidly queried, explored and compared. Furthermore, our tool provides an effective and efficient mechanism to determine pattern outliers. This approach can be effective for behavior analysis in a variety of domains that are described at the end of this paper.","keywords":"","caption":"Fig. 1. Overview of eSeeTrack. a) Timeline section; b) Detailed timeline section with optional thumbnail images of fixated objects displayed; c) Tree visualization; d) Control section. Two retail stores belonging to the same chain are explored and compared; the \u201csales promotion\u201d tag has been selected and the tree visualization shows the observed fixation orderings that end with \u201csales promotion\u201d. In the tree visualization, labels with colors other than grey belong to store 1 and grey labels belong to store 2. Font sizes in the tree as well as the bar charts on the top of the control section reveal that sales promotion had more fixations in store 1. The most common fixation sequence (sales promotion 5 times) indicates that people tend to look at the sales promotion for an extended period of time.","img_size":{"width":1926,"height":1160},"subfigures":[{"x":4.543045823843144,"y":9.085153660895104,"width":1913.212050148032,"height":1148.0023597327893,"type":"interface","id":"interface-0"}],"visualizations":[{"x":1594.108552477159,"y":70.84759358673591,"width":278.64091571686396,"height":236.82725872678398,"type":"bar_chart","id":"bar_chart-1"},{"x":66.18118122997393,"y":59.86104131194348,"width":1501.4352345020775,"height":100.80598820837842,"type":"stripe_graph","id":"stripe_graph-2"},{"x":63.70278184480237,"y":611.4202049780381,"width":1489.4875549048315,"height":368.55051244509514,"type":"tree","id":"tree-0"}],"relations":[{"vislist":[{"vislist":["bar_chart-1"],"relation":null,"id":"group-0"}],"relation":"repeated","id":"relation-0"}]},"1981_0":{"comp":[["bar_chart","bar_chart",["repeated"]],["comb","table",["nested"]]],"visType":["bar_chart","comb","table"],"compType":["repeated","nested"],"compressed_tree":[{"composite_pattern":"nested","visualization_type":[[{"composite_pattern":"repeated","visualization_type":[["bar_chart"]]}],["table"]]},{"composite_pattern":"nested","visualization_type":[[{"composite_pattern":"repeated","visualization_type":[["bar_chart"]]}],["table"]]}],"coOccurrence":[["bar_chart","table",["coOccurrence"]]],"year":2010,"conference":["VAST"],"authors":["Maryam Nafari","Chris Weaver"],"title":"Poster: Translating cross-filtered queries into questions","doi":"10.1109/VAST.2010.5650251","abstract":"Complex combinations of coordinated multiple views are increasingly used to design tools for highly interactive visual exploration and analysis of multidimensional data. While complex coordination patterns provide substantial utility through expressive querying, they also exhibit usability problems for users when learning required interaction sequences, recalling past queries, and interpreting visual states. As visual analysis tools grow more sophisticated, there is a growing need to make them more understandable as well. Our long-term goal is to exploit natural language familiarity and literacy to directly facilitate individual and collaborative use of visual analysis tools. In this poster, we present work in progress on an automatically generated query-to-question user interface to translate interactive states during visual analysis into an accompanying visual log of formatted text. Our effort currently focuses on a symmetric and thus relatively simple coordination pattern: cross-filtered views. We describe our current thinking about query-to-question translation in a typical cross-filtered visualization of movies, people, and genres in the Internet Movie Database.","keywords":"Coordinated multiple views, cross-filtered queries, interaction states, natural language generation, visual provenance","caption":"Figure 1: A simplified version of the Cinegraph visualization, showing popular recent movies, people, and genres in the Internet Movie Database, alongside a hand-formatted execution of our current question generator algorithm. The event and question views (rightmost pair of columns) show correspondences between interactions (selections and cross-filterings) and natural language fragments that describe visual query states.","img_size":{"width":2112,"height":846},"subfigures":[{"x":11.106318361018397,"y":12.586856123585715,"width":2072.1752312332783,"height":820.8262877528289,"type":"interface","id":"interface-0"}],"visualizations":[{"x":1004.6596758817922,"y":63.617731172545305,"width":78.52049571020018,"height":769.0981887511916,"type":"bar_chart","id":"bar_chart-0"},{"x":169.12106768350813,"y":67.64442326024786,"width":98.65395614871305,"height":581.8570066730219,"type":"bar_chart","id":"bar_chart-1"},{"x":302.00190657769303,"y":37.444232602478564,"width":438.9094375595805,"height":793.2583412774071,"type":"table","id":"table-2"},{"x":769.0981887511916,"y":43.484270734032435,"width":316.0953288846519,"height":789.2316491897045,"type":"table","id":"table-3"},{"x":10.066730219256435,"y":43.484270734032435,"width":257.7082936129647,"height":608.0305052430887,"type":"table","id":"table-4"}],"relations":[{"vislist":[{"vislist":[{"vislist":[{"vislist":["bar_chart-1"],"relation":null,"id":"group-0"}],"relation":"repeated","id":"relation-0"}],"relation":null,"id":"group-3"},{"vislist":["table-4"],"relation":null,"id":"group-4"}],"relation":"nested","id":"relation-2"},{"vislist":[{"vislist":[{"vislist":[{"vislist":["bar_chart-0"],"relation":null,"id":"group-1"}],"relation":"repeated","id":"relation-1"}],"relation":null,"id":"group-5"},{"vislist":["table-3"],"relation":null,"id":"group-6"}],"relation":"nested","id":"relation-3"}]},"1982_2":{"comp":[["comb","comb",["repeated"]],["bar_chart","line_chart",["nested"]]],"visType":["comb","bar_chart","line_chart"],"compType":["repeated","nested"],"compressed_tree":[{"composite_pattern":"repeated","visualization_type":[[{"composite_pattern":"nested","visualization_type":[["bar_chart"],["line_chart"]]}]]}],"coOccurrence":[["bar_chart","line_chart",["coOccurrence"]]],"year":2010,"conference":["VAST"],"authors":["Ming C. Hao","Manish Marwah","Halld\xf3r Janetzko","Daniel A. Keim","Umeshwar Dayal","Ratnesh K. Sharma","Debprakash Patnaik","Naren Ramakrishnan"],"title":"Visual analysis of frequent patterns in large time series","doi":"10.1109/VAST.2010.5650766","abstract":"The detection of previously unknown, frequently occurring patterns in time series, often called motifs, has been recognized as an important task. To find these motifs, we use an advanced temporal data mining algorithm. Since our algorithm usually finds hundreds of motifs, we need to analyze and access the discovered motifs. For this purpose, we introduce three novel visual analytics methods: (1) motif layout, using colored rectangles for visualizing the occurrences and hierarchical relationships of motifs in a multivariate time series, (2) motif distortion, for enlarging or shrinking motifs as appropriate for easy analysis and (3) motif merging, to combine a number of identical adjacent motif instances without cluttering the display. We have applied and evaluated our methods using two real-world data sets: data center cooling and oil well production.","keywords":"","caption":"Figure 4: Oil Well Production Time Series (85,035 records ) with Seven Different Motifs (x-axis: time, y-axis: % oil flow and pressure, color: motif type)","img_size":{"width":1236,"height":723},"subfigures":[{"x":6.185818345662044,"y":3.978211539647571,"width":1225.1672910726927,"height":324.16049994233475,"type":"interface","id":"interface-0"}],"visualizations":[{"x":2.725204169826963,"y":41.284040995607604,"width":1220.8528550512444,"height":114.32503660322106,"type":"bar_chart","id":"bar_chart-0"},{"x":3.502928257686648,"y":168.31185944363102,"width":1225.818448023426,"height":149.2576866764275,"type":"bar_chart","id":"bar_chart-1"},{"x":5.620058565153699,"y":389.5519765739385,"width":1221.5841874084917,"height":119.61786237188868,"type":"bar_chart","id":"bar_chart-2"},{"x":4.561493411420173,"y":512.3455344070278,"width":1222.6427525622255,"height":159.84333821376288,"type":"bar_chart","id":"bar_chart-3"},{"x":2.725204169826963,"y":40.22547584187408,"width":1219.7942898975111,"height":116.44216691068812,"type":"line_chart","id":"line_chart-4"},{"x":6.6786237188872235,"y":165.13616398243042,"width":1218.4084919472914,"height":153.49194729136167,"type":"line_chart","id":"line_chart-5"},{"x":6.6786237188872235,"y":389.5519765739385,"width":1215.2327964860908,"height":122.79355783308927,"type":"line_chart","id":"line_chart-6"},{"x":6.6786237188872235,"y":511.2869692532943,"width":1217.349926793558,"height":160.90190336749637,"type":"line_chart","id":"line_chart-7"}],"relations":[{"vislist":[{"vislist":[{"vislist":[{"vislist":["bar_chart-0"],"relation":null,"id":"group-0"},{"vislist":["line_chart-4"],"relation":null,"id":"group-1"}],"relation":"nested","id":"relation-0"},{"vislist":[{"vislist":["bar_chart-1"],"relation":null,"id":"group-2"},{"vislist":["line_chart-5"],"relation":null,"id":"group-3"}],"relation":"nested","id":"relation-1"}],"relation":null,"id":"group-4"}],"relation":"repeated","id":"relation-2"}]},"1989_4":{"comp":[["scatterplot","scatterplot",["repeated"]]],"visType":["scatterplot"],"compType":["repeated"],"compressed_tree":[{"composite_pattern":"repeated","visualization_type":[["scatterplot"]]}],"coOccurrence":[["scatterplot","scatterplot",["coOccurrence"]]],"year":2010,"conference":["VAST"],"authors":["Stephen Ingram","Tamara Munzner","Veronika Irvine","Melanie Tory","Steven Bergner","Torsten M\xf6ller"],"title":"DimStiller: Workflows for dimensional analysis and reduction","doi":"10.1109/VAST.2010.5652392","abstract":"DimStiller is a system for dimensionality reduction and analysis. It frames the task of understanding and transforming input dimensions as a series of analysis steps where users transform data tables by chaining together different techniques, called operators, into pipelines of expressions. The individual operators have controls and views that are linked together based on the structure of the expression. Users interact with the operator controls to tune parameter choices, with immediate visual feedback guiding the exploration of local neighborhoods of the space of possible data tables. DimStiller also provides global guidance for navigating data-table space through expression templates called workflows, which permit re-use of common patterns of analysis.","keywords":"","caption":"Figure 5: Running the Cluster Verify workflow on a computa- tional chemistry dataset. The scree plot in the lower left shows that most of the variability resides in a low dimensional subspace. We choose a threshold of 3 dimensions at the \u201cknee\u201d in the plot. We see in the colored SPLOM view that while the clusters are spatially coherent, they do not reflect the spatial structure in this projection, suggesting that this clustering is not the most appropriate.","img_size":{"width":1002,"height":591},"subfigures":[{"x":3.5615798247261723,"y":3.3662394912443157,"width":993.6186741289217,"height":583.6385475297086,"type":"interface","id":"interface-0"}],"visualizations":[{"x":8.211566617862331,"y":371.2137628111274,"width":415.3440702781846,"height":185.17423133235727,"type":"bar_chart","id":"bar_chart-0"},{"x":506.6244509516836,"y":59.70571010248903,"width":211.13323572474383,"height":215.45973645680823,"type":"scatterplot","id":"scatterplot-1"},{"x":493.6449487554904,"y":304.5856515373353,"width":223.2474377745242,"height":234.49633967789174,"type":"scatterplot","id":"scatterplot-2"},{"x":729.871888726208,"y":308.9121522693998,"width":222.3821376281113,"height":224.11273792093704,"type":"scatterplot","id":"scatterplot-3"}],"relations":[{"vislist":[{"vislist":["scatterplot-1","scatterplot-2","scatterplot-3"],"relation":null,"id":"group-0"}],"relation":"repeated","id":"relation-0"}]},"1992_3":{"comp":[["others","others",["repeated"]]],"visType":["others"],"compType":["repeated"],"compressed_tree":[{"composite_pattern":"repeated","visualization_type":[["others"]]}],"coOccurrence":[["others","others",["coOccurrence"]]],"year":2010,"conference":["VAST"],"authors":["Jaegul Choo","Hanseung Lee","Jaeyeon Kihm","Haesun Park"],"title":"iVisClassifier: An interactive visual analytics system for classification based on supervised dimension reduction","doi":"10.1109/VAST.2010.5652443","abstract":"We present an interactive visual analytics system for classification, iVisClassifier, based on a supervised dimension reduction method, linear discriminant analysis (LDA). Given high-dimensional data and associated cluster labels, LDA gives their reduced dimensional representation, which provides a good overview about the cluster structure. Instead of a single two- or three-dimensional scatter plot, iVisClassifier fully interacts with all the reduced dimensions obtained by LDA through parallel coordinates and a scatter plot. Furthermore, it significantly improves the interactivity and interpretability of LDA. LDA enables users to understand each of the reduced dimensions and how they influence the data by reconstructing the basis vector into the original data domain. By using heat maps, iVisClassifier gives an overview about the cluster relationship in terms of pairwise distances between cluster centroids both in the original space and in the reduced dimensional space. Equipped with these functionalities, iVisClassifier supports users\' classification tasks in an efficient way. Using several facial image data, we show how the above analysis is performed.","keywords":"","caption":"Figure 4: The overview of the system. SCface data with randomly chosen 30 persons\u2019 images were used, and different colors correspond to different clusters, e.g., persons. The arrow indicates a clicking operation. (A) Parallel coordinates view. The LDA results in 29 dimensions are represented. (B) Basis view. The LDA basis vectors are reconstructed in the original data domain, e.g., images in this case. (C) Heat map view. The pairwise distances between cluster centroids are visualized. The leftmost one is computed from the original space, and the rest from each of the LDA dimensions. Upon clicking, the full-size of a heat map is shown (D), and clicking each square shows the existing data in the corresponding pair of clusters (E). (F) Scatter plot view. A 2D scatter plot is visualized using two user-selected dimensions. When clicking a particular data point, its original data item is shown (G). (H) Control interfaces. Users can change the transparency and the colors in parallel coordinates. Data can be filtered at the data level as well as at the cluster level. The interfaces for unseen data visualize them one by one, interactively classify them, and finally updates the LDA model. A horizontal slide bar for the regularization parameter value in LDA controls how scattered each cluster is visualized. (I) shows the legend about cluster labels in terms of their assigned colors and enumerations.","img_size":{"width":2112,"height":1209},"subfigures":[{"x":10.093457606484217,"y":10.727316600258773,"width":2093.0996825894294,"height":1190.1187304094778,"type":"interface","id":"interface-0"}],"visualizations":[{"x":183.69444444444457,"y":53.388888888888886,"width":280.7222222222222,"height":249.7222222222222,"type":"heatmap","id":"heatmap-0"},{"x":8.027777777777885,"y":339.2777777777778,"width":466.72222222222223,"height":449.49999999999994,"type":"heatmap","id":"heatmap-1"},{"x":803.6944444444446,"y":451.2222222222222,"width":1100.5,"height":700.9444444444443,"type":"heatmap","id":"heatmap-2"},{"x":493.69444444444457,"y":60.27777777777778,"width":1410.4999999999998,"height":242.83333333333331,"type":"heatmap","id":"heatmap-3"},{"x":524.6944444444446,"y":301.38888888888886,"width":1377.7777777777776,"height":122.27777777777776,"type":"heatmap","id":"heatmap-4"},{"x":1947.2500000000002,"y":39.611111111111114,"width":153.27777777777783,"height":740.5555555555555,"type":"heatmap","id":"heatmap-5"},{"x":14.432902826176964,"y":820.2978896661465,"width":458.6725845873017,"height":372.98888214517524,"type":"others","id":"others-8"},{"x":1733.8124412822767,"y":709.6268741943742,"width":140.56974807664608,"height":182.72625987918155,"type":"others","id":"others-9"},{"x":490.2500000000001,"y":63.722222222222214,"width":1412.2222222222222,"height":242.83333333333331,"type":"parallel_coordinate","id":"parallel_coordinate-6"},{"x":803.6944444444446,"y":451.2222222222222,"width":1102.222222222222,"height":699.2222222222222,"type":"scatterplot","id":"scatterplot-7"}],"relations":[{"vislist":[{"vislist":["others-8"],"relation":null,"id":"group-0"}],"relation":"repeated","id":"relation-0"}]},"1995_1":{"comp":[["bar_chart","bar_chart",["repeated"]],["graph","map",["coordinated"]]],"visType":["bar_chart","graph","map"],"compType":["repeated","coordinated"],"compressed_tree":[{"composite_pattern":"repeated","visualization_type":[["bar_chart"]]},{"composite_pattern":"coordinated","visualization_type":[["graph"],["map"]]}],"coOccurrence":[["bar_chart","graph",["coOccurrence"]],["bar_chart","map",["coOccurrence"]],["graph","map",["coOccurrence"]]],"year":2010,"conference":["VAST"],"authors":["Zicheng Liao","Yizhou Yu","Baoquan Chen"],"title":"Anomaly detection in GPS data based on visual analytics","doi":"10.1109/VAST.2010.5652467","abstract":"Modern machine learning techniques provide robust approaches for data-driven modeling and critical information extraction, while human experts hold the advantage of possessing high-level intelligence and domain-specific expertise. We combine the power of the two for anomaly detection in GPS data by integrating them through a visualization and human-computer interaction interface. In this paper we introduce GPSvas (GPS Visual Analytics System), a system that detects anomalies in GPS data using the approach of visual analytics: a conditional random field (CRF) model is used as the machine learning component for anomaly detection in streaming GPS traces. A visualization component and an interactive user interface are built to visualize the data stream, display significant analysis results (i.e., anomalies or uncertain predications) and hidden information extracted by the anomaly detection model, which enable human experts to observe the real-time data behavior and gain insights into the data flow. Human experts further provide guidance to the machine learning model through the interaction tools; the learning model is then incrementally improved through an active learning procedure.","keywords":"","caption":"Figure 2: A snapshot of the visual interface. Middle left: main window for visualization and information display. Upper left: interface for visualization configurations and user operations. Bottom Left: interface that shows time and supports play-back. Right panel. Display dynamic histograms of the traffic or the selected items, a legend and system status.","img_size":{"width":1964,"height":1050},"subfigures":[{"x":6.624726286846846,"y":3.780425456260764,"width":1952.985137177387,"height":1044.6740802624108,"type":"interface","id":"interface-0"}],"visualizations":[{"x":1603.820767121683,"y":145.3483189287654,"width":331.3195425983234,"height":82.82988564958079,"type":"bar_chart","id":"bar_chart-0"},{"x":1611.0233658738205,"y":276.79574615527395,"width":315.11369540601396,"height":75.62728689744335,"type":"bar_chart","id":"bar_chart-1"},{"x":1607.4220664977515,"y":399.2399249416108,"width":320.51564447011697,"height":86.43118502564951,"type":"bar_chart","id":"bar_chart-2"},{"x":1603.820767121683,"y":496.4750080954666,"width":320.51564447011697,"height":118.84287941026808,"type":"bar_chart","id":"bar_chart-3"},{"x":7,"y":81.97674418604653,"width":1566.2790697674416,"height":920.9302325581393,"type":"map","id":"map-4"},{"x":13.983784224242218,"y":85.70124323996599,"width":1551.4463954730625,"height":909.766679841136,"type":"graph","id":"graph-6"}],"relations":[{"vislist":[{"vislist":["bar_chart-0","bar_chart-1","bar_chart-2","bar_chart-3"],"relation":null,"id":"group-0"}],"relation":"repeated","id":"relation-0"},{"vislist":[{"vislist":["graph-6"],"relation":null,"id":"group-3"},{"vislist":["map-4"],"relation":null,"id":"group-4"}],"relation":"coordinated","id":"relation-2"}]},"1999_9":{"comp":[["line_chart","line_chart",["repeated"]]],"visType":["line_chart"],"compType":["repeated"],"compressed_tree":[{"composite_pattern":"repeated","visualization_type":[["line_chart"]]}],"coOccurrence":[],"year":2010,"conference":["VAST"],"authors":["Hartmut Ziegler","Marco Jenny","Tino Gruse","Daniel A. Keim"],"title":"Visual market sector analysis for financial time series data","doi":"10.1109/VAST.2010.5652530","abstract":"The massive amount of financial time series data that originates from the stock market generates large amounts of complex data of high interest. However, adequate solutions that can effectively handle the information in order to gain insight and to understand the market mechanisms are rare. In this paper, we present two techniques and applications that enable the user to interactively analyze large amounts of time series data in real-time in order to get insight into the development of assets, market sectors, countries, and the financial market as a whole. The first technique allows users to quickly analyze combinations of single assets, market sectors as well as countries, compare them to each other, and to visually discover the periods of time where market sectors and countries get into turbulence. The second application clusters a selection of large amounts of financial time series data according to their similarity, and analyzes the distribution of the assets among market sectors. This allows users to identify the characteristic graphs which are representative for the development of a particular market sector, and also to identify the assets which behave considerably differently compared to other assets in the same sector. Both applications allow the user to perform investigative exploration techniques and interactive visual analysis in real-time.","keywords":"Visual Analytics, financial Information Visualization, Time Series Data, Time Series Clustering, Explorative Analysis","caption":"Figure 9: The interactive visualization tool shows the cluster centroids on top, below are the assets that match one of the given graphs closest. The assets are colored according to market sectors, each of the 42 sectors has its own color. Here, we compare 40 assets from the tobacco industry (orange) with 100 assets from the health care sector (pink). It is noteworthy that most assets of the tobacco industry perform quite well, compared to the health sector where many have negative trends. A click with the mouse opens detailed information of an asset on the right.","img_size":{"width":2082,"height":546},"subfigures":[{"x":1.9721662271262863,"y":4.536656459144508,"width":345.11506354156063,"height":523.9113333479313,"type":"single","id":"single-0"},{"x":1692.6710662075116,"y":6.754706932961576,"width":385.10844982074013,"height":530.3213605117799,"type":"single","id":"single-1"}],"visualizations":[{"x":1695.0031152647975,"y":233.00310289376995,"width":380.5109034267912,"height":298.35514018691595,"type":"heatmap","id":"heatmap-0"},{"x":10.809968847352025,"y":12.47973840778863,"width":339.4330218068535,"height":159.98753894080994,"type":"line_chart","id":"line_chart-1"},{"x":8.64797507788162,"y":176.79126488753943,"width":332.9470404984424,"height":354.5669781931464,"type":"line_chart","id":"line_chart-2"},{"x":345.9190031152648,"y":178.9532586570098,"width":332.94704049844233,"height":350.24299065420564,"type":"line_chart","id":"line_chart-3"},{"x":352.404984423676,"y":10.31774463831823,"width":326.4610591900311,"height":166.4735202492212,"type":"line_chart","id":"line_chart-4"},{"x":687.5140186915888,"y":5.9937570993774045,"width":328.6230529595015,"height":166.47352024922117,"type":"line_chart","id":"line_chart-5"},{"x":681.0280373831775,"y":176.79126488753943,"width":225.17067129300187,"height":350.4795558875991,"type":"line_chart","id":"line_chart-6"},{"x":1016.1370716510903,"y":12.47973840778863,"width":341.59501557632393,"height":159.98753894080994,"type":"line_chart","id":"line_chart-7"},{"x":1018.2990654205607,"y":176.79126488753943,"width":114.58566978193153,"height":350.2429906542055,"type":"line_chart","id":"line_chart-8"},{"x":1357.732087227414,"y":14.641732177259028,"width":339.43302180685373,"height":159.98753894080997,"type":"line_chart","id":"line_chart-9"},{"x":1353.4080996884736,"y":172.46727734859857,"width":114.5856697819313,"height":112.42367601246113,"type":"line_chart","id":"line_chart-10"},{"x":1132.8847352024923,"y":178.95325865700985,"width":112.42367601246109,"height":19.45794392523362,"type":"line_chart","id":"line_chart-11"},{"x":1130.722741433022,"y":198.4112025822435,"width":112.42367601246089,"height":23.781931464174423,"type":"line_chart","id":"line_chart-12"},{"x":1699.3271028037384,"y":8.155750868847806,"width":371.86292834890946,"height":218.36137071651095,"type":"line_chart","id":"line_chart-13"}],"relations":[{"vislist":[{"vislist":["line_chart-2"],"relation":null,"id":"group-0"}],"relation":"repeated","id":"relation-0"}]},"2001_1":{"comp":[["pie_chart","pie_chart",["repeated"]]],"visType":["pie_chart"],"compType":["repeated"],"compressed_tree":[{"composite_pattern":"repeated","visualization_type":[["pie_chart"]]}],"coOccurrence":[["pie_chart","pie_chart",["coOccurrence"]]],"year":2010,"conference":["VAST"],"authors":["Narges Mahyar","Ali Sarvghad","Melanie Tory"],"title":"A closer look at note taking in the co-located collaborative visual analytics process","doi":"10.1109/VAST.2010.5652879","abstract":"This paper highlights the important role that record-keeping (i.e. taking notes and saving charts) plays in collaborative data analysis within the business domain. The discussion of record-keeping is based on observations from a user study in which co-located teams worked on collaborative visual analytics tasks using large interactive wall and tabletop displays. Part of our findings is a collaborative data analysis framework that encompasses note taking as one of the main activities. We observed that record-keeping was a critical activity within the analysis process. Based on our observations, we characterize notes according to their content, scope, and usage, and describe how they fit into a process of collaborative data analysis. We then discuss suggestions for the design of collaborative visual analytics tools.","keywords":"note taking, recording, collaboration, tabletop, wall display, history, provenance","caption":"Figure 2. Partial screen shot of Explorer, depicting a comparison chart that visualizes margin, quantity sold, and sales revenue over category, filtered based on state (Texas) and city (Dallas).","img_size":{"width":990,"height":609},"subfigures":[{"x":6.051704809996007,"y":4.110940870570361,"width":978.5446849196011,"height":600.1299882181281,"type":"interface","id":"interface-0"}],"visualizations":[{"x":140.91666666666666,"y":395.5,"width":160.99999999999997,"height":185.5,"type":"pie_chart","id":"pie_chart-0"},{"x":353.25,"y":394.3333333333333,"width":164.5,"height":186.6666666666666,"type":"pie_chart","id":"pie_chart-1"},{"x":566.75,"y":395.5,"width":168.00000000000003,"height":189,"type":"pie_chart","id":"pie_chart-2"},{"x":766.25,"y":388.5,"width":213.5000000000001,"height":206.49999999999997,"type":"table","id":"table-3"},{"x":214.41666666666666,"y":9.333333333333332,"width":771.1666666666667,"height":227.49999999999997,"type":"table","id":"table-4"}],"relations":[{"vislist":[{"vislist":["pie_chart-0","pie_chart-1","pie_chart-2"],"relation":null,"id":"group-0"}],"relation":"repeated","id":"relation-0"}]},"2003_9":{"comp":[["scatterplot","scatterplot",["repeated"]]],"visType":["scatterplot"],"compType":["repeated"],"compressed_tree":[{"composite_pattern":"repeated","visualization_type":[["scatterplot"]]}],"coOccurrence":[["scatterplot","scatterplot",["coOccurrence"]]],"year":2010,"conference":["VAST"],"authors":["Yang Chen","Scott Barlowe","Jing Yan"],"title":"Click2Annotate: Automated Insight Externalization with rich semantics","doi":"10.1109/VAST.2010.5652885","abstract":"Insight Externalization (IE) refers to the process of capturing and recording the semantics of insights in decision making and problem solving. To reduce human effort, Automated Insight Externalization (AIE) is desired. Most existing IE approaches achieve automation by capturing events (e.g., clicks and key presses) or actions (e.g., panning and zooming). In this paper, we propose a novel AIE approach named Click2Annotate. It allows semi-automatic insight annotation that captures low-level analytics task results (e.g., clusters and outliers), which have higher semantic richness and abstraction levels than actions and events. Click2Annotate has two significant benefits. First, it reduces human effort required in IE and generates annotations easy to understand. Second, the rich semantic information encoded in the annotations enables various insight management activities, such as insight browsing and insight retrieval. We present a formal user study that proved this first benefit. We also illustrate the second benefit by presenting the novel insight management activities we developed based on Click2Annotate, namely scented insight browsing and faceted insight search.","keywords":"Visual Analytics, Decision Making, Annotation, Insight Management, Multidimensional Visualization","caption":"Figure 8: Insight management activities. (a) Scented insight browsing. (b) Faceted insight retrieval.","img_size":{"width":2034,"height":699},"subfigures":[{"x":4.628885187152647,"y":5.119387135709047,"width":1122.5926626087128,"height":633.5918328144804,"type":"interface","id":"interface-0"},{"x":1126.82467077879,"y":4.006341547185691,"width":904.0622225293746,"height":631.5741245365956,"type":"interface","id":"interface-1"}],"visualizations":[{"x":38.018691588785046,"y":156.2383177570093,"width":1081.4205607476636,"height":413.9813084112149,"type":"scatterplot","id":"scatterplot-0"},{"x":1478.5046728971963,"y":230.1635514018691,"width":206.99065420560737,"height":145.73831775700933,"type":"scatterplot","id":"scatterplot-1"},{"x":1746.747663551402,"y":225.9392523364486,"width":204.87850467289718,"height":143.62616822429902,"type":"scatterplot","id":"scatterplot-2"}],"relations":[{"vislist":[{"vislist":["scatterplot-1","scatterplot-2"],"relation":null,"id":"group-0"}],"relation":"repeated","id":"relation-0"}]},"2004_10":{"comp":[["scatterplot","scatterplot",["repeated"]]],"visType":["scatterplot"],"compType":["repeated"],"compressed_tree":[{"composite_pattern":"repeated","visualization_type":[["scatterplot"]]}],"coOccurrence":[["scatterplot","scatterplot",["coOccurrence"]]],"year":2010,"conference":["VAST"],"authors":["Jing Jin","Pedro A. Szekely"],"title":"Interactive querying of temporal data using a comic strip metaphor","doi":"10.1109/VAST.2010.5652890","abstract":"Finding patterns in temporal data is an important data analysis task in many domains. Static visualizations can help users easily see certain instances of patterns, but are not specially designed to support systematic analysis tasks, such as finding all instances of a pattern automatically. VizPattern is an interactive visual query environment that uses a comic strip metaphor to enable users to easily and quickly define and locate complex temporal patterns. Evaluations provide evidence that VizPattern is applicable in many domains, and that it enables a wide variety of users to answer questions about temporal data faster and with fewer errors than existing state-of-the-art visual analysis systems.","keywords":"","caption":"Figure 10: Visualizing patients\u2019 medical history related to nifedipine.","img_size":{"width":907,"height":687},"subfigures":[{"x":5.5468598515005185,"y":8.26577845653156,"width":895.9062802969978,"height":671.1995848570216,"type":"interface","id":"interface-0"}],"visualizations":[{"x":330.25954198473283,"y":416.0458015267174,"width":506.94656488549623,"height":157.32824427480924,"type":"line_chart","id":"line_chart-0"},{"x":13.854961832061122,"y":143.3435114503816,"width":291.9312977099236,"height":131.1068702290075,"type":"line_chart","id":"line_chart-1"},{"x":10.358778625954187,"y":267.45801526717554,"width":295.42748091603056,"height":134.60305343511448,"type":"line_chart","id":"line_chart-2"},{"x":10.358778625954187,"y":405.557251908397,"width":297.1755725190839,"height":129.35877862595413,"type":"line_chart","id":"line_chart-3"},{"x":12.106870229007596,"y":534.9160305343511,"width":295.4274809160305,"height":117.12213740458016,"type":"line_chart","id":"line_chart-4"},{"x":13.854961832061065,"y":139.8473282442748,"width":293.67938931297704,"height":125.86259541984735,"type":"scatterplot","id":"scatterplot-5"},{"x":13.98473282442751,"y":270.9541984732824,"width":293.5496183206106,"height":132.8549618320611,"type":"scatterplot","id":"scatterplot-6"},{"x":10.358778625954187,"y":405.557251908397,"width":297.1755725190839,"height":129.35877862595413,"type":"scatterplot","id":"scatterplot-7"},{"x":13.854961832061065,"y":538.412213740458,"width":295.4274809160305,"height":111.87786259541987,"type":"scatterplot","id":"scatterplot-8"},{"x":352.98473282442745,"y":573.3740458015267,"width":484.22137404580155,"height":99.64122137404583,"type":"scatterplot","id":"scatterplot-9"}],"relations":[{"vislist":[{"vislist":["scatterplot-5","scatterplot-6","scatterplot-7","scatterplot-8"],"relation":null,"id":"group-0"}],"relation":"repeated","id":"relation-0"}]},"2004_1":{"comp":[["comb","comb",["repeated"]],["glyph_based","line_chart",["accompanied"]],["line_chart","glyph_based",["accompanied"]]],"visType":["comb","glyph_based","line_chart"],"compType":["repeated","accompanied"],"compressed_tree":[{"composite_pattern":"repeated","visualization_type":[[{"composite_pattern":"accompanied","visualization_type":[["glyph_based","line_chart"]]}]]}],"coOccurrence":[["glyph_based","line_chart",["coOccurrence"]]],"year":2010,"conference":["VAST"],"authors":["Jing Jin","Pedro A. Szekely"],"title":"Interactive querying of temporal data using a comic strip metaphor","doi":"10.1109/VAST.2010.5652890","abstract":"Finding patterns in temporal data is an important data analysis task in many domains. Static visualizations can help users easily see certain instances of patterns, but are not specially designed to support systematic analysis tasks, such as finding all instances of a pattern automatically. VizPattern is an interactive visual query environment that uses a comic strip metaphor to enable users to easily and quickly define and locate complex temporal patterns. Evaluations provide evidence that VizPattern is applicable in many domains, and that it enables a wide variety of users to answer questions about temporal data faster and with fewer errors than existing state-of-the-art visual analysis systems.","keywords":"","caption":"Figure 1: Visualization of patient data.","img_size":{"width":915,"height":615},"subfigures":[{"x":5.940355311098126,"y":5.4708075710300195,"width":903.7735471778964,"height":608.639993766555,"type":"interface","id":"interface-0"}],"visualizations":[{"x":4.4656488549618985,"y":128.3206106870229,"width":710.4580152671756,"height":460.07633587786256,"type":"glyph_based","id":"glyph_based-0"},{"x":4.4656488549618985,"y":128.3206106870229,"width":707.3282442748091,"height":456.94656488549623,"type":"line_chart","id":"line_chart-1"}],"relations":[{"vislist":[{"vislist":[{"vislist":[{"vislist":["glyph_based-0","line_chart-1"],"relation":null,"id":"group-0"}],"relation":"accompanied","id":"relation-0"}],"relation":null,"id":"group-1"}],"relation":"repeated","id":"relation-1"}]},"2007_1":{"comp":[["bar_chart","bar_chart",["repeated"]]],"visType":["bar_chart"],"compType":["repeated"],"compressed_tree":[{"composite_pattern":"repeated","visualization_type":[["bar_chart"]]}],"coOccurrence":[["bar_chart","bar_chart",["coOccurrence"]]],"year":2010,"conference":["VAST"],"authors":["Zhicheng Liu","Bongshin Lee","Srikanth Kandula","Ratul Mahajan"],"title":"NetClinic: Interactive visualization to enhance automated fault diagnosis in enterprise networks","doi":"10.1109/VAST.2010.5652910","abstract":"Diagnosing faults in an operational computer network is a frustrating, time-consuming exercise. Despite advances, automatic diagnostic tools are far from perfect: they occasionally miss the true culprit and are mostly only good at narrowing down the search to a few potential culprits. This uncertainty and the inability to extract useful sense from tool output renders most tools not usable to administrators. To bridge this gap, we present NetClinic, a visual analytics system that couples interactive visualization with an automated diagnostic tool for enterprise networks. It enables administrators to verify the output of the automatic analysis at different levels of detail and to move seamlessly across levels while retaining appropriate context. A qualitative user study shows that NetClinic users can accurately identify the culprit, even when it is not present in the suggestions made by the automated component. We also find that supporting a variety of sensemaking strategies is a key to the success of systems that enhance automated diagnosis.","keywords":"Sensemaking, Semantic Graph Layout, Visual Analytics, Network Diagnosis, Information Visualization","caption":"Figure 2: NetClinic consists of three parts: 1) A Network View on the left visualizes the network at component, edge and network levels; 2) the Diagnosis View on the upper right presents suggested diagnoses at the network level; and 3) the Performance Counter View on the lower right displays variable level data. The graph shows a network with 7 machines; one cause\u2192fault path is highlighted.","img_size":{"width":2086,"height":1500},"subfigures":[{"x":6.706585810130863,"y":8.564133431546065,"width":2069.3946511425293,"height":1486.0644919582426,"type":"interface","id":"interface-0"}],"visualizations":[{"x":1573.1724137931035,"y":712.6436781609198,"width":465.51724137931024,"height":767.2413793103449,"type":"bar_chart","id":"bar_chart-0"},{"x":21.448275862068837,"y":152.29885057471265,"width":1531.6091954022988,"height":1330.459770114943,"type":"glyph_based","id":"glyph_based-1"}],"relations":[{"vislist":[{"vislist":["bar_chart-0"],"relation":null,"id":"group-0"}],"relation":"repeated","id":"relation-0"}]},"2009_2":{"comp":[["heatmap","heatmap",["repeated"]]],"visType":["heatmap"],"compType":["repeated"],"compressed_tree":[{"composite_pattern":"repeated","visualization_type":[["heatmap"]]}],"coOccurrence":[],"year":2010,"conference":["VAST"],"authors":["Daniela Oelke","David Spretke","Andreas Stoffel","Daniel A. Keim"],"title":"Visual readability analysis: How to make your writings easier to read","doi":"10.1109/VAST.2010.5652926","abstract":"We present a tool that is specifically designed to support a writer in revising a draft-version of a document. In addition to showing which paragraphs and sentences are difficult to read and understand, we assist the reader in understanding why this is the case. This requires features that are expressive predictors of readability, and are also semantically understandable. In the first part of the paper, we therefore discuss a semi-automatic feature selection approach that is used to choose appropriate measures from a collection of 141 candidate readability features. In the second part, we present the visual analysis tool VisRA, which allows the user to analyze the feature values across the text and within single sentences. The user can choose different visual representations accounting for differences in the size of the documents and the availability of information about the physical and logical layout of the documents. We put special emphasis on providing as much transparency as possible to ensure that the user can purposefully improve the readability of a sentence. Several case-studies are presented that show the wide range of applicability of our tool.","keywords":"","caption":"Figure 3: Screenshot of the VisRA tool on 3 different aggregation levels. (a) Corpus View (b) Block View (c) Detail View. To display single features, the colormap is generated as described in section 3.4 and figure 2.","img_size":{"width":2097,"height":1044},"subfigures":[{"x":1050.2853942255033,"y":344.1940572521602,"width":1041.8889278038944,"height":651.1591840689937,"type":"interface","id":"interface-0"},{"x":12.397843305829968,"y":51.685666198878856,"width":434.57666008363276,"height":588.4162854678789,"type":"single","id":"single-1"},{"x":504.94246408239746,"y":176.26996889784039,"width":558.274662762586,"height":658.1276601095834,"type":"single","id":"single-2"}],"visualizations":[{"x":1923.9452347083923,"y":423.2432432432432,"width":155.93172119487917,"height":547.9886201991465,"type":"heatmap","id":"heatmap-0"},{"x":29.003556187766748,"y":71.28307254623044,"width":408.3926031294452,"height":564.3243243243244,"type":"heatmap","id":"heatmap-1"},{"x":1067.0633001422475,"y":399.4822190611663,"width":197.51351351351357,"height":570.2645803698435,"type":"heatmap","id":"heatmap-2"},{"x":527.9850640113799,"y":233.1550497866287,"width":161.87197724039834,"height":580.6600284495021,"type":"heatmap","id":"heatmap-3"},{"x":1286.852773826458,"y":426.2133712660028,"width":637.0924608819346,"height":546.5035561877668,"type":"table","id":"table-4"}],"relations":[{"vislist":[{"vislist":["heatmap-1"],"relation":null,"id":"group-0"}],"relation":"repeated","id":"relation-0"}]},"2013_0":{"comp":[["scivis","scivis",["repeated"]]],"visType":["scivis"],"compType":["repeated"],"compressed_tree":[{"composite_pattern":"repeated","visualization_type":[["scivis"]]}],"coOccurrence":[["scivis","scivis",["coOccurrence"]]],"year":2010,"conference":["VAST"],"authors":["Orland Hoeber","Garnett Carl Wilson","Simon Harding","Ren\xe9 Enguehard","Rodolphe Devillers"],"title":"Visually representing geo-temporal differences","doi":"10.1109/VAST.2010.5652951","abstract":"Data sets that contain geospatial and temporal elements can be challenging to analyze. In particular, it can be difficult to determine how the data have changed over spatial and temporal ranges. In this poster, we present a visual approach for representing the pair-wise differences between geographically and temporally binned data. In addition to providing a novel method for visualizing such geo-temporal differences, GTdiff provides a high degree of interactivity that supports the exploration and analysis of the data.","keywords":"","caption":"Figure 1: The main visual components of GTdiff provide support for temporal filtering and binning (top portion of the left screenshot; see Section 2.1), spatial binning and the representation of geo-temporal difference graphs (bottom portion of the left screenshot; see Section 2.2), and spatial exploration and filtering of the data (right screenshot; see Section 2.3). The data shown is the catch weight of the cod fisheries off the coast of Newfoundland, Canada. GTdiff has been used in this example to highlight the collapse of the fisheries (i.e., the reduction in catch weight as identified by the red regions in the difference graphs and the small number and size of the yellow spheres that represent the catch data from the end of the temporal range in relation to the blue spheres that represent the catch data from the beginning of the temporal range).","img_size":{"width":2082,"height":957},"subfigures":[{"x":4.505749091575416,"y":7.541175391507248,"width":2074.0736242990038,"height":946.257771674462,"type":"interface","id":"interface-0"}],"visualizations":[{"x":9.269813000890471,"y":9.44746215494207,"width":708.2137132680318,"height":942.9620240250096,"type":"heatmap","id":"heatmap-0"},{"x":710.5978484107063,"y":4.590513820048331,"width":1366.8116377692454,"height":947.8189723599033,"type":"scivis","id":"scivis-1"},{"x":16.885609988622782,"y":15.990099919829373,"width":683.7443245845584,"height":928.6909390575889,"type":"scivis","id":"scivis-3"},{"x":8.14024390243901,"y":7.0024390243902435,"width":700.2439024390244,"height":945.4070471555614,"type":"small_multiple","id":"small_multiple-2"}],"relations":[{"vislist":[{"vislist":["scivis-3"],"relation":null,"id":"group-0"}],"relation":"repeated","id":"relation-0"}]},"2018_0":{"comp":[["bar_chart","bar_chart",["repeated"]]],"visType":["bar_chart"],"compType":["repeated"],"compressed_tree":[{"composite_pattern":"repeated","visualization_type":[["bar_chart"]]}],"coOccurrence":[["bar_chart","bar_chart",["coOccurrence"]]],"year":2010,"conference":["VAST"],"authors":["Heather Lipford","Felesia Stukes","Wenwen Dou","Matthew E. Hawkins","Remco Chang"],"title":"Helping users recall their reasoning process","doi":"10.1109/VAST.2010.5653598","abstract":"The final product of an analyst\'s investigation using a visualization is often a report of the discovered knowledge, as well as the methods employed and reasoning behind the discovery. We believe that analysts may have difficulty keeping track of their knowledge discovery process and will require tools to assist in accurately recovering their reasoning. We first report on a study examining analysts\' recall of their strategies and methods, demonstrating their lack of memory of the path of knowledge discovery. We then explore whether a tool visualizing the steps of the visual analysis can aid users in recalling their reasoning process. The results of our second study indicate that visualizations of interaction logs can serve as an effective memory aid, allowing analysts to recall additional details of their strategies and decisions.","keywords":"Visual analytics, visualization, reasoning process ","caption":"Figure 1. The WireVis system, showing (in clock-wise order from upper left) the Heatmap, Search by Example, Keyword Network, and Strings and Beads views.","img_size":{"width":1014,"height":636},"subfigures":[{"x":2.652755598776231,"y":4.9696175130101885,"width":1008.0174868231182,"height":626.737629844102,"type":"interface","id":"interface-0"}],"visualizations":[{"x":659.8688946015423,"y":38.68319364807599,"width":341.70694087403604,"height":243.6092544987146,"type":"bar_chart","id":"bar_chart-0"},{"x":2.6143958868894406,"y":30.508386450132544,"width":653.9845758354754,"height":294.2930591259639,"type":"heatmap","id":"heatmap-1"},{"x":7.519280205655491,"y":337.881137092806,"width":755.3521850899741,"height":281.2133676092545,"type":"line_chart","id":"line_chart-2"},{"x":779.2210796915166,"y":372.2153273241684,"width":215.8149100257069,"height":220.71979434447303,"type":"scatterplot","id":"scatterplot-3"}],"relations":[{"vislist":[{"vislist":["bar_chart-0"],"relation":null,"id":"group-0"}],"relation":"repeated","id":"relation-0"}]},"2020_1":{"comp":[["scatterplot","scatterplot",["repeated"]],["heatmap","heatmap",["repeated"]]],"visType":["scatterplot","heatmap"],"compType":["repeated"],"compressed_tree":[{"composite_pattern":"repeated","visualization_type":[["scatterplot"]]},{"composite_pattern":"repeated","visualization_type":[["heatmap"]]}],"coOccurrence":[["scatterplot","heatmap",["coOccurrence"]]],"year":2010,"conference":["VAST"],"authors":["Eric E. Monson","Guangliang Chen","Rachel Brady","Mauro Maggioni"],"title":"Data representation and exploration with Geometric Wavelets","doi":"10.1109/VAST.2010.5653822","abstract":"Geometric Wavelets is a new multi-scale data representation technique which is useful for a variety of applications such as data compression, interpretation and anomaly detection. We have developed an interactive visualization with multiple linked views to help users quickly explore data sets and understand this novel construction. Currently the interface is being used by applied mathematicians to view results and gain new insights, speeding methods development.","keywords":"","caption":"Figure 2: Annotated GUI for viewing and navigating the multi-scale Geometric Wavelets data representation.","img_size":{"width":1959,"height":630},"subfigures":[{"x":10.350851672489137,"y":8.649362178048621,"width":1945.4454074128566,"height":582.0774284131962,"type":"interface","id":"interface-0"}],"visualizations":[{"x":421.0934579439253,"y":71.904984423676,"width":290.90031152647975,"height":115.95327102803743,"type":"heatmap","id":"heatmap-0"},{"x":762.8504672897195,"y":301.7772585669782,"width":467.88161993769484,"height":213.59813084112142,"type":"parallel_coordinate","id":"parallel_coordinate-1"},{"x":437.36760124610595,"y":234.64641744548285,"width":286.83177570093454,"height":221.7352024922119,"type":"scatterplot","id":"scatterplot-2"},{"x":1253.5028712059066,"y":49.83593109105819,"width":262.0267238096699,"height":315.00363277187023,"type":"scatterplot","id":"scatterplot-3"},{"x":740.4735202492212,"y":57.6651090342679,"width":494.3271028037383,"height":225.80373831775702,"type":"sunburst_icicle","id":"sunburst_icicle-4"}],"relations":[{"vislist":[{"vislist":["scatterplot-3"],"relation":null,"id":"group-0"}],"relation":"repeated","id":"relation-0"},{"vislist":[{"vislist":["heatmap-0"],"relation":null,"id":"group-1"}],"relation":"repeated","id":"relation-1"}]},"2239_3":{"comp":[["scatterplot","scatterplot",["repeated"]]],"visType":["scatterplot"],"compType":["repeated"],"compressed_tree":[{"composite_pattern":"repeated","visualization_type":[["scatterplot"]]}],"coOccurrence":[["scatterplot","scatterplot",["coOccurrence"]]],"year":2012,"conference":["InfoVis"],"authors":["Heike Hofmann","Lendie Follett","Mahbubul Majumder","Dianne Cook"],"title":"Graphical Tests for Power Comparison of Competing Designs","doi":"10.1109/TVCG.2012.230","abstract":"Lineups [4, 28] have been established as tools for visual testing similar to standard statistical inference tests, allowing us to evaluate the validity of graphical findings in an objective manner. In simulation studies [12] lineups have been shown as being efficient: the power of visual tests is comparable to classical tests while being much less stringent in terms of distributional assumptions made. This makes lineups versatile, yet powerful, tools in situations where conditions for regular statistical tests are not or cannot be met. In this paper we introduce lineups as a tool for evaluating the power of competing graphical designs. We highlight some of the theoretical properties and then show results from two studies evaluating competing designs: both studies are designed to go to the limits of our perceptual abilities to highlight differences between designs. We use both accuracy and speed of evaluation as measures of a successful design. The first study compares the choice of coordinate system: polar versus cartesian coordinates. The results show strong support in favor of cartesian coordinates in finding fast and accurate answers to spotting patterns. The second study is aimed at finding shift differences between distributions. Both studies are motivated by data problems that we have recently encountered, and explore using simulated data to evaluate the plot designs under controlled conditions. Amazon Mechanical Turk (MTurk) is used to conduct the studies. The lineups provide an effective mechanism for objectively evaluating plot designs.","keywords":"Lineups, Visual inference, Power comparison, Efficiency of displays","caption":"Fig. 3. Screenshot of the website for the second study.","img_size":{"width":1002,"height":804},"subfigures":[{"x":1.1593209329667111,"y":7.1447675379556195,"width":996.2601748611877,"height":793.9887617446764,"type":"interface","id":"interface-0"}],"visualizations":[{"x":343.6956521739131,"y":147.7707509881423,"width":637.1620553359685,"height":638.7509881422925,"type":"scatterplot","id":"scatterplot-0"},{"x":343.58026559929766,"y":145.96410512803297,"width":640.4553075232321,"height":638.9687011960779,"type":"small_multiple","id":"small_multiple-1"}],"relations":[{"vislist":[{"vislist":["scatterplot-0"],"relation":null,"id":"group-0"}],"relation":"repeated","id":"relation-0"}]},"2259_4":{"comp":[["box_plot","box_plot",["repeated"]]],"visType":["box_plot"],"compType":["repeated"],"compressed_tree":[{"composite_pattern":"repeated","visualization_type":[["box_plot"]]}],"coOccurrence":[["box_plot","box_plot",["coOccurrence"]]],"year":2012,"conference":["InfoVis"],"authors":["Alan M. MacEachren","Robert E. Roth","James O\'Brien","Bonan Li","Derek Swingley","Mark Gahegan"],"title":"Visual Semiotics & Uncertainty Visualization: An Empirical Study","doi":"10.1109/TVCG.2012.279","abstract":"This paper presents two linked empirical studies focused on uncertainty visualization. The experiments are framed from two conceptual perspectives. First, a typology of uncertainty is used to delineate kinds of uncertainty matched with space, time, and attribute components of data. Second, concepts from visual semiotics are applied to characterize the kind of visual signification that is appropriate for representing those different categories of uncertainty. This framework guided the two experiments reported here. The first addresses representation intuitiveness, considering both visual variables and iconicity of representation. The second addresses relative performance of the most intuitive abstract and iconic representations of uncertainty on a map reading task. Combined results suggest initial guidelines for representing uncertainty and discussion focuses on practical applicability of results.","keywords":"Uncertainty visualization, uncertainty categories, visual variables, semiotics","caption":"Fig. 4. Descriptive statistics by series and symbol set with results for abstract symbols based on visual variables (Series 1) at the top followed by Series 2-10.On box-plots mean is shown as a black line, median as a gray line, and mode as a black dot.","img_size":{"width":2077,"height":2756},"subfigures":[{"x":7.497500605530091,"y":15.772609697386553,"width":2041.4852703023528,"height":2739.1201861245568,"type":"single","id":"single-0"}],"visualizations":[{"x":9.411796847252958,"y":9.41179684725296,"width":2058.176406305494,"height":2737.1764063054943,"type":"box_plot","id":"box_plot-0"}],"relations":[{"vislist":[{"vislist":["box_plot-0"],"relation":null,"id":"group-0"}],"relation":"repeated","id":"relation-0"}]},"2311_9":{"comp":[["scivis","scivis",["repeated"]]],"visType":["scivis"],"compType":["repeated"],"compressed_tree":[{"composite_pattern":"repeated","visualization_type":[["scivis"]]}],"coOccurrence":[["scivis","scivis",["coOccurrence"]]],"year":2012,"conference":["VAST"],"authors":["M. Shahriar Hossain","Praveen Kumar Reddy Ojili","Cindy Grimm","Rolf Mueller","Layne T. Watson","Naren Ramakrishnan"],"title":"Scatter/Gather Clustering: Flexibly Incorporating User Feedback to Steer Clustering Results","doi":"10.1109/TVCG.2012.258","abstract":"Significant effort has been devoted to designing clustering algorithms that are responsive to user feedback or that incorporate prior domain knowledge in the form of constraints. However, users desire more expressive forms of interaction to influence clustering outcomes. In our experiences working with diverse application scientists, we have identified an interaction style scatter/gather clustering that helps users iteratively restructure clustering results to meet their expectations. As the names indicate, scatter and gather are dual primitives that describe whether clusters in a current segmentation should be broken up further or, alternatively, brought back together. By combining scatter and gather operations in a single step, we support very expressive dynamic restructurings of data. Scatter/gather clustering is implemented using a nonlinear optimization framework that achieves both locality of clusters and satisfaction of user-supplied constraints. We illustrate the use of our scatter/gather clustering approach in a visual analytic application to study baffle shapes in the bat biosonar (ears and nose) system. We demonstrate how domain experts are adept at supplying scatter/gather constraints, and how our framework incorporates these constraints effectively without requiring numerous instance-level constraints.","keywords":"Scatter/gather clustering, alternative clustering, constrained clustering","caption":"Fig. 8. S/G cluster analysis user interface.","img_size":{"width":1752,"height":875},"subfigures":[{"x":317.7931720920452,"y":6.799555629783351,"width":1150.8656343358941,"height":864.1945527091,"type":"interface","id":"interface-0"}],"visualizations":[{"x":928.7745206247514,"y":85.29853905476325,"width":435.3313034306593,"height":321.3901419204097,"type":"scivis","id":"scivis-0"},{"x":927.200479946188,"y":439.2032347817254,"width":432.2978951342964,"height":311.65243008934254,"type":"scivis","id":"scivis-1"},{"x":444.87881619128865,"y":431.4710733566883,"width":432.6288367000364,"height":317.85031471433444,"type":"scivis","id":"scivis-2"}],"relations":[{"vislist":[{"vislist":["scivis-0","scivis-1","scivis-2"],"relation":null,"id":"group-0"}],"relation":"repeated","id":"relation-0"}]},"2315_0":{"comp":[["scatterplot","scatterplot",["repeated"]],["bar_chart","bar_chart",["repeated"]]],"visType":["scatterplot","bar_chart"],"compType":["repeated"],"compressed_tree":[{"composite_pattern":"repeated","visualization_type":[["scatterplot"]]},{"composite_pattern":"repeated","visualization_type":[["bar_chart"]]}],"coOccurrence":[["scatterplot","bar_chart",["coOccurrence"]]],"year":2012,"conference":["VAST"],"authors":["Florian Heimerl","Steffen Koch","Harald Bosch","Thomas Ertl"],"title":"Visual Classifier Training for Text Document Retrieval","doi":"10.1109/TVCG.2012.277","abstract":"Performing exhaustive searches over a large number of text documents can be tedious, since it is very hard to formulate search queries or define filter criteria that capture an analyst\'s information need adequately. Classification through machine learning has the potential to improve search and filter tasks encompassing either complex or very specific information needs, individually. Unfortunately, analysts who are knowledgeable in their field are typically not machine learning specialists. Most classification methods, however, require a certain expertise regarding their parametrization to achieve good results. Supervised machine learning algorithms, in contrast, rely on labeled data, which can be provided by analysts. However, the effort for labeling can be very high, which shifts the problem from composing complex queries or defining accurate filters to another laborious task, in addition to the need for judging the trained classifier\'s quality. We therefore compare three approaches for interactive classifier training in a user study. All of the approaches are potential candidates for the integration into a larger retrieval system. They incorporate active learning to various degrees in order to reduce the labeling effort as well as to increase effectiveness. Two of them encompass interactive visualization for letting users explore the status of the classifier in context of the labeled documents, as well as for judging the quality of the classifier in iterative feedback loops. We see our work as a step towards introducing user controlled classification methods in addition to text search and filtering for increasing recall in analytics scenarios involving large corpora.","keywords":"Visual analytics, human computer interaction, information retrieval, active learning, classification, user evaluation","caption":"Fig. 1. The interactive desktop for visual classifier training consists of (a) the Search Bar for bootstrapping the classifier, (b) the Main View showing the classifier\u2019s state with projected documents (c) the Cluster View of the documents with most uncertain classification, (d) the Content View showing the selected or highlighted documents, (e) the Term Weight View showing the highest weights, (f) the Manual View used during evaluation, (g) the Classifier History for undo/redo navigation, (h) the Labeled Document View listing labeled documents, and (i) the Labeling Controls with a preview of the estimated impact of the newly labeled documents on the classifier.","img_size":{"width":1917,"height":1060},"subfigures":[{"x":9.618087069623641,"y":3.7972821903872642,"width":1896.636381580676,"height":1050.149219385481,"type":"interface","id":"interface-0"}],"visualizations":[{"x":477.2056011390442,"y":779.5989494122726,"width":891.570467533428,"height":258.2793059750031,"type":"bar_chart","id":"bar_chart-1"},{"x":488.9394428844081,"y":173.99595111402857,"width":873.1755219133057,"height":551.3823512184654,"type":"scatterplot","id":"scatterplot-0"},{"x":21.60422731333834,"y":157.77725818442934,"width":439.8976406153592,"height":421.5031931920477,"type":"scatterplot","id":"scatterplot-2"}],"relations":[{"vislist":[{"vislist":["scatterplot-0"],"relation":null,"id":"group-0"}],"relation":"repeated","id":"relation-0"},{"vislist":[{"vislist":["bar_chart-1"],"relation":null,"id":"group-1"}],"relation":"repeated","id":"relation-1"}]},"2320_6":{"comp":[["scatterplot","scatterplot",["repeated"]]],"visType":["scatterplot"],"compType":["repeated"],"compressed_tree":[{"composite_pattern":"repeated","visualization_type":[["scatterplot"]]},{"composite_pattern":"repeated","visualization_type":[["scatterplot"]]},{"composite_pattern":"repeated","visualization_type":[["scatterplot"]]}],"coOccurrence":[["scatterplot","scatterplot",["coOccurrence"]]],"year":2012,"conference":["VAST"],"authors":["Andrada Tatu","Fabian Maass","Ines F\xe4rber","Enrico Bertini","Tobias Schreck","Thomas Seid","Daniel A. Keim"],"title":"Subspace search and visualization to make sense of alternative clusterings in high-dimensional data","doi":"10.1109/VAST.2012.6400488","abstract":"In explorative data analysis, the data under consideration often resides in a high-dimensional (HD) data space. Currently many methods are available to analyze this type of data. So far, proposed automatic approaches include dimensionality reduction and cluster analysis, whereby visual-interactive methods aim to provide effective visual mappings to show, relate, and navigate HD data. Furthermore, almost all of these methods conduct the analysis from a singular perspective, meaning that they consider the data in either the original HD data space, or a reduced version thereof. Additionally, HD data spaces often consist of combined features that measure different properties, in which case the particular relationships between the various properties may not be clear to the analysts a priori since it can only be revealed if appropriate feature combinations (subspaces) of the data are taken into consideration. Considering just a single subspace is, however, often not sufficient since different subspaces may show complementary, conjointly, or contradicting relations between data items. Useful information may consequently remain embedded in sets of subspaces of a given HD input data space. Relying on the notion of subspaces, we propose a novel method for the visual analysis of HD data in which we employ an interestingness-guided subspace search algorithm to detect a candidate set of subspaces. Based on appropriately defined subspace similarity functions, we visualize the subspaces and provide navigation facilities to interactively explore large sets of subspaces. Our approach allows users to effectively compare and relate subspaces with respect to involved dimensions and clusters of objects. We apply our approach to synthetic and real data sets. We thereby demonstrate its support for understanding HD data from different perspectives, effectively yielding a more complete view on HD data.","keywords":"","caption":"Figure 6: (1) Subspace group view for the 12D synthetic data set with six subspace groups. (2) Single subspace view showing the representative subspace for the \ufb01rst group. (3) Details-on-demand in the parallel coordinates view for the selected subspace. (4) The MDS layout of the subspace search results based on their dimension similarity. (5) Group detail view for the three (orange, green, purple) subspace groups. (6) Hierarchical navigation buttons.","img_size":{"width":2112,"height":1173},"subfigures":[{"x":10.662791907414517,"y":11.650127949867391,"width":2095.666419281705,"height":1153.4448501976904,"type":"interface","id":"interface-0"}],"visualizations":[{"x":1058.5761346998536,"y":8.587115666178624,"width":1030.4538799414347,"height":913.6691068814056,"type":"glyph_based","id":"glyph_based-0"},{"x":205.01683748169836,"y":970.3440702781844,"width":1896.0351390922397,"height":178.61200585651542,"type":"parallel_coordinate","id":"parallel_coordinate-1"},{"x":16.100292825768634,"y":972.0614934114202,"width":182.04685212298688,"height":182.04685212298693,"type":"scatterplot","id":"scatterplot-2"},{"x":1063.7284040995607,"y":13.739385065885799,"width":1030.4538799414347,"height":911.9516837481699,"type":"scatterplot","id":"scatterplot-3"},{"x":12.665446559297207,"y":281.6573938506588,"width":886.1903367496341,"height":113.34992679355781,"type":"scatterplot","id":"scatterplot-4"},{"x":22.96998535871154,"y":432.79062957540265,"width":996.1054172767205,"height":159.72035139092242,"type":"scatterplot","id":"scatterplot-5"},{"x":17.817715959004374,"y":595.9458272327967,"width":996.1054172767205,"height":334.89751098096633,"type":"scatterplot","id":"scatterplot-6"},{"x":24.68740849194728,"y":13.739385065885799,"width":750.5139092240116,"height":164.87262079062958,"type":"scatterplot","id":"scatterplot-7"}],"relations":[{"vislist":[{"vislist":["scatterplot-4"],"relation":null,"id":"group-0"}],"relation":"repeated","id":"relation-0"},{"vislist":[{"vislist":["scatterplot-5"],"relation":null,"id":"group-1"}],"relation":"repeated","id":"relation-1"},{"vislist":[{"vislist":["scatterplot-6"],"relation":null,"id":"group-2"}],"relation":"repeated","id":"relation-2"}]},"2322_1":{"comp":[["scatterplot","scatterplot",["repeated"]]],"visType":["scatterplot"],"compType":["repeated"],"compressed_tree":[{"composite_pattern":"repeated","visualization_type":[["scatterplot"]]}],"coOccurrence":[["scatterplot","scatterplot",["coOccurrence"]]],"year":2012,"conference":["VAST"],"authors":["Anushka Anand","Leland Wilkinson","Dang Tuan Nhon"],"title":"Visual pattern discovery using random projections","doi":"10.1109/VAST.2012.6400490","abstract":"An essential element of exploratory data analysis is the use of revealing low-dimensional projections of high-dimensional data. Projection Pursuit has been an effective method for finding interesting low-dimensional projections of multidimensional spaces by optimizing a score function called a projection pursuit index. However, the technique is not scalable to high-dimensional spaces. Here, we introduce a novel method for discovering noteworthy views of high-dimensional data spaces by using binning and random projections. We define score functions, akin to projection pursuit indices, that characterize visual patterns of the low-dimensional projections that constitute feature subspaces. We also describe an analytic, multivariate visualization platform based on this algorithm that is scalable to extremely large problems.","keywords":"Random Projections, High-dimensional Data","caption":"Figure 2: The Subspace Explorer showing a highly Clumpy 20-D random projection for a dataset with 2000 rows, 500 dimensions and clusters embedded in 5 dimensions. The detected known embedding dimensions are shown as orange text. (A) Control options. (B) Biplot View of the data subspace. (C) Random Projection View of the biplot of the projected data space. (D) ScoreView of the top 10 scoring random projections. The selected (red) bar represents one 20-D random projection which is shown in different perspectives in the other plots. (E) Radar plot Icon summary of all scores for the selected random projection. (F) Variable List (same set as B). (G) Parallel Coordinate View of the top used dimensions (same set as B)","img_size":{"width":1783,"height":1185},"subfigures":[{"x":36.38647922443381,"y":17.83757948493976,"width":1707.705437930948,"height":1111.4906489973034,"type":"interface","id":"interface-0"}],"visualizations":[{"x":1139.5232558139535,"y":198.81229235880394,"width":289.3604651162789,"height":194.87541528239197,"type":"bar_chart","id":"bar_chart-0"},{"x":1143.4601328903655,"y":419.2774086378737,"width":283.455149501661,"height":297.23421926910294,"type":"graph","id":"graph-4"},{"x":60.81893687707634,"y":753.9119601328902,"width":1377.906976744186,"height":307.0764119601329,"type":"parallel_coordinate","id":"parallel_coordinate-8"},{"x":60.81893687707634,"y":190.93853820598005,"width":511.79401993355486,"height":529.5099667774085,"type":"scatterplot","id":"scatterplot-10"},{"x":592.2973421926911,"y":194.87541528239197,"width":527.5415282392025,"height":525.5730897009967,"type":"scatterplot","id":"scatterplot-11"}],"relations":[{"vislist":[{"vislist":["scatterplot-10","scatterplot-11"],"relation":null,"id":"group-0"}],"relation":"repeated","id":"relation-0"}]},"2324_3":{"comp":[["scatterplot","scatterplot",["repeated"]]],"visType":["scatterplot"],"compType":["repeated"],"compressed_tree":[{"composite_pattern":"repeated","visualization_type":[["scatterplot"]]}],"coOccurrence":[["scatterplot","scatterplot",["coOccurrence"]]],"year":2012,"conference":["VAST"],"authors":["Benjamin H\xf6ferlin","Rudolf Netzel","Markus H\xf6ferlin","Daniel Weiskopf","Gunther Heidemann"],"title":"Inter-active learning of ad-hoc classifiers for video visual analytics","doi":"10.1109/VAST.2012.6400492","abstract":"Learning of classifiers to be used as filters within the analytical reasoning process leads to new and aggravates existing challenges. Such classifiers are typically trained ad-hoc, with tight time constraints that affect the amount and the quality of annotation data and, thus, also the users\' trust in the classifier trained. We approach the challenges of ad-hoc training by inter-active learning, which extends active learning by integrating human experts\' background knowledge to greater extent. In contrast to active learning, not only does inter-active learning include the users\' expertise by posing queries of data instances for labeling, but it also supports the users in comprehending the classifier model by visualization. Besides the annotation of manually or automatically selected data instances, users are empowered to directly adjust complex classifier models. Therefore, our model visualization facilitates the detection and correction of inconsistencies between the classifier model trained by examples and the user\'s mental model of the class definition. Visual feedback of the training process helps the users assess the performance of the classifier and, thus, build up trust in the filter created. We demonstrate the capabilities of inter-active learning in the domain of video visual analytics and compare its performance with the results of random sampling and uncertainty sampling of training sets.","keywords":"","caption":"Figure 4: Typical workspace of our visual analytics system for inter-active learning after learning with a couple of training examples: (a) cascaded scatterplot, (b) cascade information, (c) selection interface, (d) video context view, (e) visualization of classifier model, (f) annotation view. Details of the components can be found in Section 6.","img_size":{"width":2073,"height":939},"subfigures":[{"x":4.478793094959561,"y":-1.264154054275546,"width":2061.881550308149,"height":938.2878699092906,"type":"interface","id":"interface-0"}],"visualizations":[{"x":1329.7108527212906,"y":106.19561180896352,"width":560.0567460989639,"height":781.4998302799468,"type":"glyph_based","id":"glyph_based-1"},{"x":4.207983138281612,"y":84.74680258500736,"width":722.454554566346,"height":427.3521588665709,"type":"scatterplot","id":"scatterplot-0"}],"relations":[{"vislist":[{"vislist":["scatterplot-0"],"relation":null,"id":"group-0"}],"relation":"repeated","id":"relation-0"}]},"2325_0":{"comp":[["scatterplot","scatterplot",["repeated"]],["scatterplot","table",["nested"]],["pie_chart","map",["nested"]]],"visType":["scatterplot","table","pie_chart","map"],"compType":["repeated","nested"],"compressed_tree":[{"composite_pattern":"repeated","visualization_type":[["scatterplot"]]},{"composite_pattern":"nested","visualization_type":[["pie_chart"],["map"]]},{"composite_pattern":"nested","visualization_type":[["scatterplot"],["table"]]},{"composite_pattern":"nested","visualization_type":[["scatterplot"],["table"]]}],"coOccurrence":[["pie_chart","map",["coOccurrence"]],["pie_chart","scatterplot",["coOccurrence"]],["pie_chart","table",["coOccurrence"]],["map","scatterplot",["coOccurrence"]],["map","table",["coOccurrence"]],["scatterplot","table",["coOccurrence"]]],"year":2012,"conference":["VAST"],"authors":["Zafar Ahmed","Chris Weaver"],"title":"An adaptive parameter space-filling algorithm for highly interactive cluster exploration","doi":"10.1109/VAST.2012.6400493","abstract":"For a user to perceive continuous interactive response time in a visualization tool, the rule of thumb is that it must process, deliver, and display rendered results for any given interaction in under 100 milliseconds. In many visualization systems, successive interactions trigger independent queries and caching of results. Consequently, computationally expensive queries like multidimensional clustering cannot keep up with rapid sequences of interactions, precluding visual benefits such as motion parallax. In this paper, we describe a heuristic prefetching technique to improve the interactive response time of KMeans clustering in dynamic query visualizations of multidimensional data. We address the tradeoff between high interaction and intense query computation by observing how related interactions on overlapping data subsets produce similar clustering results, and characterizing these similarities within a parameter space of interaction. We focus on the two-dimensional parameter space defined by the minimum and maximum values of a time range manipulated by dragging and stretching a one-dimensional filtering lens over a plot of time series data. Using calculation of nearest neighbors of interaction points in parameter space, we reuse partial query results from prior interaction sequences to calculate both an immediate best-effort clustering result and to schedule calculation of an exact result. The method adapts to user interaction patterns in the parameter space by reprioritizing the interaction neighbors of visited points in the parameter space. A performance study on Mesonet meteorological data demonstrates that the method is a significant improvement over the baseline scheme in which interaction triggers on-demand, exact-range clustering with LRU caching. We also present initial evidence that approximate, temporary clustering results are sufficiently accurate (compared to exact results) to convey useful cluster structure during rapid and protracted interaction.","keywords":"","caption":"Figure 1: Mesomorph, a highly interactive tool for visual analysis of Mesonet [11] measurements over time. Lists and sliders allow selection of one or more clustering variables (A), the number of clusters (B), and two variables (C) to display in a scatter plot (D), two time series plots (E), and in other views. Sliders allow manual adjustment of the size of plotted points (F). A categorical color scheme represents cluster membership. Interaction with lenses in the time series plots triggers dynamic recomputation of clusters.","img_size":{"width":2115,"height":1302},"subfigures":[{"x":3.208307688603148,"y":6.060703220899243,"width":2107.198614009406,"height":1292.6499082151222,"type":"interface","id":"interface-0"}],"visualizations":[{"x":1691.428423180318,"y":259.25868461674605,"width":411.1479417976913,"height":285.44495415740187,"type":"line_chart","id":"line_chart-18"},{"x":440.17241379310354,"y":37.413793103448256,"width":1244.6321839080458,"height":503.8390804597702,"type":"map","id":"map-14"},{"x":438.94186046511635,"y":28.116279069767447,"width":1247.9302325581396,"height":516.9069767441862,"type":"pie_chart","id":"pie_chart-0"},{"x":1131.0804597701149,"y":566.1954022988508,"width":947.8160919540228,"height":473.9080459770114,"type":"scatterplot","id":"scatterplot-2"},{"x":1128.5862068965519,"y":1072.5287356321842,"width":952.8045977011494,"height":212.01149425287375,"type":"scatterplot","id":"scatterplot-3"},{"x":445.16091954022977,"y":553.7241379310345,"width":675.9425287356321,"height":598.6206896551724,"type":"scatterplot","id":"scatterplot-4"},{"x":1684.709302325582,"y":8.651162790697676,"width":421.7441860465113,"height":248.7209302325582,"type":"scatterplot","id":"scatterplot-5"},{"x":1131.0804597701149,"y":563.7011494252874,"width":945.3218390804597,"height":478.89655172413796,"type":"small_multiple","id":"small_multiple-10"},{"x":1128.5862068965519,"y":1072.5287356321842,"width":952.8045977011494,"height":212.01149425287375,"type":"small_multiple","id":"small_multiple-11"},{"x":1131.0804597701149,"y":563.7011494252874,"width":945.3218390804597,"height":478.89655172413796,"type":"table","id":"table-12"},{"x":1128.5862068965519,"y":1072.5287356321842,"width":952.8045977011494,"height":212.01149425287375,"type":"table","id":"table-13"},{"x":8.666666666666574,"y":493.86206896551727,"width":399.08045977011494,"height":636.0344827586207,"type":"table","id":"table-16"}],"relations":[{"vislist":[{"vislist":["scatterplot-9"],"relation":null,"id":"group-0"}],"relation":"repeated","id":"relation-0"},{"vislist":[{"vislist":["pie_chart-0"],"relation":null,"id":"group-1"},{"vislist":["map-14"],"relation":null,"id":"group-2"}],"relation":"nested","id":"relation-1"},{"vislist":[{"vislist":["scatterplot-2"],"relation":null,"id":"group-3"},{"vislist":["table-12"],"relation":null,"id":"group-4"}],"relation":"nested","id":"relation-2"},{"vislist":[{"vislist":["scatterplot-3"],"relation":null,"id":"group-5"},{"vislist":["table-13"],"relation":null,"id":"group-6"}],"relation":"nested","id":"relation-3"}]},"2326_7":{"comp":[["bar_chart","bar_chart",["repeated"]]],"visType":["bar_chart"],"compType":["repeated"],"compressed_tree":[{"composite_pattern":"repeated","visualization_type":[["bar_chart"]]}],"coOccurrence":[["bar_chart","bar_chart",["coOccurrence"]]],"year":2012,"conference":["VAST"],"authors":["Jishang Wei","Zeqian Shen","Neel Sundaresan","Kwan-Liu Ma"],"title":"Visual cluster exploration of web clickstream data","doi":"10.1109/VAST.2012.6400494","abstract":"Web clickstream data are routinely collected to study how users browse the web or use a service. It is clear that the ability to recognize and summarize user behavior patterns from such data is valuable to e-commerce companies. In this paper, we introduce a visual analytics system to explore the various user behavior patterns reflected by distinct clickstream clusters. In a practical analysis scenario, the system first presents an overview of clickstream clusters using a Self-Organizing Map with Markov chain models. Then the analyst can interactively explore the clusters through an intuitive user interface. He can either obtain summarization of a selected group of data or further refine the clustering result. We evaluated our system using two different datasets from eBay. Analysts who were working on the same data have confirmed the system\'s effectiveness in extracting user behavior patterns from complex datasets and enhancing their ability to reason.","keywords":"","caption":"Figure 6: The interface for clickstream pattern exploration. (a) Clickstreams visualization; (b) action legends; (c) the selected clickstream; (d) data profile of one single clickstream or a data group. Whenever the analyst selects a single clickstream(indicated as \u201cI\u201d) or a group(indicated as \u201cG\u201d) in area (a), the corresponding information summary is shown in area (b).","img_size":{"width":1272,"height":726},"subfigures":[{"x":4.854223475816765,"y":2.600780066246374,"width":1263.835943442584,"height":719.2531445979803,"type":"interface","id":"interface-0"}],"visualizations":[{"x":968.1742313323571,"y":620.7672035139091,"width":245.5431918008785,"height":93.54026354319181,"type":"bar_chart","id":"bar_chart-0"},{"x":962.8594436310393,"y":510.21961932650055,"width":244.4802342606149,"height":94.60322108345531,"type":"bar_chart","id":"bar_chart-1"},{"x":961.796486090776,"y":391.1683748169838,"width":246.60614934114187,"height":104.16983894582718,"type":"bar_chart","id":"bar_chart-2"},{"x":959.6705710102488,"y":284.8726207906295,"width":241.29136163982432,"height":103.10688140556363,"type":"bar_chart","id":"bar_chart-3"},{"x":6.197657393850704,"y":6.377745241581256,"width":889.6954612005856,"height":712.1815519765738,"type":"proportional_area_chart","id":"proportional_area_chart-4"}],"relations":[{"vislist":[{"vislist":["bar_chart-0","bar_chart-1","bar_chart-2","bar_chart-3"],"relation":null,"id":"group-0"}],"relation":"repeated","id":"relation-0"}]},"2338_0":{"comp":[["glyph_based","glyph_based",["repeated"]],["glyph_based","map",["coordinated"]]],"visType":["glyph_based","map"],"compType":["repeated","coordinated"],"compressed_tree":[{"composite_pattern":"repeated","visualization_type":[["glyph_based"]]},{"composite_pattern":"repeated","visualization_type":[["glyph_based"]]},{"composite_pattern":"coordinated","visualization_type":[["glyph_based"],["map"]]}],"coOccurrence":[["glyph_based","map",["coOccurrence"]]],"year":2012,"conference":["VAST"],"authors":["Ming C. Hao","Manish Marwah","Sebastian Mittelst\xe4dt","Halld\xf3r Janetzko","Daniel A. Keim","Umeshwar Dayal","Cullen Bash","Carlos J. Felix","Chandrakant D. Patel","Meichun Hsu","Yuan Chen"],"title":"Exploring cyber physical data streams using Radial Pixel Visualizations","doi":"10.1109/VAST.2012.6400541","abstract":"Cyber physical systems (CPS), such as smart buildings and data centers, are richly instrumented systems composed of tightly coupled computational and physical elements that generate large amounts of data. To explore CPS data and obtain actionable insights, we construct a Radial Pixel Visualization (RPV) system, which uses multiple concentric rings to show the data in a compact circular layout of small polygons (pixel cells), each of which represents an individual data value. RPV provides an effective visual representation of locality and periodicity of the high volume, multivariate data streams, and seamlessly combines them with the results of an automated analysis. In the outermost ring the results of correlation analysis and peak point detection are highlighted. Our explorations demonstrates how RPV can help administrators to identify periodic thermal hot spots, understand data center energy consumption, and optimize IT workload.","keywords":"","caption":"Figure 1:  This figure shows Radial Pixel Visualization (RPV) of rows of racks and hot/cold aisles in a 500 kilowatt data center over the past 24 hours in real-time. Each rack has a pair of RPV\u2019s depicting data from 5 inlet/outlet temperature sensors  which should always be below  a  threshold  and  usually  also  maintain  an  ascending  sequence,  that  is,  T1<T2<T3<T4<T5,  where  T1  is  closest  to  the  floor.  Each measurement is represented by a pixel cell. Color depicts temperature using the standard data center color map from low (purple) to high (red). By correlating thermal alarms and their physical locations and by looking at temperature patterns in the recent past, administrators are able to quickly identify problems (e.g., Rack F7 has out of sequence sensor: T3>T4) and find the root causes of those alarms. ","img_size":{"width":2017,"height":989},"subfigures":[{"x":7.181970996530873,"y":7.750367996015825,"width":2005.7918928298766,"height":979.8145409565685,"type":"interface","id":"interface-0"}],"visualizations":[{"x":58.92857142857153,"y":21.357142857142854,"width":253,"height":292.4285714285714,"type":"glyph_based","id":"glyph_based-0"},{"x":410.5000000000001,"y":22.999999999999996,"width":256.28571428571433,"height":285.8571428571428,"type":"glyph_based","id":"glyph_based-1"},{"x":768.6428571428571,"y":21.357142857142854,"width":249.71428571428575,"height":290.7857142857143,"type":"glyph_based","id":"glyph_based-2"},{"x":1123.4999999999998,"y":19.714285714285715,"width":248.07142857142838,"height":287.5,"type":"glyph_based","id":"glyph_based-3"},{"x":1649.2142857142858,"y":19.714285714285715,"width":346.64285714285705,"height":220.1428571428571,"type":"glyph_based","id":"glyph_based-4"},{"x":22.78571428571439,"y":331.85714285714283,"width":1608.3571428571424,"height":647.2857142857142,"type":"glyph_based","id":"glyph_based-5"},{"x":19.500000000000114,"y":326.9285714285714,"width":1614.9285714285709,"height":652.2142857142857,"type":"heatmap","id":"heatmap-12"},{"x":62.21428571428584,"y":21.357142857142854,"width":244.78571428571428,"height":285.85714285714283,"type":"heatmap","id":"heatmap-13"},{"x":408.857142857143,"y":19.714285714285708,"width":256.2857142857142,"height":284.21428571428567,"type":"heatmap","id":"heatmap-14"},{"x":768.6428571428571,"y":19.714285714285715,"width":251.35714285714286,"height":290.7857142857143,"type":"heatmap","id":"heatmap-15"},{"x":1121.8571428571427,"y":18.07142857142857,"width":253,"height":292.4285714285714,"type":"heatmap","id":"heatmap-16"},{"x":1644.285714285714,"y":18.07142857142857,"width":353.2142857142855,"height":218.5,"type":"heatmap","id":"heatmap-17"},{"x":33.8717890674497,"y":340.0082685126975,"width":1584.5370655048998,"height":632.7637581948053,"type":"map","id":"map-26"}],"relations":[{"vislist":[{"vislist":["glyph_based-0","glyph_based-1","glyph_based-2","glyph_based-3"],"relation":null,"id":"group-0"}],"relation":"repeated","id":"relation-0"},{"vislist":[{"vislist":["glyph_based-4"],"relation":null,"id":"group-1"}],"relation":"repeated","id":"relation-1"},{"vislist":[{"vislist":["glyph_based-5"],"relation":null,"id":"group-2"},{"vislist":["map-26"],"relation":null,"id":"group-3"}],"relation":"coordinated","id":"relation-2"}]},"2339_0":{"comp":[["contour_graph","contour_graph",["repeated"]],["line_chart","line_chart",["repeated"]]],"visType":["contour_graph","line_chart"],"compType":["repeated"],"compressed_tree":[{"composite_pattern":"repeated","visualization_type":[["contour_graph"]]},{"composite_pattern":"repeated","visualization_type":[["contour_graph"]]},{"composite_pattern":"repeated","visualization_type":[["line_chart"]]}],"coOccurrence":[["contour_graph","line_chart",["coOccurrence"]]],"year":2012,"conference":["VAST"],"authors":["Hua Guo","Diem Tran","David H. Laidlaw"],"title":"Incorporating GOMS analysis into the design of an EEG data visual analysis tool","doi":"10.1109/VAST.2012.6400542","abstract":"In this paper, we present a case study where we incorporate GOMS (Goals, Operators, Methods, and Selectors) [2] task analysis into the design process of a visual analysis tool. We performed GOMS analysis on an Electroencephalography (EEG) analyst\'s current data analysis strategy to identify important user tasks and unnecessary user actions in his current workflow. We then designed an EEG data visual analysis tool based on the GOMS analysis result. Evaluation results show that the tool we have developed, EEGVis, allows the user to analyze EEG data with reduced subjective cognitive load, faster speed and increased confidence in the analysis quality. The positive evaluation results suggest that our design process demonstrates an effective application of GOMS analysis to discover opportunities for designing better tools to support the user\'s visual analysis process.","keywords":"","caption":"Figure 2: User Interface of EEGVis","img_size":{"width":723,"height":423},"subfigures":[{"x":3.0953265348287986,"y":5.095204853784367,"width":714.5580051679271,"height":414.6103062676638,"type":"interface","id":"interface-0"}],"visualizations":[{"x":204.76154804975013,"y":33.65468917740835,"width":126.91802074279154,"height":160.003487688562,"type":"contour_graph","id":"contour_graph-0"},{"x":342.5272628731222,"y":33.11230447337933,"width":126.91802074279155,"height":160.54587239259098,"type":"contour_graph","id":"contour_graph-1"},{"x":480.29297769649423,"y":33.11230447337933,"width":131.25709837502382,"height":163.25779591273613,"type":"contour_graph","id":"contour_graph-2"},{"x":208.73862507662895,"y":240.4262846343296,"width":124.92545833716123,"height":162.9255977553091,"type":"contour_graph","id":"contour_graph-3"},{"x":340.7891095546929,"y":238.52627766342215,"width":129.20047402170286,"height":163.87560124076285,"type":"contour_graph","id":"contour_graph-4"},{"x":480.91462365911326,"y":239.00127940614902,"width":129.67547576442973,"height":162.45059601258225,"type":"contour_graph","id":"contour_graph-5"},{"x":4.616705699789294,"y":32.96519985856627,"width":202.5871682181064,"height":173.05187264626744,"type":"line_chart","id":"line_chart-6"},{"x":5.086759785498344,"y":238.56577388407115,"width":206.85505124450955,"height":175.26939970717424,"type":"line_chart","id":"line_chart-7"}],"relations":[{"vislist":[{"vislist":["contour_graph-0","contour_graph-1","contour_graph-2"],"relation":null,"id":"group-0"}],"relation":"repeated","id":"relation-0"},{"vislist":[{"vislist":["contour_graph-3","contour_graph-4","contour_graph-5"],"relation":null,"id":"group-1"}],"relation":"repeated","id":"relation-1"},{"vislist":[{"vislist":["line_chart-6","line_chart-7"],"relation":null,"id":"group-2"}],"relation":"repeated","id":"relation-2"}]},"2345_1":{"comp":[["comb","comb",["repeated"]],["glyph_based","scatterplot",["nested"]]],"visType":["comb","glyph_based","scatterplot"],"compType":["repeated","nested"],"compressed_tree":[{"composite_pattern":"repeated","visualization_type":[[{"composite_pattern":"nested","visualization_type":[["glyph_based"],["scatterplot"]]}]]}],"coOccurrence":[["glyph_based","scatterplot",["coOccurrence"]]],"year":2012,"conference":["VAST"],"authors":["Ian Bowman","Shantanu H. Joshi","Vaughan Greer","John D. Van Horn"],"title":"Feature-similarity visualization of MRI cortical surface data","doi":"10.1109/VAST.2012.6400548","abstract":"We present an analytics-based framework for simultaneous visualization of large surface data collections arising in clinical neuroimaging studies. Termed Informatics Visualization for Neuroimaging (INVIZIAN), this framework allows the visualization of both cortical surfaces characteristics and feature relatedness in unison. It also uses dimension reduction methods to derive new coordinate systems using a Jensen-Shannon divergence metric for positioning cortical surfaces in a metric space such that the proximity in location is proportional to neuroanatomical similarity. Feature data such as thickness and volume are colored on the cortical surfaces and used to display both subject-specific feature values and global trends within the population. Additionally, a query-based framework allows the neuroscience researcher to investigate probable correlations between neuroanatomical and subject patient attribute values such as age and diagnosis.","keywords":"","caption":"Figure 1: Visualization of cortical thickness in INVIZIAN\u2019s Feature-Similar Display. (Left) Quintile-based colormap legend representing 0 to 5mm thickness values. (Middle) The observed feature trend is an increase in thickness from left to right. (Right) Each brain is annotated by a glyph according to diagnosis, red representing AD (Alzheimer\u2019s Disease) and blue representing NC (Normal Control). The clustered groupings of AD and NC subjects on the left and right respectively indicate that cortical thickness is a strong predictor of Alzheimer\u2019s disease.","img_size":{"width":2139,"height":603},"subfigures":[{"x":4.6159977506062315,"y":7.373565513753181,"width":2125.308682713326,"height":589.3677725010551,"type":"interface","id":"interface-0"}],"visualizations":[{"x":235.43714821763604,"y":17.23639774859288,"width":957.8011257035648,"height":571.202626641651,"type":"glyph_based","id":"glyph_based-0"},{"x":1201.2645403377112,"y":15.898686679174489,"width":933.0192689509136,"height":580.5666041275798,"type":"glyph_based","id":"glyph_based-1"},{"x":5.350844277673546,"y":6.534709193245789,"width":1185.2120075046903,"height":583.2420262664165,"type":"heatmap","id":"heatmap-2"},{"x":1195.9136960600376,"y":6.534709193245789,"width":938.3701132285872,"height":591.2682926829268,"type":"heatmap","id":"heatmap-3"},{"x":235.43714821763604,"y":13.22326454033771,"width":953.7879924953096,"height":577.891181988743,"type":"scatterplot","id":"scatterplot-4"},{"x":1202.6022514071294,"y":6.534709193245789,"width":925.6960600375236,"height":589.9305816135085,"type":"scatterplot","id":"scatterplot-5"}],"relations":[{"vislist":[{"vislist":[{"vislist":[{"vislist":["glyph_based-0"],"relation":null,"id":"group-1"},{"vislist":["scatterplot-4"],"relation":null,"id":"group-2"}],"relation":"nested","id":"relation-0"},{"vislist":[{"vislist":["glyph_based-1"],"relation":null,"id":"group-3"},{"vislist":["scatterplot-5"],"relation":null,"id":"group-4"}],"relation":"nested","id":"relation-1"}],"relation":null,"id":"group-5"}],"relation":"repeated","id":"relation-2"}]},"2347_0":{"comp":[["line_chart","line_chart",["repeated"]],["graph","map",["coordinated"]]],"visType":["line_chart","graph","map"],"compType":["repeated","coordinated"],"compressed_tree":[{"composite_pattern":"repeated","visualization_type":[["line_chart"]]},{"composite_pattern":"coordinated","visualization_type":[["graph"],["map"]]}],"coOccurrence":[["line_chart","graph",["coOccurrence"]],["line_chart","map",["coOccurrence"]],["graph","map",["coOccurrence"]]],"year":2012,"conference":["VAST"],"authors":["Roger Beecham","Jo Wood","Audrey Bowerman"],"title":"A visual analytics approach to understanding cycling behaviour","doi":"10.1109/VAST.2012.6400550","abstract":"Existing research into cycling behaviours has either relied on detailed ethnographic studies or larger public attitude surveys [1] [9]. Instead, following recent contributions from information visualization [13] and data mining [5] [7], this design study uses visual analytics techniques to identify, describe and explain cycling behaviours within a large and attribute rich transactional dataset. Using data from London\'s bike share scheme&lt;sup&gt;1&lt;/sup&gt;, customer level classifications will be created, which consider the regularity of scheme use, journey length and travel times. Monitoring customer usage over time, user classifications will attend to the dynamics of cycling behaviour, asking substantive questions about how behaviours change under varying conditions. The 3-year PhD project will contribute to academic and strategic discussions around sustainable travel policy. A programme of research is outlined, along with an early visual analytics prototype for rapidly querying customer journeys.","keywords":"","caption":"Figure 1: An early visual analytics prototype, which links customer segments (top left), with a spatial (centre) and temporal (bottom) view.","img_size":{"width":967,"height":573},"subfigures":[{"x":4.871921619775173,"y":3.2507401968417216,"width":959.6948544336313,"height":562.8396179970667,"type":"interface","id":"interface-0"}],"visualizations":[{"x":8.024789748029285,"y":154.1106486777207,"width":131.26178243024276,"height":78.82138187559602,"type":"bar_chart","id":"bar_chart-1"},{"x":151.9946878737164,"y":14.411516661143727,"width":805.4539151561127,"height":362.4847220731751,"type":"graph","id":"graph-4"},{"x":143.49125513008877,"y":387.887310875288,"width":813.0782884281624,"height":171.6990654860051,"type":"line_chart","id":"line_chart-0"},{"x":147.75600231059786,"y":8.497184910832278,"width":812.2253786068586,"height":368.34227894360197,"type":"map","id":"map-3"},{"x":8.873861965386855,"y":13.862896311887472,"width":131.2695456710196,"height":136.67991082423842,"type":"matrix","id":"matrix-2"}],"relations":[{"vislist":[{"vislist":["line_chart-0"],"relation":null,"id":"group-0"}],"relation":"repeated","id":"relation-0"},{"vislist":[{"vislist":["graph-4"],"relation":null,"id":"group-1"},{"vislist":["map-3"],"relation":null,"id":"group-2"}],"relation":"coordinated","id":"relation-1"}]},"2348_1":{"comp":[["stripe_graph","stripe_graph",["repeated"]]],"visType":["stripe_graph"],"compType":["repeated"],"compressed_tree":[{"composite_pattern":"repeated","visualization_type":[["stripe_graph"]]}],"coOccurrence":[["stripe_graph","stripe_graph",["coOccurrence"]]],"year":2012,"conference":["VAST"],"authors":["Marco Angelini","Nicola Ferro","Guido Granato","Giuseppe Santucci","Gianmaria Silvello"],"title":"Information retrieval failure analysis: Visual analytics as a support for interactive \\"what-if\\" investigation","doi":"10.1109/VAST.2012.6400551","abstract":"This poster provides an analytical model for examining performances of IR systems, based on the discounted cumulative gain family of metrics, and visualization for interacting and exploring the performances of the system under examination. Moreover, we propose machine learning approach to learn the ranking model of the examined system in order to be able to conduct a \u201cwhat-if\u201d analysis and visually explore what can happen if you adopt a given solution before having to actually implement it.","keywords":"","caption":"Figure 2: The Visual Analytics prototype.","img_size":{"width":915,"height":588},"subfigures":[{"x":6.215413301746731,"y":3.3491519811364716,"width":903.8209368137192,"height":580.6759153087452,"type":"interface","id":"interface-0"}],"visualizations":[{"x":182.4244130005549,"y":88.5578856702517,"width":722.0606240583146,"height":472.244944455239,"type":"line_chart","id":"line_chart-1"},{"x":7.667927747664449,"y":90.92187862296956,"width":145.03815480719183,"height":463.4800693527152,"type":"stripe_graph","id":"stripe_graph-0"}],"relations":[{"vislist":[{"vislist":["stripe_graph-0"],"relation":null,"id":"group-0"}],"relation":"repeated","id":"relation-0"}]},"1798_0":{"comp":[["scatterplot","scatterplot",["repeated"]]],"visType":["scatterplot"],"compType":["repeated"],"compressed_tree":[{"composite_pattern":"repeated","visualization_type":[["scatterplot"]]}],"coOccurrence":[["scatterplot","scatterplot",["coOccurrence"]]],"year":2009,"conference":["InfoVis"],"authors":["Katerina Vrotsou","Jimmy Johansson","Matthew D. Cooper"],"title":"ActiviTree: Interactive Visual Exploration of Sequences in Event-Based Data Using Graph Similarity","doi":"10.1109/TVCG.2009.117","abstract":"The identification of significant sequences in large and complex event-based temporal data is a challenging problem with applications in many areas of today\'s information intensive society. Pure visual representations can be used for the analysis, but are constrained to small data sets. Algorithmic search mechanisms used for larger data sets become expensive as the data size increases and typically focus on frequency of occurrence to reduce the computational complexity, often overlooking important infrequent sequences and outliers. In this paper we introduce an interactive visual data mining approach based on an adaptation of techniques developed for Web searching, combined with an intuitive visual interface, to facilitate user-centred exploration of the data and identification of sequences significant to that user. The search algorithm used in the exploration executes in negligible time, even for large data, and so no pre-processing of the selected data is required, making this a completely interactive experience for the user. Our particular application area is social science diary data but the technique is applicable across many other disciplines.","keywords":"Interactive visual exploration, event-based data, sequence identification, graph similarity, node similarity","caption":"Fig. 1. The two linked views which are the core of the application: (a) \u2018ActiviTree\u2019 visual interface. In the middle the currently explored query sequence (556 \u2192 900: travel by car \u2192 work ) is drawn. The activities connecting into the query sequence are drawn as connecting nodes in the bottom of the interface, while the activities connecting out of the query are drawn as nodes in the top of the interface. All nodes are ordered by signi\ufb01cance score from left to right. Each node has a label showing the activity code describing it and its frequency of occurrence. Frequency of occurrence is also mapped to the opacity of the edges. (b) Linked view showing the currently explored query sequence (556 \u2192 900: travel by car \u2192 work ) in the context of the individuals\u2019 daily lives. In this representation the individuals\u2019 are drawn, ordered by sex and age, on the x-axis while the time is represented on the y-axis going upward. The representation reveals the daily activity sequences of each individual including the distribution, time of occurrence, and duration of the query sequence across the population.","img_size":{"width":2122,"height":942},"subfigures":[{"x":2.8182580570402003,"y":5.961744845125257,"width":871.6824003907468,"height":894.9559406325765,"type":"single","id":"single-0"},{"x":890.4915952621624,"y":8.84107901466586,"width":1197.1676360979116,"height":893.3291040202214,"type":"single","id":"single-1"}],"visualizations":[{"x":904.9022988505747,"y":27.068965517241377,"width":1151.3333333333335,"height":844.5517241379309,"type":"scatterplot","id":"scatterplot-0"},{"x":29.67241379310351,"y":21.655172413793103,"width":837.3333333333331,"height":866.2068965517241,"type":"scatterplot","id":"scatterplot-1"}],"relations":[{"vislist":[{"vislist":["scatterplot-0"],"relation":null,"id":"group-0"}],"relation":"repeated","id":"relation-0"}]},"1804_6":{"comp":[["comb","comb",["repeated"]],["tree","matrix",["stacked"]],["matrix","tree",["stacked"]]],"visType":["comb","tree","matrix"],"compType":["repeated","stacked"],"compressed_tree":[{"composite_pattern":"repeated","visualization_type":[[{"composite_pattern":"stacked","visualization_type":[["tree","matrix"]]}]]}],"coOccurrence":[["tree","matrix",["coOccurrence"]]],"year":2009,"conference":["InfoVis"],"authors":["Jin Chen","Alan M. MacEachren","Donna Peuquet"],"title":"Constructing Overview + Detail Dendrogram-Matrix Views","doi":"10.1109/TVCG.2009.130","abstract":"A dendrogram that visualizes a clustering hierarchy is often integrated with a re-orderable matrix for pattern identification. The method is widely used in many research fields including biology, geography, statistics, and data mining. However, most dendrograms do not scale up well, particularly with respect to problems of graphical and cognitive information overload. This research proposes a strategy that links an overview dendrogram and a detail-view dendrogram, each integrated with a re-orderable matrix. The overview displays only a user-controlled, limited number of nodes that represent the ldquoskeletonrdquo of a hierarchy. The detail view displays the sub-tree represented by a selected meta-node in the overview. The research presented here focuses on constructing a concise overview dendrogram and its coordination with a detail view. The proposed method has the following benefits: dramatic alleviation of information overload, enhanced scalability and data abstraction quality on the dendrogram, and the support of data exploration at arbitrary levels of detail. The contribution of the paper includes a new metric to measure the ldquoimportancerdquo of nodes in a dendrogram; the method to construct the concise overview dendrogram from the dynamically-identified, important nodes; and measure for evaluating the data abstraction quality for dendrograms. We evaluate and compare the proposed method to some related existing methods, and demonstrating how the proposed method can help users find interesting patterns through a case study on county-level U.S. cervical cancer mortality and demographic data.","keywords":"Dendrogram, reorderable matrix, compound graphs, data abstraction quality metrics, hierarchical clusters","caption":"Figure 9. The dendrogram-matrix views display the U.S. cervical cancer and demographic data. The overview summarizes the data in a finer level of detail, in 105 nodes. The detail view displays over 400 data items, and highlights 188 counties belonged to the 8 selected clusters in the overview. The 188 counties were previously represented as the 4 clusters in the overview shown in Figure 8.","img_size":{"width":1962,"height":852},"subfigures":[{"x":5.9716258147808094,"y":3.2321601371736737,"width":1951.1298419203752,"height":844.4629074472571,"type":"single","id":"single-0"}],"visualizations":[{"x":71.93457943925233,"y":406.09345794392516,"width":1881.8317757009347,"height":124.7476635514019,"type":"matrix","id":"matrix-0"},{"x":77.24299065420558,"y":663.5514018691588,"width":1873.8691588785043,"height":183.1401869158877,"type":"matrix","id":"matrix-1"},{"x":66.62616822429902,"y":47.775700934579426,"width":1887.140186915888,"height":358.3177570093457,"type":"tree","id":"tree-2"},{"x":77.24299065420558,"y":552.0747663551401,"width":1873.8691588785043,"height":127.40186915887851,"type":"tree","id":"tree-3"}],"relations":[{"vislist":[{"vislist":[{"vislist":[{"vislist":["tree-2","matrix-0"],"relation":null,"id":"group-0"}],"relation":"stacked","id":"relation-0"},{"vislist":[{"vislist":["tree-3","matrix-1"],"relation":null,"id":"group-1"}],"relation":"stacked","id":"relation-1"}],"relation":null,"id":"group-2"}],"relation":"repeated","id":"relation-2"}]},"1809_0":{"comp":[["comb","comb",["repeated"]],["bar_chart","parallel_coordinate",["coordinated"]]],"visType":["comb","bar_chart","parallel_coordinate"],"compType":["repeated","coordinated"],"compressed_tree":[{"composite_pattern":"repeated","visualization_type":[[{"composite_pattern":"coordinated","visualization_type":[["bar_chart"],["parallel_coordinate"]]}]]}],"coOccurrence":[["bar_chart","parallel_coordinate",["coOccurrence"]]],"year":2009,"conference":["InfoVis"],"authors":["Bo Hyoung Kim","Bongshin Lee","Susan Knoblach","Eric P. Hoffman","Jinwook Seo"],"title":"GeneShelf: A Web-based Visual Interface for Large Gene Expression Time-Series Data Repositories","doi":"10.1109/TVCG.2009.146","abstract":"A widespread use of high-throughput gene expression analysis techniques enabled the biomedical research community to share a huge body of gene expression datasets in many public databases on the web. However, current gene expression data repositories provide static representations of the data and support limited interactions. This hinders biologists from effectively exploring shared gene expression datasets. Responding to the growing need for better interfaces to improve the utility of the public datasets, we have designed and developed a new web-based visual interface entitled GeneShelf (http://bioinformatics.cnmcresearch.org/GeneShelf). It builds upon a zoomable grid display to represent two categorical dimensions. It also incorporates an augmented timeline with expandable time points that better shows multiple data values for the focused time point by embedding bar charts. We applied GeneShelf to one of the largest microarray datasets generated to study the progression and recovery process of injuries at the spinal cord of mice and rats. We present a case study and a preliminary qualitative user study with biologists to show the utility and usability of GeneShelf.","keywords":"bioinformatics visualization, augmented timeline, animation, zoomable grid, gene expression profiling","caption":"Fig. 1. GeneShelf (available at http://bioinformatics.cnmcresearch.org/GeneShelf) showing a relevant genetic pathway at the injury site (T9), 7 days after a mild spinal cord injury at a vertebral level T9. The gene \x93sc4mol\x94 is highlighted in red in all views. \x93sc4mol\x94 is the most active gene for moderate injury at T9, but it is defeated by \x93hmgcs1\x94 in all other conditions. GeneShelf consists of four visualization components: top 10 pathway list view (A), pathway view (B), gene list view (C), and nTimeLines grid view (D). Top 10 pathway list view (A) shows the top 10 pathway names. The current pathway is shown in the pathway view (B) at the top center and the gene names in the pathway are shown in the gene list view (C) at the top right. The horizontal axis of the nTimeLines grid view (D) is for the severity of spinal cord injuries induced (sham, mild, moderate, and severe). The vertical axis is for the sampling location relative to the injury site (T8: above, T9: at, and T10: below). The brown vertical line in the grid block for mild injury at T9 indicates the condition under which the top 10 pathways are selected.","img_size":{"width":2166,"height":1365},"subfigures":[{"x":12.31443199312939,"y":1.845231057340429,"width":2145.8871361908195,"height":1356.79465532914,"type":"single","id":"single-0"}],"visualizations":[{"x":176.59683794466395,"y":650.1284584980235,"width":175.34584980237162,"height":215.81027667984188,"type":"bar_chart","id":"bar_chart-0"},{"x":691.8438735177865,"y":655.5237154150199,"width":167.25296442687724,"height":205.01976284584973,"type":"bar_chart","id":"bar_chart-1"},{"x":694.5415019762845,"y":901.0079051383399,"width":164.55533596837924,"height":194.22924901185763,"type":"bar_chart","id":"bar_chart-2"},{"x":686.4486166007903,"y":1116.8181818181818,"width":180.7411067193677,"height":205.01976284584973,"type":"bar_chart","id":"bar_chart-3"},{"x":173.89920948616594,"y":1127.6086956521738,"width":175.3458498023715,"height":199.62450592885372,"type":"bar_chart","id":"bar_chart-4"},{"x":176.59683794466395,"y":898.3102766798416,"width":178.0434782608696,"height":191.53162055335977,"type":"bar_chart","id":"bar_chart-5"},{"x":1198.9980237154148,"y":898.3102766798416,"width":175.3458498023715,"height":196.92687747035572,"type":"bar_chart","id":"bar_chart-6"},{"x":1708.8498023715408,"y":663.6166007905139,"width":178.04347826086996,"height":207.7173913043479,"type":"bar_chart","id":"bar_chart-7"},{"x":1708.8498023715408,"y":895.6126482213438,"width":183.43873517786596,"height":199.62450592885372,"type":"bar_chart","id":"bar_chart-8"},{"x":1708.8498023715408,"y":1119.5158102766798,"width":178.04347826086996,"height":205.01976284584973,"type":"bar_chart","id":"bar_chart-9"},{"x":735.0059288537545,"y":272.4604743083003,"width":602.5096072604119,"height":322.2997320939443,"type":"flow_diagram","id":"flow_diagram-10"},{"x":103.53368455794764,"y":652.8260869565211,"width":469.5961838067281,"height":221.205533596838,"type":"parallel_coordinate","id":"parallel_coordinate-11"},{"x":103.1415310628718,"y":901.0079051383393,"width":467.0917697514465,"height":194.2292490118575,"type":"parallel_coordinate","id":"parallel_coordinate-12"},{"x":106.12693800207344,"y":1127.6086956521729,"width":464.5385941565649,"height":205.0197628458496,"type":"parallel_coordinate","id":"parallel_coordinate-13"},{"x":1635.220365753359,"y":660.9189723320156,"width":464.8713180038167,"height":213.1126482213439,"type":"parallel_coordinate","id":"parallel_coordinate-17"},{"x":1641.3760403242052,"y":890.2173913043483,"width":461.11502958646474,"height":213.1126482213438,"type":"parallel_coordinate","id":"parallel_coordinate-18"},{"x":1629.9337155407184,"y":1116.8181818181813,"width":469.9204442740114,"height":215.81027667984162,"type":"parallel_coordinate","id":"parallel_coordinate-19"},{"x":621.6873334156026,"y":898.310276679842,"width":450.42373218326156,"height":202.3221343873517,"type":"parallel_coordinate","id":"parallel_coordinate-20"},{"x":613.1647677559044,"y":650.1284584980236,"width":459.3759781271644,"height":221.205533596838,"type":"parallel_coordinate","id":"parallel_coordinate-21"},{"x":613.3456016169932,"y":1116.8181818181815,"width":452.8990436629661,"height":210.41501976284565,"type":"parallel_coordinate","id":"parallel_coordinate-25"},{"x":1111.697462586747,"y":642.0355731225301,"width":470.2896477046835,"height":229.29841897233234,"type":"parallel_coordinate","id":"parallel_coordinate-26"},{"x":1125.190927902242,"y":890.217391304348,"width":473.3195217692935,"height":213.11264822134376,"type":"parallel_coordinate","id":"parallel_coordinate-27"},{"x":1118.8888792161515,"y":1127.608695652173,"width":453.6178677327131,"height":202.32213438735164,"type":"parallel_coordinate","id":"parallel_coordinate-28"},{"x":38.67623193350863,"y":243.02913419660376,"width":516.7727985483953,"height":257.59136419950784,"type":"table","id":"table-29"},{"x":1602.15260957329,"y":266.30993792460964,"width":497.36754940899,"height":326.57340980061997,"type":"table","id":"table-30"}],"relations":[{"vislist":[{"vislist":[{"vislist":[{"vislist":["bar_chart-0"],"relation":null,"id":"group-12"},{"vislist":["parallel_coordinate-11"],"relation":null,"id":"group-13"}],"relation":"coordinated","id":"relation-11"}],"relation":null,"id":"group-14"}],"relation":"repeated","id":"relation-12"}]},"1816_1":{"comp":[["word_cloud","word_cloud",["repeated"]]],"visType":["word_cloud"],"compType":["repeated"],"compressed_tree":[{"composite_pattern":"repeated","visualization_type":[["word_cloud"]]}],"coOccurrence":[["word_cloud","word_cloud",["coOccurrence"]]],"year":2009,"conference":["InfoVis"],"authors":["Fernanda B. Vi\xe9gas","Martin Wattenberg","Jonathan Feinberg"],"title":"Participatory Visualization with Wordle","doi":"10.1109/TVCG.2009.171","abstract":"We discuss the design and usage of ldquoWordle,rdquo a Web-based tool for visualizing text. Wordle creates tag-cloud-like displays that give careful attention to typography, color, and composition. We describe the algorithms used to balance various aesthetic criteria and create the distinctive Wordle layouts. We then present the results of a study of Wordle usage, based both on spontaneous behaviour observed in the wild, and on a large-scale survey of Wordle users. The results suggest that Wordles have become a kind of medium of expression, and that a ldquoparticipatory culturerdquo has arisen around them.","keywords":"Visualization, text, tag cloud, participatory culture, memory, educational visualization, social data analysis","caption":"Fig 1: Boston Globe\'s Wordle of the Republican and Democratic campaign blogs.","img_size":{"width":923,"height":1087},"subfigures":[{"x":9.347649577379118,"y":12.221913140988095,"width":907.9033049702678,"height":1074.5407337633574,"type":"single","id":"single-0"}],"visualizations":[{"x":20.47155947188592,"y":477.9733368417673,"width":858.9253333141259,"height":157.6607140805284,"type":"others","id":"others-2"},{"x":11.241899698973711,"y":935.818581128814,"width":863.5057242146889,"height":151.24878126964012,"type":"others","id":"others-3"},{"x":20.338422391857534,"y":33.190839694656496,"width":862.9618320610687,"height":608.4987277353689,"type":"word_cloud","id":"word_cloud-0"},{"x":17.572519083969496,"y":647.2213740458016,"width":857.4300254452925,"height":436.88711481376737,"type":"word_cloud","id":"word_cloud-1"}],"relations":[{"vislist":[{"vislist":["word_cloud-0","word_cloud-1"],"relation":null,"id":"group-1"}],"relation":"repeated","id":"relation-0"}]},"1820_2":{"comp":[["bar_chart","bar_chart",["repeated"]]],"visType":["bar_chart"],"compType":["repeated"],"compressed_tree":[{"composite_pattern":"repeated","visualization_type":[["bar_chart"]]}],"coOccurrence":[["bar_chart","bar_chart",["coOccurrence"]]],"year":2009,"conference":["InfoVis"],"authors":["Zhicheng Liu","John T. Stasko","Timothy Sullivan"],"title":"SellTrend: Inter-Attribute Visual Analysis of Temporal Transaction Data","doi":"10.1109/TVCG.2009.180","abstract":"We present a case study of our experience designing SellTrend, a visualization system for analyzing airline travel purchase requests. The relevant transaction data can be characterized as multi-variate temporal and categorical event sequences, and the chief problem addressed is how to help company analysts identify complex combinations of transaction attributes that contribute to failed purchase requests. SellTrend combines a diverse set of techniques ranging from time series visualization to faceted browsing and historical trend analysis in order to help analysts make sense of the data. We believe that the combination of views and interaction capabilities in SellTrend provides an innovative approach to this problem and to other similar types of multivariate, temporally driven transaction data analysis. Initial feedback from company analysts confirms the utility and benefits of the system.","keywords":"investigative analysis, transaction analysis, information visualization, multiple views, time series data, multiple attributes, categorical data","caption":"Fig. 3. The SellTrend System Interface. Speci\ufb01c items and values have been blurred in the image when they disclose proprietary company information.","img_size":{"width":2178,"height":1605},"subfigures":[{"x":0.10015622396979709,"y":9.250856977237525,"width":2174.258955270055,"height":1597.1157021666422,"type":"interface","id":"interface-0"}],"visualizations":[{"x":16.958015267175483,"y":1339.5419847328244,"width":955.648854961832,"height":212.36641221374066,"type":"bar_chart","id":"bar_chart-0"},{"x":968.5229007633587,"y":1380.3816793893131,"width":1196.6030534351144,"height":175.61068702290072,"type":"bar_chart","id":"bar_chart-1"},{"x":335.5076335877862,"y":179.6946564885496,"width":1180.2671755725194,"height":1135.3435114503818,"type":"proportional_area_chart","id":"proportional_area_chart-2"},{"x":1572.950381679389,"y":175.61068702290078,"width":579.9236641221378,"height":1143.5114503816794,"type":"table","id":"table-3"}],"relations":[{"vislist":[{"vislist":["bar_chart-0","bar_chart-1"],"relation":null,"id":"group-0"}],"relation":"repeated","id":"relation-0"}]},"1829_3":{"comp":[["tree","tree",["repeated"]],["graph","graph",["repeated"]]],"visType":["tree","graph"],"compType":["repeated"],"compressed_tree":[{"composite_pattern":"repeated","visualization_type":[["tree"]]},{"composite_pattern":"repeated","visualization_type":[["graph"]]}],"coOccurrence":[["tree","graph",["coOccurrence"]]],"year":2009,"conference":["InfoVis"],"authors":["Jian Zhan","Chaomei Chen","Jiexun Li"],"title":"Visualizing the Intellectual Structure with Paper-Reference Matrices","doi":"10.1109/TVCG.2009.202","abstract":"Visualizing the intellectual structure of scientific domains using co-cited units such as references or authors has become a routine for domain analysis. In previous studies, paper-reference matrices are usually transformed into reference-reference matrices to obtain co-citation relationships, which are then visualized in different representations, typically as node-link networks, to represent the intellectual structures of scientific domains. Such network visualizations sometimes contain tightly knit components, which make visual analysis of the intellectual structure a challenging task. In this study, we propose a new approach to reveal co-citation relationships. Instead of using a reference-reference matrix, we directly use the original paper-reference matrix as the information source, and transform the paper-reference matrix into an FP-tree and visualize it in a Java-based prototype system. We demonstrate the usefulness of our approach through visual analyses of the intellectual structure of two domains: information visualization and Sloan Digital Sky Survey (SDSS). The results show that our visualization not only retains the major information of co-citation relationships, but also reveals more detailed sub-structures of tightly knit clusters than a conventional node-link network visualization.","keywords":"Intellectual Structure, Paper-reference Matrix, FP-tree, Co-citation","caption":"Fig. 4. The tight-knit co-citation clusters in SDSS intellectual structure shown in area A and B, and the corresponding FP-tree shown in area C. The FP-tree visualization is turned 90 degree counter clockwise for best fitting with the page layout. The two major subtree led by 280- Gunn(1998) is enlarged in area D on the left.","img_size":{"width":2178,"height":2566},"subfigures":[{"x":55.408707258148574,"y":9.13541098191846,"width":2104.008590008302,"height":2553.3873898257375,"type":"interface","id":"interface-0"}],"visualizations":[{"x":1301.2010178117048,"y":6.825775148432679,"width":848.8040712468191,"height":665.9847328244274,"type":"graph","id":"graph-0"},{"x":1484.020356234097,"y":665.9847328244274,"width":639.8676844783713,"height":476.6361323155217,"type":"graph","id":"graph-1"},{"x":60.64122137404593,"y":6.825775148432679,"width":881.4503816793895,"height":2552.3484497031345,"type":"tree","id":"tree-2"},{"x":942.0916030534354,"y":6.825775148432679,"width":1142.6208651399488,"height":2552.3484497031345,"type":"tree","id":"tree-3"}],"relations":[{"vislist":[{"vislist":["tree-2","tree-3"],"relation":null,"id":"group-0"}],"relation":"repeated","id":"relation-0"},{"vislist":[{"vislist":["graph-0","graph-1"],"relation":null,"id":"group-1"}],"relation":"repeated","id":"relation-1"}]},"1832_2":{"comp":[["comb","comb",["repeated"]],["graph","map",["coordinated"]]],"visType":["comb","graph","map"],"compType":["repeated","coordinated"],"compressed_tree":[{"composite_pattern":"repeated","visualization_type":[[{"composite_pattern":"coordinated","visualization_type":[["graph"],["map"]]}]]}],"coOccurrence":[["graph","map",["coOccurrence"]]],"year":2009,"conference":["VAST"],"authors":["Gennady L. Andrienko","Natalia V. Andrienko","Salvatore Rinzivillo","Mirco Nanni","Dino Pedreschi","Fosca Giannotti"],"title":"Interactive visual clustering of large collections of trajectories","doi":"10.1109/VAST.2009.5332584","abstract":"One of the most common operations in exploration and analysis of various kinds of data is clustering, i.e. discovery and interpretation of groups of objects having similar properties and/or behaviors. In clustering, objects are often treated as points in multi-dimensional space of properties. However, structurally complex objects, such as trajectories of moving entities and other kinds of spatio-temporal data, cannot be adequately represented in this manner. Such data require sophisticated and computationally intensive clustering algorithms, which are very hard to scale effectively to large datasets not fitting in the computer main memory. We propose an approach to extracting meaningful clusters from large databases by combining clustering and classification, which are driven by a human analyst through an interactive visual interface.","keywords":"Spatio-temporal data, movement data, trajectories, clustering, classification, scalable visualization, geovisualization","caption":"Figure 3. A fragment of the cluster overview panel.","img_size":{"width":1014,"height":447},"subfigures":[{"x":4.742171964312827,"y":3.3222256467570968,"width":1005.0702518204241,"height":439.24673635836587,"type":"interface","id":"interface-0"}],"visualizations":[{"x":13.350467289719575,"y":116.97195863278112,"width":324.45794392523374,"height":323.06542056074767,"type":"map","id":"map-0"},{"x":340.5934579439251,"y":114.18691190380915,"width":323.06542056074755,"height":327.2429906542056,"type":"map","id":"map-1"},{"x":665.0514018691589,"y":115.57943526829514,"width":327.24299065420564,"height":324.45794392523374,"type":"map","id":"map-2"},{"x":13.510753632370232,"y":118.98118855429398,"width":321.44147505138505,"height":316.1903104054762,"type":"graph","id":"graph-3"},{"x":663.659329054669,"y":114.573221609427,"width":329.13615086873756,"height":326.9311428733077,"type":"graph","id":"graph-4"},{"x":337.38941346573415,"y":113.92900671732384,"width":329.60358610778144,"height":326.9363069387824,"type":"graph","id":"graph-5"}],"relations":[{"vislist":[{"vislist":[{"vislist":[{"vislist":["graph-3"],"relation":null,"id":"group-7"},{"vislist":["map-0"],"relation":null,"id":"group-8"}],"relation":"coordinated","id":"relation-4"},{"vislist":[{"vislist":["graph-4"],"relation":null,"id":"group-9"},{"vislist":["map-2"],"relation":null,"id":"group-10"}],"relation":"coordinated","id":"relation-5"},{"vislist":[{"vislist":["graph-5"],"relation":null,"id":"group-11"},{"vislist":["map-1"],"relation":null,"id":"group-12"}],"relation":"coordinated","id":"relation-6"}],"relation":null,"id":"group-13"}],"relation":"repeated","id":"relation-7"}]},"1844_1":{"comp":[["bar_chart","bar_chart",["repeated"]],["heatmap","heatmap",["repeated"]]],"visType":["bar_chart","heatmap"],"compType":["repeated"],"compressed_tree":[{"composite_pattern":"repeated","visualization_type":[["bar_chart"]]},{"composite_pattern":"repeated","visualization_type":[["heatmap"]]}],"coOccurrence":[["bar_chart","heatmap",["coOccurrence"]]],"year":2009,"conference":["VAST"],"authors":["Stina S. Bridgeman"],"title":"Poster: Icexplorer: Studying Great Lakes Ice cover","doi":"10.1109/VAST.2009.5333082","abstract":"IceXplorer is a tool for analyzing variations in ice cover on Lake Erie. It enhances the data and pre-packaged analysis currently available in the great lakes ice atlas and serves as an example of a small, focused application where simple but carefully-chosen visualizations, interaction techniques, and automated data analysis are combined to create an effective tool for advancing scientific research.","keywords":"","caption":"Figure 1: The IceXplorer user interface, showing a central basin thaw event March 9\u201316, 1990.","img_size":{"width":1903,"height":831},"subfigures":[{"x":0.6124972225257189,"y":0.256130644780383,"width":1902.8158297269827,"height":825.2880810706267,"type":"interface","id":"interface-0"}],"visualizations":[{"x":703.0458015267176,"y":270.6564885496183,"width":243.16793893129775,"height":228.36641221374043,"type":"bar_chart","id":"bar_chart-0"},{"x":707.2748091603054,"y":556.114503816794,"width":241.05343511450386,"height":247.3969465648854,"type":"bar_chart","id":"bar_chart-1"},{"x":1646.1145038167938,"y":579.3740458015267,"width":226.25190839694642,"height":222.02290076335876,"type":"bar_chart","id":"bar_chart-2"},{"x":26.404580152671816,"y":249.51145038167937,"width":674.5267175572519,"height":249.51145038167937,"type":"heatmap","id":"heatmap-3"},{"x":26.404580152671816,"y":545.5419847328244,"width":676.6412213740458,"height":257.9694656488549,"type":"heatmap","id":"heatmap-4"},{"x":963.1297709923665,"y":545.5419847328244,"width":678.7557251908395,"height":255.854961832061,"type":"heatmap","id":"heatmap-5"},{"x":13.717557251908445,"y":61.3206106870229,"width":1873.4503816793892,"height":154.3587786259542,"type":"line_chart","id":"line_chart-6"}],"relations":[{"vislist":[{"vislist":["bar_chart-0","bar_chart-1","bar_chart-2"],"relation":null,"id":"group-0"}],"relation":"repeated","id":"relation-0"},{"vislist":[{"vislist":["heatmap-3","heatmap-4","heatmap-5"],"relation":null,"id":"group-1"}],"relation":"repeated","id":"relation-1"}]},"1845_1":{"comp":[["bar_chart","bar_chart",["repeated"]],["scatterplot","scatterplot",["repeated"]]],"visType":["bar_chart","scatterplot"],"compType":["repeated"],"compressed_tree":[{"composite_pattern":"repeated","visualization_type":[["bar_chart"]]},{"composite_pattern":"repeated","visualization_type":[["scatterplot"]]}],"coOccurrence":[["bar_chart","scatterplot",["coOccurrence"]]],"year":2009,"conference":["VAST"],"authors":["Yiwen Sun","Jason Leigh","Andrew E. Johnson","Dennis Chau"],"title":"Articulate: a conversational interface for visual analytics","doi":"10.1109/VAST.2009.5333099","abstract":"While many visualization tools exist that offer sophisticated functions for charting complex data, they still expect users to possess a high degree of expertise in wielding the tools to create an effective visualization. This poster presents Articulate, an attempt at a semi-automated visual analytic model that is guided by a conversational user interface. The goal is to relieve the user of the physical burden of having to directly craft a visualization through the manipulation of a complex user-interface, by instead being able to verbally articulate what the user wants to see, and then using natural language processing and heuristics to semi-automatically create a suitable visualization.","keywords":"","caption":"Figure 3: Relationship command represented by scatter plot matrix","img_size":{"width":1014,"height":560},"subfigures":[{"x":123.40170484745846,"y":16.718613097357622,"width":759.785318043156,"height":538.9111705401291,"type":"interface","id":"interface-0"}],"visualizations":[{"x":128.6793893129771,"y":54.14758269720103,"width":239.38931297709922,"height":141.06870229007637,"type":"bar_chart","id":"bar_chart-0"},{"x":134.3791348600509,"y":219.440203562341,"width":236.53944020356238,"height":136.793893129771,"type":"bar_chart","id":"bar_chart-1"},{"x":151.47837150127225,"y":383.30788804071256,"width":216.59033078880407,"height":145.34351145038167,"type":"bar_chart","id":"bar_chart-2"},{"x":395.14249363867685,"y":387.5826972010179,"width":225.13994910941472,"height":136.79389312977108,"type":"bar_chart","id":"bar_chart-3"},{"x":380.8931297709924,"y":216.59033078880412,"width":239.38931297709928,"height":145.34351145038167,"type":"bar_chart","id":"bar_chart-4"},{"x":382.31806615776077,"y":52.72264631043258,"width":239.38931297709928,"height":141.06870229007637,"type":"bar_chart","id":"bar_chart-5"},{"x":628.8320610687023,"y":54.14758269720103,"width":237.96437659033072,"height":156.74300254452928,"type":"scatterplot","id":"scatterplot-6"},{"x":627.4071246819339,"y":218.01526717557255,"width":239.38931297709917,"height":155.31806615776088,"type":"scatterplot","id":"scatterplot-7"},{"x":647.3562340966921,"y":383.30788804071256,"width":219.4402035623409,"height":158.16793893129767,"type":"scatterplot","id":"scatterplot-8"},{"x":125.82951653944019,"y":42.74809160305344,"width":752.3664122137403,"height":510.12722646310436,"type":"small_multiple","id":"small_multiple-9"}],"relations":[{"vislist":[{"vislist":["bar_chart-0","bar_chart-1","bar_chart-2","bar_chart-3","bar_chart-5","bar_chart-4"],"relation":null,"id":"group-0"}],"relation":"repeated","id":"relation-0"},{"vislist":[{"vislist":["scatterplot-6","scatterplot-7","scatterplot-8"],"relation":null,"id":"group-1"}],"relation":"repeated","id":"relation-1"}]},"1864_2":{"comp":[["matrix","matrix",["repeated"]]],"visType":["matrix"],"compType":["repeated"],"compressed_tree":[{"composite_pattern":"repeated","visualization_type":[["matrix"]]}],"coOccurrence":[["matrix","matrix",["coOccurrence"]]],"year":2009,"conference":["VAST"],"authors":["Youn ah Kang","Carsten G\xf6rg","John T. Stasko"],"title":"Evaluating visual analytics systems for investigative analysis: Deriving design principles from a case study","doi":"10.1109/VAST.2009.5333878","abstract":"Despite the growing number of systems providing visual analytic support for investigative analysis, few empirical studies of the potential benefits of such systems have been conducted, particularly controlled, comparative evaluations. Determining how such systems foster insight and sensemaking is important for their continued growth and study, however. Furthermore, studies that identify how people use such systems and why they benefit (or not) can help inform the design of new systems in this area. We conducted an evaluation of the visual analytics system Jigsaw employed in a small investigative sensemaking exercise, and we compared its use to three other more traditional methods of analysis. Sixteen participants performed a simulated intelligence analysis task under one of the four conditions. Experimental results suggest that Jigsaw assisted participants to analyze the data and identify an embedded threat. We describe different analysis strategies used by study participants and how computational support (or the lack thereof) influenced the strategies. We then illustrate several characteristics of the sensemaking process identified in the study and provide design implications for investigative analysis tools based thereon. We conclude with recommendations for metrics and techniques for evaluating other visual analytics investigative analysis tools.","keywords":"","caption":"Figure 2: Overview of the Jigsaw usage patterns (at the top) and an extract from the detailed usage pattern with video for P16 (at the bottom). P9-P12 were in the Entity setting, so they accessed only the Main View and the Document View in Jigsaw. P13-P16 used the full system.","img_size":{"width":2107,"height":819},"subfigures":[{"x":4.12155939481016,"y":7.041534904011527,"width":2101.061680506724,"height":810.6794354117511,"type":"interface","id":"interface-0"}],"visualizations":[{"x":12.144092219020175,"y":3.33230006199628,"width":246.79477240980077,"height":416.68516793979603,"type":"matrix","id":"matrix-0"},{"x":264.1340057636888,"y":4.190922190201733,"width":259.00136541535056,"height":417.79597737311707,"type":"matrix","id":"matrix-1"},{"x":532.6826064413737,"y":3.33230006199628,"width":254.64927128788403,"height":417.94286968649664,"type":"matrix","id":"matrix-2"},{"x":796.67732518481,"y":3.33230006199628,"width":252.22223813396735,"height":419.3580786026201,"type":"matrix","id":"matrix-3"},{"x":1056.9798100996668,"y":3.33230006199628,"width":256.1162597693289,"height":417.55151766329226,"type":"matrix","id":"matrix-4"},{"x":1320.9745288431031,"y":3.33230006199628,"width":256.318047576111,"height":419.25728016684604,"type":"matrix","id":"matrix-5"},{"x":1583.7071364991584,"y":3.33230006199628,"width":255.15312550957515,"height":425.2830292735243,"type":"matrix","id":"matrix-6"},{"x":1845.1975280309343,"y":3.33230006199628,"width":258.4701719070694,"height":433.81659388646284,"type":"matrix","id":"matrix-7"},{"x":5.257641921397379,"y":3.33230006199628,"width":2098.4100580166064,"height":436.44541484716166,"type":"small_multiple","id":"small_multiple-8"}],"relations":[{"vislist":[{"vislist":["matrix-0","matrix-1","matrix-2","matrix-3","matrix-4","matrix-5","matrix-6","matrix-7"],"relation":null,"id":"group-0"}],"relation":"repeated","id":"relation-0"}]},"1873_0":{"comp":[["bar_chart","bar_chart",["repeated"]]],"visType":["bar_chart"],"compType":["repeated"],"compressed_tree":[{"composite_pattern":"repeated","visualization_type":[["bar_chart"]]}],"coOccurrence":[["bar_chart","bar_chart",["coOccurrence"]]],"year":2009,"conference":["VAST"],"authors":["Chad Jones","Michael Ogawa","James Shearer","Anna Tikhonova","Kwan-Liu Ma"],"title":"VIDI surveillance - embassy monitoring and oversight system","doi":"10.1109/VAST.2009.5333950","abstract":"We hypothesized that potential spies would try to use other employees\' terminals in order to not draw attention to themselves. We define one type of suspicious activity as IP use on a terminal when the owner is inside the classified area. We created a timeline visualization of IP usage, overlaid with classified area entrances and exits. The vertical axis divides the timelines into 31 rows, one for each day of the month. The horizontal axis represents the time of day from early morning to late evening. A single employee\'s entire month is viewed all at once using this visualization. The employee being viewed can be changed using the arrow keys. Every IP event is represented by a vertical bar positioned at the exact time of its appearance. We color the IP events by port number, which is either intranet, HTTP, tomcat, or email, and size the bar based on the outgoing data size. Whenever an employee enters the classified area, a semi-transparent yellow region is drawn until that user exits the classified area. In rare cases when the user double enters, the region is twice as opaque, and in the other rare case where a user leaves the exits without entering, a red region is drawn until the next time the employee enters. The legend key and office diagram showing the current selected employee, highlighted in red, can be seen in the top left-hand corner.","keywords":"","caption":"Figure 1: Visualization of Employee 30\u2019s badge and network IP ac- tivity (cropped). Times when package drops occur are manually marked in black. Employee 30 does not have alibis during these times. Created with Processing [3].","img_size":{"width":1044,"height":1248},"subfigures":[{"x":7.051608181857722,"y":3.0801737900117336,"width":1035.401343770363,"height":1244.5915808351695,"type":"single","id":"single-0"}],"visualizations":[{"x":37.72519083969462,"y":41.282442748091604,"width":1000.3053435114502,"height":130.19847328244276,"type":"bar_chart","id":"bar_chart-0"},{"x":40.90076335877859,"y":234.99236641221378,"width":999.7794520016095,"height":196.8854961832061,"type":"bar_chart","id":"bar_chart-1"},{"x":31.374045801526673,"y":508.09160305343516,"width":1009.3061695588614,"height":203.23664122137401,"type":"bar_chart","id":"bar_chart-2"},{"x":3.3197846396118402,"y":816.1221374045803,"width":1037.3604307207763,"height":174.65648854961827,"type":"bar_chart","id":"bar_chart-3"},{"x":3.3197846396118402,"y":1066.9923664122139,"width":1037.3604307207763,"height":177.6878489481743,"type":"bar_chart","id":"bar_chart-4"}],"relations":[{"vislist":[{"vislist":["bar_chart-0","bar_chart-1","bar_chart-2","bar_chart-3","bar_chart-4"],"relation":null,"id":"group-0"}],"relation":"repeated","id":"relation-0"}]},"1874_2":{"comp":[["graph","graph",["repeated"]]],"visType":["graph"],"compType":["repeated"],"compressed_tree":[{"composite_pattern":"repeated","visualization_type":[["graph"]]}],"coOccurrence":[["graph","graph",["coOccurrence"]]],"year":2009,"conference":["VAST"],"authors":["Hao Zhou","Anna A. Shaverdian","H. V. Jagadish","George Michailidis"],"title":"Multiple step social structure analysis with Cytoscape","doi":"10.1109/VAST.2009.5333961","abstract":"Cytoscape is a popular open source tool for biologists to visualize interaction networks. We find that it offers most of the desired functionality for visual analytics on graph data to guide us in the identification of the underlying social structure. We demonstrate its utility in the identification of the social structure in the VAST 2009 Flitter Mini Challenge.","keywords":"","caption":"Figure 2: Possible Subnetworks.","img_size":{"width":960,"height":663},"subfigures":[{"x":4.037509660382692,"y":0.8898443497682514,"width":956.314719841814,"height":657.5654063740342,"type":"interface","id":"interface-0"}],"visualizations":[{"x":156.93511450381675,"y":48.923664122137396,"width":506.1068702290077,"height":318.84732824427476,"type":"graph","id":"graph-0"},{"x":683.2862595419847,"y":45.549618320610676,"width":254.7404580152672,"height":187.25954198473278,"type":"graph","id":"graph-1"},{"x":678.2251908396945,"y":258.11450381679384,"width":271.61068702290095,"height":153.51908396946567,"type":"graph","id":"graph-2"},{"x":156.93511450381675,"y":384.6412213740457,"width":512.854961832061,"height":207.5038167938931,"type":"graph","id":"graph-3"},{"x":676.5381679389311,"y":445.37404580152656,"width":273.29770992366434,"height":145.0839694656488,"type":"graph","id":"graph-4"},{"x":11.851145038167944,"y":533.0992366412213,"width":134.9618320610687,"height":121.46564885496184,"type":"graph","id":"graph-5"}],"relations":[{"vislist":[{"vislist":["graph-0","graph-1","graph-2","graph-3","graph-4","graph-5"],"relation":null,"id":"group-0"}],"relation":"repeated","id":"relation-0"}]},"1883_1":{"comp":[["graph","graph",["repeated"]],["bar_chart","bar_chart",["repeated"]]],"visType":["graph","bar_chart"],"compType":["repeated"],"compressed_tree":[{"composite_pattern":"repeated","visualization_type":[["graph"]]},{"composite_pattern":"repeated","visualization_type":[["bar_chart"]]}],"coOccurrence":[],"year":2009,"conference":["VAST"],"authors":["Paolo Simonetto","Pierre-Yves Koenig","Faraz Zaidi","Daniel W. Archambault","Fr\xe9d\xe9ric Gilbert","Trung-Tien Phan-Quang","Morgan Mathiaut","Antoine Lambert","Jonathan Dubois","Ronan Sicre","Mathieu Brulin","R\xe9my Vieux","Guy Melan\xe7on"],"title":"Solving the traffic and flitter challenges with tulip","doi":"10.1109/VAST.2009.5334456","abstract":"We present our visualization systems and findings for the badge and network traffic as well as the social network and geospatial challenges of the 2009 VAST contest. The summary starts by presenting an overview of our time series encoding of badge information and network traffic. Our findings suggest that employee 30 may be of interest. In the second part of the paper, we describe our system for finding subgraphs in the social network subject to degree constraints. Subsequently, we present our most likely candidate network which is similar to scenario B.","keywords":"","caption":"Figure 2: Task 2 visualization system. (a) Visual Query Generator interface with the tool bar showing Employee(EMB), Handlers(Hi), Middle- men(BMH), Fearless Leader(FL) nodes and required or optional edges. (b) Histogram view allowing user to choose the range for the number of connections for each role. (c) Our best candidate solution for this task.","img_size":{"width":2046,"height":552},"subfigures":[{"x":-0.4682121446679458,"y":0.9823611416411192,"width":680.5929883704642,"height":544.4452296453431,"type":"interface","id":"interface-0"},{"x":683.7325108633016,"y":14.264606230122517,"width":685.2491966317191,"height":530.1788452254035,"type":"interface","id":"interface-1"},{"x":1371.7260699911226,"y":9.7791021544605,"width":671.1293687227305,"height":527.96975723398,"type":"interface","id":"interface-2"}],"visualizations":[{"x":1117.545171339564,"y":193.48013239114826,"width":108.35514018691582,"height":125.35202492211837,"type":"bar_chart","id":"bar_chart-0"},{"x":1234.398753894081,"y":191.35552179924792,"width":110.4797507788162,"height":131.72585669781927,"type":"bar_chart","id":"bar_chart-1"},{"x":1117.545171339564,"y":340.0782632322698,"width":112.60436137071656,"height":125.35202492211839,"type":"bar_chart","id":"bar_chart-2"},{"x":1238.6479750778817,"y":331.5798208646685,"width":108.35514018691582,"height":127.47663551401875,"type":"bar_chart","id":"bar_chart-3"},{"x":206.08722741433024,"y":244.47078659675572,"width":225.20872274143306,"height":176.34267912772586,"type":"graph","id":"graph-4"},{"x":448.2928348909657,"y":269.9661136995595,"width":218.8348909657321,"height":133.85046728971963,"type":"graph","id":"graph-5"},{"x":894.4610591900312,"y":229.5985124534536,"width":220.9595015576324,"height":206.08722741433021,"type":"graph","id":"graph-6"},{"x":1370.373831775701,"y":3.23582625858775,"width":672.3903419657113,"height":497.1588785046728,"type":"graph","id":"graph-7"}],"relations":[{"vislist":[{"vislist":["graph-4","graph-5"],"relation":null,"id":"group-0"}],"relation":"repeated","id":"relation-0"},{"vislist":[{"vislist":["bar_chart-0","bar_chart-1","bar_chart-2","bar_chart-3"],"relation":null,"id":"group-1"}],"relation":"repeated","id":"relation-1"}]},"1672_1":{"comp":[["graph","graph",["repeated"]],["line_chart","line_chart",["repeated"]]],"visType":["graph","line_chart"],"compType":["repeated"],"compressed_tree":[{"composite_pattern":"repeated","visualization_type":[["graph"]]},{"composite_pattern":"repeated","visualization_type":[["line_chart"]]}],"coOccurrence":[["graph","line_chart",["coOccurrence"]]],"year":2008,"conference":["InfoVis"],"authors":["Aaron Barsky","Tamara Munzner","Jennifer L. Gardy","Robert Kincaid"],"title":"Cerebral: Visualizing Multiple Experimental Conditions on a Graph with Biological Context","doi":"10.1109/TVCG.2008.117","abstract":"Systems biologists use interaction graphs to model the behavior of biological systems at the molecular level. In an iterative process, such biologists observe the reactions of living cells under various experimental conditions, view the results in the context of the interaction graph, and then propose changes to the graph model. These graphs serve as a form of dynamic knowledge representation of the biological system being studied and evolve as new insight is gained from the experimental data. While numerous graph layout and drawing packages are available, these tools did not fully meet the needs of our immunologist collaborators. In this paper, we describe the data information display needs of these immunologists and translate them into design decisions. These decisions led us to create Cerebral, a system that uses a biologically guided graph layout and incorporates experimental data directly into the graph display. Small multiple views of different experimental conditions and a data-driven parallel coordinates view enable correlations between experimental conditions to be analyzed at the same time that the data is viewed in the graph context. This combination of coordinated views allows the biologist to view the data from many different perspectives simultaneously. To illustrate the typical analysis tasks performed, we analyze two datasets using Cerebral. Based on feedback from our collaborators we conclude that Cerebral is a valuable tool for analyzing experimental data in the context of an interaction graph model.","keywords":"Graph layout, systems biology visualization, small multiples, design study","caption":"Fig. 2: The Cerebral display of the TLR4 graph (V=91, E=124) with associated LPS and LPS+LL-37 time series. The small multiples show an overview of all 8 experimental conditions. The most noticeable differences between the LPS and the LPS+LL-37 condition occur at hour 4. By selecting the hour 4 conditions, the main window shows the computed difference between the two conditions.","img_size":{"width":1962,"height":1428},"subfigures":[{"x":5.859286961767847,"y":5.077007141109093,"width":1951.8573705949004,"height":1419.4204063014727,"type":"interface","id":"interface-0"}],"visualizations":[{"x":824.4653465346536,"y":127.24752475247524,"width":1056.3564356435643,"height":813.980198019802,"type":"graph","id":"graph-0"},{"x":365.97029702970303,"y":135.32673267326732,"width":422.13861386138603,"height":866.4950495049505,"type":"graph","id":"graph-1"},{"x":1351.6336633663368,"y":1127.0495049504948,"width":268.6336633663368,"height":109.06930693069307,"type":"line_chart","id":"line_chart-2"},{"x":365.97029702970303,"y":1118.970297029703,"width":939.2079207920791,"height":220.15841584158417,"type":"parallel_coordinate","id":"parallel_coordinate-3"}],"relations":[{"vislist":[{"vislist":["graph-1"],"relation":null,"id":"group-0"}],"relation":"repeated","id":"relation-0"},{"vislist":[{"vislist":["line_chart-2"],"relation":null,"id":"group-1"}],"relation":"repeated","id":"relation-1"}]},"1672_3":{"comp":[["graph","graph",["repeated"]]],"visType":["graph"],"compType":["repeated"],"compressed_tree":[{"composite_pattern":"repeated","visualization_type":[["graph"]]},{"composite_pattern":"repeated","visualization_type":[["graph"]]}],"coOccurrence":[["graph","graph",["coOccurrence"]]],"year":2008,"conference":["InfoVis"],"authors":["Aaron Barsky","Tamara Munzner","Jennifer L. Gardy","Robert Kincaid"],"title":"Cerebral: Visualizing Multiple Experimental Conditions on a Graph with Biological Context","doi":"10.1109/TVCG.2008.117","abstract":"Systems biologists use interaction graphs to model the behavior of biological systems at the molecular level. In an iterative process, such biologists observe the reactions of living cells under various experimental conditions, view the results in the context of the interaction graph, and then propose changes to the graph model. These graphs serve as a form of dynamic knowledge representation of the biological system being studied and evolve as new insight is gained from the experimental data. While numerous graph layout and drawing packages are available, these tools did not fully meet the needs of our immunologist collaborators. In this paper, we describe the data information display needs of these immunologists and translate them into design decisions. These decisions led us to create Cerebral, a system that uses a biologically guided graph layout and incorporates experimental data directly into the graph display. Small multiple views of different experimental conditions and a data-driven parallel coordinates view enable correlations between experimental conditions to be analyzed at the same time that the data is viewed in the graph context. This combination of coordinated views allows the biologist to view the data from many different perspectives simultaneously. To illustrate the typical analysis tasks performed, we analyze two datasets using Cerebral. Based on feedback from our collaborators we conclude that Cerebral is a valuable tool for analyzing experimental data in the context of an interaction graph model.","keywords":"Graph layout, systems biology visualization, small multiples, design study","caption":"Fig. 4: Interactive selection, panning, and zooming shows the expres-sion of cytokines and chemokines across time points in the context of the larger MAPK graph.","img_size":{"width":999,"height":731},"subfigures":[{"x":0.9238958338299356,"y":1.7900154038642047,"width":993.1196943154232,"height":725.808062404205,"type":"interface","id":"interface-0"}],"visualizations":[{"x":212.57991513437057,"y":72.37623762376238,"width":179.9066478076379,"height":96.15700141442717,"type":"graph","id":"graph-0"},{"x":212.57991513437057,"y":176.80480905233378,"width":179.9066478076379,"height":161.29561527581333,"type":"graph","id":"graph-1"},{"x":211.54596888260255,"y":344.30410183875534,"width":179.9066478076379,"height":141.65063649222066,"type":"graph","id":"graph-2"},{"x":411.097595473833,"y":71.34229137199435,"width":583.1456859971713,"height":440.4611032531825,"type":"graph","id":"graph-3"},{"x":755.4016973125883,"y":549.025459688826,"width":230.57001414427168,"height":33.08628005657715,"type":"graph","id":"graph-4"},{"x":210.51202263083448,"y":547.9915134370581,"width":541.7878359264497,"height":133.37906647807634,"type":"parallel_coordinate","id":"parallel_coordinate-5"}],"relations":[{"vislist":[{"vislist":["graph-0","graph-1","graph-2"],"relation":null,"id":"group-0"}],"relation":"repeated","id":"relation-0"},{"vislist":[{"vislist":["graph-4"],"relation":null,"id":"group-1"}],"relation":"repeated","id":"relation-1"}]},"1674_2":{"comp":[["others","others",["repeated"]]],"visType":["others"],"compType":["repeated"],"compressed_tree":[{"composite_pattern":"repeated","visualization_type":[["others"]]}],"coOccurrence":[["others","others",["coOccurrence"]]],"year":2008,"conference":["InfoVis"],"authors":["George G. Robertson","Roland Fernandez","Danyel Fisher","Bongshin Lee","John T. Stasko"],"title":"Effectiveness of Animation in Trend Visualization","doi":"10.1109/TVCG.2008.125","abstract":"Animation has been used to show trends in multi-dimensional data. This technique has recently gained new prominence for presentations, most notably with Gapminder Trendalyzer. In Trendalyzer, animation together with interesting data and an engaging presenter helps the audience understand the results of an analysis of the data. It is less clear whether trend animation is effective for analysis. This paper proposes two alternative trend visualizations that use static depictions of trends: one which shows traces of all trends overlaid simultaneously in one display and a second that uses a small multiples display to show the trend traces side-by-side. The paper evaluates the three visualizations for both analysis and presentation. Results indicate that trend animation can be challenging to use even for presentations; while it is the fastest technique for presentation and participants find it enjoyable and exciting, it does lead to many participant errors. Animation is the least effective form for analysis; both static depictions of trends are significantly faster than animation, and the small multiples display is more accurate.","keywords":"Information visualization, animation, trends, design, experiment","caption":"Fig. 3. Small Multiples Visualization shows trace lines for each country separately.","img_size":{"width":2178,"height":1614},"subfigures":[{"x":54.91526578083798,"y":0.7408358098543844,"width":2102.130620762642,"height":1582.7756441408053,"type":"interface","id":"interface-0"}],"visualizations":[{"x":139.2854729409324,"y":70.76858043907816,"width":1553.2366410163493,"height":1457.0308488392714,"type":"others","id":"others-1"},{"x":133.96266233766244,"y":68.12337662337661,"width":1566.837662337662,"height":1462.0324675324678,"type":"small_multiple","id":"small_multiple-0"}],"relations":[{"vislist":[{"vislist":["others-1"],"relation":null,"id":"group-0"}],"relation":"repeated","id":"relation-0"}]},"1682_13":{"comp":[["bar_chart","bar_chart",["repeated"]]],"visType":["bar_chart"],"compType":["repeated"],"compressed_tree":[{"composite_pattern":"repeated","visualization_type":[["bar_chart"]]}],"coOccurrence":[["bar_chart","bar_chart",["coOccurrence"]]],"year":2008,"conference":["InfoVis"],"authors":["Wolfgang Freiler","Kresimir Matkovic","Helwig Hauser"],"title":"Interactive Visual Analysis of Set-Typed Data","doi":"10.1109/TVCG.2008.144","abstract":"While it is quite typical to deal with attributes of different data types in the visualization of heterogeneous and multivariate datasets, most existing techniques still focus on the most usual data types such as numerical attributes or strings. In this paper we present a new approach to the interactive visual exploration and analysis of data that contains attributes which are of set type. A set-typed attribute of a data item - like one cell in a table - has a list of nGt=0 elements as its value. We present the setpsilaopsilagram as a new visualization approach to represent data of set type and to enable interactive visual exploration and analysis. We also demonstrate how this approach is capable to help in dealing with datasets that have a larger number of dimensions (more than a dozen or more), especially also in the context of categorical data. To illustrate the effectiveness of our approach, we present the interactive visual analysis of a CRM dataset with data from a questionnaire on the education and shopping habits of about 90000 people.","keywords":"Interactive Visual Analysis, Multidimensional Multivariate Data Visualization, Categorical Data Visualization, Interactive Visualization, Focus+Context Visualization, Multiple Coordinated Views","caption":"Fig. 13. A data analysis session based on the ComVis visualization prototype with different visualization techniques employed. Two set\u2019o\u2019grams (on the left) show two set-typed attributes in the data (education and technical devices), a scatterplot (top, middle) shows one categorical dimension (ZIP codes) vs. the set-typed dimension \u201cShops\u201d, the parallel coordinates show six dimensions, including four set-typed dimensions, and two \u201cregular\u201d views (one histogram and one scatterplot on the right). Households with children (brush #1 in the top right histogram) which are also online (brush #2 in the set\u2019o\u2019gram in the lower left) are highlighted.","img_size":{"width":2154,"height":1312},"subfigures":[{"x":6.673818368316452,"y":3.231779211531858,"width":2144.993582165359,"height":1306.9829680515875,"type":"interface","id":"interface-0"}],"visualizations":[{"x":22.624521072796878,"y":153.31800766283524,"width":653.4865900383141,"height":409.6858237547892,"type":"bar_chart","id":"bar_chart-0"},{"x":1440.1877394636015,"y":153.31800766283524,"width":663.5402298850574,"height":407.17241379310343,"type":"bar_chart","id":"bar_chart-1"},{"x":22.624521072796878,"y":598.1915708812261,"width":663.5402298850574,"height":402.1455938697318,"type":"bar_chart","id":"bar_chart-2"},{"x":728.8927203065134,"y":575.5708812260536,"width":701.2413793103447,"height":434.8199233716476,"type":"parallel_coordinate","id":"parallel_coordinate-3"},{"x":736.4329501915709,"y":145.77777777777777,"width":656,"height":412.199233716475,"type":"scatterplot","id":"scatterplot-4"},{"x":1445.2145593869732,"y":600.7049808429118,"width":658.5134099616857,"height":407.17241379310343,"type":"scatterplot","id":"scatterplot-5"},{"x":286.53256704980834,"y":1027.984674329502,"width":1822.2222222222222,"height":208.61302681992336,"type":"table","id":"table-6"}],"relations":[{"vislist":[{"vislist":["bar_chart-0","bar_chart-2"],"relation":null,"id":"group-0"}],"relation":"repeated","id":"relation-0"}]},"1698_2":{"comp":[["line_chart","line_chart",["repeated"]],["matrix","matrix",["repeated"]]],"visType":["line_chart","matrix"],"compType":["repeated"],"compressed_tree":[{"composite_pattern":"repeated","visualization_type":[["line_chart"]]},{"composite_pattern":"repeated","visualization_type":[["matrix"]]}],"coOccurrence":[["line_chart","matrix",["coOccurrence"]]],"year":2008,"conference":["VAST"],"authors":["Tobias Schreck","J\xfcrgen Bernard","Tatiana von Landesberger","J\xf6rn Kohlhammer"],"title":"Visual cluster analysis of trajectory data with interactive Kohonen Maps","doi":"10.1109/VAST.2008.4677350","abstract":"Visual-interactive cluster analysis provides valuable tools for effectively analyzing large and complex data sets. Due to desirable properties and an inherent predisposition for visualization, the Kohonen Feature Map (or self-organizing map, or SOM) algorithm is among the most popular and widely used visual clustering techniques. However, the unsupervised nature of the algorithm may be disadvantageous in certain applications. Depending on initialization and data characteristics, cluster maps (cluster layouts) may emerge that do not comply with user preferences, expectations, or the application context. Considering SOM-based analysis of trajectory data, we propose a comprehensive visual-interactive monitoring and control framework extending the basic SOM algorithm. The framework implements the general Visual Analytics idea to effectively combine automatic data analysis with human expert supervision. It provides simple, yet effective facilities for visually monitoring and interactively controlling the trajectory clustering process at arbitrary levels of detail. The approach allows the user to leverage existing domain knowledge and user preferences, arriving at improved cluster maps. We apply the framework on a trajectory clustering problem, demonstrating its potential in combining both unsupervised (machine) and supervised (human expert) processing, in producing appropriate cluster results.","keywords":"","caption":"Figure 3: Editor-based initialization of a 12 \xd7 9 SOM trajectory grid, using 5 user-defined example trajectories (marked blue) in conjunc- tion with weighted average interpolation. Component distributions (x1 , y1 ) to (x5 , y5 ) are shown in the left panel.","img_size":{"width":960,"height":651},"subfigures":[{"x":6.884384323440044,"y":0.8800332735008427,"width":949.1043168912057,"height":647.0866817723601,"type":"interface","id":"interface-0"}],"visualizations":[{"x":14.82872928176795,"y":211.00552486187843,"width":166.48448910903664,"height":420.0404521496158,"type":"heatmap","id":"heatmap-0"},{"x":10.456896551724128,"y":23.695402298850574,"width":174.59770114942535,"height":173.35057471264366,"type":"line_chart","id":"line_chart-1"},{"x":193.71686746987956,"y":64.48995983935743,"width":752.9638554216865,"height":575.1807228915662,"type":"line_chart","id":"line_chart-2"},{"x":11.67908654348243,"y":212.58758734733698,"width":168.68703516981338,"height":415.22525622694104,"type":"matrix","id":"matrix-6"},{"x":193.46408839779002,"y":63.541436464088385,"width":752.9060773480662,"height":575.4696132596684,"type":"small_multiple","id":"small_multiple-3"},{"x":11.704022988505756,"y":212.01149425287358,"width":167.11494252873564,"height":419.03448275862064,"type":"small_multiple","id":"small_multiple-4"}],"relations":[{"vislist":[{"vislist":["line_chart-2"],"relation":null,"id":"group-0"}],"relation":"repeated","id":"relation-0"},{"vislist":[{"vislist":["matrix-6"],"relation":null,"id":"group-1"}],"relation":"repeated","id":"relation-1"}]},"1702_6":{"comp":[["line_chart","line_chart",["repeated"]]],"visType":["line_chart"],"compType":["repeated"],"compressed_tree":[{"composite_pattern":"repeated","visualization_type":[["line_chart"]]}],"coOccurrence":[["line_chart","line_chart",["coOccurrence"]]],"year":2008,"conference":["VAST"],"authors":["Ross Maciejewski","Stephen Rudolph","Ryan Hafen","Ahmad M. Abusalah","Mohamed Yakout","Mourad Ouzzani","William S. Cleveland","Shaun J. Grannis","Michael Wade","David S. Ebert"],"title":"Understanding syndromic hotspots - a visual analytics approach","doi":"10.1109/VAST.2008.4677354","abstract":"When analyzing syndromic surveillance data, health care officials look for areas with unusually high cases of syndromes. Unfortunately, many outbreaks are difficult to detect because their signal is obscured by the statistical noise. Consequently, many detection algorithms have a high false positive rate. While many false alerts can be easily filtered by trained epidemiologists, others require health officials to drill down into the data, analyzing specific segments of the population and historical trends over time and space. Furthermore, the ability to accurately recognize meaningful patterns in the data becomes more challenging as these data sources increase in volume and complexity. To facilitate more accurate and efficient event detection, we have created a visual analytics tool that provides analysts with linked geo-spatiotemporal and statistical analytic views. We model syndromic hotspots by applying a kernel density estimation on the population sample. When an analyst selects a syndromic hotspot, temporal statistical graphs of the hotspot are created. Similarly, regions in the statistical plots may be selected to generate geospatial features specific to the current time period. Demographic filtering can then be combined to determine if certain populations are more affected than others. These tools allow analysts to perform real-time hypothesis testing and evaluation.","keywords":"","caption":"Figure 7: Using visual analytics for hypothesis testing in syndromic surveillance. (Top-Left) The user observe a heatmap for a given syndrome, in this case, gastro-intestinal. (Top-Right) Next, the user selects an area of interest, generating a time series plot for that region. Note that in the time series plot generated, an alert is occurring on the day of interest. (Bottom-Left) The user then drills down to the hospital level by selecting the neighboring hospital and generating a time series plot for that emergency department. Here, we see that there is no hospital level alert for gastro-intestinal syndromes. (Bottom-Right) Finally, the user looks for correlating symptoms and filters by the keyword fever. New time series plots are generated. While an alert still exists for the selected area, the user can now see that this alert was generated by only one individual, meaning an outbreak is unlikely.","img_size":{"width":2085,"height":1236},"subfigures":[{"x":100.46905982740371,"y":609.6390868853549,"width":827.4537148830356,"height":605.7726416345726,"type":"interface","id":"interface-0"}],"visualizations":[{"x":319.6060820367751,"y":61.18811881188119,"width":396.84865629420085,"height":360.1357850070722,"type":"heatmap","id":"heatmap-0"},{"x":1291.6230551626593,"y":57.691654879773694,"width":409.0862800565772,"height":367.1287128712871,"type":"heatmap","id":"heatmap-1"},{"x":328.3472418670439,"y":709.7821782178218,"width":398.59688826025456,"height":363.6322489391797,"type":"heatmap","id":"heatmap-2"},{"x":1288.1265912305516,"y":718.5233380480905,"width":396.84865629420074,"height":367.1287128712871,"type":"heatmap","id":"heatmap-3"},{"x":1753.1562942008486,"y":632.859971711457,"width":311.1852899575675,"height":298.9476661951909,"type":"line_chart","id":"line_chart-4"},{"x":1754.9045261669028,"y":942.2970297029701,"width":314.6817538896744,"height":276.2206506364923,"type":"line_chart","id":"line_chart-5"},{"x":468.20579915134374,"y":896.8429985855728,"width":312.933521923621,"height":302.4441301272984,"type":"line_chart","id":"line_chart-6"},{"x":726.9441301272984,"y":43.70579915134371,"width":160.83734087694484,"height":150.34794908062233,"type":"line_chart","id":"line_chart-7"},{"x":1700.7093352192362,"y":45.454031117397456,"width":159.08910891089113,"height":150.34794908062236,"type":"line_chart","id":"line_chart-8"},{"x":740.7140040940262,"y":700.2029201490386,"width":156.67093011278357,"height":468.0152534017764,"type":"line_chart","id":"line_chart-9"}],"relations":[{"vislist":[{"vislist":["line_chart-9"],"relation":null,"id":"group-0"}],"relation":"repeated","id":"relation-0"}]},"1705_3":{"comp":[["line_chart","line_chart",["repeated"]]],"visType":["line_chart"],"compType":["repeated"],"compressed_tree":[{"composite_pattern":"repeated","visualization_type":[["line_chart"]]}],"coOccurrence":[["line_chart","line_chart",["coOccurrence"]]],"year":2008,"conference":["VAST"],"authors":["Sye-Min Chan","Ling Xiao","John Gerth","Pat Hanrahan"],"title":"Maintaining interactivity while exploring massive time series","doi":"10.1109/VAST.2008.4677357","abstract":"The speed of data retrieval qualitatively affects how analysts visually explore and analyze their data. To ensure smooth interactions in massive time series datasets, one needs to address the challenges of computing &lt;i&gt;ad&lt;/i&gt; &lt;i&gt;hoc&lt;/i&gt; queries, distributing query load, and hiding system latency. In this paper, we present ATLAS, a visualization tool for temporal data that addresses these issues using a combination of high performance database technology, predictive caching, and level of detail management. We demonstrate ATLAS using commodity hardware on a network traffic dataset of more than a billion records.","keywords":"","caption":"Figure 2: Fontend interface of ATLAS. 1: The main panel where time series in focus are plotted as line graphs.  2: Context panels showing thetime series outside the focal point. 3: List of attributes that can be used for grouping and filtering.","img_size":{"width":2016,"height":1257},"subfigures":[{"x":3.9361742823763426,"y":6.5516322362920105,"width":2004.19826191012,"height":1243.8967355274162,"type":"interface","id":"interface-0"}],"visualizations":[{"x":396.0032822757112,"y":176.03501094091908,"width":1482.5448577680527,"height":77.01531728665208,"type":"line_chart","id":"line_chart-0"},{"x":244.72319474835888,"y":250.2997811816193,"width":1617.321663019694,"height":800.4091903719914,"type":"line_chart","id":"line_chart-1"},{"x":393.2527352297593,"y":1047.9584245076587,"width":1488.0459518599564,"height":71.51422319474841,"type":"line_chart","id":"line_chart-2"},{"x":247.47374179431077,"y":253.05032822757113,"width":1611.8205689277902,"height":797.6586433260395,"type":"small_multiple","id":"small_multiple-3"}],"relations":[{"vislist":[{"vislist":["line_chart-1"],"relation":null,"id":"group-0"}],"relation":"repeated","id":"relation-0"}]},"1706_5":{"comp":[["stripe_graph","stripe_graph",["repeated"]]],"visType":["stripe_graph"],"compType":["repeated"],"compressed_tree":[{"composite_pattern":"repeated","visualization_type":[["stripe_graph"]]}],"coOccurrence":[["stripe_graph","stripe_graph",["coOccurrence"]]],"year":2008,"conference":["VAST"],"authors":["Anthony C. Robinson"],"title":"Collaborative synthesis of visual analytic results","doi":"10.1109/VAST.2008.4677358","abstract":"Visual analytic tools allow analysts to generate large collections of useful analytical results. We anticipate that analysts in most real world situations will draw from these collections when working together to solve complicated problems. This indicates a need to understand how users synthesize multiple collections of results. This paper reports the results of collaborative synthesis experiments conducted with expert geographers and disease biologists. Ten participants were worked in pairs to complete a simulated real-world synthesis task using artifacts printed on cards on a large, paper-covered workspace. Experiment results indicate that groups use a number of different approaches to collaborative synthesis, and that they employ a variety of organizational metaphors to structure their information. It is further evident that establishing common ground and role assignment are critical aspects of collaborative synthesis. We conclude with a set of general design guidelines for collaborative synthesis support tools.","keywords":"Movement data, spatio-temporal data, aggregation, scalable visualization, geovisualization","caption":"Figure 6.  Detailed experiment results. Prefix A indicates actions by the GeoVISTA participant, B indicates actions by the CIDD participant, and C indicates collaborative actions. A gray bar with red ends is used to highlight the time participants spent explaining their prior work.","img_size":{"width":2115,"height":2340},"subfigures":[{"x":-1.4876366687769587,"y":5.786655252952073,"width":2117.9752733375535,"height":2336.1664881618262,"type":"single","id":"single-0"}],"visualizations":[{"x":7.9911482665355305,"y":7.9911482665355305,"width":2099.017703466929,"height":2324.017703466929,"type":"glyph_based","id":"glyph_based-0"},{"x":7.9911482665355305,"y":7.9911482665355305,"width":2099.017703466929,"height":2324.017703466929,"type":"stripe_graph","id":"stripe_graph-1"}],"relations":[{"vislist":[{"vislist":["stripe_graph-1"],"relation":null,"id":"group-0"}],"relation":"repeated","id":"relation-0"}]},"1707_2":{"comp":[["heatmap","heatmap",["repeated"]]],"visType":["heatmap"],"compType":["repeated"],"compressed_tree":[{"composite_pattern":"repeated","visualization_type":[["heatmap"]]}],"coOccurrence":[["heatmap","heatmap",["coOccurrence"]]],"year":2008,"conference":["VAST"],"authors":["Daniela Oelke","Peter Bak","Daniel A. Keim","Mark Last","Guy Danon"],"title":"Visual evaluation of text features for document summarization and analysis","doi":"10.1109/VAST.2008.4677359","abstract":"Thanks to the Web-related and other advanced technologies, textual information is increasingly being stored in digital form and posted online. Automatic methods to analyze such textual information are becoming inevitable. Many of those methods are based on quantitative text features. Analysts face the challenge to choose the most appropriate features for their tasks. This requires effective approaches for evaluation and feature-engineering.","keywords":"","caption":"Figure 4: Visualization of the classification results when the feature has been extended by taking negation and nouns into account. In comparison to figure 2, it can be seen that especially the class of negative statements profited from the changes.","img_size":{"width":1011,"height":255},"subfigures":[{"x":4.182648416903212,"y":3.1923843956822187,"width":1005.3994778323162,"height":249.72039020522743,"type":"single","id":"single-0"}],"visualizations":[{"x":5.8055783429040195,"y":8.900328137817892,"width":994.4126333059885,"height":239.687448728466,"type":"heatmap","id":"heatmap-0"}],"relations":[{"vislist":[{"vislist":["heatmap-0"],"relation":null,"id":"group-0"}],"relation":"repeated","id":"relation-0"}]},"1713_5":{"comp":[["bar_chart","bar_chart",["repeated"]]],"visType":["bar_chart"],"compType":["repeated"],"compressed_tree":[{"composite_pattern":"repeated","visualization_type":[["bar_chart"]]}],"coOccurrence":[["bar_chart","bar_chart",["coOccurrence"]]],"year":2008,"conference":["VAST"],"authors":["David Gotz","Michelle X. Zhou"],"title":"Characterizing users\' visual analytic activity for insight provenance","doi":"10.1109/VAST.2008.4677365","abstract":"Insight provenance - a historical record of the process and rationale by which an insight is derived - is an essential requirement in many visual analytics applications. While work in this area has relied on either manually recorded provenance (e.g., user notes) or automatically recorded event-based insight provenance (e.g., clicks, drags, and key-presses), both approaches have fundamental limitations. Our aim is to develop a new approach that combines the benefits of both approaches while avoiding their deficiencies. Toward this goal, we characterize userspsila visual analytic activity at multiple levels of granularity. Moreover, we identify a critical level of abstraction, Actions, that can be used to represent visual analytic activity with a set of general but semantically meaningful behavior types. In turn, the action types can be used as the semantic building blocks for insight provenance. We present a catalog of common actions identified through observations of several different visual analytic systems. In addition, we define a taxonomy to categorize actions into three major classes based on their semantic intent. The concept of actions has been integrated into our labpsilas prototype visual analytic system, HARVEST, as the basis for its insight provenance capabilities.","keywords":"Taxonomy, Information Visualization, Analytic Activity, Visual Analytics, Insight Provenance","caption":"Figure 4: A Split action in this timeline-based analysis tool breaks apart a single timeline into several based on speci\ufb01c data attributes. The user\u2019s request is to change the visual organization of informa- tion already on display. For this reason, the Split action is a visual exploration action.","img_size":{"width":1027,"height":495},"subfigures":[{"x":3.12827785250248,"y":1.6350849335953328,"width":1022.4285621478776,"height":491.7298301328085,"type":"single","id":"single-0"}],"visualizations":[{"x":16.610687022900763,"y":57.9389276941314,"width":391.7175572519084,"height":277.0992366412214,"type":"bar_chart","id":"bar_chart-0"},{"x":444.85496183206106,"y":163.74045441168866,"width":390.4580152671756,"height":47.86259541984732,"type":"bar_chart","id":"bar_chart-1"},{"x":441.0763358778626,"y":217.9007597552001,"width":398.01526717557255,"height":50.38167938931298,"type":"bar_chart","id":"bar_chart-2"},{"x":441.0763358778626,"y":272.0610650987116,"width":396.75572519083977,"height":52.90076335877865,"type":"bar_chart","id":"bar_chart-3"},{"x":441.0763358778626,"y":327.48091242695574,"width":396.75572519083977,"height":52.90076335877865,"type":"bar_chart","id":"bar_chart-4"},{"x":442.33587786259545,"y":384.160301739933,"width":396.75572519083977,"height":51.641221374045756,"type":"bar_chart","id":"bar_chart-5"}],"relations":[{"vislist":[{"vislist":["bar_chart-1","bar_chart-2","bar_chart-3","bar_chart-4","bar_chart-5"],"relation":null,"id":"group-0"}],"relation":"repeated","id":"relation-0"}]},"1716_4":{"comp":[["bar_chart","bar_chart",["repeated"]],["scatterplot","matrix",["nested"]]],"visType":["bar_chart","scatterplot","matrix"],"compType":["repeated","nested"],"compressed_tree":[{"composite_pattern":"nested","visualization_type":[["scatterplot"],["matrix"]]},{"composite_pattern":"repeated","visualization_type":[["bar_chart"]]}],"coOccurrence":[["bar_chart","bar_chart",["coOccurrence"]]],"year":2008,"conference":["VAST"],"authors":["Scott Barlowe","Tianyi Zhang","Yujie Liu","Jing Yan","Donald J. Jacobs"],"title":"Multivariate visual explanation for high dimensional datasets","doi":"10.1109/VAST.2008.4677368","abstract":"Understanding multivariate relationships is an important task in multivariate data analysis. Unfortunately, existing multivariate visualization systems lose effectiveness when analyzing relationships among variables that span more than a few dimensions. We present a novel multivariate visual explanation approach that helps users interactively discover multivariate relationships among a large number of dimensions by integrating automatic numerical differentiation techniques and multidimensional visualization techniques. The result is an efficient workflow for multivariate analysis model construction, interactive dimension reduction, and multivariate knowledge discovery leveraging both automatic multivariate analysis and interactive multivariate data visual exploration. Case studies and a formal user study with a real dataset illustrate the effectiveness of this approach.","keywords":"visual analysis, multivariate analysis, dimension reduction, multivariate model construction, multivariate visualization","caption":"Figure 5: The Boston Neighborhood Housing Price dataset [2] in (a) a scatterplot matrix and (b) first order partial derivative histogram. (a) was generated using XmdvTool [28].","img_size":{"width":2103,"height":1101},"subfigures":[{"x":-2.0250224769121408,"y":5.438845138438861,"width":1045.4190437742814,"height":1051.193089200616,"type":"single","id":"single-0"},{"x":1086.2778953840414,"y":7.530339891321834,"width":1012.5700173840385,"height":1057.2546314112976,"type":"single","id":"single-1"}],"visualizations":[{"x":1136.9224137931037,"y":82.25862068965519,"width":470.3505747126438,"height":970.2298850574712,"type":"bar_chart","id":"bar_chart-0"},{"x":1617.8189655172416,"y":4.636815832642479,"width":474.5689655172419,"height":1052.4885057471265,"type":"bar_chart","id":"bar_chart-1"},{"x":9.014303008669641,"y":12.19702160291785,"width":1027.6349980734067,"height":1039.4871307384433,"type":"matrix","id":"matrix-4"},{"x":3.5047547456427353,"y":10.305996230874591,"width":1038.6540945994595,"height":1033.989474968602,"type":"scatterplot","id":"scatterplot-3"},{"x":4.636815832642479,"y":4.636815832642479,"width":1033.57183908046,"height":1041.9425287356323,"type":"small_multiple","id":"small_multiple-2"}],"relations":[{"vislist":[{"vislist":["scatterplot-3"],"relation":null,"id":"group-0"},{"vislist":["matrix-4"],"relation":null,"id":"group-1"}],"relation":"nested","id":"relation-0"},{"vislist":[{"vislist":["bar_chart-0","bar_chart-1"],"relation":null,"id":"group-2"}],"relation":"repeated","id":"relation-1"}]},"1716_5":{"comp":[["bar_chart","bar_chart",["repeated"]]],"visType":["bar_chart"],"compType":["repeated"],"compressed_tree":[{"composite_pattern":"repeated","visualization_type":[["bar_chart"]]}],"coOccurrence":[],"year":2008,"conference":["VAST"],"authors":["Scott Barlowe","Tianyi Zhang","Yujie Liu","Jing Yan","Donald J. Jacobs"],"title":"Multivariate visual explanation for high dimensional datasets","doi":"10.1109/VAST.2008.4677368","abstract":"Understanding multivariate relationships is an important task in multivariate data analysis. Unfortunately, existing multivariate visualization systems lose effectiveness when analyzing relationships among variables that span more than a few dimensions. We present a novel multivariate visual explanation approach that helps users interactively discover multivariate relationships among a large number of dimensions by integrating automatic numerical differentiation techniques and multidimensional visualization techniques. The result is an efficient workflow for multivariate analysis model construction, interactive dimension reduction, and multivariate knowledge discovery leveraging both automatic multivariate analysis and interactive multivariate data visual exploration. Case studies and a formal user study with a real dataset illustrate the effectiveness of this approach.","keywords":"visual analysis, multivariate analysis, dimension reduction, multivariate model construction, multivariate visualization","caption":"Figure 6: Coordinated Views of the SegData Dataset. (a) The parallel coordinates view of a dataset where the variables and their derivative errors are shown. Data items with good derivative qualities are selected and highlighted. (b) The selection is propagated to the histogram view. It shows that the noise in the histograms is the unselected low quality derivatives. (c) The selection in the parallel coordinates is modified so that only data items whose y0 values fall into the lower value group are selected. (d) The corresponding histogram view shows that the selected data items have constant derivatives in both x0 and x1 .","img_size":{"width":2103,"height":672},"subfigures":[{"x":1039.1883861213485,"y":2.615049604140297,"width":536.9934020717558,"height":646.2656521772875,"type":"single","id":"single-0"}],"visualizations":[{"x":769.2941219886163,"y":447.62956037424993,"width":260.5592778866179,"height":199.95028990647387,"type":"bar_chart","id":"bar_chart-0"},{"x":1840.2997680207623,"y":444.17025313936034,"width":258.0634161465954,"height":199.47385166413318,"type":"bar_chart","id":"bar_chart-1"},{"x":769.2941219886163,"y":17.92732836818999,"width":261.62142696967607,"height":197.31224939053772,"type":"bar_chart","id":"bar_chart-2"},{"x":503.2879783658174,"y":232.77844437121993,"width":260.1598547519682,"height":203.1585382613685,"type":"bar_chart","id":"bar_chart-3"},{"x":769.2941219886163,"y":232.77844437122002,"width":263.08299918738373,"height":203.15853826136842,"type":"bar_chart","id":"bar_chart-4"},{"x":504.74955058352504,"y":446.1679881565422,"width":255.77513809884513,"height":200.23539382595317,"type":"bar_chart","id":"bar_chart-5"},{"x":1838.8381958030545,"y":13.006448915592756,"width":258.69828253426067,"height":200.23539382595308,"type":"bar_chart","id":"bar_chart-6"},{"x":1571.370479962548,"y":227.85756491862276,"width":264.54457140509135,"height":198.77382160824533,"type":"bar_chart","id":"bar_chart-7"},{"x":1841.7613402384698,"y":227.8575649186227,"width":249.92884922801454,"height":200.23539382595308,"type":"bar_chart","id":"bar_chart-8"},{"x":1568.8291452791746,"y":445.3113414324064,"width":263.74521831564334,"height":198.11847385212627,"type":"bar_chart","id":"bar_chart-9"},{"x":4.636815832642479,"y":4.636815832642479,"width":493.28009981285106,"height":637.5907673112915,"type":"parallel_coordinate","id":"parallel_coordinate-10"},{"x":1048.2202121023083,"y":4.636815832642479,"width":510.3349968808484,"height":648.8917654398006,"type":"parallel_coordinate","id":"parallel_coordinate-11"}],"relations":[{"vislist":[{"vislist":["bar_chart-2","bar_chart-3","bar_chart-4","bar_chart-0","bar_chart-5"],"relation":null,"id":"group-0"}],"relation":"repeated","id":"relation-0"}]},"1718_1":{"comp":[["table","table",["repeated"]],["graph","map",["coordinated"]],["bar_chart","matrix",["stacked"]],["matrix","bar_chart",["stacked"]]],"visType":["table","graph","map","bar_chart","matrix"],"compType":["repeated","coordinated","stacked"],"compressed_tree":[{"composite_pattern":"repeated","visualization_type":[["table"]]},{"composite_pattern":"stacked","visualization_type":[["bar_chart","matrix"]]},{"composite_pattern":"coordinated","visualization_type":[["graph"],["map"]]}],"coOccurrence":[["table","bar_chart",["coOccurrence"]],["table","matrix",["coOccurrence"]],["table","graph",["coOccurrence"]],["table","map",["coOccurrence"]],["bar_chart","matrix",["coOccurrence"]],["bar_chart","graph",["coOccurrence"]],["bar_chart","map",["coOccurrence"]],["matrix","graph",["coOccurrence"]],["matrix","map",["coOccurrence"]],["graph","map",["coOccurrence"]]],"year":2008,"conference":["VAST"],"authors":["Chris Weaver"],"title":"Multidimensional visual analysis using cross-filtered views","doi":"10.1109/VAST.2008.4677370","abstract":"Analysis of multidimensional data often requires careful examination of relationships across dimensions. Coordinated multiple view approaches have become commonplace in visual analysis tools because they directly support expression of complex multidimensional queries using simple interactions. However, generating such tools remains difficult because of the need to map domain-specific data structures and semantics into the idiosyncratic combinations of interdependent data and visual abstractions needed to reveal particular patterns and distributions in cross-dimensional relationships. This paper describes: (1) a method for interactively expressing sequences of multidimensional set queries by cross-filtering data values across pairs of views, and (2) design strategies for constructing coordinated multiple view interfaces for cross-filtered visual analysis of multidimensional data sets. Using examples of cross-filtered visualizations of data from several different domains, we describe how cross-filtering can be modularized and reused across designs, flexibly customized with respect to data types across multiple dimensions, and incorporated into more wide-ranging multiple view designs. The demonstrated analytic utility of these examples suggest that cross-filtering is a suitable design pattern for instantiation in a wide variety of visual analysis tools.","keywords":"","caption":"Figure 2: Cross-filtered visualization of guest registries from historic hotels in central Pennsylvania. Historical geographers explore early com- mercial travel patterns by posing sequences of who, what, where, and when questions involving arbitrary groups of hotels, guests, residences, and dates. Cross-filtering first on one hotel and then another allows identification of guests who visited both, with relevant dates and residences.","img_size":{"width":2107,"height":840},"subfigures":[{"x":4.121559394810178,"y":5.4552186572727805,"width":2101.061680506726,"height":833.6981254307578,"type":"interface","id":"interface-0"}],"visualizations":[{"x":327.3183361629878,"y":751.8984528989463,"width":697.5636672325967,"height":88.34097915058462,"type":"bar_chart","id":"bar_chart-0"},{"x":935.5849625261593,"y":123.24227312970419,"width":92.72523763429957,"height":623.2456927941898,"type":"bar_chart","id":"bar_chart-8"},{"x":1038.7124126097847,"y":11.320567049003698,"width":1053.6110885424093,"height":549.7867144196074,"type":"graph","id":"graph-11"},{"x":1037.402376910017,"y":5.039049235993232,"width":1064.9519878263704,"height":559.8395585738539,"type":"heatmap","id":"heatmap-2"},{"x":1037.402376910017,"y":6.827674023769126,"width":1064.9519878263704,"height":559.8395585738539,"type":"map","id":"map-1"},{"x":330.8955857385399,"y":124.87691001697797,"width":695.7750424448218,"height":710.4774547194091,"type":"matrix","id":"matrix-3"},{"x":1037.402376910017,"y":597.0738539898133,"width":1060.6544991511034,"height":238.28051074657384,"type":"table","id":"table-4"},{"x":5.365874363327674,"y":201.78777589134125,"width":311.2207130730051,"height":304.0662139219015,"type":"table","id":"table-5"},{"x":7.154499151103566,"y":534.471986417657,"width":309.4320882852292,"height":300.4889643463498,"type":"table","id":"table-6"},{"x":8.943123938879458,"y":24.713921901528035,"width":307.64346349745335,"height":152.0331069609508,"type":"table","id":"table-7"}],"relations":[{"vislist":[{"vislist":["table-7","table-6","table-5"],"relation":null,"id":"group-0"}],"relation":"repeated","id":"relation-0"},{"vislist":[{"vislist":["bar_chart-0","bar_chart-8","matrix-3"],"relation":null,"id":"group-1"}],"relation":"stacked","id":"relation-1"},{"vislist":[{"vislist":["graph-11"],"relation":null,"id":"group-2"},{"vislist":["map-1"],"relation":null,"id":"group-3"}],"relation":"coordinated","id":"relation-2"}]},"1718_2":{"comp":[["stripe_graph","stripe_graph",["repeated"]],["scatterplot","matrix",["nested"]],["others","matrix",["nested"]],["bar_chart","matrix",["stacked"]],["matrix","bar_chart",["stacked"]]],"visType":["stripe_graph","scatterplot","matrix","others","bar_chart"],"compType":["repeated","nested","stacked"],"compressed_tree":[{"composite_pattern":"repeated","visualization_type":[["stripe_graph"]]},{"composite_pattern":"stacked","visualization_type":[["bar_chart","matrix"]]},{"composite_pattern":"nested","visualization_type":[["scatterplot","others"],["matrix"]]}],"coOccurrence":[["stripe_graph","bar_chart",["coOccurrence"]],["stripe_graph","matrix",["coOccurrence"]],["stripe_graph","scatterplot",["coOccurrence"]],["stripe_graph","others",["coOccurrence"]],["bar_chart","matrix",["coOccurrence"]],["bar_chart","scatterplot",["coOccurrence"]],["bar_chart","others",["coOccurrence"]],["matrix","scatterplot",["coOccurrence"]],["matrix","others",["coOccurrence"]],["scatterplot","others",["coOccurrence"]]],"year":2008,"conference":["VAST"],"authors":["Chris Weaver"],"title":"Multidimensional visual analysis using cross-filtered views","doi":"10.1109/VAST.2008.4677370","abstract":"Analysis of multidimensional data often requires careful examination of relationships across dimensions. Coordinated multiple view approaches have become commonplace in visual analysis tools because they directly support expression of complex multidimensional queries using simple interactions. However, generating such tools remains difficult because of the need to map domain-specific data structures and semantics into the idiosyncratic combinations of interdependent data and visual abstractions needed to reveal particular patterns and distributions in cross-dimensional relationships. This paper describes: (1) a method for interactively expressing sequences of multidimensional set queries by cross-filtering data values across pairs of views, and (2) design strategies for constructing coordinated multiple view interfaces for cross-filtered visual analysis of multidimensional data sets. Using examples of cross-filtered visualizations of data from several different domains, we describe how cross-filtering can be modularized and reused across designs, flexibly customized with respect to data types across multiple dimensions, and incorporated into more wide-ranging multiple view designs. The demonstrated analytic utility of these examples suggest that cross-filtering is a suitable design pattern for instantiation in a wide variety of visual analysis tools.","keywords":"","caption":"Figure 3: Visualization of 2001-2006 major league baseball games recorded in the Retrosheet database [1], with cross-filtering on stadiums, home teams, away teams, and game dates. Variation filtering provides additional globally switchable cross-filtering on ranges of game time and two user-picked numeric attributes in a scatter plot matrix, here revealing high attendance 2006 weekend games with temperatures over 95\u25e6 F.","img_size":{"width":2115,"height":918},"subfigures":[{"x":-3.9421679082512875,"y":5.557132207563001,"width":2115.9436848742475,"height":905.7287603899267,"type":"interface","id":"interface-0"}],"visualizations":[{"x":1445.2758620689658,"y":72.10344827586208,"width":114.31034482758628,"height":306,"type":"bar_chart","id":"bar_chart-0"},{"x":998.5862068965519,"y":378.1034482758621,"width":446.6896551724139,"height":112.55172413793103,"type":"bar_chart","id":"bar_chart-1"},{"x":11.092436843810276,"y":481.4077317039406,"width":797.1107946791851,"height":419.3134909510296,"type":"glyph_based","id":"glyph_based-2"},{"x":17.275862068965402,"y":483.6206896551724,"width":791.3793103448278,"height":415.03448275862075,"type":"heatmap","id":"heatmap-3"},{"x":1564.8788799091662,"y":34.6868581145059,"width":518.7332800329378,"height":494.3174672135817,"type":"matrix","id":"matrix-15"},{"x":813.9310344827586,"y":36.931034482758626,"width":629.5862068965519,"height":341.1724137931035,"type":"matrix","id":"matrix-4"},{"x":1849.8311277501784,"y":40.311777867510166,"width":235.40407539347302,"height":217.52528485725983,"type":"scatterplot","id":"scatterplot-5"},{"x":1614.4270523567056,"y":40.311777867510166,"width":230.9343777594195,"height":220.50508327996198,"type":"scatterplot","id":"scatterplot-6"},{"x":1621.4062966371043,"y":263.096098216783,"width":228.4652630442988,"height":212.0561557538242,"type":"others","id":"others-10"},{"x":1852.3960377260914,"y":258.04714212740623,"width":223.41630695492225,"height":214.58063379851274,"type":"others","id":"others-11"},{"x":13.758620689655057,"y":59.793103448275865,"width":200.48275862068968,"height":342.93103448275866,"type":"stripe_graph","id":"stripe_graph-7"},{"x":284.58620689655163,"y":63.31034482758622,"width":196.9655172413793,"height":341.1724137931035,"type":"stripe_graph","id":"stripe_graph-8"},{"x":548.3793103448276,"y":65.06896551724137,"width":196.9655172413793,"height":339.4137931034483,"type":"stripe_graph","id":"stripe_graph-9"},{"x":824.4827586206897,"y":608.4827586206898,"width":896.896551724138,"height":251.48275862068965,"type":"table","id":"table-12"}],"relations":[{"vislist":[{"vislist":["stripe_graph-7","stripe_graph-8","stripe_graph-9"],"relation":null,"id":"group-0"}],"relation":"repeated","id":"relation-0"},{"vislist":[{"vislist":["bar_chart-0","bar_chart-1","matrix-4"],"relation":null,"id":"group-1"}],"relation":"stacked","id":"relation-1"},{"vislist":[{"vislist":["scatterplot-5","scatterplot-6","others-10","others-11"],"relation":null,"id":"group-2"},{"vislist":["matrix-15"],"relation":null,"id":"group-3"}],"relation":"nested","id":"relation-2"}]},"1724_0":{"comp":[["bar_chart","bar_chart",["repeated"]],["graph","graph",["repeated"]]],"visType":["bar_chart","graph"],"compType":["repeated"],"compressed_tree":[{"composite_pattern":"repeated","visualization_type":[["bar_chart"]]},{"composite_pattern":"repeated","visualization_type":[["graph"]]}],"coOccurrence":[["bar_chart","graph",["coOccurrence"]]],"year":2008,"conference":["VAST"],"authors":["Victor Pascual-Cid"],"title":"An information visualisation system for the understanding of web data","doi":"10.1109/VAST.2008.4677377","abstract":"Internet has become one of the best communication and marketing tools. Hence, designing well-structured Web sites with the information or products that users look for is a crucial mission. For this reason, understanding Web data is a decisive task to assure the success of a Website. In that sense, data mining techniques provide many metrics and statistics useful to automatically discover the structure, contents and usage of a site. This research aims at proving the usefulness of a set of information visualisation techniques in order to analyse Web data, using a visual Web mining tool that allows the combination, coordination and exploration of visualisations to get insight on Web data. The tool, named WET, provides a set of visual metaphors that represent the structure of the Websites where Web metrics are overlaid.","keywords":"","caption":"Figure 1: A screenshot of WET.","img_size":{"width":714,"height":547},"subfigures":[{"x":9.233629680997746,"y":12.131844498785583,"width":702.772247689047,"height":530.5764403936319,"type":"interface","id":"interface-0"}],"visualizations":[{"x":542.4033674963396,"y":288.3162518301611,"width":155.37042459736475,"height":77.6852122986823,"type":"bar_chart","id":"bar_chart-0"},{"x":543.2042459736456,"y":368.40409956076127,"width":153.7686676427527,"height":80.8887262079063,"type":"bar_chart","id":"bar_chart-1"},{"x":540.0007320644219,"y":447.69106881405554,"width":158.57393850658855,"height":86.49487554904834,"type":"bar_chart","id":"bar_chart-2"},{"x":17.82796486090774,"y":68.87554904831622,"width":253.87847730600294,"height":221.04245973645678,"type":"graph","id":"graph-3"},{"x":270.10468521229865,"y":68.07467057101022,"width":260.28550512445094,"height":219.44070278184478,"type":"graph","id":"graph-4"},{"x":19.29729484863755,"y":301.1303074670569,"width":508.16008594842026,"height":233.85651537335264,"type":"treemap","id":"treemap-5"}],"relations":[{"vislist":[{"vislist":["bar_chart-0","bar_chart-1","bar_chart-2"],"relation":null,"id":"group-0"}],"relation":"repeated","id":"relation-0"},{"vislist":[{"vislist":["graph-3","graph-4"],"relation":null,"id":"group-1"}],"relation":"repeated","id":"relation-1"}]},"1726_1":{"comp":[["bar_chart","bar_chart",["repeated"]]],"visType":["bar_chart"],"compType":["repeated"],"compressed_tree":[{"composite_pattern":"repeated","visualization_type":[["bar_chart"]]}],"coOccurrence":[["bar_chart","bar_chart",["coOccurrence"]]],"year":2008,"conference":["VAST"],"authors":["Alex Godwin","Remco Chang","Robert Kosara","William Ribarsky"],"title":"Interactive poster: Visual data mining of unevenly-spaced event sequences","doi":"10.1109/VAST.2008.4677379","abstract":"We present a process for the exploration and analysis of large databases of events. A typical database is characterized by the sequential actions of a number of individual entities. These entities can be compared by their similarities in sequence and changes in sequence over time. The correlation of two sequences can provide important clues as to the possibility of a connection between the responsible entities, but an analyst might not be able to specify the type of connection sought prior to examination. Our process incorporates extensive automated calculation and data mining but permits diversity of analysis by providing visualization of results at multiple levels, taking advantage of human intuition and visual processing to generate avenues of inquiry.","keywords":"","caption":"Figure 3: Detailed comparison views of one sequence queried against the database.","img_size":{"width":615,"height":462},"subfigures":[{"x":4.106176662218951,"y":4.171971208553376,"width":608.8267693952331,"height":455.69354304414276,"type":"interface","id":"interface-0"}],"visualizations":[{"x":11.799781181619151,"y":42.45951859956236,"width":586.3457330415754,"height":237.5711159737418,"type":"bar_chart","id":"bar_chart-0"},{"x":6.400027468207088,"y":312.80552926152643,"width":600.93838311352,"height":143.07823534547592,"type":"others","id":"others-3"},{"x":11.446372531161572,"y":9.96837009093306,"width":528.3812136757349,"height":29.8592118956806,"type":"stripe_graph","id":"stripe_graph-1"}],"relations":[{"vislist":[{"vislist":["bar_chart-0"],"relation":null,"id":"group-0"}],"relation":"repeated","id":"relation-0"}]},"1733_2":{"comp":[["bar_chart","bar_chart",["repeated"]]],"visType":["bar_chart"],"compType":["repeated"],"compressed_tree":[{"composite_pattern":"repeated","visualization_type":[["bar_chart"]]}],"coOccurrence":[["bar_chart","bar_chart",["coOccurrence"]]],"year":2008,"conference":["VAST"],"authors":["Ranko Miklin","Tomislav Lipic","Zoltan Konyha","Mario Beric","Wolfgang Freiler","Kresimir Matkovic","Denis Gracanin"],"title":"Migrant boat mini challenge award: Simple and effective integrated display geo-temporal analysis of migrant boats","doi":"10.1109/VAST.2008.4677387","abstract":"We provide a description of the tools and techniques used in our analysis of the VAST 2008 Challenge dealing with mass movement of persons departing Isla Del Sue.no on boats for the United States during 2005-2007. We used visual analytics to explore migration patterns, characterize the choice and evolution of landing sites, characterize the geographical patterns of interdictions and determine the successful landing rate. Our ComVis tool, in connection with some helper applications and Google Earth, allowed us to explore geo-temporal characteristics of the data set and answer the challenge questions. The ComVis project file captures the visual analysis context and facilitates better collaboration among team members.","keywords":"","caption":"Figure 2: The original brush of the landing records from Figure 1a (upper left view) is now combined with another brush, year 2005 records (lower left view), to provide a specific \u201cgeographical\u201d distri- bution (lower right view) and temporal distribution in four quarters of 2005 (upper right view).","img_size":{"width":849,"height":534},"subfigures":[{"x":1.6766035683767535,"y":1.8881880279320251,"width":845.05780888711,"height":528.4573621968837,"type":"interface","id":"interface-0"}],"visualizations":[{"x":115.43435448577678,"y":78.28884026258206,"width":164.75711159737412,"height":207.99124726477024,"type":"bar_chart","id":"bar_chart-0"},{"x":392.36652078774614,"y":80.62582056892776,"width":424.1619256017505,"height":206.82275711159735,"type":"bar_chart","id":"bar_chart-1"},{"x":115.43435448577678,"y":302.63894967177237,"width":161.25164113785561,"height":206.82275711159735,"type":"bar_chart","id":"bar_chart-2"},{"x":392.36652078774614,"y":301.4704595185995,"width":424.1619256017505,"height":206.82275711159735,"type":"scatterplot","id":"scatterplot-3"}],"relations":[{"vislist":[{"vislist":["bar_chart-0","bar_chart-2"],"relation":null,"id":"group-1"}],"relation":"repeated","id":"relation-0"}]},"1543_10":{"comp":[["treemap","treemap",["repeated"]]],"visType":["treemap"],"compType":["repeated"],"compressed_tree":[{"composite_pattern":"repeated","visualization_type":[["treemap"]]}],"coOccurrence":[],"year":2007,"conference":["InfoVis"],"authors":["Ying Tu","Han-Wei Shen"],"title":"Visualizing Changes of Hierarchical Data using Treemaps","doi":"10.1109/TVCG.2007.70529","abstract":"While the treemap is a popular method for visualizing hierarchical data, it is often difficult for users to track layout and attribute changes when the data evolve over time. When viewing the treemaps side by side or back and forth, there exist several problems that can prevent viewers from performing effective comparisons. Those problems include abrupt layout changes, a lack of prominent visual patterns to represent layouts, and a lack of direct contrast to highlight differences. In this paper, we present strategies to visualize changes of hierarchical data using treemaps. A new treemap layout algorithm is presented to reduce abrupt layout changes and produce consistent visual patterns. Techniques are proposed to effectively visualize the difference and contrast between two treemap snapshots in terms of the map items\' colors, sizes, and positions. Experimental data show that our algorithm can achieve a good balance in maintaining a treemap\'s stability, continuity, readability, and average aspect ratio. A software tool is created to compare treemaps and generate the visualizations. User studies show that the users can better understand the changes in the hierarchy and layout, and more quickly notice the color and size differences using our method.","keywords":"Treemap, tree comparison, visualize changes, treemap layout algorithm","caption":"Fig. 11. An Example of the Contrast Treemap - Two Corners","img_size":{"width":1056,"height":777},"subfigures":[{"x":13.191108242536673,"y":55.15845533137899,"width":158.97733301878316,"height":118.1044296625272,"type":"single","id":"single-0"}],"visualizations":[{"x":15.212923728813621,"y":8.230932203389877,"width":1033.8050847457628,"height":760.5381355932201,"type":"treemap","id":"treemap-0"}],"relations":[{"vislist":[{"vislist":["treemap-0"],"relation":null,"id":"group-0"}],"relation":"repeated","id":"relation-0"}]},"1550_2":{"comp":[["comb","comb",["repeated"]],["box_plot","scatterplot",["accompanied"]],["scatterplot","box_plot",["accompanied"]]],"visType":["comb","box_plot","scatterplot"],"compType":["repeated","accompanied"],"compressed_tree":[{"composite_pattern":"repeated","visualization_type":[[{"composite_pattern":"accompanied","visualization_type":[["box_plot","scatterplot"]]}]]}],"coOccurrence":[["box_plot","scatterplot",["coOccurrence"]]],"year":2007,"conference":["InfoVis"],"authors":["Jason Dykes","Chris Brunsdon"],"title":"Geographically Weighted Visualization: Interactive Graphics for Scale-Varying Exploratory Analysis","doi":"10.1109/TVCG.2007.70558","abstract":"We introduce a series of geographically weighted (GW) interactive graphics, or geowigs, and use them to explore spatial relationships at a range of scales. We visually encode information about geographic and statistical proximity and variation in novel ways through &lt;i&gt;gw-choropleth maps&lt;/i&gt;, multivariate &lt;i&gt;gw-boxplots, gw-shading&lt;/i&gt; and &lt;i&gt;scalograms&lt;/i&gt;. The new graphic types reveal information about GW statistics at several scales concurrently. We impement these views in prototype software containing dynamic links and GW interactions that encourage exploration and refine them to consider directional geographies. An informal evaluation uses interactive GW techniques to consider Guerry\'s dataset of \'moral statistics\', casting doubt on correlations originally proposed through visual analysis, revealing new local anomalies and suggesting multivariate geographic relationships. Few attempts at visually synthesising geography with multivariate statistical values at multiple scales have been reported. The &lt;i&gt;geowigs &lt;/i&gt;proposed here provide informative representations of multivariate local variation, particularly when combined with interactions that coordinate views and result in &lt;i&gt;gw-shading&lt;/i&gt;. We argue that they are widely applicable to area and point-based geographic data and provide a set of methods to support visual analysis using GW statistics through which the effects of geography can be explored at multiple scales.","keywords":"Geographical weighting, exploratory data analysis, scale, multivariate, directional, interaction, coordinated views","caption":"Fig. 3. gw-boxplots for a single department \u2013 variable 1 \u2018population per crime against persons\u2019 at five different scales (h=25 to h=200).","img_size":{"width":1053,"height":612},"subfigures":[{"x":4.42603369018945,"y":4.174925254829104,"width":1041.448657621298,"height":602.9753978116163,"type":"single","id":"single-0"}],"visualizations":[{"x":950.7056074766357,"y":1.9065420560747661,"width":89.60747663551389,"height":608.4280986818076,"type":"box_plot","id":"box_plot-0"},{"x":841.8087630803745,"y":5.719626168224297,"width":91.41617244617912,"height":600.5607476635513,"type":"box_plot","id":"box_plot-1"},{"x":731.4532710280373,"y":5.719626168224299,"width":99.14018691588785,"height":604.615014569658,"type":"box_plot","id":"box_plot-2"},{"x":626.5934579439254,"y":5.719626168224299,"width":87.70093457943916,"height":604.615014569658,"type":"box_plot","id":"box_plot-3"},{"x":516.014018691589,"y":1.6653592621177424,"width":95.32710280373828,"height":608.6692814757645,"type":"box_plot","id":"box_plot-4"},{"x":8.873831775701037,"y":5.719626168224299,"width":493.7943925233644,"height":604.3738317757009,"type":"heatmap","id":"heatmap-5"},{"x":6.967289719626251,"y":5.719626168224299,"width":488.0747663551401,"height":604.615014569658,"type":"map","id":"map-6"},{"x":840.5536753816839,"y":7.9918732650083735,"width":94.32139286524922,"height":596.0162534699829,"type":"scatterplot","id":"scatterplot-10"},{"x":954.8908688646897,"y":5.3515878403078485,"width":87.36937606359618,"height":601.2968243193843,"type":"scatterplot","id":"scatterplot-11"},{"x":514.01317766868,"y":4.019797258375978,"width":96.21776961034692,"height":601.2949967110501,"type":"scatterplot","id":"scatterplot-7"},{"x":626.8917135370276,"y":8.65779598096618,"width":87.5222374339549,"height":596.0171124241662,"type":"scatterplot","id":"scatterplot-8"},{"x":732.494371229439,"y":5.339940726802184,"width":98.70512515692947,"height":598.6547097741973,"type":"scatterplot","id":"scatterplot-9"}],"relations":[{"vislist":[{"vislist":[{"vislist":[{"vislist":["box_plot-4","scatterplot-7"],"relation":null,"id":"group-5"}],"relation":"accompanied","id":"relation-4"},{"vislist":[{"vislist":["scatterplot-8","box_plot-3"],"relation":null,"id":"group-4"}],"relation":"accompanied","id":"relation-3"},{"vislist":[{"vislist":["scatterplot-9","box_plot-2"],"relation":null,"id":"group-3"}],"relation":"accompanied","id":"relation-2"},{"vislist":[{"vislist":["box_plot-1","scatterplot-10"],"relation":null,"id":"group-2"}],"relation":"accompanied","id":"relation-1"},{"vislist":[{"vislist":["box_plot-0","scatterplot-11"],"relation":null,"id":"group-1"}],"relation":"accompanied","id":"relation-0"}],"relation":null,"id":"group-6"}],"relation":"repeated","id":"relation-5"}]},"1559_6":{"comp":[["bar_chart","bar_chart",["repeated"]]],"visType":["bar_chart"],"compType":["repeated"],"compressed_tree":[{"composite_pattern":"repeated","visualization_type":[["bar_chart"]]}],"coOccurrence":[["bar_chart","bar_chart",["coOccurrence"]]],"year":2007,"conference":["InfoVis"],"authors":["Wesley Willett","Jeffrey Heer","Maneesh Agrawala"],"title":"Scented Widgets: Improving Navigation Cues with Embedded Visualizations","doi":"10.1109/TVCG.2007.70589","abstract":"This paper presents scented widgets, graphical user interface controls enhanced with embedded visualizations that facilitate navigation in information spaces. We describe design guidelines for adding visual cues to common user interface widgets such as radio buttons, sliders, and combo boxes and contribute a general software framework for applying scented widgets within applications with minimal modifications to existing source code. We provide a number of example applications and describe a controlled experiment which finds that users exploring unfamiliar data make up to twice as many unique discoveries using widgets imbued with social navigation data. However, these differences equalize as familiarity with the data increases.","keywords":"Information visualization, user interface toolkits, information foraging, social navigation, social data analysis","caption":"Figure 5. HomeFinder with histogram widgets. A scatter plot and scented query widgets show available apartments from craigslist.org.","img_size":{"width":1059,"height":672},"subfigures":[{"x":2.0676629786887633,"y":3.331935144502535,"width":1052.8005750807615,"height":661.208282364226,"type":"interface","id":"interface-0"}],"visualizations":[{"x":700.3800567843981,"y":68.72198567938842,"width":69.37031405690391,"height":189.8402442193532,"type":"bar_chart","id":"bar_chart-2"},{"x":704.613419843899,"y":275.07347857077934,"width":60.18857849855402,"height":127.57446666627288,"type":"bar_chart","id":"bar_chart-3"},{"x":705.9983440349946,"y":429.17366083262704,"width":53.84368291961781,"height":116.17296217385525,"type":"bar_chart","id":"bar_chart-4"},{"x":5.088785046728958,"y":37.682242990654196,"width":686.6542056074766,"height":630.1308411214952,"type":"map","id":"map-0"}],"relations":[{"vislist":[{"vislist":["bar_chart-2","bar_chart-3","bar_chart-4"],"relation":null,"id":"group-2"}],"relation":"repeated","id":"relation-1"}]},"1567_5":{"comp":[["heatmap","heatmap",["repeated"]]],"visType":["heatmap"],"compType":["repeated"],"compressed_tree":[{"composite_pattern":"repeated","visualization_type":[["heatmap"]]}],"coOccurrence":[["heatmap","heatmap",["coOccurrence"]]],"year":2007,"conference":["VAST"],"authors":["Firdaus Janoos","Shantanu Singh","M. Okan Irfanoglu","Raghu Machiraju","Richard E. Parent"],"title":"Activity Analysis Using Spatio-Temporal Trajectory Volumes in Surveillance Applications","doi":"10.1109/VAST.2007.4388990","abstract":"In this paper, we present a system to analyze activities and detect anomalies in a surveillance application, which exploits the intuition and experience of security and surveillance experts through an easy- to-use visual feedback loop. The multi-scale and location specific nature of behavior patterns in space and time is captured using a wavelet-based feature descriptor. The system learns the fundamental descriptions of the behavior patterns in a semi-supervised fashion by the higher order singular value decomposition of the space described by the training data. This training process is guided and refined by the users in an intuitive fashion. Anomalies are detected by projecting the test data into this multi-linear space and are visualized by the system to direct the attention of the user to potential problem spots. We tested our system on real-world surveillance data, and it satisfied the security concerns of the environment.","keywords":"wavelets, HOSVD, surveillance, anomaly detection, trajectory","caption":"Figure 4: The Graphical User Interface","img_size":{"width":2115,"height":1062},"subfigures":[{"x":8.05532378461499,"y":7.224036548877616,"width":2100.0606884437484,"height":1041.69746380742,"type":"interface","id":"interface-0"}],"visualizations":[{"x":729.2864214992927,"y":28.540311173974548,"width":557.7229242950999,"height":584.8195019101378,"type":"heatmap","id":"heatmap-0"},{"x":1379.7050919377655,"y":25.53606789250354,"width":558.7892503536069,"height":588.8316831683169,"type":"heatmap","id":"heatmap-1"}],"relations":[{"vislist":[{"vislist":["heatmap-0","heatmap-1"],"relation":null,"id":"group-0"}],"relation":"repeated","id":"relation-0"}]},"1575_3":{"comp":[["area_chart","area_chart",["repeated"]]],"visType":["area_chart"],"compType":["repeated"],"compressed_tree":[{"composite_pattern":"repeated","visualization_type":[["area_chart"]]}],"coOccurrence":[["area_chart","area_chart",["coOccurrence"]]],"year":2007,"conference":["VAST"],"authors":["Daniel R. Tesone","John R. Goodall"],"title":"Balancing Interactive Data Management of Massive Data with Situational Awareness through Smart Aggregation","doi":"10.1109/VAST.2007.4388998","abstract":"Designing a visualization system capable of processing, managing, and presenting massive data sets while maximizing the user\'s situational awareness (SA) is a challenging, but important, research question in visual analytics. Traditional data management and interactive retrieval approaches have often focused on solving the data overload problem at the expense of the user\'s SA. This paper discusses various data management strategies and the strengths and limitations of each approach in providing the user with SA. A new data management strategy, coined Smart Aggregation, is presented as a powerful approach to overcome the challenges of both massive data sets and maintaining SA. By combining automatic data aggregation with user-defined controls on what, how, and when data should be aggregated, we present a visualization system that can handle massive amounts of data while affording the user with the best possible SA. This approach ensures that a system is always usable in terms of both system resources and human perceptual resources. We have implemented our Smart Aggregation approach in a visual analytics system called VIAssist (Visual Assistant for Information Assurance Analysis) to facilitate exploration, discovery, and SA in the domain of Information Assurance.","keywords":"Data management, visual analytics, data retrieval, information visualization, smart aggregation, situational awareness","caption":"Figure 1. VIAssist visual analytic system showing linked visualization views and interaction mechanisms","img_size":{"width":1014,"height":792},"subfigures":[{"x":7.436898872696726,"y":4.537950134149469,"width":1006.1181954479373,"height":782.0508916768796,"type":"interface","id":"interface-0"}],"visualizations":[{"x":204.6976016488617,"y":629.9476131774221,"width":284.15606719532457,"height":124.7060469569001,"type":"area_chart","id":"area_chart-0"},{"x":501.88265882475787,"y":617.5390512911636,"width":304.63019430765155,"height":144.559745974914,"type":"area_chart","id":"area_chart-1"},{"x":9.483050847457662,"y":307.0677966101695,"width":181.22033898305085,"height":253.3728813559323,"type":"bar_chart","id":"bar_chart-2"},{"x":504.3643712020097,"y":619.4003355741023,"width":302.76891002471274,"height":142.69846169197527,"type":"bar_chart","id":"bar_chart-3"},{"x":191.76204570360053,"y":484.57011147791366,"width":604.0307188967366,"height":115.29640411373519,"type":"table","id":"table-4"},{"x":195.6080695284988,"y":56.74418888479709,"width":611.1729740188262,"height":380.58016579135597,"type":"tree","id":"tree-5"}],"relations":[{"vislist":[{"vislist":["area_chart-0"],"relation":null,"id":"group-0"}],"relation":"repeated","id":"relation-0"}]},"1584_5":{"comp":[["bar_chart","bar_chart",["repeated"]]],"visType":["bar_chart"],"compType":["repeated"],"compressed_tree":[{"composite_pattern":"repeated","visualization_type":[["bar_chart"]]}],"coOccurrence":[["bar_chart","bar_chart",["coOccurrence"]]],"year":2007,"conference":["VAST"],"authors":["Enrico Bertini","Patrick Hertzog","Denis Lalanne"],"title":"SpiralView: Towards Security Policies Assessment through Visual Correlation of Network Resources with Evolution of Alarms","doi":"10.1109/VAST.2007.4389007","abstract":"This article presents SpiralView, a visualization tool for helping system administrators to assess network policies. The tool is meant to be a complementary support to the routine activity of network monitoring, enabling a retrospective view on the alarms generated during and extended period of time. The tool permits to reason about how alarms distribute over time and how they correlate with network resources (e.g., users, IPs, applications, etc.), supporting the analysts in understanding how the network evolves and thus in devising new security policies for the future. The spiral visualization plots alarms in time, and, coupled with interactive bar charts and a users/applications graph view, is used to present network data and perform queries. The user is able to segment the data in meaningful subsets, zoom on specific related information, and inspect for relationships between alarms, users, and applications. In designing the visualizations and their interaction, and through tests with security experts, several ameliorations over the standard techniques have been provided.","keywords":"Network security, Intrusion Detection, Visualization, Data Exploration","caption":"Figure 6: Case Study 1: the alarms generating the \u201dspikes\u201d in the spiral (alarms recurring everyday, for a long time period, at the same time) are investigated in detail. Through filtering and selection we are able to isolate the source of these recurring alarms. The alarms are generated by the user/application pair: user \u201d17\u201d and application \u201dsave.exe\u201d.","img_size":{"width":1485,"height":1152},"subfigures":[{"x":8.242508253215437,"y":6.6174601822753685,"width":1474.8716655271821,"height":1141.3053212494744,"type":"interface","id":"interface-0"}],"visualizations":[{"x":753.883399209486,"y":141.15415019762844,"width":708.0474308300397,"height":204.90118577075097,"type":"bar_chart","id":"bar_chart-0"},{"x":753.883399209486,"y":336.9486166007905,"width":708.0474308300397,"height":138.8774703557312,"type":"bar_chart","id":"bar_chart-1"},{"x":751.6067193675888,"y":496.31620553359676,"width":710.324110671937,"height":202.62450592885375,"type":"bar_chart","id":"bar_chart-2"},{"x":753.883399209486,"y":683.0039525691698,"width":710.3241106719366,"height":182.13438735177863,"type":"bar_chart","id":"bar_chart-3"},{"x":21.164865700490335,"y":821.6557772133141,"width":722.4728357299527,"height":69.19788524036892,"type":"bar_chart","id":"bar_chart-4"},{"x":17.72738735593174,"y":919.2812534093155,"width":1394.0731701862387,"height":188.2760190122426,"type":"parallel_coordinate","id":"parallel_coordinate-5"},{"x":18.515810276679872,"y":68.30039525691699,"width":730.814229249012,"height":751.3043478260869,"type":"scatterplot","id":"scatterplot-6"}],"relations":[{"vislist":[{"vislist":["bar_chart-0","bar_chart-1","bar_chart-2","bar_chart-3"],"relation":null,"id":"group-0"}],"relation":"repeated","id":"relation-0"}]},"1584_0":{"comp":[["bar_chart","bar_chart",["repeated"]]],"visType":["bar_chart"],"compType":["repeated"],"compressed_tree":[{"composite_pattern":"repeated","visualization_type":[["bar_chart"]]}],"coOccurrence":[["bar_chart","bar_chart",["coOccurrence"]]],"year":2007,"conference":["VAST"],"authors":["Enrico Bertini","Patrick Hertzog","Denis Lalanne"],"title":"SpiralView: Towards Security Policies Assessment through Visual Correlation of Network Resources with Evolution of Alarms","doi":"10.1109/VAST.2007.4389007","abstract":"This article presents SpiralView, a visualization tool for helping system administrators to assess network policies. The tool is meant to be a complementary support to the routine activity of network monitoring, enabling a retrospective view on the alarms generated during and extended period of time. The tool permits to reason about how alarms distribute over time and how they correlate with network resources (e.g., users, IPs, applications, etc.), supporting the analysts in understanding how the network evolves and thus in devising new security policies for the future. The spiral visualization plots alarms in time, and, coupled with interactive bar charts and a users/applications graph view, is used to present network data and perform queries. The user is able to segment the data in meaningful subsets, zoom on specific related information, and inspect for relationships between alarms, users, and applications. In designing the visualizations and their interaction, and through tests with security experts, several ameliorations over the standard techniques have been provided.","keywords":"Network security, Intrusion Detection, Visualization, Data Exploration","caption":"Figure 1: The whole SpiralView\u2019s interface.","img_size":{"width":1275,"height":981},"subfigures":[{"x":4.96812373963596,"y":3.348399151514539,"width":1266.3063050119324,"height":973.0597270694066,"type":"interface","id":"interface-0"}],"visualizations":[{"x":651.4529540481401,"y":128.7964989059081,"width":601.0503282275712,"height":609.636761487965,"type":"bar_chart","id":"bar_chart-0"},{"x":20.92958037644368,"y":701.8720833592378,"width":618.8427158500112,"height":55.20193239976618,"type":"bar_chart","id":"bar_chart-1"},{"x":22.21988282078363,"y":788.1255066063359,"width":1189.4735487192688,"height":155.31342515124223,"type":"parallel_coordinate","id":"parallel_coordinate-2"},{"x":13.910284463894982,"y":25.75929978118162,"width":616.0765864332604,"height":674.0350109409192,"type":"scatterplot","id":"scatterplot-3"}],"relations":[{"vislist":[{"vislist":["bar_chart-0"],"relation":null,"id":"group-0"}],"relation":"repeated","id":"relation-0"}]},"1585_9":{"comp":[["line_chart","line_chart",["repeated"]],["bar_chart","bar_chart",["repeated"]]],"visType":["line_chart","bar_chart"],"compType":["repeated"],"compressed_tree":[{"composite_pattern":"repeated","visualization_type":[["line_chart"]]},{"composite_pattern":"repeated","visualization_type":[["bar_chart"]]}],"coOccurrence":[["line_chart","bar_chart",["coOccurrence"]]],"year":2007,"conference":["VAST"],"authors":["Heidi Lam","Daniel M. Russell","Diane Tang","Tamara Munzner"],"title":"Session Viewer: Visual Exploratory Analysis of Web Session Logs","doi":"10.1109/VAST.2007.4389008","abstract":"Large-scale session log analysis typically includes statistical methods and detailed log examinations. While both methods have merits, statistical methods can miss previously unknown sub- populations in the data and detailed analyses may have selection biases. We therefore built Session Viewer, a visualization tool to facilitate and bridge between statistical and detailed analyses. Taking a multiple-coordinated view approach, Session Viewer shows multiple session populations at the Aggregate, Multiple, and Detail data levels to support different analysis styles. To bridge between the statistical and the detailed analysis levels, Session Viewer provides fluid traversal between data levels and side-by-side comparison at all data levels. We describe an analysis of a large-scale web usage study to demonstrate the use of Session Viewer, where we quantified the importance of grouping sessions based on task type.","keywords":"Web session log analysis, visual exploratory data analysis, information visualization","caption":"Figure 9: Examples to show how the Session Attributes Panel reveals trends and correlations. Top population: (a) Low satisfaction scores are highlighted in orange. Sessions are reordered by Outcome and by Satisfaction. Since the orange-highlighted sessions with low satisfaction scores cluster with the Failure and Given-up outcomes, the panel shows a high correlation between task outcome and satisfaction score in this population. Bottom population: (b1) Satisfaction score and task outcome are not correlated, as seen by the lack of clustering of low satisfaction scores in the Failure and Given-up sessions. (b2) Instead, we see the ResultClick event count correlates with task outcome, as shown by the cluster of highlighted unsuccessful sessions with low ResultClick counts on the left.","img_size":{"width":1697,"height":753},"subfigures":[{"x":-1.5379289544107397,"y":183.907128592972,"width":868.2079178931341,"height":560.3890511471878,"type":"single","id":"single-1"}],"visualizations":[{"x":8.954612005856537,"y":187.42313323572478,"width":846.7115666178626,"height":190.7306002928258,"type":"bar_chart","id":"bar_chart-0"},{"x":27.696925329429014,"y":369.33382137628115,"width":821.3543191800879,"height":380.98230904364874,"type":"bar_chart","id":"bar_chart-1"},{"x":873.3060029282578,"y":372.6412884333823,"width":821.0101274916719,"height":377.0512445095169,"type":"bar_chart","id":"bar_chart-2"},{"x":874.4084919472915,"y":192.93557833089315,"width":819.9076384726383,"height":177.5007320644217,"type":"bar_chart","id":"bar_chart-3"},{"x":5.647144948755517,"y":13.2298682284041,"width":759.614934114202,"height":152.1434846266472,"type":"bar_chart","id":"bar_chart-4"},{"x":4.544655929721841,"y":9.922401171303074,"width":1689.771474490208,"height":162.06588579795027,"type":"line_chart","id":"line_chart-5"},{"x":7.852122986822862,"y":184.11566617862377,"width":844.506588579795,"height":188.52562225475847,"type":"line_chart","id":"line_chart-6"},{"x":874.4084919472915,"y":194.0380673499268,"width":819.9076384726383,"height":173.090775988287,"type":"line_chart","id":"line_chart-7"},{"x":6.749633967789186,"y":373.74377745241594,"width":841.1991215226941,"height":376.572352967514,"type":"unit_visualization","id":"unit_visualization-8"},{"x":873.3060029282578,"y":371.53879941434855,"width":821.0101274916719,"height":378.7773310055814,"type":"unit_visualization","id":"unit_visualization-9"}],"relations":[{"vislist":[{"vislist":["line_chart-5","line_chart-6","line_chart-7"],"relation":null,"id":"group-0"}],"relation":"repeated","id":"relation-0"},{"vislist":[{"vislist":["bar_chart-0","bar_chart-1","bar_chart-2","bar_chart-3","bar_chart-4"],"relation":null,"id":"group-2"}],"relation":"repeated","id":"relation-1"}]},"1586_1":{"comp":[["line_chart","bar_chart",["repeated"]],["bar_chart","line_chart",["repeated"]]],"visType":["line_chart","bar_chart"],"compType":["repeated"],"compressed_tree":[{"composite_pattern":"repeated","visualization_type":[["line_chart","bar_chart"]]}],"coOccurrence":[["line_chart","line_chart",["coOccurrence"]]],"year":2007,"conference":["VAST"],"authors":["Remco Chang","Mohammad Ghoniem","Robert Kosara","William Ribarsky","Jing Yan","Evan A. Suma","Caroline Ziemkiewicz","Daniel A. Kern","Agus Sudjianto"],"title":"WireVis: Visualization of Categorical, Time-Varying Data From Financial Transactions","doi":"10.1109/VAST.2007.4389009","abstract":"Large financial institutions such as Bank of America handle hundreds of thousands of wire transactions per day. Although most transactions are legitimate, these institutions have legal and financial obligations in discovering those that are suspicious. With the methods of fraudulent activities ever changing, searching on predefined patterns is often insufficient in detecting previously undiscovered methods. In this paper, we present a set of coordinated visualizations based on identifying specific keywords within the wire transactions. The different views used in our system depict relationships among keywords and accounts over time. Furthermore, we introduce a search-by-example technique which extracts accounts that show similar transaction patterns. In collaboration with the Anti-Money Laundering division at Bank of America, we demonstrate that using our tool, investigators are able to detect accounts and transactions that exhibit suspicious behaviors.","keywords":"Fraud detection, financial data visualization, categorial and time-varying data","caption":"Figure 2: A view of the entire system showing the heatmap (top left), search by example (top right), keyword graph (lower right), and strings and beads (lower left).","img_size":{"width":2110,"height":1308},"subfigures":[{"x":7.413651103639965,"y":6.085148407136653,"width":2100.9431130947332,"height":1298.7139358516501,"type":"interface","id":"interface-0"}],"visualizations":[{"x":1380.5351197026264,"y":77.29969530484618,"width":655.4648802973733,"height":128.17156906296987,"type":"bar_chart","id":"bar_chart-0"},{"x":13.862068965517208,"y":100.22988505747125,"width":1345.5862068965514,"height":551.2643678160919,"type":"heatmap","id":"heatmap-1"},{"x":3.8390804597701167,"y":756.7356321839081,"width":1581.1264367816093,"height":531.2183908045976,"type":"line_chart","id":"line_chart-2"},{"x":1378.7366353439913,"y":239.163287581925,"width":654.6483065428517,"height":100.71512408351569,"type":"bar_chart","id":"bar_chart-3"},{"x":1382.3336040612598,"y":350.66931781724594,"width":651.0513378255835,"height":98.91663972488146,"type":"bar_chart","id":"bar_chart-4"},{"x":1382.3336040612598,"y":460.37686369393265,"width":651.0513378255835,"height":97.1181553662472,"type":"bar_chart","id":"bar_chart-5"},{"x":1690.206896551724,"y":829.4022988505745,"width":353.310344827586,"height":388.3908045977011,"type":"scatterplot","id":"scatterplot-6"}],"relations":[{"vislist":[{"vislist":["line_chart-3","bar_chart-0","line_chart-4","line_chart-5"],"relation":null,"id":"group-0"}],"relation":"repeated","id":"relation-0"}]},"1598_0":{"comp":[["table","table",["repeated"]]],"visType":["table"],"compType":["repeated"],"compressed_tree":[{"composite_pattern":"repeated","visualization_type":[["table"]]}],"coOccurrence":[["table","table",["coOccurrence"]]],"year":2007,"conference":["VAST"],"authors":["Hyunmo Kang","Lise Getoor","Lisa Singh"],"title":"C-GROUP: A Visual Analytic Tool for Pairwise Analysis of Dynamic Group Membership","doi":"10.1109/VAST.2007.4389022","abstract":"C-GROUP is a tool for analyzing dynamic group membership in social networks over time. Unlike most network visualization tools, which show the group structure within an entire network, or the group membership for a single actor, C-GROUP allows users to focus their analysis on a pair of individuals of interest. And unlike most dynamic social network visualization tools, which focus on the addition and deletion of nodes (actors) and edges (relationships) over time, C-GROUP focuses on changing group memberships over time. C-GROUP provides users with a flexible interface for defining (and redefining) groups interactively, and allows users to view the changing group memberships for the pair over time. This helps to highlight the similarities and differences between the individuals and their evolving group memberships. C-GROUP allows users to dynamically select the time granularity of the temporal evolution and supports two novel visual representations of the evolving group memberships. This flexibility gives users alternate views that are appropriate for different network sizes and provides users with different insights into the grouping behavior.","keywords":"","caption":"Figure 1. (a) Overview of C-GROUP (b)-(d) The evolution of author groups in the dynamic group layout view","img_size":{"width":1766,"height":1671},"subfigures":[{"x":125.33491451110554,"y":0.19314217507329434,"width":1505.3838383172983,"height":1110.8013071377682,"type":"interface","id":"interface-0"}],"visualizations":[{"x":661.5863836017568,"y":137.0073206442167,"width":902.7803806734995,"height":628.7657393850659,"type":"graph","id":"graph-0"},{"x":4.445000106403354,"y":1225.7262079062955,"width":656.6932650073205,"height":381.6632503660321,"type":"graph","id":"graph-1"},{"x":666.4795021961932,"y":1144.9897510980966,"width":555.368960468521,"height":481.9721815519765,"type":"graph","id":"graph-2"},{"x":1234.0812591508052,"y":1137.6500732064421,"width":527.4737407427915,"height":496.65153733528535,"type":"graph","id":"graph-3"},{"x":152.70204978038058,"y":773.1127379209369,"width":406.12884333821376,"height":278.90775988286964,"type":"table","id":"table-4"},{"x":580.8499267935576,"y":773.1127379209369,"width":1030.0014641288435,"height":112.54172767203521,"type":"table","id":"table-5"},{"x":571.0636896046851,"y":915.0131771595899,"width":540.6896046852123,"height":144.34699853587108,"type":"table","id":"table-6"},{"x":1143.5585651537335,"y":917.4597364568082,"width":472.1859443631038,"height":144.34699853587117,"type":"table","id":"table-7"},{"x":162.48828696925307,"y":88.07613469985358,"width":401.23572474377767,"height":156.57979502196193,"type":"table","id":"table-8"}],"relations":[{"vislist":[{"vislist":["table-4","table-5","table-6","table-7","table-8"],"relation":null,"id":"group-0"}],"relation":"repeated","id":"relation-0"}]},"1602_1":{"comp":[["heatmap","heatmap",["repeated"]]],"visType":["heatmap"],"compType":["repeated"],"compressed_tree":[{"composite_pattern":"repeated","visualization_type":[["heatmap"]]}],"coOccurrence":[["heatmap","heatmap",["coOccurrence"]]],"year":2007,"conference":["VAST"],"authors":["Cecilia R. Aragon","Stephen J. Bailey","Sarah S. Poon","Karl J. Runge","Rollin C. Thomas"],"title":"Sunfall: A Collaborative Visual Analytics System for Astrophysics","doi":"10.1109/VAST.2007.4389026","abstract":"Computational and experimental sciences produce and collect ever- larger and complex datasets, often in large-scale, multi-institution projects. The inability to gain insight into complex scientific phenomena using current software tools is a bottleneck facing virtually all endeavors of science. In this paper, we introduce Sunfall, a collaborative visual analytics system developed for the Nearby Supernova Factory, an international astrophysics experiment and the largest data volume supernova search currently in operation. Sunfall utilizes novel interactive visualization and analysis techniques to facilitate deeper scientific insight into complex, noisy, high-dimensional, high-volume, time-critical data. The system combines novel image processing algorithms, statistical analysis, and machine learning with highly interactive visual interfaces to enable collaborative, user-driven scientific exploration of supernova image and spectral data. Sunfall is currently in operation at the Nearby Supernova Factory; it is the first visual analytics system in production use at a major astrophysics project.","keywords":"","caption":"Figure 2. SNwarehouse Data Taking window. The observer can follow the targets on the Sky visualization, take notes on the success or failure of each observation, telescope status and weather conditions, and reschedule targets if necessary.","img_size":{"width":1059,"height":954},"subfigures":[{"x":3.2747203397951834,"y":4.419721305135624,"width":1053.50267849435,"height":943.0569198031137,"type":"interface","id":"interface-0"}],"visualizations":[{"x":20.374084919472924,"y":569.8857979502196,"width":237.45241581259154,"height":169.01024890190342,"type":"heatmap","id":"heatmap-0"},{"x":5.009516837481669,"y":142.4714494875549,"width":977.7452415812593,"height":266.78477306002935,"type":"line_chart","id":"line_chart-1"},{"x":255.0329428989752,"y":581.0600292825769,"width":196.94582723279643,"height":160.62957540263537,"type":"line_chart","id":"line_chart-2"}],"relations":[{"vislist":[{"vislist":["heatmap-0"],"relation":null,"id":"group-0"}],"relation":"repeated","id":"relation-0"}]},"1610_0":{"comp":[["table","table",["repeated"]]],"visType":["table"],"compType":["repeated"],"compressed_tree":[{"composite_pattern":"repeated","visualization_type":[["table"]]}],"coOccurrence":[["table","table",["coOccurrence"]]],"year":2007,"conference":["VAST"],"authors":["Patricia Crossno","Brian N. Wylie","Andrew T. Wilson","John A. Greenfield","Eric T. Stanton","Timothy M. Shead","Lisa G. Ice","Kenneth Moreland","Jeffrey Baumes","Berk Geveci"],"title":"Intelligence Analysis Using Titan","doi":"10.1109/VAST.2007.4389036","abstract":"The open source Titan informatics toolkit project, which extends the visualization toolkit (VTK) to include information visualization capabilities, is being developed by Sandia National Laboratories in collaboration with Kitware. The VAST Contest provided us with an opportunity to explore various ideas for constructing an analysis tool, while allowing us to exercise our architecture in the solution of a complex problem. As amateur analysts, we found the experience both enlightening and fun.","keywords":"","caption":"Figure 1. DatabaseView - full interface with all query windows.","img_size":{"width":1006,"height":622},"subfigures":[{"x":-0.9599294886898613,"y":2.1103797503391855,"width":1003.9982658600402,"height":614.8397549249328,"type":"interface","id":"interface-0"}],"visualizations":[{"x":138.33380480905234,"y":219.0636492220651,"width":663.3493635077793,"height":329.0353606789251,"type":"graph","id":"graph-0"},{"x":147.13154172560112,"y":51.026874115983034,"width":654.5516265912306,"height":167.15700141442716,"type":"table","id":"table-1"},{"x":1.6545721521142345,"y":278.8882602545969,"width":126.68741159830269,"height":102.93352192362096,"type":"table","id":"table-2"},{"x":802.5629420084864,"y":50.14710042432816,"width":189.15134370579923,"height":190.91089108910896,"type":"table","id":"table-3"}],"relations":[{"vislist":[{"vislist":["table-1","table-2","table-3"],"relation":null,"id":"group-0"}],"relation":"repeated","id":"relation-0"}]},"2078_0":{"comp":[["map","map",["repeated"]]],"visType":["map"],"compType":["repeated"],"compressed_tree":[{"composite_pattern":"repeated","visualization_type":[["map"]]}],"coOccurrence":[["map","map",["coOccurrence"]]],"year":2011,"conference":["InfoVis"],"authors":["Nivan Ferreira","Lauro Didier Lins","Daniel Fink","Steve Kelling","Christopher Wood","Juliana Freire","Cl\xe1udio T. Silva"],"title":"BirdVis: Visualizing and Understanding Bird Populations","doi":"10.1109/TVCG.2011.176","abstract":"Birds are unrivaled windows into biotic processes at all levels and are proven indicators of ecological well-being. Understanding the determinants of species distributions and their dynamics is an important aspect of ecology and is critical for conservation and management. Through crowdsourcing, since 2002, the eBird project has been collecting bird observation records. These observations, together with local-scale environmental covariates such as climate, habitat, and vegetation phenology have been a valuable resource for a global community of educators, land managers, ornithologists, and conservation biologists. By associating environmental inputs with observed patterns of bird occurrence, predictive models have been developed that provide a statistical framework to harness available data for predicting species distributions and making inferences about species-habitat associations. Understanding these models, however, is challenging because they require scientists to quantify and compare multiscale spatialtemporal patterns. A large series of coordinated or sequential plots must be generated, individually programmed, and manually composed for analysis. This hampers the exploration and is a barrier to making the cross-species comparisons that are essential for coordinating conservation and extracting important ecological information. To address these limitations, as part of a collaboration among computer scientists, statisticians, biologists and ornithologists, we have developed BirdVis, an interactive visualization system that supports the analysis of spatio-temporal bird distribution models. BirdVis leverages visualization techniques and uses them in a novel way to better assist users in the exploration of interdependencies among model parameters. Furthermore, the system allows for comparative visualization through coordinated views, providing an intuitive interface to identify relevant correlations and patterns. We justify our design decisions and present case studies that show how BirdVis has helped scientists obtain new evidence for existing hypotheses, as well as formulate new hypotheses in their domain.","keywords":"Ornithology, species distribution models, multiscale analysis, spatial data, temporal data","caption":"Fig. 1. Tag cloud lenses in BirdVis are used as a tool to explore and understand relative habitat preferences suggested by a species distribution model over space, time, and across species. Here, we show occurrence maps for the Indigo Bunting. The lenses cover three different regions on three different dates of the breeding season of 2009: May 4, June 22, and August 24, 2009. They show important differences in habitat preferences across these regions as well as how the preferences change over time within a region. The ability to interact with these visualizations, by changing regions and dates, and comparing different bird species, provides an unprecedented tool for scientists to understand bird distribution and consequently obtain insights about the environment and how it changes over time. The supplemental video gives an overview of different features and visualizations provided by BirdVis.","img_size":{"width":1899,"height":760},"subfigures":[{"x":30.7643067371402,"y":3.360964228274441,"width":1863.204737838881,"height":747.3395285222422,"type":"interface","id":"interface-0"}],"visualizations":[{"x":226.13622917754356,"y":210.94443654201547,"width":546.4879692011549,"height":466.06833493743983,"type":"heatmap","id":"heatmap-0"},{"x":772.6241983786985,"y":209.1167175814765,"width":544.6602502406157,"height":467.8960538979788,"type":"heatmap","id":"heatmap-1"},{"x":1322.7676055009313,"y":209.1167175814765,"width":544.6602502406157,"height":467.8960538979788,"type":"heatmap","id":"heatmap-2"},{"x":615.3445447087778,"y":32.602953240360954,"width":1001.6874487284662,"height":171.36177194421663,"type":"line_chart","id":"line_chart-3"},{"x":226.13622917754356,"y":214.59987446309344,"width":542.8325312800769,"height":466.0683349374398,"type":"map","id":"map-4"},{"x":776.2796362997764,"y":212.7721555025545,"width":539.1770933589988,"height":464.24061597690087,"type":"map","id":"map-5"},{"x":1322.7676055009313,"y":214.59987446309344,"width":542.8325312800769,"height":462.41289701636185,"type":"map","id":"map-6"}],"relations":[{"vislist":[{"vislist":["map-4","map-5","map-6"],"relation":null,"id":"group-0"}],"relation":"repeated","id":"relation-0"}]},"2080_7":{"comp":[["area_chart","area_chart",["repeated"]]],"visType":["area_chart"],"compType":["repeated"],"compressed_tree":[{"composite_pattern":"repeated","visualization_type":[["area_chart"]]}],"coOccurrence":[["area_chart","area_chart",["coOccurrence"]]],"year":2011,"conference":["InfoVis"],"authors":["Milos Krstajic","Enrico Bertini","Daniel A. Keim"],"title":"CloudLines: Compact Display of Event Episodes in Multiple Time-Series","doi":"10.1109/TVCG.2011.179","abstract":"We propose incremental logarithmic time-series technique as a way to deal with time-based representations of large and dynamic event data sets in limited space. Modern data visualization problems in the domains of news analysis, network security and financial applications, require visual analysis of incremental data, which poses specific challenges that are normally not solved by static visualizations. The incremental nature of the data implies that visualizations have to necessarily change their content and still provide comprehensible representations. In particular, in this paper we deal with the need to keep an eye on recent events together with providing a context on the past and to make relevant patterns accessible at any scale. Our technique adapts to the incoming data by taking care of the rate at which data items occur and by using a decay function to let the items fade away according to their relevance. Since access to details is also important, we also provide a novel distortion magnifying lens technique which takes into account the distortions introduced by the logarithmic time scale to augment readability in selected areas of interest. We demonstrate the validity of our techniques by applying them on incremental data coming from online news streams in different time frames.","keywords":"Incremental Visualization, Event-based Data, Lens Distortion","caption":"Fig. 8. CloudLines applied on the news entities data taken during February 2011. Dataset consisting of around 117,000 events for 16 politicians with the highest volume during the whole month are shown (names are displayed on the right side). Compact visualization immediately reveals important event episodes. The \ufb01ne structure of the data, such as the \u201dpulse\u201d of online publishing is also visible, showing higher activity in the afternoons. Detailed analysis of the visualization is given in the Subsection 6.1.","img_size":{"width":2142,"height":789},"subfigures":[{"x":10.191470269554939,"y":8.97393743553933,"width":2126.0826355546083,"height":769.9354801050118,"type":"interface","id":"interface-0"}],"visualizations":[{"x":4.0187617260787984,"y":4.010318949343315,"width":1803.084427767354,"height":774.281425891182,"type":"area_chart","id":"area_chart-0"},{"x":3.3876538836241252,"y":5.349906191369584,"width":1807.103189493433,"height":768.9230769230768,"type":"scatterplot","id":"scatterplot-1"}],"relations":[{"vislist":[{"vislist":["area_chart-0"],"relation":null,"id":"group-0"}],"relation":"repeated","id":"relation-0"}]},"2081_10":{"comp":[["map","map",["repeated"]]],"visType":["map"],"compType":["repeated"],"compressed_tree":[{"composite_pattern":"repeated","visualization_type":[["map"]]}],"coOccurrence":[["map","map",["coOccurrence"]]],"year":2011,"conference":["InfoVis"],"authors":["Roeland Scheepens","Niels Willems","Huub van de Wetering","Gennady L. Andrienko","Natalia V. Andrienko","Jarke J. van Wijk"],"title":"Composite Density Maps for Multivariate Trajectories","doi":"10.1109/TVCG.2011.181","abstract":"We consider moving objects as multivariate time-series. By visually analyzing the attributes, patterns may appear that explain why certain movements have occurred. Density maps as proposed by Scheepens et al. [25] are a way to reveal these patterns by means of aggregations of filtered subsets of trajectories. Since filtering is often not sufficient for analysts to express their domain knowledge, we propose to use expressions instead. We present a flexible architecture for density maps to enable custom, versatile exploration using multiple density fields. The flexibility comes from a script, depicted in this paper as a block diagram, which defines an advanced computation of a density field. We define six different types of blocks to create, compose, and enhance trajectories or density fields. Blocks are customized by means of expressions that allow the analyst to model domain knowledge. The versatility of our architecture is demonstrated with several maritime use cases developed with domain experts. Our approach is expected to be useful for the analysis of objects in other domains.","keywords":"Trajectories, Kernel Density Estimation, Multivariate Data, Geographical Information Systems, Raster Maps","caption":"Fig. 13. Interactions around Rotterdam harbor with \u03b2 = 60\u25e6 , \u03b3 = 30\u25e6 , N = 12, and the arrows show vessels overtaking each other. (a) An overview of all vessels using r\u03b1 (t) = do (t), (b) all interactions within a time interval of two minutes in color and an overview of all movements used as illuminated height \ufb01eld, and (c) all vessel interactions with a course difference of at least \u03b2 . The block diagram for density map c is shown at the bottom.","img_size":{"width":2154,"height":1665},"subfigures":[{"x":14.828623470828033,"y":14.773351645517625,"width":2131.4302366997426,"height":1638.9972590006475,"type":"interface","id":"interface-0"}],"visualizations":[{"x":355.7853470437019,"y":1378.2262210796914,"width":1763.4447300771203,"height":261.0925449871465,"type":"flow_diagram","id":"flow_diagram-0"},{"x":1445.847864768683,"y":669.5551601423487,"width":664.8218010410855,"height":661.5887987265456,"type":"heatmap","id":"heatmap-1"},{"x":320.0471530249109,"y":663.6298932384341,"width":1122.910430522647,"height":667.5140656304603,"type":"heatmap","id":"heatmap-2"},{"x":29.70907473309603,"y":699.1814946619218,"width":278.9940100998087,"height":280.9856004537595,"type":"heatmap","id":"heatmap-3"},{"x":6.0080071174376135,"y":1007.2953736654805,"width":306.9752833709943,"height":302.44755692577917,"type":"heatmap","id":"heatmap-4"},{"x":13.368894601542479,"y":21.40102827763496,"width":1082.8920308483291,"height":642.0308483290488,"type":"heatmap","id":"heatmap-5"},{"x":1090.6742351796058,"y":4.429039603328297,"width":1058.8967252170658,"height":663.4318766066838,"type":"heatmap","id":"heatmap-6"},{"x":77.57197943444726,"y":1403.9074550128535,"width":261.0925449871465,"height":235.41131105398446,"type":"pie_chart","id":"pie_chart-7"},{"x":21.92930591259642,"y":697.6735218508998,"width":291.05398457583556,"height":295.3341902313624,"type":"map","id":"map-8"},{"x":17.64910025706945,"y":1014.4087403598971,"width":295.33419023136247,"height":291.05398457583556,"type":"map","id":"map-9"},{"x":320.0471530249109,"y":663.6298932384341,"width":1122.910430522647,"height":684.6348882525683,"type":"map","id":"map-10"},{"x":1442.957583547558,"y":667.7120822622107,"width":671.9922879177375,"height":667.7120822622107,"type":"map","id":"map-11"},{"x":1096.2609254498716,"y":4.429039603328297,"width":1053.3100349468,"height":659.1516709511567,"type":"map","id":"map-12"},{"x":10.107261630215362,"y":26.34179398341996,"width":1087.5609345432376,"height":639.9474309370177,"type":"map","id":"map-13"}],"relations":[{"vislist":[{"vislist":["map-13","map-8","map-9","map-10","map-11","map-12"],"relation":null,"id":"group-0"}],"relation":"repeated","id":"relation-0"}]},"2082_0":{"comp":[["heatmap","heatmap",["repeated"]],["flow_diagram","flow_diagram",["repeated"]]],"visType":["heatmap","flow_diagram"],"compType":["repeated"],"compressed_tree":[{"composite_pattern":"repeated","visualization_type":[["heatmap"]]},{"composite_pattern":"repeated","visualization_type":[["flow_diagram"]]}],"coOccurrence":[["heatmap","flow_diagram",["coOccurrence"]]],"year":2011,"conference":["InfoVis"],"authors":["Markus Steinberger","Manuela Waldner","Marc Streit","Alexander Lex","Dieter Schmalstieg"],"title":"Context-Preserving Visual Links","doi":"10.1109/TVCG.2011.183","abstract":"Evaluating, comparing, and interpreting related pieces of information are tasks that are commonly performed during visual data analysis and in many kinds of information-intensive work. Synchronized visual highlighting of related elements is a well-known technique used to assist this task. An alternative approach, which is more invasive but also more expressive is visual linking in which line connections are rendered between related elements. In this work, we present context-preserving visual links as a new method for generating visual links. The method specifically aims to fulfill the following two goals: first, visual links should minimize the occlusion of important information; second, links should visually stand out from surrounding information by minimizing visual interference. We employ an image-based analysis of visual saliency to determine the important regions in the original representation. A consequence of the image-based approach is that our technique is application-independent and can be employed in a large number of visual data analysis scenarios in which the underlying content cannot or should not be altered. We conducted a controlled experiment that indicates that users can find linked elements in complex visualizations more quickly and with greater subjective satisfaction than in complex visualizations in which plain highlighting is used. Context-preserving visual links were perceived as visually more attractive than traditional visual links that do not account for the context information.","keywords":"Visual links, highlighting, connectedness, routing, image-based, saliency","caption":"Fig. 1. Context-preserving visual links connecting related entities in an information visualization framework. Note that the links avoid occlusion of salient regions and, therefore, choose their routes along the window borders. The small inset shows the visual saliency derived from the base representation.","img_size":{"width":1898,"height":1000},"subfigures":[{"x":6.957084929056762,"y":9.922799795150768,"width":1854.3056257581425,"height":981.2186533501432,"type":"interface","id":"interface-0"}],"visualizations":[{"x":1243.7295423023575,"y":496.5325936199722,"width":303.74479889043005,"height":438.28016643550615,"type":"flow_diagram","id":"flow_diagram-0"},{"x":1640.4008321775307,"y":493.75866851595,"width":101.24826629681,"height":92.9264909847434,"type":"flow_diagram","id":"flow_diagram-1"},{"x":1643.174757281553,"y":600.5547850208044,"width":104.02219140083207,"height":102.63522884882104,"type":"flow_diagram","id":"flow_diagram-2"},{"x":1641.7877947295417,"y":729.5423023578362,"width":95.70041608876545,"height":87.37864077669906,"type":"flow_diagram","id":"flow_diagram-3"},{"x":1641.7877947295417,"y":830.7905686546462,"width":101.24826629681,"height":97.0873786407767,"type":"flow_diagram","id":"flow_diagram-4"},{"x":476.1831414730326,"y":797.0290326311009,"width":117.7015965174403,"height":174.25950653231405,"type":"flow_diagram","id":"flow_diagram-5"},{"x":638.2139107048334,"y":793.9718483059725,"width":38.21480406410399,"height":30.5718432512831,"type":"flow_diagram","id":"flow_diagram-6"},{"x":638.2139107048334,"y":841.3582053454614,"width":39.7433962266681,"height":30.57184325128321,"type":"flow_diagram","id":"flow_diagram-7"},{"x":636.6853185422692,"y":887.2159702223862,"width":39.7433962266681,"height":35.15761973897565,"type":"flow_diagram","id":"flow_diagram-8"},{"x":636.6853185422692,"y":934.6023272618751,"width":42.80058055179643,"height":36.686211901539764,"type":"flow_diagram","id":"flow_diagram-9"},{"x":780.4840499306515,"y":113.73092926490983,"width":226.07489597780864,"height":378.640776699029,"type":"heatmap","id":"heatmap-10"},{"x":575.2135922330095,"y":112.34396671289872,"width":155.3398058252427,"height":373.09292649098467,"type":"heatmap","id":"heatmap-11"},{"x":395.1677568571322,"y":647.2270006998133,"width":191.07402032051974,"height":113.11582002974772,"type":"heatmap","id":"heatmap-12"},{"x":194.9221835612274,"y":634.9982633993001,"width":62.672278665130534,"height":149.80203193128747,"type":"heatmap","id":"heatmap-13"},{"x":278.9947525022561,"y":631.9410790741716,"width":93.24412191641369,"height":154.38780841898003,"type":"heatmap","id":"heatmap-14"},{"x":98.62087731968542,"y":838.301021020333,"width":290.4325108871901,"height":136.04470246821018,"type":"line_chart","id":"line_chart-15"},{"x":13.019716216092519,"y":894.8589310352069,"width":87.12975326615704,"height":77.95820029077207,"type":"line_chart","id":"line_chart-16"},{"x":727.7794729542301,"y":611.6504854368931,"width":328.71012482662957,"height":328.71012482662957,"type":"parallel_coordinate","id":"parallel_coordinate-17"},{"x":1073.1331484049929,"y":135.92233009708733,"width":447.0274362710017,"height":265.4166020214579,"type":"scatterplot","id":"scatterplot-18"},{"x":1559.9039809026629,"y":150.64981745802322,"width":252.217706823086,"height":244.5747460102654,"type":"sunburst_icicle","id":"sunburst_icicle-19"},{"x":603.0562909658578,"y":647.2270006998133,"width":105.47285921692696,"height":105.47285921692696,"type":"sunburst_icicle","id":"sunburst_icicle-20"},{"x":386.5866851595006,"y":112.34396671289872,"width":145.63106796116494,"height":368.9320388349514,"type":"tree","id":"tree-21"},{"x":109.32102245763453,"y":634.9982633993001,"width":67.258055152823,"height":149.80203193128747,"type":"tree","id":"tree-22"}],"relations":[{"vislist":[{"vislist":["heatmap-10","heatmap-11"],"relation":null,"id":"group-0"}],"relation":"repeated","id":"relation-0"},{"vislist":[{"vislist":["flow_diagram-2","flow_diagram-3","flow_diagram-1","flow_diagram-4","flow_diagram-0"],"relation":null,"id":"group-2"}],"relation":"repeated","id":"relation-1"}]},"2084_9":{"comp":[["comb","comb",["repeated"]],["graph","map",["coordinated"]]],"visType":["comb","graph","map"],"compType":["repeated","coordinated"],"compressed_tree":[{"composite_pattern":"repeated","visualization_type":[[{"composite_pattern":"coordinated","visualization_type":[["graph"],["map"]]}]]}],"coOccurrence":[["graph","map",["coOccurrence"]]],"year":2011,"conference":["InfoVis"],"authors":["Basak Alper","Nathalie Henry Riche","Gonzalo Ramos","Mary Czerwinski"],"title":"Design Study of LineSets, a Novel Set Visualization Technique","doi":"10.1109/TVCG.2011.186","abstract":"Computing and visualizing sets of elements and their relationships is one of the most common tasks one performs when analyzing and organizing large amounts of data. Common representations of sets such as convex or concave geometries can become cluttered and difficult to parse when these sets overlap in multiple or complex ways, e.g., when multiple elements belong to multiple sets. In this paper, we present a design study of a novel set visual representation, LineSets, consisting of a curve connecting all of the set\'s elements. Our approach to design the visualization differs from traditional methodology used by the InfoVis community. We first explored the potential of the visualization concept by running a controlled experiment comparing our design sketches to results from the state-of-the-art technique. Our results demonstrated that LineSets are advantageous for certain tasks when compared to concave shapes. We discuss an implementation of LineSets based on simple heuristics and present a study demonstrating that our generated curves do as well as human-drawn ones. Finally, we present two applications of our technique in the context of search tasks on a map and community analysis tasks in social networks.","keywords":"Set visualization, clustering, faceted data visualization, graph visualization","caption":"Fig. 9. Application with category selector area (A), map visualization (B) and list view (C) sections. Detail of the list view (upper right) shows the flattened versions of LineSets. In the close up view (bottom right), element A is an exact match to user specified criteria with 3 concentric rings around black dot, whereas element B matches only a subset of the criteria.","img_size":{"width":1863,"height":1006},"subfigures":[{"x":12.483495314598727,"y":9.977755224400587,"width":1840.1733145065016,"height":986.0444895511985,"type":"interface","id":"interface-0"}],"visualizations":[{"x":20.71414913957941,"y":17.311648804644552,"width":950.2179732313574,"height":971.3766730401529,"type":"map","id":"map-0"},{"x":1251.765774378585,"y":577.0554346555049,"width":597.7695984703633,"height":413.5564200290075,"type":"map","id":"map-1"},{"x":22.82375478927199,"y":19.272030651340998,"width":946.2567049808431,"height":967.4559386973183,"type":"graph","id":"graph-2"},{"x":1251.765774378585,"y":577.0554346555049,"width":594.3671128107073,"height":411.63288718929255,"type":"graph","id":"graph-3"}],"relations":[{"vislist":[{"vislist":[{"vislist":[{"vislist":["graph-2"],"relation":null,"id":"group-1"},{"vislist":["map-0"],"relation":null,"id":"group-0"}],"relation":"coordinated","id":"relation-0"},{"vislist":[{"vislist":["graph-3"],"relation":null,"id":"group-3"},{"vislist":["map-1"],"relation":null,"id":"group-2"}],"relation":"coordinated","id":"relation-1"}],"relation":null,"id":"group-4"}],"relation":"repeated","id":"relation-2"}]},"2092_6":{"comp":[["bar_chart","bar_chart",["repeated"]]],"visType":["bar_chart"],"compType":["repeated"],"compressed_tree":[{"composite_pattern":"repeated","visualization_type":[["bar_chart"]]}],"coOccurrence":[["bar_chart","bar_chart",["coOccurrence"]]],"year":2011,"conference":["InfoVis"],"authors":["Johnny Rodgers","Lyn Bartram"],"title":"Exploring Ambient and Artistic Visualization for Residential Energy Use Feedback","doi":"10.1109/TVCG.2011.196","abstract":"Providing effective feedback on resource consumption in the home is a key challenge of environmental conservation efforts. One promising approach for providing feedback about residential energy consumption is the use of ambient and artistic visualizations. Pervasive computing technologies enable the integration of such feedback into the home in the form of distributed point-of-consumption feedback devices to support decision-making in everyday activities. However, introducing these devices into the home requires sensitivity to the domestic context. In this paper we describe three abstract visualizations and suggest four design requirements that this type of device must meet to be effective: pragmatic, aesthetic, ambient, and ecological. We report on the findings from a mixed methods user study that explores the viability of using ambient and artistic feedback in the home based on these requirements. Our findings suggest that this approach is a viable way to provide resource use feedback and that both the aesthetics of the representation and the context of use are important elements that must be considered in this design space.","keywords":"Ambient visualization, informative art, casual infovis, sustainability, distributed visualization","caption":"Fig. 7. Comprehension in aggregate (left) and by display design. Responses that explicitly articulated the data mappings in the visualization were coded as \u02bbcorrect,\u02bc generally articulated mappings were coded \u02bbgood,\u02bc partial comprehension was coded \u02bbfair,\u02bc and incorrect or lack of comprehension was coded \u02bbnone.\u02bc","img_size":{"width":1026,"height":717},"subfigures":[{"x":7.348418169047296,"y":6.3357724777210995,"width":1016.6441689455064,"height":699.7500388947632,"type":"single","id":"single-0"}],"visualizations":[{"x":17.667938931297787,"y":9.122137404580204,"width":492.5954198473283,"height":698.7557251908396,"type":"bar_chart","id":"bar_chart-0"},{"x":521.2099236641222,"y":36.48854961832066,"width":499.89312977099235,"height":218.93129770992365,"type":"bar_chart","id":"bar_chart-1"},{"x":524.8587786259543,"y":255.41984732824432,"width":499.2339412565765,"height":215.28244274809163,"type":"bar_chart","id":"bar_chart-2"},{"x":524.8587786259543,"y":470.70229007633594,"width":496.24427480916034,"height":237.1755725190839,"type":"bar_chart","id":"bar_chart-3"}],"relations":[{"vislist":[{"vislist":["bar_chart-0","bar_chart-1","bar_chart-2","bar_chart-3"],"relation":null,"id":"group-0"}],"relation":"repeated","id":"relation-0"}]},"2092_9":{"comp":[["scatterplot","scatterplot",["repeated"]]],"visType":["scatterplot"],"compType":["repeated"],"compressed_tree":[{"composite_pattern":"repeated","visualization_type":[["scatterplot"]]}],"coOccurrence":[["scatterplot","scatterplot",["coOccurrence"]]],"year":2011,"conference":["InfoVis"],"authors":["Johnny Rodgers","Lyn Bartram"],"title":"Exploring Ambient and Artistic Visualization for Residential Energy Use Feedback","doi":"10.1109/TVCG.2011.196","abstract":"Providing effective feedback on resource consumption in the home is a key challenge of environmental conservation efforts. One promising approach for providing feedback about residential energy consumption is the use of ambient and artistic visualizations. Pervasive computing technologies enable the integration of such feedback into the home in the form of distributed point-of-consumption feedback devices to support decision-making in everyday activities. However, introducing these devices into the home requires sensitivity to the domestic context. In this paper we describe three abstract visualizations and suggest four design requirements that this type of device must meet to be effective: pragmatic, aesthetic, ambient, and ecological. We report on the findings from a mixed methods user study that explores the viability of using ambient and artistic feedback in the home based on these requirements. Our findings suggest that this approach is a viable way to provide resource use feedback and that both the aesthetics of the representation and the context of use are important elements that must be considered in this design space.","keywords":"Ambient visualization, informative art, casual infovis, sustainability, distributed visualization","caption":"Fig. 10. Display preference in aggregate (left) and by display design. At right, the X-axis indicates participant preference, while the Y-axis indicates which visualization design the participant was exposed to during the scenario activity.","img_size":{"width":1059,"height":642},"subfigures":[{"x":4.12517752605347,"y":4.295499060368053,"width":1051.4326443720975,"height":634.7755026547953,"type":"single","id":"single-0"}],"visualizations":[{"x":17.370229007633554,"y":6.534351145038168,"width":444.33587786259545,"height":624.030534351145,"type":"bar_chart","id":"bar_chart-0"},{"x":466.01571367775085,"y":91.55331322486263,"width":583.2121880131924,"height":188.32621999508294,"type":"scatterplot","id":"scatterplot-1"},{"x":469.446920642265,"y":272.06525713044925,"width":586.5947654472327,"height":158.67877025024217,"type":"scatterplot","id":"scatterplot-2"},{"x":471.4844724738125,"y":427.95987973721316,"width":583.2026612083441,"height":185.78171736846951,"type":"scatterplot","id":"scatterplot-3"}],"relations":[{"vislist":[{"vislist":["scatterplot-1","scatterplot-2","scatterplot-3"],"relation":null,"id":"group-0"}],"relation":"repeated","id":"relation-0"}]},"2093_8":{"comp":[["word_cloud","word_cloud",["repeated"]]],"visType":["word_cloud"],"compType":["repeated"],"compressed_tree":[{"composite_pattern":"repeated","visualization_type":[["word_cloud"]]}],"coOccurrence":[["word_cloud","word_cloud",["coOccurrence"]]],"year":2011,"conference":["InfoVis"],"authors":["Aidan Slingsby","Jason Dykes","Jo Wood"],"title":"Exploring Uncertainty in Geodemographics with Interactive Graphics","doi":"10.1109/TVCG.2011.197","abstract":"Geodemographic classifiers characterise populations by categorising geographical areas according to the demographic and lifestyle characteristics of those who live within them. The dimension-reducing quality of such classifiers provides a simple and effective means of characterising population through a manageable set of categories, but inevitably hides heterogeneity, which varies within and between the demographic categories and geographical areas, sometimes systematically. This may have implications for their use, which is widespread in government and commerce for planning, marketing and related activities. We use novel interactive graphics to delve into OAC - a free and open geodemographic classifier that classifies the UK population in over 200,000 small geographical areas into 7 super-groups, 21 groups and 52 sub-groups. Our graphics provide access to the original 41 demographic variables used in the classification and the uncertainty associated with the classification of each geographical area on-demand. It also supports comparison geographically and by category. This serves the dual purpose of helping understand the classifier itself leading to its more informed use and providing a more comprehensive view of population in a comprehensible manner. We assess the impact of these interactive graphics on experienced OAC users who explored the details of the classification, its uncertainty and the nature of between - and within - class variation and then reflect on their experiences. Visualization of the complexities and subtleties of the classification proved to be a thought-provoking exercise both confirming and challenging users\' understanding of population, the OAC classifier and the way it is used in their organisations. Users identified three contexts for which the techniques were deemed useful in the context of local government, confirming the validity of the proposed methods.","keywords":"Geodemographics, OAC, classification, cartography, uncertainty","caption":"Fig. 8. The N postcode area in North London has been selected (other OAs are faded out) and this saved selection (see top left) is being dis-played (see left-aligned [display] label). The legend indicates over half the people in N are in OAs classified as \u2018Multicultural\u2019. The barchart shows that the OA indicated by the mouse cursor is strongly similar to both \u2018City Living\u2019 and \u2018Multicultural\u2019, a common situation London. These two population profiles are shown (see left-aligned [display] labels in thelegend) for this spatial selection (N) along with the OA identified with the mouse (thin black line), showing similar variables values except therightmost variable (wholesale/retail trade employment), identifiable witha tooltip in the software. See Fig. 3 for help with interpretation.","img_size":{"width":1068,"height":826},"subfigures":[{"x":7.079738076001666,"y":17.803353890605994,"width":1061.7560828876085,"height":797.4258756492471,"type":"interface","id":"interface-0"}],"visualizations":[{"x":947.0000000000002,"y":176.54961832061068,"width":118.80277074333371,"height":630.534351145038,"type":"area_chart","id":"area_chart-0"},{"x":947.0000000000002,"y":81.96946564885496,"width":117.6997455470736,"height":90.37659033078883,"type":"bar_chart","id":"bar_chart-1"},{"x":135.7124681933842,"y":693.587786259542,"width":798.676844783715,"height":113.49618320610683,"type":"line_chart","id":"line_chart-2"},{"x":13.809160305343541,"y":634.7379134860051,"width":96.68193384223925,"height":176.54961832061062,"type":"word_cloud","id":"word_cloud-3"},{"x":127.30534351145036,"y":563.2773536895675,"width":735.6234096692112,"height":130.31043256997452,"type":"word_cloud","id":"word_cloud-4"},{"x":123.10178117048349,"y":210.17811704834605,"width":58.84987277353685,"height":348.8956743002544,"type":"word_cloud","id":"word_cloud-5"},{"x":867.1323155216286,"y":218.58524173027993,"width":71.46055979643756,"height":475.00254452926214,"type":"word_cloud","id":"word_cloud-6"},{"x":135.7124681933842,"y":16.814249363867685,"width":802.880407124682,"height":189.16030534351145,"type":"word_cloud","id":"word_cloud-7"}],"relations":[{"vislist":[{"vislist":["word_cloud-3","word_cloud-4","word_cloud-5","word_cloud-6","word_cloud-7"],"relation":null,"id":"group-0"}],"relation":"repeated","id":"relation-0"}]},"2097_2":{"comp":[["matrix","matrix",["repeated"]]],"visType":["matrix"],"compType":["repeated"],"compressed_tree":[{"composite_pattern":"repeated","visualization_type":[["matrix"]]},{"composite_pattern":"repeated","visualization_type":[["matrix"]]},{"composite_pattern":"repeated","visualization_type":[["matrix"]]}],"coOccurrence":[["matrix","matrix",["coOccurrence"]]],"year":2011,"conference":["InfoVis"],"authors":["David Lloyd","Jason Dykes"],"title":"Human-Centered Approaches in Geovisualization Design: Investigating Multiple Methods Through a Long-Term Case Study","doi":"10.1109/TVCG.2011.209","abstract":"Working with three domain specialists we investigate human-centered approaches to geovisualization following an ISO13407 taxonomy covering context of use, requirements and early stages of design. Our case study, undertaken over three years, draws attention to repeating trends: that generic approaches fail to elicit adequate requirements for geovis application design; that the use of real data is key to understanding needs and possibilities; that trust and knowledge must be built and developed with collaborators. These processes take time but modified human-centred approaches can be effective. A scenario developed through contextual inquiry but supplemented with domain data and graphics is useful to geovis designers. Wireframe, paper and digital prototypes enable successful communication between specialist and geovis domains when incorporating real and interesting data, prompting exploratory behaviour and eliciting previously unconsidered requirements. Paper prototypes are particularly successful at eliciting suggestions, especially for novel visualization. Enabling specialists to explore their data freely with a digital prototype is as effective as using a structured task protocol and is easier to administer. Autoethnography has potential for framing the design process. We conclude that a common understanding of context of use, domain data and visualization possibilities are essential to successful geovis design and develop as this progresses. HC approaches can make a significant contribution here. However, modified approaches, applied with flexibility, are most promising. We advise early, collaborative engagement with data - through simple, transient visual artefacts supported by data sketches and existing designs - before moving to successively more sophisticated data wireframes and data prototypes.","keywords":"Evaluation, geovisualization, context of use, requirements, field study, prototypes, sketching, design","caption":"Fig. 3. Wireframe prototype (foreground), containing spatial (map), tem- poral (glyphs) and crime attribute (tree map) data. Other sheets (back- ground) show alternative states of the wireframe.","img_size":{"width":1086,"height":840},"subfigures":[{"x":139.2535745581532,"y":395.41645439777807,"width":546.2999574484613,"height":421.05963871351406,"type":"interface","id":"interface-0"},{"x":439.5195713857556,"y":41.881655850171235,"width":597.8557011709399,"height":538.1074056260672,"type":"interface","id":"interface-1"},{"x":23.489675677211018,"y":10.4974446446755,"width":644.5478198615475,"height":511.47858103968707,"type":"interface","id":"interface-2"}],"visualizations":[{"x":526.1034482758621,"y":43.448275862068975,"width":191.49425287356314,"height":196.3218390804598,"type":"map","id":"map-0"},{"x":493.91954022988506,"y":204.36781609195407,"width":185.0574712643678,"height":180.22988505747125,"type":"map","id":"map-1"},{"x":2.2344704305079692,"y":16.09195402298851,"width":661.2758620689654,"height":511.7241379310346,"type":"glyph_based","id":"glyph_based-2"},{"x":143.11494252873572,"y":391.0344827586207,"width":548.7356321839079,"height":416.7816091954024,"type":"glyph_based","id":"glyph_based-3"},{"x":472.99999999999994,"y":74.02298850574712,"width":555.1724137931034,"height":494.02298850574726,"type":"glyph_based","id":"glyph_based-4"},{"x":143.11494252873572,"y":395.86206896551727,"width":548.7356321839079,"height":413.5632183908046,"type":"matrix","id":"matrix-5"},{"x":3.1149425287356394,"y":16.09195402298851,"width":662.9885057471265,"height":510.1149425287357,"type":"matrix","id":"matrix-6"},{"x":654.8390804597701,"y":78.85057471264368,"width":373.33333333333314,"height":397.4712643678161,"type":"matrix","id":"matrix-7"}],"relations":[{"vislist":[{"vislist":["matrix-6"],"relation":null,"id":"group-0"}],"relation":"repeated","id":"relation-0"},{"vislist":[{"vislist":["matrix-7"],"relation":null,"id":"group-2"}],"relation":"repeated","id":"relation-1"},{"vislist":[{"vislist":["matrix-5"],"relation":null,"id":"group-3"}],"relation":"repeated","id":"relation-2"}]},"2099_3":{"comp":[["graph","graph",["repeated"]]],"visType":["graph"],"compType":["repeated"],"compressed_tree":[{"composite_pattern":"repeated","visualization_type":[["graph"]]}],"coOccurrence":[["graph","graph",["coOccurrence"]]],"year":2011,"conference":["InfoVis"],"authors":["Steffen Hadlak","Hans-J\xf6rg Schulz","Heidrun Schumann"],"title":"In Situ Exploration of Large Dynamic Networks","doi":"10.1109/TVCG.2011.213","abstract":"The analysis of large dynamic networks poses a challenge in many fields, ranging from large bot-nets to social networks. As dynamic networks exhibit different characteristics, e.g., being of sparse or dense structure, or having a continuous or discrete time line, a variety of visualization techniques have been specifically designed to handle these different aspects of network structure and time. This wide range of existing techniques is well justified, as rarely a single visualization is suitable to cover the entire visual analysis. Instead, visual representations are often switched in the course of the exploration of dynamic graphs as the focus of analysis shifts between the temporal and the structural aspects of the data. To support such a switching in a seamless and intuitive manner, we introduce the concept of in situ visualization- a novel strategy that tightly integrates existing visualization techniques for dynamic networks. It does so by allowing the user to interactively select in a base visualization a region for which a different visualization technique is then applied and embedded in the selection made. This permits to change the way a locally selected group of data items, such as nodes or time points, are shown - right in the place where they are positioned, thus supporting the user\'s overall mental map. Using this approach, a user can switch seamlessly between different visual representations to adapt a region of a base visualization to the specifics of the data within it or to the current analysis focus. This paper presents and discusses the in situ visualization strategy and its implications for dynamic graph visualization. Furthermore, it illustrates its usefulness by employing it for the visual exploration of dynamic networks from two different fields: model versioning and wireless mesh networks.","keywords":"Dynamic graph data, multiform visualization, multi-focus+context","caption":"Fig. 3. Visualization of the revision graph of a biological model. The base visualization is showing the branching temporal aspect as an overview, whereby color corresponds to the structural complexity of each model revision. Two selections are made on a number of consecutive time steps of branch7, each showing a supergraph visualization of these model revisions. A \ufb01sheye is utilized to enlarge these selections. An initial simulation parameter for this model is mapped on the color of the nodes. Nodes of interest are selected and thus substituted with a time-value-plot \u2013 in two cases using eccentric positioning.","img_size":{"width":2061,"height":927},"subfigures":[{"x":24.781267874766108,"y":17.317165349096534,"width":2013.5858191358884,"height":893.4397013414697,"type":"interface","id":"interface-0"}],"visualizations":[{"x":556.4509246088194,"y":162.19203413940252,"width":685.6899004267425,"height":592.0668563300143,"type":"graph","id":"graph-0"},{"x":1279.0625889046942,"y":166.14793741109528,"width":683.0526315789474,"height":584.1550497866286,"type":"graph","id":"graph-1"},{"x":54.05120910384078,"y":90.98577524893312,"width":1960.8093883357037,"height":795.1365576102417,"type":"tree","id":"tree-2"}],"relations":[{"vislist":[{"vislist":["graph-0","graph-1"],"relation":null,"id":"group-0"}],"relation":"repeated","id":"relation-0"}]},"2109_12":{"comp":[["word_cloud","word_cloud",["repeated"]]],"visType":["word_cloud"],"compType":["repeated"],"compressed_tree":[{"composite_pattern":"repeated","visualization_type":[["word_cloud"]]}],"coOccurrence":[["word_cloud","word_cloud",["coOccurrence"]]],"year":2011,"conference":["InfoVis"],"authors":["Weiwei Cui","Shixia Liu","Li Tan","Conglei Shi","Yangqiu Song","Zekai Gao","Huamin Qu","Xin Tong"],"title":"TextFlow: Towards Better Understanding of Evolving Topics in Text","doi":"10.1109/TVCG.2011.239","abstract":"Understanding how topics evolve in text data is an important and challenging task. Although much work has been devoted to topic analysis, the study of topic evolution has largely been limited to individual topics. In this paper, we introduce TextFlow, a seamless integration of visualization and topic mining techniques, for analyzing various evolution patterns that emerge from multiple topics. We first extend an existing analysis technique to extract three-level features: the topic evolution trend, the critical event, and the keyword correlation. Then a coherent visualization that consists of three new visual components is designed to convey complex relationships between them. Through interaction, the topic mining model and visualization can communicate with each other to help users refine the analysis result and gain insights into the data progressively. Finally, two case studies are conducted to demonstrate the effectiveness and usefulness of TextFlow in helping users understand the major topic evolution patterns in time-varying text data.","keywords":"Text visualization, Topic evolution, Hierarchical Dirichlet process, Critical event","caption":"Fig. 13. Topic \ufb02ows for VisWeek publication data: (a) topics related to scienti\ufb01c visualization; (b) topics related to information visualization.","img_size":{"width":1065,"height":686},"subfigures":[{"x":8.841935417638101,"y":11.911423755759337,"width":1023.9592641995093,"height":672.3982377285134,"type":"single","id":"single-0"}],"visualizations":[{"x":46.36513994910945,"y":15.709923664122137,"width":972.269720101781,"height":474.7888040712468,"type":"sankey_diagram","id":"sankey_diagram-0"},{"x":4.472010178117046,"y":495.735368956743,"width":179.7913486005089,"height":186.7735368956742,"type":"word_cloud","id":"word_cloud-1"},{"x":184.26335877862593,"y":490.49872773536896,"width":872.773536895674,"height":190.26463104325697,"type":"word_cloud","id":"word_cloud-2"}],"relations":[{"vislist":[{"vislist":["word_cloud-1","word_cloud-2"],"relation":null,"id":"group-0"}],"relation":"repeated","id":"relation-0"}]},"2113_3":{"comp":[["others","others",["repeated"]]],"visType":["others"],"compType":["repeated"],"compressed_tree":[{"composite_pattern":"repeated","visualization_type":[["others"]]}],"coOccurrence":[["others","others",["coOccurrence"]]],"year":2011,"conference":["InfoVis"],"authors":["A. Johannes Pretorius","Mark-Anthony Bray","Anne E. Carpenter","Roy A. Ruddle"],"title":"Visualization of Parameter Space for Image Analysis","doi":"10.1109/TVCG.2011.253","abstract":"Image analysis algorithms are often highly parameterized and much human input is needed to optimize parameter settings. This incurs a time cost of up to several days. We analyze and characterize the conventional parameter optimization process for image analysis and formulate user requirements. With this as input, we propose a change in paradigm by optimizing parameters based on parameter sampling and interactive visual exploration. To save time and reduce memory load, users are only involved in the first step - initialization of sampling - and the last step - visual analysis of output. This helps users to more thoroughly explore the parameter space and produce higher quality results. We describe a custom sampling plug-in we developed for CellProfiler - a popular biomedical image analysis framework. Our main focus is the development of an interactive visualization technique that enables users to analyze the relationships between sampled input parameters and corresponding output. We implemented this in a prototype called Paramorama. It provides users with a visual overview of parameters and their sampled values. User-defined areas of interest are presented in a structured way that includes image-based output and a novel layout algorithm. To find optimal parameter settings, users can tag high- and low-quality results to refine their search. We include two case studies to illustrate the utility of this approach.","keywords":"Information visualization, visual analytics, parameter space, image analysis, sampling","caption":"Fig. 4. Visualization of parameter space for image analysis. (a) The overview shows sampled parameter values as a clustering hierarchy. (b) The re\ufb01nement view shows scaled previews of the image-based outcomes for selected subtrees in the clustering hierarchy. (c) The reference image view superimposes the output that currently has the focus in the re\ufb01nement view on a reference image. (d) Selected subtrees are highlighted in blue in the overview and (e) shown in distinct regions in the re\ufb01nement view. (f) Users can specify a level in the clustering tree at which to position subtrees side-by-side in the re\ufb01nement view. Further interactive features include: (g) brushing; tagging of (h) high-quality and (i) low- quality outcomes; and (j) \ufb01ltering. The data set shown here was generated by sampling the parameter space of the IdentifyPrimaryObjects module in CellPro\ufb01ler for human HT29 cells (5 parameters, 4 samples each, yielding 1,024 outcomes). At this point the user has identi\ufb01ed and tagged a number of high-quality outcomes where all cells have been detected (coded in green in the overview and detail view). The user has also tagged low-quality outcomes where all cells have not been detected (magenta). The distribution of green and magenta in the overview indicates which parts of parameter space to consider and which parts to disregard.","img_size":{"width":2022,"height":1220},"subfigures":[{"x":44.97053218628812,"y":27.604488347541892,"width":1939.8495680211242,"height":1180.3716863530285,"type":"interface","id":"interface-0"}],"visualizations":[{"x":332.8066630449414,"y":110.05875258073084,"width":1375.863254894364,"height":1046.6244839828796,"type":"others","id":"others-1"},{"x":60.942528735632266,"y":88.81226053639848,"width":250.0766283524905,"height":1091.455938697318,"type":"tree","id":"tree-0"}],"relations":[{"vislist":[{"vislist":["others-1"],"relation":null,"id":"group-0"}],"relation":"repeated","id":"relation-0"}]},"2115_0":{"comp":[["scatterplot","scatterplot",["repeated"]]],"visType":["scatterplot"],"compType":["repeated"],"compressed_tree":[{"composite_pattern":"repeated","visualization_type":[["scatterplot"]]}],"coOccurrence":[["scatterplot","scatterplot",["coOccurrence"]]],"year":2011,"conference":["VAST"],"authors":["Bum Chul Kwon","Brian D. Fisher","Ji Soo Yi"],"title":"Visual analytic roadblocks for novice investigators","doi":"10.1109/VAST.2011.6102435","abstract":"We have observed increasing interest in visual analytics tools and their applications in investigative analysis. Despite the growing interest and substantial studies regarding the topic, understanding the major roadblocks of using such tools from novice users\' perspectives is still limited. Therefore, we attempted to identify such \u201cvisual analytic roadblocks\u201d for novice users in an investigative analysis scenario. To achieve this goal, we reviewed the existing models, theories, and frameworks that could explain the cognitive processes of human-visualization interaction in investigative analysis. Then, we conducted a qualitative experiment with six novice participants, using a slightly modified version of pair analytics, and analyzed the results through the open-coding method. As a result, we came up with four visual analytic roadblocks and explained these roadblocks using existing cognitive models and theories. We also provided design suggestions to overcome these roadblocks.","keywords":"Visual analytics, investigative analysis, cognitive model, framework, roadblock, qualitative experiment","caption":"Figure 1: The ten views of Jigsaw used in this study. (Top row) Document, List, Document Cluster, Graph, Document Grid; (Bottom row) Cal- endar, Timeline, WordTree, Scatterplot, Circular Graph. Figures are captured from (http://www.cc.gatech.edu/gvu/ii/jigsaw/views.html).","img_size":{"width":2115,"height":648},"subfigures":[{"x":8.978096822262225,"y":9.205235729106098,"width":2103.657737334613,"height":633.9992863303419,"type":"interface","id":"interface-0"}],"visualizations":[{"x":432.02214930270736,"y":344.8203445447088,"width":369.5611156685809,"height":286.27973748974574,"type":"bar_chart","id":"bar_chart-0"},{"x":1691.6529942575885,"y":343.0853158326498,"width":412.9368334700571,"height":294.954881050041,"type":"chord_diagram","id":"chord_diagram-1"},{"x":1271.7760459392946,"y":42.9253486464315,"width":411.2018047579987,"height":275.8695652173914,"type":"graph","id":"graph-2"},{"x":1698.5931091058246,"y":89.7711238720263,"width":399.05660377358487,"height":192.5881870385562,"type":"heatmap","id":"heatmap-3"},{"x":10.410172272354586,"y":348.290401968827,"width":412.9368334700574,"height":289.7497949138639,"type":"matrix","id":"matrix-4"},{"x":1695.1230516817066,"y":91.50615258408536,"width":400.79163248564373,"height":190.85315832649712,"type":"matrix","id":"matrix-5"},{"x":938.6505332239544,"y":27.310090237899942,"width":324.4503691550453,"height":294.954881050041,"type":"scatterplot","id":"scatterplot-6"},{"x":1273.5110746513537,"y":348.290401968827,"width":409.46677604593947,"height":284.54470877768665,"type":"scatterplot","id":"scatterplot-7"},{"x":848.4290401968831,"y":351.76045939294505,"width":412.9368334700574,"height":275.8695652173913,"type":"tree","id":"tree-8"}],"relations":[{"vislist":[{"vislist":["scatterplot-6"],"relation":null,"id":"group-0"}],"relation":"repeated","id":"relation-0"}]},"2116_0":{"comp":[["scatterplot","scatterplot",["repeated"]]],"visType":["scatterplot"],"compType":["repeated"],"compressed_tree":[{"composite_pattern":"repeated","visualization_type":[["scatterplot"]]}],"coOccurrence":[["scatterplot","scatterplot",["coOccurrence"]]],"year":2011,"conference":["VAST"],"authors":["Georgia Albuquerque","Martin Eisemann","Marcus A. Magnor"],"title":"Perception-based visual quality measures","doi":"10.1109/VAST.2011.6102437","abstract":"In recent years diverse quality measures to support the exploration of high-dimensional data sets have been proposed. Such measures can be very useful to rank and select information-bearing projections of very high dimensional data, when the visual exploration of all possible projections becomes unfeasible. But even though a ranking of the low dimensional projections may support the user in the visual exploration task, different measures deliver different distances between the views that do not necessarily match the expectations of human perception. As an alternative solution, we propose a perception-based approach that, similar to the existing measures, can be used to select information bearing projections of the data. Specifically, we construct a perceptual embedding for the different projections based on the data from a psychophysics study and multi-dimensional scaling. This embedding together with a ranking function is then used to estimate the value of the projections for a specific user task in a perceptual sense.","keywords":"","caption":"Figure 2: Screenshot of the distance comparison test. A series of scatterplot triplets is presented to each participant of the study. For each triplet, the participant is asked to decide which of the lateral images is more similar to the central one.","img_size":{"width":1014,"height":477},"subfigures":[{"x":4.301081447051773,"y":5.400150175161233,"width":1006.983304248414,"height":466.1996996496776,"type":"interface","id":"interface-0"}],"visualizations":[{"x":24.25929978118166,"y":52.18818380743982,"width":307.910284463895,"height":311.0415754923413,"type":"scatterplot","id":"scatterplot-0"},{"x":356.176148796499,"y":52.18818380743982,"width":304.77899343544857,"height":306.8665207877462,"type":"scatterplot","id":"scatterplot-1"},{"x":672.4365426695842,"y":55.319474835886204,"width":302.6914660831509,"height":307.910284463895,"type":"scatterplot","id":"scatterplot-2"}],"relations":[{"vislist":[{"vislist":["scatterplot-0","scatterplot-1","scatterplot-2"],"relation":null,"id":"group-0"}],"relation":"repeated","id":"relation-0"}]},"2118_2":{"comp":[["bar_chart","bar_chart",["repeated"]],["tree","tree",["repeated"]]],"visType":["bar_chart","tree"],"compType":["repeated"],"compressed_tree":[{"composite_pattern":"repeated","visualization_type":[["bar_chart"]]},{"composite_pattern":"repeated","visualization_type":[["tree"]]}],"coOccurrence":[["bar_chart","tree",["coOccurrence"]]],"year":2011,"conference":["VAST"],"authors":["Sebastian Bremm","Tatiana von Landesberger","Martin Hess","Tobias Schreck","Philipp Weil","Kay Hamacher"],"title":"Interactive visual comparison of multiple trees","doi":"10.1109/VAST.2011.6102439","abstract":"Traditionally, the visual analysis of hierarchies, respectively, trees, is conducted by focusing on one given hierarchy. However, in many research areas multiple, differing hierarchies need to be analyzed simultaneously in a comparative way - in particular to highlight differences between them, which sometimes can be subtle. A prominent example is the analysis of so-called phylogenetic trees in biology, reflecting hierarchical evolutionary relationships among a set of organisms. Typically, the analysis considers multiple phylogenetic trees, either to account for statistical significance or for differences in derivation of such evolutionary hierarchies; for example, based on different input data, such as the 16S ribosomal RNA and protein sequences of highly conserved enzymes. The simultaneous analysis of a collection of such trees leads to more insight into the evolutionary process. We introduce a novel visual analytics approach for the comparison of multiple hierarchies focusing on both global and local structures. A new tree comparison score has been elaborated for the identification of interesting patterns. We developed a set of linked hierarchy views showing the results of automatic tree comparison on various levels of details. This combined approach offers detailed assessment of local and global tree similarities. The approach was developed in close cooperation with experts from the evolutionary biology domain. We apply it to a phylogenetic data set on bacterial ancestry, demonstrating its application benefit.","keywords":"","caption":"Figure 3: Overview of our approach showing a visualization of mul- tiple levels of detail for tree comparison. 1) Global pairwise tree dis- tance matrix. 2) Score distribution for 1:n tree comparison. 3) Con- sensus tree for 1:n comparison with average matching scores. 4) Selected trees with scores showing similarity to the reference tree. Selected nodes (pink) are highlighted in all views.","img_size":{"width":1017,"height":636},"subfigures":[{"x":4.3146323061573755,"y":3.6254322868997884,"width":1009.7234544112466,"height":628.7491354262,"type":"interface","id":"interface-0"}],"visualizations":[{"x":13.011627906976768,"y":264.1196013289037,"width":271.51495016611295,"height":163.7541528239203,"type":"bar_chart","id":"bar_chart-0"},{"x":18.294019933554836,"y":100.36544850498339,"width":265.17607973421923,"height":142.62458471760797,"type":"heatmap","id":"heatmap-1"},{"x":14.068106312292372,"y":96.13953488372091,"width":268.34551495016615,"height":146.85049833887044,"type":"matrix","id":"matrix-2"},{"x":305.656146179402,"y":70.78405315614619,"width":347.58139534883713,"height":270.45847176079735,"type":"tree","id":"tree-5"},{"x":656.4069767441858,"y":67.61461794019934,"width":345.468438538206,"height":271.51495016611295,"type":"tree","id":"tree-6"},{"x":656.4069767441858,"y":356.0332225913621,"width":342.2990033222592,"height":267.28903654485055,"type":"tree","id":"tree-7"},{"x":305.656146179402,"y":352.8637873754153,"width":342.29900332225907,"height":268.34551495016615,"type":"tree","id":"tree-8"},{"x":13.011627906976768,"y":433.156146179402,"width":289.4750830564784,"height":186.9966777408638,"type":"tree","id":"tree-9"}],"relations":[{"vislist":[{"vislist":["bar_chart-0"],"relation":null,"id":"group-2"}],"relation":"repeated","id":"relation-2"},{"vislist":[{"vislist":["tree-5","tree-6","tree-8","tree-7"],"relation":null,"id":"group-3"}],"relation":"repeated","id":"relation-3"}]},"2126_1":{"comp":[["bar_chart","bar_chart",["repeated"]]],"visType":["bar_chart"],"compType":["repeated"],"compressed_tree":[{"composite_pattern":"repeated","visualization_type":[["bar_chart"]]}],"coOccurrence":[["bar_chart","bar_chart",["coOccurrence"]]],"year":2011,"conference":["VAST"],"authors":["Thorsten May","Andreas Bannach","James Davey","Tobias Ruppert","J\xf6rn Kohlhammer"],"title":"Guiding feature subset selection with an interactive visualization","doi":"10.1109/VAST.2011.6102448","abstract":"We propose a method for the semi-automated refinement of the results of feature subset selection algorithms. Feature subset selection is a preliminary step in data analysis which identifies the most useful subset of features (columns) in a data table. So-called filter techniques use statistical ranking measures for the correlation of features. Usually a measure is applied to all entities (rows) of a data table. However, the differing contributions of subsets of data entities are masked by statistical aggregation. Feature and entity subset selection are, thus, highly interdependent. Due to the difficulty in visualizing a high-dimensional data table, most feature subset selection algorithms are applied as a black box at the outset of an analysis. Our visualization technique, SmartStripes, allows users to step into the feature subset selection process. It enables the investigation of dependencies and interdependencies between different feature and entity subsets. A user may even choose to control the iterations manually, taking into account the ranking measures, the contributions of different entity subsets, as well as the semantics of the features.","keywords":"","caption":"Figure 2: Overview of the SmartStripes interface. (1) The feature partition view. (2) The dependency view. (3) Value subset labels. (4) Feature labels and feature relevance visualized in the form of a bar chart. The target feature label is black, the hue and saturation of the other labels is determined by their quality.","img_size":{"width":1701,"height":1074},"subfigures":[{"x":5.382779068179819,"y":5.004238755637979,"width":1690.23444186364,"height":1067.4205454628373,"type":"interface","id":"interface-0"}],"visualizations":[{"x":211.80897009966773,"y":37.465116279069754,"width":1480.764119601329,"height":1013.3421926910296,"type":"bar_chart","id":"bar_chart-1"},{"x":10.21096345514951,"y":21.40863787375415,"width":158.78073089700996,"height":1043.671096345515,"type":"bar_chart","id":"bar_chart-2"},{"x":208.24086378737536,"y":37.465116279069754,"width":1484.3322259136212,"height":1009.7740863787375,"type":"heatmap","id":"heatmap-4"},{"x":208.24086378737536,"y":37.465116279069754,"width":1484.3322259136212,"height":1009.7740863787375,"type":"heatmap","id":"heatmap-5"}],"relations":[{"vislist":[{"vislist":["bar_chart-2"],"relation":null,"id":"group-0"}],"relation":"repeated","id":"relation-0"}]},"2130_3":{"comp":[["area_chart","area_chart",["repeated"]],["area_chart","bar_chart",["stacked"]],["comb","sankey_diagram",["nested"]],["bar_chart","area_chart",["stacked"]]],"visType":["area_chart","bar_chart","comb","sankey_diagram"],"compType":["repeated","stacked","nested"],"compressed_tree":[{"composite_pattern":"repeated","visualization_type":[["area_chart"]]},{"composite_pattern":"nested","visualization_type":[[{"composite_pattern":"stacked","visualization_type":[["area_chart","bar_chart"]]}],["sankey_diagram"]]}],"coOccurrence":[["area_chart","bar_chart",["coOccurrence"]],["area_chart","sankey_diagram",["coOccurrence"]],["bar_chart","sankey_diagram",["coOccurrence"]]],"year":2011,"conference":["VAST"],"authors":["Stef van den Elzen","Jarke J. van Wijk"],"title":"BaobabView: Interactive construction and analysis of decision trees","doi":"10.1109/VAST.2011.6102453","abstract":"We present a system for the interactive construction and analysis of decision trees that enables domain experts to bring in domain specific knowledge. We identify different user tasks and corresponding requirements, and develop a system incorporating a tight integration of visualization, interaction and algorithmic support. Domain experts are supported in growing, pruning, optimizing and analysing decision trees. Furthermore, we present a scalable decision tree visualization optimized for exploration. We show the effectiveness of our approach by applying the methods to two use cases. The first case illustrates the advantages of interactive construction, the second case demonstrates the effectiveness of analysis of decision trees and exploration of the structure of the data.","keywords":"","caption":"Figure 3: Interface of the interactive decision tree construction software with according proposed decision tree visualization; Based on adapted node-link diagram. Nodes contain important decision tree components. Links are visualized as a stream of items.","img_size":{"width":2109,"height":894},"subfigures":[{"x":282.2729184034756,"y":1.838695534218881,"width":1487.296040055123,"height":890.3226089315631,"type":"interface","id":"interface-0"}],"visualizations":[{"x":406.2363977485928,"y":98.13789868667916,"width":120.0243902439024,"height":77.81801125703565,"type":"area_chart","id":"area_chart-0"},{"x":408.874296435272,"y":189.14540337711065,"width":118.70544090056279,"height":87.05065666041273,"type":"area_chart","id":"area_chart-1"},{"x":664.9026128985709,"y":70.23002960425447,"width":723.1566984944902,"height":639.9168937411966,"type":"area_chart","id":"area_chart-15"},{"x":407.55534709193245,"y":285.42870544090056,"width":117.38649155722322,"height":83.093808630394,"type":"area_chart","id":"area_chart-2"},{"x":398.32270168855536,"y":377.75515947467164,"width":134.53283302063784,"height":81.77485928705443,"type":"area_chart","id":"area_chart-3"},{"x":400.96060037523443,"y":475.3574108818011,"width":126.61913696060031,"height":73.86116322701697,"type":"area_chart","id":"area_chart-4"},{"x":665.9143540742074,"y":78.30399189278664,"width":725.1623408253771,"height":629.3340946543325,"type":"bar_chart","id":"bar_chart-14"},{"x":1553.7223264540335,"y":514.9258911819885,"width":201.79924953095676,"height":200.48030018761733,"type":"matrix","id":"matrix-5"},{"x":1548.446529080675,"y":84.9484052532833,"width":212.3508442776736,"height":192.56660412757978,"type":"matrix","id":"matrix-6"},{"x":663.4315196998125,"y":77.03470919324579,"width":726.7410881801125,"height":625.1819887429642,"type":"sankey_diagram","id":"sankey_diagram-7"},{"x":364.030018761726,"y":553.1754221388366,"width":221.58348968105062,"height":146.40337711069424,"type":"table","id":"table-10"},{"x":411.56823255053786,"y":794.5009916837424,"width":153.31245915264023,"height":76.65622957632011,"type":"table","id":"table-11"},{"x":581.6566604127578,"y":718.0440900562852,"width":1164.6322701688553,"height":117.38649155722328,"type":"table","id":"table-9"},{"x":663.4315196998125,"y":71.75891181988743,"width":725.422138836773,"height":630.4577861163225,"type":"area_chart","id":"area_chart-12"},{"x":1532.6191369606001,"y":293.3424015009381,"width":212.3508442776736,"height":207.07504690431517,"type":"tree","id":"tree-13"}],"relations":[{"vislist":[{"vislist":["area_chart-0","area_chart-1","area_chart-2","area_chart-3","area_chart-4"],"relation":null,"id":"group-4"}],"relation":"repeated","id":"relation-3"},{"vislist":[{"vislist":[{"vislist":[{"vislist":["area_chart-12","bar_chart-14"],"relation":null,"id":"group-5"}],"relation":"stacked","id":"relation-4"}],"relation":null,"id":"group-6"},{"vislist":["sankey_diagram-7"],"relation":null,"id":"group-7"}],"relation":"nested","id":"relation-5"}]},"2134_4":{"comp":[["line_chart","line_chart",["repeated"]]],"visType":["line_chart"],"compType":["repeated"],"compressed_tree":[{"composite_pattern":"repeated","visualization_type":[["line_chart"]]}],"coOccurrence":[["line_chart","line_chart",["coOccurrence"]]],"year":2011,"conference":["VAST"],"authors":["Shehzad Afzal","Ross Maciejewski","David S. Ebert"],"title":"Visual analytics decision support environment for epidemic modeling and response evaluation","doi":"10.1109/VAST.2011.6102457","abstract":"In modeling infectious diseases, scientists are studying the mechanisms by which diseases spread, predicting the future course of the outbreak, and evaluating strategies applied to control an epidemic. While recent work has focused on accurately modeling disease spread, less work has been performed in developing interactive decision support tools for analyzing the future course of the outbreak and evaluating potential disease mitigation strategies. The absence of such tools makes it difficult for researchers, analysts and public health officials to evaluate response measures within outbreak scenarios. As such, our research focuses on the development of an interactive decision support environment in which users can explore epidemic models and their impact. This environment provides a spatiotemporal view where users can interactively utilize mitigative response measures and observe the impact of their decision over time. Our system also provides users with a linked decision history visualization and navigation tool that support the simultaneous comparison of mortality and infection rates corresponding to different response measures at different points in time.","keywords":"","caption":"Figure 4: Here we illustrate the effects of utilizing decision measures within the confines of a pandemic influenza simulation. In the left image, the analyst has used no decision measures and is visualizing the spread of the pandemic on day 36 of the simulation. In the right image, the analyst has decided to see what effects (on day 36) deploying the strategic national stockpile on day 3 would have had on the pandemic.","img_size":{"width":2115,"height":756},"subfigures":[{"x":3.414265311662284,"y":2.080995651731835,"width":1058.761087353241,"height":747.4282910655107,"type":"interface","id":"interface-0"}],"visualizations":[{"x":170.62851782363978,"y":242.42307692307688,"width":652.0919324577862,"height":378.29268292682934,"type":"heatmap","id":"heatmap-0"},{"x":1218.208255159475,"y":243.7457786116322,"width":657.3827392120074,"height":375.64727954971863,"type":"heatmap","id":"heatmap-1"},{"x":826.688555347092,"y":49.3086303939962,"width":224.85928705440907,"height":232.79549718574108,"type":"line_chart","id":"line_chart-2"},{"x":825.3658536585366,"y":284.749530956848,"width":223.53658536585374,"height":235.44090056285182,"type":"line_chart","id":"line_chart-3"},{"x":825.3658536585366,"y":521.5131332082551,"width":226.18198874296434,"height":218.24577861163223,"type":"line_chart","id":"line_chart-4"},{"x":1878.2363977485932,"y":44.017823639774825,"width":218.24577861163198,"height":234.1181988742965,"type":"line_chart","id":"line_chart-5"},{"x":1874.2682926829273,"y":284.749530956848,"width":218.2457786116322,"height":230.15009380863043,"type":"line_chart","id":"line_chart-6"},{"x":167.9831144465291,"y":245.06848030018756,"width":657.3827392120076,"height":375.64727954971863,"type":"map","id":"map-7"},{"x":1214.2401500938086,"y":245.06848030018756,"width":662.673545966229,"height":373.001876172608,"type":"map","id":"map-8"}],"relations":[{"vislist":[{"vislist":["line_chart-2","line_chart-3","line_chart-4"],"relation":null,"id":"group-0"}],"relation":"repeated","id":"relation-0"}]},"2135_8":{"comp":[["line_chart","line_chart",["repeated"]],["graph","tree",["accompanied"]],["tree","graph",["accompanied"]]],"visType":["line_chart","graph","tree"],"compType":["repeated","accompanied"],"compressed_tree":[{"composite_pattern":"repeated","visualization_type":[["line_chart"]]},{"composite_pattern":"accompanied","visualization_type":[["graph","tree"]]}],"coOccurrence":[["line_chart","graph",["coOccurrence"]],["line_chart","tree",["coOccurrence"]],["graph","tree",["coOccurrence"]]],"year":2011,"conference":["VAST"],"authors":["Lei Shi","Qi Liao","Yuan He","Rui Li","Aaron Striegel","Zhong Su"],"title":"SAVE: Sensor anomaly visualization engine","doi":"10.1109/VAST.2011.6102458","abstract":"Diagnosing a large-scale sensor network is a crucial but challenging task. Particular challenges include the resource and bandwidth constraints on sensor nodes, the spatiotemporally dynamic network behaviors, and the lack of accurate models to understand such behaviors in a hostile environment. In this paper, we present the Sensor Anomaly Visualization Engine (SAVE), a system that fully leverages the power of both visualization and anomaly detection analytics to guide the user to quickly and accurately diagnose sensor network failures and faults. SAVE combines customized visualizations over separate sensor data facets as multiple coordinated views. Temporal expansion model, correlation graph and dynamic projection views are proposed to effectively interpret the topological, correlational and dimensional sensor data dynamics and their anomalies. Through a case study with real-world sensor network system and administrators, we demonstrate that SAVE is able to help better locate the system problem and further identify the root cause of major sensor network failure scenarios.","keywords":"","caption":"Figure 10: Validate the health of the parent node.","img_size":{"width":687,"height":657},"subfigures":[{"x":4.240535823935495,"y":2.3595323518813274,"width":679.2181940712768,"height":652.2809352962378,"type":"interface","id":"interface-0"}],"visualizations":[{"x":26.95689655172418,"y":76.77586206896552,"width":361.2241379310345,"height":343.6034482758621,"type":"graph","id":"graph-0"},{"x":395.73275862068965,"y":74.25862068965519,"width":280.6724137931035,"height":236.62068965517244,"type":"graph","id":"graph-1"},{"x":21.922413793103487,"y":500.9310344827587,"width":178.72413793103448,"height":41.53448275862069,"type":"graph","id":"graph-2"},{"x":26.95689655172418,"y":76.77586206896552,"width":361.2241379310345,"height":343.6034482758621,"type":"graph","id":"graph-3"},{"x":395.73275862068965,"y":74.25862068965519,"width":280.6724137931035,"height":236.62068965517244,"type":"graph","id":"graph-4"},{"x":21.922413793103487,"y":500.9310344827587,"width":178.72413793103448,"height":41.53448275862069,"type":"graph","id":"graph-5"},{"x":394.4741379310346,"y":480.7931034482759,"width":276.89655172413796,"height":55.37931034482756,"type":"line_chart","id":"line_chart-10"},{"x":394.4741379310346,"y":534.9137931034483,"width":276.89655172413796,"height":55.37931034482756,"type":"line_chart","id":"line_chart-11"},{"x":394.4741379310346,"y":429.18965517241384,"width":275.6379310344826,"height":51.60344827586209,"type":"line_chart","id":"line_chart-6"},{"x":394.4741379310346,"y":480.7931034482759,"width":276.89655172413796,"height":55.37931034482756,"type":"line_chart","id":"line_chart-7"},{"x":394.4741379310346,"y":534.9137931034483,"width":276.89655172413796,"height":55.37931034482756,"type":"line_chart","id":"line_chart-8"},{"x":394.4741379310346,"y":429.18965517241384,"width":275.6379310344826,"height":51.60344827586209,"type":"line_chart","id":"line_chart-9"},{"x":204.42241379310354,"y":446.8103448275863,"width":188.79310344827582,"height":109.49999999999999,"type":"tree","id":"tree-12"},{"x":26.43103448275872,"y":78.0344827586207,"width":363.0086206896552,"height":342.3448275862069,"type":"tree","id":"tree-13"},{"x":204.42241379310354,"y":446.8103448275863,"width":188.79310344827582,"height":109.49999999999999,"type":"tree","id":"tree-14"},{"x":26.43103448275872,"y":78.0344827586207,"width":363.0086206896552,"height":342.3448275862069,"type":"tree","id":"tree-15"}],"relations":[{"vislist":[{"vislist":["line_chart-9","line_chart-8","line_chart-7"],"relation":null,"id":"group-0"}],"relation":"repeated","id":"relation-0"},{"vislist":[{"vislist":["graph-3","tree-15"],"relation":null,"id":"group-1"}],"relation":"accompanied","id":"relation-1"}]},"2141_0":{"comp":[["bar_chart","bar_chart",["repeated"]],["scatterplot","scatterplot",["repeated"]]],"visType":["bar_chart","scatterplot"],"compType":["repeated"],"compressed_tree":[{"composite_pattern":"repeated","visualization_type":[["bar_chart"]]},{"composite_pattern":"repeated","visualization_type":[["scatterplot"]]}],"coOccurrence":[],"year":2011,"conference":["VAST"],"authors":["Anushka Anand","Leland Wilkinson","Dang Tuan Nhon"],"title":"Using random projections to identify class-separating variables in high-dimensional spaces","doi":"10.1109/VAST.2011.6102465","abstract":"Projection Pursuit has been an effective method for finding interesting low-dimensional (usually 2D) projections in multidimensional spaces. Unfortunately, projection pursuit is not scalable to high-dimensional spaces. We introduce a novel method for approximating the results of projection pursuit to find class-separating views by using random projections. We build an analytic visualization platform based on this algorithm that is scalable to extremely large problems. Then, we discuss its extension to the recognition of other noteworthy configurations in high-dimensional spaces.","keywords":"","caption":"Figure 1: Top: RP Explorer displaying class separating projections and variables for the Optdigits dataset. The axis-parallel scatterplots in the Variable Viewer (right panel) do not separate groups as well as the projections in the Projection Viewer (left panel) do. Bottom: RP Explorer displaying near-optimal class-separating axis-parallel pro- jections in the Variable Viewer for the Cancer dataset. The random projections in the Projection Viewer are selected to maximize the Classification Score so generally show data clearly separated.","img_size":{"width":972,"height":1218},"subfigures":[{"x":19.230920909655463,"y":11.956799759412087,"width":936.1301440910144,"height":566.6965210536131,"type":"interface","id":"interface-0"}],"visualizations":[{"x":465.4919472913617,"y":16.0497803806735,"width":301.37920937042463,"height":1162.7174231332356,"type":"bar_chart","id":"bar_chart-0"},{"x":22.8333333333336,"y":14.000000000000059,"width":919.3333333333333,"height":1169,"type":"scatterplot","id":"scatterplot-1"},{"x":25.166666666666625,"y":11.666666666666629,"width":912.3333333333334,"height":1169,"type":"small_multiple","id":"small_multiple-2"}],"relations":[{"vislist":[{"vislist":["bar_chart-0"],"relation":null,"id":"group-0"}],"relation":"repeated","id":"relation-0"},{"vislist":[{"vislist":["scatterplot-1"],"relation":null,"id":"group-1"}],"relation":"repeated","id":"relation-1"}]},"2147_0":{"comp":[["treemap","treemap",["repeated"]]],"visType":["treemap"],"compType":["repeated"],"compressed_tree":[{"composite_pattern":"repeated","visualization_type":[["treemap"]]}],"coOccurrence":[["treemap","treemap",["coOccurrence"]]],"year":2011,"conference":["VAST"],"authors":["John Alexis Guerra G\xf3mez","Audra Buck-Coleman","Catherine Plaisant","Ben Shneiderman"],"title":"TreeVersity: Comparing tree structures by topology and node\'s attributes differences","doi":"10.1109/VAST.2011.6102471","abstract":"It is common to classify data in hierarchies, they provide a comprehensible way of understanding big amounts of data. From budgets to organizational charts or even the stock market, trees are everywhere and people find them easy to use. However when analysts need to compare two versions of the same tree structure, or two related taxonomies, the task is not so easy. Much work has been done on this topic, but almost all of it has been restricted to either compare the trees by topology, or by the node attribute values. With this project we are proposing TreeVersity, a framework for comparing tree structures, both by structural changes and by differences in the node attributes. This paper is based on our previous work on comparing traffic agencies using LifeFlow [1, 2] and on a first prototype of TreeVersity.","keywords":"","caption":"Figure 2: Gas Tank Visualization representing the data from Figure 1. It shows the absolute amount of change using color and a label, and the relative difference using the amount of space filled in each node. It also shows the topological differences using again a black border. This view also allows the selection of a node along all the compared trees and the diffTree to see its details, like it was done with the \\"Receipts, Federal litigative and judiciary\\" that decreased only on $2 from 1968 to 1969.","img_size":{"width":1014,"height":609},"subfigures":[{"x":5.58133759910478,"y":4.113702612939923,"width":1002.8373248017889,"height":600.7725947741199,"type":"interface","id":"interface-0"}],"visualizations":[{"x":245.56930693069302,"y":25.841584158415838,"width":398.8217821782178,"height":279.95049504950487,"type":"heatmap","id":"heatmap-0"},{"x":650.4207920792078,"y":28.425742574257416,"width":348.86138613861385,"height":272.1980198019802,"type":"heatmap","id":"heatmap-1"},{"x":246.4306930693069,"y":325.60396039603955,"width":751.9900990099009,"height":275.64356435643566,"type":"heatmap","id":"heatmap-2"},{"x":14.717821782178218,"y":38.762376237623755,"width":192.95049504950492,"height":199.84158415841583,"type":"table","id":"table-3"},{"x":359.2722772277227,"y":43.930693069306926,"width":266.16831683168306,"height":257.55445544554453,"type":"treemap","id":"treemap-4"},{"x":762.4009900990096,"y":56.85148514851483,"width":210.17821782178225,"height":232.57425742574253,"type":"treemap","id":"treemap-5"},{"x":385.97524752475243,"y":341.10891089108907,"width":610.7227722772277,"height":258.41584158415833,"type":"treemap","id":"treemap-6"}],"relations":[{"vislist":[{"vislist":["treemap-4","treemap-5","treemap-6"],"relation":null,"id":"group-0"}],"relation":"repeated","id":"relation-0"}]},"2147_1":{"comp":[["tree","tree",["repeated"]]],"visType":["tree"],"compType":["repeated"],"compressed_tree":[{"composite_pattern":"repeated","visualization_type":[["tree"]]}],"coOccurrence":[["tree","tree",["coOccurrence"]]],"year":2011,"conference":["VAST"],"authors":["John Alexis Guerra G\xf3mez","Audra Buck-Coleman","Catherine Plaisant","Ben Shneiderman"],"title":"TreeVersity: Comparing tree structures by topology and node\'s attributes differences","doi":"10.1109/VAST.2011.6102471","abstract":"It is common to classify data in hierarchies, they provide a comprehensible way of understanding big amounts of data. From budgets to organizational charts or even the stock market, trees are everywhere and people find them easy to use. However when analysts need to compare two versions of the same tree structure, or two related taxonomies, the task is not so easy. Much work has been done on this topic, but almost all of it has been restricted to either compare the trees by topology, or by the node attribute values. With this project we are proposing TreeVersity, a framework for comparing tree structures, both by structural changes and by differences in the node attributes. This paper is based on our previous work on comparing traffic agencies using LifeFlow [1, 2] and on a first prototype of TreeVersity.","keywords":"","caption":"Figure 1: Example of the slope visualization representing a subset of a made up Federal Budget. The image shows the comparison of years 1968 vs 1969, where a cut of 58% was made on the \\"Depart- ment of Agriculture\\". Red nodes represent cuts, while green ones represent increases. The node with the black border represents a created node (topological difference).","img_size":{"width":1014,"height":609},"subfigures":[{"x":3.640186818797821,"y":4.11094087057036,"width":1004.1273401955406,"height":600.1299882181285,"type":"interface","id":"interface-0"}],"visualizations":[{"x":281.7475247524752,"y":31.009900990099005,"width":324.74257425742564,"height":274.7821782178217,"type":"heatmap","id":"heatmap-0"},{"x":649.5594059405938,"y":31.009900990099005,"width":341.97029702970275,"height":273.059405940594,"type":"heatmap","id":"heatmap-1"},{"x":273.1336633663366,"y":338.5247524752475,"width":649.4851485148513,"height":250.6633663366336,"type":"heatmap","id":"heatmap-2"},{"x":13.856435643564367,"y":36.17821782178217,"width":223.09900990099004,"height":116.28712871287127,"type":"table","id":"table-3"},{"x":391.1435643564355,"y":80.10891089108911,"width":214.48514851485146,"height":181.75247524752473,"type":"tree","id":"tree-4"},{"x":746.8960396039603,"y":80.10891089108911,"width":243.77227722772247,"height":183.47524752475243,"type":"tree","id":"tree-5"},{"x":496.2326732673267,"y":370.39603960396033,"width":426.3861386138612,"height":198.11881188118815,"type":"tree","id":"tree-6"}],"relations":[{"vislist":[{"vislist":["tree-4","tree-5","tree-6"],"relation":null,"id":"group-0"}],"relation":"repeated","id":"relation-0"}]},"2155_0":{"comp":[["bar_chart","bar_chart",["repeated"]],["line_chart","map",["large_view"]],["comb","map",["large_view"]]],"visType":["bar_chart","line_chart","map","comb"],"compType":["repeated","large_view"],"compressed_tree":[{"composite_pattern":"large_view","visualization_type":[["line_chart",{"composite_pattern":"repeated","visualization_type":[["bar_chart"]]}],["map"]]}],"coOccurrence":[["bar_chart","line_chart",["coOccurrence"]],["bar_chart","map",["coOccurrence"]],["line_chart","map",["coOccurrence"]]],"year":2011,"conference":["VAST"],"authors":["Iulian Peca","Haolin Zhi","Katerina Vrotsou","Natalia V. Andrienko","Gennady L. Andrienko"],"title":"KD-photomap: Exploring photographs in space and time","doi":"10.1109/VAST.2011.6102479","abstract":"KD-photomap is a web-based visual analytics system for browsing collections of geotagged Flickr photographs in search of interesting pictures, places, and events. Spatial filtering of the data is performed through zooming, moving or searching along the map. Temporal filtering is possible through defining time windows using interactive histograms and calendar controls. Information about the number and spatiotemporal distribution of photos captured in an explored area is continuously provided using various visual cues.","keywords":"","caption":"Figure 1: Overview of KD-photomap interface.","img_size":{"width":915,"height":658},"subfigures":[{"x":0.8262221273338259,"y":9.331614809925243,"width":912.6473546452684,"height":646.3395547282768,"type":"interface","id":"interface-0"}],"visualizations":[{"x":15.886138613861363,"y":83.76237623762376,"width":298.75247524752467,"height":64.2178217821782,"type":"bar_chart","id":"bar_chart-0"},{"x":16.81683168316829,"y":149.84158415841583,"width":295.02970297029697,"height":61.42574257425741,"type":"bar_chart","id":"bar_chart-1"},{"x":15.886138613861363,"y":212.19801980198022,"width":296.8910891089108,"height":61.42574257425741,"type":"bar_chart","id":"bar_chart-2"},{"x":16.81683168316829,"y":278.27722772277224,"width":295.02970297029697,"height":60.49504950495048,"type":"bar_chart","id":"bar_chart-3"},{"x":14.955445544554436,"y":343.4257425742574,"width":297.82178217821775,"height":65.1485148514851,"type":"bar_chart","id":"bar_chart-4"},{"x":242.04455445544548,"y":502.5742574257426,"width":89.34653465346531,"height":48.39603960396039,"type":"line_chart","id":"line_chart-10"},{"x":26.123762376237607,"y":570.5148514851485,"width":86.55445544554453,"height":43.74257425742576,"type":"line_chart","id":"line_chart-11"},{"x":136.87623762376234,"y":569.5841584158416,"width":84.6930693069307,"height":44.67326732673268,"type":"line_chart","id":"line_chart-12"},{"x":446.79702970297035,"y":53.049504950495056,"width":415.0891089108911,"height":209.4059405940594,"type":"line_chart","id":"line_chart-7"},{"x":24.26237623762375,"y":506.2970297029703,"width":88.4158415841584,"height":43.74257425742576,"type":"line_chart","id":"line_chart-8"},{"x":135.0148514851485,"y":502.5742574257426,"width":83.76237623762376,"height":48.39603960396039,"type":"line_chart","id":"line_chart-9"},{"x":8.440594059405896,"y":11.16831683168317,"width":901.841584158416,"height":641.2475247524751,"type":"map","id":"map-6"}],"relations":[{"vislist":[{"vislist":["line_chart-7",{"vislist":[{"vislist":["bar_chart-0","bar_chart-1","bar_chart-2","bar_chart-3","bar_chart-4"],"relation":null,"id":"group-0"}],"relation":"repeated","id":"relation-0"},{"vislist":[{"vislist":["line_chart-8","line_chart-9","line_chart-10","line_chart-11","line_chart-12"],"relation":null,"id":"group-1"}],"relation":"repeated","id":"relation-1"}],"relation":null,"id":"group-8"},{"vislist":["map-6"],"relation":null,"id":"group-9"}],"relation":"large_view","id":"relation-4"}]},"2156_0":{"comp":[["graph","graph",["repeated","nested"]]],"visType":["graph"],"compType":["repeated","nested"],"compressed_tree":[{"composite_pattern":"nested","visualization_type":[["graph"],["graph"]]},{"composite_pattern":"repeated","visualization_type":[["graph"]]}],"coOccurrence":[["graph","graph",["coOccurrence"]]],"year":2011,"conference":["VAST"],"authors":["Bruno Pinaud","Jonathan Dubois","Guy Melan\xe7on"],"title":"PORGY: Interactive and visual reasoning with graph rewriting systems","doi":"10.1109/VAST.2011.6102480","abstract":"Graph rewriting systems are easily described and explained. They can be seen as a game where one iterates transformation rules on an initial graph, until some condition is met. A rule describes a local pattern (i.e. a subgraph) that must be identified in a graph and specifies how to transform this subgraph. The graph rewriting formalism is at the same time extremely rich and complex, making the study of a model expressed in terms of graph rewriting quite challenging. For instance, predicting whether rules can be applied in any order is often difficult. When modelling complex systems, graphical formalisms have clear advantages: they are more intuitive and make it easier to visualize a system and convey intuitions about it. This work focuses on the design of an interactive visual graph rewriting system which supports graphical manipulations and computation to reason and simulate on a system. PORGY has been designed based on regular exchanges with graph rewriting systems experts and users over the past three years. The design choices relied on a careful methodology inspired from Munzner\'s nested process model for visualization design and validation [4].","keywords":"","caption":"Figure 1: Overview of the PORGY graph rewriting framework allowing end-users (here biologists) to explore, study and simulate a model for biochemical calculus. Graphs describing the states and bindings of molecules are being transformed through the application of rewriting rules. The simulation is driven from the visualization, where rules are seen as elementary programming instructions.","img_size":{"width":1708,"height":1073},"subfigures":[{"x":25.57641104532084,"y":23.181714505759054,"width":1669.4060713144959,"height":1048.3334956853325,"type":"interface","id":"interface-0"}],"visualizations":[{"x":45.41583175616278,"y":834.9302599199912,"width":540.5936865983028,"height":202.34512291668332,"type":"graph","id":"graph-0"},{"x":676.0454148059757,"y":134.81886286165636,"width":456.0315456778979,"height":397.1400546797589,"type":"graph","id":"graph-1"},{"x":679.0654912674189,"y":557.629567463681,"width":451.9744608981747,"height":479.4960267271286,"type":"graph","id":"graph-2"},{"x":1159.488755403282,"y":614.8096706174257,"width":500.8521594684384,"height":203.19269102990032,"type":"graph","id":"graph-3"},{"x":1317.2529042728152,"y":840.5409719301917,"width":172.7056013897586,"height":165.0297968835471,"type":"graph","id":"graph-4"},{"x":247.91567607220802,"y":160.3473442914144,"width":216.69759030451382,"height":214.86117004769594,"type":"graph","id":"graph-5"},{"x":248.18075503128355,"y":595.4884107653544,"width":216.20182692495712,"height":214.92252617392208,"type":"graph","id":"graph-6"},{"x":42.09144522779684,"y":126.5326327887002,"width":629.3810953739516,"height":702.314563697568,"type":"graph","id":"graph-8"},{"x":1154.079787005385,"y":130.71398024244823,"width":523.8119299321664,"height":447.16854909238094,"type":"line_chart","id":"line_chart-7"}],"relations":[{"vislist":[{"vislist":["graph-5","graph-6"],"relation":null,"id":"group-1"},{"vislist":["graph-8"],"relation":null,"id":"group-0"}],"relation":"nested","id":"relation-0"},{"vislist":[{"vislist":["graph-3"],"relation":null,"id":"group-2"}],"relation":"repeated","id":"relation-1"}]},"2158_0":{"comp":[["map","map",["repeated"]]],"visType":["map"],"compType":["repeated"],"compressed_tree":[{"composite_pattern":"repeated","visualization_type":[["map"]]}],"coOccurrence":[["map","map",["coOccurrence"]]],"year":2011,"conference":["VAST"],"authors":["Scott D. Rothenberger","John E. Wenskovitch","G. Elisabeta Marai"],"title":"Pexel and heatmap visual analysis of multidimensional gun/homicide data","doi":"10.1109/VAST.2011.6102482","abstract":"We present a visual analysis tool for mining correlations in county-level, multidimensional gun/homicide data. The tool uses 2D pexels, heatmaps, linked-views, dynamic queries and details-on-demand to analyze annual county-level data on firearm homicide rates and gun availability, as well as various socio-demographic measures. A statistical significance filter was implemented as a visual means to validate exploratory hypotheses. Results from expert evaluations indicate that our methods outperform typical graphical techniques used by statisticians, such as bar graphs, scatterplots and residual plots, to show spatial and temporal relationships. Our visualization has the potential to convey the impact of gun availability on firearm homicides to the public health arena and the general public.","keywords":"","caption":"Figure 1: Interactive visual analysis of gun/homicide correlations, including a detailed view map with pexels and linked heatmaps,      county-level details-on-demand, and an expanded heatmap popup.","img_size":{"width":1341,"height":890},"subfigures":[{"x":4.254627326489348,"y":8.85966351958913,"width":1329.6498884555708,"height":879.85815389679,"type":"interface","id":"interface-0"}],"visualizations":[{"x":31.584787277254634,"y":246.14862312181955,"width":578.8065605500115,"height":395.8206299725415,"type":"glyph_based","id":"glyph_based-0"},{"x":236.70337658298064,"y":53.042933356023795,"width":172.53015196753182,"height":151.5397899236248,"type":"heatmap","id":"heatmap-1"},{"x":434.23938184291325,"y":53.752520659588505,"width":176.97072064610575,"height":150.83020262006008,"type":"heatmap","id":"heatmap-2"},{"x":633.2610500311906,"y":54.49500287197119,"width":177.3194770551928,"height":150.0877204076774,"type":"heatmap","id":"heatmap-3"},{"x":628.8859890407372,"y":399.00650854668044,"width":705.5305556151923,"height":475.35659540646736,"type":"heatmap","id":"heatmap-4"},{"x":33.57016037277459,"y":242.99394036493644,"width":576.5787861137027,"height":396.80543276968893,"type":"heatmap","id":"heatmap-5"},{"x":36.19467829162625,"y":54.54656704460157,"width":177.57764967323467,"height":148.73308156447604,"type":"map","id":"map-6"},{"x":237.68601953214875,"y":54.86850347130972,"width":172.85058368893462,"height":149.71421980833884,"type":"map","id":"map-7"},{"x":434.5340174274681,"y":54.330886372419315,"width":179.282234402693,"height":151.55491157780028,"type":"map","id":"map-8"},{"x":632.8148364201711,"y":53.122034427790915,"width":182.97798934849652,"height":154.0668381929997,"type":"map","id":"map-9"},{"x":35.43309667685764,"y":245.78834482106097,"width":575.6473179616612,"height":395.8739646176474,"type":"map","id":"map-10"},{"x":626.2613005931189,"y":400.93216679497397,"width":700.4204152842417,"height":473.79373617630034,"type":"map","id":"map-11"}],"relations":[{"vislist":[{"vislist":["map-6","map-7","map-8","map-9"],"relation":null,"id":"group-0"}],"relation":"repeated","id":"relation-0"}]},"2161_1":{"comp":[["scatterplot","scatterplot",["repeated"]]],"visType":["scatterplot"],"compType":["repeated"],"compressed_tree":[{"composite_pattern":"repeated","visualization_type":[["scatterplot"]]}],"coOccurrence":[["scatterplot","scatterplot",["coOccurrence"]]],"year":2011,"conference":["VAST"],"authors":["Harald Bosch","Dennis Thom","Michael W\xf6rne","Steffen Koch","Edwin Puttmann","Dominik J\xe4ckle","Thomas Ertl"],"title":"ScatterBlogs: Geo-spatial document analysis","doi":"10.1109/VAST.2011.6102488","abstract":"We presented Scatterblogs, a system for microblog analysis that seamlessly integrates search backend and visual frontend. It provides powerful, automatic algorithms for detecting spatio-temporal `anomalies\' within blog entries as well as corresponding visual representations and interaction facilities for inspecting anomalies or exploiting them in further analytic steps. Apart from that, we consider the system\'s combinatoric facilities for building complex hypotheses from temporal, spatial, and content-related aspects an important feature. This was the key for creating a cross-checked analysis for MC1.","keywords":"","caption":"Figure 2: The ScatterBlogs analysis desktop comprises amongst oth- ers: textual quering, a time-range slider including a histogram and weather information, blog scatterplots on the map and in a time- space cube, a map lens with a local tag cloud, a subset manage- ment component combining and tagging selections, and a table of the messages. The current message set is manually tagged to em- phasize the two affected areas (green and yellow) and the truck ac- cident (blue).","img_size":{"width":1014,"height":861},"subfigures":[{"x":7.659493769573589,"y":6.731646933275649,"width":1003.2583147282594,"height":849.3693496968938,"type":"interface","id":"interface-0"}],"visualizations":[{"x":4.9883720930232585,"y":137.30232558139534,"width":1005.4534883720929,"height":21.453488372093034,"type":"bar_chart","id":"bar_chart-0"},{"x":4.9883720930232585,"y":137.30232558139534,"width":1005.4534883720929,"height":21.453488372093034,"type":"bar_chart","id":"bar_chart-1"},{"x":13.569767441860447,"y":560.6511627906976,"width":516.313953488372,"height":287.4767441860465,"type":"flow_diagram","id":"flow_diagram-2"},{"x":13.569767441860447,"y":560.6511627906976,"width":516.313953488372,"height":287.4767441860465,"type":"flow_diagram","id":"flow_diagram-3"},{"x":19.2906976744186,"y":566.3720930232557,"width":510.5930232558139,"height":281.7558139534884,"type":"glyph_based","id":"glyph_based-4"},{"x":19.2906976744186,"y":566.3720930232557,"width":510.5930232558139,"height":281.7558139534884,"type":"glyph_based","id":"glyph_based-5"},{"x":14.999999999999998,"y":562.0813953488372,"width":513.4534883720929,"height":284.61627906976736,"type":"graph","id":"graph-6"},{"x":14.999999999999998,"y":562.0813953488372,"width":513.4534883720929,"height":284.61627906976736,"type":"graph","id":"graph-7"},{"x":13.569767441860447,"y":183.06976744186045,"width":512.0232558139535,"height":357.55813953488376,"type":"scatterplot","id":"scatterplot-8"},{"x":534.1744186046511,"y":181.63953488372093,"width":469.11627906976736,"height":447.6627906976743,"type":"scatterplot","id":"scatterplot-9"},{"x":13.569767441860447,"y":183.06976744186045,"width":512.0232558139535,"height":357.55813953488376,"type":"scatterplot","id":"scatterplot-10"},{"x":534.1744186046511,"y":181.63953488372093,"width":469.11627906976736,"height":447.6627906976743,"type":"scatterplot","id":"scatterplot-11"},{"x":529.8837209302324,"y":652.1860465116279,"width":453.3837209302326,"height":175.9186046511628,"type":"table","id":"table-12"},{"x":529.8837209302324,"y":652.1860465116279,"width":453.3837209302326,"height":175.9186046511628,"type":"table","id":"table-13"}],"relations":[{"vislist":[{"vislist":["scatterplot-10","scatterplot-11"],"relation":null,"id":"group-0"}],"relation":"repeated","id":"relation-0"}]},"2165_1":{"comp":[["bar_chart","bar_chart",["repeated"]]],"visType":["bar_chart"],"compType":["repeated"],"compressed_tree":[{"composite_pattern":"repeated","visualization_type":[["bar_chart"]]}],"coOccurrence":[["bar_chart","bar_chart",["coOccurrence"]]],"year":2011,"conference":["VAST"],"authors":["Lane Harrison","Wenwen Dou","Aidong Lu","William Ribarsky","Xiaoyu Wang"],"title":"Guiding security analysis through visualization","doi":"10.1109/VAST.2011.6102492","abstract":"We present a multiple views visualization for the security data in the VAST 2010 Mini Challenge 2. The visualization is used to monitor log event activity on the network log data included in the challenge. Interactions are provided that allow analysts to investigate suspicious activity and escalate events as needed. Additionally, a database application is used to allow SQL queries for more detailed investigation.","keywords":"","caption":"Figure 1: (a) An overview of visualization used. (b) The dark red-pink color is one rarely seen and warranted investigation. (c) Shows a transition in IDS event frequency. The bottom timestep has a few periods during which bursts of activity occur. This led to the discovery of the office machines exhibiting malicious behavior.","img_size":{"width":1566,"height":1020},"subfigures":[{"x":2.653599842747414,"y":41.16782689970537,"width":1177.81252080648,"height":907.2692822214826,"type":"interface","id":"interface-0"}],"visualizations":[{"x":11.868458274398904,"y":626.1386138613859,"width":910.3536067892504,"height":115.41725601131543,"type":"bar_chart","id":"bar_chart-0"},{"x":11.868458274398904,"y":774.7383309759547,"width":910.3536067892504,"height":119.74540311173972,"type":"bar_chart","id":"bar_chart-1"},{"x":1236.7340876944838,"y":135.6152758132956,"width":323.1683168316831,"height":164.46958981612445,"type":"bar_chart","id":"bar_chart-2"},{"x":1245.3903818953324,"y":584.2998585572842,"width":313.0693069306931,"height":82.23479490806221,"type":"bar_chart","id":"bar_chart-3"},{"x":1246.8330975954739,"y":794.9363507779348,"width":304.41301272984424,"height":72.13578500707206,"type":"bar_chart","id":"bar_chart-4"},{"x":33.50919377652059,"y":64.92220650636492,"width":887.2701555869875,"height":554.002828854314,"type":"graph","id":"graph-5"}],"relations":[{"vislist":[{"vislist":["bar_chart-1","bar_chart-0"],"relation":null,"id":"group-0"}],"relation":"repeated","id":"relation-0"}]},"2170_1":{"comp":[["word_cloud","word_cloud",["repeated"]],["bar_chart","bar_chart",["repeated"]]],"visType":["word_cloud","bar_chart"],"compType":["repeated"],"compressed_tree":[{"composite_pattern":"repeated","visualization_type":[["word_cloud"]]},{"composite_pattern":"repeated","visualization_type":[["bar_chart"]]}],"coOccurrence":[["word_cloud","bar_chart",["coOccurrence"]]],"year":2011,"conference":["VAST"],"authors":["Enrico Bertini","Juri Buchm\xfcller","Fabian Fische","Stephan Huber","Thomas Lindemeier","Fabian Maass","Florian Mansmann","Thomas Ramm","Michael Regenscheit","Christian Rohrdantz","Christian Scheible","Tobias Schreck","Stephan Sellien","Florian Stoffel","Mark Tautzenberger","Matthias Zieker","Daniel A. Keim"],"title":"Visual analytics of terrorist activities related to epidemics","doi":"10.1109/VAST.2011.6102498","abstract":"The task of the VAST 2011 Grand Challenge was to investigate potential terrorist activities and their relation to the spread of an epidemic. Three different data sets were provided as part of three Mini Challenges (MCs). MC 1 was about analyzing geo-tagged microblogging (Twitter) messages to characterize the spread of an epidemic. MC 2 required analyzing threats to a computer network using a situational awareness approach. In MC 3 possible criminal and terrorist activities were to be analyzed based on a collection of news articles. To solve the Grand Challenge, insight from each of the individual MCs had to be integrated appropriately.","keywords":"","caption":"Figure 1: Tool designed for the solution of MC 1 showing geo- locations and text content of Tweets for different time ranges.","img_size":{"width":960,"height":1305},"subfigures":[{"x":8.830003003584638,"y":435.9884311556683,"width":945.1157156887755,"height":435.8008378632248,"type":"interface","id":"interface-0"}],"visualizations":[{"x":134.84483120367878,"y":795.683084156163,"width":696.090201863736,"height":70.55163422643487,"type":"bar_chart","id":"bar_chart-11"},{"x":135.1207906295754,"y":462.3865300146413,"width":550.2781844802344,"height":330.54904831625186,"type":"map","id":"map-4"},{"x":683.4882869692534,"y":475.7613469985359,"width":271.3177159590043,"height":158.5871156661786,"type":"word_cloud","id":"word_cloud-7"},{"x":683.4882869692534,"y":643.9019033674964,"width":271.3177159590043,"height":164.31918008784768,"type":"word_cloud","id":"word_cloud-8"}],"relations":[{"vislist":[{"vislist":["word_cloud-7","word_cloud-8"],"relation":null,"id":"group-0"}],"relation":"repeated","id":"relation-0"},{"vislist":[{"vislist":["bar_chart-11"],"relation":null,"id":"group-8"}],"relation":"repeated","id":"relation-5"}]},"2981_0":{"comp":[["comb","comb",["repeated"]],["unit_visualization","map",["nested"]]],"visType":["comb","unit_visualization","map"],"compType":["repeated","nested"],"compressed_tree":[{"composite_pattern":"repeated","visualization_type":[[{"composite_pattern":"nested","visualization_type":[["unit_visualization"],["map"]]}]]}],"coOccurrence":[["unit_visualization","map",["coOccurrence"]]],"year":2018,"conference":["InfoVis"],"authors":["Jo Wood","Alexander Kachkaev","Jason Dykes"],"title":"Design Exposition with Literate Visualization","doi":"10.1109/TVCG.2018.2864836","abstract":"We propose a new approach to the visualization design and communication process, literate visualization, based upon and extending, Donald Knuth\'s idea of literate programming. It integrates the process of writing data visualization code with description of the design choices that led to the implementation (design exposition). We develop a model of design exposition characterised by four visualization designer architypes: the evaluator, the autonomist, the didacticist and the rationalist. The model is used to justify the key characteristics of literate visualization: `notebook\' documents that integrate live coding input, rendered output and textual narrative; low cost of authoring textual narrative; guidelines to encourage structured visualization design and its documentation. We propose narrative schemas for structuring and validating a wide range of visualization design approaches and models, and branching narratives for capturing alternative designs and design views. We describe a new open source literate visualization environment, litvis, based on a declarative interface to Vega and Vega-Lite through the functional programming language Elm combined with markdown for formatted narrative. We informally assess the approach, its implementation and potential by considering three examples spanning a range of design abstractions: new visualization idioms; validation though visualization algebra; and feminist data visualization. We argue that the rich documentation of the design process provided by literate visualization offers the potential to improve the validity of visualization design and so benefit both academic visualization and visualization practice.","keywords":"storytelling,design,literate programming,theory","caption":"Fig. 1. Literate Visualization code (left) and output (centre and right) for a design exposition that elicits user feedback.","img_size":{"width":1950,"height":696},"subfigures":[{"x":9.005221046309684,"y":17.074909724758477,"width":1930.770594174212,"height":669.1676090820858,"type":"interface","id":"interface-0"}],"visualizations":[{"x":789.6010186757213,"y":73.21222410865875,"width":498.25976230899835,"height":336.03565365025463,"type":"map","id":"map-0"},{"x":782.9796264855687,"y":429.11205432937186,"width":496.6044142614602,"height":228.43803056027156,"type":"map","id":"map-1"},{"x":1302.7589134125635,"y":151.01358234295415,"width":319.48217317487246,"height":139.0492359932088,"type":"map","id":"map-2"},{"x":1302.7589134125635,"y":291.71816638370115,"width":317.82682512733436,"height":137.39388794567068,"type":"map","id":"map-3"},{"x":1302.7589134125635,"y":429.11205432937186,"width":317.82682512733436,"height":129.1171477079796,"type":"map","id":"map-4"},{"x":1627.2071307300507,"y":151.01358234295415,"width":319.48217317487246,"height":135.7385398981324,"type":"map","id":"map-5"},{"x":1627.2071307300507,"y":290.06281833616293,"width":321.1375212224109,"height":132.427843803056,"type":"map","id":"map-6"},{"x":1628.862478777589,"y":420.8353140916808,"width":317.82682512733436,"height":140.70458404074702,"type":"map","id":"map-7"},{"x":1304.6867657074908,"y":150.752304704631,"width":320.0650118323627,"height":138.30815654818448,"type":"unit_visualization","id":"unit_visualization-8"},{"x":1303.2237507734812,"y":287.74274269647117,"width":322.99104170038004,"height":139.76557843684506,"type":"unit_visualization","id":"unit_visualization-9"},{"x":1304.675997577666,"y":429.21608414207145,"width":318.6070336762301,"height":132.25719341798433,"type":"unit_visualization","id":"unit_visualization-10"},{"x":1628.4234755738246,"y":149.30046851385853,"width":322.09842062776954,"height":139.73097786589977,"type":"unit_visualization","id":"unit_visualization-11"},{"x":1626.9281712336053,"y":287.6072715810814,"width":320.65048606085935,"height":132.63226534847547,"type":"unit_visualization","id":"unit_visualization-12"},{"x":1625.4632777913907,"y":424.85266620262325,"width":323.58027294529353,"height":138.022327169222,"type":"unit_visualization","id":"unit_visualization-13"}],"relations":[{"vislist":[{"id":"group-24","relation":null,"vislist":[{"vislist":[{"id":"group-12","relation":null,"vislist":["unit_visualization-8"]},{"id":"group-13","relation":null,"vislist":["map-2"]}],"relation":"nested","id":"relation-1"},{"vislist":[{"id":"group-14","relation":null,"vislist":["unit_visualization-9"]},{"id":"group-15","relation":null,"vislist":["map-3"]}],"relation":"nested","id":"relation-2"},{"vislist":[{"id":"group-16","relation":null,"vislist":["unit_visualization-10"]},{"id":"group-17","relation":null,"vislist":["map-4"]}],"relation":"nested","id":"relation-3"},{"vislist":[{"id":"group-18","relation":null,"vislist":["unit_visualization-11"]},{"id":"group-19","relation":null,"vislist":["map-5"]}],"relation":"nested","id":"relation-4"},{"vislist":[{"id":"group-20","relation":null,"vislist":["unit_visualization-12"]},{"id":"group-21","relation":null,"vislist":["map-6"]}],"relation":"nested","id":"relation-5"},{"vislist":[{"id":"group-22","relation":null,"vislist":["unit_visualization-13"]},{"id":"group-23","relation":null,"vislist":["map-7"]}],"relation":"nested","id":"relation-6"}]}],"relation":"repeated","id":"relation-7"}]},"2981_8":{"comp":[["map","map",["repeated"]]],"visType":["map"],"compType":["repeated"],"compressed_tree":[{"composite_pattern":"repeated","visualization_type":[["map"]]},{"composite_pattern":"repeated","visualization_type":[["map"]]},{"composite_pattern":"repeated","visualization_type":[["map"]]}],"coOccurrence":[["map","map",["coOccurrence"]]],"year":2018,"conference":["InfoVis"],"authors":["Jo Wood","Alexander Kachkaev","Jason Dykes"],"title":"Design Exposition with Literate Visualization","doi":"10.1109/TVCG.2018.2864836","abstract":"We propose a new approach to the visualization design and communication process, literate visualization, based upon and extending, Donald Knuth\'s idea of literate programming. It integrates the process of writing data visualization code with description of the design choices that led to the implementation (design exposition). We develop a model of design exposition characterised by four visualization designer architypes: the evaluator, the autonomist, the didacticist and the rationalist. The model is used to justify the key characteristics of literate visualization: `notebook\' documents that integrate live coding input, rendered output and textual narrative; low cost of authoring textual narrative; guidelines to encourage structured visualization design and its documentation. We propose narrative schemas for structuring and validating a wide range of visualization design approaches and models, and branching narratives for capturing alternative designs and design views. We describe a new open source literate visualization environment, litvis, based on a declarative interface to Vega and Vega-Lite through the functional programming language Elm combined with markdown for formatted narrative. We informally assess the approach, its implementation and potential by considering three examples spanning a range of design abstractions: new visualization idioms; validation though visualization algebra; and feminist data visualization. We argue that the rich documentation of the design process provided by literate visualization offers the potential to improve the validity of visualization design and so benefit both academic visualization and visualization practice.","keywords":"storytelling,design,literate programming,theory","caption":"Fig. 9. Litvis document using the Kindlmann and Scheidegger visualiza- tion algebra to validate mapping of the UK \u2018Brexit\u2019 referendum results. Headings and algebraic expression text are generated automatically from the schema specification. Note that only two of the three sets of tests pass, suggesting this form of representation may not be suitable.","img_size":{"width":1062,"height":2375},"subfigures":[{"x":19.217149438441584,"y":11.214480485490315,"width":1013.0525473560973,"height":601.1176313454455,"type":"interface","id":"interface-0"}],"visualizations":[{"x":22.556439428249607,"y":87.38897215330181,"width":180.88712114349943,"height":400.41736819339474,"type":"map","id":"map-3"},{"x":211.66446673416584,"y":90.05003322343354,"width":169.67106653166763,"height":405.6979246245619,"type":"map","id":"map-4"},{"x":389.0356960014788,"y":90.03761795164239,"width":167.92860799704303,"height":403.07208552528095,"type":"map","id":"map-5"},{"x":566.1121905562746,"y":90.0500332234338,"width":177.77561888744893,"height":405.697924624561,"type":"map","id":"map-6"},{"x":30.734084390234937,"y":732.0309375578197,"width":235.53183121952688,"height":531.8923659557856,"type":"map","id":"map-7"},{"x":270.79132891229193,"y":729.3084074962331,"width":232.4173421754156,"height":521.433408221818,"type":"map","id":"map-8"},{"x":515.5293184669838,"y":726.6653048987228,"width":228.94136306603227,"height":521.4182741311205,"type":"map","id":"map-9"},{"x":33.732806274793646,"y":1555.4145403839352,"width":238.53438745041228,"height":496.73230316069595,"type":"map","id":"map-10"},{"x":282.7497409064296,"y":1549.97911350759,"width":231.50051818713965,"height":502.30181762767546,"type":"map","id":"map-11"},{"x":530.7622222590605,"y":1544.6962973704485,"width":238.47555548187702,"height":518.1687891876747,"type":"map","id":"map-12"},{"x":776.5854705429525,"y":1544.643031458914,"width":227.82905891409504,"height":512.9739817250264,"type":"map","id":"map-13"}],"relations":[{"vislist":[{"id":"group-0","relation":null,"vislist":["map-3","map-4","map-5","map-6"]}],"relation":"repeated","id":"relation-0"},{"vislist":[{"id":"group-1","relation":null,"vislist":["map-7","map-8","map-9"]}],"relation":"repeated","id":"relation-1"},{"vislist":[{"id":"group-2","relation":null,"vislist":["map-10","map-11","map-12","map-13"]}],"relation":"repeated","id":"relation-2"}]},"2981_9":{"comp":[["proportional_area_chart","proportional_area_chart",["repeated"]]],"visType":["proportional_area_chart"],"compType":["repeated"],"compressed_tree":[{"composite_pattern":"repeated","visualization_type":[["proportional_area_chart"]]}],"coOccurrence":[["proportional_area_chart","proportional_area_chart",["coOccurrence"]]],"year":2018,"conference":["InfoVis"],"authors":["Jo Wood","Alexander Kachkaev","Jason Dykes"],"title":"Design Exposition with Literate Visualization","doi":"10.1109/TVCG.2018.2864836","abstract":"We propose a new approach to the visualization design and communication process, literate visualization, based upon and extending, Donald Knuth\'s idea of literate programming. It integrates the process of writing data visualization code with description of the design choices that led to the implementation (design exposition). We develop a model of design exposition characterised by four visualization designer architypes: the evaluator, the autonomist, the didacticist and the rationalist. The model is used to justify the key characteristics of literate visualization: `notebook\' documents that integrate live coding input, rendered output and textual narrative; low cost of authoring textual narrative; guidelines to encourage structured visualization design and its documentation. We propose narrative schemas for structuring and validating a wide range of visualization design approaches and models, and branching narratives for capturing alternative designs and design views. We describe a new open source literate visualization environment, litvis, based on a declarative interface to Vega and Vega-Lite through the functional programming language Elm combined with markdown for formatted narrative. We informally assess the approach, its implementation and potential by considering three examples spanning a range of design abstractions: new visualization idioms; validation though visualization algebra; and feminist data visualization. We argue that the rich documentation of the design process provided by literate visualization offers the potential to improve the validity of visualization design and so benefit both academic visualization and visualization practice.","keywords":"storytelling,design,literate programming,theory","caption":"Fig. 8. Valid design exposition in litvis using the \u2018idiom\u2019 narrative schema","img_size":{"width":1047,"height":672},"subfigures":[{"x":16.56861163999888,"y":5.350946697933763,"width":1019.8135658600147,"height":662.7863021975734,"type":"interface","id":"interface-0"}],"visualizations":[{"x":85.79702970297029,"y":390.65346534653463,"width":144.4752475247525,"height":125.46534653465346,"type":"proportional_area_chart","id":"proportional_area_chart-0"},{"x":585.7574257425742,"y":84.59405940594058,"width":82.69306930693074,"height":85.54455445544554,"type":"proportional_area_chart","id":"proportional_area_chart-1"},{"x":582.9059405940594,"y":228.1188118811881,"width":61.78217821782175,"height":86.49504950495047,"type":"proportional_area_chart","id":"proportional_area_chart-2"},{"x":804.371287128713,"y":227.16831683168317,"width":86.49504950495043,"height":65.58415841584156,"type":"proportional_area_chart","id":"proportional_area_chart-3"},{"x":581.0049504950495,"y":371.64356435643555,"width":89.34653465346537,"height":86.49504950495047,"type":"proportional_area_chart","id":"proportional_area_chart-4"},{"x":792.0148514851486,"y":369.7425742574257,"width":91.2475247524751,"height":88.39603960396039,"type":"proportional_area_chart","id":"proportional_area_chart-5"},{"x":36.37128712871288,"y":228.1188118811881,"width":153.02970297029702,"height":78.89108910891088,"type":"table","id":"table-6"}],"relations":[{"vislist":[{"id":"group-0","relation":null,"vislist":["proportional_area_chart-1","proportional_area_chart-2","proportional_area_chart-3","proportional_area_chart-4","proportional_area_chart-5"]}],"relation":"repeated","id":"relation-0"}]},"2984_7":{"comp":[["storyline","storyline",["repeated"]]],"visType":["storyline"],"compType":["repeated"],"compressed_tree":[{"composite_pattern":"repeated","visualization_type":[["storyline"]]}],"coOccurrence":[["storyline","storyline",["coOccurrence"]]],"year":2018,"conference":["InfoVis"],"authors":["Tan Tang","Sadia Rubab","Jiewen Lai","Weiwei Cui","Lingyun Yu","Yingcai Wu"],"title":"iStoryline: Effective Convergence to Hand-drawn Storylines","doi":"10.1109/TVCG.2018.2864899","abstract":"Storyline visualization techniques have progressed significantly to generate illustrations of complex stories automatically. However, the visual layouts of storylines are not enhanced accordingly despite the improvement in the performance and extension of its application area. Existing methods attempt to achieve several shared optimization goals, such as reducing empty space and minimizing line crossings and wiggles. However, these goals do not always produce optimal results when compared to hand-drawn storylines. We conducted a preliminary study to learn how users translate a narrative into a hand-drawn storyline and check whether the visual elements in hand-drawn illustrations can be mapped back to appropriate narrative contexts. We also compared the hand-drawn storylines with storylines generated by the state-of-the-art methods and found they have significant differences. Our findings led to a design space that summarizes (1) how artists utilize narrative elements and (2) the sequence of actions artists follow to portray expressive and attractive storylines. We developed iStoryline, an authoring tool for integrating high-level user interactions into optimization algorithms and achieving a balance between hand-drawn storylines and automatic layouts. iStoryline allows users to create novel storyline visualizations easily according to their preferences by modifying the automatically generated layouts. The effectiveness and usability of iStoryline are studied with qualitative evaluations.","keywords":"Hand-drawn illustrations,automatic layout,design space,interactions,optimization","caption":"Fig. 9. Illustrations of (a) iStoryline and (b) StoryFlow layouts for the movie The Chronicles of Narnia: The Lion, the Witch and the Wardrobe.","img_size":{"width":1062,"height":822},"subfigures":[{"x":4.790908301963642,"y":11.922991398164243,"width":1023.3156310070568,"height":386.74766038092156,"type":"single","id":"single-0"}],"visualizations":[{"x":0,"y":12.803738317757007,"width":1026.504672897196,"height":386.67289719626166,"type":"storyline","id":"storyline-0"},{"x":2.205607476635464,"y":419.9626168224299,"width":1029.4205607476633,"height":399.47663551401865,"type":"storyline","id":"storyline-1"}],"relations":[{"relation":"repeated","vislist":[{"id":"group-0","relation":null,"vislist":["storyline-0","storyline-1"]}],"id":"relation-0"}]},"2990_0":{"comp":[["map","map",["repeated"]],["heatmap","map",["coordinated"]],["line_chart","heatmap",["large_view"]],["line_chart","map",["large_view"]],["scatterplot","heatmap",["large_view"]],["scatterplot","map",["large_view"]]],"visType":["map","heatmap","line_chart","scatterplot"],"compType":["repeated","coordinated","large_view"],"compressed_tree":[{"composite_pattern":"coordinated","visualization_type":[["heatmap"],["map"]]},{"composite_pattern":"coordinated","visualization_type":[["heatmap"],["map"]]},{"composite_pattern":"large_view","visualization_type":[["line_chart","scatterplot"],["heatmap","map"]]},{"composite_pattern":"repeated","visualization_type":[["map"]]}],"coOccurrence":[["heatmap","map",["coOccurrence"]],["heatmap","line_chart",["coOccurrence"]],["heatmap","scatterplot",["coOccurrence"]],["map","line_chart",["coOccurrence"]],["map","scatterplot",["coOccurrence"]],["line_chart","scatterplot",["coOccurrence"]]],"year":2018,"conference":["InfoVis"],"authors":["Nina McCurdy","Julie Gerdes","Miriah D. Meyer"],"title":"A Framework for Externalizing Implicit Error Using Visualization","doi":"10.1109/TVCG.2018.2864913","abstract":"This paper presents a framework for externalizing and analyzing expert knowledge about discrepancies in data through the use of visualization. Grounded in an 18-month design study with global health experts, the framework formalizes the notion of data discrepancies as implicit error, both in global health data and more broadly. We use the term implicit error to describe measurement error that is inherent to and pervasive throughout a dataset, but that isn\'t explicitly accounted for or defined. Instead, implicit error exists in the minds of experts, is mainly qualitative, and is accounted for subjectively during expert interpretation of the data. Externalizing knowledge surrounding implicit error can assist in synchronizing, validating, and enhancing interpretation, and can inform error analysis and mitigation. The framework consists of a description of implicit error components that are important for downstream analysis, along with a process model for externalizing and analyzing implicit error using visualization. As a second contribution, we provide a rich, reflective, and verifiable description of our research process as an exemplar summary toward the ongoing inquiry into ways of increasing the validity and transferability of design study research.","keywords":"implicit error,knowledge externalization,design study","caption":"Fig. 1. Technology probes developed during the second (top) and third (bottom) phases of the project. Both versions allow users to explore country and subcountry data from countries\u2019 MoH offices (top), and country level data from WHO (bottom). The third phase probe integrates a fully implemented annotation platform.","img_size":{"width":1037,"height":1005},"subfigures":[{"x":14.266645789375147,"y":392.7501990799314,"width":827.2309889383838,"height":604.5369929915886,"type":"interface","id":"interface-0"}],"visualizations":[{"x":203.31368258463138,"y":114.74256661088944,"width":77.61616681683617,"height":272.9501866392071,"type":"bar_chart","id":"bar_chart-0"},{"x":875.9871283305447,"y":143.20182777706273,"width":119.01145578581543,"height":62.09293345346893,"type":"bar_chart","id":"bar_chart-1"},{"x":537.868202972983,"y":526.925683242185,"width":223.23330943893893,"height":68.45821489460786,"type":"line_chart","id":"line_chart-2"},{"x":534.8917588471305,"y":606.2975265982521,"width":225.21760552284059,"height":66.47391881070624,"type":"line_chart","id":"line_chart-3"},{"x":699.5637158384494,"y":263.0668094771439,"width":261.92708307502164,"height":101.19910027898564,"type":"line_chart","id":"line_chart-4"},{"x":844.417329963272,"y":464.47286199316443,"width":107.15198853069057,"height":108.14413657264154,"type":"line_chart","id":"line_chart-5"},{"x":13.800875273523047,"y":437.6258205689278,"width":827.6822872447788,"height":552.6596845555235,"type":"map","id":"map-6"},{"x":288.32058811199204,"y":127.02909013901653,"width":403.2513385833322,"height":255.5402255491446,"type":"map","id":"map-7"},{"x":702.7003785205935,"y":146.7762268330144,"width":78.2868899081194,"height":57.60733408333317,"type":"map","id":"map-8"},{"x":788.3728240804223,"y":148.2533379633563,"width":81.24111216880306,"height":57.60733408333317,"type":"map","id":"map-9"},{"x":546.4901088899926,"y":682.4608760423223,"width":221.01978222001202,"height":74.15748898678342,"type":"scatterplot","id":"scatterplot-10"},{"x":158.8546288877744,"y":581.9293575151484,"width":418.2907422244501,"height":377.2908385411331,"type":"heatmap","id":"heatmap-11"},{"x":393.0184780079683,"y":248.6706950125864,"width":197.9630439840618,"height":117.32378854625497,"type":"heatmap","id":"heatmap-12"}],"relations":[{"vislist":[{"id":"group-1","relation":null,"vislist":["heatmap-11"]},{"id":"group-2","relation":null,"vislist":["map-6"]}],"relation":"coordinated","id":"relation-0"},{"vislist":[{"id":"group-3","relation":null,"vislist":["heatmap-12"]},{"id":"group-4","relation":null,"vislist":["map-7"]}],"relation":"coordinated","id":"relation-1"},{"vislist":[{"vislist":["line_chart-2","line_chart-3","scatterplot-10"],"relation":null,"id":"group-0"},{"vislist":["heatmap-11","map-6"],"relation":null,"id":"group-1"}],"relation":"large_view","id":"relation-2"},{"vislist":[{"id":"group-5","relation":null,"vislist":["map-9","map-8"]}],"relation":"repeated","id":"relation-3"}]},"2990_3":{"comp":[["bar_chart","bar_chart",["repeated"]],["bar_chart","heatmap",["large_view"]],["bar_chart","map",["large_view"]],["line_chart","line_chart",["repeated"]],["line_chart","heatmap",["large_view"]],["line_chart","map",["large_view"]],["heatmap","map",["coordinated"]]],"visType":["bar_chart","heatmap","map","line_chart"],"compType":["repeated","large_view","coordinated"],"compressed_tree":[{"composite_pattern":"coordinated","visualization_type":[["heatmap"],["map"]]},{"composite_pattern":"coordinated","visualization_type":[["heatmap"],["map"]]},{"composite_pattern":"repeated","visualization_type":[["bar_chart"]]},{"composite_pattern":"repeated","visualization_type":[["line_chart"]]},{"composite_pattern":"repeated","visualization_type":[["line_chart"]]},{"composite_pattern":"large_view","visualization_type":[["bar_chart","line_chart"],["heatmap","map"]]}],"coOccurrence":[["heatmap","map",["coOccurrence"]],["heatmap","bar_chart",["coOccurrence"]],["heatmap","line_chart",["coOccurrence"]],["map","bar_chart",["coOccurrence"]],["map","line_chart",["coOccurrence"]],["bar_chart","line_chart",["coOccurrence"]]],"year":2018,"conference":["InfoVis"],"authors":["Nina McCurdy","Julie Gerdes","Miriah D. Meyer"],"title":"A Framework for Externalizing Implicit Error Using Visualization","doi":"10.1109/TVCG.2018.2864913","abstract":"This paper presents a framework for externalizing and analyzing expert knowledge about discrepancies in data through the use of visualization. Grounded in an 18-month design study with global health experts, the framework formalizes the notion of data discrepancies as implicit error, both in global health data and more broadly. We use the term implicit error to describe measurement error that is inherent to and pervasive throughout a dataset, but that isn\'t explicitly accounted for or defined. Instead, implicit error exists in the minds of experts, is mainly qualitative, and is accounted for subjectively during expert interpretation of the data. Externalizing knowledge surrounding implicit error can assist in synchronizing, validating, and enhancing interpretation, and can inform error analysis and mitigation. The framework consists of a description of implicit error components that are important for downstream analysis, along with a process model for externalizing and analyzing implicit error using visualization. As a second contribution, we provide a rich, reflective, and verifiable description of our research process as an exemplar summary toward the ongoing inquiry into ways of increasing the validity and transferability of design study research.","keywords":"implicit error,knowledge externalization,design study","caption":"Fig. 3. Prototypical instantiation of the framework for externalizing implicit error. (Right) expert knowledge surrounding implicit error is externalized via an annotation template, shown here featuring an example annotation discussed in section 6. (Left) once submitted, annotations are displayed either (a) as popup markers in information mode or (b) as bullseyes encoding categorical data trait attributes in data mode, which are linked (c) to a scented interactive legend displaying the distribution across categories for each trait. In information mode, annotations can additionally be viewed (d) in the chart view (e) as footnotes annotated along line charts.","img_size":{"width":2127,"height":747},"subfigures":[{"x":8.321721925651199,"y":107.43146034565844,"width":982.8488588855954,"height":566.7338978959148,"type":"interface","id":"interface-0"}],"visualizations":[{"x":680.6992524329783,"y":208.635851394806,"width":57.20112904790461,"height":85.801693571857,"type":"bar_chart","id":"bar_chart-0"},{"x":751.5196979208602,"y":208.635851394806,"width":76.26817206387284,"height":78.99203535186831,"type":"bar_chart","id":"bar_chart-1"},{"x":842.7691180687082,"y":208.635851394806,"width":40.85794931993189,"height":73.54430877587743,"type":"bar_chart","id":"bar_chart-2"},{"x":909.5037686245968,"y":208.635851394806,"width":43.581812607927425,"height":76.2681720638729,"type":"bar_chart","id":"bar_chart-3"},{"x":687.5089106529667,"y":365.25799045454494,"width":125.2977112477912,"height":62.64885562389559,"type":"line_chart","id":"line_chart-4"},{"x":816.8924168327513,"y":365.25799045454494,"width":123.93577960379343,"height":64.01078726789336,"type":"line_chart","id":"line_chart-5"},{"x":692.9566372289578,"y":452.4216156703997,"width":118.4880530278025,"height":64.01078726789336,"type":"line_chart","id":"line_chart-6"},{"x":830.5117332727286,"y":449.6977523824042,"width":108.95453151981837,"height":68.09658219988648,"type":"line_chart","id":"line_chart-7"},{"x":698.4043638049487,"y":539.5852408862545,"width":110.31646316381615,"height":61.28692397989777,"type":"line_chart","id":"line_chart-8"},{"x":825.0640066967377,"y":538.2233092422566,"width":95.33521507984109,"height":66.73465055588883,"type":"line_chart","id":"line_chart-9"},{"x":944.913991368538,"y":520.5181978702863,"width":140.27895933176615,"height":81.71589863986378,"type":"line_chart","id":"line_chart-10"},{"x":944.913991368538,"y":629.4727293901046,"width":141.64089097576402,"height":83.07783028386154,"type":"line_chart","id":"line_chart-11"},{"x":429.860819828408,"y":9.53765490943755,"width":221.94030587515658,"height":131.8413319573542,"type":"map","id":"map-12"},{"x":18.248808388941853,"y":135.2516682554814,"width":965.1591992373689,"height":539.3536701620591,"type":"map","id":"map-13"},{"x":116.69278850237775,"y":199.42113521874666,"width":810.7487173806761,"height":474.2746126793894,"type":"heatmap","id":"heatmap-14"},{"x":450.62117521567836,"y":48.665535285758025,"width":194.53382559291785,"height":90.22737098692528,"type":"heatmap","id":"heatmap-15"}],"relations":[{"relation":"coordinated","vislist":[{"id":"group-1","relation":null,"vislist":["heatmap-14"]},{"id":"group-2","relation":null,"vislist":["map-13"]}],"id":"relation-0"},{"relation":"coordinated","vislist":[{"id":"group-3","relation":null,"vislist":["heatmap-15"]},{"id":"group-4","relation":null,"vislist":["map-12"]}],"id":"relation-1"},{"relation":"repeated","vislist":[{"id":"group-5","relation":null,"vislist":["bar_chart-0","bar_chart-1","bar_chart-2","bar_chart-3"]}],"id":"relation-2"},{"relation":"repeated","vislist":[{"id":"group-6","relation":null,"vislist":["line_chart-5","line_chart-4","line_chart-6","line_chart-7","line_chart-8","line_chart-9"]}],"id":"relation-3"},{"relation":"repeated","vislist":[{"id":"group-7","relation":null,"vislist":["line_chart-10","line_chart-11"]}],"id":"relation-4"},{"relation":"large_view","vislist":[{"relation":null,"vislist":["bar_chart-0","bar_chart-1","bar_chart-2","bar_chart-3","line_chart-4","line_chart-5","line_chart-6","line_chart-7","line_chart-8","line_chart-9","line_chart-10","line_chart-11"],"id":"group-0"},{"relation":null,"vislist":["heatmap-14","map-13"],"id":"group-1"}],"id":"relation-5"}]},"2992_7":{"comp":[["bar_chart","bar_chart",["repeated"]],["heatmap","map",["coordinated"]]],"visType":["bar_chart","heatmap","map"],"compType":["repeated","coordinated"],"compressed_tree":[{"composite_pattern":"coordinated","visualization_type":[["heatmap"],["map"]]},{"composite_pattern":"repeated","visualization_type":[["bar_chart"]]}],"coOccurrence":[["heatmap","map",["coOccurrence"]],["heatmap","bar_chart",["coOccurrence"]],["map","bar_chart",["coOccurrence"]]],"year":2018,"conference":["InfoVis"],"authors":["Ali Sarvghad","Bahador Saket","Alex Endert","Nadir Weibel"],"title":"Embedded Merge & Split: Visual Adjustment of Data Grouping","doi":"10.1109/TVCG.2018.2865075","abstract":"Data grouping is among the most frequently used operations in data visualization. It is the process through which relevant information is gathered, simplified, and expressed in summary form. Many popular visualization tools support automatic grouping of data (e.g., dividing up a numerical variable into bins). Although grouping plays a pivotal role in supporting data exploration, further adjustment and customization of auto-generated grouping criteria is non-trivial. Such adjustments are currently performed either programmatically or through menus and dialogues which require specific parameter adjustments over several steps. In response, we introduce Embedded Merge &amp; Split (EMS), a new interaction technique for direct adjustment of data grouping criteria. We demonstrate how the EMS technique can be designed to directly manipulate width and position in bar charts and histograms, as a means for adjustment of data grouping criteria. We also offer a set of design guidelines for supporting EMS. Finally, we present the results of two user studies, providing initial evidence that EMS can significantly reduce interaction time compared to WIMP-based technique and was subjectively preferred by participants.","keywords":"Data Visualization,Direct Manipulation,Embedded Merge & Split,Data Grouping,Embedded Interaction","caption":"Fig. 7. Avantgarde tool Interface. Avantgarde is an exploratory data analysis tool currently used by HIV researchers at the University of California San Diego.","img_size":{"width":1052,"height":683},"subfigures":[{"x":7.019463057837147,"y":6.19194691272809,"width":1034.1808156487266,"height":669.1035502365664,"type":"interface","id":"interface-0"}],"visualizations":[{"x":210.5683264753534,"y":370.09830180057054,"width":107.49363581522618,"height":136.08236874480758,"type":"bar_chart","id":"bar_chart-0"},{"x":336.35875136551164,"y":366.6676538490208,"width":102.91943854649321,"height":141.80011533072388,"type":"bar_chart","id":"bar_chart-1"},{"x":459.8620776213034,"y":371.2418511177538,"width":104.06298786367637,"height":136.08236874480758,"type":"bar_chart","id":"bar_chart-2"},{"x":581.0783052427287,"y":371.2418511177538,"width":107.4936358152263,"height":136.08236874480758,"type":"bar_chart","id":"bar_chart-3"},{"x":706.8687301328869,"y":371.2418511177538,"width":108.63718513240951,"height":136.08236874480758,"type":"bar_chart","id":"bar_chart-4"},{"x":831.5156057058621,"y":368.9547524833873,"width":107.49363581522607,"height":138.36946737917413,"type":"bar_chart","id":"bar_chart-5"},{"x":211.71187579253666,"y":516.4726144000274,"width":105.20653718085964,"height":136.0823687448077,"type":"bar_chart","id":"bar_chart-6"},{"x":335.2152020483284,"y":516.4726144000274,"width":107.49363581522618,"height":137.2259180619909,"type":"bar_chart","id":"bar_chart-7"},{"x":459.8620776213034,"y":516.4726144000274,"width":107.49363581522624,"height":136.0823687448077,"type":"bar_chart","id":"bar_chart-8"},{"x":186.33615549664808,"y":203.75642988259733,"width":414.4915689951472,"height":132.96561223210665,"type":"scatterplot","id":"scatterplot-9"},{"x":611.6700894397757,"y":120.51406298576032,"width":429.97454326090474,"height":222.9921168507352,"type":"map","id":"map-11"},{"x":185.43278251125662,"y":110.87741061152397,"width":401.1344349774859,"height":83.24517877695116,"type":"matrix","id":"matrix-12"},{"x":822.2787568479716,"y":123.85607934433567,"width":220.44248630405707,"height":220.2878413113272,"type":"heatmap","id":"heatmap-13"}],"relations":[{"vislist":[{"id":"group-0","relation":null,"vislist":["heatmap-13"]},{"id":"group-1","relation":null,"vislist":["map-11"]}],"relation":"coordinated","id":"relation-0"},{"vislist":[{"id":"group-2","relation":null,"vislist":["bar_chart-8","bar_chart-7","bar_chart-6","bar_chart-5","bar_chart-4","bar_chart-3","bar_chart-2","bar_chart-1","bar_chart-0"]}],"relation":"repeated","id":"relation-1"}]},"2993_0":{"comp":[["line_chart","line_chart",["repeated"]],["area_chart","area_chart",["repeated"]]],"visType":["line_chart","area_chart"],"compType":["repeated"],"compressed_tree":[{"composite_pattern":"repeated","visualization_type":[["line_chart"]]},{"composite_pattern":"repeated","visualization_type":[["area_chart"]]}],"coOccurrence":[["line_chart","area_chart",["coOccurrence"]]],"year":2018,"conference":["InfoVis"],"authors":["Yixuan Zhang","Kartik Chanana","Cody Dunne"],"title":"IDMVis: Temporal Event Sequence Visualization for Type 1 Diabetes Treatment Decision Support","doi":"10.1109/TVCG.2018.2865076","abstract":"Type 1 diabetes is a chronic, incurable autoimmune disease affecting millions of Americans in which the body stops producing insulin and blood glucose levels rise. The goal of intensive diabetes management is to lower average blood glucose through frequent adjustments to insulin protocol, diet, and behavior. Manual logs and medical device data are collected by patients, but these multiple sources are presented in disparate visualization designs to the clinician-making temporal inference difficult. We conducted a design study over 18 months with clinicians performing intensive diabetes management. We present a data abstraction and novel hierarchical task abstraction for this domain. We also contribute IDMVis: a visualization tool for temporal event sequences with multidimensional, interrelated data. IDMVis includes a novel technique for folding and aligning records by dual sentinel events and scaling the intermediate timeline. We validate our design decisions based on our domain abstractions, best practices, and through a qualitative evaluation with six clinicians. The results of this study indicate that IDMVis accurately reflects the workflow of clinicians. Using IDMVis, clinicians are able to identify issues of data quality such as missing or conflicting data, reconstruct patient records when data is missing, differentiate between days with different patterns, and promote educational interventions after identifying discrepancies.","keywords":"Design study,task analysis,event sequence visualization,time series data,qualitative evaluation,health applications","caption":"Fig. 1. IDMVis is an interactive visualization tool for showing type 1 diabetes patient data. It is designed to help clinicians perform temporal inference tasks: specifically for recommending adjustments to patient insulin protocol, diet, and behavior. (A) The overview panel displays two weeks of event sequence data at a glance; (B) the detail panel shows additional information for the selected day; (C) the summary statistics panel displays the distribution of insulin and carbohydrate intake overall and for specific events (e.g., breakfast).","img_size":{"width":1950,"height":1094},"subfigures":[{"x":66.05420889695695,"y":33.77843592779051,"width":1841.0518931363067,"height":1050.8202387211727,"type":"interface","id":"interface-0"}],"visualizations":[{"x":1467.5402635431917,"y":124.93704245973646,"width":105.71595900439206,"height":280.307467057101,"type":"area_chart","id":"area_chart-0"},{"x":1352.2137628111273,"y":490.1376281112738,"width":100.91068814055642,"height":213.03367496339683,"type":"area_chart","id":"area_chart-1"},{"x":1457.9297218155198,"y":490.1376281112738,"width":108.91947291361657,"height":216.23718887262078,"type":"area_chart","id":"area_chart-2"},{"x":1574.857979502196,"y":493.3411420204978,"width":94.50366032210832,"height":208.2284040995608,"type":"area_chart","id":"area_chart-3"},{"x":1680.5739385065883,"y":486.9341142020498,"width":91.30014641288426,"height":224.24597364568086,"type":"area_chart","id":"area_chart-4"},{"x":1775.0775988286969,"y":490.1376281112738,"width":102.14703907097507,"height":217.2882666768918,"type":"area_chart","id":"area_chart-5"},{"x":1354.8514558370923,"y":779.9201819525317,"width":104.42177791056653,"height":213.75752184045393,"type":"area_chart","id":"area_chart-6"},{"x":1461.7302167573189,"y":775.0062159332108,"width":100.73630339607598,"height":221.12847086943518,"type":"area_chart","id":"area_chart-7"},{"x":1562.466520153395,"y":777.4631989428713,"width":101.96479490090609,"height":214.98601334528408,"type":"area_chart","id":"area_chart-8"},{"x":1666.8882980639617,"y":776.234707438041,"width":104.42177791056653,"height":216.21450485011428,"type":"area_chart","id":"area_chart-9"},{"x":1774.3558432268671,"y":775.7477692343109,"width":97.41696743027998,"height":218.80769366016682,"type":"area_chart","id":"area_chart-10"},{"x":72.39553847529709,"y":119.89116143325306,"width":1183.0465116279067,"height":719.6411960132889,"type":"line_chart","id":"line_chart-11"},{"x":1654.9458272327963,"y":120.13177159590043,"width":88.0966325036602,"height":285.11273792093704,"type":"area_chart","id":"area_chart-12"},{"x":61.958381927999646,"y":840.0479519048698,"width":1225.3440702781845,"height":249.87408491947292,"type":"line_chart","id":"line_chart-13"}],"relations":[{"vislist":[{"id":"group-0","relation":null,"vislist":["line_chart-11"]}],"relation":"repeated","id":"relation-0"},{"vislist":[{"id":"group-1","relation":null,"vislist":["area_chart-0","area_chart-1","area_chart-2","area_chart-3","area_chart-4","area_chart-5","area_chart-6","area_chart-7","area_chart-8","area_chart-9","area_chart-10","area_chart-12"]}],"relation":"repeated","id":"relation-1"}]},"2994_1":{"comp":[["line_chart","line_chart",["repeated"]]],"visType":["line_chart"],"compType":["repeated"],"compressed_tree":[{"composite_pattern":"repeated","visualization_type":[["line_chart"]]}],"coOccurrence":[["line_chart","line_chart",["coOccurrence"]]],"year":2018,"conference":["InfoVis"],"authors":["Anna Gogolou","Theophanis Tsandilas","Themis Palpanas","Anastasia Bezerianos"],"title":"Comparing Similarity Perception in Time Series Visualizations","doi":"10.1109/TVCG.2018.2865077","abstract":"A common challenge faced by many domain experts working with time series data is how to identify and compare similar patterns. This operation is fundamental in high-level tasks, such as detecting recurring phenomena or creating clusters of similar temporal sequences. While automatic measures exist to compute time series similarity, human intervention is often required to visually inspect these automatically generated results. The visualization literature has examined similarity perception and its relation to automatic similarity measures for line charts, but has not yet considered if alternative visual representations, such as horizon graphs and colorfields, alter this perception. Motivated by how neuroscientists evaluate epileptiform patterns, we conducted two experiments that study how these three visualization techniques affect similarity perception in EEG signals. We seek to understand if the time series results returned from automatic similarity measures are perceived in a similar manner, irrespective of the visualization technique; and if what people perceive as similar with each visualization aligns with different automatic measures and their similarity constraints. Our findings indicate that horizon graphs align with similarity measures that allow local variations in temporal position or speed (i.e., dynamic time warping) more than the two other techniques. On the other hand, horizon graphs do not align with measures that are insensitive to amplitude and y-offset scaling (i.e., measures based on z-normalization), but the inverse seems to be the case for line charts and colorfields. Overall, our work indicates that the choice of visualization affects what temporal patterns we consider as similar, i.e., the notion of similarity in time series is not visualization independent.","keywords":"Time series,similarity perception,automatic similarity search,line charts,horizon graphs,colorfields,evaluation","caption":"Fig. 2. The Muse tool1 used by neuroscientists to visualize measure- ments from 295 electrodes and sensors placed on patients. Here the neuroscientist has restricted their view to 6 groups of sensors (30 in total) from one recording trial (trial 10). Purple lines indicate manual annotations of epileptiform discharges that neuroscientists have detected on different sensors. The particular discharges are highlighted in a green oval for illustration purposes only (these highlights are not part of the tool). The scroll bar in the bottom indicates what time frame of the series is currently visible, and is augmented with indications of where manual annotations exist (small colored line segments).","img_size":{"width":1002,"height":624},"subfigures":[{"x":4.2434359186994675,"y":7.028788468946344,"width":988.6786044592549,"height":609.2514751080076,"type":"interface","id":"interface-0"}],"visualizations":[{"x":3.753883097306641,"y":42.6879828474394,"width":992.1027039263138,"height":575.8577208909835,"type":"line_chart","id":"line_chart-0"}],"relations":[{"vislist":[{"id":"group-0","relation":null,"vislist":["line_chart-0"]}],"relation":"repeated","id":"relation-0"}]},"2994_3":{"comp":[["area_chart","area_chart",["repeated"]]],"visType":["area_chart"],"compType":["repeated"],"compressed_tree":[{"composite_pattern":"repeated","visualization_type":[["area_chart"]]}],"coOccurrence":[["area_chart","area_chart",["coOccurrence"]]],"year":2018,"conference":["InfoVis"],"authors":["Anna Gogolou","Theophanis Tsandilas","Themis Palpanas","Anastasia Bezerianos"],"title":"Comparing Similarity Perception in Time Series Visualizations","doi":"10.1109/TVCG.2018.2865077","abstract":"A common challenge faced by many domain experts working with time series data is how to identify and compare similar patterns. This operation is fundamental in high-level tasks, such as detecting recurring phenomena or creating clusters of similar temporal sequences. While automatic measures exist to compute time series similarity, human intervention is often required to visually inspect these automatically generated results. The visualization literature has examined similarity perception and its relation to automatic similarity measures for line charts, but has not yet considered if alternative visual representations, such as horizon graphs and colorfields, alter this perception. Motivated by how neuroscientists evaluate epileptiform patterns, we conducted two experiments that study how these three visualization techniques affect similarity perception in EEG signals. We seek to understand if the time series results returned from automatic similarity measures are perceived in a similar manner, irrespective of the visualization technique; and if what people perceive as similar with each visualization aligns with different automatic measures and their similarity constraints. Our findings indicate that horizon graphs align with similarity measures that allow local variations in temporal position or speed (i.e., dynamic time warping) more than the two other techniques. On the other hand, horizon graphs do not align with measures that are insensitive to amplitude and y-offset scaling (i.e., measures based on z-normalization), but the inverse seems to be the case for line charts and colorfields. Overall, our work indicates that the choice of visualization affects what temporal patterns we consider as similar, i.e., the notion of similarity in time series is not visualization independent.","keywords":"Time series,similarity perception,automatic similarity search,line charts,horizon graphs,colorfields,evaluation","caption":"Fig. 4. Experimental screen for the Horizon Graph condition. The answer order and horizontal shift was randomized across visualizations. From the top the series are: Query, Out-ED, Top-ED, Top-DTW, Out-DTW.","img_size":{"width":1033,"height":482},"subfigures":[{"x":0.25205272283582253,"y":16.74081750857819,"width":1024.1012976452348,"height":461.4317045230148,"type":"single","id":"single-0"}],"visualizations":[{"x":172.46632503660322,"y":149.610541727672,"width":317.56954612005853,"height":46.57686676427525,"type":"area_chart","id":"area_chart-0"},{"x":689.0461200585651,"y":54.33967789165445,"width":323.92093704245974,"height":46.576866764275245,"type":"area_chart","id":"area_chart-1"},{"x":514.0300146412884,"y":239.2357247437774,"width":317.5695461200585,"height":49.39970717423134,"type":"area_chart","id":"area_chart-2"},{"x":3.0959004392386973,"y":337.329428989751,"width":315.4524158125915,"height":47.28257686676426,"type":"area_chart","id":"area_chart-3"},{"x":346.7767203513909,"y":430.4831625183015,"width":314.7467057101024,"height":45.16544655929721,"type":"area_chart","id":"area_chart-4"}],"relations":[{"vislist":[{"id":"group-0","relation":null,"vislist":["area_chart-0","area_chart-1","area_chart-2","area_chart-3","area_chart-4"]}],"relation":"repeated","id":"relation-0"}]},"2998_0":{"comp":[["map","map",["repeated"]],["map","matrix",["stacked"]],["map","area_chart",["stacked"]],["bar_chart","matrix",["stacked"]],["matrix","bar_chart",["stacked"]],["matrix","area_chart",["stacked"]],["matrix","map",["stacked"]],["matrix","heatmap",["stacked"]],["area_chart","matrix",["stacked"]],["area_chart","map",["stacked"]],["area_chart","scatterplot",["stacked"]],["heatmap","matrix",["stacked"]],["scatterplot","area_chart",["stacked"]]],"visType":["map","matrix","area_chart","bar_chart","heatmap","scatterplot"],"compType":["repeated","stacked"],"compressed_tree":[{"composite_pattern":"stacked","visualization_type":[["bar_chart","matrix"]]},{"composite_pattern":"stacked","visualization_type":[["matrix","area_chart"]]},{"composite_pattern":"stacked","visualization_type":[["matrix","map"]]},{"composite_pattern":"stacked","visualization_type":[["heatmap","matrix"]]},{"composite_pattern":"stacked","visualization_type":[["heatmap","matrix"]]},{"composite_pattern":"stacked","visualization_type":[["bar_chart","matrix"]]},{"composite_pattern":"stacked","visualization_type":[["matrix","map"]]},{"composite_pattern":"stacked","visualization_type":[["matrix","area_chart"]]},{"composite_pattern":"stacked","visualization_type":[["map","area_chart"]]},{"composite_pattern":"stacked","visualization_type":[["area_chart","scatterplot"]]},{"composite_pattern":"stacked","visualization_type":[["scatterplot","area_chart"]]},{"composite_pattern":"stacked","visualization_type":[["area_chart","map"]]},{"composite_pattern":"repeated","visualization_type":[["map"]]}],"coOccurrence":[["bar_chart","matrix",["coOccurrence"]],["bar_chart","area_chart",["coOccurrence"]],["bar_chart","map",["coOccurrence"]],["bar_chart","heatmap",["coOccurrence"]],["bar_chart","scatterplot",["coOccurrence"]],["matrix","area_chart",["coOccurrence"]],["matrix","map",["coOccurrence"]],["matrix","heatmap",["coOccurrence"]],["matrix","scatterplot",["coOccurrence"]],["area_chart","map",["coOccurrence"]],["area_chart","heatmap",["coOccurrence"]],["area_chart","scatterplot",["coOccurrence"]],["map","heatmap",["coOccurrence"]],["map","scatterplot",["coOccurrence"]],["heatmap","scatterplot",["coOccurrence"]]],"year":2018,"conference":["InfoVis"],"authors":["Di Weng","Ran Chen","Zikun Deng","Feiran Wu","Jingmin Chen","Yingcai Wu"],"title":"SRVis: Towards Better Spatial Integration in Ranking Visualization","doi":"10.1109/TVCG.2018.2865126","abstract":"Interactive ranking techniques have substantially promoted analysts\' ability in making judicious and informed decisions effectively based on multiple criteria. However, the existing techniques cannot satisfactorily support the analysis tasks involved in ranking large-scale spatial alternatives, such as selecting optimal locations for chain stores, where the complex spatial contexts involved are essential to the decision-making process. Limitations observed in the prior attempts of integrating rankings with spatial contexts motivate us to develop a context-integrated visual ranking technique. Based on a set of generic design requirements we summarized by collaborating with domain experts, we propose SRVis, a novel spatial ranking visualization technique that supports efficient spatial multi-criteria decision-making processes by addressing three major challenges in the aforementioned context integration, namely, a) the presentation of spatial rankings and contexts, b) the scalability of rankings\' visual representations, and c) the analysis of context-integrated spatial rankings. Specifically, we encode massive rankings and their cause with scalable matrix-based visualizations and stacked bar charts based on a novel two-phase optimization framework that minimizes the information loss, and the flexible spatial filtering and intuitive comparative analysis are adopted to enable the in-depth evaluation of the rankings and assist users in selecting the best spatial alternative. The effectiveness of the proposed technique has been evaluated and demonstrated with an empirical study of optimization methods, two case studies, and expert interviews.","keywords":"Spatial ranking,visualization","caption":"Fig. 1. The interface of SRVis. (A-E) The ranking view presents the rankings of alternatives and the cause of rankings with a matrix-based context-integrated visualization. Flexible spatial filtering features provided by B, C, and E enable users to conveniently explore and identify spatial patterns in the ranking datasets. (F) The inspector view adopts a table-based ranking technique to show all alternatives in the filtered region. A projection view is also utilized to assist users in finding similar alternatives based on their criteria. (G) The snapshot view allows users to save snapshots of rankings and criterion weights, such that users can compare these snapshots to find insights from the comparative analysis.","img_size":{"width":1884,"height":1076},"subfigures":[{"x":22.56140639966758,"y":28.73146829240188,"width":1846.0219755414341,"height":1037.6001403026182,"type":"interface","id":"interface-0"}],"visualizations":[{"x":1770.2074688796679,"y":28.276625172890743,"width":90.78284923928071,"height":138.4066390041494,"type":"area_chart","id":"area_chart-0"},{"x":926.3734439834024,"y":175.12033304880225,"width":105.66528354080228,"height":761.5226943096823,"type":"area_chart","id":"area_chart-1"},{"x":170.2627704927331,"y":956.9405255878291,"width":756.6008775580751,"height":92.27109266943302,"type":"area_chart","id":"area_chart-2"},{"x":924.4296836716186,"y":70.8253491827725,"width":106.6125598191309,"height":103.02483354934897,"type":"area_chart","id":"area_chart-23"},{"x":65.18450269539515,"y":959.5879075753721,"width":99.77060007203211,"height":86.87737633861677,"type":"area_chart","id":"area_chart-24"},{"x":267.0184501845019,"y":25.8875446389962,"width":635.2767527675276,"height":31.763837638376383,"type":"bar_chart","id":"bar_chart-3"},{"x":1151.0982019363762,"y":29.76486860304288,"width":156.2655601659751,"height":132.4536652835408,"type":"bar_chart","id":"bar_chart-4"},{"x":1303.3136531365315,"y":33.8285040485903,"width":150.8782287822878,"height":127.05535055350553,"type":"bar_chart","id":"bar_chart-5"},{"x":1466.1033210332107,"y":37.79898375338734,"width":142.93726937269366,"height":115.14391143911438,"type":"bar_chart","id":"bar_chart-6"},{"x":1609.0405904059041,"y":25.8875446389962,"width":162.78966789667902,"height":138.9667896678967,"type":"bar_chart","id":"bar_chart-7"},{"x":16.878228782287806,"y":268.0868066316161,"width":59.55719557195579,"height":615.4243542435426,"type":"bar_chart","id":"bar_chart-8"},{"x":1082.6390041493778,"y":160.7302904564315,"width":781.3278008298752,"height":453.91424619640384,"type":"bar_chart","id":"bar_chart-9"},{"x":60.75103631195879,"y":75.81877368333174,"width":103.03988275804602,"height":95.06480076953316,"type":"heatmap","id":"heatmap-14"},{"x":274.9594095940959,"y":65.59234168696668,"width":631.3062730627306,"height":99.26199261992616,"type":"heatmap","id":"heatmap-15"},{"x":60.5535055350553,"y":236.32296899323973,"width":99.2619926199262,"height":702.7749077490776,"type":"heatmap","id":"heatmap-19"},{"x":171.72693726937274,"y":176.76577342128405,"width":754.3911439114393,"height":766.3025830258305,"type":"map","id":"map-10"},{"x":1128.774550484094,"y":912.2932226832643,"width":144.35961272475788,"height":147.3360995850622,"type":"map","id":"map-11"},{"x":1282.0636237897647,"y":915.2697095435684,"width":145.84785615491023,"height":144.35961272475777,"type":"map","id":"map-12"},{"x":1442.7939142461964,"y":925.6874135546336,"width":159.24204702627935,"height":133.94190871369278,"type":"map","id":"map-13"},{"x":60.06852847863607,"y":72.23792720915475,"width":104.28479433255902,"height":101.63052856041331,"type":"matrix","id":"matrix-25"},{"x":272.72861224150915,"y":67.95874435519364,"width":633.829573696041,"height":98.74208575769771,"type":"matrix","id":"matrix-26"},{"x":58.63611763525384,"y":235.93296185142972,"width":101.43186184633478,"height":704.2936507652264,"type":"matrix","id":"matrix-27"},{"x":1069.0553505535056,"y":613.5185409489593,"width":790.1254612546128,"height":266.0221402214022,"type":"scatterplot","id":"scatterplot-20"},{"x":933.510955910408,"y":939.89706145992,"width":132.76261018222047,"height":124.82821750569128,"type":"scatterplot","id":"scatterplot-22"}],"relations":[{"vislist":[{"vislist":["bar_chart-3","matrix-26"],"relation":null,"id":"group-0"}],"relation":"stacked","id":"relation-0"},{"vislist":[{"vislist":["matrix-26","area_chart-23"],"relation":null,"id":"group-1"}],"relation":"stacked","id":"relation-1"},{"vislist":[{"vislist":["matrix-26","map-10"],"relation":null,"id":"group-2"}],"relation":"stacked","id":"relation-2"},{"vislist":[{"vislist":["heatmap-14","matrix-26"],"relation":null,"id":"group-3"}],"relation":"stacked","id":"relation-3"},{"vislist":[{"vislist":["heatmap-14","matrix-27"],"relation":null,"id":"group-4"}],"relation":"stacked","id":"relation-4"},{"vislist":[{"vislist":["bar_chart-8","matrix-27"],"relation":null,"id":"group-5"}],"relation":"stacked","id":"relation-5"},{"vislist":[{"vislist":["matrix-27","map-10"],"relation":null,"id":"group-6"}],"relation":"stacked","id":"relation-6"},{"vislist":[{"vislist":["matrix-27","area_chart-24"],"relation":null,"id":"group-7"}],"relation":"stacked","id":"relation-7"},{"vislist":[{"vislist":["map-10","area_chart-2"],"relation":null,"id":"group-8"}],"relation":"stacked","id":"relation-8"},{"vislist":[{"vislist":["area_chart-2","scatterplot-22"],"relation":null,"id":"group-9"}],"relation":"stacked","id":"relation-9"},{"vislist":[{"vislist":["scatterplot-22","area_chart-1"],"relation":null,"id":"group-10"}],"relation":"stacked","id":"relation-10"},{"vislist":[{"vislist":["area_chart-1","map-10"],"relation":null,"id":"group-11"}],"relation":"stacked","id":"relation-11"},{"vislist":[{"vislist":["map-12","map-11","map-13"],"relation":null,"id":"group-13"}],"relation":"repeated","id":"relation-12"}]},"3000_0":{"comp":[["graph","graph",["large_view","repeated"]],["heatmap","contour_graph",["coordinated"]],["comb","graph",["large_view"]]],"visType":["graph","heatmap","contour_graph","comb"],"compType":["large_view","repeated","coordinated"],"compressed_tree":[{"composite_pattern":"coordinated","visualization_type":[["heatmap"],["contour_graph"]]},{"composite_pattern":"large_view","visualization_type":[["graph",{"composite_pattern":"repeated","visualization_type":[["graph"]]}],["graph"]]}],"coOccurrence":[["graph","graph",["coOccurrence"]]],"year":2018,"conference":["InfoVis"],"authors":["Wei Che","Fangzhou Guo","Dongming Han","Jacheng Pan","Xiaotao Nie","Jiazhi Xia","Xiaolong Zhang"],"title":"Structure-Based Suggestive Exploration: A New Approach for Effective Exploration of Large Networks","doi":"10.1109/TVCG.2018.2865139","abstract":"When analyzing a visualized network, users need to explore different sections of the network to gain insight. However, effective exploration of large networks is often a challenge. While various tools are available for users to explore the global and local features of a network, these tools usually require significant interaction activities, such as repetitive navigation actions to follow network nodes and edges. In this paper, we propose a structure-based suggestive exploration approach to support effective exploration of large networks by suggesting appropriate structures upon user request. Encoding nodes with vectorized representations by transforming information of surrounding structures of nodes into a high dimensional space, our approach can identify similar structures within a large network, enable user interaction with multiple similar structures simultaneously, and guide the exploration of unexplored structures. We develop a web-based visual exploration system to incorporate this suggestive exploration approach and compare performances of our approach under different vectorizing methods and networks. We also present the usability and effectiveness of our approach through a controlled user study with two datasets.","keywords":"Large Network Exploration,Structure-Based Exploration,Suggestive Exploration","caption":"Figure 1. The user interface of our prototype system. (a) a heatmap view to show the rough shape of a network; (b) a sketching exemplar view where users can specify a structure exemplar manually; (c) a node-link view to present the structure of the network; (d) a suggestion gallery to visualize similar structures detected by a query engine; (e) an exploration history view to show exploration history; and (f) the control panel to enable users to adjust parameters of querying structures.","img_size":{"width":1962,"height":1092},"subfigures":[{"x":10.30322786057961,"y":20.915713461873406,"width":1463.072175383097,"height":822.0348551340977,"type":"interface","id":"interface-0"},{"x":812.8380588935975,"y":540.9765104893135,"width":1143.3378840933171,"height":547.265089014186,"type":"interface","id":"interface-1"}],"visualizations":[{"x":21.61844671992131,"y":45.54526491209931,"width":291.70240853284264,"height":281.35148927539154,"type":"contour_graph","id":"contour_graph-7"},{"x":13.915129151291522,"y":344.6045928617245,"width":306.2435424354244,"height":314.30258302583024,"type":"graph","id":"graph-0"},{"x":835.9372693726937,"y":578.3167699834956,"width":346.53874538745384,"height":249.83025830258305,"type":"graph","id":"graph-1"},{"x":1198.5940959409593,"y":570.2577293930898,"width":366.1652401586255,"height":255.91654446583144,"type":"graph","id":"graph-2"},{"x":1565.280442804428,"y":570.2577293930898,"width":366.68634686346877,"height":257.88929889298885,"type":"graph","id":"graph-3"},{"x":836.7593360995851,"y":879.0373443983401,"width":939.4522821576763,"height":187.2863070539419,"type":"graph","id":"graph-4"},{"x":332.2946058091286,"y":31.717842323651453,"width":1123.7178423236514,"height":809.5601659751036,"type":"graph","id":"graph-5"},{"x":21.974169741697438,"y":50.449611311909,"width":290.12546125461245,"height":274.00738007380073,"type":"heatmap","id":"heatmap-6"}],"relations":[{"vislist":[{"vislist":["heatmap-6"],"relation":null,"id":"group-1"},{"vislist":["contour_graph-7"],"relation":null,"id":"group-2"}],"relation":"coordinated","id":"relation-0"},{"vislist":[{"vislist":["graph-4",{"vislist":[{"vislist":["graph-2","graph-1","graph-3"],"relation":null,"id":"group-3"}],"relation":"repeated","id":"relation-1"}],"relation":null,"id":"group-5"},{"vislist":["graph-5"],"relation":null,"id":"group-6"}],"relation":"large_view","id":"relation-3"}]},"3021_2":{"comp":[["bar_chart","bar_chart",["repeated"]],["line_chart","line_chart",["repeated"]]],"visType":["bar_chart","line_chart"],"compType":["repeated"],"compressed_tree":[{"composite_pattern":"repeated","visualization_type":[["bar_chart"]]},{"composite_pattern":"repeated","visualization_type":[["line_chart"]]},{"composite_pattern":"repeated","visualization_type":[["line_chart"]]},{"composite_pattern":"repeated","visualization_type":[["line_chart"]]},{"composite_pattern":"repeated","visualization_type":[["bar_chart"]]},{"composite_pattern":"repeated","visualization_type":[["line_chart"]]},{"composite_pattern":"repeated","visualization_type":[["line_chart"]]},{"composite_pattern":"repeated","visualization_type":[["line_chart"]]},{"composite_pattern":"repeated","visualization_type":[["bar_chart"]]}],"coOccurrence":[["bar_chart","line_chart",["coOccurrence"]]],"year":2018,"conference":["InfoVis"],"authors":["Ricardo Langner","Ulrike Kister","Raimund Dachselt"],"title":"Multiple Coordinated Views at Large Displays for Multiple Users: Empirical Findings on User Behavior, Movements, and Distances","doi":"10.1109/TVCG.2018.2865235","abstract":"Interactive wall-sized displays benefit data visualization. Due to their sheer display size, they make it possible to show large amounts of data in multiple coordinated views (MCV) and facilitate collaborative data analysis. In this work, we propose a set of important design considerations and contribute a fundamental input vocabulary and interaction mapping for MCV functionality. We also developed a fully functional application with more than 45 coordinated views visualizing a real-world, multivariate data set of crime activities, which we used in a comprehensive qualitative user study investigating how pairs of users behave. Most importantly, we found that flexible movement is essential and-depending on user goals-is connected to collaboration, perception, and interaction. Therefore, we argue that for future systems interaction from the distance is required and needs good support. We show that our consistent design for both direct touch at the large display and distant interaction using mobile phones enables the seamless exploration of large-scale MCV at wall-sized displays. Our MCV application builds on design aspects such as simplicity, flexibility, and visual consistency and, therefore, supports realistic workflows. We believe that in the future, many visual data analysis scenarios will benefit from wall-sized displays presenting numerous coordinated visualizations, for which our findings provide a valuable foundation.","keywords":"Multiple coordinated views,wall-sized displays,mobile devices,distant interaction,physical navigation,user behavior,user movements,multi-user,collaborative data analysis","caption":"Fig. 3. Complete screenshot of the implemented prototype: All views are linked by default, green is used a base color for visualizations, while other colors highlight selected data items. A magic lens on the map augments neighborhoods (circles) with icons for the highest weapon type.","img_size":{"width":2157,"height":772},"subfigures":[{"x":14.011268389273686,"y":15.626948282630607,"width":2137.067631752057,"height":752.875469020575,"type":"interface","id":"interface-0"}],"visualizations":[{"x":1973.7802277239546,"y":14.35733704704051,"width":176.39460958621206,"height":72.63307453549919,"type":"bar_chart","id":"bar_chart-0"},{"x":1975.666801088513,"y":90.76355831165657,"width":173.5647495393748,"height":70.74650117094077,"type":"bar_chart","id":"bar_chart-1"},{"x":990.9376203995264,"y":466.23342893755176,"width":89.36823719829793,"height":72.2831330280352,"type":"bar_chart","id":"bar_chart-10"},{"x":9.1553480475382,"y":10.630730050933805,"width":177.61375212224107,"height":761.3692699490663,"type":"bar_chart","id":"bar_chart-11"},{"x":187.84306895618903,"y":12.080545178732088,"width":536.6684062997317,"height":153.65195035137546,"type":"bar_chart","id":"bar_chart-12"},{"x":1882.8523377949223,"y":393.70362791035257,"width":269.9223305364731,"height":224.93527544706103,"type":"bar_chart","id":"bar_chart-2"},{"x":992.314480873739,"y":11.688841607027074,"width":85.42552085131412,"height":76.22584937501887,"type":"bar_chart","id":"bar_chart-3"},{"x":989.6860033090829,"y":87.91469098204593,"width":86.73975963364228,"height":77.54008815734676,"type":"bar_chart","id":"bar_chart-4"},{"x":991.1855592142592,"y":164.3591916947749,"width":86.84675454642945,"height":77.93939510577016,"type":"bar_chart","id":"bar_chart-5"},{"x":993.4123990744242,"y":240.0717469403802,"width":84.61991468626455,"height":77.93939510577016,"type":"bar_chart","id":"bar_chart-6"},{"x":990.0721392841768,"y":318.0111420461503,"width":90.18701433667697,"height":74.59913531552286,"type":"bar_chart","id":"bar_chart-7"},{"x":988.9587193540943,"y":391.49685743159074,"width":89.07359440659434,"height":76.82597517568774,"type":"bar_chart","id":"bar_chart-8"},{"x":725.5930072469633,"y":164.08471214460357,"width":264.1619952479103,"height":227.36330934272866,"type":"bar_chart","id":"bar_chart-9"},{"x":188.1203070875652,"y":239.30584675252018,"width":358.34516295359384,"height":300.9478857705506,"type":"graph","id":"graph-15"},{"x":1617.217861822413,"y":14.35733704704051,"width":176.39460958621223,"height":76.40622126461605,"type":"line_chart","id":"line_chart-16"},{"x":1794.5557580909044,"y":14.35733704704051,"width":179.22446963305012,"height":74.51964790005763,"type":"line_chart","id":"line_chart-17"},{"x":1794.5557580909044,"y":89.82027162937734,"width":179.22446963305012,"height":75.46293458233683,"type":"line_chart","id":"line_chart-18"},{"x":1617.217861822413,"y":90.76355831165657,"width":176.39460958621223,"height":74.51964790005762,"type":"line_chart","id":"line_chart-19"},{"x":1617.217861822413,"y":166.22649289399342,"width":175.451322903933,"height":74.51964790005763,"type":"line_chart","id":"line_chart-20"},{"x":1616.2745751401337,"y":240.74614079405103,"width":177.33789626849148,"height":74.51964790005763,"type":"line_chart","id":"line_chart-21"},{"x":1619.1044351869714,"y":316.2090753763878,"width":173.5647495393748,"height":76.40622126461608,"type":"line_chart","id":"line_chart-22"},{"x":1793.6124714086254,"y":165.28320621171417,"width":179.22446963304995,"height":74.51964790005763,"type":"line_chart","id":"line_chart-23"},{"x":1794.5557580909044,"y":240.74614079405103,"width":179.22446963305012,"height":75.4629345823368,"type":"line_chart","id":"line_chart-24"},{"x":1793.6124714086254,"y":314.32250201182944,"width":181.1110429976084,"height":77.34950794689526,"type":"line_chart","id":"line_chart-25"},{"x":1974.7235144062338,"y":316.2090753763878,"width":177.33789626849148,"height":74.51964790005763,"type":"line_chart","id":"line_chart-26"},{"x":1973.7802277239546,"y":238.85956742949253,"width":179.22446963304995,"height":76.40622126461608,"type":"line_chart","id":"line_chart-27"},{"x":1974.7235144062338,"y":163.3966328471558,"width":178.28118295077093,"height":74.51964790005762,"type":"line_chart","id":"line_chart-28"},{"x":725.9132296655582,"y":615.1974005347178,"width":1423.8944184927657,"height":151.20854803286704,"type":"line_chart","id":"line_chart-29"},{"x":723.5628016992238,"y":539.9839404158588,"width":891.9847129797248,"height":77.56388808519341,"type":"line_chart","id":"line_chart-30"},{"x":187.84306895618903,"y":163.5056503607427,"width":182.60086853351865,"height":76.82597517568773,"type":"line_chart","id":"line_chart-31"},{"x":371.55735741979004,"y":165.73249022090758,"width":177.03376888310657,"height":75.71255524560527,"type":"line_chart","id":"line_chart-32"},{"x":548.5911263028966,"y":164.61907029082514,"width":177.03376888310638,"height":77.93939510577016,"type":"line_chart","id":"line_chart-33"},{"x":545.2508665126494,"y":243.67188532667774,"width":178.14718881318893,"height":74.59913531552286,"type":"line_chart","id":"line_chart-34"},{"x":545.2508665126494,"y":314.93076085195327,"width":178.14718881318893,"height":77.9393951057702,"type":"line_chart","id":"line_chart-35"},{"x":546.3642864427318,"y":390.64331609755857,"width":178.14718881318893,"height":77.9393951057702,"type":"line_chart","id":"line_chart-36"},{"x":547.4777063728142,"y":466.35587134316387,"width":177.0337688831065,"height":74.5991353155229,"type":"line_chart","id":"line_chart-37"},{"x":187.63840023353484,"y":541.0140340176088,"width":182.206246655809,"height":224.5612075012382,"type":"line_chart","id":"line_chart-38"},{"x":371.4429472986053,"y":541.8131842222393,"width":175.01389481413239,"height":226.95865811513056,"type":"line_chart","id":"line_chart-39"},{"x":548.8542927266298,"y":541.0140340176088,"width":175.81304501876318,"height":227.75780831976124,"type":"line_chart","id":"line_chart-40"},{"x":1077.8155688933364,"y":11.749272167688028,"width":538.2933833112427,"height":527.4344389793156,"type":"map","id":"map-13"},{"x":1077.8155688933364,"y":11.749272167688028,"width":538.2933833112427,"height":528.9857167410194,"type":"map","id":"map-14"},{"x":723.1839285111499,"y":14.30906876298065,"width":267.7153185512982,"height":150.2402384705793,"type":"matrix","id":"matrix-41"},{"x":722.8329088046326,"y":392.6360571271889,"width":265.476234030238,"height":151.13745996770967,"type":"matrix","id":"matrix-42"},{"x":11.293675169242334,"y":11.928745982995025,"width":177.22867677594212,"height":760.071254017005,"type":"proportional_area_chart","id":"proportional_area_chart-43"},{"x":728.8536835791541,"y":161.0601935139707,"width":259.3590391843056,"height":224.77783395973145,"type":"proportional_area_chart","id":"proportional_area_chart-44"},{"x":1616.032562781857,"y":390.60107238694485,"width":266.81977501306534,"height":228.03783097046875,"type":"scatterplot","id":"scatterplot-45"},{"x":1077.8155688933364,"y":11.749272167688028,"width":538.2933833112427,"height":528.9857167410194,"type":"scatterplot","id":"scatterplot-46"},{"x":723.9830787157806,"y":15.907369172242129,"width":266.11701814203667,"height":150.2402384705793,"type":"scatterplot","id":"scatterplot-47"},{"x":724.1471475869605,"y":386.0648632155493,"width":265.476234030238,"height":156.39441509702147,"type":"scatterplot","id":"scatterplot-48"}],"relations":[{"vislist":[{"vislist":["bar_chart-12"],"relation":null,"id":"group-0"}],"relation":"repeated","id":"relation-0"},{"vislist":[{"vislist":["line_chart-33","line_chart-34","line_chart-35","line_chart-36","line_chart-37"],"relation":null,"id":"group-1"}],"relation":"repeated","id":"relation-1"},{"vislist":[{"vislist":["line_chart-32","line_chart-31"],"relation":null,"id":"group-2"}],"relation":"repeated","id":"relation-2"},{"vislist":[{"vislist":["line_chart-38","line_chart-39","line_chart-40"],"relation":null,"id":"group-3"}],"relation":"repeated","id":"relation-3"},{"vislist":[{"vislist":["bar_chart-10","bar_chart-8","bar_chart-7","bar_chart-6","bar_chart-5","bar_chart-4","bar_chart-3"],"relation":null,"id":"group-4"}],"relation":"repeated","id":"relation-4"},{"vislist":[{"vislist":["line_chart-16","line_chart-19","line_chart-20","line_chart-21","line_chart-22"],"relation":null,"id":"group-5"}],"relation":"repeated","id":"relation-5"},{"vislist":[{"vislist":["line_chart-17","line_chart-18","line_chart-23","line_chart-24","line_chart-25"],"relation":null,"id":"group-6"}],"relation":"repeated","id":"relation-6"},{"vislist":[{"vislist":["line_chart-26","line_chart-27","line_chart-28"],"relation":null,"id":"group-7"}],"relation":"repeated","id":"relation-7"},{"vislist":[{"vislist":["bar_chart-0","bar_chart-1"],"relation":null,"id":"group-8"}],"relation":"repeated","id":"relation-8"}]},"3060_0":{"comp":[["comb","comb",["repeated"]],["bar_chart","sankey_diagram",["nested"]],["bar_chart","line_chart",["stacked"]],["line_chart","bar_chart",["stacked"]]],"visType":["comb","bar_chart","sankey_diagram","line_chart"],"compType":["repeated","nested","stacked"],"compressed_tree":[{"composite_pattern":"repeated","visualization_type":[[{"composite_pattern":"stacked","visualization_type":[["bar_chart","line_chart"]]}]]},{"composite_pattern":"repeated","visualization_type":[[{"composite_pattern":"stacked","visualization_type":[["bar_chart","line_chart"]]}]]},{"composite_pattern":"nested","visualization_type":[["bar_chart"],["sankey_diagram"]]},{"composite_pattern":"nested","visualization_type":[["bar_chart"],["sankey_diagram"]]}],"coOccurrence":[["bar_chart","line_chart",["coOccurrence"]],["bar_chart","sankey_diagram",["coOccurrence"]],["line_chart","sankey_diagram",["coOccurrence"]]],"year":2018,"conference":["VAST"],"authors":["Xun Zhao","Yanhong Wu","Dik Lun Lee","Weiwei Cui"],"title":"iForest: Interpreting Random Forests via Visual Analytics","doi":"10.1109/TVCG.2018.2864475","abstract":"As an ensemble model that consists of many independent decision trees, random forests generate predictions by feeding the input to internal trees and summarizing their outputs. The ensemble nature of the model helps random forests outperform any individual decision tree. However, it also leads to a poor model interpretability, which significantly hinders the model from being used in fields that require transparent and explainable predictions, such as medical diagnosis and financial fraud detection. The interpretation challenges stem from the variety and complexity of the contained decision trees. Each decision tree has its unique structure and properties, such as the features used in the tree and the feature threshold in each tree node. Thus, a data input may lead to a variety of decision paths. To understand how a final prediction is achieved, it is desired to understand and compare all decision paths in the context of all tree structures, which is a huge challenge for any users. In this paper, we propose a visual analytic system aiming at interpreting random forest models and predictions. In addition to providing users with all the tree information, we summarize the decision paths in random forests, which eventually reflects the working mechanism of the model and reduces users\' mental burden of interpretation. To demonstrate the effectiveness of our system, two usage scenarios and a qualitative user study are conducted.","keywords":"Interpretable Machine Learning,Random Forests,Random Forest Visualization,Visual Analytics","caption":"Figure 1. Using iForest to interpret random forests with Titanic dataset: (A) a Data Overview displaying an overview of how random forests classify data; (B) a Feature View depicting the relationships between features and predictions from various perspectives; (C) a Decision Path View revealing the underlying working mechanisms by enabling users to audit and compare different decision paths. iForest allows users to interpret random forests from various perspectives. For example, users can compare the negative decision paths (c1) against the positive ones (c2) to examine the most significant reasons for generating different results.","img_size":{"width":1981,"height":985},"subfigures":[{"x":9.15507957692764,"y":9.038303889507684,"width":1963.9281829771228,"height":969.3999030139247,"type":"interface","id":"interface-0"}],"visualizations":[{"x":432.51909476661893,"y":123.78542797227895,"width":334.3705799151343,"height":69.53029179289835,"type":"bar_chart","id":"bar_chart-0"},{"x":432.51909476661825,"y":266.6337902784717,"width":331.5841584158414,"height":79.59200245697411,"type":"bar_chart","id":"bar_chart-1"},{"x":431.125884016973,"y":435.843270367656,"width":337.1570014144272,"height":68.17981209408212,"type":"bar_chart","id":"bar_chart-2"},{"x":428.3394625176795,"y":584.5568334376395,"width":339.9434229137196,"height":75.2022038611947,"type":"bar_chart","id":"bar_chart-3"},{"x":429.7326732673266,"y":746.5292675388016,"width":339.94342291371976,"height":68.17981209408191,"type":"bar_chart","id":"bar_chart-4"},{"x":429.7326732673266,"y":895.3699886844887,"width":339.9434229137199,"height":76.56231054792822,"type":"bar_chart","id":"bar_chart-5"},{"x":1049.711456859971,"y":858.6503523456931,"width":430.5021216407352,"height":120.480404608202,"type":"bar_chart","id":"bar_chart-6"},{"x":1483,"y":857.4167582348203,"width":490.41018387553004,"height":127.23783112313465,"type":"bar_chart","id":"bar_chart-7"},{"x":1078.968882602546,"y":43.18953323903819,"width":808.0622347949079,"height":330.1909476661952,"type":"bar_chart","id":"bar_chart-8"},{"x":1078.968882602546,"y":387.31258840169727,"width":808.0622347949079,"height":267.49646393210753,"type":"bar_chart","id":"bar_chart-9"},{"x":450.63083451202255,"y":677.1004243281471,"width":316.2588401697313,"height":66.87411598302685,"type":"line_chart","id":"line_chart-10"},{"x":447.8444130127297,"y":367.8076379066478,"width":319.0452616690241,"height":65.4809052333805,"type":"line_chart","id":"line_chart-11"},{"x":1045.5318246110328,"y":734.2220650636492,"width":436.07496463932097,"height":122.60254596888262,"type":"line_chart","id":"line_chart-12"},{"x":1480.2135785007072,"y":738.4016973125883,"width":493.1966053748231,"height":118.42291371994338,"type":"line_chart","id":"line_chart-13"},{"x":1080.3620933521925,"y":41.7963224893918,"width":883.2956152758131,"height":332.97736916548797,"type":"sankey_diagram","id":"sankey_diagram-14"},{"x":1080.3620933521925,"y":385.9193776520509,"width":886.0820367751061,"height":271.67609618104666,"type":"sankey_diagram","id":"sankey_diagram-15"},{"x":783.6082036775105,"y":45.97595473833098,"width":296.7538896746819,"height":332.97736916548797,"type":"scatterplot","id":"scatterplot-16"},{"x":786.3946251768034,"y":388.70579915134374,"width":293.96746817538906,"height":313.4724186704384,"type":"scatterplot","id":"scatterplot-17"},{"x":36.84724186704375,"y":112.85007072135784,"width":380.34653465346526,"height":383.13295615275814,"type":"scatterplot","id":"scatterplot-18"},{"x":41.026874115982935,"y":546.1386138613863,"width":374.77369165487977,"height":420.74964639321075,"type":"table","id":"table-19"},{"x":784.0210947437072,"y":707.2439988686192,"width":267.1634250801124,"height":271.29062821696033,"type":"scatterplot","id":"scatterplot-20"},{"x":427.8147019773592,"y":525.4083409476852,"width":342.2894124337464,"height":63.51156237943794,"type":"line_chart","id":"line_chart-21"},{"x":426.3794825609486,"y":500.91572823631935,"width":345.15985126656915,"height":24.6384898519101,"type":"bar_chart","id":"bar_chart-22"},{"x":445.7810641561975,"y":346.31029099875553,"width":327.39917669519224,"height":21.69239510172582,"type":"bar_chart","id":"bar_chart-23"},{"x":429.3315714510166,"y":213.5443236150248,"width":334.7465687823365,"height":51.125093227964804,"type":"line_chart","id":"line_chart-24"},{"x":429.33157145101626,"y":189.7730561350476,"width":334.74656878233696,"height":23.47678849326336,"type":"bar_chart","id":"bar_chart-25"},{"x":424.88111274491337,"y":60.324396803056715,"width":345.1505210959082,"height":59.8092216610622,"type":"line_chart","id":"line_chart-26"},{"x":426.3667558164768,"y":39.20462252104781,"width":342.17923495277984,"height":22.346480148744263,"type":"bar_chart","id":"bar_chart-27"},{"x":447.22099427491696,"y":659.4794176455109,"width":313.9980721481932,"height":22.44574486164846,"type":"bar_chart","id":"bar_chart-28"},{"x":427.8587414508461,"y":843.5247918271295,"width":340.6982985854099,"height":52.86644688009035,"type":"line_chart","id":"line_chart-29"},{"x":435.31848901636016,"y":814.3853088627062,"width":333.29397796120867,"height":32.94693952649577,"type":"bar_chart","id":"bar_chart-30"},{"x":1083.234835255468,"y":704.5323888065421,"width":399.2109061203225,"height":31.591710936533904,"type":"bar_chart","id":"bar_chart-31"},{"x":1519.3484360048024,"y":706.6975471963216,"width":446.841064257467,"height":33.276661332548116,"type":"bar_chart","id":"bar_chart-32"}],"relations":[{"vislist":[{"id":"group-10","relation":null,"vislist":[{"vislist":[{"id":"group-5","relation":null,"vislist":["bar_chart-27","line_chart-26","bar_chart-0"]}],"relation":"stacked","id":"relation-0"},{"vislist":[{"id":"group-6","relation":null,"vislist":["bar_chart-25","line_chart-24","bar_chart-1"]}],"relation":"stacked","id":"relation-1"},{"vislist":[{"id":"group-7","relation":null,"vislist":["line_chart-11","bar_chart-23","bar_chart-2"]}],"relation":"stacked","id":"relation-2"},{"vislist":[{"id":"group-8","relation":null,"vislist":["bar_chart-22","line_chart-21","bar_chart-3"]}],"relation":"stacked","id":"relation-3"},{"vislist":[{"id":"group-9","relation":null,"vislist":["bar_chart-30","line_chart-29","bar_chart-5"]}],"relation":"stacked","id":"relation-4"}]}],"relation":"repeated","id":"relation-5"},{"vislist":[{"id":"group-15","relation":null,"vislist":[{"vislist":[{"id":"group-13","relation":null,"vislist":["bar_chart-32","line_chart-13","bar_chart-7"]}],"relation":"stacked","id":"relation-7"},{"vislist":[{"id":"group-14","relation":null,"vislist":["bar_chart-31","line_chart-12","bar_chart-6"]}],"relation":"stacked","id":"relation-6"}]}],"relation":"repeated","id":"relation-8"},{"vislist":[{"id":"group-16","relation":null,"vislist":["bar_chart-8"]},{"id":"group-17","relation":null,"vislist":["sankey_diagram-14"]}],"relation":"nested","id":"relation-9"},{"vislist":[{"id":"group-18","relation":null,"vislist":["bar_chart-9"]},{"id":"group-19","relation":null,"vislist":["sankey_diagram-15"]}],"relation":"nested","id":"relation-10"}]},"3062_8":{"comp":[["bar_chart","bar_chart",["repeated"]],["bar_chart","comb",["stacked"]],["area_chart","area_chart",["repeated"]],["scatterplot","matrix",["nested"]],["comb","bar_chart",["stacked"]]],"visType":["bar_chart","comb","area_chart","scatterplot","matrix"],"compType":["repeated","stacked","nested"],"compressed_tree":[{"composite_pattern":"nested","visualization_type":[["scatterplot"],["matrix"]]},{"composite_pattern":"repeated","visualization_type":[["bar_chart"]]},{"composite_pattern":"stacked","visualization_type":[["bar_chart",{"composite_pattern":"repeated","visualization_type":[["area_chart"]]}]]}],"coOccurrence":[["scatterplot","matrix",["coOccurrence"]],["scatterplot","bar_chart",["coOccurrence"]],["scatterplot","area_chart",["coOccurrence"]],["matrix","bar_chart",["coOccurrence"]],["matrix","area_chart",["coOccurrence"]],["bar_chart","area_chart",["coOccurrence"]]],"year":2018,"conference":["VAST"],"authors":["Jiawei Zhang","Yang Wang","Piero Molino","Lezhi Li","David S. Ebert"],"title":"Manifold: A Model-Agnostic Framework for Interpretation and Diagnosis of Machine Learning Models","doi":"10.1109/TVCG.2018.2864499","abstract":"Interpretation and diagnosis of machine learning models have gained renewed interest in recent years with breakthroughs in new approaches. We present Manifold, a framework that utilizes visual analysis techniques to support interpretation, debugging, and comparison of machine learning models in a more transparent and interactive manner. Conventional techniques usually focus on visualizing the internal logic of a specific model type (i.e., deep neural networks), lacking the ability to extend to a more complex scenario where different model types are integrated. To this end, Manifold is designed as a generic framework that does not rely on or access the internal logic of the model and solely observes the input (i.e., instances or features) and the output (i.e., the predicted result and probability distribution). We describe the workflow of Manifold as an iterative process consisting of three major phases that are commonly involved in the model development and diagnosis process: inspection (hypothesis), explanation (reasoning), and refinement (verification). The visual components supporting these tasks include a scatterplot-based visual summary that overviews the models\' outcome and a customizable tabular view that reveals feature discrimination. We demonstrate current applications of the framework on the classification and regression tasks and discuss other potential machine learning use scenarios where Manifold can be applied.","keywords":"Interactive machine learning,performance analysis,model comparison,model debugging","caption":"Fig. 5. Left: Model performance comparison between model pairs for the bike sharing regression problem. Two instance subsets where both top two performing models (M2 & M3) generated over-predicted (pink) and under-predicted (blue) values were selected for further study. Right: the contributing features sorted by the divergence between the value distributions of the two instance subsets.","img_size":{"width":1899,"height":1370},"subfigures":[{"x":13.108255588342184,"y":15.465604618149902,"width":1866.7207085621058,"height":1345.1367311298163,"type":"interface","id":"interface-0"}],"visualizations":[{"x":797.9890965732087,"y":183.52024922118378,"width":64.01869158878503,"height":1186.4797507788162,"type":"area_chart","id":"area_chart-0"},{"x":891.8831775700935,"y":179.25233644859813,"width":76.82242990654187,"height":1190.747663551402,"type":"area_chart","id":"area_chart-1"},{"x":994.3130841121493,"y":170.71651090342678,"width":51.214953271028094,"height":1199.2834890965732,"type":"area_chart","id":"area_chart-2"},{"x":1079.6713395638628,"y":170.71651090342678,"width":55.48286604361373,"height":1199.2834890965732,"type":"area_chart","id":"area_chart-3"},{"x":1676.830885938766,"y":174.5534982150609,"width":96.32618378751455,"height":103.37444113782051,"type":"bar_chart","id":"bar_chart-10"},{"x":1775.5064888430497,"y":174.5534982150609,"width":117.47095583843227,"height":98.67560290428322,"type":"bar_chart","id":"bar_chart-11"},{"x":678.4875389408097,"y":174.98442367601245,"width":106.69781931464173,"height":1186.4797507788162,"type":"bar_chart","id":"bar_chart-4"},{"x":1182.1012461059188,"y":162.18068535825543,"width":102.42990654205597,"height":614.5794392523364,"type":"bar_chart","id":"bar_chart-5"},{"x":1288.7990654205605,"y":183.52024922118378,"width":68.28660436137079,"height":192.05607476635515,"type":"bar_chart","id":"bar_chart-6"},{"x":1374.157320872274,"y":174.98442367601245,"width":110.96573208722747,"height":200.59190031152644,"type":"bar_chart","id":"bar_chart-7"},{"x":1484.178518363737,"y":169.85465998152358,"width":103.37444113782047,"height":103.37444113782051,"type":"bar_chart","id":"bar_chart-8"},{"x":1578.1552830344829,"y":179.25233644859816,"width":96.32618378751476,"height":352.4128675152972,"type":"bar_chart","id":"bar_chart-9"},{"x":11.371411121464243,"y":92.65744383542116,"width":586.6639522008713,"height":1277.3425561645756,"type":"matrix","id":"matrix-13"},{"x":8.425233644859759,"y":102.42990654205609,"width":584.7040498442368,"height":1267.570093457944,"type":"scatterplot","id":"scatterplot-12"}],"relations":[{"vislist":[{"vislist":["scatterplot-12"],"relation":null,"id":"group-0"},{"vislist":["matrix-13"],"relation":null,"id":"group-1"}],"relation":"nested","id":"relation-0"},{"vislist":[{"vislist":["bar_chart-5","bar_chart-6","bar_chart-7","bar_chart-8","bar_chart-9","bar_chart-10","bar_chart-11"],"relation":null,"id":"group-3"}],"relation":"repeated","id":"relation-2"},{"vislist":[{"vislist":["bar_chart-4",{"vislist":[{"vislist":["area_chart-0","area_chart-1","area_chart-2","area_chart-3"],"relation":null,"id":"group-4"}],"relation":"repeated","id":"relation-3"}],"relation":null,"id":"group-5"}],"relation":"stacked","id":"relation-4"}]},"3065_0":{"comp":[["line_chart","line_chart",["repeated"]],["line_chart","area_chart",["accompanied"]],["area_chart","area_chart",["repeated"]],["area_chart","line_chart",["accompanied"]],["comb","comb",["repeated"]]],"visType":["line_chart","area_chart","comb"],"compType":["repeated","accompanied"],"compressed_tree":[{"composite_pattern":"repeated","visualization_type":[["line_chart"]]},{"composite_pattern":"repeated","visualization_type":[["area_chart"]]},{"composite_pattern":"repeated","visualization_type":[[{"composite_pattern":"accompanied","visualization_type":[["area_chart","line_chart"]]}]]}],"coOccurrence":[["line_chart","area_chart",["coOccurrence"]]],"year":2018,"conference":["VAST"],"authors":["Junpeng Wang","Liang Gou","Han-Wei Shen","Hao Yang"],"title":"DQNViz: A Visual Analytics Approach to Understand Deep Q-Networks","doi":"10.1109/TVCG.2018.2864504","abstract":"Deep Q-Network (DQN), as one type of deep reinforcement learning model, targets to train an intelligent agent that acquires optimal actions while interacting with an environment. The model is well known for its ability to surpass professional human players across many Atari 2600 games. Despite the superhuman performance, in-depth understanding of the model and interpreting the sophisticated behaviors of the DQN agent remain to be challenging tasks, due to the long-time model training process and the large number of experiences dynamically generated by the agent. In this work, we propose DQNViz, a visual analytics system to expose details of the blind training process in four levels, and enable users to dive into the large experience space of the agent for comprehensive analysis. As an initial attempt in visualizing DQN models, our work focuses more on Atari games with a simple action space, most notably the Breakout game. From our visual analytics of the agent\'s experiences, we extract useful action/reward patterns that help to interpret the model and control the training. Through multiple case studies conducted together with deep learning experts, we demonstrate that DQNViz can effectively help domain experts to understand, diagnose, and potentially improve DQN models.","keywords":"Deep Q-Network (DQN),reinforcement learning,model interpretation,visual analytics","caption":"Fig. 1. DQNViz: (a) the Statistics view presents the overall training statistics with line charts and stacked area charts; (b) the Epoch view shows epoch-level statistics with pie charts and stacked bar charts; (c) the Trajectory view reveals the movement and reward patterns of the DQN agent in different episodes; (d) the Segment view reveals what the agent really sees from a selected segment.","img_size":{"width":1954,"height":1151},"subfigures":[{"x":15.150416338942579,"y":11.736726653859941,"width":1922.4252523389364,"height":1133.8989913650903,"type":"interface","id":"interface-0"}],"visualizations":[{"x":26.968921959812818,"y":292.83816919672427,"width":1240.3402274730267,"height":103.56238792493227,"type":"area_chart","id":"area_chart-0"},{"x":24.560494333651597,"y":403.62584000014016,"width":1249.9739379776715,"height":122.82980893422202,"type":"area_chart","id":"area_chart-1"},{"x":32.45614144612803,"y":623.8944444364678,"width":1906.8783089135113,"height":521.7252863847965,"type":"area_chart","id":"area_chart-12"},{"x":1472.7320383847468,"y":88.78338215546034,"width":453.4241731391932,"height":190.9154413217655,"type":"bar_chart","id":"bar_chart-10"},{"x":1474.7285599215577,"y":310.5369259846456,"width":452.09837146334763,"height":197.54444970099348,"type":"bar_chart","id":"bar_chart-11"},{"x":1306.1747228127122,"y":92.79303922382479,"width":156.4669835947852,"height":185.8045430188074,"type":"donut_chart","id":"donut_chart-2"},{"x":1297.917445482866,"y":326.29595015576325,"width":164.94080996884756,"height":161.35514018691586,"type":"donut_chart","id":"donut_chart-3"},{"x":27.11211957493523,"y":70.6003549738536,"width":242.65439861553693,"height":216.771262763213,"type":"line_chart","id":"line_chart-4"},{"x":276.2373021535533,"y":67.3649629923131,"width":244.27209460630732,"height":223.24204672629395,"type":"line_chart","id":"line_chart-5"},{"x":528.5978767137116,"y":70.6003549738536,"width":245.88979059707736,"height":220.0066547447535,"type":"line_chart","id":"line_chart-6"},{"x":789.0469312277214,"y":62.51187502000237,"width":234.56591866168577,"height":229.7128306893749,"type":"line_chart","id":"line_chart-7"},{"x":1034.936721824799,"y":72.21805096462386,"width":241.0367026247668,"height":216.771262763213,"type":"line_chart","id":"line_chart-8"},{"x":28.590342679127616,"y":623.9065420560748,"width":1914.7476635514022,"height":527.093457943925,"type":"line_chart","id":"line_chart-9"}],"relations":[{"vislist":[{"vislist":["line_chart-4","line_chart-5","line_chart-6","line_chart-7","line_chart-8"],"relation":null,"id":"group-4"}],"relation":"repeated","id":"relation-0"},{"vislist":[{"vislist":["area_chart-0","area_chart-1"],"relation":null,"id":"group-5"}],"relation":"repeated","id":"relation-1"},{"vislist":[{"vislist":[{"vislist":[{"vislist":["area_chart-12","line_chart-9"],"relation":null,"id":"group-6"}],"relation":"accompanied","id":"relation-2"}],"relation":null,"id":"group-8"}],"relation":"repeated","id":"relation-4"}]},"3070_0":{"comp":[["bar_chart","bar_chart",["repeated"]],["heatmap","parallel_coordinate",["nested"]],["graph","donut_chart",["nested"]]],"visType":["bar_chart","heatmap","parallel_coordinate","graph","donut_chart"],"compType":["repeated","nested"],"compressed_tree":[{"composite_pattern":"nested","visualization_type":[["heatmap"],["parallel_coordinate"]]},{"composite_pattern":"nested","visualization_type":[["graph"],["donut_chart"]]},{"composite_pattern":"repeated","visualization_type":[["bar_chart"]]}],"coOccurrence":[["heatmap","parallel_coordinate",["coOccurrence"]],["heatmap","graph",["coOccurrence"]],["heatmap","donut_chart",["coOccurrence"]],["heatmap","bar_chart",["coOccurrence"]],["parallel_coordinate","graph",["coOccurrence"]],["parallel_coordinate","donut_chart",["coOccurrence"]],["parallel_coordinate","bar_chart",["coOccurrence"]],["graph","donut_chart",["coOccurrence"]],["graph","bar_chart",["coOccurrence"]],["donut_chart","bar_chart",["coOccurrence"]]],"year":2018,"conference":["VAST"],"authors":["Xuanwu Yue","Xinhuan Shu","Xinyu Zhu","Xinnan Du","Zheqing Yu","Dimitrios Papadopoulos","Siyuan Liu"],"title":"BitExTract: Interactive Visualization for Extracting Bitcoin Exchange Intelligence","doi":"10.1109/TVCG.2018.2864814","abstract":"The emerging prosperity of cryptocurrencies, such as Bitcoin, has come into the spotlight during the past few years. Cryptocurrency exchanges, which act as the gateway to this world, now play a dominant role in the circulation of Bitcoin. Thus, delving into the analysis of the transaction patterns of exchanges can shed light on the evolution and trends in the Bitcoin market, and participants can gain hints for identifying credible exchanges as well. Not only Bitcoin practitioners but also researchers in the financial domains are interested in the business intelligence behind the curtain. However, the task of multiple exchanges exploration and comparisons has been limited owing to the lack of efficient tools. Previous methods of visualizing Bitcoin data have mainly concentrated on tracking suspicious transaction logs, but it is cumbersome to analyze exchanges and their relationships with existing tools and methods. In this paper, we present BitExTract, an interactive visual analytics system, which, to the best of our knowledge, is the first attempt to explore the evolutionary transaction patterns of Bitcoin exchanges from two perspectives, namely, exchange versus exchange and exchange versus client. In particular, BitExTract summarizes the evolution of the Bitcoin market by observing the transactions between exchanges over time via a massive sequence view. A node-link diagram with ego-centered views depicts the trading network of exchanges and their temporal transaction distribution. Moreover, BitExTract embeds multiple parallel bars on a timeline to examine and compare the evolution patterns of transactions between different exchanges. Three case studies with novel insights demonstrate the effectiveness and usability of our system.","keywords":"Bitcoin exchange,transaction data,comparative analysis,visual analytics,FinTech","caption":"Fig. 1. With BitExTract, we can observe the evolution of transaction and connection patterns of Bitcoin exchanges from different perspectives A) The comparison view is designed to be highly interactive to compare multiple exchanges\u2019 different indices. B) The exchanges list panel reveals Bitcoin exchanges\u2019 historical transaction volume. C) The massive sequence view (MSV) demonstrates the overview of Bitcoin exchange market. Users can focus on one exchange to specifically exam its holistic connections. D) The connection view illustrates the connection details intuitively with a node-link design which can facilitate the recognition of unique patterns.","img_size":{"width":1969,"height":1043},"subfigures":[{"x":12.765423534349834,"y":7.7325455737101425,"width":1939.7766304842069,"height":1028.7657538279725,"type":"interface","id":"interface-0"}],"visualizations":[{"x":1658.9124726477025,"y":134.65426695842453,"width":296.6958424507659,"height":903.7811816192558,"type":"bar_chart","id":"bar_chart-1"},{"x":20.2385120350109,"y":944.8621444201314,"width":1022.4595185995624,"height":84.4442013129102,"type":"bar_chart","id":"bar_chart-2"},{"x":1092.9080962800876,"y":570.5689277899344,"width":529.487964989059,"height":463.30196936542666,"type":"donut_chart","id":"donut_chart-3"},{"x":1157.3642238257196,"y":627.7322864525928,"width":368.3701866429473,"height":358.3463153469626,"type":"graph","id":"graph-8"},{"x":15.673960612691445,"y":68.46827133479212,"width":1602.1575492341356,"height":472.43107221006574,"type":"heatmap","id":"heatmap-4"},{"x":415.07221006564544,"y":552.3107221006564,"width":659.5776805251643,"height":383.42231947483594,"type":"heatmap","id":"heatmap-5"},{"x":29.36761487964986,"y":613.9321663019695,"width":321.80087527352293,"height":139.21881838074398,"type":"heatmap","id":"heatmap-6"},{"x":13.391684901531706,"y":68.46827133479212,"width":1606.7221006564555,"height":472.43107221006574,"type":"parallel_coordinate","id":"parallel_coordinate-7"}],"relations":[{"vislist":[{"vislist":["heatmap-4"],"relation":null,"id":"group-0"},{"vislist":["parallel_coordinate-7"],"relation":null,"id":"group-1"}],"relation":"nested","id":"relation-0"},{"vislist":[{"vislist":["graph-8"],"relation":null,"id":"group-2"},{"vislist":["donut_chart-3"],"relation":null,"id":"group-3"}],"relation":"nested","id":"relation-1"},{"vislist":[{"vislist":["bar_chart-1"],"relation":null,"id":"group-4"}],"relation":"repeated","id":"relation-2"}]},"3071_3":{"comp":[["comb","comb",["repeated"]],["comb","bar_chart",["nested"]],["area_chart","polar_plot",["accompanied"]],["polar_plot","area_chart",["accompanied"]],["glyph_based","matrix",["nested"]],["scatterplot","polar_plot",["nested"]],["graph","matrix",["coordinated"]],["bar_chart","matrix",["stacked"]],["matrix","bar_chart",["stacked"]]],"visType":["comb","bar_chart","area_chart","polar_plot","glyph_based","matrix","scatterplot","graph"],"compType":["repeated","nested","accompanied","coordinated","stacked"],"compressed_tree":[{"composite_pattern":"nested","visualization_type":[["glyph_based"],["matrix"]]},{"composite_pattern":"coordinated","visualization_type":[["graph"],["matrix"]]},{"composite_pattern":"repeated","visualization_type":[[{"composite_pattern":"nested","visualization_type":[["scatterplot"],["polar_plot"]]}]]},{"composite_pattern":"stacked","visualization_type":[["bar_chart","matrix"]]},{"composite_pattern":"stacked","visualization_type":[["bar_chart","matrix"]]},{"composite_pattern":"nested","visualization_type":[[{"composite_pattern":"accompanied","visualization_type":[["area_chart","polar_plot"]]}],["bar_chart"]]}],"coOccurrence":[["glyph_based","matrix",["coOccurrence"]],["glyph_based","area_chart",["coOccurrence"]],["glyph_based","polar_plot",["coOccurrence"]],["glyph_based","scatterplot",["coOccurrence"]],["glyph_based","graph",["coOccurrence"]],["glyph_based","bar_chart",["coOccurrence"]],["matrix","area_chart",["coOccurrence"]],["matrix","polar_plot",["coOccurrence"]],["matrix","scatterplot",["coOccurrence"]],["matrix","graph",["coOccurrence"]],["matrix","bar_chart",["coOccurrence"]],["area_chart","polar_plot",["coOccurrence"]],["area_chart","scatterplot",["coOccurrence"]],["area_chart","graph",["coOccurrence"]],["area_chart","bar_chart",["coOccurrence"]],["polar_plot","scatterplot",["coOccurrence"]],["polar_plot","graph",["coOccurrence"]],["polar_plot","bar_chart",["coOccurrence"]],["scatterplot","graph",["coOccurrence"]],["scatterplot","bar_chart",["coOccurrence"]],["graph","bar_chart",["coOccurrence"]]],"year":2018,"conference":["VAST"],"authors":["Ke Xu","Meng Xia","Xing Mu","Yun Wang","Nan Cao"],"title":"EnsembleLens: Ensemble-based Visual Exploration of Anomaly Detection Algorithms with Multidimensional Data","doi":"10.1109/TVCG.2018.2864825","abstract":"The results of anomaly detection are sensitive to the choice of detection algorithms as they are specialized for different properties of data, especially for multidimensional data. Thus, it is vital to select the algorithm appropriately. To systematically select the algorithms, ensemble analysis techniques have been developed to support the assembly and comparison of heterogeneous algorithms. However, challenges remain due to the absence of the ground truth, interpretation, or evaluation of these anomaly detectors. In this paper, we present a visual analytics system named EnsembleLens that evaluates anomaly detection algorithms based on the ensemble analysis process. The system visualizes the ensemble processes and results by a set of novel visual designs and multiple coordinated contextual views to meet the requirements of correlation analysis, assessment and reasoning of anomaly detection algorithms. We also introduce an interactive analysis workflow that dynamically produces contextualized and interpretable data summaries that allow further refinements of exploration results based on user feedback. We demonstrate the effectiveness of EnsembleLens through a quantitative evaluation, three case studies with real-world data and interviews with two domain experts.","keywords":"Algorithm Evaluation,Ensemble Analysis,Anomaly Detection,Visual Analysis,Multidimensional Data","caption":"Fig. 4. The EnsembleLens system contains six interactively coordinated views: (i) a detector view, (ii) a feature subspace view, (iii) an inspection view (global inspection view & correlation matrix view), (iv) a ranking view, (v) a validation view and (vi) a raw data table. Users can change the detection mode in (a) and provide their feedback by using (b) after they label the detected anomalous points. The progress of exploration can be reflected by (d) the real-time combination result. Raw data description can be obtained via informative tooltips. (c) is the color schemes used in different views.","img_size":{"width":2133,"height":1173},"subfigures":[{"x":4.5224169706209825,"y":38.7963081542207,"width":2113.288295729117,"height":1123.4291377831423,"type":"interface","id":"interface-0"}],"visualizations":[{"x":71.8036659312932,"y":154.00227823410208,"width":234.3526814964273,"height":237.09904003677707,"type":"area_chart","id":"area_chart-0"},{"x":1786.704022988506,"y":840.425287356322,"width":274.1494252873563,"height":298.86781609195384,"type":"bar_chart","id":"bar_chart-1"},{"x":1313.030889251684,"y":105.31337430336079,"width":183.01801536029896,"height":92.21292312384294,"type":"bar_chart","id":"bar_chart-2"},{"x":26.79660117089743,"y":107.27296212871856,"width":339.6685579009954,"height":328.20960060444145,"type":"bar_chart","id":"bar_chart-23"},{"x":975.1514762788246,"y":96.16247353534587,"width":196.39240879047478,"height":96.43641578600369,"type":"bar_chart","id":"bar_chart-3"},{"x":406.9683908045974,"y":101.12068965517244,"width":539.3103448275864,"height":521.3333333333329,"type":"glyph_based","id":"glyph_based-4"},{"x":424.16146868241674,"y":102.00236605838593,"width":506.24534791589633,"height":515.3488590434489,"type":"graph","id":"graph-24"},{"x":1317.7770161999713,"y":197.52629742720373,"width":186.4508547447893,"height":463.1288749865895,"type":"matrix","id":"matrix-12"},{"x":975.3023480706199,"y":194.71063565242972,"width":192.81956080723782,"height":463.6974103245813,"type":"matrix","id":"matrix-13"},{"x":406.9683908045976,"y":96.62643678160917,"width":534.8160919540231,"height":530.3218390804597,"type":"matrix","id":"matrix-14"},{"x":1031.669540229885,"y":822.4482758620691,"width":746.0459770114941,"height":316.84482758620686,"type":"parallel_coordinate","id":"parallel_coordinate-15"},{"x":69.36873694455025,"y":148.66232795550263,"width":237.54552194227085,"height":239.73856247979958,"type":"polar_plot","id":"polar_plot-17"},{"x":39.872740314256816,"y":533.2550096455157,"width":159.67323632654043,"height":158.06037535354503,"type":"polar_plot","id":"polar_plot-18"},{"x":39.872740314256816,"y":742.9269361349121,"width":159.67323632654043,"height":161.28609729953587,"type":"polar_plot","id":"polar_plot-19"},{"x":41.48560128725223,"y":955.8245845702996,"width":154.8346534075543,"height":154.83465340755424,"type":"polar_plot","id":"polar_plot-20"},{"x":83.94667171828654,"y":580.2199759344413,"width":63.532301479966556,"height":59.54485476095146,"type":"scatterplot","id":"scatterplot-25"},{"x":85.56317341670488,"y":794.2869555773547,"width":65.1543815429213,"height":52.65398939777562,"type":"scatterplot","id":"scatterplot-26"},{"x":83.95701808567023,"y":1008.049325358112,"width":66.74833105172578,"height":62.574001217476585,"type":"scatterplot","id":"scatterplot-27"},{"x":391.2385057471263,"y":734.810344827586,"width":568.5229885057472,"height":399.9885057471265,"type":"table","id":"table-21"},{"x":1784.8540663697886,"y":652.1608061841548,"width":204.89889851631395,"height":234.99704180119616,"type":"table","id":"table-22"}],"relations":[{"vislist":[{"vislist":["glyph_based-4"],"relation":null,"id":"group-0"},{"vislist":["matrix-14"],"relation":null,"id":"group-1"}],"relation":"nested","id":"relation-0"},{"vislist":[{"vislist":["graph-24"],"relation":null,"id":"group-11"},{"vislist":["matrix-14"],"relation":null,"id":"group-12"}],"relation":"coordinated","id":"relation-6"},{"vislist":[{"vislist":[{"vislist":[{"vislist":["scatterplot-27"],"relation":null,"id":"group-13"},{"vislist":["polar_plot-20"],"relation":null,"id":"group-14"}],"relation":"nested","id":"relation-5"},{"vislist":[{"vislist":["scatterplot-26"],"relation":null,"id":"group-15"},{"vislist":["polar_plot-19"],"relation":null,"id":"group-16"}],"relation":"nested","id":"relation-4"},{"vislist":[{"vislist":["scatterplot-25"],"relation":null,"id":"group-17"},{"vislist":["polar_plot-18"],"relation":null,"id":"group-18"}],"relation":"nested","id":"relation-3"}],"relation":null,"id":"group-19"}],"relation":"repeated","id":"relation-7"},{"vislist":[{"vislist":["bar_chart-3","matrix-13"],"relation":null,"id":"group-20"}],"relation":"stacked","id":"relation-8"},{"vislist":[{"vislist":["bar_chart-2","matrix-12"],"relation":null,"id":"group-21"}],"relation":"stacked","id":"relation-9"},{"vislist":[{"vislist":[{"vislist":[{"vislist":["area_chart-0","polar_plot-17"],"relation":null,"id":"group-2"}],"relation":"accompanied","id":"relation-1"}],"relation":null,"id":"group-26"},{"vislist":["bar_chart-23"],"relation":null,"id":"group-27"}],"relation":"nested","id":"relation-10"}]},"3072_0":{"comp":[["bar_chart","bar_chart",["repeated"]],["proportional_area_chart","bar_chart",["nested"]]],"visType":["bar_chart","proportional_area_chart"],"compType":["repeated","nested"],"compressed_tree":[{"composite_pattern":"nested","visualization_type":[["proportional_area_chart"],["bar_chart"]]},{"composite_pattern":"repeated","visualization_type":[["bar_chart"]]}],"coOccurrence":[["proportional_area_chart","bar_chart",["coOccurrence"]]],"year":2018,"conference":["VAST"],"authors":["Gromit Yeuk-Yin Chan","Panpan Xu","Zeng Dai","Liu Ren"],"title":"VIBR: Visualizing Bipartite Relations at Scale with the Minimum Description Length Principle","doi":"10.1109/TVCG.2018.2864826","abstract":"Bipartite graphs model the key relations in many large scale real-world data: customers purchasing items, legislators voting for bills, people\'s affiliation with different social groups, faults occurring in vehicles, etc. However, it is challenging to visualize large scale bipartite graphs with tens of thousands or even more nodes or edges. In this paper, we propose a novel visual summarization technique for bipartite graphs based on the minimum description length (MDL) principle. The method simultaneously groups the two different set of nodes and constructs aggregated bipartite relations with balanced granularity and precision. It addresses the key trade-off that often occurs for visualizing large scale and noisy data: acquiring a clear and uncluttered overview while maximizing the information content in it. We formulate the visual summarization task as a co-clustering problem and propose an efficient algorithm based on locality sensitive hashing (LSH) that can easily scale to large graphs under reasonable interactive time constraints that previous related methods cannot satisfy. The method leads to the opportunity of introducing a visual analytics framework with multiple levels-of-detail to facilitate interactive data exploration. In the framework, we also introduce a compact visual design inspired by adjacency list representation of graphs as the building block for a small multiples display to compare the bipartite relations for different subsets of data. We showcase the applicability and effectiveness of our approach by applying it on synthetic data with ground truth and performing case studies on real-world datasets from two application domains including roll-call vote record analysis and vehicle fault pattern analysis. Interviews with experts in the political science community and the automotive industry further highlight the benefits of our approach.","keywords":"Bipartite Graph,Visual Summarization,Minimum Description Length,Information Theory","caption":"Fig. 1. V I B R interface. First analyst selects the data using the filters D and computes a summarization A filtered by the density and the sizes of the clusters B . From the adjacency list A she observes different fault patterns (a and b). Splitting the summary view into small multiples 1 , several unique groups of faults (e.g. c) only occur in vehicles with a particular engine code. Next level of detail is shown by bringing up a matrix view for a particular block 2 . Labels are always provided in the legend bar with text search G . The node attribute value distributions and detail node information are displayed in E and table F respectively.","img_size":{"width":1964,"height":1106},"subfigures":[{"x":10.279772430583629,"y":10.452491096415013,"width":1938.5295940681729,"height":1088.7803974446085,"type":"interface","id":"interface-0"}],"visualizations":[{"x":588.5612648221346,"y":190.1620449134012,"width":1138.7865612648222,"height":854.6363636363636,"type":"bar_chart","id":"bar_chart-0"},{"x":221.35177865612656,"y":242.62054293711668,"width":271.0355731225296,"height":207.64822134387347,"type":"bar_chart","id":"bar_chart-1"},{"x":221.35177865612656,"y":467.75493028889525,"width":277.592885375494,"height":146.4466403162055,"type":"bar_chart","id":"bar_chart-2"},{"x":586.3754940711462,"y":190.1620449134012,"width":1138.7865612648222,"height":852.4505928853753,"type":"bar_chart","id":"bar_chart-3"},{"x":589.9638132765792,"y":197.44480091035453,"width":1136.7827798022483,"height":841.3932550138945,"type":"proportional_area_chart","id":"proportional_area_chart-6"},{"x":219.16600790513843,"y":732.2331911584605,"width":351.9090909090908,"height":369.93344688160624,"type":"table","id":"table-4"},{"x":1615.8735177865615,"y":159.5612543995672,"width":264.478260869565,"height":657.9169960474306,"type":"table","id":"table-5"}],"relations":[{"vislist":[{"vislist":["proportional_area_chart-6"],"relation":null,"id":"group-1"},{"vislist":["bar_chart-3"],"relation":null,"id":"group-2"}],"relation":"nested","id":"relation-0"},{"vislist":[{"vislist":["bar_chart-0","bar_chart-1"],"relation":null,"id":"group-3"}],"relation":"repeated","id":"relation-1"}]},"3075_0":{"comp":[["map","map",["repeated"]],["graph","graph",["repeated"]],["glyph_based","graph",["nested"]],["error_bar","graph",["nested"]]],"visType":["map","graph","glyph_based","error_bar"],"compType":["repeated","nested"],"compressed_tree":[{"composite_pattern":"repeated","visualization_type":[["map"]]},{"composite_pattern":"nested","visualization_type":[["glyph_based"],["graph"]]},{"composite_pattern":"nested","visualization_type":[["error_bar"],["graph"]]},{"composite_pattern":"repeated","visualization_type":[["graph"]]}],"coOccurrence":[["map","glyph_based",["coOccurrence"]],["map","graph",["coOccurrence"]],["map","error_bar",["coOccurrence"]],["glyph_based","graph",["coOccurrence"]],["glyph_based","error_bar",["coOccurrence"]],["graph","error_bar",["coOccurrence"]]],"year":2018,"conference":["VAST"],"authors":["Hong Wang","Yafeng Lu","Shade T. Shutters","Michael Steptoe","Feng Wan","Steven Landis","Ross Maciejewski"],"title":"A Visual Analytics Framework for Spatiotemporal Trade Network Analysis","doi":"10.1109/TVCG.2018.2864844","abstract":"Economic globalization is increasing connectedness among regions of the world, creating complex interdependencies within various supply chains. Recent studies have indicated that changes and disruptions within such networks can serve as indicators for increased risks of violence and armed conflicts. This is especially true of countries that may not be able to compete for scarce commodities during supply shocks. Thus, network-induced vulnerability to supply disruption is typically exported from wealthier populations to disadvantaged populations. As such, researchers and stakeholders concerned with supply chains, political science, environmental studies, etc. need tools to explore the complex dynamics within global trade networks and how the structure of these networks relates to regional instability. However, the multivariate, spatiotemporal nature of the network structure creates a bottleneck in the extraction and analysis of correlations and anomalies for exploratory data analysis and hypothesis generation. Working closely with experts in political science and sustainability, we have developed a highly coordinated, multi-view framework that utilizes anomaly detection, network analytics, and spatiotemporal visualization methods for exploring the relationship between global trade networks and regional instability. Requirements for analysis and initial research questions to be investigated are elicited from domain experts, and a variety of visual encoding techniques for rapid assessment of analysis and correlations between trade goods, network patterns, and time series signatures are explored. We demonstrate the application of our framework through case studies focusing on armed conflicts in Africa, regional instability measures, and their relationship to international global trade.","keywords":"Global trade network,anomaly detection,visual analytics","caption":"Fig. 1. A visual analytics framework for exploring global trade networks and their relationship to regional instability. The anomaly time series (1) on top displays the time series and anomalies of the trade attributes and stability measures for a selected country. The choropleth view (2) along with the small multiple maps (3) display the first order trade relationships centering on selected countries. The colored bars below each small multiple map show the temporal correlation of the selected trade measure to the stability measure. The clustering view (4) displays the hierarchical clustering for the countries, based on either the triadic similarity or top partner similarity. The groups can also be configured to show the average triad distributions (as (6)) and other measures. The trade diffusion graph (5) displays the propagation effect of anomalies. Connections between the nodes indicate the import dependency from the target node to the source node is larger than a threshold, which can be adjusted using the slider on the right.","img_size":{"width":1974,"height":973},"subfigures":[{"x":15.259152023595327,"y":10.557067951933638,"width":1944.7156623165386,"height":948.1846741876274,"type":"interface","id":"interface-0"}],"visualizations":[{"x":272.00642398437,"y":787.5635967309847,"width":182.38320665948442,"height":166.97758311738232,"type":"error_bar","id":"error_bar-23"},{"x":516.7201682326994,"y":789.1153595433931,"width":187.20458007481415,"height":169.8709758284687,"type":"error_bar","id":"error_bar-24"},{"x":759.5172763200752,"y":791.9706394718827,"width":186.8728828681939,"height":158.16349763558708,"type":"error_bar","id":"error_bar-25"},{"x":1300.0078686653806,"y":574.718582865914,"width":365.4774341411642,"height":394.7693057627792,"type":"glyph_based","id":"glyph_based-26"},{"x":16.19548218960996,"y":676.1056427631809,"width":153.1749528400575,"height":94.71123038202029,"type":"graph","id":"graph-16"},{"x":1304.2826086956522,"y":573.0316113841393,"width":355.74110671936745,"height":398.0454545454546,"type":"graph","id":"graph-21"},{"x":271.6719367588932,"y":576.8774611865108,"width":680.7154150197628,"height":378.81620553359676,"type":"graph","id":"graph-22"},{"x":167.83399209486154,"y":186.52370624579927,"width":819.1660079051385,"height":403.8142292490118,"type":"heatmap","id":"heatmap-17"},{"x":163.98814229248998,"y":40.38141375568073,"width":1794.088932806324,"height":151.91106719367588,"type":"line_chart","id":"line_chart-20"},{"x":1025.458498023715,"y":476.8853663248508,"width":234.59683794466395,"height":103.83794466403162,"type":"map","id":"map-10"},{"x":1250.4407114624505,"y":192.29248094935662,"width":232.67391304347822,"height":234.59683794466403,"type":"map","id":"map-11"},{"x":1260.0553359683793,"y":478.80829122603643,"width":224.982213438735,"height":107.6837944664032,"type":"map","id":"map-12"},{"x":1485.0375494071143,"y":480.73121612722224,"width":221.13636363636368,"height":99.99209486166006,"type":"map","id":"map-13"},{"x":1486.9604743083,"y":194.2154058505424,"width":219.213438735178,"height":234.59683794466403,"type":"map","id":"map-14"},{"x":1711.9426877470353,"y":194.2154058505424,"width":230.75098814229247,"height":232.67391304347828,"type":"map","id":"map-15"},{"x":165.91106719367582,"y":186.52370624579927,"width":824.9347826086956,"height":407.66007905138343,"type":"map","id":"map-8"},{"x":1025.458498023715,"y":192.29248094935662,"width":230.75098814229247,"height":232.67391304347828,"type":"map","id":"map-9"}],"relations":[{"vislist":[{"vislist":["map-9","map-10","map-11","map-12","map-13","map-14","map-15"],"relation":null,"id":"group-3"}],"relation":"repeated","id":"relation-1"},{"vislist":[{"vislist":["glyph_based-26"],"relation":null,"id":"group-4"},{"vislist":["graph-21"],"relation":null,"id":"group-5"}],"relation":"nested","id":"relation-2"},{"vislist":[{"vislist":["error_bar-23","error_bar-24","error_bar-25"],"relation":null,"id":"group-1"},{"vislist":["graph-22"],"relation":null,"id":"group-6"}],"relation":"nested","id":"relation-3"},{"vislist":[{"vislist":["graph-16"],"relation":null,"id":"group-7"}],"relation":"repeated","id":"relation-4"}]},"3076_3":{"comp":[["bar_chart","bar_chart",["repeated"]],["bar_chart","treemap",["nested"]],["treemap","graph",["nested"]],["unit_visualization","treemap",["nested"]],["comb","graph",["nested"]]],"visType":["bar_chart","treemap","graph","unit_visualization","comb"],"compType":["repeated","nested"],"compressed_tree":[{"composite_pattern":"repeated","visualization_type":[["bar_chart"]]},{"composite_pattern":"nested","visualization_type":[["treemap"],["graph"]]},{"composite_pattern":"nested","visualization_type":[[{"composite_pattern":"nested","visualization_type":[["bar_chart","unit_visualization"],["treemap"]]}],["graph"]]}],"coOccurrence":[["bar_chart","unit_visualization",["coOccurrence"]],["bar_chart","treemap",["coOccurrence"]],["bar_chart","graph",["coOccurrence"]],["unit_visualization","treemap",["coOccurrence"]],["unit_visualization","graph",["coOccurrence"]],["treemap","graph",["coOccurrence"]]],"year":2018,"conference":["VAST"],"authors":["Shunan Guo","Zhuochen Jin","David Gotz","Fan Du","Hongyuan Zha","Nan Cao"],"title":"Visual Progression Analysis of Event Sequence Data","doi":"10.1109/TVCG.2018.2864885","abstract":"Event sequence data is common to a broad range of application domains, from security to health care to scholarly communication. This form of data captures information about the progression of events for an individual entity (e.g., a computer network device; a patient; an author) in the form of a series of time-stamped observations. Moreover, each event is associated with an event type (e.g., a computer login attempt, or a hospital discharge). Analyses of event sequence data have been shown to help reveal important temporal patterns, such as clinical paths resulting in improved outcomes, or an understanding of common career trajectories for scholars. Moreover, recent research has demonstrated a variety of techniques designed to overcome methodological challenges such as large volumes of data and high dimensionality. However, the effective identification and analysis of latent stages of progression, which can allow for variation within different but similarly evolving event sequences, remain a significant challenge with important real-world motivations. In this paper, we propose an unsupervised stage analysis algorithm to identify semantically meaningful progression stages as well as the critical events which help define those stages. The algorithm follows three key steps: (1) event representation estimation, (2) event sequence warping and alignment, and (3) sequence segmentation. We also present a novel visualization system, ET<sup>2</sup>, which interactively illustrates the results of the stage analysis algorithm to help reveal evolution patterns across stages. Finally, we report three forms of evaluation for ET<sup>2</sup>: (1) case studies with two real-world datasets, (2) interviews with domain expert users, and (3) a performance evaluation on the progression analysis algorithm and the visualization design.","keywords":"Progression Analysis,Visual Analysis,Event Sequence Data","caption":"Fig. 4. The user interface of ET2 consists of seven coordinated views: (1) query view, (2) sequence view, (3) cluster view, (4) thread view, (5) stage transition view, (6) event overview, and (7) entity list view.","img_size":{"width":2034,"height":823},"subfigures":[{"x":279.6345066017303,"y":80.87981806670778,"width":966.1418107417834,"height":694.2997031131973,"type":"interface","id":"interface-0"},{"x":1179.458201605923,"y":413.4814855629444,"width":732.9490829820443,"height":397.83515202524455,"type":"interface","id":"interface-1"},{"x":1287.7861182935796,"y":45.122772452096754,"width":731.172176489867,"height":314.4266623213652,"type":"interface","id":"interface-2"}],"visualizations":[{"x":525.0221402214024,"y":217.19912736618213,"width":61.390617752331195,"height":558.7417731966697,"type":"bar_chart","id":"bar_chart-0"},{"x":643.4612546125463,"y":220.23602773518576,"width":51.62730627306268,"height":552.7158671586717,"type":"bar_chart","id":"bar_chart-1"},{"x":1292.3682825218061,"y":177.12986104130292,"width":737.8749675815775,"height":186.17179761720618,"type":"bar_chart","id":"bar_chart-14"},{"x":819.60147601476,"y":226.3098284731932,"width":49.205278206628,"height":544.5428919770882,"type":"bar_chart","id":"bar_chart-2"},{"x":938.0405904059043,"y":229.34672884219688,"width":60.73800738007389,"height":543.6051660516605,"type":"bar_chart","id":"bar_chart-3"},{"x":1047.369003690037,"y":214.16222699717844,"width":79.66289124429682,"height":561.7786735656734,"type":"bar_chart","id":"bar_chart-4"},{"x":523.3685704700379,"y":104.65186716479911,"width":721.537088047894,"height":105.52785704530527,"type":"graph","id":"graph-6"},{"x":1292.2758161558113,"y":178.66297791838105,"width":727.7001108082833,"height":174.29942773851087,"type":"graph","id":"graph-7"},{"x":129.7485928705441,"y":619.4793621013131,"width":122.11632270168853,"height":160.27767354596634,"type":"matrix","id":"matrix-10"},{"x":136.108818011257,"y":376.51876172607876,"width":109.51848826180573,"height":226.3667125035721,"type":"matrix","id":"matrix-9"},{"x":279.03321033210335,"y":86.61241149902345,"width":224.73062730627308,"height":255.09963099630997,"type":"scatterplot","id":"scatterplot-8"},{"x":1180.92222105521,"y":440.8783987637144,"width":736.99622556788,"height":375.1325082887068,"type":"storyline","id":"storyline-11"},{"x":1293.8974971795787,"y":180.16592788234732,"width":734.8165382660342,"height":183.18784404768758,"type":"treemap","id":"treemap-12"},{"x":522.810506566604,"y":106.84521575984992,"width":721.249530956848,"height":104.30769230769234,"type":"treemap","id":"treemap-5"},{"x":1292.3495837507485,"y":178.58362109710873,"width":734.8258704347732,"height":178.63200733673878,"type":"unit_visualization","id":"unit_visualization-13"}],"relations":[{"vislist":[{"vislist":["bar_chart-0","bar_chart-1","bar_chart-2","bar_chart-3","bar_chart-4"],"relation":null,"id":"group-1"}],"relation":"repeated","id":"relation-0"},{"vislist":[{"vislist":["treemap-5"],"relation":null,"id":"group-5"},{"vislist":["graph-6"],"relation":null,"id":"group-6"}],"relation":"nested","id":"relation-3"},{"vislist":[{"vislist":[{"vislist":[{"vislist":["bar_chart-14","unit_visualization-13"],"relation":null,"id":"group-1"},{"vislist":["treemap-12"],"relation":null,"id":"group-2"}],"relation":"nested","id":"relation-1"}],"relation":null,"id":"group-7"},{"vislist":["graph-7"],"relation":null,"id":"group-8"}],"relation":"nested","id":"relation-4"}]},"3077_0":{"comp":[["sunburst_icicle","sunburst_icicle",["repeated"]]],"visType":["sunburst_icicle"],"compType":["repeated"],"compressed_tree":[{"composite_pattern":"repeated","visualization_type":[["sunburst_icicle"]]}],"coOccurrence":[["sunburst_icicle","sunburst_icicle",["coOccurrence"]]],"year":2018,"conference":["VAST"],"authors":["Po-Ming Law","Zhicheng Liu","Sana Malik","Rahul C. Basole"],"title":"MAQUI: Interweaving Queries and Pattern Mining for Recursive Event Sequence Exploration","doi":"10.1109/TVCG.2018.2864886","abstract":"Exploring event sequences by defining queries alone or by using mining algorithms alone is often not sufficient to support analysis. Analysts often interweave querying and mining in a recursive manner during event sequence analysis: sequences extracted as query results are used for mining patterns, patterns generated are incorporated into a new query for segmenting the sequences, and the resulting segments are mined or queried again. To support flexible analysis, we propose a framework that describes the process of interwoven querying and mining. Based on this framework, we developed MAQUI, a Mining And Querying User Interface that enables recursive event sequence exploration. To understand the efficacy of MAQUI, we conducted two case studies with domain experts. The findings suggest that the capability of interweaving querying and mining helps the participants articulate their questions and gain novel insights from their data.","keywords":"Sequential pattern mining,temporal query,event sequence exploration","caption":"Fig. 1. There are four major views in MAQUI: (a) the workspace, (b) the frequent pattern view (c) the attribute-value pair view and (d) the raw sequence view. (1) As the analyst clicks on the rectangular region between HOME and OFFICE , it becomes the current focus and is highlighted in yellow. The frequent pattern view, the attribute-value pair view and the raw sequence view are subsequently updated. (2) The analyst is selecting the SUBWAY \u2192SUBWAY \u2192SUBWAY pattern and using it to split up the segments between HOME and OFFICE . The bottom panel is in turn created.","img_size":{"width":1979,"height":884},"subfigures":[{"x":17.74058426783567,"y":11.256118409337526,"width":1938.5704638172656,"height":862.7244294938843,"type":"interface","id":"interface-0"}],"visualizations":[{"x":82.63793103448285,"y":116.85057471264369,"width":1327.6934865900384,"height":264.18390804597703,"type":"sunburst_icicle","id":"sunburst_icicle-0"},{"x":47.074712643678225,"y":511.4329501915709,"width":1366.6436781609195,"height":257.40996168582376,"type":"sunburst_icicle","id":"sunburst_icicle-1"}],"relations":[{"vislist":[{"vislist":["sunburst_icicle-0","sunburst_icicle-1"],"relation":null,"id":"group-0"}],"relation":"repeated","id":"relation-0"}]},"3081_0":{"comp":[["bar_chart","bar_chart",["repeated"]],["heatmap","sankey_diagram",["nested"]],["donut_chart","map",["coordinated"]]],"visType":["bar_chart","heatmap","sankey_diagram","donut_chart","map"],"compType":["repeated","nested","coordinated"],"compressed_tree":[{"composite_pattern":"nested","visualization_type":[["heatmap"],["sankey_diagram"]]},{"composite_pattern":"repeated","visualization_type":[["bar_chart"]]},{"composite_pattern":"coordinated","visualization_type":[["donut_chart"],["map"]]}],"coOccurrence":[["heatmap","sankey_diagram",["coOccurrence"]],["heatmap","bar_chart",["coOccurrence"]],["heatmap","donut_chart",["coOccurrence"]],["heatmap","map",["coOccurrence"]],["sankey_diagram","bar_chart",["coOccurrence"]],["sankey_diagram","donut_chart",["coOccurrence"]],["sankey_diagram","map",["coOccurrence"]],["bar_chart","donut_chart",["coOccurrence"]],["bar_chart","map",["coOccurrence"]],["donut_chart","map",["coOccurrence"]]],"year":2018,"conference":["VAST"],"authors":["Dongyu Liu","Panpan Xu","Liu Ren"],"title":"TPFlow: Progressive Partition and Multidimensional Pattern Extraction for Large-Scale Spatio-Temporal Data Analysis","doi":"10.1109/TVCG.2018.2865018","abstract":"Consider a multi-dimensional spatio-temporal (ST) dataset where each entry is a numerical measure defined by the corresponding temporal, spatial and other domain-specific dimensions. A typical approach to explore such data utilizes interactive visualizations with multiple coordinated views. Each view displays the aggregated measures along one or two dimensions. By brushing on the views, analysts can obtain detailed information. However, this approach often cannot provide sufficient guidance for analysts to identify patterns hidden within subsets of data. Without a priori hypotheses, analysts need to manually select and iterate through different slices to search for patterns, which can be a tedious and lengthy process. In this work, we model multidimensional ST data as tensors and propose a novel piecewise rank-one tensor decomposition algorithm which supports automatically slicing the data into homogeneous partitions and extracting the latent patterns in each partition for comparison and visual summarization. The algorithm optimizes a quantitative measure about how faithfully the extracted patterns visually represent the original data. Based on the algorithm we further propose a visual analytics framework that supports a top-down, progressive partitioning workflow for level-of-detail multidimensional ST data exploration. We demonstrate the general applicability and effectiveness of our technique on three datasets from different application domains: regional sales trend analysis, customer traffic analysis in department stores, and taxi trip analysis with origin-destination (OD) data. We further interview domain experts to verify the usability of the prototype.","keywords":"Spatio-temporal data,tensor decomposition,interactive exploration,automatic pattern discoveries","caption":"Fig. 1. The user interface of TPFlow. a Tree View starts with a root node (a1) representing the original data and visualizes the overall data partitioning process. Every other node on the tree represents a subset of data. The system supports a steerable and iterative workflow by allowing analysts to directly interact with every node (a2 , a4 , a5 , a6 ). b d Each individual chart visualizes the latent c patterns extracted by our tensor-based model. The analysts select multiple nodes highlighted in different colors on the Tree View (a3 ) to compare the patterns across different subsets of data. One interesting pattern here is that the pink states (d1), located mostly in the northeast region of Germany, perform significantly different from the other states (b1, c1, c2 ). Please refer to the details in Sec. 5.1.","img_size":{"width":1436,"height":1012},"subfigures":[{"x":7.844424984758325,"y":8.08961776657796,"width":1416.951435117227,"height":999.1824920127424,"type":"interface","id":"interface-0"}],"visualizations":[{"x":37.190660621791714,"y":554.2879874631993,"width":665.8973063438597,"height":221.9657687812866,"type":"bar_chart","id":"bar_chart-0"},{"x":717.9999999999999,"y":319.9999904632569,"width":717.9999999999999,"height":692.0000095367432,"type":"donut_chart","id":"donut_chart-1"},{"x":7.999999999999998,"y":41.99999046325684,"width":1406,"height":508,"type":"heatmap","id":"heatmap-2"},{"x":37.190660621791714,"y":786.4201273337051,"width":664.2029111623232,"height":211.79939769206752,"type":"line_chart","id":"line_chart-3"},{"x":718.3375235994802,"y":317.0726620480839,"width":717.6624764005196,"height":694.9273379519162,"type":"map","id":"map-5"},{"x":9.864497137386708,"y":41.50286393154636,"width":1404.6310010405778,"height":512.2771886147989,"type":"sankey_diagram","id":"sankey_diagram-4"}],"relations":[{"vislist":[{"vislist":["heatmap-2"],"relation":null,"id":"group-0"},{"vislist":["sankey_diagram-4"],"relation":null,"id":"group-1"}],"relation":"nested","id":"relation-0"},{"vislist":[{"vislist":["bar_chart-0"],"relation":null,"id":"group-2"}],"relation":"repeated","id":"relation-1"},{"vislist":[{"vislist":["donut_chart-1"],"relation":null,"id":"group-3"},{"vislist":["map-5"],"relation":null,"id":"group-4"}],"relation":"coordinated","id":"relation-2"}]},"3083_0":{"comp":[["graph","graph",["repeated"]],["error_bar","bar_chart",["accompanied"]],["bar_chart","error_bar",["accompanied"]]],"visType":["graph","error_bar","bar_chart"],"compType":["repeated","accompanied"],"compressed_tree":[{"composite_pattern":"accompanied","visualization_type":[["error_bar","bar_chart"]]},{"composite_pattern":"repeated","visualization_type":[["graph"]]}],"coOccurrence":[["error_bar","bar_chart",["coOccurrence"]],["error_bar","graph",["coOccurrence"]],["bar_chart","graph",["coOccurrence"]]],"year":2018,"conference":["VAST"],"authors":["Xu-Meng Wang","Wei Che","Jia-Kai Chou","Chris Bryan","Huihua Guan","Wenlong Chen","Rusheng Pan","Kwan-Liu Ma"],"title":"GraphProtector: A Visual Interface for Employing and Assessing Multiple Privacy Preserving Graph Algorithms","doi":"10.1109/TVCG.2018.2865021","abstract":"Analyzing social networks reveals the relationships between individuals and groups in the data. However, such analysis can also lead to privacy exposure (whether intentionally or inadvertently): leaking the real-world identity of ostensibly anonymous individuals. Most sanitization strategies modify the graph\'s structure based on hypothesized tactics that an adversary would employ. While combining multiple anonymization schemes provides a more comprehensive privacy protection, deciding the appropriate set of techniques-along with evaluating how applying the strategies will affect the utility of the anonymized results-remains a significant challenge. To address this problem, we introduce GraphProtector, a visual interface that guides a user through a privacy preservation pipeline. GraphProtector enables multiple privacy protection schemes which can be simultaneously combined together as a hybrid approach. To demonstrate the effectiveness of GraphPro tector, we report several case studies and feedback collected from interviews with expert users in various scenarios.","keywords":"Graph privacy,k-anonymity,structural features,privacy preservation","caption":"Fig. 1. The visual privacy preservation stage of GraphProtector. (a) The graph protector view integrates multiple privacy-preserving schemes. (b) The provenance view illustrates the effect caused by each process. (c) The utility view lists user-selected utility metrics. (d) The priority view depicts the processing priority for nodes/identities specified by users.","img_size":{"width":1969,"height":1106},"subfigures":[{"x":17.67241203405035,"y":8.749664738429816,"width":1936.116857563296,"height":1087.270045565964,"type":"interface","id":"interface-0"}],"visualizations":[{"x":46.80434782608705,"y":118.03162055335973,"width":907.0948616600791,"height":281.9644268774703,"type":"bar_chart","id":"bar_chart-0"},{"x":48.990118577075194,"y":120.21739130434788,"width":904.9090909090908,"height":279.77865612648225,"type":"error_bar","id":"error_bar-1"},{"x":1029.4569618210455,"y":115.2551486152644,"width":332.8683221849191,"height":298.57618925595744,"type":"graph","id":"graph-16"},{"x":1037.2208662535056,"y":457.94868259380786,"width":329.2919548981477,"height":290.24047265022205,"type":"graph","id":"graph-17"},{"x":1037.1979805919075,"y":780.8936935978328,"width":326.34986582680455,"height":301.9720722637939,"type":"graph","id":"graph-18"},{"x":337.51185770750993,"y":467.7549407114625,"width":552.9999999999998,"height":266.66403162055343,"type":"graph","id":"graph-2"},{"x":83.96245059288543,"y":834.9644268774701,"width":303.82213438735175,"height":242.62055335968364,"type":"graph","id":"graph-3"},{"x":429.3142292490119,"y":826.2213438735179,"width":163.93280632411057,"height":126.77470355731224,"type":"graph","id":"graph-4"},{"x":427.1284584980238,"y":955.1818181818182,"width":161.74703557312245,"height":128.96047430830026,"type":"graph","id":"graph-5"},{"x":597.359799983404,"y":785.5105920540713,"width":366.3601620477375,"height":296.7001312358437,"type":"graph","id":"graph-6"},{"x":1032.586956521739,"y":118.03162055335973,"width":327.8656126482215,"height":292.893280632411,"type":"heatmap","id":"heatmap-7"},{"x":1036.9584980237153,"y":459.01185770750993,"width":327.8656126482215,"height":288.5217391304348,"type":"heatmap","id":"heatmap-8"},{"x":1036.9584980237153,"y":782.505928853755,"width":323.49407114624523,"height":297.2648221343872,"type":"heatmap","id":"heatmap-9"},{"x":48.990118577075194,"y":463.3833992094862,"width":277.592885375494,"height":273.2213438735178,"type":"table","id":"table-10"},{"x":1640.2312252964425,"y":74.31620553359689,"width":295.0790513833992,"height":146.4466403162055,"type":"table","id":"table-11"},{"x":1367.0098814229248,"y":452.4545454545455,"width":229.505928853755,"height":233.87747035573125,"type":"table","id":"table-12"},{"x":1360.4525691699605,"y":115.84584980237159,"width":227.32015810276675,"height":227.32015810276675,"type":"table","id":"table-13"},{"x":1358.2667984189723,"y":784.6916996047429,"width":233.87747035573125,"height":238.24901185770747,"type":"table","id":"table-14"},{"x":1634.5675408566167,"y":363.9164338715483,"width":266.26197295377415,"height":706.3338449190398,"type":"table","id":"table-15"}],"relations":[{"vislist":[{"vislist":["error_bar-1","bar_chart-0"],"relation":null,"id":"group-6"}],"relation":"accompanied","id":"relation-3"},{"vislist":[{"vislist":["graph-4","graph-5"],"relation":null,"id":"group-7"}],"relation":"repeated","id":"relation-4"}]},"3083_2":{"comp":[["line_chart","line_chart",["repeated"]]],"visType":["line_chart"],"compType":["repeated"],"compressed_tree":[{"composite_pattern":"repeated","visualization_type":[["line_chart"]]}],"coOccurrence":[["line_chart","line_chart",["coOccurrence"]]],"year":2018,"conference":["VAST"],"authors":["Xu-Meng Wang","Wei Che","Jia-Kai Chou","Chris Bryan","Huihua Guan","Wenlong Chen","Rusheng Pan","Kwan-Liu Ma"],"title":"GraphProtector: A Visual Interface for Employing and Assessing Multiple Privacy Preserving Graph Algorithms","doi":"10.1109/TVCG.2018.2865021","abstract":"Analyzing social networks reveals the relationships between individuals and groups in the data. However, such analysis can also lead to privacy exposure (whether intentionally or inadvertently): leaking the real-world identity of ostensibly anonymous individuals. Most sanitization strategies modify the graph\'s structure based on hypothesized tactics that an adversary would employ. While combining multiple anonymization schemes provides a more comprehensive privacy protection, deciding the appropriate set of techniques-along with evaluating how applying the strategies will affect the utility of the anonymized results-remains a significant challenge. To address this problem, we introduce GraphProtector, a visual interface that guides a user through a privacy preservation pipeline. GraphProtector enables multiple privacy protection schemes which can be simultaneously combined together as a hybrid approach. To demonstrate the effectiveness of GraphPro tector, we report several case studies and feedback collected from interviews with expert users in various scenarios.","keywords":"Graph privacy,k-anonymity,structural features,privacy preservation","caption":"Fig. 3. The interface for visual specification of priority and utility is composed of three views: (a) the node-link view, rendering the overview of the graph, (b) the utility view and (c) the priority view for specifying node priority.","img_size":{"width":1893,"height":1071},"subfigures":[{"x":7.9750307780380485,"y":7.360370938922515,"width":1873.4941085100127,"height":1053.9074463951074,"type":"interface","id":"interface-0"}],"visualizations":[{"x":3.732758620689651,"y":4.103448275862069,"width":1009.448275862069,"height":1058.689655172414,"type":"graph","id":"graph-0"},{"x":1035.75,"y":410.3448275862069,"width":478.05172413793116,"height":225.6896551724139,"type":"line_chart","id":"line_chart-1"},{"x":1035.75,"y":615.5172413793105,"width":480.10344827586204,"height":225.68965517241378,"type":"line_chart","id":"line_chart-2"},{"x":1035.75,"y":824.7931034482759,"width":478.05172413793116,"height":219.53448275862084,"type":"line_chart","id":"line_chart-3"},{"x":1015.2327586206898,"y":4.103448275862069,"width":867.8793103448276,"height":340.5862068965518,"type":"table","id":"table-4"}],"relations":[{"vislist":[{"vislist":["line_chart-1","line_chart-2","line_chart-3"],"relation":null,"id":"group-0"}],"relation":"repeated","id":"relation-0"}]},"3084_0":{"comp":[["bar_chart","bar_chart",["repeated"]]],"visType":["bar_chart"],"compType":["repeated"],"compressed_tree":[{"composite_pattern":"repeated","visualization_type":[["bar_chart"]]}],"coOccurrence":[["bar_chart","bar_chart",["coOccurrence"]]],"year":2018,"conference":["VAST"],"authors":["Shahid Latif","Fabian G. Beck"],"title":"VIS Author Profiles: Interactive Descriptions of Publication Records Combining Text and Visualization","doi":"10.1109/TVCG.2018.2865022","abstract":"Publication records and collaboration networks are important for assessing the expertise and experience of researchers. Existing digital libraries show the raw publication lists in author profiles, whereas visualization techniques focus on specific subproblems. Instead, we look at publication records from various perspectives mixing low-level publication data with high-level abstractions and background information. This work presents VIS Author Profiles, a novel approach to generate integrated textual and visual descriptions to highlight patterns in publication records. We leverage template-based natural language generation to summarize notable publication statistics, evolution of research topics, and collaboration relationships. Seamlessly integrated visualizations augment the textual description and are interactively connected with each other and the text. The underlying publication data and detailed explanations of the analysis are available on demand. We compare our approach to existing systems by taking into account information needs of users and demonstrate its usefulness in two realistic application examples.","keywords":"Natural language generation,document visualization,interactive documents,sparklines,digital libraries","caption":"Fig. 1. Pro\ufb01le of author Ben Shneiderman. The text consists of three sections describing general information, research areas, and collaboration relationships. The visualization below provides information on joint work with co-authors on a timeline. The sidebar shows details on demand, whereas the top-right bar chart displays the temporal distribution of publications. Badges at the top summarize achievements. The cut-outs on the right are two different versions of the sidebar (list of collaboration groups and similar authors).","img_size":{"width":1930,"height":1024},"subfigures":[{"x":10.105311398954118,"y":12.586830236702943,"width":1906.169992578988,"height":998.8263395265932,"type":"interface","id":"interface-0"}],"visualizations":[{"x":235.2996938115681,"y":830.0780144360448,"width":516.7315060012269,"height":59.13548570041303,"type":"bar_chart","id":"bar_chart-0"},{"x":235.2996938115681,"y":889.2135001364579,"width":515.3235182464551,"height":49.27957141701063,"type":"bar_chart","id":"bar_chart-1"},{"x":236.70768156633977,"y":938.4930715534686,"width":519.5474815107704,"height":57.72749794564129,"type":"bar_chart","id":"bar_chart-2"},{"x":860.895664702745,"y":66.30815467093248,"width":323.27673505656077,"height":64.71580564662221,"type":"bar_chart","id":"bar_chart-3"},{"x":1482.776844539326,"y":703.3591165065889,"width":205.56621219667338,"height":297.0854162568362,"type":"bar_chart","id":"bar_chart-4"}],"relations":[{"vislist":[{"vislist":["bar_chart-0","bar_chart-1","bar_chart-2"],"relation":null,"id":"group-0"}],"relation":"repeated","id":"relation-0"}]},"3085_0":{"comp":[["bar_chart","bar_chart",["repeated"]]],"visType":["bar_chart"],"compType":["repeated"],"compressed_tree":[{"composite_pattern":"repeated","visualization_type":[["bar_chart"]]},{"composite_pattern":"repeated","visualization_type":[["bar_chart"]]}],"coOccurrence":[["bar_chart","bar_chart",["coOccurrence"]]],"year":2018,"conference":["VAST"],"authors":["Jay Koven","Cristian Felix","Hossein Siadati","Markus Jakobsson","Enrico Bertini"],"title":"Lessons Learned Developing a Visual Analytics Solution for Investigative Analysis of Scamming Activities","doi":"10.1109/TVCG.2018.2865023","abstract":"The forensic investigation of communication datasets which contain unstructured text, social network information, and metadata is a complex task that is becoming more important due to the immense amount of data being collected. Currently there are limited approaches that allow an investigator to explore the network, text and metadata in a unified manner. We developed Beagle as a forensic tool for email datasets that allows investigators to flexibly form complex queries in order to discover important information in email data. Beagle was successfully deployed at a security firm which had a large email dataset that was difficult to properly investigate. We discuss our experience developing Beagle as well as the lessons we learned applying visual analytic techniques to a difficult real-world problem.","keywords":"Visual Analytics,Email Investigation,Email Forensics","caption":"Fig. 1. Beagle has 5 main panels: (a) the Interactive Query Panel to specify queries composed of correspondents, keywords and time; (b) the Correspondents Panel to list correspondents and their communication frequency; (c) the Content Panels to display keywords or entities extracted from the emails; (d) the Email Panel to display emails in full detail; (e) the Timeline Panel to show the temporal distribution of the emails. All panels display information conditioned to the current query.","img_size":{"width":1860,"height":1069},"subfigures":[{"x":8.907359392239162,"y":14.41771055152054,"width":1842.1852812155207,"height":1046.0830353306976,"type":"interface","id":"interface-0"}],"visualizations":[{"x":6.910183875530436,"y":954.0862800565772,"width":1844.6676096181047,"height":114.91371994342285,"type":"bar_chart","id":"bar_chart-0"},{"x":475.6371994342292,"y":65.01697312588402,"width":387.07779349363517,"height":887.5572842998586,"type":"bar_chart","id":"bar_chart-1"},{"x":865.7390381895334,"y":68.04101838755305,"width":356.83734087694484,"height":887.5572842998586,"type":"bar_chart","id":"bar_chart-2"}],"relations":[{"vislist":[{"id":"group-0","relation":null,"vislist":["bar_chart-1"]}],"relation":"repeated","id":"relation-0"},{"vislist":[{"id":"group-1","relation":null,"vislist":["bar_chart-2"]}],"relation":"repeated","id":"relation-1"}]},"3088_0":{"comp":[["graph","graph",["large_view","repeated"]]],"visType":["graph"],"compType":["large_view","repeated"],"compressed_tree":[{"composite_pattern":"repeated","visualization_type":[["graph"]]},{"composite_pattern":"large_view","visualization_type":[["graph"],["graph"]]}],"coOccurrence":[["graph","graph",["coOccurrence"]]],"year":2018,"conference":["VAST"],"authors":["Cong Xie","Wei Xu","Klaus Mueller"],"title":"A Visual Analytics Framework for the Detection of Anomalous Call Stack Trees in High Performance Computing Applications","doi":"10.1109/TVCG.2018.2865026","abstract":"Anomalous runtime behavior detection is one of the most important tasks for performance diagnosis in High Performance Computing (HPC). Most of the existing methods find anomalous executions based on the properties of individual functions, such as execution time. However, it is insufficient to identify abnormal behavior without taking into account the context of the executions, such as the invocations of children functions and the communications with other HPC nodes. We improve upon the existing anomaly detection approaches by utilizing the call stack structures of the executions, which record rich temporal and contextual information. With our call stack tree (CSTree) representation of the executions, we formulate the anomaly detection problem as finding anomalous tree structures in a call stack forest. The CSTrees are converted to vector representations using our proposed stack2vec embedding. Structural and temporal visualizations of CSTrees are provided to support users in the identification and verification of the anomalies during an active anomaly detection process. Three case studies of real-world HPC applications demonstrate the capabilities of our approach.","keywords":"Call Stack,Performance Visualization,Representation Learning,Active Learning,Anomaly Detection","caption":"Fig. 1. The interface of our system for anomalous call stack tree (CSTree) detection. (a) The scatter plot shows the projection of our stack2vec embeddings of the CSTrees. Each point in the projection represents a CSTree. (b) Summary structures of the top candidate anomalies from (a). (c) The user can investigate the detailed structure and the anomalous subtrees of a CSTree of interest. (d) The level-of-detail timeline visualization of the selected CSTree shows the temporal pattern of the invocations and the communications between the HPC nodes. (e) The user is able to label the CSTrees of interest after exploration to update the anomaly detection model.","img_size":{"width":1964,"height":1057},"subfigures":[{"x":15.17471248821444,"y":8.056777303919818,"width":1932.42285975591,"height":1040.8864453921592,"type":"interface","id":"interface-0"}],"visualizations":[{"x":963.1996047430827,"y":6.266788458164501,"width":985.9762845849797,"height":557.7450592885375,"type":"graph","id":"graph-1"},{"x":8.557312252964408,"y":566.1007805530262,"width":812.594861660079,"height":482.5434782608694,"type":"graph","id":"graph-2"},{"x":590.0287461906337,"y":624.1658413412354,"width":225.14129365818738,"height":220.13799291696589,"type":"graph","id":"graph-3"},{"x":595.344854073993,"y":844.4965689271313,"width":220.46962417371375,"height":204.3637027663299,"type":"graph","id":"graph-4"},{"x":822.8889844015578,"y":860.5953255735049,"width":1113.9549598767007,"height":172.16618947358378,"type":"others","id":"others-6"},{"x":332.34189723320145,"y":6.266788458164501,"width":635.0355731225297,"height":557.7450592885375,"type":"scatterplot","id":"scatterplot-0"},{"x":825.9522380978777,"y":575.4094448047182,"width":1112.2988621957404,"height":220.74669572201446,"type":"sunburst_icicle","id":"sunburst_icicle-5"}],"relations":[{"vislist":[{"vislist":["graph-1"],"relation":null,"id":"group-2"}],"relation":"repeated","id":"relation-1"},{"vislist":[{"vislist":["graph-4","graph-3"],"relation":null,"id":"group-1"},{"vislist":["graph-2"],"relation":null,"id":"group-3"}],"relation":"large_view","id":"relation-2"}]},"3089_0":{"comp":[["bar_chart","bar_chart",["repeated"]]],"visType":["bar_chart"],"compType":["repeated"],"compressed_tree":[{"composite_pattern":"repeated","visualization_type":[["bar_chart"]]}],"coOccurrence":[["bar_chart","bar_chart",["coOccurrence"]]],"year":2018,"conference":["VAST"],"authors":["Bum Chul Kwon","Min-Je Choi","Joanne Taery Kim","Edward Choi","Young Bin Kim","Soonwook Kwon","Jimeng Sun","Jaegul Choo"],"title":"RetainVis: Visual Analytics with Interpretable and Interactive Recurrent Neural Networks on Electronic Medical Records","doi":"10.1109/TVCG.2018.2865027","abstract":"We have recently seen many successful applications of recurrent neural networks (RNNs) on electronic medical records (EMRs), which contain histories of patients\' diagnoses, medications, and other various events, in order to predict the current and future states of patients. Despite the strong performance of RNNs, it is often challenging for users to understand why the model makes a particular prediction. Such black-box nature of RNNs can impede its wide adoption in clinical practice. Furthermore, we have no established methods to interactively leverage users\' domain expertise and prior knowledge as inputs for steering the model. Therefore, our design study aims to provide a visual analytics solution to increase interpretability and interactivity of RNNs via a joint effort of medical experts, artificial intelligence scientists, and visual analytics researchers. Following the iterative design process between the experts, we design, implement, and evaluate a visual analytics tool called RetainVis, which couples a newly improved, interpretable, and interactive RNN-based model called RetainEX and visualizations for users\' exploration of EMR data in the context of prediction tasks. Our study shows the effective use of RetainVis for gaining insights into how individual medical codes contribute to making risk predictions, using EMRs of patients with heart failure and cataract symptoms. Our study also demonstrates how we made substantial changes to the state-of-the-art RNN model called RETAIN in order to make use of temporal information and increase interactivity. This study will provide a useful guideline for researchers that aim to design an interpretable and interactive visual analytics tool for RNNs.","keywords":"Interactive Artificial Intelligence,XAI (Explainable Artificial Intelligence),Interpretable Deep Learning,Healthcare","caption":"Fig. 1. A screenshot of RetainVis consisting of five areas: (A) Overview shows an overview of all patients (left) and an attribute summary view (right) of patients. (B) Patient Summary shows the summary of the patient cohort built from (A). (C) Patient List shows individual patients in a row of rectangles. In Patient List, users can select a patient of interest to view details in (E) Patient Details. Users can open (D) Patient Editor to conduct a what-if analysis, and (E) Patient Details shows the updated results.","img_size":{"width":1956,"height":856},"subfigures":[{"x":9.035992201946348,"y":10.200458887278959,"width":1937.9280155961042,"height":831.9297051097112,"type":"interface","id":"interface-0"}],"visualizations":[{"x":1442.847979474022,"y":226.6286080821039,"width":194.47081462475944,"height":91.58948043617698,"type":"area_chart","id":"area_chart-0"},{"x":1442.847979474022,"y":320.72738935214875,"width":179.41500962155212,"height":94.09878127004491,"type":"area_chart","id":"area_chart-1"},{"x":79.34219269102987,"y":58.29900332225915,"width":880.1727574750829,"height":152.14617940199335,"type":"area_chart","id":"area_chart-2"},{"x":76.53367543296984,"y":209.06350224502884,"width":871.9820397690827,"height":90.3348300192431,"type":"bar_chart","id":"bar_chart-3"},{"x":1002.4656831302118,"y":762.3643361128929,"width":820.5413726747918,"height":67.75112251443238,"type":"bar_chart","id":"bar_chart-4"},{"x":1450.3758819756254,"y":127.51122514432328,"width":225.8370750481076,"height":97.8627325208467,"type":"bar_chart","id":"bar_chart-5"},{"x":1449.1212315586918,"y":38.431045542014104,"width":452.92880051314944,"height":63.98717126363054,"type":"bar_chart","id":"bar_chart-6"},{"x":140.5208466966004,"y":609.2969852469532,"width":737.7344451571522,"height":145.53944836433618,"type":"bar_chart","id":"bar_chart-7"},{"x":997.4470814624761,"y":574.1667735728032,"width":856.9262347658756,"height":179.41500962155237,"type":"bar_chart","id":"bar_chart-8"},{"x":996.192431045542,"y":463.757536882617,"width":815.5227710070559,"height":97.86273252084675,"type":"line_chart","id":"line_chart-10"},{"x":84.06157793457344,"y":59.76010262989096,"width":871.9820397690827,"height":153.06735086593966,"type":"line_chart","id":"line_chart-9"},{"x":1012.5028864656832,"y":34.66709429121231,"width":373.8858242463117,"height":362.59397049390634,"type":"scatterplot","id":"scatterplot-11"},{"x":57.713919178960886,"y":323.23669018601663,"width":903.3483001924311,"height":239.63822963438102,"type":"scatterplot","id":"scatterplot-12"}],"relations":[{"vislist":[{"vislist":["bar_chart-6"],"relation":null,"id":"group-0"}],"relation":"repeated","id":"relation-0"}]},"3091_0":{"comp":[["area_chart","area_chart",["repeated"]],["bar_chart","bar_chart",["repeated"]]],"visType":["area_chart","bar_chart"],"compType":["repeated"],"compressed_tree":[{"composite_pattern":"repeated","visualization_type":[["area_chart"]]},{"composite_pattern":"repeated","visualization_type":[["bar_chart"]]}],"coOccurrence":[["area_chart","bar_chart",["coOccurrence"]]],"year":2018,"conference":["VAST"],"authors":["John R. Goodall","Eric D. Ragan","Chad A. Steed","Joel W. Reed","G. David Richardson","Kelly M. T. Huffer","Robert A. Bridges","Jason A. Laska"],"title":"Situ: Identifying and Explaining Suspicious Behavior in Networks","doi":"10.1109/TVCG.2018.2865029","abstract":"Despite the best efforts of cyber security analysts, networked computing assets are routinely compromised, resulting in the loss of intellectual property, the disclosure of state secrets, and major financial damages. Anomaly detection methods are beneficial for detecting new types of attacks and abnormal network activity, but such algorithms can be difficult to understand and trust. Network operators and cyber analysts need fast and scalable tools to help identify suspicious behavior that bypasses automated security systems, but operators do not want another automated tool with algorithms they do not trust. Experts need tools to augment their own domain expertise and to provide a contextual understanding of suspicious behavior to help them make decisions. In this paper we present Situ, a visual analytics system for discovering suspicious behavior in streaming network data. Situ provides a scalable solution that combines anomaly detection with information visualization. The system\'s visualizations enable operators to identify and investigate the most anomalous events and IP addresses, and the tool provides context to help operators understand why they are anomalous. Finally, operators need tools that can be integrated into their workflow and with their existing tools. This paper describes the Situ platform and its deployment in an operational network setting. We discuss how operators are currently using the tool in a large organization\'s security operations center and present the results of expert reviews with professionals.","keywords":"Network security,situational awareness,privacy and security,streaming data,machine learning,visualization","caption":"Fig. 1. The IP Detail Page of the Situ system includes a temporal histogram for selecting a time range, horizon graphs for temporal context, bar charts of field distributions for network flows of that IP, and a two-hop communication graph.","img_size":{"width":1461,"height":1026},"subfigures":[{"x":48.60622604215955,"y":13.639687654208746,"width":1368.330850296382,"height":960.0939765653726,"type":"interface","id":"interface-0"}],"visualizations":[{"x":102.81448513245235,"y":411.3495901707989,"width":1301.5339810381074,"height":46.568117367322664,"type":"area_chart","id":"area_chart-0"},{"x":105.5664552852648,"y":371.5386088108237,"width":1296.3690024246007,"height":37.492318201378914,"type":"area_chart","id":"area_chart-1"},{"x":102.68243080823567,"y":334.04629060944484,"width":1297.8110146631152,"height":37.49231820137886,"type":"area_chart","id":"area_chart-2"},{"x":107.00846752377939,"y":292.2279356925221,"width":1297.8110146631154,"height":37.492318201378914,"type":"area_chart","id":"area_chart-3"},{"x":87.84755593023587,"y":886.142752744042,"width":252.9090522635638,"height":85.09089608867578,"type":"bar_chart","id":"bar_chart-10"},{"x":76.72621051497336,"y":172.54091989581264,"width":1325.2092471948918,"height":103.82488117304922,"type":"bar_chart","id":"bar_chart-11"},{"x":81.94364439712022,"y":476.0034316943938,"width":557.8979154413536,"height":81.36011266853075,"type":"bar_chart","id":"bar_chart-4"},{"x":85.81793547657409,"y":560.2692626725149,"width":550.1493332824459,"height":77.48582158907686,"type":"bar_chart","id":"bar_chart-5"},{"x":85.67169175382516,"y":644.6525001222348,"width":551.9090065751602,"height":77.99998808128603,"type":"bar_chart","id":"bar_chart-6"},{"x":92.76259976121479,"y":725.0161242059842,"width":548.3635525714656,"height":77.99998808128615,"type":"bar_chart","id":"bar_chart-7"},{"x":86.85350975505675,"y":801.8342942860385,"width":551.9090065751602,"height":83.90907808744407,"type":"bar_chart","id":"bar_chart-8"},{"x":383.3020562381375,"y":886.142752744042,"width":258.81814226972193,"height":82.7272600862125,"type":"bar_chart","id":"bar_chart-9"},{"x":789.6308411214953,"y":489.0280373831776,"width":482.63551401869165,"height":489.0280373831776,"type":"graph","id":"graph-12"}],"relations":[{"vislist":[{"vislist":["area_chart-2","area_chart-3","area_chart-1","area_chart-0"],"relation":null,"id":"group-0"}],"relation":"repeated","id":"relation-0"},{"vislist":[{"vislist":["bar_chart-4","bar_chart-5","bar_chart-6","bar_chart-7","bar_chart-8","bar_chart-9","bar_chart-10"],"relation":null,"id":"group-1"}],"relation":"repeated","id":"relation-1"}]},"3091_3":{"comp":[["bar_chart","bar_chart",["repeated"]],["heatmap","map",["coordinated"]]],"visType":["bar_chart","heatmap","map"],"compType":["repeated","coordinated"],"compressed_tree":[{"composite_pattern":"coordinated","visualization_type":[["heatmap"],["map"]]},{"composite_pattern":"repeated","visualization_type":[["bar_chart"]]}],"coOccurrence":[["heatmap","map",["coOccurrence"]],["heatmap","bar_chart",["coOccurrence"]],["map","bar_chart",["coOccurrence"]]],"year":2018,"conference":["VAST"],"authors":["John R. Goodall","Eric D. Ragan","Chad A. Steed","Joel W. Reed","G. David Richardson","Kelly M. T. Huffer","Robert A. Bridges","Jason A. Laska"],"title":"Situ: Identifying and Explaining Suspicious Behavior in Networks","doi":"10.1109/TVCG.2018.2865029","abstract":"Despite the best efforts of cyber security analysts, networked computing assets are routinely compromised, resulting in the loss of intellectual property, the disclosure of state secrets, and major financial damages. Anomaly detection methods are beneficial for detecting new types of attacks and abnormal network activity, but such algorithms can be difficult to understand and trust. Network operators and cyber analysts need fast and scalable tools to help identify suspicious behavior that bypasses automated security systems, but operators do not want another automated tool with algorithms they do not trust. Experts need tools to augment their own domain expertise and to provide a contextual understanding of suspicious behavior to help them make decisions. In this paper we present Situ, a visual analytics system for discovering suspicious behavior in streaming network data. Situ provides a scalable solution that combines anomaly detection with information visualization. The system\'s visualizations enable operators to identify and investigate the most anomalous events and IP addresses, and the tool provides context to help operators understand why they are anomalous. Finally, operators need tools that can be integrated into their workflow and with their existing tools. This paper describes the Situ platform and its deployment in an operational network setting. We discuss how operators are currently using the tool in a large organization\'s security operations center and present the results of expert reviews with professionals.","keywords":"Network security,situational awareness,privacy and security,streaming data,machine learning,visualization","caption":"Fig. 3. Event Search Page showing the details of an event, relevant temporal context, and the raw data.","img_size":{"width":1048,"height":706},"subfigures":[{"x":29.404044580797454,"y":10.131653890705739,"width":990.7543270727157,"height":652.9033769382769,"type":"interface","id":"interface-0"}],"visualizations":[{"x":49.94426456383329,"y":69.60393009730996,"width":966.1565966117192,"height":67.80046292012065,"type":"bar_chart","id":"bar_chart-0"},{"x":45.10137435525325,"y":144.66872833030064,"width":230.0372849075522,"height":53.2717922943805,"type":"bar_chart","id":"bar_chart-1"},{"x":296.9316652014156,"y":144.66872833030064,"width":221.56222704253696,"height":55.693237398670526,"type":"bar_chart","id":"bar_chart-2"},{"x":546.340510943288,"y":144.66872833030064,"width":221.5622270425371,"height":53.2717922943805,"type":"bar_chart","id":"bar_chart-3"},{"x":793.3279115808702,"y":143.45800577815564,"width":220.35150449039205,"height":56.903959950815526,"type":"bar_chart","id":"bar_chart-4"},{"x":794.5386341330152,"y":207.6263010418413,"width":222.77294959468213,"height":55.693237398670526,"type":"bar_chart","id":"bar_chart-5"},{"x":548.761956047578,"y":205.2048559375512,"width":220.35150449039213,"height":58.11468250296056,"type":"bar_chart","id":"bar_chart-6"},{"x":299.3531103057056,"y":206.41557848969623,"width":220.35150449039205,"height":56.903959950815526,"type":"bar_chart","id":"bar_chart-7"},{"x":35.41559393809315,"y":203.9941333854062,"width":237.30162022042225,"height":61.74685015939557,"type":"bar_chart","id":"bar_chart-8"},{"x":692.2523364485984,"y":281.52024292871596,"width":182.54828660436146,"height":74.77881619937693,"type":"heatmap","id":"heatmap-10"},{"x":192.9937694704051,"y":277.1214890346349,"width":180.3489096573209,"height":74.77881619937699,"type":"heatmap","id":"heatmap-9"},{"x":190.40103722676773,"y":275.95272179323564,"width":184.56070088964873,"height":77.39642295372363,"type":"map","id":"map-11"},{"x":690.5010009277513,"y":280.91403095693585,"width":182.57617722416865,"height":77.39642295372369,"type":"map","id":"map-12"},{"x":33.460040286514165,"y":437.2553278006406,"width":669.5295713361911,"height":194.92633089534667,"type":"table","id":"table-13"},{"x":720.2492129794472,"y":432.25223301152573,"width":298.41066952398205,"height":48.750257892531685,"type":"table","id":"table-14"}],"relations":[{"vislist":[{"vislist":["heatmap-9"],"relation":null,"id":"group-0"},{"vislist":["map-11"],"relation":null,"id":"group-1"}],"relation":"coordinated","id":"relation-0"},{"vislist":[{"vislist":["bar_chart-2","bar_chart-3","bar_chart-4","bar_chart-5","bar_chart-6","bar_chart-7","bar_chart-8","bar_chart-1","bar_chart-0"],"relation":null,"id":"group-4"}],"relation":"repeated","id":"relation-2"}]},"3091_4":{"comp":[["area_chart","area_chart",["repeated"]]],"visType":["area_chart"],"compType":["repeated"],"compressed_tree":[{"composite_pattern":"repeated","visualization_type":[["area_chart"]]}],"coOccurrence":[["area_chart","area_chart",["coOccurrence"]]],"year":2018,"conference":["VAST"],"authors":["John R. Goodall","Eric D. Ragan","Chad A. Steed","Joel W. Reed","G. David Richardson","Kelly M. T. Huffer","Robert A. Bridges","Jason A. Laska"],"title":"Situ: Identifying and Explaining Suspicious Behavior in Networks","doi":"10.1109/TVCG.2018.2865029","abstract":"Despite the best efforts of cyber security analysts, networked computing assets are routinely compromised, resulting in the loss of intellectual property, the disclosure of state secrets, and major financial damages. Anomaly detection methods are beneficial for detecting new types of attacks and abnormal network activity, but such algorithms can be difficult to understand and trust. Network operators and cyber analysts need fast and scalable tools to help identify suspicious behavior that bypasses automated security systems, but operators do not want another automated tool with algorithms they do not trust. Experts need tools to augment their own domain expertise and to provide a contextual understanding of suspicious behavior to help them make decisions. In this paper we present Situ, a visual analytics system for discovering suspicious behavior in streaming network data. Situ provides a scalable solution that combines anomaly detection with information visualization. The system\'s visualizations enable operators to identify and investigate the most anomalous events and IP addresses, and the tool provides context to help operators understand why they are anomalous. Finally, operators need tools that can be integrated into their workflow and with their existing tools. This paper describes the Situ platform and its deployment in an operational network setting. We discuss how operators are currently using the tool in a large organization\'s security operations center and present the results of expert reviews with professionals.","keywords":"Network security,situational awareness,privacy and security,streaming data,machine learning,visualization","caption":"Fig. 4. Event Detail Page showing the details of an event, relevant temporal context, and the raw data","img_size":{"width":1059,"height":707},"subfigures":[{"x":26.32224778703889,"y":3.1454834202047723,"width":985.2356565246426,"height":662.3492415348813,"type":"interface","id":"interface-0"}],"visualizations":[{"x":28.433021806853564,"y":264.29906542056074,"width":982.3115264797506,"height":134.35202492211835,"type":"area_chart","id":"area_chart-0"},{"x":35.04049844236756,"y":405.258566978193,"width":475.7383177570094,"height":107.92211838006233,"type":"matrix","id":"matrix-1"},{"x":521.7912772585669,"y":405.258566978193,"width":477.94080996884736,"height":107.92211838006233,"type":"matrix","id":"matrix-2"},{"x":548.2211838006228,"y":533.0031152647975,"width":460.32087227414326,"height":116.73208722741424,"type":"matrix","id":"matrix-3"},{"x":54.86292834890952,"y":533.0031152647975,"width":453.7133956386294,"height":114.52959501557619,"type":"matrix","id":"matrix-4"},{"x":26.230529595015526,"y":35.23986908802733,"width":984.5140186915888,"height":191.61682242990653,"type":"table","id":"table-5"}],"relations":[{"vislist":[{"vislist":["area_chart-0"],"relation":null,"id":"group-0"}],"relation":"repeated","id":"relation-0"}]},"3092_0":{"comp":[["bar_chart","bar_chart",["repeated"]],["area_chart","area_chart",["repeated"]],["heatmap","others",["coordinated"]]],"visType":["bar_chart","area_chart","heatmap","others"],"compType":["repeated","coordinated"],"compressed_tree":[{"composite_pattern":"repeated","visualization_type":[["bar_chart"]]},{"composite_pattern":"repeated","visualization_type":[["area_chart"]]},{"composite_pattern":"coordinated","visualization_type":[["heatmap"],["others"]]}],"coOccurrence":[["bar_chart","area_chart",["coOccurrence"]],["bar_chart","heatmap",["coOccurrence"]],["bar_chart","others",["coOccurrence"]],["area_chart","heatmap",["coOccurrence"]],["area_chart","others",["coOccurrence"]],["heatmap","others",["coOccurrence"]]],"year":2018,"conference":["VAST"],"authors":["Akhilesh Camisetty","Chaitanya Chandurkar","Maoyuan Sun","David Koop"],"title":"Enhancing Web-based Analytics Applications through Provenance","doi":"10.1109/TVCG.2018.2865039","abstract":"Visual analytics systems continue to integrate new technologies and leverage modern environments for exploration and collaboration, making tools and techniques available to a wide audience through web browsers. Many of these systems have been developed with rich interactions, offering users the opportunity to examine details and explore hypotheses that have not been directly encoded by a designer. Understanding is enhanced when users can replay and revisit the steps in the sensemaking process, and in collaborative settings, it is especially important to be able to review not only the current state but also what decisions were made along the way. Unfortunately, many web-based systems lack the ability to capture such reasoning, and the path to a result is transient, forgotten when a user moves to a new view. This paper explores the requirements to augment existing client-side web applications with support for capturing, reviewing, sharing, and reusing steps in the reasoning process. Furthermore, it considers situations where decisions are made with streaming data, and the insights gained from revisiting those choices when more data is available. It presents a proof of concept, the Shareable Interactive Manipulation Provenance framework (SIMProv.js), that addresses these requirements in a modern, client-side JavaScript library, and describes how it can be integrated with existing frameworks.","keywords":"Collaboration,provenance,streaming data,history,web","caption":"Fig. 1: Shown are three states from an analyst using a dc.js web application examining data captured from two motorcyclists racing around a track. One of the riders is a professional racer (a) and one is a journalist (b). In the course of investigation, the analyst decides to examine how much speed the racer was carrying as he held a steep banking angle (c). While such web apps enable useful analyses, the visited states and paths of reasoning are generally lost when the analyst ends the session.","img_size":{"width":2121,"height":460},"subfigures":[{"x":7.553693599283927,"y":8.753059124951184,"width":684.5733986104171,"height":396.05962265522624,"type":"single","id":"single-0"}],"visualizations":[{"x":439.3193052468859,"y":110.86478737877847,"width":241.95900391597985,"height":91.96631823050814,"type":"area_chart","id":"area_chart-0"},{"x":438.22446812509406,"y":209.4001283400372,"width":243.05384103777166,"height":91.96631823050815,"type":"area_chart","id":"area_chart-1"},{"x":439.3193052468859,"y":306.8406321795042,"width":244.14867815956347,"height":93.06115535229992,"type":"area_chart","id":"area_chart-2"},{"x":1155.0446902105239,"y":108.7955653271621,"width":242.95321556592015,"height":94.33821668251157,"type":"area_chart","id":"area_chart-3"},{"x":1155.0446902105239,"y":207.01069502402348,"width":242.95321556592015,"height":93.04591234439496,"type":"area_chart","id":"area_chart-4"},{"x":1155.0446902105239,"y":306.51812905900135,"width":246.83012858026996,"height":94.33821668251157,"type":"area_chart","id":"area_chart-5"},{"x":1861.8496811697958,"y":110.8722680088519,"width":240.23373331320298,"height":91.82679381469924,"type":"area_chart","id":"area_chart-6"},{"x":1861.8496811697958,"y":210.1194087984763,"width":241.16127668506877,"height":89.97170707096791,"type":"area_chart","id":"area_chart-7"},{"x":1859.1683746158335,"y":302.59013491992835,"width":248.63810923020222,"height":99.15016625744269,"type":"area_chart","id":"area_chart-8"},{"x":601.3551992720671,"y":11.234609295727996,"width":73.35408716004804,"height":93.06115535229993,"type":"bar_chart","id":"bar_chart-10"},{"x":1145.4892488025737,"y":11.234609295727996,"width":169.6997538777232,"height":95.25082959588345,"type":"bar_chart","id":"bar_chart-11"},{"x":1315.189002680297,"y":11.234609295727996,"width":75.54376140363183,"height":95.25082959588345,"type":"bar_chart","id":"bar_chart-12"},{"x":1852.5742474511392,"y":12.552670591093133,"width":169.74043705141372,"height":91.8267938146992,"type":"bar_chart","id":"bar_chart-13"},{"x":2021.3871411306868,"y":12.552670591093133,"width":75.13101312111759,"height":91.8267938146992,"type":"bar_chart","id":"bar_chart-14"},{"x":430.5606082725519,"y":10.337852195487214,"width":169.0090012350883,"height":92.86307533074891,"type":"bar_chart","id":"bar_chart-9"},{"x":7.4919665776679745,"y":56.073065378312975,"width":364.8005888476985,"height":346.24547763498265,"type":"heatmap","id":"heatmap-15"},{"x":730.8381412947083,"y":60.50037889812673,"width":348.7372227216605,"height":322.91532611983035,"type":"heatmap","id":"heatmap-16"},{"x":1435.4189448232987,"y":58.71061248338815,"width":371.81385542168846,"height":312.01933447378286,"type":"heatmap","id":"heatmap-17"},{"x":7.501758451642872,"y":54.49082505207428,"width":367.9995179980804,"height":347.80156667906766,"type":"others","id":"others-18"},{"x":727.6535647240607,"y":63.70778143452394,"width":353.49711941379206,"height":322.9340874806025,"type":"others","id":"others-19"},{"x":1430.6437668197293,"y":58.73690050302149,"width":381.3642114288256,"height":313.5751500429083,"type":"others","id":"others-20"}],"relations":[{"vislist":[{"vislist":["bar_chart-9","bar_chart-10"],"relation":null,"id":"group-5"}],"relation":"repeated","id":"relation-0"},{"vislist":[{"vislist":["area_chart-0","area_chart-1","area_chart-2"],"relation":null,"id":"group-6"}],"relation":"repeated","id":"relation-1"},{"vislist":[{"vislist":["heatmap-15"],"relation":null,"id":"group-10"},{"vislist":["others-18"],"relation":null,"id":"group-11"}],"relation":"coordinated","id":"relation-5"}]},"3096_3":{"comp":[["bar_chart","bar_chart",["repeated"]]],"visType":["bar_chart"],"compType":["repeated"],"compressed_tree":[{"composite_pattern":"repeated","visualization_type":[["bar_chart"]]}],"coOccurrence":[["bar_chart","bar_chart",["coOccurrence"]]],"year":2018,"conference":["VAST"],"authors":["Dennis Dingen","Marcel van \'t Veer","Patrick Houthuizen","Eveline H. J. Mestrom","Hendrikus H. M. Korsten","Arthur R. A. Bouwman","Jarke J. van Wijk"],"title":"RegressionExplorer: Interactive Exploration of Logistic Regression Models with Subgroup Analysis","doi":"10.1109/TVCG.2018.2865043","abstract":"We present RegressionExplorer, a Visual Analytics tool for the interactive exploration of logistic regression models. Our application domain is Clinical Biostatistics, where models are derived from patient data with the aim to obtain clinically meaningful insights and consequences. Development and interpretation of a proper model requires domain expertise and insight into model characteristics. Because of time constraints, often a limited number of candidate models is evaluated. RegressionExplorer enables experts to quickly generate, evaluate, and compare many different models, taking the workflow for model development as starting point. Global patterns in parameter values of candidate models can be explored effectively. In addition, experts are enabled to compare candidate models across multiple subpopulations. The insights obtained can be used to formulate new hypotheses or to steer model development. The effectiveness of the tool is demonstrated for two uses cases: prediction of a cardiac conduction disorder in patients after receiving a heart valve implant and prediction of hypernatremia in critically ill patients.","keywords":"Visual analytics,Predictive visual analytics,Exploratory data analysis,Multivariate statistics,Regression analysis,Variable selection,Subgroup analysis","caption":"Fig. 3: Overview of the RegressionExplorer system: (A) Univariate analysis panel; (B) Responder drop panel; (C) Fixed covariates drop panel; (D) Optional covariates drop panel; (E) Matrix containing all generated multivariate models; (F) Population control panel; (G) Legend.","img_size":{"width":2151,"height":1164},"subfigures":[{"x":71.43839420162267,"y":34.71824819387301,"width":2004.089379304371,"height":1122.7913789833813,"type":"interface","id":"interface-0"}],"visualizations":[{"x":1980.2289719626172,"y":130.54205607476638,"width":94.28037383177616,"height":123.28971962616824,"type":"bar_chart","id":"bar_chart-0"},{"x":1588.602803738318,"y":123.28971962616824,"width":391.6261682242989,"height":141.42056074766356,"type":"bar_chart","id":"bar_chart-1"},{"x":1146.2102803738323,"y":123.28971962616824,"width":442.3925233644859,"height":137.79439252336454,"type":"bar_chart","id":"bar_chart-2"},{"x":802.849992896177,"y":123.28971962616806,"width":170.32705886607872,"height":126.91588785046723,"type":"bar_chart","id":"bar_chart-3"},{"x":399.2196261682246,"y":116.0373831775701,"width":126.91588785046736,"height":130.54205607476638,"type":"bar_chart","id":"bar_chart-4"},{"x":653.0514018691592,"y":126.9158878504673,"width":134.1682242990655,"height":123.28971962616826,"type":"bar_chart","id":"bar_chart-5"},{"x":566.0233644859817,"y":112.41121495327104,"width":65.27102803738308,"height":148.67289719626174,"type":"bar_chart","id":"bar_chart-6"},{"x":384.7149532710284,"y":268.01643547422196,"width":1334.4299065420564,"height":877.811645442743,"type":"heatmap_matrix","id":"heatmap_matrix-9"},{"x":985.7087590655369,"y":123.43773690778978,"width":153.47019051839615,"height":130.240935721588,"type":"bar_chart","id":"bar_chart-10"}],"relations":[{"vislist":[{"id":"group-0","relation":null,"vislist":["bar_chart-0","bar_chart-1","bar_chart-2","bar_chart-3","bar_chart-4","bar_chart-5","bar_chart-6","bar_chart-10"]}],"relation":"repeated","id":"relation-0"}]},"3096_4":{"comp":[["heatmap","heatmap",["repeated"]]],"visType":["heatmap"],"compType":["repeated"],"compressed_tree":[{"composite_pattern":"repeated","visualization_type":[["heatmap"]]}],"coOccurrence":[["heatmap","heatmap",["coOccurrence"]]],"year":2018,"conference":["VAST"],"authors":["Dennis Dingen","Marcel van \'t Veer","Patrick Houthuizen","Eveline H. J. Mestrom","Hendrikus H. M. Korsten","Arthur R. A. Bouwman","Jarke J. van Wijk"],"title":"RegressionExplorer: Interactive Exploration of Logistic Regression Models with Subgroup Analysis","doi":"10.1109/TVCG.2018.2865043","abstract":"We present RegressionExplorer, a Visual Analytics tool for the interactive exploration of logistic regression models. Our application domain is Clinical Biostatistics, where models are derived from patient data with the aim to obtain clinically meaningful insights and consequences. Development and interpretation of a proper model requires domain expertise and insight into model characteristics. Because of time constraints, often a limited number of candidate models is evaluated. RegressionExplorer enables experts to quickly generate, evaluate, and compare many different models, taking the workflow for model development as starting point. Global patterns in parameter values of candidate models can be explored effectively. In addition, experts are enabled to compare candidate models across multiple subpopulations. The insights obtained can be used to formulate new hypotheses or to steer model development. The effectiveness of the tool is demonstrated for two uses cases: prediction of a cardiac conduction disorder in patients after receiving a heart valve implant and prediction of hypernatremia in critically ill patients.","keywords":"Visual analytics,Predictive visual analytics,Exploratory data analysis,Multivariate statistics,Regression analysis,Variable selection,Subgroup analysis","caption":"Fig. 4: Predicting math test failure: (A) The subpopulations are generated by splitting on gender and active romantic involvement; (B) Univariate analysis for subpopulations; (C, D) The first and second part of the multivariate analysis. (1, 2, 3) Indication of a mediation, moderation and confounding effect, respectively.","img_size":{"width":2148,"height":1288},"subfigures":[{"x":82.40859297757125,"y":76.63853037741266,"width":1966.075546786449,"height":1131.870564357744,"type":"interface","id":"interface-0"}],"visualizations":[{"x":506.23676012461067,"y":758.3551401869158,"width":1544.797507788162,"height":445.3831775700933,"type":"heatmap","id":"heatmap-0"},{"x":507.6106404385842,"y":182.04778265090766,"width":1553.4838079124531,"height":470.7591812792857,"type":"heatmap","id":"heatmap-1"},{"x":281.53894080996895,"y":264.822429906542,"width":82.89719980966629,"height":940.6178734101442,"type":"heatmap","id":"heatmap-2"},{"x":510.24922118380067,"y":184.57320872274144,"width":1548.3198010954025,"height":460.65747699195066,"type":"matrix","id":"matrix-3"},{"x":281.53894080996895,"y":264.822429906542,"width":84.11310792622004,"height":939.4019652935903,"type":"matrix","id":"matrix-4"},{"x":505.06084924649537,"y":757.7208056817885,"width":1545.9734186662772,"height":446.01751207522057,"type":"matrix","id":"matrix-5"}],"relations":[{"vislist":[{"vislist":["heatmap-2"],"relation":null,"id":"group-0"}],"relation":"repeated","id":"relation-0"}]},"3097_6":{"comp":[["graph","graph",["repeated"]],["sankey_diagram","bar_chart",["stacked"]],["bar_chart","sankey_diagram",["stacked"]]],"visType":["graph","sankey_diagram","bar_chart"],"compType":["repeated","stacked"],"compressed_tree":[{"composite_pattern":"repeated","visualization_type":[["graph"]]},{"composite_pattern":"stacked","visualization_type":[["sankey_diagram","bar_chart"]]},{"composite_pattern":"stacked","visualization_type":[["sankey_diagram","bar_chart"]]}],"coOccurrence":[["graph","sankey_diagram",["coOccurrence"]],["graph","bar_chart",["coOccurrence"]],["sankey_diagram","bar_chart",["coOccurrence"]]],"year":2018,"conference":["VAST"],"authors":["Hendrik Strobelt","Sebastian Gehrmann","Michael Behrisch","Adam Perer","Hanspeter Pfister","Alexander M. Rush"],"title":"Seq2Seq-Vis: A Visual Debugging Tool for Sequence-to-Sequence Models","doi":"10.1109/TVCG.2018.2865044","abstract":"Neural sequence-to-sequence models have proven to be accurate and robust for many sequence prediction tasks, and have become the standard approach for automatic translation of text. The models work with a five-stage blackbox pipeline that begins with encoding a source sequence to a vector space and then decoding out to a new target sequence. This process is now standard, but like many deep learning methods remains quite difficult to understand or debug. In this work, we present a visual analysis tool that allows interaction and \u201cwhat if\u201d-style exploration of trained sequence-to-sequence models through each stage of the translation process. The aim is to identify which patterns have been learned, to detect model errors, and to probe the model with counterfactual scenario. We demonstrate the utility of our tool through several real-world sequence-to-sequence use cases on large-scale models.","keywords":"Explainable AI,Visual Debugging,Visual Analytics,Machine Learning,Deep Learning,NLP","caption":"Fig. 7. Overview of Seq2Seq-Vis: The two main views (a) Translation View and (b) Neighborhood View facilitate different modes of analysis. Translation View provides (c) visualizations for attention, (d) the top k word predictions for each time step, and1/3(e) the beam search tree. The Neighborhood View goes deeper into what the model has learned by providing (f,g) a projection of state trajectories and (h) a list of nearest neighbors for a specific model state.","img_size":{"width":2109,"height":1434},"subfigures":[{"x":409.0992974763305,"y":5.108975381508086,"width":1260.6445113356442,"height":1414.2549399468232,"type":"interface","id":"interface-0"}],"visualizations":[{"x":557.3732723183324,"y":87.9732973763308,"width":364.7953650637537,"height":169.29729649367573,"type":"bar_chart","id":"bar_chart-0"},{"x":1045.1107217405886,"y":83.94240936457663,"width":419.2123532224352,"height":171.3127404995528,"type":"bar_chart","id":"bar_chart-1"},{"x":443.95040788103887,"y":509.1602009104204,"width":1047.6076990716049,"height":304.9374523119224,"type":"graph","id":"graph-2"},{"x":1498.9356259601907,"y":669.006446073928,"width":120.49947712325957,"height":122.95865012577521,"type":"graph","id":"graph-3"},{"x":459.19787838296764,"y":884.4984162927414,"width":577.9056555911435,"height":543.4772335559267,"type":"graph","id":"graph-4"},{"x":552.886957266532,"y":10.280638112793309,"width":373.99854965585024,"height":72.5621512178303,"type":"sankey_diagram","id":"sankey_diagram-7"},{"x":1046.0446324804043,"y":7.0966520076621595,"width":423.5870558941902,"height":72.52211113391579,"type":"sankey_diagram","id":"sankey_diagram-8"},{"x":436.4466319657069,"y":293.5485859757942,"width":1054.0772150737193,"height":165.26640848192153,"type":"tree","id":"tree-5"}],"relations":[{"vislist":[{"vislist":["graph-2"],"relation":null,"id":"group-0"}],"relation":"repeated","id":"relation-0"},{"vislist":[{"vislist":["sankey_diagram-7","bar_chart-0"],"relation":null,"id":"group-1"}],"relation":"stacked","id":"relation-1"},{"vislist":[{"vislist":["sankey_diagram-8","bar_chart-1"],"relation":null,"id":"group-2"}],"relation":"stacked","id":"relation-2"}]},"3098_0":{"comp":[["scatterplot","scatterplot",["repeated"]]],"visType":["scatterplot"],"compType":["repeated"],"compressed_tree":[{"composite_pattern":"repeated","visualization_type":[["scatterplot"]]}],"coOccurrence":[["scatterplot","scatterplot",["coOccurrence"]]],"year":2018,"conference":["VAST"],"authors":["Michelle Dowling","John E. Wenskovitch","J. T. Fry","Scotland Leman","Leanna House","Chris North"],"title":"SIRIUS: Dual, Symmetric, Interactive Dimension Reductions","doi":"10.1109/TVCG.2018.2865047","abstract":"Much research has been done regarding how to visualize and interact with observations and attributes of high-dimensional data for exploratory data analysis. From the analyst\'s perceptual and cognitive perspective, current visualization approaches typically treat the observations of the high-dimensional dataset very differently from the attributes. Often, the attributes are treated as inputs (e.g., sliders), and observations as outputs (e.g., projection plots), thus emphasizing investigation of the observations. However, there are many cases in which analysts wish to investigate both the observations and the attributes of the dataset, suggesting a symmetry between how analysts think about attributes and observations. To address this, we define SIRIUS (Symmetric Interactive Representations In a Unified System), a symmetric, dual projection technique to support exploratory data analysis of high-dimensional data. We provide an example implementation of SIRIUS and demonstrate how this symmetry affords additional insights.","keywords":"Dimension reduction,semantic interaction,exploratory data analysis,observation projection,attribute projection","caption":"Fig. 1. The initial, interactive symmetric dual projections of a multidimensional dataset using SIRIUS. Observations (animals) are projected in the left panel, while attributes (animal characteristics) are projected in the right panel. Both panels project similar items closer together based on a weighted high-dimensional distance function in which the weights reflect a conceptual notion of \u201cimportance.\u201d These weights are reflected by the node sizes and opacities in the opposing panel. For example, Quadrupedal has a higher weight in the left projection of animals, and Tiger has a slightly higher weight in the right projection of characteristics.","img_size":{"width":1969,"height":629},"subfigures":[{"x":17.66524802000454,"y":13.614037423994079,"width":1933.669503959988,"height":607.9286419215379,"type":"interface","id":"interface-0"}],"visualizations":[{"x":14.932827735644633,"y":16.9100758396533,"width":934.3683640303356,"height":595.1798483206933,"type":"scatterplot","id":"scatterplot-0"},{"x":1021.8320693391113,"y":19.04333694474539,"width":930.1018418201517,"height":599.4463705308774,"type":"scatterplot","id":"scatterplot-1"}],"relations":[{"vislist":[{"vislist":["scatterplot-0","scatterplot-1"],"relation":null,"id":"group-0"}],"relation":"repeated","id":"relation-0"}]},"2460_0":{"comp":[["matrix","matrix",["repeated"]]],"visType":["matrix"],"compType":["repeated"],"compressed_tree":[{"composite_pattern":"repeated","visualization_type":[["matrix"]]}],"coOccurrence":[["matrix","matrix",["coOccurrence"]]],"year":2014,"conference":["InfoVis"],"authors":["Ramik Sadana","Timothy Major","Alistair D. M. Dove","John T. Stasko"],"title":"OnSet: A Visualization Technique for Large-scale Binary Set Data","doi":"10.1109/TVCG.2014.2346249","abstract":"Visualizing sets to reveal relationships between constituent elements is a complex representational problem. Recent research presents several automated placement and grouping techniques to highlight connections between set elements. However, these techniques do not scale well for sets with cardinality greater than one hundred elements. We present OnSet, an interactive, scalable visualization technique for representing large-scale binary set data. The visualization technique defines a single, combined domain of elements for all sets, and models each set by the elements that it both contains and does not contain. OnSet employs direct manipulation interaction and visual highlighting to support easy identification of commonalities and differences as well as membership patterns across different sets of elements. We present case studies to illustrate how the technique can be successfully applied across different domains such as bio-chemical metabolomics and task and event scheduling.","keywords":"Set visualization, information visualization, direct manipulation, Euler diagrams, interaction, logical operations","caption":"Fig. 1. User interface of OnSet. The list of sets is on the right (the orange bar indicates the number of elements in the set). Each set is represented as a rectangular region with the set elements being smaller interior rectangles. This view shows two individual sets (one is dimmed) on the left and two compositions of individual sets on the right. ","img_size":{"width":1885,"height":595},"subfigures":[{"x":18.64293488874719,"y":13.543750284745903,"width":1850.452385836024,"height":572.0232264514192,"type":"interface","id":"interface-0"}],"visualizations":[{"x":1541.951219512195,"y":144.83739837398366,"width":330.08130081300806,"height":450.16260162601634,"type":"bar_chart","id":"bar_chart-0"},{"x":60.121951219512184,"y":197.88617886178855,"width":318.2926829268293,"height":327.7235772357724,"type":"heatmap","id":"heatmap-1"},{"x":432.6422764227641,"y":197.88617886178855,"width":312.3983739837399,"height":331.26016260162606,"type":"heatmap","id":"heatmap-2"},{"x":796.9105691056909,"y":167.23577235772353,"width":348.94308943089436,"height":359.5528455284552,"type":"heatmap","id":"heatmap-3"},{"x":1171.7886178861786,"y":166.05691056910564,"width":346.5853658536587,"height":363.08943089430886,"type":"heatmap","id":"heatmap-4"},{"x":62.47967479674796,"y":196.7073170731707,"width":315.9349593495934,"height":330.08130081300806,"type":"matrix","id":"matrix-5"},{"x":433.82113821138205,"y":197.88617886178855,"width":315.9349593495934,"height":332.4390243902439,"type":"matrix","id":"matrix-6"},{"x":798.089430894309,"y":167.23577235772353,"width":348.94308943089436,"height":363.08943089430903,"type":"matrix","id":"matrix-7"},{"x":1169.430894308943,"y":164.87804878048775,"width":350.1219512195121,"height":361.910569105691,"type":"matrix","id":"matrix-8"}],"relations":[{"vislist":[{"vislist":["matrix-5","matrix-6","matrix-7","matrix-8"],"relation":null,"id":"group-0"}],"relation":"repeated","id":"relation-0"}]},"2463_10":{"comp":[["line_chart","line_chart",["repeated"]],["line_chart","sankey_diagram",["nested"]],["box_plot","box_plot",["repeated"]],["box_plot","sankey_diagram",["nested"]],["heatmap","sankey_diagram",["nested"]],["scatterplot","parallel_coordinate",["stacked"]],["parallel_coordinate","scatterplot",["stacked"]]],"visType":["line_chart","sankey_diagram","box_plot","heatmap","scatterplot","parallel_coordinate"],"compType":["repeated","nested","stacked"],"compressed_tree":[{"composite_pattern":"nested","visualization_type":[["line_chart","box_plot","heatmap"],["sankey_diagram"]]},{"composite_pattern":"stacked","visualization_type":[["scatterplot","parallel_coordinate"]]},{"composite_pattern":"repeated","visualization_type":[["line_chart"]]},{"composite_pattern":"repeated","visualization_type":[["box_plot"]]}],"coOccurrence":[["line_chart","box_plot",["coOccurrence"]],["line_chart","heatmap",["coOccurrence"]],["line_chart","sankey_diagram",["coOccurrence"]],["line_chart","scatterplot",["coOccurrence"]],["line_chart","parallel_coordinate",["coOccurrence"]],["box_plot","heatmap",["coOccurrence"]],["box_plot","sankey_diagram",["coOccurrence"]],["box_plot","scatterplot",["coOccurrence"]],["box_plot","parallel_coordinate",["coOccurrence"]],["heatmap","sankey_diagram",["coOccurrence"]],["heatmap","scatterplot",["coOccurrence"]],["heatmap","parallel_coordinate",["coOccurrence"]],["sankey_diagram","scatterplot",["coOccurrence"]],["sankey_diagram","parallel_coordinate",["coOccurrence"]],["scatterplot","parallel_coordinate",["coOccurrence"]]],"year":2014,"conference":["InfoVis"],"authors":["Samuel Gratzl","Nils Gehlenborg","Alexander Lex","Hanspeter Pfister","Marc Streit"],"title":"Domino: Extracting, Comparing, and Manipulating Subsets Across Multiple Tabular Datasets","doi":"10.1109/TVCG.2014.2346260","abstract":"Answering questions about complex issues often requires analysts to take into account information contained in multiple interconnected datasets. A common strategy in analyzing and visualizing large and heterogeneous data is dividing it into meaningful subsets. Interesting subsets can then be selected and the associated data and the relationships between the subsets visualized. However, neither the extraction and manipulation nor the comparison of subsets is well supported by state-of-the-art techniques. In this paper we present Domino, a novel multiform visualization technique for effectively representing subsets and the relationships between them. By providing comprehensive tools to arrange, combine, and extract subsets, Domino allows users to create both common visualization techniques and advanced visualizations tailored to specific use cases. In addition to the novel technique, we present an implementation that enables analysts to manage the wide range of options that our approach offers. Innovative interactive features such as placeholders and live previews support rapid creation of complex analysis setups. We introduce the technique and the implementation using a simple example and demonstrate scalability and effectiveness in a use case from the field of cancer genomics.","keywords":"Multiple coordinated views, visual linking, relationships, heterogeneous data, categorical data","caption":"Fig. 10: Key \ufb01ndings on subtypes in glioblastoma multiforme. Orange highlighting indicates patients with the G-CIMP subtype. (1) The mRNA gene expression matrix. In this heatmap, red and blue indicate expression levels higher and lower than the cohort average, respectively. Gray represents the average. (2) Partitioning block representing the tumor subtypes de\ufb01ned by Brennan et al. [3]. (3) The mutation status of the IDH1 gene. Purple represents mutations; orange represents patients without mutation, and gray represents missing data. (4) Patient survival illustrated by Kaplan-Meier plots. (5) Patient age as boxplots. (6) Copy number for each patient and gene sorted by genomic location. Blue and red hues represent copy number losses and ampli\ufb01cations, respectively. Gray represents the normal state of two copies per gene. (7) Block extracted from the copy number heatmap to highlight uncommon copy number patterns observed in the G-CIMP subtype. (8) Copy number and gene expression levels for CDKN2A and EGFR. (9) Scatterplot showing the relationship between patient age and overall survival time.","img_size":{"width":1869,"height":912},"subfigures":[{"x":7.681047684304799,"y":7.289933657125969,"width":1852.2803980686167,"height":898.7778102732472,"type":"interface","id":"interface-0"}],"visualizations":[{"x":167.6202263083452,"y":55.46817538896747,"width":122.54596888260254,"height":384.4073550212164,"type":"box_plot","id":"box_plot-1"},{"x":616.5254596888262,"y":69.65770862800568,"width":762.3649222065064,"height":356.02828854314004,"type":"heatmap","id":"heatmap-2"},{"x":1488.5367751060824,"y":73.52758132956157,"width":260.5714285714285,"height":223.1626591230552,"type":"heatmap","id":"heatmap-3"},{"x":372.7234794908063,"y":38.6987270155587,"width":121.2560113154173,"height":419.2362093352194,"type":"line_chart","id":"line_chart-4"},{"x":1478.2171145686,"y":666.9080622347951,"width":370.2178217821783,"height":220.5827439886846,"type":"parallel_coordinate","id":"parallel_coordinate-0"},{"x":390.78288543140025,"y":521.1428571428572,"width":1057.765205091938,"height":379.2475247524753,"type":"parallel_coordinate","id":"parallel_coordinate-5"},{"x":11.082005207773413,"y":1.2296121665582245,"width":1743.0026562511196,"height":459.31292756561834,"type":"sankey_diagram","id":"sankey_diagram-7"},{"x":37.33451202263089,"y":523.7227722772278,"width":352.1584158415842,"height":370.2178217821782,"type":"scatterplot","id":"scatterplot-6"}],"relations":[{"vislist":[{"vislist":["line_chart-4","box_plot-1","heatmap-2","heatmap-3"],"relation":null,"id":"group-0"},{"vislist":["sankey_diagram-7"],"relation":null,"id":"group-1"}],"relation":"nested","id":"relation-0"},{"vislist":[{"vislist":["scatterplot-6","parallel_coordinate-5"],"relation":null,"id":"group-2"}],"relation":"stacked","id":"relation-1"},{"vislist":[{"vislist":["line_chart-4"],"relation":null,"id":"group-3"}],"relation":"repeated","id":"relation-2"},{"vislist":[{"vislist":["box_plot-1"],"relation":null,"id":"group-4"}],"relation":"repeated","id":"relation-3"}]},"2464_0":{"comp":[["line_chart","line_chart",["repeated"]]],"visType":["line_chart"],"compType":["repeated"],"compressed_tree":[{"composite_pattern":"repeated","visualization_type":[["line_chart"]]}],"coOccurrence":[["line_chart","line_chart",["coOccurrence"]]],"year":2014,"conference":["InfoVis"],"authors":["Cagatay Turkay","Aidan Slingsby","Helwig Hauser","Jo Wood","Jason Dykes"],"title":"Attribute Signatures: Dynamic Visual Summaries for Analyzing Multivariate Geographical Data","doi":"10.1109/TVCG.2014.2346265","abstract":"The visual analysis of geographically referenced datasets with a large number of attributes is challenging due to the fact that the characteristics of the attributes are highly dependent upon the locations at which they are focussed, and the scale and time at which they are measured. Specialized interactive visual methods are required to help analysts in understanding the characteristics of the attributes when these multiple aspects are considered concurrently. Here, we develop attribute signatures-interactively crafted graphics that show the geographic variability of statistics of attributes through which the extent of dependency between the attributes and geography can be visually explored. We compute a number of statistical measures, which can also account for variations in time and scale, and use them as a basis for our visualizations. We then employ different graphical configurations to show and compare both continuous and discrete variation of location and scale. Our methods allow variation in multiple statistical summaries of multiple attributes to be considered concurrently and geographically, as evidenced by examples in which the census geography of London and the wider UK are explored.","keywords":"Visual analytics, multi-variate data, geographic information, geovisualization, interactive data analysis","caption":"Fig. 1. Attribute signatures (right) are dynamically created in response to an interactive geographic selection sequence (left) that follows the coastline from South Gloucestershire to St Ives on the north Cornwall coast where each output area is represented with an orange dot. The signatures show how the average values for 41 attributes vary as the selection moves. The trace of the brush sequence is linked to the signatures \u2013 the faded points and the vertical dashed lines on the signatures are linked to the location highlighted on the map. A small holiday resort, Lynton (green rectangle), is characterized by the high proportion of population in the hotel and catering industry. Fishing & agriculture towns, such as Hartland (red markers), are characterized with low population densities where population is in mostly detached houses.","img_size":{"width":1886,"height":1017},"subfigures":[{"x":18.011133611500508,"y":14.468871775521512,"width":1852.754999612453,"height":990.8405064254781,"type":"interface","id":"interface-0"}],"visualizations":[{"x":1035.7814710042435,"y":21.577086280056587,"width":827.1216407355023,"height":970.9688826025462,"type":"line_chart","id":"line_chart-1"},{"x":21.658415841584148,"y":10.069306930693068,"width":986.7920792079206,"height":991.1074964639324,"type":"map","id":"map-3"}],"relations":[{"vislist":[{"vislist":["line_chart-1"],"relation":null,"id":"group-3"}],"relation":"repeated","id":"relation-2"}]},"2473_11":{"comp":[["bar_chart","bar_chart",["repeated"]],["glyph_based","scatterplot",["nested"]]],"visType":["bar_chart","glyph_based","scatterplot"],"compType":["repeated","nested"],"compressed_tree":[{"composite_pattern":"nested","visualization_type":[["glyph_based"],["scatterplot"]]},{"composite_pattern":"repeated","visualization_type":[["bar_chart"]]}],"coOccurrence":[["glyph_based","scatterplot",["coOccurrence"]],["glyph_based","bar_chart",["coOccurrence"]],["scatterplot","bar_chart",["coOccurrence"]]],"year":2014,"conference":["InfoVis"],"authors":["Zan Armstrong","Martin Wattenberg"],"title":"Visualizing Statistical Mix Effects and Simpson\'s Paradox","doi":"10.1109/TVCG.2014.2346297","abstract":"We discuss how \u201cmix effects\u201d can surprise users of visualizations and potentially lead them to incorrect conclusions. This statistical issue (also known as \u201comitted variable bias\u201d or, in extreme cases, as \u201cSimpson\'s paradox\u201d) is widespread and can affect any visualization in which the quantity of interest is an aggregated value such as a weighted sum or average. Our first contribution is to document how mix effects can be a serious issue for visualizations, and we analyze how mix effects can cause problems in a variety of popular visualization techniques, from bar charts to treemaps. Our second contribution is a new technique, the \u201ccomet chart,\u201d that is meant to ameliorate some of these issues.","keywords":"Mix effects, Omitted variable bias, Simpson\'s paradox, Statistics","caption":"Fig. 10: Comet chart embedded in the tool, supplemented by a sortable bar chart view (right) and filtering/scale/highlighting options and data input (top). Bar chart and comet charts are linked: one county is shown in red on both the comet chart and bar chart in response to a click.","img_size":{"width":1064,"height":546},"subfigures":[{"x":2.8323195713208054,"y":1.5365992384737954,"width":1056.0169226827265,"height":540.6070920857754,"type":"interface","id":"interface-0"}],"visualizations":[{"x":494.36542669584236,"y":106.33260393873086,"width":549.5842450765862,"height":433.69365426695833,"type":"bar_chart","id":"bar_chart-0"},{"x":9.297592997811805,"y":103.94310722100654,"width":451.6148796498905,"height":434.8884026258205,"type":"glyph_based","id":"glyph_based-1"},{"x":8.102844638949662,"y":101.55361050328227,"width":451.6148796498905,"height":436.0831509846826,"type":"scatterplot","id":"scatterplot-2"}],"relations":[{"vislist":[{"vislist":["glyph_based-1"],"relation":null,"id":"group-0"},{"vislist":["scatterplot-2"],"relation":null,"id":"group-1"}],"relation":"nested","id":"relation-0"},{"vislist":[{"vislist":["bar_chart-0"],"relation":null,"id":"group-2"}],"relation":"repeated","id":"relation-1"}]},"2476_4":{"comp":[["tree","tree",["repeated"]],["bar_chart","tree",["nested"]],["matrix","comb",["stacked"]],["comb","matrix",["stacked"]],["comb","comb",["stacked"]]],"visType":["tree","bar_chart","matrix","comb"],"compType":["repeated","nested","stacked"],"compressed_tree":[{"composite_pattern":"stacked","visualization_type":[["matrix",{"composite_pattern":"repeated","visualization_type":[["tree"]]},{"composite_pattern":"nested","visualization_type":[["bar_chart"],["tree"]]}]]}],"coOccurrence":[["tree","bar_chart",["coOccurrence"]],["tree","matrix",["coOccurrence"]],["bar_chart","matrix",["coOccurrence"]]],"year":2014,"conference":["InfoVis"],"authors":["Ali K. Al-Awami","Johanna Beyer","Hendrik Strobelt","Narayanan Kasthuri","Jeff Lichtman","Hanspeter Pfister","Markus Hadwiger"],"title":"NeuroLines: A Subway Map Metaphor for Visualizing Nanoscale Neuronal Connectivity","doi":"10.1109/TVCG.2014.2346312","abstract":"We present NeuroLines, a novel visualization technique designed for scalable detailed analysis of neuronal connectivity at the nanoscale level. The topology of 3D brain tissue data is abstracted into a multi-scale, relative distance-preserving subway map visualization that allows domain scientists to conduct an interactive analysis of neurons and their connectivity. Nanoscale connectomics aims at reverse-engineering the wiring of the brain. Reconstructing and analyzing the detailed connectivity of neurons and neurites (axons, dendrites) will be crucial for understanding the brain and its development and diseases. However, the enormous scale and complexity of nanoscale neuronal connectivity pose big challenges to existing visualization techniques in terms of scalability. NeuroLines offers a scalable visualization framework that can interactively render thousands of neurites, and that supports the detailed analysis of neuronal structures and their connectivity. We describe and analyze the design of NeuroLines based on two real-world use-cases of our collaborators in developmental neuroscience, and investigate its scalability to large-scale neuronal connectivity data.","keywords":"Connectomics, Neuroscience, Data Abstraction, Multi-Trees, Focus+Context","caption":"Fig. 5: NeuroLines overview. We visualize neurites using a multi-scale approach with three tiers of linked views (a,b,c), which provide overview as well as details. The navigation bar (a) shows individual neurites as lines color-coded according to selected neurite attributes and sorting criteria. The neurite overview (b) allows inspecting all neurites at a medium level of abstraction. The workspace view (c) allows the inspection of neurites at a detailed level of abstraction. The neurite analysis (d) shows statistics for a selected neurite. Pinning (e) a neurite to the workspace allows keeping a speci\ufb01c neurite in focus while exploring others. The synapse analysis (f) shows synapse details and its neighborhood in the original EM volume. (g) NeuroLines is also coupled with a 3D volume renderer for additional visualization and exploration in 3D.","img_size":{"width":2147,"height":870},"subfigures":[{"x":13.463344595597325,"y":12.245383302900631,"width":2115.3950337778565,"height":847.0687273914252,"type":"single","id":"single-0"}],"visualizations":[{"x":143.23809668455775,"y":159.48466084018105,"width":521.9620782358227,"height":155.7480696239848,"type":"bar_chart","id":"bar_chart-7"},{"x":43.08790094957067,"y":71.76281970722275,"width":69.07463901796432,"height":762.4091431942488,"type":"matrix","id":"matrix-6"},{"x":147.94749794913866,"y":83.62469237079571,"width":514.2936833470059,"height":65.1673502871206,"type":"tree","id":"tree-0"},{"x":727.4085315832651,"y":113.5664479081214,"width":1349.1402789171452,"height":73.97374897456933,"type":"tree","id":"tree-1"},{"x":725.6472518457756,"y":201.63043478260872,"width":1349.1402789171452,"height":70.45118949958984,"type":"tree","id":"tree-2"},{"x":727.4085315832651,"y":309.0684987694832,"width":1350.9015586546345,"height":149.70877768662842,"type":"tree","id":"tree-3"},{"x":729.1698113207549,"y":654.2793273174734,"width":1042.6776045939296,"height":190.2182116488926,"type":"tree","id":"tree-4"},{"x":146.63576715541325,"y":318.8951269369165,"width":516.0549630844955,"height":524.8613617719443,"type":"tree","id":"tree-5"}],"relations":[{"vislist":[{"vislist":["matrix-6",{"vislist":[{"vislist":["tree-1","tree-2","tree-3","tree-4"],"relation":null,"id":"group-0"}],"relation":"repeated","id":"relation-0"},{"vislist":[{"vislist":["bar_chart-7"],"relation":null,"id":"group-1"},{"vislist":["tree-0","tree-5"],"relation":null,"id":"group-2"}],"relation":"nested","id":"relation-1"}],"relation":null,"id":"group-3"}],"relation":"stacked","id":"relation-2"}]},"2479_7":{"comp":[["bar_chart","bar_chart",["repeated"]],["line_chart","line_chart",["repeated"]],["graph","map",["coordinated"]]],"visType":["bar_chart","line_chart","graph","map"],"compType":["repeated","coordinated"],"compressed_tree":[{"composite_pattern":"repeated","visualization_type":[["bar_chart"]]},{"composite_pattern":"repeated","visualization_type":[["line_chart"]]},{"composite_pattern":"coordinated","visualization_type":[["graph"],["map"]]}],"coOccurrence":[["bar_chart","line_chart",["coOccurrence"]],["bar_chart","graph",["coOccurrence"]],["bar_chart","map",["coOccurrence"]],["line_chart","graph",["coOccurrence"]],["line_chart","map",["coOccurrence"]],["graph","map",["coOccurrence"]]],"year":2014,"conference":["InfoVis"],"authors":["Jo Wood","Roger Beecham","Jason Dykes"],"title":"Moving beyond sequential design: Reflections on a rich multi-channel approach to data visualization","doi":"10.1109/TVCG.2014.2346323","abstract":"We reflect on a four-year engagement with transport authorities and others involving a large dataset describing the use of a public bicycle-sharing scheme. We describe the role visualization of these data played in fostering engagement with policy makers, transport operators, the transport research community, the museum and gallery sector and the general public. We identify each of these as `channels\'-evolving relationships between producers and consumers of visualization-where traditional roles of the visualization expert and domain expert are blurred. In each case, we identify the different design decisions that were required to support each of these channels and the role played by the visualization process. Using chauffeured interaction with a flexible visual analytics system we demonstrate how insight was gained by policy makers into gendered spatio-temporal cycle behaviors, how this led to further insight into workplace commuting activity, group cycling behavior and explanations for street navigation choice. We demonstrate how this supported, and was supported by, the seemingly unrelated development of narrative-driven visualization via TEDx, of the creation and the setting of an art installation and the curating of digital and physical artefacts. We assert that existing models of visualization design, of tool/technique development and of insight generation do not adequately capture the richness of parallel engagement via these multiple channels of communication. We argue that developing multiple channels in parallel opens up opportunities for visualization design and analysis by building trust and authority and supporting creativity. This rich, non-sequential approach to visualization design is likely to foster serendipity, deepen insight and increase impact.","keywords":"Movement visualization, visual analytics, bikeshare, impact, visualization models, design study","caption":"Fig. 4. Visual analysis application for querying customers\u2019 travel behaviors. The main map view shows a \ufb01lterable spatial distribution of journeys. The bottom row shows a temporal view by day and hour. Customer characteristics such as geodemographic pro\ufb01le, journey frequency and relative cycling speed are shown to the left. In all cases, comparisons may be made between the \ufb01ltered selection (blue) and global patterns (grey).","img_size":{"width":2135,"height":1203},"subfigures":[{"x":8.31437695157288,"y":10.601840680167681,"width":2111.7940092317963,"height":1181.7963186396632,"type":"interface","id":"interface-0"}],"visualizations":[{"x":21.346835443038007,"y":1044.6303797468354,"width":340.3609225540212,"height":153.6622489727597,"type":"bar_chart","id":"bar_chart-0"},{"x":21.346835443038007,"y":916.7164556962025,"width":335.01265822784814,"height":127.9139240506329,"type":"bar_chart","id":"bar_chart-1"},{"x":102.37794671037251,"y":283.48278914638973,"width":228.02315007402063,"height":101.13930043605757,"type":"bar_chart","id":"bar_chart-2"},{"x":31.74377219950236,"y":408.5277424127882,"width":271.07387901142056,"height":489.18848117917497,"type":"bar_chart","id":"bar_chart-3"},{"x":376.8891627879394,"y":12.782604573533726,"width":1740.9132780695884,"height":789.4799551426985,"type":"graph","id":"graph-10"},{"x":377.32735495789035,"y":13.256545684903065,"width":1745.4899603728736,"height":831.7435381642554,"type":"heatmap","id":"heatmap-5"},{"x":381.2322541980981,"y":876.2392777708203,"width":1704.4885183506922,"height":304.58214073620616,"type":"line_chart","id":"line_chart-6"},{"x":377.32735495789035,"y":17.161444925110843,"width":1745.4899603728736,"height":827.8386389240475,"type":"map","id":"map-4"},{"x":14.171725618567622,"y":17.16144492511094,"width":330.0054895713058,"height":259.98539051792704,"type":"matrix","id":"matrix-7"}],"relations":[{"vislist":[{"vislist":["bar_chart-1","bar_chart-0"],"relation":null,"id":"group-0"}],"relation":"repeated","id":"relation-0"},{"vislist":[{"vislist":["line_chart-6"],"relation":null,"id":"group-1"}],"relation":"repeated","id":"relation-1"},{"vislist":[{"vislist":["graph-10"],"relation":null,"id":"group-2"},{"vislist":["map-4"],"relation":null,"id":"group-3"}],"relation":"coordinated","id":"relation-2"}]},"2492_2":{"comp":[["bar_chart","bar_chart",["repeated"]],["bar_chart","map",["nested"]],["bar_chart","graph",["nested"]]],"visType":["bar_chart","map","graph"],"compType":["repeated","nested"],"compressed_tree":[{"composite_pattern":"repeated","visualization_type":[["bar_chart"]]},{"composite_pattern":"nested","visualization_type":[["bar_chart"],["map","graph"]]}],"coOccurrence":[["bar_chart","map",["coOccurrence"]]],"year":2014,"conference":["InfoVis"],"authors":["Stef van den Elzen","Jarke J. van Wijk"],"title":"Multivariate Network Exploration and Presentation: From Detail to Overview via Selections and Aggregations","doi":"10.1109/TVCG.2014.2346441","abstract":"Network data is ubiquitous; e-mail traffic between persons, telecommunication, transport and financial networks are some examples. Often these networks are large and multivariate, besides the topological structure of the network, multivariate data on the nodes and links is available. Currently, exploration and analysis methods are focused on a single aspect; the network topology or the multivariate data. In addition, tools and techniques are highly domain specific and require expert knowledge. We focus on the non-expert user and propose a novel solution for multivariate network exploration and analysis that tightly couples structural and multivariate analysis. In short, we go from Detail to Overview via Selections and Aggregations (DOSA): users are enabled to gain insights through the creation of selections of interest (manually or automatically), and producing high-level, infographic-style overviews simultaneously. Finally, we present example explorations on real-world datasets that demonstrate the effectiveness of our method for the exploration and understanding of multivariate networks where presentation of findings comes for free.","keywords":"Multivariate Networks, Selections of Interest, Interaction, Direct Manipulation","caption":"Fig. 3. Graphical user interface of the implemented prototype showing all coherent components: a) Low-level detail view showing a two-dimensional projection of the nodes based on available attributes. The projection and other visual attributes can be set using controls at the bottom (e). Four selections of interest are shown in the detail view, visualized using boxes for direct manipulation. All selections of interest show between edges, the green, blue, and, orange selections also show within edges. The orange selection additionally shows edges with the background selection. b) High-level overview showing aggregations of the selections of interest including associated aggregated edges. For each of the selections an interactive histogram visualization is shown. Visual representation and attribute mapping are con\ufb01gurable to users needs with controls at the bottom (f). c) Attribute component showing all available attributes with according Scented Widgets for the nodes and links in different tab-pages. The Scented Widgets provide information on the distribution of attributes and can be used to directly control the ranges of the multidimensional selections of interest. d) Selection component containing a list of all selections. Selection priority (order) is controlled via drag and drop operations. Additionally, selections can be hidden or locked here.","img_size":{"width":2151,"height":1260},"subfigures":[{"x":11.688528539221814,"y":16.102197698280726,"width":2113.8505199633682,"height":1208.8641667103175,"type":"interface","id":"interface-0"}],"visualizations":[{"x":48.07425742574259,"y":114.05940594059406,"width":276.23762376237624,"height":506.1386138613861,"type":"bar_chart","id":"bar_chart-0"},{"x":1463.1237623762377,"y":288.71287128712873,"width":172.871287128713,"height":180,"type":"bar_chart","id":"bar_chart-1"},{"x":1823.1237623762377,"y":290.4950495049505,"width":155.04950495049528,"height":178.21782178217828,"type":"bar_chart","id":"bar_chart-2"},{"x":1812.430693069307,"y":666.5346534653464,"width":169.30693069306926,"height":172.8712871287129,"type":"bar_chart","id":"bar_chart-3"},{"x":1468.4702970297033,"y":664.7524752475247,"width":163.9603960396039,"height":176.43564356435638,"type":"bar_chart","id":"bar_chart-4"},{"x":1356.193069306931,"y":156.83168316831683,"width":771.6831683168317,"height":900,"type":"graph","id":"graph-5"},{"x":358.1732673267327,"y":349.3069306930693,"width":994.4554455445543,"height":597.029702970297,"type":"scatterplot","id":"scatterplot-6"}],"relations":[{"vislist":[{"vislist":["bar_chart-0"],"relation":null,"id":"group-0"}],"relation":"repeated","id":"relation-0"},{"vislist":[{"vislist":["bar_chart-3","bar_chart-2","bar_chart-1","bar_chart-4"],"relation":null,"id":"group-1"},{"vislist":["map-5","graph-5"],"relation":null,"id":"group-3"}],"relation":"nested","id":"relation-1"}]},"2494_0":{"comp":[["pie_chart","others",["repeated"]],["others","pie_chart",["repeated"]],["bar_chart","bar_chart",["repeated"]]],"visType":["pie_chart","others","bar_chart"],"compType":["repeated"],"compressed_tree":[{"composite_pattern":"repeated","visualization_type":[["pie_chart","others"]]},{"composite_pattern":"repeated","visualization_type":[["bar_chart"]]}],"coOccurrence":[["pie_chart","bar_chart",["coOccurrence"]]],"year":2014,"conference":["InfoVis"],"authors":["Tom Polk","Jing Yang","Yueqi Hu","Ye Zhao"],"title":"TenniVis: Visualization for Tennis Match Analysis","doi":"10.1109/TVCG.2014.2346445","abstract":"Existing research efforts into tennis visualization have primarily focused on using ball and player tracking data to enhance professional tennis broadcasts and to aid coaches in helping their students. Gathering and analyzing this data typically requires the use of an array of synchronized cameras, which are expensive for non-professional tennis matches. In this paper, we propose TenniVis, a novel tennis match visualization system that relies entirely on data that can be easily collected, such as score, point outcomes, point lengths, service information, and match videos that can be captured by one consumer-level camera. It provides two new visualizations to allow tennis coaches and players to quickly gain insights into match performance. It also provides rich interactions to support ad hoc hypothesis development and testing. We first demonstrate the usefulness of the system by analyzing the 2007 Australian Open men\'s singles final. We then validate its usability by two pilot user studies where two college tennis coaches analyzed the matches of their own players. The results indicate that useful insights can quickly be discovered and ad hoc hypotheses based on these insights can conveniently be tested through linked match videos.","keywords":"Visual knowledge discovery, sports analytics, tennis visualization","caption":"Fig. 1. A college men\u2019s singles tennis match in TenniVis. (a) Match scores and \ufb01lters. (b) Pie Meter view. Each Pie Meter represents a game. Balls above/below it represent points gained by player one/two. Solid/hollow balls represent good (ace, winner, forced error) /bad (double-fault, unforced error) points. The darker the green/red colors in the pie, the better the chance player one/two had to win the game. Needle color shows who won the game (green for player one, red for player two). Needle angle indicates the \ufb01nal score (the closer to East, the closer the score was). Red and green boxes identify service breaks. (1) A game won easily by player one. (2) A game won with dif\ufb01culty by player two. (c) Bar charts of point outcome statistics in multiple \ufb01lter con\ufb01gurations. (d) Video viewer playing a video clip of a point.","img_size":{"width":2151,"height":1106},"subfigures":[{"x":13.511189867013385,"y":19.277808712688255,"width":2127.10228224193,"height":1069.0066488070015,"type":"interface","id":"interface-0"}],"visualizations":[{"x":500.59900990099004,"y":854.1386138613861,"width":380.1386138613862,"height":219.00990099009914,"type":"bar_chart","id":"bar_chart-0"},{"x":885.4306930693069,"y":854.1386138613861,"width":380.1386138613862,"height":219.00990099009914,"type":"bar_chart","id":"bar_chart-1"},{"x":1265.569306930693,"y":857.2673267326733,"width":383.26732673267344,"height":217.44554455445552,"type":"bar_chart","id":"bar_chart-2"},{"x":1648.836633663366,"y":855.7029702970298,"width":383.2673267326732,"height":219.00990099009903,"type":"bar_chart","id":"bar_chart-3"},{"x":496.9112685380607,"y":97.40954679144207,"width":1621.8996851461,"height":641.7949715972177,"type":"others","id":"others-4"}],"relations":[{"vislist":[{"vislist":["pie_chart-4","others-4"],"relation":null,"id":"group-2"}],"relation":"repeated","id":"relation-0"},{"vislist":[{"vislist":["bar_chart-0","bar_chart-1","bar_chart-2","bar_chart-3"],"relation":null,"id":"group-1"}],"relation":"repeated","id":"relation-1"}]},"2494_1":{"comp":[["matrix","matrix",["repeated"]]],"visType":["matrix"],"compType":["repeated"],"compressed_tree":[{"composite_pattern":"repeated","visualization_type":[["matrix"]]}],"coOccurrence":[["matrix","matrix",["coOccurrence"]]],"year":2014,"conference":["InfoVis"],"authors":["Tom Polk","Jing Yang","Yueqi Hu","Ye Zhao"],"title":"TenniVis: Visualization for Tennis Match Analysis","doi":"10.1109/TVCG.2014.2346445","abstract":"Existing research efforts into tennis visualization have primarily focused on using ball and player tracking data to enhance professional tennis broadcasts and to aid coaches in helping their students. Gathering and analyzing this data typically requires the use of an array of synchronized cameras, which are expensive for non-professional tennis matches. In this paper, we propose TenniVis, a novel tennis match visualization system that relies entirely on data that can be easily collected, such as score, point outcomes, point lengths, service information, and match videos that can be captured by one consumer-level camera. It provides two new visualizations to allow tennis coaches and players to quickly gain insights into match performance. It also provides rich interactions to support ad hoc hypothesis development and testing. We first demonstrate the usefulness of the system by analyzing the 2007 Australian Open men\'s singles final. We then validate its usability by two pilot user studies where two college tennis coaches analyzed the matches of their own players. The results indicate that useful insights can quickly be discovered and ad hoc hypotheses based on these insights can conveniently be tested through linked match videos.","keywords":"Visual knowledge discovery, sports analytics, tennis visualization","caption":"Fig. 2. Fish Grid views of the Federer-Gonzalez match (won by Federer 7-6, 6-4, 6-4). (a)-(c) are captured from a zoomed-in view and (d) is a zoomed out view. Each Fish Grid is a score matrix rotated 45 degrees with point outcomes mapped on it as balls (green/red: point gained by Federer/Gonzalez; solid/hollow: good/bad shot). The horizontal order of the balls indicates the temporal order of the points. The vertical position of a ball indicate who was in lead before the point (above the horizontal, Federer is in the lead; below the horizontal, Gonzalez is in the lead). (a) A game won easily by Federer. (b) The longest game in the match (won by Gonzalez). (c) A game with a \u201cchoke\u201d point for Gonzalez, identi\ufb01ed using \ufb01lters. (d) Fish Grids for the entire match. Although shown small here, they still convey trend information for each game. (e) Sample Point Outcome Glyphs (balls) at different zoom levels. At the maximum zoom level, tick marks represent point length in seconds and triangles represent service side (left/right) and \ufb01rst vs. second serve (solid/hollow).","img_size":{"width":2157,"height":828},"subfigures":[{"x":8.864644117199223,"y":434.74605442708247,"width":2137.7040228111264,"height":372.43902919059826,"type":"single","id":"single-0"}],"visualizations":[{"x":17.536585365853657,"y":15.379924953095683,"width":481.5816135084427,"height":369.6172607879924,"type":"matrix","id":"matrix-0"},{"x":528.795497185741,"y":11.333020637898684,"width":1038.7054409005627,"height":380.4090056285178,"type":"matrix","id":"matrix-1"},{"x":1661.9287054409006,"y":20.775797373358344,"width":458.64915572232644,"height":364.2213883677298,"type":"matrix","id":"matrix-2"},{"x":1892.6022514071292,"y":405.23170731707313,"width":248.21013133208274,"height":199.64727954971858,"type":"matrix","id":"matrix-3"},{"x":4.755878150741715,"y":440.3048780487804,"width":1881.8105065666039,"height":353.42964352720446,"type":"matrix","id":"matrix-4"}],"relations":[{"vislist":[{"vislist":["matrix-4"],"relation":null,"id":"group-0"}],"relation":"repeated","id":"relation-0"}]},"2496_0":{"comp":[["area_chart","area_chart",["repeated"]],["comb","comb",["repeated"]],["bar_chart","line_chart",["accompanied"]],["line_chart","bar_chart",["accompanied"]]],"visType":["area_chart","comb","bar_chart","line_chart"],"compType":["repeated","accompanied"],"compressed_tree":[{"composite_pattern":"repeated","visualization_type":[["area_chart"]]},{"composite_pattern":"repeated","visualization_type":[[{"composite_pattern":"accompanied","visualization_type":[["bar_chart","line_chart"]]}]]}],"coOccurrence":[["area_chart","bar_chart",["coOccurrence"]],["area_chart","line_chart",["coOccurrence"]],["bar_chart","line_chart",["coOccurrence"]]],"year":2014,"conference":["InfoVis"],"authors":["Jaemin Jo","Jaeseok Huh","Jonghun Park","Bo Hyoung Kim","Jinwook Seo"],"title":"LiveGantt: Interactively Visualizing a Large Manufacturing Schedule","doi":"10.1109/TVCG.2014.2346454","abstract":"In this paper, we introduce LiveGantt as a novel interactive schedule visualization tool that helps users explore highly-concurrent large schedules from various perspectives. Although a Gantt chart is the most common approach to illustrate schedules, currently available Gantt chart visualization tools suffer from limited scalability and lack of interactions. LiveGantt is built with newly designed algorithms and interactions to improve conventional charts with better scalability, explorability, and reschedulability. It employs resource reordering and task aggregation to display the schedules in a scalable way. LiveGantt provides four coordinated views and filtering techniques to help users explore and interact with the schedules in more flexible ways. In addition, LiveGantt is equipped with an efficient rescheduler to allow users to instantaneously modify their schedules based on their scheduling experience in the fields. To assess the usefulness of the application of LiveGantt, we conducted a case study on manufacturing schedule data with four industrial engineering researchers. Participants not only grasped an overview of a schedule but also explored the schedule from multiple perspectives to make enhancements.","keywords":"Schedule visualization, event sequence visualization, simplification, exploratory interactions, simulation","caption":"Fig. 1. Livegantt shows a schedule that contains 3, 404 tasks on 100 resources(Le machines). (A)The exploration history view illustrates the exploration sequence. Three exploration steps are taken before the current context. Two vews with controllers are juxtaposed allowing users to investigate a schedule from two different perspectives. (B) Schedule view gives an overview of a schedule based on a Gantt chart with similar Ga bars around a focus time line ( a black vertical ban) aggregated into larger bars. Tasks that immedate ollow the focus me e a accented with sata colors o mprove sual saliency In the figure above a user is examining details on an aggregated task(green striped). The most frequent sequence after the selected task is also highlighted with saturated colors ()Package ew shows changes in packages production as arael ine charts. The slopes of the lines are represented as hue/saturation to facilitate understanding and analysis.","img_size":{"width":1952,"height":701},"subfigures":[{"x":7.9809599216689975,"y":17.07324094592391,"width":1920.4423707313388,"height":672.518971147594,"type":"interface","id":"interface-0"}],"visualizations":[{"x":1050.4990378447724,"y":18.071520205259745,"width":857.6779987171262,"height":658.5965362411803,"type":"area_chart","id":"area_chart-0"},{"x":23.789608723540727,"y":273.49679281590767,"width":136.4772289929442,"height":108.93136626042332,"type":"bar_chart","id":"bar_chart-4"},{"x":19.29332185997277,"y":26.92996749201054,"width":138.71141624478082,"height":109.76414364005802,"type":"bar_chart","id":"bar_chart-6"},{"x":8.43475853841103,"y":157.8871468946548,"width":153.54318133587768,"height":97.59179957678369,"type":"bar_chart","id":"bar_chart-7"},{"x":21.285439384220656,"y":25.584028223219992,"width":140.23348300192427,"height":112.68762026940345,"type":"line_chart","id":"line_chart-2"},{"x":22.537524053880695,"y":163.31334188582423,"width":138.9813983322642,"height":96.41051956382296,"type":"line_chart","id":"line_chart-3"},{"x":196.57729313662603,"y":18.071520205259745,"width":845.157152020526,"height":657.3444515715202,"type":"others","id":"others-1"},{"x":22.537524053880695,"y":398.7052597819114,"width":130.21680564464398,"height":105.17511225144322,"type":"others","id":"others-5"}],"relations":[{"vislist":[{"vislist":["area_chart-0"],"relation":null,"id":"group-0"}],"relation":"repeated","id":"relation-0"},{"vislist":[{"vislist":[{"vislist":[{"vislist":["bar_chart-6","line_chart-2"],"relation":null,"id":"group-1"}],"relation":"accompanied","id":"relation-1"},{"vislist":[{"vislist":["bar_chart-7","line_chart-3"],"relation":null,"id":"group-2"}],"relation":"accompanied","id":"relation-2"}],"relation":null,"id":"group-3"}],"relation":"repeated","id":"relation-3"}]},"2496_3":{"comp":[["bar_chart","bar_chart",["repeated"]],["bar_chart","line_chart",["accompanied"]],["line_chart","bar_chart",["accompanied"]]],"visType":["bar_chart","line_chart"],"compType":["repeated","accompanied"],"compressed_tree":[{"composite_pattern":"accompanied","visualization_type":[["line_chart","bar_chart"]]},{"composite_pattern":"repeated","visualization_type":[["bar_chart"]]}],"coOccurrence":[["bar_chart","bar_chart",["coOccurrence"]]],"year":2014,"conference":["InfoVis"],"authors":["Jaemin Jo","Jaeseok Huh","Jonghun Park","Bo Hyoung Kim","Jinwook Seo"],"title":"LiveGantt: Interactively Visualizing a Large Manufacturing Schedule","doi":"10.1109/TVCG.2014.2346454","abstract":"In this paper, we introduce LiveGantt as a novel interactive schedule visualization tool that helps users explore highly-concurrent large schedules from various perspectives. Although a Gantt chart is the most common approach to illustrate schedules, currently available Gantt chart visualization tools suffer from limited scalability and lack of interactions. LiveGantt is built with newly designed algorithms and interactions to improve conventional charts with better scalability, explorability, and reschedulability. It employs resource reordering and task aggregation to display the schedules in a scalable way. LiveGantt provides four coordinated views and filtering techniques to help users explore and interact with the schedules in more flexible ways. In addition, LiveGantt is equipped with an efficient rescheduler to allow users to instantaneously modify their schedules based on their scheduling experience in the fields. To assess the usefulness of the application of LiveGantt, we conducted a case study on manufacturing schedule data with four industrial engineering researchers. Participants not only grasped an overview of a schedule but also explored the schedule from multiple perspectives to make enhancements.","keywords":"Schedule visualization, event sequence visualization, simplification, exploratory interactions, simulation","caption":"Fig 4. The perormance ew an the resource view. (a) The performace view displays two important measures for assessing schedules, changes in utilitzation and the number of concurrent changeovrse. A time interval is selected for tempora filtering(gray rectangle). A reference line (black vetical line) folows the mouse cursor indicatng coresponding values. This feature can be tumed off. (b) The resource view allows users to inspect resources by their attributes of utilization and total changeover time. Some resources are brushed with semitransparent gray. The resource view supports brushing and linking so resources on other charts are also highlighted. Brushing can trigger resource filtering.","img_size":{"width":2141,"height":721},"subfigures":[{"x":5.6388552160902625,"y":10.845682159819916,"width":1058.2806370408675,"height":661.9643127740197,"type":"single","id":"single-0"},{"x":1078.5750215132348,"y":17.07063942637597,"width":1049.0713386585253,"height":658.8504789674922,"type":"single","id":"single-1"}],"visualizations":[{"x":1083.5465041693396,"y":28.844130853111015,"width":508.1270044900578,"height":317.2360487491982,"type":"bar_chart","id":"bar_chart-0"},{"x":1076.679923027582,"y":363.93329057087885,"width":513.6202694034637,"height":310.3694676074406,"type":"bar_chart","id":"bar_chart-1"},{"x":1601.286722257858,"y":21.977549711353475,"width":521.8601667735727,"height":649.5785760102632,"type":"bar_chart","id":"bar_chart-2"},{"x":19.226427196921104,"y":19.23091725465045,"width":1049.2135984605518,"height":697.0484823184892,"type":"bar_chart","id":"bar_chart-3"},{"x":16.47979474021809,"y":17.857601026298937,"width":1051.9602309172549,"height":698.4217985468406,"type":"line_chart","id":"line_chart-4"}],"relations":[{"vislist":[{"vislist":["line_chart-4","bar_chart-3"],"relation":null,"id":"group-0"}],"relation":"accompanied","id":"relation-0"},{"vislist":[{"vislist":["bar_chart-1","bar_chart-0"],"relation":null,"id":"group-1"}],"relation":"repeated","id":"relation-1"}]},"2539_0":{"comp":[["glyph_based","glyph_based",["repeated"]],["bar_chart","bar_chart",["repeated"]]],"visType":["glyph_based","bar_chart"],"compType":["repeated"],"compressed_tree":[{"composite_pattern":"repeated","visualization_type":[["glyph_based"]]},{"composite_pattern":"repeated","visualization_type":[["bar_chart"]]}],"coOccurrence":[["glyph_based","bar_chart",["coOccurrence"]]],"year":2014,"conference":["VAST"],"authors":["Josua Krause","Adam Perer","Enrico Bertini"],"title":"INFUSE: Interactive Feature Selection for Predictive Modeling of High Dimensional Data","doi":"10.1109/TVCG.2014.2346482","abstract":"Predictive modeling techniques are increasingly being used by data scientists to understand the probability of predicted outcomes. However, for data that is high-dimensional, a critical step in predictive modeling is determining which features should be included in the models. Feature selection algorithms are often used to remove non-informative features from models. However, there are many different classes of feature selection algorithms. Deciding which one to use is problematic as the algorithmic output is often not amenable to user interpretation. This limits the ability for users to utilize their domain expertise during the modeling process. To improve on this limitation, we developed INFUSE, a novel visual analytics system designed to help analysts understand how predictive features are being ranked across feature selection algorithms, cross-validation folds, and classifiers. We demonstrate how our system can lead to important insights in a case study involving clinical researchers predicting patient outcomes from electronic medical records.","keywords":"Predictive modeling, feature selection, classification, visual analytics, high-dimensional data","caption":"Fig. 1. An overview of INFUSE, a visual analytics tool that supports users to understand the predictive power of features in their models. Each feature is ranked by various feature selection algorithms, and the ranking information is visualized in each of the three views within the system. On the left, the Feature View provides a way to visualize an overview of all features according to their rank using a variety of layouts. On the top-right, the List View provides a sorted list of all features, useful for selections. On the bottom-right, the Classi\ufb01er View provides access to the quality scores of each model. Each of the views are coordinated, and users can brush between all three views.","img_size":{"width":2157,"height":670},"subfigures":[{"x":66.45938116959263,"y":11.2913432144783,"width":2020.94785975187,"height":648.9850461785984,"type":"interface","id":"interface-0"}],"visualizations":[{"x":1703.1860166773572,"y":505.87203335471446,"width":380.4842847979471,"height":135.590763309814,"type":"bar_chart","id":"bar_chart-0"},{"x":62.26106478511867,"y":17.46856959589479,"width":1627.0891597177676,"height":599.0898011545861,"type":"glyph_based","id":"glyph_based-1"}],"relations":[{"vislist":[{"vislist":["glyph_based-1"],"relation":null,"id":"group-0"}],"relation":"repeated","id":"relation-0"},{"vislist":[{"vislist":["bar_chart-0"],"relation":null,"id":"group-1"}],"relation":"repeated","id":"relation-1"}]},"2542_0":{"comp":[["comb","comb",["repeated"]],["scatterplot","heatmap",["accompanied"]],["heatmap","scatterplot",["accompanied"]],["bar_chart","stripe_graph",["stacked"]],["stripe_graph","bar_chart",["stacked"]]],"visType":["comb","scatterplot","heatmap","bar_chart","stripe_graph"],"compType":["repeated","accompanied","stacked"],"compressed_tree":[{"composite_pattern":"repeated","visualization_type":[[{"composite_pattern":"stacked","visualization_type":[["bar_chart","stripe_graph"]]}]]},{"composite_pattern":"accompanied","visualization_type":[["scatterplot","heatmap"]]}],"coOccurrence":[["bar_chart","stripe_graph",["coOccurrence"]],["bar_chart","scatterplot",["coOccurrence"]],["bar_chart","heatmap",["coOccurrence"]],["stripe_graph","scatterplot",["coOccurrence"]],["stripe_graph","heatmap",["coOccurrence"]],["scatterplot","heatmap",["coOccurrence"]]],"year":2014,"conference":["VAST"],"authors":["Charles D. Stolper","Adam Perer","David Gotz"],"title":"Progressive Visual Analytics: User-Driven Visual Exploration of In-Progress Analytics","doi":"10.1109/TVCG.2014.2346574","abstract":"As datasets grow and analytic algorithms become more complex, the typical workflow of analysts launching an analytic, waiting for it to complete, inspecting the results, and then re-Iaunching the computation with adjusted parameters is not realistic for many real-world tasks. This paper presents an alternative workflow, progressive visual analytics, which enables an analyst to inspect partial results of an algorithm as they become available and interact with the algorithm to prioritize subspaces of interest. Progressive visual analytics depends on adapting analytical algorithms to produce meaningful partial results and enable analyst intervention without sacrificing computational speed. The paradigm also depends on adapting information visualization techniques to incorporate the constantly refining results without overwhelming analysts and provide interactions to support an analyst directing the analytic. The contributions of this paper include: a description of the progressive visual analytics paradigm; design goals for both the algorithms and visualizations in progressive visual analytics systems; an example progressive visual analytics system (Progressive Insights) for analyzing common patterns in a collection of event sequences; and an evaluation of Progressive Insights and the progressive visual analytics paradigm by clinical researchers analyzing electronic medical records.","keywords":"Progressive visual analytics, information visualization, interactive machine learning, electronic medical records","caption":"Fig. 1. The Progressive Insights system features progressive visual analytics, and supports user-driven exploration of in-progress analytics. Partial results from the progressive analytics enhance the scatterplot, list, and tree visualizations without interfering with users\u2019 cognitive work\ufb02ow.","img_size":{"width":1333,"height":918},"subfigures":[{"x":25.114706898230093,"y":30.37756111810794,"width":1263.9606525915399,"height":854.7370769000195,"type":"interface","id":"interface-0"}],"visualizations":[{"x":29.594694360392452,"y":153.70332138397904,"width":919.2678134036253,"height":354.5960123015605,"type":"scatterplot","id":"scatterplot-0"},{"x":971.2109959342843,"y":153.70332138397904,"width":317.3485320177831,"height":566.1617003134158,"type":"bar_chart","id":"bar_chart-1"},{"x":28.104795149041365,"y":555.9761084487745,"width":403.7626862761466,"height":184.74750220753572,"type":"bar_chart","id":"bar_chart-2"},{"x":501.89274435868936,"y":558.9559068714767,"width":402.2727870647956,"height":178.78790536213126,"type":"bar_chart","id":"bar_chart-3"},{"x":916.1447735815033,"y":561.0431738670151,"width":48.94014173389122,"height":176.99827454860193,"type":"stripe_graph","id":"stripe_graph-4"},{"x":435.78384252320177,"y":555.9761084487731,"width":58.59859505516258,"height":184.74750220753546,"type":"stripe_graph","id":"stripe_graph-6"},{"x":29.59469436039251,"y":153.70332138397904,"width":919.2678134036253,"height":356.0859115129116,"type":"heatmap","id":"heatmap-8"}],"relations":[{"vislist":[{"vislist":[{"vislist":[{"vislist":["bar_chart-2","stripe_graph-6"],"relation":null,"id":"group-0"}],"relation":"stacked","id":"relation-0"},{"vislist":[{"vislist":["bar_chart-3","stripe_graph-4"],"relation":null,"id":"group-1"}],"relation":"stacked","id":"relation-1"}],"relation":null,"id":"group-2"}],"relation":"repeated","id":"relation-2"},{"vislist":[{"vislist":["scatterplot-0","heatmap-8"],"relation":null,"id":"group-3"}],"relation":"accompanied","id":"relation-3"}]},"2546_7":{"comp":[["comb","comb",["repeated"]],["bar_chart","scatterplot",["stacked"]],["scatterplot","bar_chart",["stacked"]]],"visType":["comb","bar_chart","scatterplot"],"compType":["repeated","stacked"],"compressed_tree":[{"composite_pattern":"repeated","visualization_type":[[{"composite_pattern":"stacked","visualization_type":[["bar_chart","scatterplot"]]}]]}],"coOccurrence":[["bar_chart","scatterplot",["coOccurrence"]]],"year":2014,"conference":["VAST"],"authors":["Haidong Chen","Wei Che","Honghui Mei","Zhiqi Liu","Kun Zhou","Weifeng Che","Wentao Gu","Kwan-Liu Ma"],"title":"Visual Abstraction and Exploration of Multi-class Scatterplots","doi":"10.1109/TVCG.2014.2346594","abstract":"Scatterplots are widely used to visualize scatter dataset for exploring outliers, clusters, local trends, and correlations. Depicting multi-class scattered points within a single scatterplot view, however, may suffer from heavy overdraw, making it inefficient for data analysis. This paper presents a new visual abstraction scheme that employs a hierarchical multi-class sampling technique to show a feature-preserving simplification. To enhance the density contrast, the colors of multiple classes are optimized by taking the multi-class point distributions into account. We design a visual exploration system that supports visual inspection and quantitative analysis from different perspectives. We have applied our system to several challenging datasets, and the results demonstrate the efficiency of our approach.","keywords":"Scatterplot, overdraw reduction, sampling, visual abstraction","caption":"Fig. 8. The main interface of our exploration system.","img_size":{"width":2087,"height":1149},"subfigures":[{"x":27.782467774273556,"y":27.254941837558313,"width":2018.875699927226,"height":1105.4760871022538,"type":"interface","id":"interface-0"}],"visualizations":[{"x":1595.7060513928259,"y":69.50421595832464,"width":424.7324544876429,"height":822.8435543463551,"type":"bar_chart","id":"bar_chart-2"},{"x":1597.6345432613866,"y":68.8208832374503,"width":422.2640611323947,"height":827.182493519976,"type":"scatterplot","id":"scatterplot-10"},{"x":437.0366032210835,"y":148.04099560761347,"width":1118.718887262079,"height":809.1786237188873,"type":"scatterplot","id":"scatterplot-3"}],"relations":[{"vislist":[{"vislist":[{"vislist":[{"vislist":["bar_chart-2","scatterplot-10"],"relation":null,"id":"group-4"}],"relation":"stacked","id":"relation-4"}],"relation":null,"id":"group-5"}],"relation":"repeated","id":"relation-5"}]},"2548_5":{"comp":[["bar_chart","bar_chart",["repeated"]],["bar_chart","donut_chart",["nested"]],["bar_chart","box_plot",["large_view"]],["chord_diagram","donut_chart",["nested"]]],"visType":["bar_chart","donut_chart","box_plot","chord_diagram"],"compType":["repeated","nested","large_view"],"compressed_tree":[{"composite_pattern":"repeated","visualization_type":[["bar_chart"]]},{"composite_pattern":"large_view","visualization_type":[["bar_chart"],["box_plot"]]},{"composite_pattern":"nested","visualization_type":[["bar_chart"],["donut_chart"]]},{"composite_pattern":"nested","visualization_type":[["chord_diagram"],["donut_chart"]]}],"coOccurrence":[["bar_chart","box_plot",["coOccurrence"]],["bar_chart","donut_chart",["coOccurrence"]],["bar_chart","chord_diagram",["coOccurrence"]],["box_plot","donut_chart",["coOccurrence"]],["box_plot","chord_diagram",["coOccurrence"]],["donut_chart","chord_diagram",["coOccurrence"]]],"year":2014,"conference":["VAST"],"authors":["Bilal Alsallakh","Allan Hanbury","Helwig Hauser","Silvia Miksch","Andreas Rauber"],"title":"Visual Methods for Analyzing Probabilistic Classification Data","doi":"10.1109/TVCG.2014.2346660","abstract":"Multi-class classifiers often compute scores for the classification samples describing probabilities to belong to different classes. In order to improve the performance of such classifiers, machine learning experts need to analyze classification results for a large number of labeled samples to find possible reasons for incorrect classification. Confusion matrices are widely used for this purpose. However, they provide no information about classification scores and features computed for the samples. We propose a set of integrated visual methods for analyzing the performance of probabilistic classifiers. Our methods provide insight into different aspects of the classification results for a large number of samples. One visualization emphasizes at which probabilities these samples were classified and how these probabilities correlate with classification error in terms of false positives and false negatives. Another view emphasizes the features of these samples and ranks them by their separation power between selected true and false classifications. We demonstrate the insight gained using our technique in a benchmarking classification dataset, and show how it enables improving classification performance by interactively defining and evaluating post-classification rules.","keywords":"Probabilistic classification, confusion analysis, feature evaluation and selection, visual inspection","caption":"Fig. 5. The interactive exploration environment showing information about classi\ufb01cation results, class probabilities, and feature distributions. The summary charts show breakdowns of the samples by (a) actual class, (b) predicted class, (c) classi\ufb01cation correctness, (d) the probability of the predict class, (e) the probability rank of the actual class. The wheel view (f) shows the same data as in Fig. ??b, classi\ufb01ed using a k-NN classi\ufb01er. Selected samples are highlighted in color. The feature analysis view (g) shows summary information data features of the selected samples, broken down according to their classi\ufb01cation results, and the selection criteria in natural text. (h) A control panel to rank the features according to their separation power along with a recall-precision curve for possible separation. (i) A histogram of the top ranked feature.","img_size":{"width":2151,"height":1062},"subfigures":[{"x":7.287458527561375,"y":9.859804562244928,"width":2134.8627519568986,"height":1039.1550872334337,"type":"interface","id":"interface-0"}],"visualizations":[{"x":1841.2906295754024,"y":273.6632503660322,"width":242.56515373352886,"height":205.24743777452412,"type":"bar_chart","id":"bar_chart-0"},{"x":22.0519765739385,"y":37.31771595900438,"width":255.00439238653001,"height":242.56515373352855,"type":"bar_chart","id":"bar_chart-1"},{"x":20.497071742313324,"y":315.6456808199121,"width":255.00439238652996,"height":244.12005856515367,"type":"bar_chart","id":"bar_chart-2"},{"x":22.0519765739385,"y":562.8755490483161,"width":259.66910688140547,"height":101.06881405563684,"type":"bar_chart","id":"bar_chart-3"},{"x":14.277452415812602,"y":663.944363103953,"width":265.8887262079063,"height":199.02781844802337,"type":"bar_chart","id":"bar_chart-4"},{"x":31.381405563689615,"y":883.1859443631037,"width":241.01024890190334,"height":171.03953147877021,"type":"bar_chart","id":"bar_chart-5"},{"x":311.2642752562225,"y":41.98243045387993,"width":1149.0746705710098,"height":985.8096632503657,"type":"bar_chart","id":"bar_chart-6"},{"x":1492.9919472913614,"y":217.68667642752555,"width":651.505124450952,"height":836.5387994143483,"type":"box_plot","id":"box_plot-7"},{"x":308.15446559297226,"y":43.537335285505115,"width":1156.8491947291361,"height":985.8096632503657,"type":"chord_diagram","id":"chord_diagram-8"},{"x":312.81918008784777,"y":43.537335285505115,"width":1149.0746705710098,"height":984.2547584187406,"type":"donut_chart","id":"donut_chart-9"},{"x":1849.065153733528,"y":82.40995607613469,"width":275.2181551976575,"height":132.16691068814052,"type":"line_chart","id":"line_chart-10"}],"relations":[{"vislist":[{"vislist":["bar_chart-1","bar_chart-2","bar_chart-3","bar_chart-4","bar_chart-5"],"relation":null,"id":"group-1"}],"relation":"repeated","id":"relation-0"},{"vislist":[{"vislist":["bar_chart-0"],"relation":null,"id":"group-2"},{"vislist":["box_plot-7"],"relation":null,"id":"group-3"}],"relation":"large_view","id":"relation-1"},{"vislist":[{"vislist":["bar_chart-6"],"relation":null,"id":"group-8"},{"vislist":["donut_chart-9"],"relation":null,"id":"group-9"}],"relation":"nested","id":"relation-2"},{"vislist":[{"vislist":["chord_diagram-8"],"relation":null,"id":"group-6"},{"vislist":["donut_chart-9"],"relation":null,"id":"group-7"}],"relation":"nested","id":"relation-3"}]},"2548_6":{"comp":[["table","table",["repeated"]]],"visType":["table"],"compType":["repeated"],"compressed_tree":[{"composite_pattern":"repeated","visualization_type":[["table"]]}],"coOccurrence":[["table","table",["coOccurrence"]]],"year":2014,"conference":["VAST"],"authors":["Bilal Alsallakh","Allan Hanbury","Helwig Hauser","Silvia Miksch","Andreas Rauber"],"title":"Visual Methods for Analyzing Probabilistic Classification Data","doi":"10.1109/TVCG.2014.2346660","abstract":"Multi-class classifiers often compute scores for the classification samples describing probabilities to belong to different classes. In order to improve the performance of such classifiers, machine learning experts need to analyze classification results for a large number of labeled samples to find possible reasons for incorrect classification. Confusion matrices are widely used for this purpose. However, they provide no information about classification scores and features computed for the samples. We propose a set of integrated visual methods for analyzing the performance of probabilistic classifiers. Our methods provide insight into different aspects of the classification results for a large number of samples. One visualization emphasizes at which probabilities these samples were classified and how these probabilities correlate with classification error in terms of false positives and false negatives. Another view emphasizes the features of these samples and ranks them by their separation power between selected true and false classifications. We demonstrate the insight gained using our technique in a benchmarking classification dataset, and show how it enables improving classification performance by interactively defining and evaluating post-classification rules.","keywords":"Probabilistic classification, confusion analysis, feature evaluation and selection, visual inspection","caption":"Fig. 6. Obtaining details about elements interactively: (a) selecting samples confused between c2 and c7 . The list view show their (b) fea- tures and (c) class probabilities. One sample is selected for inspection by showing its graphical representation (d). Its class probabilities are highlighted both in the list view, and in the wheel view using arrows.","img_size":{"width":1065,"height":497},"subfigures":[{"x":574.5407044502603,"y":17.638715076819693,"width":475.9608652002193,"height":471.0109101291568,"type":"single","id":"single-0"}],"visualizations":[{"x":14.03367496339682,"y":6.549048316251831,"width":470.80380673499263,"height":488.1027781879021,"type":"bar_chart","id":"bar_chart-0"},{"x":15.489019033674998,"y":5.821376281112738,"width":468.6207906295755,"height":488.8304502230413,"type":"chord_diagram","id":"chord_diagram-1"},{"x":11.850658857979546,"y":2.3481734958460483,"width":472.2591508052709,"height":492.30365300830795,"type":"donut_chart","id":"donut_chart-2"},{"x":574.5270270886643,"y":72.76720351390924,"width":467.89311859443615,"height":198.6544655929722,"type":"table","id":"table-3"},{"x":575.0688140556371,"y":301.25622254758423,"width":465.71010248901877,"height":189.92240117130308,"type":"table","id":"table-4"}],"relations":[{"vislist":[{"vislist":["table-3","table-4"],"relation":null,"id":"group-0"}],"relation":"repeated","id":"relation-0"}]},"2550_1":{"comp":[["bar_chart","bar_chart",["repeated"]]],"visType":["bar_chart"],"compType":["repeated"],"compressed_tree":[{"composite_pattern":"repeated","visualization_type":[["bar_chart"]]},{"composite_pattern":"repeated","visualization_type":[["bar_chart"]]}],"coOccurrence":[["bar_chart","bar_chart",["coOccurrence"]]],"year":2014,"conference":["VAST"],"authors":["Steffen Koch","Markus John","Michael W\xf6rne","Andreas M\xfclle","Thomas Ertl"],"title":"VarifocalReader -- In-Depth Visual Analysis of Large Text Documents","doi":"10.1109/TVCG.2014.2346677","abstract":"Interactive visualization provides valuable support for exploring, analyzing, and understanding textual documents. Certain tasks, however, require that insights derived from visual abstractions are verified by a human expert perusing the source text. So far, this problem is typically solved by offering overview-detail techniques, which present different views with different levels of abstractions. This often leads to problems with visual continuity. Focus-context techniques, on the other hand, succeed in accentuating interesting subsections of large text documents but are normally not suited for integrating visual abstractions. With VarifocalReader we present a technique that helps to solve some of these approaches\' problems by combining characteristics from both. In particular, our method simplifies working with large and potentially complex text documents by simultaneously offering abstract representations of varying detail, based on the inherent structure of the document, and access to the text itself. In addition, VarifocalReader supports intra-document exploration through advanced navigation concepts and facilitates visual analysis tasks. The approach enables users to apply machine learning techniques and search mechanisms as well as to assess and adapt these techniques. This helps to extract entities, concepts and other artifacts from texts. In combination with the automatic generation of intermediate text levels through topic segmentation for thematic orientation, users can test hypotheses or develop interesting new research questions. To illustrate the advantages of our approach, we provide usage examples from literature studies.","keywords":"visual analytics, document analysis, literary analysis, natural language processing, text mining, machine learning, distant reading","caption":"Fig. 2. Emil Staiger\u2019s \u201cGrundbegriffe der Poetik\u201d divided (from left to right) into layers showing chapters, subchapters (with word clouds), pages (with bar charts), lines of text, and scanned images of the actual pages.","img_size":{"width":2154,"height":1227},"subfigures":[{"x":4.627731269553791,"y":22.48997056527812,"width":2126.309317410674,"height":1197.1037434764942,"type":"interface","id":"interface-0"}],"visualizations":[{"x":4.748677248677248,"y":49.50962243736751,"width":152.30728679947563,"height":82.12256147067848,"type":"bar_chart","id":"bar_chart-0"},{"x":6.313218390804593,"y":456.0114942528736,"width":73.30143156861311,"height":71.20366178133212,"type":"bar_chart","id":"bar_chart-1"},{"x":6.313218390804593,"y":754.5344827586206,"width":75.21839080459768,"height":51.71264367816093,"type":"bar_chart","id":"bar_chart-2"},{"x":4.748677248677248,"y":1078.9137931034484,"width":32.908045977011454,"height":47.01149425287349,"type":"bar_chart","id":"bar_chart-3"},{"x":194.35919540229887,"y":61.11494252873563,"width":71.2098097765122,"height":1156.2966955684637,"type":"bar_chart","id":"bar_chart-4"},{"x":631.357892793346,"y":58.39485757965013,"width":51.718076847169144,"height":1157.6948049645362,"type":"bar_chart","id":"bar_chart-5"},{"x":750.4644920476435,"y":58.403364001487276,"width":58.53662437032211,"height":1163.3759345357262,"type":"bar_chart","id":"bar_chart-6"}],"relations":[{"vislist":[{"vislist":["bar_chart-0","bar_chart-1","bar_chart-2","bar_chart-3"],"relation":null,"id":"group-0"}],"relation":"repeated","id":"relation-0"},{"vislist":[{"vislist":["bar_chart-5"],"relation":null,"id":"group-1"}],"relation":"repeated","id":"relation-1"}]},"2553_8":{"comp":[["bar_chart","bar_chart",["repeated"]],["line_chart","line_chart",["repeated"]],["scatterplot","scatterplot",["repeated"]]],"visType":["bar_chart","line_chart","scatterplot"],"compType":["repeated"],"compressed_tree":[{"composite_pattern":"repeated","visualization_type":[["bar_chart"]]},{"composite_pattern":"repeated","visualization_type":[["bar_chart"]]},{"composite_pattern":"repeated","visualization_type":[["line_chart"]]},{"composite_pattern":"repeated","visualization_type":[["scatterplot"]]}],"coOccurrence":[["bar_chart","line_chart",["coOccurrence"]],["bar_chart","scatterplot",["coOccurrence"]],["line_chart","scatterplot",["coOccurrence"]]],"year":2014,"conference":["VAST"],"authors":["Kresimir Matkovic","Denis Gracanin","Rainer Splechtna","Mario Jelovic","Benedikt Stehno","Helwig Hauser","Werner Purgathofer"],"title":"Visual Analytics for Complex Engineering Systems: Hybrid Visual Steering of Simulation Ensembles","doi":"10.1109/TVCG.2014.2346744","abstract":"In this paper we propose a novel approach to hybrid visual steering of simulation ensembles. A simulation ensemble is a collection of simulation runs of the same simulation model using different sets of control parameters. Complex engineering systems have very large parameter spaces so a na\xefve sampling can result in prohibitively large simulation ensembles. Interactive steering of simulation ensembles provides the means to select relevant points in a multi-dimensional parameter space (design of experiment). Interactive steering efficiently reduces the number of simulation runs needed by coupling simulation and visualization and allowing a user to request new simulations on the fly. As system complexity grows, a pure interactive solution is not always sufficient. The new approach of hybrid steering combines interactive visual steering with automatic optimization. Hybrid steering allows a domain expert to interactively (in a visualization) select data points in an iterative manner, approximate the values in a continuous region of the simulation space (by regression) and automatically find the \u201cbest\u201d points in this continuous region based on the specified constraints and objectives (by optimization). We argue that with the full spectrum of optimization options, the steering process can be improved substantially. We describe an integrated system consisting of a simulation, a visualization, and an optimization component. We also describe typical tasks and propose an interactive analysis workflow for complex engineering systems. We demonstrate our approach on a case study from automotive industry, the optimization of a hydraulic circuit in a high pressure common rail Diesel injection system.","keywords":"Interactive Visual Analysis, Integrated Design Environment, Simulation, Visual Steering, Automatic Optimization","caption":"Figure 7. The initial view con\ufb01guration (more than 2700 records). The Parameters Exploration View is shown in the upper left corner. The other views depict selected state parameters studied during the analysis.","img_size":{"width":2154,"height":884},"subfigures":[{"x":108.28150671051964,"y":24.41855566667498,"width":1917.0983569530329,"height":849.2406118739999,"type":"interface","id":"interface-0"}],"visualizations":[{"x":121.58563181526618,"y":587.7645926876203,"width":274.94932649134057,"height":273.5676715843489,"type":"bar_chart","id":"bar_chart-0"},{"x":433.8396407953817,"y":590.5279025016035,"width":256.98781270044896,"height":277.71263630532394,"type":"bar_chart","id":"bar_chart-1"},{"x":135.40218088518282,"y":459.27068633739566,"width":537.4637588197562,"height":71.84605516356639,"type":"bar_chart","id":"bar_chart-2"},{"x":131.25721616420785,"y":376.371391917896,"width":540.2270686337395,"height":74.60936497754972,"type":"bar_chart","id":"bar_chart-3"},{"x":135.40218088518282,"y":289.3271327774213,"width":537.4637588197562,"height":77.37267479153303,"type":"bar_chart","id":"bar_chart-4"},{"x":138.16549069916616,"y":202.2828736369467,"width":529.1738293778062,"height":78.7543296985247,"type":"bar_chart","id":"bar_chart-5"},{"x":134.02052597819113,"y":122.14688903143038,"width":537.4637588197562,"height":78.7543296985247,"type":"bar_chart","id":"bar_chart-6"},{"x":132.63887107119947,"y":37.86593970493904,"width":538.8454137267479,"height":84.28094932649134,"type":"bar_chart","id":"bar_chart-7"},{"x":722.6055163566389,"y":44.77421423989734,"width":298.43745991019875,"height":511.2123155869147,"type":"line_chart","id":"line_chart-8"},{"x":1059.7293136626042,"y":46.155869146889,"width":280.4759461193073,"height":511.2123155869147,"type":"line_chart","id":"line_chart-9"},{"x":1376.1282873636947,"y":46.155869146889,"width":326.0705580500321,"height":509.83066067992314,"type":"line_chart","id":"line_chart-10"},{"x":1736.7402180885185,"y":43.39255933290567,"width":288.7658755612572,"height":515.3572803078897,"type":"line_chart","id":"line_chart-11"},{"x":747.4753046824887,"y":596.0545221295703,"width":473.90763309813974,"height":251.46119307248225,"type":"parallel_coordinate","id":"parallel_coordinate-12"},{"x":1283.5574085952535,"y":593.2912123155868,"width":352.32200128287377,"height":272.18601667735726,"type":"scatterplot","id":"scatterplot-13"},{"x":1673.184092366902,"y":598.8178319435535,"width":349.5586914688904,"height":266.6593970493907,"type":"scatterplot","id":"scatterplot-14"}],"relations":[{"vislist":[{"vislist":["bar_chart-0","bar_chart-1"],"relation":null,"id":"group-0"}],"relation":"repeated","id":"relation-0"},{"vislist":[{"vislist":["bar_chart-2","bar_chart-3","bar_chart-4","bar_chart-5","bar_chart-6","bar_chart-7"],"relation":null,"id":"group-1"}],"relation":"repeated","id":"relation-1"},{"vislist":[{"vislist":["line_chart-8","line_chart-9","line_chart-10","line_chart-11"],"relation":null,"id":"group-2"}],"relation":"repeated","id":"relation-2"},{"vislist":[{"vislist":["scatterplot-14","scatterplot-13"],"relation":null,"id":"group-3"}],"relation":"repeated","id":"relation-3"}]},"2554_7":{"comp":[["matrix","matrix",["repeated"]]],"visType":["matrix"],"compType":["repeated"],"compressed_tree":[{"composite_pattern":"repeated","visualization_type":[["matrix"]]}],"coOccurrence":[["matrix","matrix",["coOccurrence"]]],"year":2014,"conference":["VAST"],"authors":["Zuchao Wang","Tangzhi Ye","Min Lu","Xiaoru Yuan","Huamin Qu","Jacky Yuan","Qianliang Wu"],"title":"Visual Exploration of Sparse Traffic Trajectory Data","doi":"10.1109/TVCG.2014.2346746","abstract":"In this paper, we present a visual analysis system to explore sparse traffic trajectory data recorded by transportation cells. Such data contains the movements of nearly all moving vehicles on the major roads of a city. Therefore it is very suitable for macro-traffic analysis. However, the vehicle movements are recorded only when they pass through the cells. The exact tracks between two consecutive cells are unknown. To deal with such uncertainties, we first design a local animation, showing the vehicle movements only in the vicinity of cells. Besides, we ignore the micro-behaviors of individual vehicles, and focus on the macro-traffic patterns. We apply existing trajectory aggregation techniques to the dataset, studying cell status pattern and inter-cell flow pattern. Beyond that, we propose to study the correlation between these two patterns with dynamic graph visualization techniques. It allows us to check how traffic congestion on one cell is correlated with traffic flows on neighbouring links, and with route selection in its neighbourhood. Case studies show the effectiveness of our system.","keywords":"Sparse Traffic Trajectory, Traffic Visualization, Dynamic Graph Visualization, Traffic Congestion","caption":"Fig. 8. (a) Pixel table view shows the temporal patterns of one cell, including traf\ufb01c speed, \ufb02ow volume, abnormality and congestion status in Dec. 2012. (b) Pixel table supports periodic \ufb01ltering. This table shows the traf\ufb01c status during the daytime of weekends. (c) Local animation view shows the traf\ufb01c animation at one cell.","img_size":{"width":1055,"height":726},"subfigures":[{"x":763.4646794592882,"y":479.3371695077164,"width":196.6134460844546,"height":203.65022956883618,"type":"single","id":"single-1"},{"x":112.69338179171838,"y":18.946049736959406,"width":868.2974640057581,"height":458.04585527255756,"type":"single","id":"single-0"}],"visualizations":[{"x":83.37694483734093,"y":8.214992927864214,"width":894.4073550212163,"height":468.25459688826027,"type":"heatmap","id":"heatmap-0"},{"x":108.02192362093353,"y":537.055162659123,"width":540.1357850070722,"height":121.1711456859972,"type":"heatmap","id":"heatmap-1"},{"x":764.1944837340877,"y":482.6308345120226,"width":193.052333804809,"height":195.1060820367751,"type":"heatmap","id":"heatmap-2"},{"x":84.40381895332393,"y":9.241867043847241,"width":892.3536067892503,"height":468.25459688826027,"type":"matrix","id":"matrix-3"},{"x":106.99504950495054,"y":538.0820367751061,"width":542.189533239038,"height":121.17114568599709,"type":"matrix","id":"matrix-4"},{"x":764.1944837340877,"y":481.60396039603955,"width":195.10608203677498,"height":195.10608203677515,"type":"matrix","id":"matrix-5"}],"relations":[{"vislist":[{"vislist":["matrix-3"],"relation":null,"id":"group-0"}],"relation":"repeated","id":"relation-0"}]},"2556_4":{"comp":[["map","map",["repeated"]],["bar_chart","matrix",["nested"]]],"visType":["map","bar_chart","matrix"],"compType":["repeated","nested"],"compressed_tree":[{"composite_pattern":"repeated","visualization_type":[["map"]]},{"composite_pattern":"nested","visualization_type":[["bar_chart"],["matrix"]]}],"coOccurrence":[],"year":2014,"conference":["VAST"],"authors":["Patrick K\xf6thur","Mike Sips","Henryk Dobslaw","Doris Dransch"],"title":"Visual Analytics for Comparison of Ocean Model Output with Reference Data: Detecting and Analyzing Geophysical Processes Using Clustering Ensembles","doi":"10.1109/TVCG.2014.2346751","abstract":"Researchers assess the quality of an ocean model by comparing its output to that of a previous model version or to observations. One objective of the comparison is to detect and to analyze differences and similarities between both data sets regarding geophysical processes, such as particular ocean currents. This task involves the analysis of thousands or hundreds of thousands of geographically referenced temporal profiles in the data. To cope with the amount of data, modelers combine aggregation of temporal profiles to single statistical values with visual comparison. Although this strategy is based on experience and a well-grounded body of expert knowledge, our discussions with domain experts have shown that it has two limitations: (1) using a single statistical measure results in a rather limited scope of the comparison and in significant loss of information, and (2) the decisions modelers have to make in the process may lead to important aspects being overlooked.","keywords":"Ocean modeling, model assessment, geospatial time series, cluster ensembles, visual comparison, visual analytics","caption":"Fig. 5. Comparison of a new version of the Ocean Model for Circulation and Tides (OMCT) \u2013 OMCTnew \u2013 with the current state-of-the-art OMCT version \u2013 OMCTcurrent .","img_size":{"width":2157,"height":2564},"subfigures":[{"x":8.180884626737557,"y":72.81795975952666,"width":1044.1009507251404,"height":894.9160328827187,"type":"single","id":"single-0"},{"x":1104.7181646481222,"y":101.5498856522939,"width":1044.100950725139,"height":746.3955161832663,"type":"single","id":"single-1"},{"x":305.00737194554017,"y":1134.5517924451888,"width":1525.9653721468453,"height":1145.9260141127693,"type":"single","id":"single-2"}],"visualizations":[{"x":336.1337110829369,"y":1934.9018924920017,"width":272.07088106787523,"height":344.47684135206777,"type":"box_plot","id":"box_plot-0"},{"x":625.7575522197072,"y":1932.7077724833896,"width":272.07088106787523,"height":353.2533213865153,"type":"box_plot","id":"box_plot-1"},{"x":924.1578733909253,"y":1937.0960125006138,"width":263.29440103342756,"height":335.70036131762004,"type":"box_plot","id":"box_plot-2"},{"x":335.5562958719967,"y":1172.1621829507062,"width":1476.6427657958066,"height":355.44744139512756,"type":"line_chart","id":"line_chart-6"},{"x":335.8085203550295,"y":1573.623145876301,"width":1477.7882821962003,"height":284.40453732832543,"type":"line_chart","id":"line_chart-7"},{"x":21.94505685668082,"y":93.58745318202494,"width":1020.075920258929,"height":870.8879431365514,"type":"map","id":"map-14"},{"x":333.93959107432505,"y":1932.7077724833896,"width":853.5126833500278,"height":335.7003613176202,"type":"small_multiple","id":"small_multiple-10"},{"x":1425.3249003076621,"y":118.36503211632738,"width":698.7466344794398,"height":734.2487729518366,"type":"bar_chart","id":"bar_chart-11"},{"x":333.93959107432505,"y":1932.7077724833896,"width":853.5126833500278,"height":335.7003613176202,"type":"small_multiple","id":"small_multiple-12"},{"x":1425.3249003076621,"y":118.36503211632738,"width":698.7466344794398,"height":734.2487729518366,"type":"matrix","id":"matrix-13"}],"relations":[{"vislist":[{"vislist":["map-14"],"relation":null,"id":"group-0"}],"relation":"repeated","id":"relation-0"},{"vislist":[{"vislist":["bar_chart-11"],"relation":null,"id":"group-1"},{"vislist":["matrix-13"],"relation":null,"id":"group-2"}],"relation":"nested","id":"relation-1"}]},"2558_0":{"comp":[["bar_chart","bar_chart",["repeated"]],["stripe_graph","comb",["stacked"]],["comb","stripe_graph",["stacked"]]],"visType":["bar_chart","stripe_graph","comb"],"compType":["repeated","stacked"],"compressed_tree":[{"composite_pattern":"stacked","visualization_type":[["stripe_graph",{"composite_pattern":"repeated","visualization_type":[["bar_chart"]]}]]}],"coOccurrence":[["bar_chart","stripe_graph",["coOccurrence"]]],"year":2014,"conference":["VAST"],"authors":["Bowen Yu","Harish Doraiswamy","Xi Chen","Emily R. Miraldi","Mario Luis Arrieta-Ortiz","Christoph Hafemeister","Aviv Madar","Richard Bonneau","Cl\xe1udio T. Silva"],"title":"Genotet: An Interactive Web-based Visual Exploration Framework to Support Validation of Gene Regulatory Networks","doi":"10.1109/TVCG.2014.2346753","abstract":"Elucidation of transcriptional regulatory networks (TRNs) is a fundamental goal in biology, and one of the most important components of TRNs are transcription factors (TFs), proteins that specifically bind to gene promoter and enhancer regions to alter target gene expression patterns. Advances in genomic technologies as well as advances in computational biology have led to multiple large regulatory network models (directed networks) each with a large corpus of supporting data and gene-annotation. There are multiple possible biological motivations for exploring large regulatory network models, including: validating TF-target gene relationships, figuring out co-regulation patterns, and exploring the coordination of cell processes in response to changes in cell state or environment. Here we focus on queries aimed at validating regulatory network models, and on coordinating visualization of primary data and directed weighted gene regulatory networks. The large size of both the network models and the primary data can make such coordinated queries cumbersome with existing tools and, in particular, inhibits the sharing of results between collaborators. In this work, we develop and demonstrate a web-based framework for coordinating visualization and exploration of expression data (RNA-seq, microarray), network models and gene-binding data (ChIP-seq). Using specialized data structures and multiple coordinated views, we design an efficient querying model to support interactive analysis of the data. Finally, we show the effectiveness of our framework through case studies for the mouse immune system (a dataset focused on a subset of key cellular functions) and a model bacteria (a small genome with high data-completeness).","keywords":"Web-based visualization, gene regulatory network","caption":"Fig. 1. An overview of Genotet interface. Genotet supports multiple views, where each view presents a different visualization metaphor for different types of gene regulation data. A powerful visual query interface achieved through dynamic linking / grouping of views enables an integrated visualization environment which signi\ufb01cantly reduces the overhead involved during the analysis of this data.","img_size":{"width":1732,"height":961},"subfigures":[{"x":12.29192869293066,"y":16.28090562459128,"width":1702.16669934824,"height":933.6887260712468,"type":"interface","id":"interface-0"}],"visualizations":[{"x":13.551495016611456,"y":526.7940199335549,"width":1553.244186046512,"height":386.3156146179402,"type":"bar_chart","id":"bar_chart-0"},{"x":13.551495016611455,"y":907.5935251217845,"width":1553.2441860465115,"height":31.34057626901049,"type":"stripe_graph","id":"stripe_graph-1"},{"x":8.762458471760965,"y":76.62458471760796,"width":774.2275747508306,"height":405.47176079734214,"type":"graph","id":"graph-2"},{"x":789.3754152823922,"y":228.27740863787378,"width":767.8421926910299,"height":250.62624584717608,"type":"stripe_graph","id":"stripe_graph-4"},{"x":789.3754152823922,"y":228.27740863787378,"width":767.8421926910299,"height":250.62624584717608,"type":"heatmap","id":"heatmap-5"},{"x":782.9900332225915,"y":83.00996677740864,"width":782.2093023255813,"height":145.26744186046514,"type":"line_chart","id":"line_chart-6"}],"relations":[{"vislist":[{"vislist":["stripe_graph-1",{"vislist":[{"vislist":["bar_chart-0"],"relation":null,"id":"group-0"}],"relation":"repeated","id":"relation-0"}],"relation":null,"id":"group-1"}],"relation":"stacked","id":"relation-1"}]},"2559_2":{"comp":[["scatterplot","scatterplot",["repeated"]]],"visType":["scatterplot"],"compType":["repeated"],"compressed_tree":[{"composite_pattern":"repeated","visualization_type":[["scatterplot"]]},{"composite_pattern":"repeated","visualization_type":[["scatterplot"]]},{"composite_pattern":"repeated","visualization_type":[["scatterplot"]]},{"composite_pattern":"repeated","visualization_type":[["scatterplot"]]}],"coOccurrence":[["scatterplot","scatterplot",["coOccurrence"]]],"year":2014,"conference":["VAST"],"authors":["Maria Luj\xe1n Ganuza","Gabriela Ferracutti","Maria Florencia Gargiulo","Silvia Mabel Castro","Ernesto A. Bjerg","M. Eduard Gr\xf6ller","Kresimir Matkovic"],"title":"The Spinel Explorer - Interactive Visual Analysis of Spinel Group Minerals","doi":"10.1109/TVCG.2014.2346754","abstract":"Geologists usually deal with rocks that are up to several thousand million years old. They try to reconstruct the tectonic settings where these rocks were formed and the history of events that affected them through the geological time. The spinel group minerals provide useful information regarding the geological environment in which the host rocks were formed. They constitute excellent indicators of geological environments (tectonic settings) and are of invaluable help in the search for mineral deposits of economic interest. The current workflow requires the scientists to work with different applications to analyze spine data. They do use specific diagrams, but these are usually not interactive. The current workflow hinders domain experts to fully exploit the potentials of tediously and expensively collected data. In this paper, we introduce the Spinel Explorer-an interactive visual analysis application for spinel group minerals. The design of the Spinel Explorer and of the newly introduced interactions is a result of a careful study of geologists\' tasks. The Spinel Explorer includes most of the diagrams commonly used for analyzing spinel group minerals, including 2D binary plots, ternary plots, and 3D Spinel prism plots. Besides specific plots, conventional information visualization views are also integrated in the Spinel Explorer. All views are interactive and linked. The Spinel Explorer supports conventional statistics commonly used in spinel minerals exploration. The statistics views and different data derivation techniques are fully integrated in the system. Besides the Spinel Explorer as newly proposed interactive exploration system, we also describe the identified analysis tasks, and propose a new workflow. We evaluate the Spinel Explorer using real-life data from two locations in Argentina: the Frontal Cordillera in Central Andes and Patagonia. We describe the new findings of the geologists which would have been much more difficult to achieve using the current workflow only. Very positive feedback from geologists confirms the usefulness of the Spinel Explorer.","keywords":"Interactive visual analysis, visualization in earth/space/ and environmental sciences, coordinated and multiple views, design studies","caption":"Fig. 3. A screenshot from an analysis session where Spinel prisms, triangle plots, parallel coordinates, scatterplots, and box-plot views for statistics were used. Two composite brushes are active (red and green). The data pane on the left can be used for \ufb01ltering, all details are shown on demand in a table.","img_size":{"width":1912,"height":2699},"subfigures":[{"x":62.97554569905069,"y":49.38886779917201,"width":1826.5576229637159,"height":2618.655147112162,"type":"interface","id":"interface-0"}],"visualizations":[{"x":1447.3582399745426,"y":1484.4344532335008,"width":274.66492367020095,"height":1159.6001555895123,"type":"box_plot","id":"box_plot-0"},{"x":881.8922581064495,"y":1500.584308380099,"width":434.7984579736153,"height":1115.834818166982,"type":"parallel_coordinate","id":"parallel_coordinate-1"},{"x":387.0107196447104,"y":1920.0683219223768,"width":417.24992585541844,"height":735.5961655821451,"type":"scatterplot","id":"scatterplot-2"},{"x":399.37368041079685,"y":1128.8388328928427,"width":401.7962248978106,"height":729.4146851991022,"type":"scatterplot","id":"scatterplot-3"},{"x":400.0334575117687,"y":336.39182443962636,"width":403.2440171679572,"height":743.6448108811682,"type":"scatterplot","id":"scatterplot-4"},{"x":900.1607775057935,"y":393.9981126064774,"width":369.2039377966363,"height":421.5732906755917,"type":"scatterplot","id":"scatterplot-5"},{"x":902.7792451497413,"y":967.4425266310401,"width":361.34853486479307,"height":398.0070818800617,"type":"scatterplot","id":"scatterplot-6"},{"x":1368.4584666646915,"y":366.92259842928104,"width":189.47342660442837,"height":449.0042546424269,"type":"scatterplot","id":"scatterplot-7"},{"x":1594.5528076548499,"y":406.72794015290043,"width":95.5328201366865,"height":347.10257982996126,"type":"scatterplot","id":"scatterplot-8"},{"x":1594.538331513557,"y":955.8472437128572,"width":91.42411375796928,"height":346.2688308583092,"type":"scatterplot","id":"scatterplot-9"},{"x":1368.464130965434,"y":917.7447225200085,"width":186.15090263592853,"height":466.7261761741392,"type":"scatterplot","id":"scatterplot-10"},{"x":114.41395561574905,"y":265.4934230367063,"width":147.41220136078744,"height":2414.5093029167633,"type":"table","id":"table-11"}],"relations":[{"vislist":[{"vislist":["scatterplot-2","scatterplot-3","scatterplot-4"],"relation":null,"id":"group-0"}],"relation":"repeated","id":"relation-0"},{"vislist":[{"vislist":["scatterplot-6","scatterplot-5"],"relation":null,"id":"group-1"}],"relation":"repeated","id":"relation-1"},{"vislist":[{"vislist":["scatterplot-7","scatterplot-10"],"relation":null,"id":"group-2"}],"relation":"repeated","id":"relation-2"},{"vislist":[{"vislist":["scatterplot-8","scatterplot-9"],"relation":null,"id":"group-3"}],"relation":"repeated","id":"relation-3"}]},"2563_1":{"comp":[["bar_chart","bar_chart",["repeated"]],["contour_graph","map",["coordinated"]]],"visType":["bar_chart","contour_graph","map"],"compType":["repeated","coordinated"],"compressed_tree":[{"composite_pattern":"repeated","visualization_type":[["bar_chart"]]},{"composite_pattern":"coordinated","visualization_type":[["contour_graph"],["map"]]}],"coOccurrence":[["bar_chart","contour_graph",["coOccurrence"]],["bar_chart","map",["coOccurrence"]],["contour_graph","map",["coOccurrence"]]],"year":2014,"conference":["VAST"],"authors":["Sungahn Ko","Jieqiong Zhao","Jing Xia","Shehzad Afzal","Xiaoyu Wang","Greg Abram","Niklas Elmqvist","Len Kne","David Van Riper","Kelly P. Gaither","Shaun Kennedy","William J. Tolone","William Ribarsky","David S. Ebert"],"title":"VASA: Interactive Computational Steering of Large Asynchronous Simulation Pipelines for Societal Infrastructure","doi":"10.1109/TVCG.2014.2346911","abstract":"We present VASA, a visual analytics platform consisting of a desktop application, a component model, and a suite of distributed simulation components for modeling the impact of societal threats such as weather, food contamination, and traffic on critical infrastructure such as supply chains, road networks, and power grids. Each component encapsulates a high-fidelity simulation model that together form an asynchronous simulation pipeline: a system of systems of individual simulations with a common data and parameter exchange format. At the heart of VASA is the Workbench, a visual analytics application providing three distinct features: (1) low-fidelity approximations of the distributed simulation components using local simulation proxies to enable analysts to interactively configure a simulation run; (2) computational steering mechanisms to manage the execution of individual simulation components; and (3) spatiotemporal and interactive methods to explore the combined results of a simulation run. We showcase the utility of the platform using examples involving supply chains during a hurricane as well as food contamination in a fast food restaurant chain.","keywords":"Computational steering, visual analytics, critical infrastructure, homeland security","caption":"Fig. 2. Multiple coordinated views in the VASA Workbench. (a) Calendar view with available events (e.g., weather, food poisoning, cyberattack, etc). (b) Event timeline for con\ufb01guring events. (b-1) Event buttons. (b-2) Fixed event. (c) Map legend. (d) Geographical map. (d-1) Fixed Sandy estimation (red). (e) Pixel/schedule view showing food deliveries. Each area divided by a blue line means a route that visits 3\u20134 restaurants, 3 times a week. This view also can be used for pixel-based visualization.","img_size":{"width":1833,"height":1368},"subfigures":[{"x":6.846305058306564,"y":13.9127397344456,"width":1819.307389883385,"height":1342.0430780374434,"type":"interface","id":"interface-0"}],"visualizations":[{"x":377.6202263083452,"y":1261.5785007072136,"width":129.64073550212163,"height":92.87694483734096,"type":"bar_chart","id":"bar_chart-0"},{"x":511.13083451202266,"y":1269.3182461103254,"width":123.83592644978785,"height":83.20226308345106,"type":"bar_chart","id":"bar_chart-1"},{"x":644.6414427157001,"y":1267.383309759547,"width":129.64073550212174,"height":83.20226308345129,"type":"bar_chart","id":"bar_chart-2"},{"x":776.2171145685999,"y":1267.383309759547,"width":121.90099009900996,"height":85.13719943422916,"type":"bar_chart","id":"bar_chart-3"},{"x":898.1181046676097,"y":1269.3182461103254,"width":137.3804809052333,"height":83.20226308345106,"type":"bar_chart","id":"bar_chart-4"},{"x":1029.6937765205093,"y":1267.383309759547,"width":139.31541725601141,"height":89.00707213578515,"type":"bar_chart","id":"bar_chart-5"},{"x":1167.0742574257429,"y":1265.4483734087694,"width":178.0141442715699,"height":87.07213578500703,"type":"bar_chart","id":"bar_chart-6"},{"x":1345.0884016973127,"y":1309.951909476662,"width":131.5756718528999,"height":44.503536067892576,"type":"bar_chart","id":"bar_chart-7"},{"x":1397.8067321675576,"y":434.99275452963735,"width":430.636410321374,"height":755.5254784487965,"type":"contour_graph","id":"contour_graph-14"},{"x":395.03465346534654,"y":452.77510608203676,"width":884.2659123055162,"height":551.4568599717115,"type":"map","id":"map-8"},{"x":358.27086280056585,"y":361.8330975954738,"width":1464.7468175388965,"height":892.0056577086281,"type":"map","id":"map-9"},{"x":6.11244695898165,"y":19.349363507779348,"width":286.37057991513444,"height":1343.97850534468,"type":"table","id":"table-10"}],"relations":[{"vislist":[{"vislist":["bar_chart-0","bar_chart-1","bar_chart-2","bar_chart-3","bar_chart-4","bar_chart-5","bar_chart-6","bar_chart-7"],"relation":null,"id":"group-0"}],"relation":"repeated","id":"relation-0"},{"vislist":[{"vislist":["contour_graph-14"],"relation":null,"id":"group-5"},{"vislist":["map-9"],"relation":null,"id":"group-6"}],"relation":"coordinated","id":"relation-3"}]},"2565_0":{"comp":[["bar_chart","bar_chart",["repeated"]]],"visType":["bar_chart"],"compType":["repeated"],"compressed_tree":[{"composite_pattern":"repeated","visualization_type":[["bar_chart"]]}],"coOccurrence":[["bar_chart","bar_chart",["coOccurrence"]]],"year":2014,"conference":["VAST"],"authors":["Cong Xie","Wei Che","Xinxin Huang","Yueqi Hu","Scott Barlowe","Jing Yang"],"title":"VAET: A Visual Analytics Approach for E-Transactions Time-Series","doi":"10.1109/TVCG.2014.2346913","abstract":"Previous studies on E-transaction time-series have mainly focused on finding temporal trends of transaction behavior. Interesting transactions that are time-stamped and situation-relevant may easily be obscured in a large amount of information. This paper proposes a visual analytics system, Visual Analysis of E-transaction Time-Series (VAET), that allows the analysts to interactively explore large transaction datasets for insights about time-varying transactions. With a set of analyst-determined training samples, VAET automatically estimates the saliency of each transaction in a large time-series using a probabilistic decision tree learner. It provides an effective time-of-saliency (TOS) map where the analysts can explore a large number of transactions at different time granularities. Interesting transactions are further encoded with KnotLines, a compact visual representation that captures both the temporal variations and the contextual connection of transactions. The analysts can thus explore, select, and investigate knotlines of interest. A case study and user study with a real E-transactions dataset (26 million records) demonstrate the effectiveness of VAET.","keywords":"Time-Series, Visual Analytics, E-transaction","caption":"Fig. 1. The visual analysis interface of the VAET system. (a) The time-of-saliency (TOS) map overviews the saliency of each transaction computed with a probabilistic decision tree learner. (b) The KnotLines view shows the detailed information of transactions. The un\ufb01lled knots indicate fake transactions. (c) The legend of the sales category and the (d) bar chart shows the item volume of the selected transactions in TOS map. (e) Detailed transaction information and (f) statistical information are shown in auxiliary views.","img_size":{"width":1947,"height":1018},"subfigures":[{"x":19.202296160411738,"y":13.208415838820757,"width":1893.039646280043,"height":990.1689586351789,"type":"interface","id":"interface-0"}],"visualizations":[{"x":44.05304101838744,"y":21.598302687411593,"width":508.28005657708616,"height":305.25601131541725,"type":"bar_chart","id":"bar_chart-0"},{"x":31.09405940594047,"y":676.7468175388968,"width":819.2956152758132,"height":328.2942008486563,"type":"bar_chart","id":"bar_chart-1"},{"x":555.2128712871286,"y":397.40876944837345,"width":1352.053748231966,"height":604.752475247525,"type":"glyph_based","id":"glyph_based-2"},{"x":591.2100424328146,"y":21.598302687411593,"width":1101.5134370579913,"height":364.2913719943423,"type":"stripe_graph","id":"stripe_graph-3"},{"x":46.30987753016747,"y":334.9578254976634,"width":493.96693909652527,"height":330.9080888119076,"type":"table","id":"table-4"}],"relations":[{"vislist":[{"vislist":["bar_chart-1"],"relation":null,"id":"group-0"}],"relation":"repeated","id":"relation-0"}]},"2572_1":{"comp":[["area_chart","area_chart",["repeated"]],["stripe_graph","bar_chart",["accompanied"]],["bar_chart","stripe_graph",["accompanied"]]],"visType":["area_chart","stripe_graph","bar_chart"],"compType":["repeated","accompanied"],"compressed_tree":[{"composite_pattern":"accompanied","visualization_type":[["stripe_graph","bar_chart"]]},{"composite_pattern":"repeated","visualization_type":[["area_chart"]]}],"coOccurrence":[["area_chart","area_chart",["coOccurrence"]]],"year":2014,"conference":["VAST"],"authors":["Halld\xf3r Janetzko","Dominik Sacha","Manuel Stein","Tobias Schreck","Daniel A. Keim","Oliver Deussen"],"title":"Feature-Driven Visual Analytics of Soccer Data","doi":"10.1109/VAST.2014.7042477","abstract":"Soccer is one the most popular sports today and also very interesting from an scientific point of view. We present a system for analyzing high-frequency position-based soccer data at various levels of detail, allowing to interactively explore and analyze for movement features and game events. Our Visual Analytics method covers single-player, multi-player and event-based analytical views. Depending on the task the most promising features are semi-automatically selected, processed, and visualized. Our aim is to help soccer analysts in finding the most important and interesting events in a match. We present a flexible, modular, and expandable layer-based system allowing in-depth analysis. The integration of Visual Analytics techniques into the analysis process enables the analyst to find interesting events based on classification and allows, by a set of custom views, to communicate the found results. The feedback loop in the Visual Analytics pipeline helps to further improve the classification results. We evaluate our approach by investigating real-world soccer matches and collecting additional expert feedback. Several use cases and findings illustrate the capabilities of our approach.","keywords":"Visual Analytics, Sport Analytics, Soccer Analysis","caption":"Fig. 1. Interesting phases of a single player can be automatically found by applying the clustering approach presented in Section 3. In this case, we analyze a forward and are interested in the attacks in that the player was involved. Resulting phases can be inspected using the small-multiples view (top-right panel) in combination with the other rendering layers and Horizon Graphs (left and bottom panels).","img_size":{"width":2148,"height":1113},"subfigures":[{"x":8.818590742747023,"y":7.221133682320477,"width":2125.6823625003117,"height":1087.6290463323942,"type":"interface","id":"interface-0"}],"visualizations":[{"x":1406.1100594805573,"y":775.35855639988,"width":731.7904630494675,"height":328.8900300573814,"type":"area_chart","id":"area_chart-6"},{"x":396.67777776634466,"y":989.729707368257,"width":1013.6920635149294,"height":119.71915669205713,"type":"bar_chart","id":"bar_chart-3"},{"x":409.81116417289803,"y":32.26163214569169,"width":991.2136504901813,"height":728.5838785657581,"type":"others","id":"others-0"},{"x":1409.871493042209,"y":331.96664694959617,"width":726.1617758203457,"height":447.17384895794896,"type":"parallel_coordinate","id":"parallel_coordinate-5"},{"x":394.8037338489705,"y":773.7266416708852,"width":1017.440151349674,"height":218.58243094394393,"type":"scatterplot","id":"scatterplot-1"},{"x":394.78774868588334,"y":995.3696595678531,"width":1013.6837618874923,"height":114.11782372143666,"type":"stripe_graph","id":"stripe_graph-2"}],"relations":[{"vislist":[{"vislist":["stripe_graph-2","bar_chart-3"],"relation":null,"id":"group-0"}],"relation":"accompanied","id":"relation-0"},{"vislist":[{"vislist":["area_chart-6"],"relation":null,"id":"group-1"}],"relation":"repeated","id":"relation-1"}]},"2590_0":{"comp":[["bar_chart","bar_chart",["repeated"]],["bar_chart","error_bar",["accompanied"]],["error_bar","bar_chart",["accompanied"]]],"visType":["bar_chart","error_bar"],"compType":["repeated","accompanied"],"compressed_tree":[{"composite_pattern":"accompanied","visualization_type":[["error_bar","bar_chart"]]},{"composite_pattern":"repeated","visualization_type":[["bar_chart"]]}],"coOccurrence":[["error_bar","bar_chart",["coOccurrence"]]],"year":2014,"conference":["VAST"],"authors":["Yafeng Lu","Robert Kr\xfcger","Dennis Thom","Feng Wan","Steffen Koch","Thomas Ertl","Ross Maciejewski"],"title":"Integrating Predictive Analytics and Social Media","doi":"10.1109/VAST.2014.7042495","abstract":"A key analytical task across many domains is model building and exploration for predictive analysis. Data is collected, parsed and analyzed for relationships, and features are selected and mapped to estimate the response of a system under exploration. As social media data has grown more abundant, data can be captured that may potentially represent behavioral patterns in society. In turn, this unstructured social media data can be parsed and integrated as a key factor for predictive intelligence. In this paper, we present a framework for the development of predictive models utilizing social media data. We combine feature selection mechanisms, similarity comparisons and model cross-validation through a variety of interactive visualizations to support analysts in model building and prediction. In order to explore how predictions might be performed in such a framework, we present results from a user study focusing on social media data as a predictor for movie box-office success.","keywords":"Social Media, Predictive Analytics, Feature Selection","caption":"Fig. 1: Front Page of the Frozen Weekend. View (a) is the Tweet and Youtube comments line. The solid lines indicate the number of Tweets per day starting 14 days before the release (x-axis). The left y-axis indicates the number of Tweets.The dashed lines represents the number of Youtube comments per day using the right y-axis. Each color represents one movie. Clicking the legend highlights the corresponding trend line. View (b) is the opening weekend gross bar graph. The left bar indicates the real gross while the right bar indicates the baseline model\u2019s prediction. View (c) shows the Tweets and users.","img_size":{"width":1864,"height":1005},"subfigures":[{"x":22.02581616807189,"y":6.121273512730023,"width":1829.5528289264873,"height":988.6392505757119,"type":"interface","id":"interface-0"}],"visualizations":[{"x":34.323196605374754,"y":730.6506364922204,"width":1064.7029702970297,"height":267.2418670438472,"type":"bar_chart","id":"bar_chart-0"},{"x":1108.9766619519094,"y":733.4936350777934,"width":705.063649222065,"height":260.13437057991507,"type":"bar_chart","id":"bar_chart-1"},{"x":1141.671145685997,"y":61.124469589816115,"width":676.6336633663366,"height":470.51626591230547,"type":"bar_chart","id":"bar_chart-2"},{"x":1143.0926449787835,"y":59.702970297029694,"width":675.2121640735501,"height":469.09476661951896,"type":"error_bar","id":"error_bar-3"},{"x":27.215700141442653,"y":58.28147100424327,"width":1086.0254596888258,"height":473.35926449787837,"type":"line_chart","id":"line_chart-4"}],"relations":[{"vislist":[{"vislist":["error_bar-3","bar_chart-2"],"relation":null,"id":"group-0"}],"relation":"accompanied","id":"relation-0"},{"vislist":[{"vislist":["bar_chart-1","bar_chart-0"],"relation":null,"id":"group-1"}],"relation":"repeated","id":"relation-1"}]},"2586_0":{"comp":[["heatmap","heatmap",["large_view","repeated"]]],"visType":["heatmap"],"compType":["large_view","repeated"],"compressed_tree":[{"composite_pattern":"repeated","visualization_type":[["heatmap"]]},{"composite_pattern":"large_view","visualization_type":[["heatmap"],["heatmap"]]}],"coOccurrence":[],"year":2014,"conference":["VAST"],"authors":["Johanna Schmidt","Reinhold Preiner","Thomas Auzinger","Michael Wimmer","M. Eduard Gr\xf6ller","Stefan Bruckner"],"title":"YMCA - Your Mesh Comparison Application","doi":"10.1109/VAST.2014.7042491","abstract":"Polygonal meshes can be created in several different ways. In this paper we focus on the reconstruction of meshes from point clouds, which are sets of points in 3D. Several algorithms that tackle this task already exist, but they have different benefits and drawbacks, which leads to a large number of possible reconstruction results (i.e., meshes). The evaluation of those techniques requires extensive comparisons between different meshes which is up to now done by either placing images of rendered meshes side-by-side, or by encoding differences by heat maps. A major drawback of both approaches is that they do not scale well with the number of meshes. This paper introduces a new comparative visual analysis technique for 3D meshes which enables the simultaneous comparison of several meshes and allows for the interactive exploration of their differences. Our approach gives an overview of the differences of the input meshes in a 2D view. By selecting certain areas of interest, the user can switch to a 3D representation and explore the spatial differences in detail. To inspect local variations, we provide a magic lens tool in 3D. The location and size of the lens provide further information on the variations of the reconstructions in the selected area. With our comparative visualization approach, differences between several mesh reconstruction algorithms can be easily localized and inspected.","keywords":"Visual analysis, comparative visualization, 3D data exploration, focus+context, mesh comparison","caption":"Fig. 1: Visual analysis for mesh comparison. We propose YMCA, a system that combines explicit encoding, juxtaposition and quantitative measures to allow the user to compare multiple meshes. YMCA conveys an overview of the available data (a, b), points to interesting features in the data (c) and allows for the inspection of local areas of interest (d,e).","img_size":{"width":2173,"height":447},"subfigures":[{"x":1.9855489415601866,"y":9.291551402424426,"width":854.2965068036563,"height":422.0871403113305,"type":"single","id":"single-0"},{"x":877.448275807031,"y":10.870745301557525,"width":418.1034483859371,"height":422.09363095497457,"type":"single","id":"single-1"},{"x":1308.8134627425636,"y":14.052625461287933,"width":855.9006780420025,"height":423.6420667402896,"type":"single","id":"single-2"}],"visualizations":[{"x":5.275761537960153,"y":10.728627819250853,"width":424.43172207398914,"height":431.2981091683651,"type":"heatmap","id":"heatmap-2"},{"x":1310.4095606169853,"y":14.35943345722155,"width":424.0635948154136,"height":420.19958802117907,"type":"heatmap","id":"heatmap-3"},{"x":876.1541186812091,"y":10.596930720173614,"width":414.9430853889039,"height":423.8876836240305,"type":"heatmap","id":"heatmap-4"},{"x":1172.7978726645435,"y":10.465233621096408,"width":118.6705686038946,"height":416.47725807969584,"type":"heatmap","id":"heatmap-5"},{"x":1785.0415453993282,"y":231.04029460508244,"width":350.51479279922387,"height":146.06962538210976,"type":"heatmap","id":"heatmap-6"},{"x":483.29881154499134,"y":40.879456706281815,"width":332.037351443124,"height":356.01782682512743,"type":"parallel_coordinate","id":"parallel_coordinate-0"},{"x":1774.5551782682512,"y":57.48132427843802,"width":359.70713073005146,"height":151.2614601018676,"type":"parallel_coordinate","id":"parallel_coordinate-1"}],"relations":[{"vislist":[{"vislist":["heatmap-5"],"relation":null,"id":"group-0"}],"relation":"repeated","id":"relation-0"},{"vislist":[{"vislist":["heatmap-5"],"relation":null,"id":"group-1"},{"vislist":["heatmap-4"],"relation":null,"id":"group-2"}],"relation":"large_view","id":"relation-1"}]},"2585_0":{"comp":[["heatmap","heatmap",["repeated"]],["glyph_based","scatterplot",["nested"]],["line_chart","area_chart",["stacked"]],["area_chart","line_chart",["stacked"]]],"visType":["heatmap","glyph_based","scatterplot","line_chart","area_chart"],"compType":["repeated","nested","stacked"],"compressed_tree":[{"composite_pattern":"repeated","visualization_type":[["heatmap"]]},{"composite_pattern":"nested","visualization_type":[["glyph_based"],["scatterplot"]]},{"composite_pattern":"stacked","visualization_type":[["line_chart","area_chart"]]}],"coOccurrence":[["heatmap","glyph_based",["coOccurrence"]],["heatmap","scatterplot",["coOccurrence"]],["heatmap","line_chart",["coOccurrence"]],["heatmap","area_chart",["coOccurrence"]],["glyph_based","scatterplot",["coOccurrence"]],["glyph_based","line_chart",["coOccurrence"]],["glyph_based","area_chart",["coOccurrence"]],["scatterplot","line_chart",["coOccurrence"]],["scatterplot","area_chart",["coOccurrence"]],["line_chart","area_chart",["coOccurrence"]]],"year":2014,"conference":["VAST"],"authors":["Wenchao Wu","Yixian Zheng","Huamin Qu","Wei Che","M. Eduard Gr\xf6ller","Lionel M. Ni"],"title":"BoundarySeer: Visual Analysis of 2D Boundary Changes","doi":"10.1109/VAST.2014.7042490","abstract":"Boundary changes exist ubiquitously in our daily life. From the Antarctic ozone hole to the land desertification, and from the territory of a country to the area within one-hour reach from a downtown location, boundaries change over time. With a large number of time-varying boundaries recorded, people often need to analyze the changes, detect their similarities or differences, and find out spatial and temporal patterns of the evolution for various applications. In this paper, we present a comprehensive visual analytics system, BoundarySeer, to help users gain insight into the changes of boundaries. Our system consists of four major viewers: 1) a global viewer to show boundary groups based on their similarity and the distribution of boundary attributes such as smoothness and perimeter; 2) a region viewer to display the regions encircled by the boundaries and how they are affected by boundary changes; 3) a trend viewer to reveal the temporal patterns in the boundary evolution and potential spatio-temporal correlations; 4) a directional change viewer to encode movements of boundary segments in different directions. Quantitative analyses of boundaries (e.g., similarity measurement and adaptive clustering) and intuitive visualizations (e.g., density map and ThemeRiver) are integrated into these viewers, which enable users to explore boundary changes from different aspects and at different scales. Case studies with two real-world datasets have been carried out to demonstrate the effectiveness of our system.","keywords":"Boundary change, visual analytics, scatter plot, ThemeRiver, contour map, radial visualization","caption":"Fig. 1: A visual analytic\\u0001 system used to analyze the boundary changes of the Antarctic ozone hole from Aug. 23rd to Nov. 5th, 2012. The global viewer shows the similarity of the boundaries and their various attributes such as smoothness,t ime, and area. The region viewer displays the regions encircled by the boundaries and their stability (e.g., how frequently they are contained in the boundaries).\\u0001 The directional change viewer presents the changes of the boundaries in different directions. The trend viewer reveals the evolution of the area, perimeter as well as the spatial content contained in the boundaries over time.","img_size":{"width":1901,"height":1190},"subfigures":[{"x":22.163253464742773,"y":8.792179084376036,"width":1859.9261371348182,"height":1156.1613769735202,"type":"interface","id":"interface-0"}],"visualizations":[{"x":39.702338988946146,"y":839.6079373354067,"width":1263.365163291949,"height":320.3193365967917,"type":"area_chart","id":"area_chart-8"},{"x":1327.7196081330367,"y":63.208965960786,"width":534.686886026694,"height":564.1172793460343,"type":"glyph_based","id":"glyph_based-7"},{"x":51.47587719298252,"y":114.82456140350882,"width":548.0263157894735,"height":527.1491228070176,"type":"heatmap","id":"heatmap-0"},{"x":688.2302631578948,"y":60.021929824561475,"width":608.0482456140351,"height":592.3903508771931,"type":"heatmap","id":"heatmap-1"},{"x":1327.427114135494,"y":718.9510924658142,"width":529.7587719298247,"height":438.421052631579,"type":"heatmap","id":"heatmap-2"},{"x":40.87009659163448,"y":841.6046012377441,"width":1263.0701754385964,"height":315.7675438596492,"type":"heatmap","id":"heatmap-3"},{"x":31.950383700124352,"y":707.8411346567509,"width":1148.9464225096287,"height":138.16444321318315,"type":"line_chart","id":"line_chart-4"},{"x":48.86622807017551,"y":109.6052631578948,"width":553.2456140350877,"height":537.5877192982457,"type":"map","id":"map-6"},{"x":1327.3932386169226,"y":62.20371769611046,"width":535.0119456940101,"height":565.409655471458,"type":"scatterplot","id":"scatterplot-5"}],"relations":[{"vislist":[{"vislist":["heatmap-2"],"relation":null,"id":"group-0"}],"relation":"repeated","id":"relation-0"},{"vislist":[{"vislist":["glyph_based-7"],"relation":null,"id":"group-1"},{"vislist":["scatterplot-5"],"relation":null,"id":"group-2"}],"relation":"nested","id":"relation-1"},{"vislist":[{"vislist":["line_chart-4","area_chart-8"],"relation":null,"id":"group-3"}],"relation":"stacked","id":"relation-2"}]},"2580_8":{"comp":[["graph","graph",["repeated"]],["matrix","matrix",["repeated"]]],"visType":["graph","matrix"],"compType":["repeated"],"compressed_tree":[{"composite_pattern":"repeated","visualization_type":[["graph"]]},{"composite_pattern":"repeated","visualization_type":[["graph"]]},{"composite_pattern":"repeated","visualization_type":[["matrix"]]}],"coOccurrence":[["graph","matrix",["coOccurrence"]]],"year":2014,"conference":["VAST"],"authors":["Olav Lenz","Frank Keul","Sebastian Bremm","Kay Hamacher","Tatiana von Landesberger"],"title":"Visual Analysis of Patterns in Multiple Amino Acid Mutation Graphs","doi":"10.1109/VAST.2014.7042485","abstract":"Proteins are essential parts in all living organisms. They consist of sequences of amino acids. An interaction with reactive agent can stimulate a mutation at a specific position in the sequence. This mutation may set off a chain reaction, which effects other amino acids in the protein. Chain reactions need to be analyzed, as they may invoke unwanted side effects in drug treatment. A mutation chain is represented by a directed acyclic graph, where amino acids are connected by their mutation dependencies. As each amino acid may mutate individually, many mutation graphs exist. To determine important impacts of mutations, experts need to analyze and compare common patterns in these mutations graphs. Experts, however, lack suitable tools for this purpose. We present a new system for the search and the exploration of frequent patterns (i.e., motifs) in mutation graphs. We present a fast pattern search algorithm specifically developed for finding biologically relevant patterns in many mutation graphs (i.e., many labeled acyclic directed graphs). Our visualization system allows an interactive exploration and comparison of the found patterns. It enables locating the found patterns in the mutation graphs and in the 3D protein structures. In this way, potentially interesting patterns can be discovered. These patterns serve as starting point for a further biological analysis. In cooperation with biologists, we use our approach for analyzing a real world data set based on multiple HIV protease sequences.","keywords":"Biologic Visualization, Graph Visualization, Motif Search, Motif Visualization, Biology, Mutations, Pattern Visualization","caption":"Fig. 8. Bene\ufb01t of our Pattern Overview. Top: A large number of found patterns presented in a standard way. Patterns are dif\ufb01cult to com- pare and analyze. Bottom: Our pattern overview visualizes the same amount of information in a compact and structured way. The patterns are grouped by their structure. The number of found patterns is indi- cated by color from light to dark green (few to many patterns).","img_size":{"width":1059,"height":1142},"subfigures":[{"x":12.611690171254063,"y":472.94899688152674,"width":1036.897284633284,"height":664.0609255863393,"type":"single","id":"single-0"}],"visualizations":[{"x":2.4976415094339623,"y":468.8845757704681,"width":1054.004716981132,"height":668.8221581921181,"type":"graph","id":"graph-0"},{"x":9.444114543282467,"y":22.142361997354524,"width":1040.676948847195,"height":356.360841044449,"type":"graph","id":"graph-1"},{"x":5.31698389458279,"y":5.016105417276627,"width":1041.6778916544658,"height":377.87994143484633,"type":"matrix","id":"matrix-2"},{"x":2.4976415094339623,"y":469.8418740849195,"width":1054.004716981132,"height":668.2578526910369,"type":"matrix","id":"matrix-3"},{"x":2.4976415094339623,"y":6.688140556368867,"width":1050.3389458272331,"height":381.22401171303085,"type":"small_multiple","id":"small_multiple-4"},{"x":2.4976415094339623,"y":5.016105417276627,"width":1054.004716981132,"height":382.89604685212305,"type":"tree","id":"tree-5"}],"relations":[{"vislist":[{"vislist":["graph-1"],"relation":null,"id":"group-0"}],"relation":"repeated","id":"relation-0"},{"vislist":[{"vislist":["graph-0"],"relation":null,"id":"group-1"}],"relation":"repeated","id":"relation-1"},{"vislist":[{"vislist":["matrix-3"],"relation":null,"id":"group-2"}],"relation":"repeated","id":"relation-2"}]},"2580_11":{"comp":[["graph","graph",["repeated"]]],"visType":["graph"],"compType":["repeated"],"compressed_tree":[{"composite_pattern":"repeated","visualization_type":[["graph"]]}],"coOccurrence":[["graph","graph",["coOccurrence"]]],"year":2014,"conference":["VAST"],"authors":["Olav Lenz","Frank Keul","Sebastian Bremm","Kay Hamacher","Tatiana von Landesberger"],"title":"Visual Analysis of Patterns in Multiple Amino Acid Mutation Graphs","doi":"10.1109/VAST.2014.7042485","abstract":"Proteins are essential parts in all living organisms. They consist of sequences of amino acids. An interaction with reactive agent can stimulate a mutation at a specific position in the sequence. This mutation may set off a chain reaction, which effects other amino acids in the protein. Chain reactions need to be analyzed, as they may invoke unwanted side effects in drug treatment. A mutation chain is represented by a directed acyclic graph, where amino acids are connected by their mutation dependencies. As each amino acid may mutate individually, many mutation graphs exist. To determine important impacts of mutations, experts need to analyze and compare common patterns in these mutations graphs. Experts, however, lack suitable tools for this purpose. We present a new system for the search and the exploration of frequent patterns (i.e., motifs) in mutation graphs. We present a fast pattern search algorithm specifically developed for finding biologically relevant patterns in many mutation graphs (i.e., many labeled acyclic directed graphs). Our visualization system allows an interactive exploration and comparison of the found patterns. It enables locating the found patterns in the mutation graphs and in the 3D protein structures. In this way, potentially interesting patterns can be discovered. These patterns serve as starting point for a further biological analysis. In cooperation with biologists, we use our approach for analyzing a real world data set based on multiple HIV protease sequences.","keywords":"Biologic Visualization, Graph Visualization, Motif Search, Motif Visualization, Biology, Mutations, Pattern Visualization","caption":"Fig. 12. Detailed Pattern View. A: Overview of the number of found patterns by basic types. B: The patterns found and their frequency in- dicated by background color. Dark green means many patterns found. C: Information panel showing additional analytical information for user- selected patterns.","img_size":{"width":1053,"height":630},"subfigures":[{"x":6.2157310043177665,"y":7.229197772599023,"width":1035.4032686457617,"height":611.239004933638,"type":"interface","id":"interface-0"}],"visualizations":[{"x":750.1822840409956,"y":178.02342606149344,"width":297.93557833089324,"height":273.03074670571016,"type":"bar_chart","id":"bar_chart-0"},{"x":737.2686676427526,"y":40.58565153733529,"width":308.08199121522705,"height":133.74816983894584,"type":"bar_chart","id":"bar_chart-1"},{"x":4.882137628111224,"y":248.12591508052714,"width":701.9472913616398,"height":374.49487554904846,"type":"graph","id":"graph-2"},{"x":2.3217152029351067,"y":39.663250366032216,"width":713.0161054172768,"height":172.48901903367505,"type":"graph","id":"graph-3"},{"x":15.028550512445065,"y":51.65446559297218,"width":107.92093704245971,"height":150.3513909224012,"type":"tree","id":"tree-4"},{"x":255.77525622254754,"y":54.42166910688141,"width":110.68814055636895,"height":149.4289897510981,"type":"tree","id":"tree-5"},{"x":8.57174231332354,"y":249.04831625183022,"width":171.56661786237188,"height":123.60175695461199,"type":"tree","id":"tree-6"},{"x":4.882137628111224,"y":375.4172767203514,"width":178.0234260614934,"height":117.14494875549047,"type":"tree","id":"tree-7"},{"x":529.7284040995606,"y":247.20351390922403,"width":177.1010248901904,"height":129.13616398243047,"type":"tree","id":"tree-8"}],"relations":[{"vislist":[{"vislist":["graph-2"],"relation":null,"id":"group-0"}],"relation":"repeated","id":"relation-0"}]},"2579_0":{"comp":[["matrix","matrix",["repeated"]],["matrix","bar_chart",["stacked"]],["bar_chart","bar_chart",["repeated"]],["bar_chart","matrix",["stacked"]],["graph","map",["coordinated"]]],"visType":["matrix","bar_chart","graph","map"],"compType":["repeated","stacked","coordinated"],"compressed_tree":[{"composite_pattern":"repeated","visualization_type":[["matrix"]]},{"composite_pattern":"coordinated","visualization_type":[["graph"],["map"]]},{"composite_pattern":"repeated","visualization_type":[["bar_chart"]]},{"composite_pattern":"stacked","visualization_type":[["matrix","bar_chart"]]}],"coOccurrence":[["matrix","graph",["coOccurrence"]],["matrix","map",["coOccurrence"]],["matrix","bar_chart",["coOccurrence"]],["graph","map",["coOccurrence"]],["graph","bar_chart",["coOccurrence"]],["map","bar_chart",["coOccurrence"]]],"year":2014,"conference":["VAST"],"authors":["Sungahn Ko","Shehzad Afzal","Simon J. Walton","Yang Yang","Junghoon Chae","Abish Malik","Yun Jang","Min Che","David S. Ebert"],"title":"Analyzing High-dimensional Multivariate Network Links with Integrated Anomaly Detection, Highlighting and Exploration","doi":"10.1109/VAST.2014.7042484","abstract":"This paper focuses on the integration of a family of visual analytics techniques for analyzing high-dimensional, multivariate network data that features spatial and temporal information, network connections, and a variety of other categorical and numerical data types. Such data types are commonly encountered in transportation, shipping, and logistics industries. Due to the scale and complexity of the data, it is essential to integrate techniques for data analysis, visualization, and exploration. We present new visual representations, Petal and Thread, to effectively present many-to-many network data including multi-attribute vectors. In addition, we deploy an information-theoretic model for anomaly detection across varying dimensions, displaying highlighted anomalies in a visually consistent manner, as well as supporting a managed process of exploration. Lastly, we evaluate the proposed methodology through data exploration and an empirical study.","keywords":"","caption":"Figure 1: Our system consists of multiple coordinated and linked views: (A) Calendar view, (B) Clock view, (C) Line graph view, (D) Statistics, (E) Legend view for displaying types of delays, (F) Geographical view, (G) Matrix view, (H) Legend view for delay type and time, (I) Node \ufb01lter, (J) Pattern on itinerary view, (K) Time and aggregation \ufb01lter, and (L) Twitter tag cloud view. In the (H) legend, the darker the red, the longer the average delay is. A route from Dallas (DFW) to Portland (PDX) is speci\ufb01ed in (F), and the top 20 airports in terms of delays are visualized in (G) for explanation. In (G-3), the red links have the highest level of Z-scores, while the purple links have the second largest level of Z-scores.","img_size":{"width":1612,"height":1014},"subfigures":[{"x":6.028241460596552,"y":10.304919123186826,"width":1597.1727234962502,"height":993.3901617536251,"type":"interface","id":"interface-0"}],"visualizations":[{"x":4.361842105263122,"y":827.2105263157891,"width":311.31578947368416,"height":171.22368421052624,"type":"bar_chart","id":"bar_chart-0"},{"x":56.31686742297388,"y":602.4020216415631,"width":167.89693799639736,"height":132.95884685263832,"type":"sector_chart","id":"sector_chart-1"},{"x":58.82571444662103,"y":453.7629000955586,"width":90.59454564627362,"height":73.0164994761011,"type":"bar_chart","id":"bar_chart-2"},{"x":165.58092157622235,"y":73.78567649785796,"width":46.584121525012,"height":369.7614646047826,"type":"bar_chart","id":"bar_chart-3"},{"x":327.3458760553555,"y":158.44612922345192,"width":1026.962568876943,"height":522.1820753539374,"type":"graph","id":"graph-8"},{"x":3.0789395631875416,"y":51.11817645265779,"width":163.6000811103496,"height":393.70952817735116,"type":"heatmap","id":"heatmap-9"},{"x":325.9584216906882,"y":6.09017135551749,"width":1034.0020278708269,"height":149.94588449794227,"type":"line_chart","id":"line_chart-6"},{"x":330.1693123257673,"y":161.27434253986237,"width":1022.7372130909691,"height":520.7921283845109,"type":"map","id":"map-7"},{"x":1.5209639276798432,"y":48.201153597884186,"width":164.08132007929166,"height":399.2703140487871,"type":"matrix","id":"matrix-4"},{"x":329.0197368421052,"y":678.2236842105262,"width":1031.7894736842104,"height":326.88157894736827,"type":"matrix","id":"matrix-5"}],"relations":[{"vislist":[{"vislist":["matrix-5"],"relation":null,"id":"group-0"}],"relation":"repeated","id":"relation-0"},{"vislist":[{"vislist":["graph-8"],"relation":null,"id":"group-1"},{"vislist":["map-7"],"relation":null,"id":"group-2"}],"relation":"coordinated","id":"relation-1"},{"vislist":[{"vislist":["bar_chart-0"],"relation":null,"id":"group-3"}],"relation":"repeated","id":"relation-2"},{"vislist":[{"vislist":["matrix-4","bar_chart-3","bar_chart-2"],"relation":null,"id":"group-4"}],"relation":"stacked","id":"relation-3"}]},"2579_5":{"comp":[["matrix","matrix",["repeated"]],["glyph_based","map",["coordinated"]]],"visType":["matrix","glyph_based","map"],"compType":["repeated","coordinated"],"compressed_tree":[{"composite_pattern":"repeated","visualization_type":[["matrix"]]},{"composite_pattern":"coordinated","visualization_type":[["glyph_based"],["map"]]}],"coOccurrence":[["glyph_based","map",["coOccurrence"]]],"year":2014,"conference":["VAST"],"authors":["Sungahn Ko","Shehzad Afzal","Simon J. Walton","Yang Yang","Junghoon Chae","Abish Malik","Yun Jang","Min Che","David S. Ebert"],"title":"Analyzing High-dimensional Multivariate Network Links with Integrated Anomaly Detection, Highlighting and Exploration","doi":"10.1109/VAST.2014.7042484","abstract":"This paper focuses on the integration of a family of visual analytics techniques for analyzing high-dimensional, multivariate network data that features spatial and temporal information, network connections, and a variety of other categorical and numerical data types. Such data types are commonly encountered in transportation, shipping, and logistics industries. Due to the scale and complexity of the data, it is essential to integrate techniques for data analysis, visualization, and exploration. We present new visual representations, Petal and Thread, to effectively present many-to-many network data including multi-attribute vectors. In addition, we deploy an information-theoretic model for anomaly detection across varying dimensions, displaying highlighted anomalies in a visually consistent manner, as well as supporting a managed process of exploration. Lastly, we evaluate the proposed methodology through data exploration and an empirical study.","keywords":"","caption":"Figure 5: (a) ORD is the most congested airport for both in-bound (vertical) and out-bound (horizontal). It is notable that carrier delay is the prevalent (out-bound) delay for DTW and MSP while NAS delay is the prominent delay for the incoming \ufb02ights (vertical) in at EWR, JFK and LGA (b). (c) Flights heading to Hawaii from west cost airports in winter had long delays. Flights heading for ORD, ATL and airports from mid-east and east usually suffer from NAS delays.","img_size":{"width":1794,"height":897},"subfigures":[{"x":458.2261868851693,"y":13.514152021468421,"width":1331.002755828371,"height":875.1876090163282,"type":"single","id":"single-0"}],"visualizations":[{"x":467.18750000000006,"y":9.835526315789473,"width":1322.856985209814,"height":879.2960526315788,"type":"sector_chart","id":"sector_chart-0"},{"x":469.15460526315786,"y":7.868421052631579,"width":1320.8898799466565,"height":881.2631578947369,"type":"glyph_based","id":"glyph_based-1"},{"x":465.2203947368421,"y":7.868421052631579,"width":1324.824090472972,"height":883.2302631578947,"type":"map","id":"map-3"},{"x":3.9555147901857373,"y":7.868421052631579,"width":454.40131578947364,"height":885.1760641571826,"type":"matrix","id":"matrix-2"}],"relations":[{"vislist":[{"vislist":["matrix-2"],"relation":null,"id":"group-0"}],"relation":"repeated","id":"relation-0"},{"vislist":[{"vislist":["glyph_based-1"],"relation":null,"id":"group-1"},{"vislist":["map-3"],"relation":null,"id":"group-2"}],"relation":"coordinated","id":"relation-1"}]},"2576_5":{"comp":[["area_chart","area_chart",["repeated"]],["scivis","scivis",["repeated"]]],"visType":["area_chart","scivis"],"compType":["repeated"],"compressed_tree":[{"composite_pattern":"repeated","visualization_type":[["area_chart"]]},{"composite_pattern":"repeated","visualization_type":[["scivis"]]}],"coOccurrence":[["area_chart","scivis",["coOccurrence"]]],"year":2014,"conference":["VAST"],"authors":["Miguel Nunes","Benjamin Rowland","Matthias Schlachter","Sol\xe9akh\xe9na Ken","Kresimir Matkovic","Anne Laprie","Katja B\xfchler"],"title":"An Integrated Visual Analysis System for Fusing MR Spectroscopy and Multi-Modal Radiology Imaging","doi":"10.1109/VAST.2014.7042481","abstract":"For cancers such as glioblastoma multiforme, there is an increasing interest in defining \\"biological target volumes\\" (BTV), high tumour-burden regions which may be targeted with dose boosts in radiotherapy. The definition of a BTV requires insight into tumour characteristics going beyond conventionally defined radiological abnormalities and anatomical features. Molecular and biochemical imaging techniques, like positron emission tomography, the use of Magnetic Resonance (MR) Imaging contrast agents or MR Spectroscopy deliver this information and support BTV delineation. MR Spectroscopy Imaging (MRSI) is the only non-invasive technique in this list. Studies with MRSI have shown that voxels with certain metabolic signatures are more susceptible to predict the site of relapse. Nevertheless, the discovery of complex relationships between a high number of different metabolites, anatomical, molecular and functional features is an ongoing topic of research - still lacking appropriate tools supporting a smooth workflow by providing data integration and fusion of MRSI data with other imaging modalities. We present a solution bridging this gap which gives fast and flexible access to all data at once. By integrating a customized visualization of the multi-modal and multi-variate image data with a highly flexible visual analytics (VA) framework, it is for the first time possible to interactively fuse, visualize and explore user defined metabolite relations derived from MRSI in combination with markers delivered by other imaging modalities. Real-world medical cases demonstrate the utility of our solution. By making MRSI data available both in a VA tool and in a multi-modal visualization renderer we can combine insights from each side to arrive at a superior BTV delineation. We also report feedback from domain experts indicating significant positive impact in how this work can improve the understanding of MRSI data and its integration into radiotherapy planning.","keywords":"MR spectroscopy, cancer, brain, visualization, multi-modality data, radiotherapy planning, medical decision support systems","caption":"Fig. 6: Screen-shot of our system: ComVis (Left) and MITK (Right) running side-by-side in dual screen.","img_size":{"width":1520,"height":482},"subfigures":[{"x":5.387642347308172,"y":11.632861979618443,"width":835.7736264845329,"height":453.2223561806615,"type":"interface","id":"interface-0"},{"x":841.7105042926723,"y":20.326782700010952,"width":664.5926252107834,"height":441.3464345999785,"type":"interface","id":"interface-1"}],"visualizations":[{"x":1400.481036077706,"y":94.7650323774283,"width":99.83348751156336,"height":167.3265494912118,"type":"area_chart","id":"area_chart-0"},{"x":1397.668825161887,"y":304.27474560592043,"width":98.4273820536539,"height":108.27012025901944,"type":"area_chart","id":"area_chart-1"},{"x":28.122109158186877,"y":51.17576318223865,"width":306.53098982423677,"height":201.07308048103607,"type":"bar_chart","id":"bar_chart-2"},{"x":19.685476410730804,"y":257.87326549491206,"width":201.0730804810361,"height":198.26086956521732,"type":"bar_chart","id":"bar_chart-3"},{"x":881.6281221091581,"y":89.14061054579089,"width":240.44403330249784,"height":327.62257169287705,"type":"scivis","id":"scivis-4"},{"x":1136.1332099907493,"y":84.92229417206288,"width":243.25624421831643,"height":330.4347826086957,"type":"scivis","id":"scivis-5"},{"x":223.5707678075856,"y":253.65494912118407,"width":428.86216466234976,"height":201.07308048103596,"type":"parallel_coordinate","id":"parallel_coordinate-7"},{"x":344.9602779841307,"y":49.634023623964296,"width":305.7946948140682,"height":194.7801191389939,"type":"scatterplot","id":"scatterplot-6"}],"relations":[{"vislist":[{"vislist":["area_chart-0","area_chart-1"],"relation":null,"id":"group-0"}],"relation":"repeated","id":"relation-0"},{"vislist":[{"vislist":["scivis-5","scivis-4"],"relation":null,"id":"group-2"}],"relation":"repeated","id":"relation-2"}]},"2575_0":{"comp":[["comb","comb",["repeated"]],["scatterplot","scatterplot",["repeated"]],["stripe_graph","area_chart",["accompanied"]],["area_chart","stripe_graph",["accompanied"]]],"visType":["comb","scatterplot","stripe_graph","area_chart"],"compType":["repeated","accompanied"],"compressed_tree":[{"composite_pattern":"repeated","visualization_type":[[{"composite_pattern":"accompanied","visualization_type":[["stripe_graph","area_chart"]]}]]},{"composite_pattern":"repeated","visualization_type":[["scatterplot"]]}],"coOccurrence":[["stripe_graph","area_chart",["coOccurrence"]],["stripe_graph","scatterplot",["coOccurrence"]],["area_chart","scatterplot",["coOccurrence"]]],"year":2014,"conference":["VAST"],"authors":["Michael Behrisch","Fatih Korkmaz","Lin Shao","Tobias Schreck"],"title":"Feedback-Driven Interactive Exploration of Large Multidimensional Data Supported by Visual Classifier","doi":"10.1109/VAST.2014.7042480","abstract":"The extraction of relevant and meaningful information from multivariate or high-dimensional data is a challenging problem. One reason for this is that the number of possible representations, which might contain relevant information, grows exponentially with the amount of data dimensions. Also, not all views from a possibly large view space, are potentially relevant to a given analysis task or user. Focus+Context or Semantic Zoom Interfaces can help to some extent to efficiently search for interesting views or data segments, yet they show scalability problems for very large data sets. Accordingly, users are confronted with the problem of identifying interesting views, yet the manual exploration of the entire view space becomes ineffective or even infeasible. While certain quality metrics have been proposed recently to identify potentially interesting views, these often are defined in a heuristic way and do not take into account the application or user context. We introduce a framework for a feedback-driven view exploration, inspired by relevance feedback approaches used in Information Retrieval. Our basic idea is that users iteratively express their notion of interestingness when presented with candidate views. From that expression, a model representing the user\'s preferences, is trained and used to recommend further interesting view candidates. A decision support system monitors the exploration process and assesses the relevance-driven search process for convergence and stability. We present an instantiation of our framework for exploration of Scatter Plot Spaces based on visual features. We demonstrate the effectiveness of this implementation by a case study on two real-world datasets. We also discuss our framework in light of design alternatives and point out its usefulness for development of user- and context-dependent visual exploration systems.","keywords":"View Space Exploration Framework, Interesting View Problem, Relevance Feedback, User Preference Model","caption":"Fig. 1. The user interacts in the View Space Explorer by choosing relevant or irrelevant examples (4) from a small sample set. An incremental decision tree visualization (5) and a feature tube visualization (6) help to assess the exploration convergence. Speci\ufb01c decision support intervention points can be enabled/disabled in (3). Additional decision support noti\ufb01cations are shown in (8).","img_size":{"width":1722,"height":972},"subfigures":[{"x":45.80153183229092,"y":9.827131286324757,"width":1639.6918539709386,"height":943.052122461637,"type":"interface","id":"interface-0"}],"visualizations":[{"x":1352.7628458498025,"y":109.4940711462451,"width":194.01581027667999,"height":789.5098814229248,"type":"area_chart","id":"area_chart-0"},{"x":269.3478260869565,"y":104.94822028446349,"width":1062.2845849802368,"height":399.54251694095444,"type":"scatterplot","id":"scatterplot-1"},{"x":305.870030564516,"y":358.50919790459204,"width":211.29697590800527,"height":218.53160419081536,"type":"scatterplot","id":"scatterplot-10"},{"x":1119.9767677889379,"y":363.05671378737276,"width":212.45387182953007,"height":218.5490724252532,"type":"scatterplot","id":"scatterplot-7"},{"x":891.0850974168511,"y":364.517054270555,"width":216.20017553666685,"height":214.10964145888914,"type":"scatterplot","id":"scatterplot-8"},{"x":535.4729033450634,"y":361.50396509350264,"width":215.23937849505865,"height":215.57956981299418,"type":"scatterplot","id":"scatterplot-9"},{"x":269.3478260869563,"y":110.69965423623678,"width":1060.3636363636365,"height":391.8815462706094,"type":"small_multiple","id":"small_multiple-2"},{"x":1350.8418972332015,"y":111.41501976284583,"width":194.01581027667999,"height":785.6679841897231,"type":"small_multiple","id":"small_multiple-3"},{"x":1350.8418972332015,"y":103.73122529644269,"width":195.93675889328048,"height":795.2727272727273,"type":"stripe_graph","id":"stripe_graph-4"}],"relations":[{"vislist":[{"vislist":[{"vislist":[{"vislist":["stripe_graph-4","area_chart-0"],"relation":null,"id":"group-0"}],"relation":"accompanied","id":"relation-0"}],"relation":null,"id":"group-1"}],"relation":"repeated","id":"relation-1"},{"vislist":[{"vislist":["scatterplot-1"],"relation":null,"id":"group-2"}],"relation":"repeated","id":"relation-2"}]},"2495_2":{"comp":[["bar_chart","bar_chart",["repeated"]]],"visType":["bar_chart"],"compType":["repeated"],"compressed_tree":[{"composite_pattern":"repeated","visualization_type":[["bar_chart"]]}],"coOccurrence":[],"year":2014,"conference":["InfoVis"],"authors":["Zhicheng Liu","Jeffrey Heer"],"title":"The Effects of Interactive Latency on Exploratory Visual Analysis","doi":"10.1109/TVCG.2014.2346452","abstract":"To support effective exploration, it is often stated that interactive visualizations should provide rapid response times. However, the effects of interactive latency on the process and outcomes of exploratory visual analysis have not been systematically studied. We present an experiment measuring user behavior and knowledge discovery with interactive visualizations under varying latency conditions. We observe that an additional delay of 500ms incurs significant costs, decreasing user activity and data set coverage. Analyzing verbal data from think-aloud protocols, we find that increased latency reduces the rate at which users make observations, draw generalizations and generate hypotheses. Moreover, we note interaction effects in which initial exposure to higher latencies leads to subsequently reduced performance in a low-latency setting. Overall, increased latency causes users to shift exploration strategy, in turn affecting performance. We discuss how these results can inform the design of interactive analysis tools.","keywords":"Interaction, latency, exploratory analysis, interactive visualization, scalability, user performance, verbal analysis","caption":"Fig. 1. Visualizations for the datasets used in the study.","img_size":{"width":1042,"height":1241},"subfigures":[{"x":16.761869244034685,"y":19.14809452660833,"width":993.2110420332741,"height":568.7410407386335,"type":"interface","id":"interface-0"},{"x":11.614349621908268,"y":694.1240931533654,"width":989.9369972965004,"height":444.3373933794814,"type":"interface","id":"interface-1"}],"visualizations":[{"x":790.4391796322491,"y":52.65912305516257,"width":210.63649222065055,"height":401.96463932107497,"type":"bar_chart","id":"bar_chart-0"},{"x":499.05869872701555,"y":408.98585572843,"width":275.58274398868474,"height":173.77510608203673,"type":"bar_chart","id":"bar_chart-1"},{"x":26.8818953323904,"y":414.25176803394623,"width":159.7326732673267,"height":168.50919377652048,"type":"bar_chart","id":"bar_chart-2"},{"x":205.92291371994338,"y":412.4964639321075,"width":279.0933521923623,"height":172.019801980198,"type":"bar_chart","id":"bar_chart-3"},{"x":479.7503536067893,"y":723.1852899575672,"width":205.37057991513436,"height":382.65629420084883,"type":"bar_chart","id":"bar_chart-4"},{"x":713.2057991513437,"y":724.940594059406,"width":280.848656294201,"height":224.67892503536075,"type":"bar_chart","id":"bar_chart-5"},{"x":718.47171145686,"y":972.4384724186706,"width":277.3380480905234,"height":156.22206506364932,"type":"bar_chart","id":"bar_chart-6"},{"x":18.105374823196595,"y":45.63790664780754,"width":760.0466760961812,"height":359.8373408769449,"type":"map","id":"map-7"},{"x":14.594766619519078,"y":723.1852899575672,"width":440.5813295615275,"height":416.00707213578517,"type":"scatterplot","id":"scatterplot-8"}],"relations":[{"vislist":[{"vislist":["bar_chart-2","bar_chart-3","bar_chart-1"],"relation":null,"id":"group-0"}],"relation":"repeated","id":"relation-0"}]},"2562_0":{"comp":[["map","map",["repeated"]],["line_chart","line_chart",["repeated"]]],"visType":["map","line_chart"],"compType":["repeated"],"compressed_tree":[{"composite_pattern":"repeated","visualization_type":[["map"]]},{"composite_pattern":"repeated","visualization_type":[["line_chart"]]},{"composite_pattern":"repeated","visualization_type":[["map"]]}],"coOccurrence":[["map","line_chart",["coOccurrence"]]],"year":2014,"conference":["VAST"],"authors":["Jiawan Zhang","E. Yanli","Jing Ma","Yahui Zhao","Binghan Xu","Liting Sun","Jinyan Chen","Xiaoru Yuan"],"title":"Visual Analysis of Public Utility Service Problems in a Metropolis","doi":"10.1109/TVCG.2014.2346898","abstract":"Issues about city utility services reported by citizens can provide unprecedented insights into the various aspects of such services. Analysis of these issues can improve living quality through evidence-based decision making. However, these issues are complex, because of the involvement of spatial and temporal components, in addition to having multi-dimensional and multivariate natures. Consequently, exploring utility service problems and creating visual representations are difficult. To analyze these issues, we propose a visual analytics process based on the main tasks of utility service management. We also propose an aggregate method that transforms numerous issues into legible events and provide visualizations for events. In addition, we provide a set of tools and interaction techniques to explore such issues. Our approach enables administrators to make more informed decisions.","keywords":"utility services, evidence-based decision making, visual analytics, aggregate","caption":"Fig. 1. Visual Analytics Approach to Public Utility Service Problems. a)Dotmap for visualizing the spatial distribution of issues; b)Heatmap for visualizing the spatial distribution of issues; c)Visualization of one event; d)Visualization of events; e)Changes in spatial distributions over months; f)Multiple temporal scale analysis; g)Animation for visualizing time sequence of issues in one event.","img_size":{"width":1440,"height":839},"subfigures":[{"x":10.453194978939766,"y":13.542343603762758,"width":1409.737270529228,"height":814.7232498805391,"type":"interface","id":"interface-0"}],"visualizations":[{"x":23.99787835926452,"y":703.7157001414428,"width":1395.5643564356437,"height":122.23055162659115,"type":"heatmap","id":"heatmap-0"},{"x":423.91725601131543,"y":24.92079207920792,"width":322.7835926449787,"height":307.3564356435644,"type":"heatmap","id":"heatmap-1"},{"x":431.0374823196605,"y":361.9448373408769,"width":290.74257425742576,"height":287.1824611032532,"type":"heatmap","id":"heatmap-2"},{"x":797.7291371994343,"y":380.9321074964639,"width":515.0297029702969,"height":164.95190947666197,"type":"line_chart","id":"line_chart-3"},{"x":765.6881188118812,"y":18.987270155586987,"width":652.6874115983028,"height":113.92362093352192,"type":"line_chart","id":"line_chart-4"},{"x":769.2482319660538,"y":130.53748231966057,"width":645.5671852899576,"height":112.73691654879772,"type":"line_chart","id":"line_chart-5"},{"x":772.8083451202262,"y":248.021216407355,"width":567.2446958981612,"height":117.48373408769451,"type":"line_chart","id":"line_chart-6"},{"x":23.99787835926452,"y":704.902404526167,"width":1396.751060820368,"height":118.67043847241861,"type":"map","id":"map-7"},{"x":19.25106082036777,"y":22.547383309759546,"width":417.7199434229137,"height":290.74257425742576,"type":"map","id":"map-8"},{"x":19.25106082036777,"y":367.8783592644979,"width":430.7736916548797,"height":263.4483734087695,"type":"map","id":"map-9"},{"x":422.7305516265912,"y":23.734087694483733,"width":321.5968882602545,"height":310.91654879773694,"type":"map","id":"map-10"},{"x":433.4108910891088,"y":363.13154172560115,"width":288.36916548797734,"height":284.80905233380486,"type":"map","id":"map-11"},{"x":798.9158415841583,"y":548.2574257425742,"width":517.4031117397452,"height":132.910891089109,"type":"map","id":"map-12"}],"relations":[{"vislist":[{"vislist":["map-7"],"relation":null,"id":"group-0"}],"relation":"repeated","id":"relation-0"},{"vislist":[{"vislist":["line_chart-4","line_chart-5","line_chart-6"],"relation":null,"id":"group-1"}],"relation":"repeated","id":"relation-1"},{"vislist":[{"vislist":["map-12"],"relation":null,"id":"group-2"}],"relation":"repeated","id":"relation-2"}]},"2372_3":{"comp":[["chord_diagram","chord_diagram",["repeated"]]],"visType":["chord_diagram"],"compType":["repeated"],"compressed_tree":[{"composite_pattern":"repeated","visualization_type":[["chord_diagram"]]}],"coOccurrence":[["chord_diagram","chord_diagram",["coOccurrence"]]],"year":2013,"conference":["InfoVis"],"authors":["Michelle Borkin","Chelsea S. Yeh","Madelaine Boyd","Peter Macko","Krzysztof Z. Gajos","Margo I. Seltzer","Hanspeter Pfister"],"title":"Evaluation of filesystem Provenance Visualization Tools","doi":"10.1109/TVCG.2013.155","abstract":"Having effective visualizations of filesystem provenance data is valuable for understanding its complex hierarchical structure. The most common visual representation of provenance data is the node-link diagram. While effective for understanding local activity, the node-link diagram fails to offer a high-level summary of activity and inter-relationships within the data. We present a new tool, InProv, which displays filesystem provenance with an interactive radial-based tree layout. The tool also utilizes a new time-based hierarchical node grouping method for filesystem provenance data we developed to match the user\'s mental model and make data exploration more intuitive. We compared InProv to a conventional node-link based tool, Orbiter, in a quantitative evaluation with real users of filesystem provenance data including provenance data experts, IT professionals, and computational scientists. We also compared in the evaluation our new node grouping method to a conventional method. The results demonstrate that InProv results in higher accuracy in identifying system activity than Orbiter with large complex data sets. The results also show that our new time-based hierarchical node grouping method improves performance in both tools, and participants found both tools significantly easier to use with the new time-based node grouping method. Subjective measures show that participants found InProv to require less mental activity, less physical activity, less work, and is less stressful to use. Our study also reveals one of the first cases of gender differences in visualization; both genders had comparable performance with InProv, but women had a significantly lower average accuracy (56%) compared to men (70%) with Orbiter.","keywords":"Provenance data, graph/network data, hierarchy data, quantitative evaluation, gender differences","caption":"Fig. 4. Left: Screenshot of InProv showing the interactions of the node \u201cbash\u201d with its parent and child nodes. The blue edges represent incoming edges from parent nodes, and the red edges represent outgoing edges to child nodes. Right: Schematic drawing displaying the key visual encodings and interaction features for InProv. The \u201cnode stack\u201d and \u201ccontext views\u201d both provide context of browsing history as well as location within the hierarchical structure.","img_size":{"width":2130,"height":779},"subfigures":[{"x":8.999285331634985,"y":36.083851415893456,"width":1036.2760453324647,"height":709.0531596834321,"type":"interface","id":"interface-0"}],"visualizations":[{"x":107.93457344451573,"y":127.86112892880051,"width":556.0679923027583,"height":534.2078255291855,"type":"chord_diagram","id":"chord_diagram-0"},{"x":745.9781911481721,"y":112.83226427196922,"width":192.6427196921103,"height":183.07889672867222,"type":"chord_diagram","id":"chord_diagram-1"},{"x":745.9781911481721,"y":304.1087235407313,"width":176.2475946119307,"height":168.05003207184097,"type":"chord_diagram","id":"chord_diagram-2"},{"x":750.076972418217,"y":498.1177036561899,"width":173.51507376523406,"height":170.7825529185376,"type":"chord_diagram","id":"chord_diagram-3"},{"x":1207.7742142398977,"y":159.2851186658114,"width":479.55740859525326,"height":472.7261064785119,"type":"donut_chart","id":"donut_chart-4"}],"relations":[{"vislist":[{"vislist":["chord_diagram-0","chord_diagram-1","chord_diagram-2","chord_diagram-3"],"relation":null,"id":"group-0"}],"relation":"repeated","id":"relation-0"}]},"2378_7":{"comp":[["map","map",["repeated"]]],"visType":["map"],"compType":["repeated"],"compressed_tree":[{"composite_pattern":"repeated","visualization_type":[["map"]]}],"coOccurrence":[["map","map",["coOccurrence"]]],"year":2013,"conference":["InfoVis"],"authors":["Lauro Didier Lins","James T. Klosowski","Carlos Eduardo Scheidegger"],"title":"Nanocubes for Real-Time Exploration of Spatiotemporal Datasets","doi":"10.1109/TVCG.2013.179","abstract":"Consider real-time exploration of large multidimensional spatiotemporal datasets with billions of entries, each defined by a location, a time, and other attributes. Are certain attributes correlated spatially or temporally? Are there trends or outliers in the data? Answering these questions requires aggregation over arbitrary regions of the domain and attributes of the data. Many relational databases implement the well-known data cube aggregation operation, which in a sense precomputes every possible aggregate query over the database. Data cubes are sometimes assumed to take a prohibitively large amount of space, and to consequently require disk storage. In contrast, we show how to construct a data cube that fits in a modern laptop\'s main memory, even for billions of entries; we call this data structure a nanocube. We present algorithms to compute and query a nanocube, and show how it can be used to generate well-known visual encodings such as heatmaps, histograms, and parallel coordinate plots. When compared to exact visualizations created by scanning an entire dataset, nanocube plots have bounded screen error across a variety of scales, thanks to a hierarchical structure in space and time. We demonstrate the effectiveness of our technique on a variety of real-world datasets, and present memory, timing, and network bandwidth measurements. We find that the timings for the queries in our examples are dominated by network and user-interaction latencies.","keywords":"Data cube, Data structures, Interactive exploration","caption":"Fig. 9. Two kinds of Customer Tickets: Type 1 (Red) and Type 2 (Blue). The heatmap on the left map corresponds to time bar A, and the one on the right to time bar B: both encode the difference between number of reports of Type 2 and Type 1 in each point of the map. Reports of Type 1 exceed reports of Type 2, but not everywhere: notice that the region of Denver is still blue. Zooming into Denver we see that the number of Type 1 reports has increased over time, but Type 2 still dominates.","img_size":{"width":1041,"height":720},"subfigures":[{"x":6.325717729370327,"y":12.43555452574725,"width":1006.9104730272347,"height":690.531318245783,"type":"interface","id":"interface-0"}],"visualizations":[{"x":8.653232981760032,"y":143.56134930316972,"width":501.52287644487564,"height":283.4561885551941,"type":"map","id":"map-0"},{"x":507.7421483959659,"y":142.04093949770916,"width":491.02854751260577,"height":284.96448393187575,"type":"map","id":"map-1"}],"relations":[{"vislist":[{"vislist":["map-0","map-1"],"relation":null,"id":"group-5"}],"relation":"repeated","id":"relation-3"}]},"2381_0":{"comp":[["table","table",["repeated"]],["bar_chart","bar_chart",["repeated"]],["bar_chart","donut_chart",["nested"]],["bar_chart","table",["large_view"]],["pie_chart","graph",["nested"]],["comb","comb",["nested"]]],"visType":["table","bar_chart","donut_chart","pie_chart","graph","comb"],"compType":["repeated","nested","large_view"],"compressed_tree":[{"composite_pattern":"repeated","visualization_type":[["table"]]},{"composite_pattern":"large_view","visualization_type":[["bar_chart"],["table"]]},{"composite_pattern":"repeated","visualization_type":[["bar_chart"]]},{"composite_pattern":"nested","visualization_type":[[{"composite_pattern":"nested","visualization_type":[["pie_chart"],["graph"]]}],[{"composite_pattern":"nested","visualization_type":[["bar_chart"],["donut_chart"]]}]]}],"coOccurrence":[["table","bar_chart",["coOccurrence"]],["table","donut_chart",["coOccurrence"]],["table","pie_chart",["coOccurrence"]],["table","graph",["coOccurrence"]],["bar_chart","donut_chart",["coOccurrence"]],["bar_chart","pie_chart",["coOccurrence"]],["bar_chart","graph",["coOccurrence"]],["donut_chart","pie_chart",["coOccurrence"]],["donut_chart","graph",["coOccurrence"]],["pie_chart","graph",["coOccurrence"]]],"year":2013,"conference":["InfoVis"],"authors":["Bilal Alsallakh","Wolfgang Aigner","Silvia Miksch","Helwig Hauser"],"title":"Radial Sets: Interactive Visual Analysis of Large Overlapping Sets","doi":"10.1109/TVCG.2013.184","abstract":"In many applications, data tables contain multi-valued attributes that often store the memberships of the table entities to multiple sets such as which languages a person masters, which skills an applicant documents, or which features a product comes with. With a growing number of entities, the resulting element-set membership matrix becomes very rich of information about how these sets overlap. Many analysis tasks targeted at set-typed data are concerned with these overlaps as salient features of such data. This paper presents Radial Sets, a novel visual technique to analyze set memberships for a large number of elements. Our technique uses frequency-based representations to enable quickly finding and analyzing different kinds of overlaps between the sets, and relating these overlaps to other attributes of the table entities. Furthermore, it enables various interactions to select elements of interest, find out if they are over-represented in specific sets or overlaps, and if they exhibit a different distribution for a specific attribute compared to the rest of the elements. These interactions allow formulating highly-expressive visual queries on the elements in terms of their set memberships and attribute values. As we demonstrate via two usage scenarios, Radial Sets enable revealing and analyzing a multitude of overlapping patterns between large sets, beyond the limits of state-of-the-art techniques.","keywords":"Multi-valued attributes, set-typed data, overlapping sets, visualization technique, scalability","caption":"Fig. 1. The main interface of Radial Sets: (a) the sizes of the overlapping sets, (b) a histogram of the elements by degree, (c) the Radial Sets view showing n > 50, 000 papers multi-classified into 11 ACM classes [1]; hyperedges of degree 3 are depicted to indicate overlaps between triples of sets; (d) a list of 1, 098 selected elements and their attributes, along with a natural text describing the selection criteria, (e) the overlap analysis view showing details about overlaps classified by degree into different lists, (f) a search box to select elements containing a specific text, (g) a linked view showing the publication dates for all papers and for the ones in (d).","img_size":{"width":2150,"height":1096},"subfigures":[{"x":13.425213024124496,"y":31.804203919135848,"width":2127.812747416696,"height":1062.7185439526456,"type":"interface","id":"interface-0"}],"visualizations":[{"x":24.73125884016975,"y":51.15700141442716,"width":235.63224893917956,"height":308.4922206506364,"type":"bar_chart","id":"bar_chart-0"},{"x":23.181046676096198,"y":466.6138613861386,"width":238.73267326732665,"height":251.13437057991504,"type":"bar_chart","id":"bar_chart-1"},{"x":1401.3196605374803,"y":747.697767441878,"width":548.7751060820357,"height":220.4995787626732,"type":"bar_chart","id":"bar_chart-2"},{"x":352.56192806011296,"y":163.99262696319053,"width":916.0388677374197,"height":869.156816282155,"type":"bar_chart","id":"bar_chart-8"},{"x":297.5685997171146,"y":89.91230551626589,"width":1109.9519094766613,"height":973.5332390381898,"type":"donut_chart","id":"donut_chart-3"},{"x":504.03570596355615,"y":275.65386546649705,"width":626.5044963231257,"height":653.9280317591664,"type":"graph","id":"graph-4"},{"x":505.2970297029703,"y":285.2390381895331,"width":620.0848656294197,"height":572.02828854314,"type":"pie_chart","id":"pie_chart-5"},{"x":1430.7736916548795,"y":93.012729844413,"width":688.2942008486564,"height":252.68458274398864,"type":"table","id":"table-6"},{"x":1432.3239038189533,"y":514.6704384724186,"width":683.643564356436,"height":533.2729844413012,"type":"table","id":"table-7"}],"relations":[{"vislist":[{"vislist":["table-6","table-7"],"relation":null,"id":"group-2"}],"relation":"repeated","id":"relation-1"},{"vislist":[{"vislist":["bar_chart-2"],"relation":null,"id":"group-4"},{"vislist":["table-7"],"relation":null,"id":"group-3"}],"relation":"large_view","id":"relation-2"},{"vislist":[{"vislist":["bar_chart-0","bar_chart-1"],"relation":null,"id":"group-5"}],"relation":"repeated","id":"relation-3"},{"vislist":[{"vislist":[{"vislist":[{"vislist":["pie_chart-5"],"relation":null,"id":"group-8"},{"vislist":["graph-4"],"relation":null,"id":"group-9"}],"relation":"nested","id":"relation-5"}],"relation":null,"id":"group-10"},{"vislist":[{"vislist":[{"vislist":["bar_chart-8"],"relation":null,"id":"group-6"},{"vislist":["donut_chart-3"],"relation":null,"id":"group-7"}],"relation":"nested","id":"relation-4"}],"relation":null,"id":"group-11"}],"relation":"nested","id":"relation-6"}]},"2384_10":{"comp":[["comb","comb",["repeated"]],["matrix","graph",["nested"]],["graph","graph",["nested"]],["graph","map",["coordinated"]]],"visType":["comb","matrix","graph","map"],"compType":["repeated","nested","coordinated"],"compressed_tree":[{"composite_pattern":"repeated","visualization_type":[[{"composite_pattern":"coordinated","visualization_type":[["graph"],["map"]]}]]},{"composite_pattern":"nested","visualization_type":[["matrix","graph"],["graph"]]}],"coOccurrence":[["graph","map",["coOccurrence"]],["graph","matrix",["coOccurrence"]],["map","matrix",["coOccurrence"]]],"year":2013,"conference":["InfoVis"],"authors":["Charles Perin","Romain Vuillemot","Jean-Daniel Fekete"],"title":"SoccerStories: A Kick-off for Visual Soccer Analysis","doi":"10.1109/TVCG.2013.192","abstract":"This article presents SoccerStories, a visualization interface to support analysts in exploring soccer data and communicating interesting insights. Currently, most analyses on such data relate to statistics on individual players or teams. However, soccer analysts we collaborated with consider that quantitative analysis alone does not convey the right picture of the game, as context, player positions and phases of player actions are the most relevant aspects. We designed SoccerStories to support the current practice of soccer analysts and to enrich it, both in the analysis and communication stages. Our system provides an overview+detail interface of game phases, and their aggregation into a series of connected visualizations, each visualization being tailored for actions such as a series of passes or a goal attempt. To evaluate our tool, we ran two qualitative user studies on recent games using SoccerStories with data from one of the world\'s leading live sports data providers. The first study resulted in a series of four articles on soccer tactics, by a tactics analyst, who said he would not have been able to write these otherwise. The second study consisted in an exploratory follow-up to investigate design alternatives for embedding soccer phases into word-sized graphics. For both experiments, we received a very enthusiastic feedback and participants consider further use of SoccerStories to enhance their current workflow.","keywords":"Visual knowledge discovery, visual knowledge representation, sport analytics, visual aggregation","caption":"Fig. 10. SoccerStories user interface: (1) complete game overview as a timeline, (2) temporal zoom on a game phase and layout on a soccer field, (3) details on the side. After iterations, we added (4) the thumbnails and (5) generated text-annotations.","img_size":{"width":2163,"height":1168},"subfigures":[{"x":0.8573758166532491,"y":21.4907863534384,"width":2150.102898671627,"height":1137.4489016375214,"type":"interface","id":"interface-0"}],"visualizations":[{"x":5.984439304491071,"y":397.6080309185227,"width":289.58036193710007,"height":762.500000341582,"type":"bar_chart","id":"bar_chart-0"},{"x":1124.224160914577,"y":535.8360269069022,"width":369.99848412099504,"height":291.86968966529633,"type":"graph","id":"graph-2"},{"x":310.45252507030904,"y":179.61935151191184,"width":1302.7460278135075,"height":983.7916687616658,"type":"graph","id":"graph-3"},{"x":1630.0216387848295,"y":31.056693146176432,"width":519.5877273344767,"height":798.2160383034653,"type":"graph","id":"graph-5"},{"x":1627.2931870672385,"y":25.63938656565857,"width":522.3092145177069,"height":806.3158019053539,"type":"map","id":"map-6"},{"x":1463.0662638867839,"y":227.3637531704031,"width":143.6579597488014,"height":304.41248456652687,"type":"matrix","id":"matrix-1"},{"x":1421.913421968518,"y":850.617648258508,"width":145.2688641527223,"height":299.5263942436303,"type":"matrix","id":"matrix-4"}],"relations":[{"vislist":[{"vislist":[{"vislist":[{"vislist":["graph-5"],"relation":null,"id":"group-1"},{"vislist":["map-6"],"relation":null,"id":"group-0"}],"relation":"coordinated","id":"relation-0"}],"relation":null,"id":"group-2"}],"relation":"repeated","id":"relation-1"},{"vislist":[{"vislist":["matrix-1","graph-2","matrix-4"],"relation":null,"id":"group-4"},{"vislist":["graph-3"],"relation":null,"id":"group-3"}],"relation":"nested","id":"relation-2"}]},"2389_7":{"comp":[["glyph_based","glyph_based",["repeated"]],["glyph_based","comb",["large_view"]],["others","others",["repeated"]],["donut_chart","comb",["large_view"]],["tree","comb",["large_view"]]],"visType":["glyph_based","comb","others","donut_chart","tree"],"compType":["repeated","large_view"],"compressed_tree":[{"composite_pattern":"repeated","visualization_type":[["glyph_based"]]},{"composite_pattern":"large_view","visualization_type":[["donut_chart","glyph_based","tree"],[{"composite_pattern":"repeated","visualization_type":[["others"]]}]]}],"coOccurrence":[["others","glyph_based",["coOccurrence"]],["others","donut_chart",["coOccurrence"]],["others","tree",["coOccurrence"]],["glyph_based","donut_chart",["coOccurrence"]],["glyph_based","tree",["coOccurrence"]],["donut_chart","tree",["coOccurrence"]]],"year":2013,"conference":["InfoVis"],"authors":["Eamonn Maguire","Philippe Rocca-Serra","Susanna-Assunta Sansone","Jim Davies","Min Chen"],"title":"Visual Compression of Workflow Visualizations with Automated Detection of Macro Motifs","doi":"10.1109/TVCG.2013.225","abstract":"This paper is concerned with the creation of \'macros\' in workflow visualization as a support tool to increase the efficiency of data curation tasks. We propose computation of candidate macros based on their usage in large collections of workflows in data repositories. We describe an efficient algorithm for extracting macro motifs from workflow graphs. We discovered that the state transition information, used to identify macro candidates, characterizes the structural pattern of the macro and can be harnessed as part of the visual design of the corresponding macro glyph. This facilitates partial automation and consistency in glyph design applicable to a large set of macro glyphs. We tested this approach against a repository of biological data holding some 9,670 workflows and found that the algorithmically generated candidate macros are in keeping with domain expert expectations.","keywords":"Workflow visualization, motif detection, glyph-based visualization, glyph generation, state-transition-based algorithm","caption":"Fig. 7. AutoMacron provides a user interface (A) for domain experts to select macros from a list of computed motifs. As shown in the detailed view in (B), the overall score determines the order of motifs in the list. The three indicators are shown in unnormalized form in order to be semantically meaningful. The detail view (C) shows an example where a score is adjusted dynamically when a motif encompassing other motifs is selected. (D) shows a pop-up window for a specific macro, detailing its subgraph and three automatically generated pictograms for different levels of details in visualization.","img_size":{"width":2097,"height":1056},"subfigures":[{"x":4.426051612062683,"y":43.88445363792996,"width":1414.077800974695,"height":970.4787949343599,"type":"interface","id":"interface-0"}],"visualizations":[{"x":172.62298682284023,"y":551.9648609077599,"width":142.2430453879942,"height":194.8111273792094,"type":"donut_chart","id":"donut_chart-0"},{"x":654.2291752796544,"y":585.6875095191941,"width":124.22817092637781,"height":366.1710247069602,"type":"glyph_based","id":"glyph_based-7"},{"x":53.85338246829259,"y":164.9352954778766,"width":460.4440519755854,"height":369.2812388858456,"type":"others","id":"others-4"},{"x":512.685654555987,"y":161.61841475499645,"width":441.7905625560928,"height":681.0268186826559,"type":"others","id":"others-5"},{"x":953.7540554107414,"y":161.585309203358,"width":442.75311551830634,"height":675.78673729287,"type":"others","id":"others-6"},{"x":427.7327964860907,"y":550.4187408491947,"width":132.9663250366031,"height":412.81405563689606,"type":"tree","id":"tree-1"},{"x":859.1002928257684,"y":842.6354319180089,"width":358.69985358711574,"height":106.68228404099557,"type":"tree","id":"tree-2"},{"x":1494.5556368960467,"y":609.1713030746706,"width":349.42313323572466,"height":428.2752562225474,"type":"tree","id":"tree-3"}],"relations":[{"vislist":[{"vislist":["glyph_based-7"],"relation":null,"id":"group-2"}],"relation":"repeated","id":"relation-1"},{"vislist":[{"vislist":["donut_chart-0","glyph_based-7","tree-1"],"relation":null,"id":"group-4"},{"vislist":[{"vislist":[{"vislist":["others-4","others-5","others-6"],"relation":null,"id":"group-1"}],"relation":"repeated","id":"relation-0"}],"relation":null,"id":"group-3"}],"relation":"large_view","id":"relation-2"}]},"2431_0":{"comp":[["area_chart","area_chart",["repeated"]]],"visType":["area_chart"],"compType":["repeated"],"compressed_tree":[{"composite_pattern":"repeated","visualization_type":[["area_chart"]]}],"coOccurrence":[["area_chart","area_chart",["coOccurrence"]]],"year":2013,"conference":["VAST"],"authors":["Wenwen Dou","Li Yu","Xiaoyu Wang","Zhiqiang Ma","William Ribarsky"],"title":"HierarchicalTopics: Visually Exploring Large Text Collections Using Topic Hierarchies","doi":"10.1109/TVCG.2013.162","abstract":"Analyzing large textual collections has become increasingly challenging given the size of the data available and the rate that more data is being generated. Topic-based text summarization methods coupled with interactive visualizations have presented promising approaches to address the challenge of analyzing large text corpora. As the text corpora and vocabulary grow larger, more topics need to be generated in order to capture the meaningful latent themes and nuances in the corpora. However, it is difficult for most of current topic-based visualizations to represent large number of topics without being cluttered or illegible. To facilitate the representation and navigation of a large number of topics, we propose a visual analytics system - HierarchicalTopic (HT). HT integrates a computational algorithm, Topic Rose Tree, with an interactive visual interface. The Topic Rose Tree constructs a topic hierarchy based on a list of topics. The interactive visual interface is designed to present the topic content as well as temporal evolution of topics in a hierarchical fashion. User interactions are provided for users to make changes to the topic hierarchy based on their mental model of the topic space. To qualitatively evaluate HT, we present a case study that showcases how HierarchicalTopics aid expert users in making sense of a large number of topics and discovering interesting patterns of topic groups. We have also conducted a user study to quantitatively evaluate the effect of hierarchical topic structure. The study results reveal that the HT leads to faster identification of large number of relevant topics. We have also solicited user feedback during the experiments and incorporated some suggestions into the current version of HierarchicalTopics.","keywords":"Hierarchical topic representation, topic modeling, visual analytics, rose tree","caption":"Fig. 1. Overview of the HierarchicalTopics system. The Hierarchical Topic structure is shown on the left in a tree visualization. The Hierarchical ThemeRiver view on the right presents the temporal pattern of topics in a hierarchical fashion. The dataset being visualized is the CNN news corpus. Topics are organized into 5 categories and annotations are attached to describe each news category. The corresponding categories in both view are outlined with same colors.","img_size":{"width":1936,"height":846},"subfigures":[{"x":14.222647400937515,"y":7.016964731690495,"width":1903.5185916045523,"height":837.013793597072,"type":"interface","id":"interface-0"}],"visualizations":[{"x":723.9820397690829,"y":571.3976908274536,"width":588.6234765875562,"height":263.2661962796665,"type":"area_chart","id":"area_chart-0"},{"x":726.4656831302117,"y":20.028864656831317,"width":584.8980115458628,"height":536.4669660038487,"type":"area_chart","id":"area_chart-1"},{"x":1317.5728030788969,"y":57.28351507376525,"width":589.8652982681207,"height":186.27325208466968,"type":"area_chart","id":"area_chart-2"},{"x":1312.6055163566389,"y":309.37331622835154,"width":593.590763309814,"height":224.76972418216812,"type":"area_chart","id":"area_chart-3"},{"x":1316.3309813983326,"y":568.9140474663245,"width":588.623476587556,"height":245.88069275176403,"type":"area_chart","id":"area_chart-4"},{"x":3.725465041693394,"y":6.368826170622211,"width":720.2565747273894,"height":835.7459910198846,"type":"tree","id":"tree-5"}],"relations":[{"vislist":[{"vislist":["area_chart-0","area_chart-1","area_chart-2","area_chart-3","area_chart-4"],"relation":null,"id":"group-0"}],"relation":"repeated","id":"relation-0"}]},"2433_0":{"comp":[["scatterplot","scatterplot",["repeated"]],["scatterplot","others",["stacked"]],["scatterplot","heatmap",["stacked"]],["others","scatterplot",["stacked"]],["others","heatmap",["stacked"]],["heatmap","others",["stacked"]],["heatmap","scatterplot",["stacked"]]],"visType":["scatterplot","others","heatmap"],"compType":["repeated","stacked"],"compressed_tree":[{"composite_pattern":"repeated","visualization_type":[["scatterplot"]]},{"composite_pattern":"stacked","visualization_type":[["others","scatterplot","heatmap"]]}],"coOccurrence":[["scatterplot","others",["coOccurrence"]],["scatterplot","heatmap",["coOccurrence"]],["others","heatmap",["coOccurrence"]]],"year":2013,"conference":["VAST"],"authors":["Jian Zhao","Christopher Collins","Fanny Chevalier","Ravin Balakrishnan"],"title":"Interactive Exploration of Implicit and Explicit Relations in Faceted Datasets","doi":"10.1109/TVCG.2013.167","abstract":"Many datasets, such as scientific literature collections, contain multiple heterogeneous facets which derive implicit relations, as well as explicit relational references between data items. The exploration of this data is challenging not only because of large data scales but also the complexity of resource structures and semantics. In this paper, we present PivotSlice, an interactive visualization technique which provides efficient faceted browsing as well as flexible capabilities to discover data relationships. With the metaphor of direct manipulation, PivotSlice allows the user to visually and logically construct a series of dynamic queries over the data, based on a multi-focus and multi-scale tabular view that subdivides the entire dataset into several meaningful parts with customized semantics. PivotSlice further facilitates the visual exploration and sensemaking process through features including live search and integration of online data, graphical interaction histories and smoothly animated visual state transitions. We evaluated PivotSlice through a qualitative lab study with university researchers and report the findings from our observations and interviews. We also demonstrate the effectiveness of PivotSlice using a scenario of exploring a repository of information visualization literature.","keywords":"Faceted browsing, network exploration, dynamic query, interaction, information visualization, visual analytics","caption":"Fig. 1. The main PivotSlice interface: (a) Search and Operation Panel, (b) History Panel, (c) Information Panel, (d) Main Canvas, and (e) Cell Relation Panel. The user is conducting faceted exploration by sub-dividing the entire data into 3-by-4 regions and discovering relationships among different sub-datasets, using the a table of queries constructed by two sets of filters on both axes.","img_size":{"width":1574,"height":895},"subfigures":[{"x":5.596009674389937,"y":5.105879914605715,"width":1562.807980651218,"height":885.7407465524873,"type":"interface","id":"interface-0"}],"visualizations":[{"x":178.54150197628454,"y":153.88339920948616,"width":1142.6284584980242,"height":583.6956521739132,"type":"graph","id":"graph-0"},{"x":175.00395256916994,"y":148.57707509881422,"width":1149.703557312253,"height":590.7707509881425,"type":"heatmap","id":"heatmap-1"},{"x":56.496047430830004,"y":749.9604743083006,"width":114.9703557312253,"height":136.195652173913,"type":"heatmap","id":"heatmap-2"},{"x":598.4875173990204,"y":33.90513934494731,"width":75.35367042198459,"height":70.92110157363254,"type":"heatmap","id":"heatmap-3"},{"x":678.8278277754011,"y":33.90513934494731,"width":74.24552820989652,"height":70.92110157363254,"type":"heatmap","id":"heatmap-4"},{"x":758.6140670457377,"y":32.2429260268153,"width":71.47517267967658,"height":72.58331489176454,"type":"heatmap","id":"heatmap-5"},{"x":836.1840218918983,"y":32.7969971328593,"width":74.79959931594055,"height":72.58331489176454,"type":"heatmap","id":"heatmap-6"},{"x":915.858143037924,"y":32.89093440858179,"width":74.35764633420727,"height":73.59751982813006,"type":"heatmap","id":"heatmap-7"},{"x":47.7608091577659,"y":159.85457240556065,"width":118.9373006248766,"height":582.2624141538262,"type":"others","id":"others-15"},{"x":180.71304991446272,"y":739.5679233055864,"width":1129.9663527860478,"height":130.94691579341082,"type":"others","id":"others-16"},{"x":678.0937615213388,"y":32.89093440858179,"width":75.65230320982255,"height":72.56445409921756,"type":"scatterplot","id":"scatterplot-10"},{"x":758.377838397069,"y":32.118972130930544,"width":72.56445409921751,"height":73.33641637686881,"type":"scatterplot","id":"scatterplot-11"},{"x":835.5740661621941,"y":32.118972130930544,"width":75.65230320982255,"height":74.88034093217131,"type":"scatterplot","id":"scatterplot-12"},{"x":915.0861807602729,"y":32.118972130930544,"width":74.8803409321713,"height":73.33641637686881,"type":"scatterplot","id":"scatterplot-13"},{"x":178.54150197628454,"y":150.34584980237156,"width":1142.6284584980242,"height":587.2332015810279,"type":"scatterplot","id":"scatterplot-8"},{"x":597.8096846456089,"y":34.434858963884295,"width":75.65230320982255,"height":71.02052954391506,"type":"scatterplot","id":"scatterplot-9"}],"relations":[{"vislist":[{"vislist":["scatterplot-9","scatterplot-10","scatterplot-11","scatterplot-12","scatterplot-13"],"relation":null,"id":"group-0"}],"relation":"repeated","id":"relation-0"},{"vislist":[{"vislist":["others-15","scatterplot-8","heatmap-2","others-16"],"relation":null,"id":"group-1"}],"relation":"stacked","id":"relation-1"}]},"2377_0":{"comp":[["bar_chart","bar_chart",["stacked","repeated"]],["bar_chart","parallel_coordinate",["nested"]],["comb","table",["nested"]]],"visType":["bar_chart","parallel_coordinate","comb","table"],"compType":["stacked","repeated","nested"],"compressed_tree":[{"composite_pattern":"stacked","visualization_type":[["bar_chart"]]},{"composite_pattern":"stacked","visualization_type":[["bar_chart"]]},{"composite_pattern":"repeated","visualization_type":[["bar_chart"]]},{"composite_pattern":"nested","visualization_type":[[{"composite_pattern":"nested","visualization_type":[["bar_chart"],["parallel_coordinate"]]}],["table"]]}],"coOccurrence":[["bar_chart","parallel_coordinate",["coOccurrence"]],["bar_chart","table",["coOccurrence"]],["parallel_coordinate","table",["coOccurrence"]]],"year":2013,"conference":["InfoVis"],"authors":["Samuel Gratzl","Alexander Lex","Nils Gehlenborg","Hanspeter Pfister","Marc Streit"],"title":"LineUp: Visual Analysis of Multi-Attribute Rankings","doi":"10.1109/TVCG.2013.173","abstract":"Rankings are a popular and universal approach to structuring otherwise unorganized collections of items by computing a rank for each item based on the value of one or more of its attributes. This allows us, for example, to prioritize tasks or to evaluate the performance of products relative to each other. While the visualization of a ranking itself is straightforward, its interpretation is not, because the rank of an item represents only a summary of a potentially complicated relationship between its attributes and those of the other items. It is also common that alternative rankings exist which need to be compared and analyzed to gain insight into how multiple heterogeneous attributes affect the rankings. Advanced visual exploration tools are needed to make this process efficient. In this paper we present a comprehensive analysis of requirements for the visualization of multi-attribute rankings. Based on these considerations, we propose LineUp - a novel and scalable visualization technique that uses bar charts. This interactive technique supports the ranking of items based on multiple heterogeneous attributes with different scales and semantics. It enables users to interactively combine attributes and flexibly refine parameters to explore the effect of changes in the attribute combination. This process can be employed to derive actionable insights as to which attributes of an item need to be modified in order for its rank to change. Additionally, through integration of slope graphs, LineUp can also be used to compare multiple alternative rankings on the same set of items, for example, over time or across different attribute combinations. We evaluate the effectiveness of the proposed multi-attribute visualization technique in a qualitative study. The study shows that users are able to successfully solve complex ranking tasks in a short period of time.","keywords":"Ranking visualization, ranking, scoring, multi-attribute, multifactorial, multi-faceted, stacked bar charts","caption":"Fig. 1. LineUp showing a ranking of the top Universities according to the QS World University Ranking 2012 dataset with custom attributes and weights, compared to the official ranking.","img_size":{"width":1967,"height":820},"subfigures":[{"x":5.240652159703708,"y":9.592293484859727,"width":1942.1661006212146,"height":800.8154130302808,"type":"single","id":"single-0"}],"visualizations":[{"x":385.6942682376693,"y":20.525148836391757,"width":512.779861951012,"height":87.056054349912,"type":"bar_chart","id":"bar_chart-1"},{"x":999.5978550160621,"y":16.84471153225559,"width":252.62840064249332,"height":90.68368985039268,"type":"bar_chart","id":"bar_chart-2"},{"x":6.1721293441635625,"y":747.2239950737355,"width":549.191789074472,"height":64.73335319518911,"type":"bar_chart","id":"bar_chart-3"},{"x":384.44045461395984,"y":103.95225111709078,"width":509.06862215313254,"height":67.042588028301,"type":"bar_chart","id":"bar_chart-5"},{"x":997.9949229991626,"y":106.43749568179393,"width":249.61539763099813,"height":62.072098898894495,"type":"bar_chart","id":"bar_chart-6"},{"x":22.070020556015066,"y":109.74589936042034,"width":1909.1784513883117,"height":632.8629402133482,"type":"bar_chart","id":"bar_chart-7"},{"x":388.0290355813145,"y":106.11131358712035,"width":1555.3675376917906,"height":646.3541769395994,"type":"parallel_coordinate","id":"parallel_coordinate-4"},{"x":14.65153182526137,"y":105.01388824879257,"width":1921.5278820317,"height":643.5713754725341,"type":"table","id":"table-0"}],"relations":[{"vislist":[{"vislist":["bar_chart-1","bar_chart-5"],"relation":null,"id":"group-3"}],"relation":"stacked","id":"relation-1"},{"vislist":[{"vislist":["bar_chart-2","bar_chart-6"],"relation":null,"id":"group-4"}],"relation":"stacked","id":"relation-2"},{"vislist":[{"vislist":["bar_chart-3"],"relation":null,"id":"group-5"}],"relation":"repeated","id":"relation-3"},{"vislist":[{"vislist":[{"vislist":[{"vislist":["bar_chart-7"],"relation":null,"id":"group-2"},{"vislist":["parallel_coordinate-4"],"relation":null,"id":"group-1"}],"relation":"nested","id":"relation-0"}],"relation":null,"id":"group-7"},{"vislist":["table-0"],"relation":null,"id":"group-6"}],"relation":"nested","id":"relation-4"}]},"2388_4":{"comp":[["table","table",["repeated"]],["others","stripe_graph",["stacked"]],["stripe_graph","others",["stacked"]]],"visType":["table","others","stripe_graph"],"compType":["repeated","stacked"],"compressed_tree":[{"composite_pattern":"stacked","visualization_type":[["others","stripe_graph"]]},{"composite_pattern":"repeated","visualization_type":[["table"]]}],"coOccurrence":[["others","stripe_graph",["coOccurrence"]],["others","table",["coOccurrence"]],["stripe_graph","table",["coOccurrence"]]],"year":2013,"conference":["InfoVis"],"authors":["Joel A. Ferstay","Cydney B. Nielsen","Tamara Munzner"],"title":"Variant View: Visualizing Sequence Variants in their Gene Context","doi":"10.1109/TVCG.2013.214","abstract":"Scientists use DNA sequence differences between an individual\'s genome and a standard reference genome to study the genetic basis of disease. Such differences are called sequence variants, and determining their impact in the cell is difficult because it requires reasoning about both the type and location of the variant across several levels of biological context. In this design study, we worked with four analysts to design a visualization tool supporting variant impact assessment for three different tasks. We contribute data and task abstractions for the problem of variant impact assessment, and the carefully justified design and implementation of the Variant View tool. Variant View features an information-dense visual encoding that provides maximal information at the overview level, in contrast to the extensive navigation required by currently-prevalent genome browsers. We provide initial evidence that the tool simplified and accelerated workflows for these three tasks through three case studies. Finally, we reflect on the lessons learned in creating and refining data and task abstractions that allow for concise overviews of sprawling information spaces that can reduce or remove the need for the memory-intensive use of navigation.","keywords":"Information visualization, design study, bioinformatics, genetic variants","caption":"Fig. 3. The Variant View tool, annotated to indicate its three main views. The primary view (A) is the central overview for performing variant im- pact assessment; the reorderable gene list view (B) can sort genes alphabetically or by derived measures of variant importance; the sec- ondary Variant Data table (C) contains peripheral information.","img_size":{"width":1037,"height":686},"subfigures":[{"x":10.570656813394383,"y":5.366541310037729,"width":1010.0179853520845,"height":677.4571499313598,"type":"interface","id":"interface-0"}],"visualizations":[{"x":165.89925848337464,"y":170.2968871614483,"width":529.9804523993994,"height":268.74808637685595,"type":"others","id":"others-3"},{"x":123.18122644283775,"y":292.6450511504666,"width":619.7970422463204,"height":147.4348587963599,"type":"stripe_graph","id":"stripe_graph-2"},{"x":43.924597364568,"y":445.95021961932645,"width":700.0614934114204,"height":200.87847730600288,"type":"table","id":"table-0"},{"x":769.0959004392387,"y":92.40409956076132,"width":219.9619326500731,"height":556.4333821376281,"type":"table","id":"table-1"}],"relations":[{"vislist":[{"vislist":["others-3","stripe_graph-2"],"relation":null,"id":"group-1"}],"relation":"stacked","id":"relation-0"},{"vislist":[{"vislist":["table-0","table-1"],"relation":null,"id":"group-2"}],"relation":"repeated","id":"relation-1"}]},"2392_0":{"comp":[["line_chart","line_chart",["repeated"]],["bar_chart","bar_chart",["repeated"]]],"visType":["line_chart","bar_chart"],"compType":["repeated"],"compressed_tree":[{"composite_pattern":"repeated","visualization_type":[["line_chart"]]},{"composite_pattern":"repeated","visualization_type":[["bar_chart"]]}],"coOccurrence":[["line_chart","bar_chart",["coOccurrence"]]],"year":2013,"conference":["InfoVis"],"authors":["John Alexis Guerra G\xf3mez","Michael L. Pack","Catherine Plaisant","Ben Shneiderman"],"title":"Visualizing Change over Time Using Dynamic Hierarchies: TreeVersity2 and the StemView","doi":"10.1109/TVCG.2013.231","abstract":"To analyze data such as the US Federal Budget or characteristics of the student population of a University it is common to look for changes over time. This task can be made easier and more fruitful if the analysis is performed by grouping by attributes, such as by Agencies, Bureaus and Accounts for the Budget, or Ethnicity, Gender and Major in a University. We present TreeVersity2, a web based interactive data visualization tool that allows users to analyze change in datasets by creating dynamic hierarchies based on the data attributes. TreeVersity2 introduces a novel space filling visualization (StemView) to represent change in trees at multiple levels - not just at the leaf level. With this visualization users can explore absolute and relative changes, created and removed nodes, and each node\'s actual values, while maintaining the context of the tree. In addition, TreeVersity2 provides overviews of change over the entire time period, and a reporting tool that lists outliers in textual form, which helps users identify the major changes in the data without having to manually setup filters. We validated TreeVersity2 with 12 case studies with organizations as diverse as the National Cancer Institute, Federal Drug Administration, Department of Transportation, Office of the Bursar of the University of Maryland, or eBay. Our case studies demonstrated that TreeVersity2 is flexible enough to be used in different domains and provide useful insights for the data owners. A TreeVersity2 demo can be found at https://treeversity.cattlab.umd.edu.","keywords":"Information visualization, Tree comparison","caption":"Fig. 1. Exploring change in the US Federal Budget since 1970. The left panel shows the timelines of the actual budgets for each element in the tree: overall at the top, by Agency in the middle and by Bureau at the bottom. The StemView (center panel) compares 2013 and 2012. Each box in the StemView represents an element in the Budget. The green box on the top tells us that overall the Budget increased by US$7.81 Billion. The middle row shows the changes by Agency. Color represent the change in dollars (green for an increase)while the height of the boxes show the percentage of change. The width shows the budget in 2013. Defense, Health, Treasury and Social Security are the main players, and all are increasing.","img_size":{"width":1818,"height":991},"subfigures":[{"x":15.278349997838642,"y":15.03096119149978,"width":1791.660884669167,"height":955.6647042970961,"type":"interface","id":"interface-0"}],"visualizations":[{"x":473.7729844413012,"y":168.20367751060823,"width":995.2050919377652,"height":257.9123055162659,"type":"bar_chart","id":"bar_chart-0"},{"x":476.5763790664781,"y":426.1159830268742,"width":986.794908062235,"height":256.5106082036775,"type":"bar_chart","id":"bar_chart-1"},{"x":475.17468175388973,"y":681.2248939179633,"width":989.598302687412,"height":259.3140028288543,"type":"bar_chart","id":"bar_chart-2"},{"x":1513.8323903818955,"y":473.7736916548798,"width":241.09193776520488,"height":105.12729844413015,"type":"bar_chart","id":"bar_chart-3"},{"x":64.47736916548796,"y":175.2121640735502,"width":379.85997171145686,"height":243.89533239038195,"type":"line_chart","id":"line_chart-4"},{"x":61.67397454031115,"y":435.92786421499295,"width":382.6633663366337,"height":241.09193776520513,"type":"line_chart","id":"line_chart-5"},{"x":63.07567185289954,"y":689.6350777934937,"width":377.05657708628013,"height":241.09193776520513,"type":"line_chart","id":"line_chart-6"}],"relations":[{"vislist":[{"vislist":["line_chart-4","line_chart-5","line_chart-6"],"relation":null,"id":"group-0"}],"relation":"repeated","id":"relation-0"},{"vislist":[{"vislist":["bar_chart-0","bar_chart-1","bar_chart-2"],"relation":null,"id":"group-1"}],"relation":"repeated","id":"relation-1"}]},"2427_0":{"comp":[["table","table",["repeated"]],["box_plot","box_plot",["repeated"]],["proportional_area_chart","matrix",["nested"]]],"visType":["table","box_plot","proportional_area_chart","matrix"],"compType":["repeated","nested"],"compressed_tree":[{"composite_pattern":"repeated","visualization_type":[["table"]]},{"composite_pattern":"repeated","visualization_type":[["box_plot"]]},{"composite_pattern":"nested","visualization_type":[["proportional_area_chart"],["matrix"]]}],"coOccurrence":[["table","box_plot",["coOccurrence"]],["table","proportional_area_chart",["coOccurrence"]],["table","matrix",["coOccurrence"]],["box_plot","proportional_area_chart",["coOccurrence"]],["box_plot","matrix",["coOccurrence"]],["proportional_area_chart","matrix",["coOccurrence"]]],"year":2013,"conference":["VAST"],"authors":["Thomas M\xfchlbacher","Harald Piringer"],"title":"A Partition-Based Framework for Building and Validating Regression Models","doi":"10.1109/TVCG.2013.125","abstract":"Regression models play a key role in many application domains for analyzing or predicting a quantitative dependent variable based on one or more independent variables. Automated approaches for building regression models are typically limited with respect to incorporating domain knowledge in the process of selecting input variables (also known as feature subset selection). Other limitations include the identification of local structures, transformations, and interactions between variables. The contribution of this paper is a framework for building regression models addressing these limitations. The framework combines a qualitative analysis of relationship structures by visualization and a quantification of relevance for ranking any number of features and pairs of features which may be categorical or continuous. A central aspect is the local approximation of the conditional target distribution by partitioning 1D and 2D feature domains into disjoint regions. This enables a visual investigation of local patterns and largely avoids structural assumptions for the quantitative ranking. We describe how the framework supports different tasks in model building (e.g., validation and comparison), and we present an interactive workflow for feature subset selection. A real-world case study illustrates the step-wise identification of a five-dimensional model for natural gas consumption. We also report feedback from domain experts after two months of deployment in the energy sector, indicating a significant effort reduction for building and improving regression models.","keywords":"Regression, model building, visual knowledge discovery, feature selection, data partitioning, guided visualization","caption":"Fig. 1. Analyzing relationships using our framework: The conditional distribution of the dependent variable natural gas consumption is visualized over partitioned input features (a) and feature pairs (b), which are ranked by measures quantifying their relevance (c).","img_size":{"width":1976,"height":1074},"subfigures":[{"x":21.38406350664116,"y":11.823857121554957,"width":1930.9464940090604,"height":1059.4963470211928,"type":"interface","id":"interface-0"}],"visualizations":[{"x":359.3457330415756,"y":98.70459518599563,"width":1078.7002188183808,"height":970.5951859956236,"type":"bar_chart","id":"bar_chart-0"},{"x":32.6805251641139,"y":105.75492341356676,"width":324.3150984682714,"height":155.10722100656454,"type":"box_plot","id":"box_plot-1"},{"x":27.98030634573317,"y":265.56236323851203,"width":329.015317286652,"height":155.10722100656454,"type":"box_plot","id":"box_plot-2"},{"x":23.28008752735244,"y":418.31947483588624,"width":336.0656455142233,"height":155.1072210065645,"type":"box_plot","id":"box_plot-3"},{"x":25.63019693654278,"y":575.7768052516413,"width":331.3654266958424,"height":162.15754923413564,"type":"box_plot","id":"box_plot-4"},{"x":25.63019693654278,"y":740.2844638949672,"width":331.3654266958424,"height":171.55798687089714,"type":"box_plot","id":"box_plot-5"},{"x":23.28008752735244,"y":911.8424507658643,"width":331.3654266958424,"height":148.05689277899353,"type":"box_plot","id":"box_plot-6"},{"x":361.6958424507661,"y":94.00437636761487,"width":1078.700218818381,"height":970.5951859956236,"type":"proportional_area_chart","id":"proportional_area_chart-7"},{"x":356.99562363238533,"y":101.05470459518601,"width":1085.750547045952,"height":968.2450765864332,"type":"matrix","id":"matrix-8"},{"x":1449.7964989059087,"y":434.77024070021884,"width":491.17286652078775,"height":629.8293216630195,"type":"table","id":"table-10"},{"x":1452.1466083150988,"y":91.65426695842451,"width":488.8227571115973,"height":274.96280087527356,"type":"table","id":"table-9"}],"relations":[{"vislist":[{"vislist":["table-9","table-10"],"relation":null,"id":"group-0"}],"relation":"repeated","id":"relation-0"},{"vislist":[{"vislist":["box_plot-1","box_plot-2","box_plot-3","box_plot-4","box_plot-5","box_plot-6"],"relation":null,"id":"group-3"}],"relation":"repeated","id":"relation-2"},{"vislist":[{"vislist":["proportional_area_chart-7"],"relation":null,"id":"group-5"},{"vislist":["matrix-8"],"relation":null,"id":"group-6"}],"relation":"nested","id":"relation-3"}]},"2428_3":{"comp":[["bar_chart","bar_chart",["repeated"]]],"visType":["bar_chart"],"compType":["repeated"],"compressed_tree":[{"composite_pattern":"repeated","visualization_type":[["bar_chart"]]},{"composite_pattern":"repeated","visualization_type":[["bar_chart"]]}],"coOccurrence":[["bar_chart","bar_chart",["coOccurrence"]]],"year":2013,"conference":["VAST"],"authors":["Rick Walker","Aidan Slingsby","Jason Dykes","Kai X","Jo Wood","Phong H. Nguyen","Derek Stephens","B. L. William Wong","Yongjun Zheng"],"title":"An Extensible Framework for Provenance in Human Terrain Visual Analytics","doi":"10.1109/TVCG.2013.132","abstract":"We describe and demonstrate an extensible framework that supports data exploration and provenance in the context of Human Terrain Analysis (HTA). Working closely with defence analysts we extract requirements and a list of features that characterise data analysed at the end of the HTA chain. From these, we select an appropriate non-classified data source with analogous features, and model it as a set of facets. We develop ProveML, an XML-based extension of the Open Provenance Model, using these facets and augment it with the structures necessary to record the provenance of data, analytical process and interpretations. Through an iterative process, we develop and refine a prototype system for Human Terrain Visual Analytics (HTVA), and demonstrate means of storing, browsing and recalling analytical provenance and process through analytic bookmarks in ProveML. We show how these bookmarks can be combined to form narratives that link back to the live data. Throughout the process, we demonstrate that through structured workshops, rapid prototyping and structured communication with intelligence analysts we are able to establish requirements, and design schema, techniques and tools that meet the requirements of the intelligence community. We use the needs and reactions of defence analysts in defining and steering the methods to validate the framework.","keywords":"Human terrain analysis, provenance, framework, bookmarks, narratives","caption":"Fig. 3. Screenshots of the HTVA prototype with visual summaries of the attributes for a particular facet on the right and mappings between visual variables and facet attributes at the bottom of each of the three screen shots. Left: scatterplot of places showing the relationship between various documents\u2019 attributes (count: x, average sentiment: y, standard deviation of sentiment: size and average source uncertainty: colour ). Middle: density map of document sentiment (purple=positive; orange=negative), constrained to a document time range; Right: Dot map of places, coloured by their average document rating and sized by the standard deviation of this (a rudimentary indication of the degree to which views about a place are contradictory).","img_size":{"width":2162,"height":689},"subfigures":[{"x":14.01006443161362,"y":8.058542127055789,"width":701.794357705817,"height":672.8829157458885,"type":"interface","id":"interface-0"},{"x":1452.961614897947,"y":5.842360189504062,"width":699.5304623402614,"height":678.442934886318,"type":"interface","id":"interface-1"}],"visualizations":[{"x":532.5259781911482,"y":327.1651699807569,"width":177.5086593970493,"height":61.01860166773578,"type":"bar_chart","id":"bar_chart-10"},{"x":1974.7838357921744,"y":34.55323925593334,"width":169.18794098781294,"height":58.24502886465682,"type":"bar_chart","id":"bar_chart-4"},{"x":1972.0102629890955,"y":94.18505452212962,"width":173.34830019243105,"height":51.311096856959566,"type":"bar_chart","id":"bar_chart-5"},{"x":1970.623476587556,"y":155.20365618986537,"width":176.12187299551016,"height":61.01860166773571,"type":"bar_chart","id":"bar_chart-6"},{"x":1969.2366901860169,"y":214.8354714560616,"width":178.89544579858875,"height":83.20718409236684,"type":"bar_chart","id":"bar_chart-7"},{"x":535.2995509942273,"y":446.42880051314955,"width":174.73508659397046,"height":58.24502886465678,"type":"bar_chart","id":"bar_chart-8"},{"x":533.9127645926876,"y":385.4101988454137,"width":177.5086593970493,"height":56.85824246311746,"type":"bar_chart","id":"bar_chart-9"},{"x":47.15073765234124,"y":9.591084028223264,"width":488.14881334188584,"height":571.3559974342527,"type":"heatmap","id":"heatmap-11"},{"x":535.2995509942273,"y":35.94002565747277,"width":173.34830019243105,"height":142.83899935856317,"type":"heatmap","id":"heatmap-12"},{"x":741.930724823605,"y":10.977870429762701,"width":514.4977549711352,"height":564.4220654265556,"type":"heatmap","id":"heatmap-13"},{"x":1460.2860808210391,"y":10.977870429762701,"width":514.4977549711352,"height":565.8088518280949,"type":"heatmap","id":"heatmap-14"},{"x":1460.2860808210391,"y":12.364656831302144,"width":515.8845413726749,"height":564.4220654265556,"type":"map","id":"map-19"},{"x":45.763951250801796,"y":6.817511225144359,"width":488.14881334188595,"height":574.1295702373317,"type":"map","id":"map-21"},{"x":536.6863373957666,"y":29.28400657502753,"width":171.9615137908915,"height":149.30915897010806,"type":"map","id":"map-22"},{"x":535.2995509942273,"y":34.55323925593334,"width":174.73508659397046,"height":144.2257857601026,"type":"scatterplot","id":"scatterplot-15"},{"x":1458.8992944194997,"y":10.977870429762701,"width":515.8845413726749,"height":564.4220654265556,"type":"scatterplot","id":"scatterplot-16"},{"x":47.15073765234124,"y":8.204297626683799,"width":488.14881334188584,"height":572.7427838357921,"type":"scatterplot","id":"scatterplot-18"}],"relations":[{"vislist":[{"vislist":["bar_chart-10","bar_chart-9","bar_chart-8"],"relation":null,"id":"group-2"}],"relation":"repeated","id":"relation-1"},{"vislist":[{"vislist":["bar_chart-4","bar_chart-5","bar_chart-6"],"relation":null,"id":"group-6"}],"relation":"repeated","id":"relation-4"}]},"2432_7":{"comp":[["scatterplot","scatterplot",["repeated"]]],"visType":["scatterplot"],"compType":["repeated"],"compressed_tree":[{"composite_pattern":"repeated","visualization_type":[["scatterplot"]]}],"coOccurrence":[["scatterplot","scatterplot",["coOccurrence"]]],"year":2013,"conference":["VAST"],"authors":["Wesley Willett","Shiry Ginosar","Avital Steinitz","Bj\xf6rn Hartmann","Maneesh Agrawala"],"title":"Identifying Redundancy and Exposing Provenance in Crowdsourced Data Analysis","doi":"10.1109/TVCG.2013.164","abstract":"We present a system that lets analysts use paid crowd workers to explore data sets and helps analysts interactively examine and build upon workers\' insights. We take advantage of the fact that, for many types of data, independent crowd workers can readily perform basic analysis tasks like examining views and generating explanations for trends and patterns. However, workers operating in parallel can often generate redundant explanations. Moreover, because workers have different competencies and domain knowledge, some responses are likely to be more plausible than others. To efficiently utilize the crowd\'s work, analysts must be able to quickly identify and consolidate redundant responses and determine which explanations are the most plausible. In this paper, we demonstrate several crowd-assisted techniques to help analysts make better use of crowdsourced explanations: (1) We explore crowd-assisted strategies that utilize multiple workers to detect redundant explanations. We introduce color clustering with representative selection-a strategy in which multiple workers cluster explanations and we automatically select the most-representative result-and show that it generates clusterings that are as good as those produced by experts. (2) We capture explanation provenance by introducing highlighting tasks and capturing workers\' browsing behavior via an embedded web browser, and refine that provenance information via source-review tasks. We expose this information in an explanation-management interface that allows analysts to interactively filter and sort responses, select the most plausible explanations, and decide which to explore further.","keywords":"Crowdsourcing, social data analysis","caption":"Fig. 8. The explanation-management interface. Explanations (A) can be clustered and collapsed by chart, topic, and source. Filtering (B) and clustering (C) controls allow the analyst to hide low-scoring clusters and control how they are nested. Explanations, clusters, and charts, can be dragged to the shoebox (D) and annotated for later review.","img_size":{"width":2165,"height":1041},"subfigures":[{"x":53.00771442057198,"y":39.09901897581366,"width":2069.1400041871116,"height":939.0984873939169,"type":"interface","id":"interface-0"}],"visualizations":[{"x":179.33992094861645,"y":271.56521739130443,"width":271.5652173913044,"height":230.4189723320159,"type":"scatterplot","id":"scatterplot-0"},{"x":179.33992094861645,"y":746.8043478260872,"width":269.5079051383399,"height":226.30434782608702,"type":"scatterplot","id":"scatterplot-1"}],"relations":[{"vislist":[{"vislist":["scatterplot-0","scatterplot-1"],"relation":null,"id":"group-0"}],"relation":"repeated","id":"relation-0"}]},"2439_6":{"comp":[["bar_chart","bar_chart",["repeated"]]],"visType":["bar_chart"],"compType":["repeated"],"compressed_tree":[{"composite_pattern":"repeated","visualization_type":[["bar_chart"]]}],"coOccurrence":[["bar_chart","bar_chart",["coOccurrence"]]],"year":2013,"conference":["VAST"],"authors":["Bing Wan","Puripant Ruchikachorn","Klaus Mueller"],"title":"SketchPadN-D: WYDIWYG Sculpting and Editing in High-Dimensional Space","doi":"10.1109/TVCG.2013.190","abstract":"High-dimensional data visualization has been attracting much attention. To fully test related software and algorithms, researchers require a diverse pool of data with known and desired features. Test data do not always provide this, or only partially. Here we propose the paradigm WYDIWYGS (What You Draw Is What You Get). Its embodiment, SketchPad&lt;sup&gt;ND&lt;/sup&gt;, is a tool that allows users to generate high-dimensional data in the same interface they also use for visualization. This provides for an immersive and direct data generation activity, and furthermore it also enables users to interactively edit and clean existing high-dimensional data from possible artifacts. SketchPad&lt;sup&gt;ND&lt;/sup&gt; offers two visualization paradigms, one based on parallel coordinates and the other based on a relatively new framework using an N-D polygon to navigate in high-dimensional space. The first interface allows users to draw arbitrary profiles of probability density functions along each dimension axis and sketch shapes for data density and connections between adjacent dimensions. The second interface embraces the idea of sculpting. Users can carve data at arbitrary orientations and refine them wherever necessary. This guarantees that the data generated is truly high-dimensional. We demonstrate our tool\'s usefulness in real data visualization scenarios.","keywords":"Synthetic data generation, data editing, data acquisition and management, multivariate data, high-dimensional data, interaction, user interface, parallel coordinates, scatterplot, N-D navigation, multiple views","caption":"Fig.7. Scatterplot sketching interface.","img_size":{"width":2155,"height":1176},"subfigures":[{"x":13.81910688844988,"y":17.757428864542273,"width":2128.612953519507,"height":1132.9757735231362,"type":"interface","id":"interface-0"}],"visualizations":[{"x":973.281181619256,"y":620.1663019693653,"width":589.2866520787744,"height":123.51859956236329,"type":"bar_chart","id":"bar_chart-0"},{"x":973.281181619256,"y":753.9781181619255,"width":584.140043763676,"height":131.2385120350109,"type":"bar_chart","id":"bar_chart-1"},{"x":973.281181619256,"y":916.0962800875271,"width":558.4070021881836,"height":136.38512035010945,"type":"bar_chart","id":"bar_chart-2"},{"x":214.156455142232,"y":257.33041575492337,"width":553.2603938730854,"height":494.0743982494529,"type":"scatterplot","id":"scatterplot-3"},{"x":1751.8850919745098,"y":727.5312157906011,"width":125.38381941501736,"height":150.9249678143724,"type":"scatterplot","id":"scatterplot-4"},{"x":1937.638898515276,"y":688.0585319006883,"width":186.91476783164603,"height":185.75380654076628,"type":"scatterplot","id":"scatterplot-5"},{"x":1754.2070145562693,"y":892.3877190955311,"width":142.798238778214,"height":145.12016135997348,"type":"scatterplot","id":"scatterplot-6"},{"x":1958.5362017511122,"y":894.7096416772906,"width":141.63727748733413,"height":142.798238778214,"type":"scatterplot","id":"scatterplot-7"},{"x":968.1345733041574,"y":131.23851203501093,"width":545.5404814004374,"height":470.9146608315098,"type":"scatterplot","id":"scatterplot-8"},{"x":1714.3927789934355,"y":146.67833698030634,"width":414.30196936542643,"height":396.2888402625821,"type":"scatterplot","id":"scatterplot-9"},{"x":1716.9660831509848,"y":146.67833698030634,"width":411.7286652078774,"height":396.2888402625821,"type":"small_multiple","id":"small_multiple-10"}],"relations":[{"vislist":[{"vislist":["bar_chart-0","bar_chart-1"],"relation":null,"id":"group-0"}],"relation":"repeated","id":"relation-0"}]},"2440_10":{"comp":[["bar_chart","bar_chart",["repeated"]]],"visType":["bar_chart"],"compType":["repeated"],"compressed_tree":[{"composite_pattern":"repeated","visualization_type":[["bar_chart"]]}],"coOccurrence":[["bar_chart","bar_chart",["coOccurrence"]]],"year":2013,"conference":["VAST"],"authors":["Natalia V. Andrienko","Gennady L. Andrienko","Louise Barrett","Marcus Dostie","S. Peter Henzi"],"title":"Space Transformation for Understanding Group Movement","doi":"10.1109/TVCG.2013.193","abstract":"We suggest a methodology for analyzing movement behaviors of individuals moving in a group. Group movement is analyzed at two levels of granularity: the group as a whole and the individuals it comprises. For analyzing the relative positions and movements of the individuals with respect to the rest of the group, we apply space transformation, in which the trajectories of the individuals are converted from geographical space to an abstract \'group space\'. The group space reference system is defined by both the position of the group center, which is taken as the coordinate origin, and the direction of the group\'s movement. Based on the individuals\' positions mapped onto the group space, we can compare the behaviors of different individuals, determine their roles and/or ranks within the groups, and, possibly, understand how group movement is organized. The utility of the methodology has been evaluated by applying it to a set of real data concerning movements of wild social animals and discussing the results with experts in animal ethology.","keywords":"Visual analytics, movement data, collective movement","caption":"Fig.11. The frequency histograms show the statistical distributions of the characteristics of the overall group movement: 3rd quartile of the distance to the group centre (top left), 3rd quartile of the deviation from the group movement direction (top right), displacement in 15-minutes time interval (bottom left), and speed (bottom right). The table below the histograms shows the summary statistics for these attributes.","img_size":{"width":1060,"height":697},"subfigures":[{"x":4.890561329250271,"y":11.988667899631327,"width":1044.7766311644534,"height":668.3572717087667,"type":"interface","id":"interface-0"}],"visualizations":[{"x":12.938419723219626,"y":46.48009846509822,"width":496.7759030874005,"height":214.7082293004867,"type":"bar_chart","id":"bar_chart-0"},{"x":550.4106538545033,"y":42.27013318469653,"width":492.5659378069987,"height":218.91819458088838,"type":"bar_chart","id":"bar_chart-1"},{"x":8.878504672897208,"y":307.49794585000353,"width":502.239139897857,"height":220.13755988568494,"type":"bar_chart","id":"bar_chart-2"},{"x":546.2006885741016,"y":310.3045893702714,"width":488.6357600240294,"height":219.50225592928007,"type":"bar_chart","id":"bar_chart-3"},{"x":1.8540784405524464,"y":531.6920943134536,"width":1040.1830790568658,"height":151.77392510402217,"type":"table","id":"table-4"}],"relations":[{"vislist":[{"vislist":["bar_chart-0","bar_chart-1","bar_chart-2","bar_chart-3"],"relation":null,"id":"group-0"}],"relation":"repeated","id":"relation-0"}]},"2440_8":{"comp":[["heatmap","heatmap",["repeated"]]],"visType":["heatmap"],"compType":["repeated"],"compressed_tree":[{"composite_pattern":"repeated","visualization_type":[["heatmap"]]}],"coOccurrence":[["heatmap","heatmap",["coOccurrence"]]],"year":2013,"conference":["VAST"],"authors":["Natalia V. Andrienko","Gennady L. Andrienko","Louise Barrett","Marcus Dostie","S. Peter Henzi"],"title":"Space Transformation for Understanding Group Movement","doi":"10.1109/TVCG.2013.193","abstract":"We suggest a methodology for analyzing movement behaviors of individuals moving in a group. Group movement is analyzed at two levels of granularity: the group as a whole and the individuals it comprises. For analyzing the relative positions and movements of the individuals with respect to the rest of the group, we apply space transformation, in which the trajectories of the individuals are converted from geographical space to an abstract \'group space\'. The group space reference system is defined by both the position of the group center, which is taken as the coordinate origin, and the direction of the group\'s movement. Based on the individuals\' positions mapped onto the group space, we can compare the behaviors of different individuals, determine their roles and/or ranks within the groups, and, possibly, understand how group movement is organized. The utility of the methodology has been evaluated by applying it to a set of real data concerning movements of wild social animals and discussing the results with experts in animal ethology.","keywords":"Visual analytics, movement data, collective movement","caption":"Fig.9. A: The density of \u201ctrend setting\u201d events extracted from the trajectories is represented on a map of the group space. B: The \u201ctrend setting\u201d events are shown in a space-time cube. C: The positions of the events in time (horizontal dimension) and within the trajectories of the group members (vertical dimension) are shown on a temporal bar chart. D: The temporal bar chart shows the relative ordering of the individuals along the group movement course.","img_size":{"width":1068,"height":901},"subfigures":[{"x":10.138371592685566,"y":11.520603965787094,"width":1041.6938642692057,"height":872.9330643839857,"type":"interface","id":"interface-0"}],"visualizations":[{"x":5.182307692307717,"y":8.31692307692308,"width":491.1809834469327,"height":498.0678870496592,"type":"heatmap","id":"heatmap-0"},{"x":498.63413985180534,"y":7.005164334396389,"width":552.3371647509573,"height":491.92528735632163,"type":"heatmap","id":"heatmap-1"},{"x":2.3967355451043817,"y":504.1037974683543,"width":1053.8278481012658,"height":193.88607594936713,"type":"scatterplot","id":"scatterplot-2"},{"x":501.4228312795294,"y":4.260225266483587,"width":547.4888300152928,"height":493.3018878067399,"type":"scatterplot","id":"scatterplot-3"},{"x":8.686112002415339,"y":726.3949290046278,"width":1042.818232994856,"height":154.93420754986764,"type":"stripe_graph","id":"stripe_graph-4"},{"x":3.5471251975883433,"y":509.1073037329319,"width":1053.7610383952037,"height":189.97086449156564,"type":"stripe_graph","id":"stripe_graph-5"}],"relations":[{"vislist":[{"vislist":["heatmap-0","heatmap-1"],"relation":null,"id":"group-0"}],"relation":"repeated","id":"relation-0"}]},"2442_1":{"comp":[["pie_chart","pie_chart",["repeated"]]],"visType":["pie_chart"],"compType":["repeated"],"compressed_tree":[{"composite_pattern":"repeated","visualization_type":[["pie_chart"]]}],"coOccurrence":[["pie_chart","pie_chart",["coOccurrence"]]],"year":2013,"conference":["VAST"],"authors":["Amir Hossein Hajizadeh","Melanie Tory","Rock Leung"],"title":"Supporting Awareness through Collaborative Brushing and Linking of Tabular Data","doi":"10.1109/TVCG.2013.197","abstract":"Maintaining an awareness of collaborators\' actions is critical during collaborative work, including during collaborative visualization activities. Particularly when collaborators are located at a distance, it is important to know what everyone is working on in order to avoid duplication of effort, share relevant results in a timely manner and build upon each other\'s results. Can a person\'s brushing actions provide an indication of their queries and interests in a data set? Can these actions be revealed to a collaborator without substantially disrupting their own independent work? We designed a study to answer these questions in the context of distributed collaborative visualization of tabular data. Participants in our study worked independently to answer questions about a tabular data set, while simultaneously viewing brushing actions of a fictitious collaborator, shown directly within a shared workspace. We compared three methods of presenting the collaborator\'s actions: brushing &amp;amp; linking (i.e. highlighting exactly what the collaborator would see), selection (i.e. showing only a selected item), and persistent selection (i.e. showing only selected items but having them persist for some time). Our results demonstrated that persistent selection enabled some awareness of the collaborator\'s activities while causing minimal interference with independent work. Other techniques were less effective at providing awareness, and brushing &amp;amp; linking caused substantial interference. These findings suggest promise for the idea of exploiting natural brushing actions to provide awareness in collaborative work.","keywords":"Collaboration, awareness, attentionally ambient visualization, brushing and linking, linked views, user study","caption":"Fig. 2. Screen shot of a distributed collaboration prototype we devel- oped. Each user has their own work area where they can create charts. Shared parts of collaborators\u2019 workspaces may be viewed by selecting the appropriate tab.","img_size":{"width":1041,"height":609},"subfigures":[{"x":5.154433556528377,"y":4.110940870570365,"width":1031.339338576478,"height":600.1299882181294,"type":"interface","id":"interface-0"}],"visualizations":[{"x":48.09190371991244,"y":83.95404814004377,"width":261.1903719912473,"height":183.89934354485777,"type":"bar_chart","id":"bar_chart-0"},{"x":734.382932166302,"y":83.95404814004377,"width":278.5142231947484,"height":183.89934354485777,"type":"bar_chart","id":"bar_chart-1"},{"x":49.42450765864328,"y":331.8183807439825,"width":278.5142231947484,"height":183.89934354485774,"type":"line_chart","id":"line_chart-2"},{"x":409.2275711159738,"y":82.62144420131293,"width":183.89934354485774,"height":158.57986870897156,"type":"pie_chart","id":"pie_chart-3"},{"x":409.2275711159738,"y":330.4857768052517,"width":193.22757111597366,"height":159.91247264770243,"type":"pie_chart","id":"pie_chart-4"}],"relations":[{"vislist":[{"vislist":["pie_chart-3","pie_chart-4"],"relation":null,"id":"group-0"}],"relation":"repeated","id":"relation-0"}]},"2443_7":{"comp":[["comb","comb",["repeated"]],["matrix","matrix",["repeated"]],["area_chart","line_chart",["accompanied"]],["line_chart","area_chart",["accompanied"]],["graph","map",["coordinated"]]],"visType":["comb","matrix","area_chart","line_chart","graph","map"],"compType":["repeated","accompanied","coordinated"],"compressed_tree":[{"composite_pattern":"repeated","visualization_type":[[{"composite_pattern":"accompanied","visualization_type":[["area_chart","line_chart"]]}]]},{"composite_pattern":"coordinated","visualization_type":[["graph"],["map"]]},{"composite_pattern":"repeated","visualization_type":[["matrix"]]}],"coOccurrence":[["area_chart","line_chart",["coOccurrence"]],["area_chart","graph",["coOccurrence"]],["area_chart","map",["coOccurrence"]],["area_chart","matrix",["coOccurrence"]],["line_chart","graph",["coOccurrence"]],["line_chart","map",["coOccurrence"]],["line_chart","matrix",["coOccurrence"]],["graph","map",["coOccurrence"]],["graph","matrix",["coOccurrence"]],["map","matrix",["coOccurrence"]]],"year":2013,"conference":["VAST"],"authors":["Steffen Hadlak","Heidrun Schumann","Clemens H. Cap","Till Wollenberg"],"title":"Supporting the Visual Analysis of Dynamic Networks by Clustering associated Temporal Attributes","doi":"10.1109/TVCG.2013.198","abstract":"The visual analysis of dynamic networks is a challenging task. In this paper, we introduce a new approach supporting the discovery of substructures sharing a similar trend over time by combining computation, visualization and interaction. With existing techniques, their discovery would be a tedious endeavor because of the number of nodes, edges as well as time points to be compared. First, on the basis of the supergraph, we therefore group nodes and edges according to their associated attributes that are changing over time. Second, the supergraph is visualized to provide an overview of the groups of nodes and edges with similar behavior over time in terms of their associated attributes. Third, we provide specific interactions to explore and refine the temporal clustering, allowing the user to further steer the analysis of the dynamic network. We demonstrate our approach by the visual analysis of a large wireless mesh network.","keywords":"Dynamic networks, visualization, supergraph clustering","caption":"Fig. 8. The supergraph is clustered according to the time interval as selected in Figure 7c. The time points outside of this interval are faded out in gray. The clusters are laid out on top of a map ( c OpenStreetMap contributors). Cluster VII which shows a generally good link quality is highlighted in purple and the clusters (III, IV, V and VI) showing the drop-off are highlighted in red to orange. The network view reveals that these four clusters completely contain three connected villages dropping out at the same time. This was caused by a power outage in that region.","img_size":{"width":2160,"height":1209},"subfigures":[{"x":14.481502322032705,"y":18.420642736290823,"width":2142.614184549425,"height":1185.025532577397,"type":"interface","id":"interface-0"}],"visualizations":[{"x":1110.4234135667398,"y":55.55579868708972,"width":902.1203501094096,"height":145.5032822757112,"type":"area_chart","id":"area_chart-0"},{"x":1110.4234135667398,"y":206.3501094091904,"width":902.1203501094096,"height":156.08533916849018,"type":"area_chart","id":"area_chart-1"},{"x":1113.0689277899346,"y":370.3719912472648,"width":902.1203501094096,"height":150.79431072210065,"type":"area_chart","id":"area_chart-2"},{"x":1113.0689277899346,"y":526.457330415755,"width":899.4748358862148,"height":158.73085339168495,"type":"area_chart","id":"area_chart-3"},{"x":1113.0689277899346,"y":690.4792122538295,"width":910.0568927789935,"height":153.43982494529538,"type":"area_chart","id":"area_chart-4"},{"x":1113.0689277899346,"y":846.5645514223196,"width":910.0568927789935,"height":161.37636761487965,"type":"area_chart","id":"area_chart-5"},{"x":1113.0689277899346,"y":1010.5864332603941,"width":907.4113785557987,"height":150.7943107221007,"type":"area_chart","id":"area_chart-6"},{"x":13.22757111597366,"y":431.21881838074415,"width":1073.3862144420136,"height":772.4901531728667,"type":"graph","id":"graph-7"},{"x":1118.359956236324,"y":370.3719912472648,"width":899.4748358862148,"height":158.730853391685,"type":"line_chart","id":"line_chart-10"},{"x":1113.0689277899346,"y":526.457330415755,"width":902.1203501094096,"height":164.02188183807448,"type":"line_chart","id":"line_chart-11"},{"x":1113.0689277899346,"y":687.8336980306347,"width":910.0568927789935,"height":156.08533916849026,"type":"line_chart","id":"line_chart-12"},{"x":1110.4234135667398,"y":841.2735229759302,"width":912.7024070021885,"height":169.31291028446387,"type":"line_chart","id":"line_chart-13"},{"x":1110.4234135667398,"y":1007.9409190371991,"width":912.7024070021885,"height":153.43982494529553,"type":"line_chart","id":"line_chart-14"},{"x":1110.4234135667398,"y":55.555798687089734,"width":904.7658643326045,"height":158.73085339168495,"type":"line_chart","id":"line_chart-8"},{"x":1113.0689277899346,"y":208.99562363238516,"width":899.4748358862148,"height":153.43982494529538,"type":"line_chart","id":"line_chart-9"},{"x":17.826039387308697,"y":431.21881838074404,"width":1066.1422319474837,"height":774.3650600559375,"type":"map","id":"map-15"},{"x":226.59052549809186,"y":53.02927168079933,"width":312.32574849370405,"height":350.68773137795125,"type":"matrix","id":"matrix-25"},{"x":552.0773204173822,"y":46.29980377425295,"width":314.2098960144112,"height":364.1466671910433,"type":"matrix","id":"matrix-26"}],"relations":[{"vislist":[{"vislist":[{"vislist":[{"vislist":["area_chart-6","line_chart-14"],"relation":null,"id":"group-6"}],"relation":"accompanied","id":"relation-6"},{"vislist":[{"vislist":["area_chart-5","line_chart-13"],"relation":null,"id":"group-5"}],"relation":"accompanied","id":"relation-5"},{"vislist":[{"vislist":["line_chart-12","area_chart-4"],"relation":null,"id":"group-4"}],"relation":"accompanied","id":"relation-4"},{"vislist":[{"vislist":["line_chart-11","area_chart-3"],"relation":null,"id":"group-3"}],"relation":"accompanied","id":"relation-3"},{"vislist":[{"vislist":["line_chart-9","area_chart-1"],"relation":null,"id":"group-1"}],"relation":"accompanied","id":"relation-1"},{"vislist":[{"vislist":["area_chart-2","line_chart-10"],"relation":null,"id":"group-2"}],"relation":"accompanied","id":"relation-2"},{"vislist":[{"vislist":["area_chart-0","line_chart-8"],"relation":null,"id":"group-0"}],"relation":"accompanied","id":"relation-0"}],"relation":null,"id":"group-7"}],"relation":"repeated","id":"relation-7"},{"vislist":[{"vislist":["graph-7"],"relation":null,"id":"group-9"},{"vislist":["map-15"],"relation":null,"id":"group-8"}],"relation":"coordinated","id":"relation-8"},{"vislist":[{"vislist":["matrix-26","matrix-25"],"relation":null,"id":"group-10"}],"relation":"repeated","id":"relation-9"}]},"2447_2":{"comp":[["parallel_coordinate","parallel_coordinate",["repeated"]],["area_chart","comb",["accompanied"]],["comb","area_chart",["accompanied"]],["glyph_based","stripe_graph",["nested"]]],"visType":["parallel_coordinate","area_chart","comb","glyph_based","stripe_graph"],"compType":["repeated","accompanied","nested"],"compressed_tree":[{"composite_pattern":"repeated","visualization_type":[["parallel_coordinate"]]},{"composite_pattern":"repeated","visualization_type":[["parallel_coordinate"]]},{"composite_pattern":"repeated","visualization_type":[["parallel_coordinate"]]},{"composite_pattern":"accompanied","visualization_type":[["area_chart",{"composite_pattern":"nested","visualization_type":[["glyph_based"],["stripe_graph"]]}]]}],"coOccurrence":[["parallel_coordinate","glyph_based",["coOccurrence"]],["parallel_coordinate","stripe_graph",["coOccurrence"]],["parallel_coordinate","area_chart",["coOccurrence"]],["glyph_based","stripe_graph",["coOccurrence"]],["glyph_based","area_chart",["coOccurrence"]],["stripe_graph","area_chart",["coOccurrence"]]],"year":2013,"conference":["VAST"],"authors":["Philip A. Legg","David H. S. Chung","Matthew L. Parry","Rhodri Bown","Mark W. Jones","Iwan W. Griffiths","Min Chen"],"title":"Transformation of an Uncertain Video Search Pipeline to a Sketch-Based Visual Analytics Loop","doi":"10.1109/TVCG.2013.207","abstract":"Traditional sketch-based image or video search systems rely on machine learning concepts as their core technology. However, in many applications, machine learning alone is impractical since videos may not be semantically annotated sufficiently, there may be a lack of suitable training data, and the search requirements of the user may frequently change for different tasks. In this work, we develop a visual analytics systems that overcomes the shortcomings of the traditional approach. We make use of a sketch-based interface to enable users to specify search requirement in a flexible manner without depending on semantic annotation. We employ active machine learning to train different analytical models for different types of search requirements. We use visualization to facilitate knowledge discovery at the different stages of visual analytics. This includes visualizing the parameter space of the trained model, visualizing the search space to support interactive browsing, visualizing candidature search results to support rapid interaction for active learning while minimizing watching videos, and visualizing aggregated information of the search results. We demonstrate the system for searching spatiotemporal attributes from sports video to identify key instances of the team and player performance.","keywords":"Visual knowledge discovery, data clustering, machine learning, multimedia visualization","caption":"Fig. 2. The user interface consists of a number of interactive panels to encourage data exploration. The sketch input panel allows a user to draw a particular search query using intuitive sketch tools. The search results panel displays the top 12 video segments that correspond with the user sketch based on the current model parameters. The model visualization allows the user to analyse how each video segment corresponds to the different similarity metrics within the model. The search space visualization shows the overall similarity against the video timeline, in conjunction with match event data to provide context to the game. When the user accepts or rejects results, they are moved to the corresponding panels and the model is updated to reflect their decision, depicted by the weighting parameters in the model visualization.","img_size":{"width":1942,"height":1505},"subfigures":[{"x":23.232070932666293,"y":11.76669992401835,"width":1898.7394079600356,"height":1484.6700015027031,"type":"interface","id":"interface-0"}],"visualizations":[{"x":35.87588685524491,"y":930.9784832720267,"width":923.2993053872802,"height":274.84018533917424,"type":"area_chart","id":"area_chart-0"},{"x":39.085517872275396,"y":1078.9998178382305,"width":910.7728912077012,"height":127.02859322852939,"type":"glyph_based","id":"glyph_based-12"},{"x":51.59411746507873,"y":176.14073894798452,"width":897.704069705177,"height":325.94136078101394,"type":"parallel_coordinate","id":"parallel_coordinate-1"},{"x":976.4609399923676,"y":170.6934866882449,"width":915.1465275122101,"height":338.35877358210064,"type":"parallel_coordinate","id":"parallel_coordinate-2"},{"x":663.3814151456202,"y":540.9780806745268,"width":602.1828878330609,"height":329.0277634551775,"type":"parallel_coordinate","id":"parallel_coordinate-3"},{"x":40.504957283931894,"y":540.9780806745268,"width":153.13241821184369,"height":130.3694911803533,"type":"parallel_coordinate","id":"parallel_coordinate-4"},{"x":199.84544650436382,"y":574.0877927203309,"width":138.6469191918044,"height":91.05170812596099,"type":"parallel_coordinate","id":"parallel_coordinate-5"},{"x":350.9085077133447,"y":576.1571497231936,"width":136.57756218894156,"height":91.0517081259611,"type":"parallel_coordinate","id":"parallel_coordinate-6"},{"x":1298.674015024485,"y":540.9780806745268,"width":153.13241821184374,"height":126.23077717462786,"type":"parallel_coordinate","id":"parallel_coordinate-7"},{"x":1447.667719230603,"y":569.9490787146053,"width":151.06306120898077,"height":95.19042213168655,"type":"parallel_coordinate","id":"parallel_coordinate-8"},{"x":34.325596416638504,"y":1069.5154531644478,"width":920.2927341189705,"height":142.7939212253584,"type":"stripe_graph","id":"stripe_graph-13"}],"relations":[{"vislist":[{"vislist":["parallel_coordinate-5","parallel_coordinate-4","parallel_coordinate-6"],"relation":null,"id":"group-0"}],"relation":"repeated","id":"relation-0"},{"vislist":[{"vislist":["parallel_coordinate-3"],"relation":null,"id":"group-1"}],"relation":"repeated","id":"relation-1"},{"vislist":[{"vislist":["parallel_coordinate-8","parallel_coordinate-7"],"relation":null,"id":"group-2"}],"relation":"repeated","id":"relation-2"},{"vislist":[{"vislist":["area_chart-0",{"vislist":[{"vislist":["glyph_based-12"],"relation":null,"id":"group-4"},{"vislist":["stripe_graph-13"],"relation":null,"id":"group-3"}],"relation":"nested","id":"relation-3"}],"relation":null,"id":"group-5"}],"relation":"accompanied","id":"relation-4"}]},"2449_0":{"comp":[["bar_chart","bar_chart",["repeated"]]],"visType":["bar_chart"],"compType":["repeated"],"compressed_tree":[{"composite_pattern":"repeated","visualization_type":[["bar_chart"]]}],"coOccurrence":[["bar_chart","bar_chart",["coOccurrence"]]],"year":2013,"conference":["VAST"],"authors":["Jaegul Choo","Changhyun Lee","Chandan K. Reddy","Haesun Park"],"title":"UTOPIAN: User-Driven Topic Modeling Based on Interactive Nonnegative Matrix Factorization","doi":"10.1109/TVCG.2013.212","abstract":"Topic modeling has been widely used for analyzing text document collections. Recently, there have been significant advancements in various topic modeling techniques, particularly in the form of probabilistic graphical modeling. State-of-the-art techniques such as Latent Dirichlet Allocation (LDA) have been successfully applied in visual text analytics. However, most of the widely-used methods based on probabilistic modeling have drawbacks in terms of consistency from multiple runs and empirical convergence. Furthermore, due to the complicatedness in the formulation and the algorithm, LDA cannot easily incorporate various types of user feedback. To tackle this problem, we propose a reliable and flexible visual analytics system for topic modeling called UTOPIAN (User-driven Topic modeling based on Interactive Nonnegative Matrix Factorization). Centered around its semi-supervised formulation, UTOPIAN enables users to interact with the topic modeling method and steer the result in a user-driven manner. We demonstrate the capability of UTOPIAN via several usage scenarios with real-world document corpuses such as InfoVis/VAST paper data set and product review data sets.","keywords":"Latent Dirichlet allocation, nonnegative matrix factorization, topic modeling, visual analytics, interactive clustering, text analytics","caption":"Fig. 1. An overview of UTOPIAN. Given a scatter plot visualization generated by the modified t-SNE, UTOPIAN provides various interaction capabilities: (1) topic merging, (2) document-induced topic creation, (3) topic splitting, and (4) keyword-induced topic creation. Additionally, the user can refine topic keyword weights. The document viewer highlights the representative keywords from each topic.","img_size":{"width":1937,"height":982},"subfigures":[{"x":13.404881983017706,"y":4.5666886703418506,"width":1906.0102469031865,"height":973.9117190468327,"type":"interface","id":"interface-0"}],"visualizations":[{"x":621.4137931034484,"y":641.4980842911878,"width":263.37164750957845,"height":242.67816091954023,"type":"bar_chart","id":"bar_chart-0"},{"x":909.2413793103448,"y":643.3793103448277,"width":253.96551724137942,"height":242.67816091954023,"type":"bar_chart","id":"bar_chart-1"},{"x":32.590038314176184,"y":45.14942528735632,"width":368.72030651341,"height":167.42911877394636,"type":"scatterplot","id":"scatterplot-2"},{"x":11.896551724137849,"y":560.6053639846743,"width":551.1992337164752,"height":233.2720306513411,"type":"scatterplot","id":"scatterplot-3"},{"x":425.7662835249041,"y":139.21072796934865,"width":859.7203065134102,"height":436.4444444444445,"type":"scatterplot","id":"scatterplot-4"},{"x":1208.3563218390805,"y":3.063438642661032,"width":633.9731800766285,"height":400.7011494252873,"type":"scatterplot","id":"scatterplot-5"},{"x":1217.7624521072798,"y":598.2298850574713,"width":201.29118773946357,"height":361.1954022988506,"type":"table","id":"table-6"}],"relations":[{"vislist":[{"vislist":["bar_chart-0","bar_chart-1"],"relation":null,"id":"group-0"}],"relation":"repeated","id":"relation-0"}]},"2451_0":{"comp":[["matrix","matrix",["repeated"]]],"visType":["matrix"],"compType":["repeated"],"compressed_tree":[{"composite_pattern":"repeated","visualization_type":[["matrix"]]}],"coOccurrence":[["matrix","matrix",["coOccurrence"]]],"year":2013,"conference":["VAST"],"authors":["Jiawan Zhang","Kai Kang","Dajian Liu","Ye Yuan","E. Yanli"],"title":"Vis4Heritage: Visual Analytics Approach on Grotto Wall Painting Degradations","doi":"10.1109/TVCG.2013.219","abstract":"For preserving the grotto wall paintings and protecting these historic cultural icons from the damage and deterioration in nature environment, a visual analytics framework and a set of tools are proposed for the discovery of degradation patterns. In comparison with the traditional analysis methods that used restricted scales, our method provides users with multi-scale analytic support to study the problems on site, cave, wall and particular degradation area scales, through the application of multidimensional visualization techniques. Several case studies have been carried out using real-world wall painting data collected from a renowned World Heritage site, to verify the usability and effectiveness of the proposed method. User studies and expert reviews were also conducted through by domain experts ranging from scientists such as microenvironment researchers, archivists, geologists, chemists, to practitioners such as conservators, restorers and curators.","keywords":"Cultural heritage, wall paintings, degradation, visual analytics","caption":"Fig. 1. Interactive Visual Analytics on Wall Painting Degradations of Dunhuang Mogao Grottoes. (a) Overall site-level degradation visualization. The correlated caves are highlighted when cave 225 is selected; (b)Aggregated degradation visualization of caves in different floors in which spatial clustering patterns are obvious; (c) An illustrated Dunhuang Mogao Grottoes spatial profile; (d) Tem- poral degradation changes visualization; (e) Radar visualizations of high-dimensional degradation data; (f) Cave-scale degradations are visualized in glyphs and orthographic views.","img_size":{"width":1422,"height":760},"subfigures":[{"x":16.290756864080148,"y":4.21181872112604,"width":1396.6946133862855,"height":723.2672343419129,"type":"interface","id":"interface-0"}],"visualizations":[{"x":592.3438735177865,"y":9.01185770750984,"width":251.87451728681125,"height":180.26017294383118,"type":"area_chart","id":"area_chart-0"},{"x":62.56866987784746,"y":17.618836115829932,"width":426.5147867380591,"height":432.90794199965745,"type":"bar_chart","id":"bar_chart-1"},{"x":590.8418972332015,"y":7.5098814229248605,"width":255.33596837944677,"height":183.24110671936762,"type":"line_chart","id":"line_chart-2"},{"x":86.1778656126482,"y":390.51383399209493,"width":1272.1739130434783,"height":268.85375494071155,"type":"line_chart","id":"line_chart-3"},{"x":57.64031620553356,"y":645.8498023715417,"width":1362.1107370986153,"height":100.63241106719363,"type":"line_chart","id":"line_chart-4"},{"x":957.3241106719369,"y":7.5098814229248605,"width":444.58498023715424,"height":468.61660079051387,"type":"matrix","id":"matrix-5"},{"x":592.3438735177865,"y":201.26482213438734,"width":253.83399209486174,"height":261.3438735177866,"type":"polar_plot","id":"polar_plot-6"}],"relations":[{"vislist":[{"vislist":["matrix-5"],"relation":null,"id":"group-0"}],"relation":"repeated","id":"relation-0"}]},"2452_0":{"comp":[["map","map",["repeated"]],["table","table",["repeated"]],["bar_chart","table",["nested"]]],"visType":["map","table","bar_chart"],"compType":["repeated","nested"],"compressed_tree":[{"composite_pattern":"repeated","visualization_type":[["map"]]},{"composite_pattern":"nested","visualization_type":[["bar_chart"],["table"]]},{"composite_pattern":"nested","visualization_type":[["bar_chart"],["table"]]},{"composite_pattern":"nested","visualization_type":[["bar_chart"],["table"]]},{"composite_pattern":"nested","visualization_type":[["bar_chart"],["table"]]},{"composite_pattern":"nested","visualization_type":[["bar_chart"],["table"]]},{"composite_pattern":"repeated","visualization_type":[["table"]]}],"coOccurrence":[["map","bar_chart",["coOccurrence"]],["map","table",["coOccurrence"]],["bar_chart","table",["coOccurrence"]]],"year":2013,"conference":["VAST"],"authors":["Rachel Shadoan","Chris Weaver"],"title":"Visual Analysis of Higher-Order Conjunctive Relationships in Multidimensional Data Using a Hypergraph Query System","doi":"10.1109/TVCG.2013.220","abstract":"Visual exploration and analysis of multidimensional data becomes increasingly difficult with increasing dimensionality. We want to understand the relationships between dimensions of data, but lack flexible techniques for exploration beyond low-order relationships. Current visual techniques for multidimensional data analysis focus on binary conjunctive relationships between dimensions. Recent techniques, such as cross-filtering on an attribute relationship graph, facilitate the exploration of some higher-order conjunctive relationships, but require a great deal of care and precision to do so effectively. This paper provides a detailed analysis of the expressive power of existing visual querying systems and describes a more flexible approach in which users can explore n-ary conjunctive inter- and intra- dimensional relationships by interactively constructing queries as visual hypergraphs. In a hypergraph query, nodes represent subsets of values and hyperedges represent conjunctive relationships. Analysts can dynamically build and modify the query using sequences of simple interactions. The hypergraph serves not only as a query specification, but also as a compact visual representation of the interactive state. Using examples from several domains, focusing on the digital humanities, we describe the design considerations for developing the querying system and incorporating it into visual analysis tools. We analyze query expressiveness with regard to the kinds of questions it can and cannot pose, and describe how it simultaneously expands the expressiveness of and is complemented by cross-filtering.","keywords":"Graph search, graph query language, multidimensional data, attribute relationship graphs, multivariate data analysis, higher-order conjunctive queries, visual query language, digital humanities","caption":"Fig. 1. Candid, displaying the results of a query regarding the nationality and location of mistresses in the Electronic Enlightenment data set.","img_size":{"width":2163,"height":1163},"subfigures":[{"x":9.1769847783533,"y":10.32445284646553,"width":2142.170964330805,"height":1146.0642728162804,"type":"interface","id":"interface-0"}],"visualizations":[{"x":11.441301272984362,"y":44.41442715700133,"width":327.35077793493633,"height":590.5473833097597,"type":"bar_chart","id":"bar_chart-0"},{"x":368.40169731258834,"y":42.769448373408686,"width":333.93069306930687,"height":286.22630834512023,"type":"bar_chart","id":"bar_chart-1"},{"x":363.4667609618104,"y":368.4752475247524,"width":340.5106082036776,"height":266.48656294200856,"type":"bar_chart","id":"bar_chart-2"},{"x":1435.9929278642153,"y":41.12446958981603,"width":324.06082036775115,"height":587.2574257425744,"type":"bar_chart","id":"bar_chart-3"},{"x":1791.3083451202267,"y":368.4752475247524,"width":330.6407355021213,"height":263.1966053748233,"type":"bar_chart","id":"bar_chart-4"},{"x":730.2970297029703,"y":31.254596888260167,"width":695.8260254596889,"height":296.0961810466761,"type":"map","id":"map-5"},{"x":727.007072135785,"y":361.89533239038184,"width":702.4059405940598,"height":292.8062234794908,"type":"map","id":"map-6"},{"x":45.98585572842989,"y":750.1103253182462,"width":398.0848656294202,"height":312.5459688826027,"type":"graph","id":"graph-7"},{"x":745.1018387553042,"y":699.1159830268741,"width":1297.8882602545973,"height":460.4631507965251,"type":"graph","id":"graph-8"},{"x":1791.3083451202267,"y":41.12446958981603,"width":332.285714285714,"height":284.5813295615276,"type":"table","id":"table-9"},{"x":1792.9533239038192,"y":370.1202263083451,"width":332.2857142857142,"height":259.9066478076379,"type":"table","id":"table-10"},{"x":1435.9929278642153,"y":44.41442715700133,"width":325.7057991513436,"height":585.6124469589816,"type":"table","id":"table-11"},{"x":370.04667609618093,"y":41.12446958981603,"width":330.64073550212174,"height":287.8712871287129,"type":"table","id":"table-12"},{"x":363.4667609618104,"y":368.4752475247524,"width":340.5106082036776,"height":266.48656294200856,"type":"table","id":"table-13"},{"x":11.441301272984362,"y":41.12446958981603,"width":328.99575671852904,"height":593.837340876945,"type":"table","id":"table-14"}],"relations":[{"vislist":[{"vislist":["map-5","map-6"],"relation":null,"id":"group-0"}],"relation":"repeated","id":"relation-0"},{"vislist":[{"vislist":["bar_chart-0"],"relation":null,"id":"group-2"},{"vislist":["table-14"],"relation":null,"id":"group-1"}],"relation":"nested","id":"relation-1"},{"vislist":[{"vislist":["bar_chart-1"],"relation":null,"id":"group-4"},{"vislist":["table-12"],"relation":null,"id":"group-3"}],"relation":"nested","id":"relation-2"},{"vislist":[{"vislist":["bar_chart-2"],"relation":null,"id":"group-6"},{"vislist":["table-13"],"relation":null,"id":"group-5"}],"relation":"nested","id":"relation-3"},{"vislist":[{"vislist":["bar_chart-3"],"relation":null,"id":"group-8"},{"vislist":["table-11"],"relation":null,"id":"group-7"}],"relation":"nested","id":"relation-4"},{"vislist":[{"vislist":["bar_chart-4"],"relation":null,"id":"group-10"},{"vislist":["table-10"],"relation":null,"id":"group-9"}],"relation":"nested","id":"relation-5"},{"vislist":[{"vislist":["table-9","table-10","table-11","table-12","table-13","table-14"],"relation":null,"id":"group-11"}],"relation":"repeated","id":"relation-6"}]},"2452_8":{"comp":[["table","table",["repeated"]],["scatterplot","scatterplot",["repeated"]],["matrix","bar_chart",["stacked"]],["bar_chart","matrix",["stacked"]]],"visType":["table","scatterplot","matrix","bar_chart"],"compType":["repeated","stacked"],"compressed_tree":[{"composite_pattern":"repeated","visualization_type":[["table"]]},{"composite_pattern":"repeated","visualization_type":[["scatterplot"]]},{"composite_pattern":"stacked","visualization_type":[["matrix","bar_chart"]]}],"coOccurrence":[["table","scatterplot",["coOccurrence"]],["table","matrix",["coOccurrence"]],["table","bar_chart",["coOccurrence"]],["scatterplot","matrix",["coOccurrence"]],["scatterplot","bar_chart",["coOccurrence"]],["matrix","bar_chart",["coOccurrence"]]],"year":2013,"conference":["VAST"],"authors":["Rachel Shadoan","Chris Weaver"],"title":"Visual Analysis of Higher-Order Conjunctive Relationships in Multidimensional Data Using a Hypergraph Query System","doi":"10.1109/TVCG.2013.220","abstract":"Visual exploration and analysis of multidimensional data becomes increasingly difficult with increasing dimensionality. We want to understand the relationships between dimensions of data, but lack flexible techniques for exploration beyond low-order relationships. Current visual techniques for multidimensional data analysis focus on binary conjunctive relationships between dimensions. Recent techniques, such as cross-filtering on an attribute relationship graph, facilitate the exploration of some higher-order conjunctive relationships, but require a great deal of care and precision to do so effectively. This paper provides a detailed analysis of the expressive power of existing visual querying systems and describes a more flexible approach in which users can explore n-ary conjunctive inter- and intra- dimensional relationships by interactively constructing queries as visual hypergraphs. In a hypergraph query, nodes represent subsets of values and hyperedges represent conjunctive relationships. Analysts can dynamically build and modify the query using sequences of simple interactions. The hypergraph serves not only as a query specification, but also as a compact visual representation of the interactive state. Using examples from several domains, focusing on the digital humanities, we describe the design considerations for developing the querying system and incorporating it into visual analysis tools. We analyze query expressiveness with regard to the kinds of questions it can and cannot pose, and describe how it simultaneously expands the expressiveness of and is complemented by cross-filtering.","keywords":"Graph search, graph query language, multidimensional data, attribute relationship graphs, multivariate data analysis, higher-order conjunctive queries, visual query language, digital humanities","caption":"Fig. 5. Cinegraph extended, displaying actors involved with movies that won awards who were also involved in movies with a low rating.","img_size":{"width":2166,"height":1067},"subfigures":[{"x":7.238676161956414,"y":7.212261850763908,"width":2149.251776800509,"height":1053.7110341859272,"type":"interface","id":"interface-0"}],"visualizations":[{"x":498.16653716475236,"y":709.648391191702,"width":94.52693321604356,"height":265.93145810229834,"type":"bar_chart","id":"bar_chart-13"},{"x":186.25955185270215,"y":972.4301359343264,"width":312.93779840508853,"height":91.29131576636162,"type":"bar_chart","id":"bar_chart-14"},{"x":707.9653465346535,"y":457.2857142857143,"width":648.953323903819,"height":567.4568599717115,"type":"graph","id":"graph-0"},{"x":200.5097998656621,"y":707.0468247431482,"width":300.48598005210647,"height":264.7362285809178,"type":"matrix","id":"matrix-1"},{"x":7.699434229137169,"y":10.564356435643566,"width":316.9306930693069,"height":250.52616690240455,"type":"scatterplot","id":"scatterplot-2"},{"x":326.13932107496464,"y":253.5445544554456,"width":262.59971711456865,"height":291.2743988684583,"type":"scatterplot","id":"scatterplot-3"},{"x":10.717821782178193,"y":259.5813295615276,"width":313.9123055162659,"height":285.2376237623763,"type":"scatterplot","id":"scatterplot-4"},{"x":597.7942008486563,"y":31.6930693069307,"width":252.03536067892503,"height":316.9306930693069,"type":"table","id":"table-5"},{"x":873.9766619519096,"y":34.71145685997171,"width":639.8981612446959,"height":342.58698727015565,"type":"table","id":"table-6"},{"x":1541.0403111739745,"y":33.2022630834512,"width":301.8387553041018,"height":325.98585572843,"type":"table","id":"table-7"},{"x":1870.0445544554455,"y":33.2022630834512,"width":264.1089108910892,"height":150.9193776520509,"type":"table","id":"table-8"},{"x":1868.535360678925,"y":235.43422913719945,"width":261.0905233380481,"height":144.8826025459689,"type":"table","id":"table-9"}],"relations":[{"vislist":[{"vislist":["table-5","table-6","table-7","table-8","table-9"],"relation":null,"id":"group-0"}],"relation":"repeated","id":"relation-0"},{"vislist":[{"vislist":["scatterplot-2","scatterplot-3","scatterplot-4"],"relation":null,"id":"group-1"}],"relation":"repeated","id":"relation-1"},{"vislist":[{"vislist":["matrix-1","bar_chart-14","bar_chart-13"],"relation":null,"id":"group-3"}],"relation":"stacked","id":"relation-2"}]},"2458_0":{"comp":[["scatterplot","scatterplot",["repeated"]],["bar_chart","bar_chart",["repeated"]],["heatmap","map",["annotated"]]],"visType":["scatterplot","bar_chart","heatmap","map"],"compType":["repeated","annotated"],"compressed_tree":[{"composite_pattern":"repeated","visualization_type":[["scatterplot"]]},{"composite_pattern":"repeated","visualization_type":[["bar_chart"]]},{"composite_pattern":"annotated","visualization_type":[["heatmap"],["map"]]}],"coOccurrence":[["scatterplot","bar_chart",["coOccurrence"]],["scatterplot","heatmap",["coOccurrence"]],["scatterplot","map",["coOccurrence"]],["bar_chart","heatmap",["coOccurrence"]],["bar_chart","map",["coOccurrence"]],["heatmap","map",["coOccurrence"]]],"year":2013,"conference":["VAST"],"authors":["Zuchao Wang","Min Lu","Xiaoru Yuan","Junping Zhang","Huub van de Wetering"],"title":"Visual Traffic Jam Analysis Based on Trajectory Data","doi":"10.1109/TVCG.2013.228","abstract":"In this work, we present an interactive system for visual analysis of urban traffic congestion based on GPS trajectories. For these trajectories we develop strategies to extract and derive traffic jam information. After cleaning the trajectories, they are matched to a road network. Subsequently, traffic speed on each road segment is computed and traffic jam events are automatically detected. Spatially and temporally related events are concatenated in, so-called, traffic jam propagation graphs. These graphs form a high-level description of a traffic jam and its propagation in time and space. Our system provides multiple views for visually exploring and analyzing the traffic condition of a large city as a whole, on the level of propagation graphs, and on road segment level. Case studies with 24 days of taxi GPS trajectories collected in Beijing demonstrate the effectiveness of our system.","keywords":"Traffic visualization, traffic jam propagation","caption":"Fig. 1. An overview of our system. (a) The spatial view shows the traf\ufb01c jam density on each road of Beijing by color, and one traf\ufb01c jam propagation graph is highlighted in black. (b) The embedded road speed views show the speed patterns of four roads in the highlighted black propagation graph. (c) The graph list view shows a list of sorted traf\ufb01c jam propagation graphs. (d) The multi-faceted \ufb01lter view allows \ufb01ltering of propagation graphs by time and size. (e) The graph projection view shows the topological relationship of graph clusters, where graphs in the same cluster have very similar topology.","img_size":{"width":1987,"height":641},"subfigures":[{"x":9.445177947432414,"y":5.362118447831705,"width":1965.0028164797093,"height":630.2757631043362,"type":"interface","id":"interface-0"}],"visualizations":[{"x":750.6069609507642,"y":565.0797962648558,"width":603.8590831918507,"height":60.72325976230899,"type":"bar_chart","id":"bar_chart-0"},{"x":750.6069609507642,"y":447.00679117147706,"width":600.4855687606112,"height":102.89219015280145,"type":"bar_chart","id":"bar_chart-1"},{"x":18.55432937181664,"y":3.142515530700811,"width":716.8718166383701,"height":634.7149689385984,"type":"map","id":"map-4"},{"x":372.6971258181929,"y":92.52899420616308,"width":334.470646449817,"height":323.9369357285246,"type":"heatmap","id":"heatmap-6"},{"x":1362.8998302207135,"y":16.88370118845501,"width":605.5458404074705,"height":613.9796264855688,"type":"scatterplot","id":"scatterplot-2"},{"x":748.9202037351444,"y":37.12478777589134,"width":595.4252971137521,"height":396.3879456706282,"type":"scatterplot","id":"scatterplot-3"}],"relations":[{"vislist":[{"vislist":["scatterplot-3"],"relation":null,"id":"group-0"}],"relation":"repeated","id":"relation-0"},{"vislist":[{"vislist":["bar_chart-1"],"relation":null,"id":"group-3"}],"relation":"repeated","id":"relation-2"},{"vislist":[{"vislist":["heatmap-6"],"relation":null,"id":"group-4"},{"vislist":["map-4"],"relation":null,"id":"group-5"}],"relation":"annotated","id":"relation-3"}]},"1435_10":{"comp":[["line_chart","line_chart",["repeated"]]],"visType":["line_chart"],"compType":["repeated"],"compressed_tree":[{"composite_pattern":"repeated","visualization_type":[["line_chart"]]}],"coOccurrence":[["line_chart","line_chart",["coOccurrence"]]],"year":2006,"conference":["InfoVis"],"authors":["Jeffrey Heer","Maneesh Agrawala"],"title":"Multi-Scale Banking to 45 Degrees","doi":"10.1109/TVCG.2006.163","abstract":"In his text Visualizing Data, William Cleveland demonstrates how the aspect ratio of a line chart can affect an analyst\'s perception of trends in the data. Cleveland proposes an optimization technique for computing the aspect ratio such that the average absolute orientation of line segments in the chart is equal to 45 degrees. This technique, called banking to 45deg, is designed to maximize the discriminability of the orientations of the line segments in the chart. In this paper, we revisit this classic result and describe two new extensions. First, we propose alternate optimization criteria designed to further improve the visual perception of line segment orientations. Second, we develop multi-scale banking, a technique that combines spectral analysis with banking to 45deg. Our technique automatically identifies trends at various frequency scales and then generates a banked chart for each of these scales. We demonstrate the utility of our techniques in a range of visualization tools and analysis examples","keywords":"Information visualization, banking to 45 degrees, line charts, time-series, sparklines, graphical perception","caption":"Figure 9. Trend Explorer application, visualizing a segment of electroencephalogram (EEG) readings. An interactive spectrum view shows trends identified by the multi-scale banking algorithm and enables users to select different filtering points, triggering recalculation of the aspect ratio. By selecting a data range in the line chart (shown in the image on the left), users can \u201czoom\u201d into subsets of data (shown in the image on the right).","img_size":{"width":2073,"height":570},"subfigures":[{"x":4.899928142648519,"y":5.355248120489388,"width":1024.7946413354666,"height":559.289503759019,"type":"interface","id":"interface-0"}],"visualizations":[{"x":17.005742411812964,"y":89.43396226415095,"width":972.7284659557015,"height":151.35110746513539,"type":"line_chart","id":"line_chart-0"},{"x":1073.062346185398,"y":87.73337991399977,"width":981.2313371616079,"height":156.45283829764912,"type":"line_chart","id":"line_chart-1"},{"x":23.808039376538147,"y":245.8867924528302,"width":965.9261689909764,"height":277.19360131255127,"type":"line_chart","id":"line_chart-2"},{"x":1076.4634946677606,"y":245.8867924528302,"width":962.5250205086137,"height":278.8941755537326,"type":"line_chart","id":"line_chart-3"}],"relations":[{"vislist":[{"vislist":["line_chart-0","line_chart-2"],"relation":null,"id":"group-0"}],"relation":"repeated","id":"relation-0"}]},"1445_4":{"comp":[["tree","tree",["repeated"]]],"visType":["tree"],"compType":["repeated"],"compressed_tree":[{"composite_pattern":"repeated","visualization_type":[["tree"]]}],"coOccurrence":[],"year":2006,"conference":["InfoVis"],"authors":["Christian Hein","Gerik Scheuermann","Christoph Flamm","Ivo L. Hofacker","Peter F. Stadler"],"title":"Visualization of Barrier Tree Sequences","doi":"10.1109/TVCG.2006.196","abstract":"Dynamical models that explain the formation of spatial structures of RNA molecules have reached a complexity that requires novel visualization methods that help to analyze the validity of these models. We focus on the visualization of so-called folding landscapes of a growing RNA molecule. Folding landscapes describe the energy of a molecule as a function of its spatial configuration; thus they are huge and high dimensional. Their most salient features, however, are encapsulated by their so-called barrier tree that reflects the local minima and their connecting saddle points. For each length of the growing RNA chain there exists a folding landscape. We visualize the sequence of folding landscapes by an animation of the corresponding barrier trees. To generate the animation, we adapt the foresight layout with tolerance algorithm for general dynamic graph layout problems. Since it is very general, we give a detailed description of each phase: constructing a supergraph for the trees, layout of that supergraph using a modified DOT algorithm, and presentation techniques for the final animation","keywords":"Graph drawing, dynamic graph, RNA folding, energy landscape, fitness landscape, barrier tree","caption":"Fig. 5. The 20 subgraph layouts of the ATT sequence.","img_size":{"width":2137,"height":1914},"subfigures":[{"x":8.713515655776977,"y":12.310277866953998,"width":542.6679980359003,"height":406.6081474587589,"type":"single","id":"single-0"}],"visualizations":[{"x":32.666666666666515,"y":62.33333333333334,"width":2097.7969838537824,"height":1845.130317187116,"type":"small_multiple","id":"small_multiple-0"},{"x":25.107367977475775,"y":58.43564891209508,"width":2099.8684034612975,"height":1838.9581649491774,"type":"tree","id":"tree-1"}],"relations":[{"vislist":[{"vislist":["tree-1"],"relation":null,"id":"group-0"}],"relation":"repeated","id":"relation-0"}]},"1447_16":{"comp":[["bar_chart","bar_chart",["repeated"]]],"visType":["bar_chart"],"compType":["repeated"],"compressed_tree":[{"composite_pattern":"repeated","visualization_type":[["bar_chart"]]}],"coOccurrence":[["bar_chart","bar_chart",["coOccurrence"]]],"year":2006,"conference":["InfoVis"],"authors":["Roel Vliegen","Jarke J. van Wijk","Erik-Jan van der Linden"],"title":"Visualizing Business Data with Generalized Treemaps","doi":"10.1109/TVCG.2006.200","abstract":"Business data is often presented using simple business graphics. These familiar visualizations are effective for providing overviews, but fall short for the presentation of large amounts of detailed information. Treemaps can provide such detail, but are often not easy to understand. We present how standard treemap algorithms can be adapted such that the results mimic familiar business graphics. Specifically, we present the use of different layout algorithms per level, a number of variations of the squarified algorithm, the use of variable borders, and the use of non-rectangular shapes. The combined use of these leads to histograms, pie charts and a variety of other styles","keywords":"Information visualization, treemap, business graphics, hierarchical data","caption":"Fig. 16: School results (detail of Figure 15).","img_size":{"width":1093,"height":411},"subfigures":[{"x":4.1833814341269235,"y":2.745452398241435,"width":1083.60836492521,"height":407.5596498317283,"type":"single","id":"single-0"}],"visualizations":[{"x":10.516356638871152,"y":22.16484926234768,"width":1038.3149454778702,"height":377.18665811417577,"type":"bar_chart","id":"bar_chart-0"},{"x":9.815266196279744,"y":21.463758819756272,"width":1039.717126363053,"height":376.48556767158436,"type":"small_multiple","id":"small_multiple-1"}],"relations":[{"vislist":[{"vislist":["bar_chart-0"],"relation":null,"id":"group-0"}],"relation":"repeated","id":"relation-0"}]},"1449_0":{"comp":[["line_chart","line_chart",["repeated"]]],"visType":["line_chart"],"compType":["repeated"],"compressed_tree":[{"composite_pattern":"repeated","visualization_type":[["line_chart"]]}],"coOccurrence":[["line_chart","line_chart",["coOccurrence"]]],"year":2006,"conference":["VAST"],"authors":["Paul E. Keel"],"title":"Collaborative Visual Analytics: Inferring from the Spatial Organization and Collaborative Use of Information","doi":"10.1109/VAST.2006.261415","abstract":"We introduce a visual analytics environment for the support of remote-collaborative sense-making activities. Team members use their individual graphical interfaces to collect, organize and comprehend task-relevant information relative to their areas of expertise. A system of computational agents infers possible relationships among information items through the analysis of the spatial and temporal organization and collaborative use of information. The computational agents support the exchange of information among team members to converge their individual contributions. Our system allows users to navigate vast amounts of shared information effectively and remotely dispersed team members to work independently without diverting from common objectives as well as to minimize the necessary amount of verbal communication","keywords":"Visual analytics, Spatial information organization,Indirect human computer interaction,Indirect collaboration, Agents,Sense-making","caption":"Figure 1: Workspace window (below) and Kiosk window (above)","img_size":{"width":1017,"height":897},"subfigures":[{"x":8.832051860478598,"y":237.07326330669923,"width":1004.0386604521414,"height":660.2420063782856,"type":"interface","id":"interface-0"}],"visualizations":[{"x":241.02076832014848,"y":710.5816030391544,"width":68.1077886082354,"height":89.59888533620956,"type":"graph","id":"graph-0"},{"x":732.0871312990994,"y":581.1708205456092,"width":105.4495020026164,"height":184.3127905809979,"type":"line_chart","id":"line_chart-2"},{"x":845.7849646379221,"y":582.1637817528378,"width":128.02112574307677,"height":176.20078599116812,"type":"line_chart","id":"line_chart-3"},{"x":726.8081601631017,"y":420.30078172459855,"width":179.72459673412817,"height":111.5331761291398,"type":"map","id":"map-1"},{"x":547.8741832707528,"y":322.88973242766497,"width":150.3883163417577,"height":84.59109997458435,"type":"tree","id":"tree-5"}],"relations":[{"vislist":[{"vislist":["line_chart-3"],"relation":null,"id":"group-0"}],"relation":"repeated","id":"relation-0"}]},"1451_5":{"comp":[["line_chart","line_chart",["repeated"]]],"visType":["line_chart"],"compType":["repeated"],"compressed_tree":[{"composite_pattern":"repeated","visualization_type":[["line_chart"]]}],"coOccurrence":[["line_chart","line_chart",["coOccurrence"]]],"year":2006,"conference":["VAST"],"authors":["Stephen G. Eick","Justin Mauger","Alan Ratner"],"title":"Visualizing the Performance of Computational Linguistics Algorithms","doi":"10.1109/VAST.2006.261417","abstract":"We have built a visualization system and analysis portal for evaluating the performance of computational linguistics algorithms. Our system focuses on algorithms that classify and cluster documents by assigning weights to words and scoring each document against high dimensional reference concept vectors. The visualization and algorithm analysis techniques include confusion matrices, ROC curves, document visualizations showing word importance, and interactive reports. One of the unique aspects of our system is that the visualizations are thin-client Web-based components built using SVG visualization components","keywords":"AJAX, thin-client, SVG, ROC curves, confusion matrices, document categorization","caption":"Figure 2. Linked (log-transformed) ROC and Confusion Matrices.","img_size":{"width":1812,"height":1248},"subfigures":[{"x":11.309981131868344,"y":5.18688221770999,"width":1793.74143928441,"height":1239.8094533115661,"type":"interface","id":"interface-0"}],"visualizations":[{"x":265.54802259887003,"y":265.5819209039548,"width":242.0790960451977,"height":237.37853107344628,"type":"line_chart","id":"line_chart-0"},{"x":559.3333333333333,"y":270.2824858757062,"width":235.02824858757046,"height":235.02824858757063,"type":"line_chart","id":"line_chart-1"},{"x":554.6327683615818,"y":580.5197740112994,"width":242.0790960451977,"height":232.677966101695,"type":"line_chart","id":"line_chart-2"},{"x":267.89830508474574,"y":580.5197740112994,"width":235.0282485875706,"height":232.677966101695,"type":"line_chart","id":"line_chart-3"},{"x":561.683615819209,"y":890.7570621468925,"width":232.6779661016949,"height":235.02824858757063,"type":"line_chart","id":"line_chart-4"},{"x":267.89830508474574,"y":888.406779661017,"width":235.0282485875706,"height":239.7288135593219,"type":"line_chart","id":"line_chart-5"},{"x":933.4942528735631,"y":262.9885057471264,"width":583.3563218390804,"height":729.1954022988505,"type":"matrix","id":"matrix-6"},{"x":1219.7627118644066,"y":1076.4293785310736,"width":272.63276836158184,"height":129.26553672316368,"type":"table","id":"table-7"}],"relations":[{"vislist":[{"vislist":["line_chart-0","line_chart-1","line_chart-2","line_chart-3","line_chart-4","line_chart-5"],"relation":null,"id":"group-0"}],"relation":"repeated","id":"relation-0"}]},"1455_4":{"comp":[["others","others",["repeated"]]],"visType":["others"],"compType":["repeated"],"compressed_tree":[{"composite_pattern":"repeated","visualization_type":[["others"]]}],"coOccurrence":[["others","others",["coOccurrence"]]],"year":2006,"conference":["VAST"],"authors":["Mark Sifer"],"title":"User Interfaces for the Exploration of Hierarchical Multi-dimensional Data","doi":"10.1109/VAST.2006.261422","abstract":"A variety of user interfaces have been developed to support the querying of hierarchical multi-dimensional data in an OLAP setting such as pivot tables and Polaris. They are used to regularly check portions of a dataset and to explore a new dataset for the first time. In this paper, we establish criteria for OLAP user interface capabilities to facilitate comparison. Two criteria are the number of displayed dimensions along which comparisons can be made and the number of dimensions that are viewable at once - visual comparison depth and width. We argue that interfaces with greater visual comparison depth support regular checking of known data by users that know roughly where to look, while interfaces with greater comparison width support exploration of new data by users that have no a priori starting point and need to scan all dimensions. Pivot tables and Polaris are examples of the former. The main contribution of this paper is to introduce a new scalable interface that uses parallel dimension axis which supports the latter, greater visual comparison width. We compare our approach to both table based and parallel coordinate based interfaces. We present an implementation of our interface SGViewer, user scenarios and provide an evaluation that supports the usability of our interface","keywords":"Data exploration, OLAP, visualization, parallel coordinates","caption":"Figure 4. The SGViewer tool presenting sales data.","img_size":{"width":1895,"height":1035},"subfigures":[{"x":6.166645368165677,"y":6.085151606407956,"width":1884.4753673249622,"height":1024.6402980436967,"type":"interface","id":"interface-0"}],"visualizations":[{"x":131.11995542532898,"y":60.55380667165299,"width":1691.262843325653,"height":811.8252778612908,"type":"others","id":"others-0"}],"relations":[{"vislist":[{"vislist":["others-0"],"relation":null,"id":"group-0"}],"relation":"repeated","id":"relation-0"}]},"1457_9":{"comp":[["graph","graph",["repeated"]]],"visType":["graph"],"compType":["repeated"],"compressed_tree":[{"composite_pattern":"repeated","visualization_type":[["graph"]]}],"coOccurrence":[["graph","graph",["coOccurrence"]]],"year":2006,"conference":["VAST"],"authors":["Zaixian Xie","Shiping Huang","Matthew O. Ward","Elke A. Rundensteiner"],"title":"Exploratory Visualization of Multivariate Data with Variable Quality","doi":"10.1109/VAST.2006.261424","abstract":"Real-world data is known to be imperfect, suffering from various forms of defects such as sensor variability, estimation errors, uncertainty, human errors in data entry, and gaps in data gathering. Analysis conducted on variable quality data can lead to inaccurate or incorrect results. An effective visualization system must make users aware of the quality of their data by explicitly conveying not only the actual data content, but also its quality attributes. While some research has been conducted on visualizing uncertainty in spatio-temporal data and univariate data, little work has been reported on extending this capability into multivariate data visualization. In this paper we describe our approach to the problem of visually exploring multivariate data with variable quality. As a foundation, we propose a general approach to defining quality measures for tabular data, in which data may experience quality problems at three granularities: individual data values, complete records, and specific dimensions. We then present two approaches to visual mapping of quality information into display space. In particular, one solution embeds the quality measures as explicit values into the original dataset by regarding value quality and record quality as new data dimensions. The other solution is to superimpose the quality information within the data visualizations using additional visual variables. We also report on user studies conducted to assess alternate mappings of quality attributes to visual variables for the second method. In addition, we describe case studies that expose some of the advantages and disadvantages of these two approaches","keywords":"Uncertainty visualization, multivariate visualization,data quality","caption":"Figure 10: Sample of star glyphs (dataset:an adaptation of cars, value quality:line width, record quality:brightness )","img_size":{"width":915,"height":516},"subfigures":[{"x":18.077072299024692,"y":13.747553253961625,"width":886.9612589275647,"height":495.7263060397964,"type":"single","id":"single-0"}],"visualizations":[{"x":14.15517241379311,"y":9.885057471264368,"width":894.5977011494251,"height":502.16091482666724,"type":"graph","id":"graph-0"}],"relations":[{"vislist":[{"vislist":["graph-0"],"relation":null,"id":"group-0"}],"relation":"repeated","id":"relation-0"}]},"1459_0":{"comp":[["bar_chart","bar_chart",["repeated"]]],"visType":["bar_chart"],"compType":["repeated"],"compressed_tree":[{"composite_pattern":"repeated","visualization_type":[["bar_chart"]]}],"coOccurrence":[["bar_chart","bar_chart",["coOccurrence"]]],"year":2006,"conference":["VAST"],"authors":["Hyunmo Kang","Catherine Plaisant","Bongshin Lee","Benjamin B. Bederson"],"title":"NetLens: Iterative Exploration of Content-Actor Network Data","doi":"10.1109/VAST.2006.261426","abstract":"Networks have remained a challenge for information retrieval and visualization because of the rich set of tasks that users want to accomplish. This paper offers an abstract content-actor network data model, a classification of tasks, and a tool to support them. The NetLens interface was designed around the abstract content-actor network data model to allow users to pose a series of elementary queries and iteratively refine visual overviews and sorted lists. This enables the support of complex queries that are traditionally hard to specify. NetLens is general and scalable in that it applies to any dataset that can be represented with our abstract data model. This paper describes NetLens applying a subset of the ACM Digital Library consisting of about 4,000 papers from the CM I conference written by about 6,000 authors. In addition, we are now working on a collection of half a million emails, and a dataset of legal cases","keywords":"Human-Computer Interaction, information visualization, network visualization, content-actor network data, iterative query refinement, incremental data exploration, user interfaces, digital library, piccolo","caption":"Figure 1. NetLens has two symmetric windows. The left is for Content (papers), the right for Actors (authors). Each side is further divided into panels; overview at the top, filters on the right, and lists at the bottom. Here the Content side has two lists to reflect the citation or reference relationship between papers. The paper overview panel shows the distribution of papers (in logarithmic scale) over time, grouped by topics. Users can see which topics have seen their number of papers increase or decrease over 22 years. On the right side the overview of the authors shows the distribution of countries of origin in logarithmic scale.","img_size":{"width":1722,"height":1290},"subfigures":[{"x":-1.191004319505302,"y":7.584391857262061,"width":1719.8739027716497,"height":1277.0879077066372,"type":"interface","id":"interface-1"}],"visualizations":[{"x":20.473197781885347,"y":181.2199630314233,"width":612.8096118299445,"height":152.60628465804072,"type":"bar_chart","id":"bar_chart-0"},{"x":22.85767097966726,"y":367.2088724584103,"width":612.8096118299445,"height":145.452865064695,"type":"bar_chart","id":"bar_chart-1"},{"x":27.62661737523104,"y":572.2735674676525,"width":605.6561922365988,"height":128.76155268022183,"type":"bar_chart","id":"bar_chart-2"},{"x":886.0369685767097,"y":193.14232902033274,"width":598.5027726432531,"height":650.9611829944547,"type":"bar_chart","id":"bar_chart-3"},{"x":22.85767097966726,"y":739.1866913123845,"width":610.4251386321625,"height":114.45471349353045,"type":"bar_chart","id":"bar_chart-4"},{"x":867.9786768676798,"y":931.0151269284768,"width":836.0102379670985,"height":337.829090575159,"type":"table","id":"table-5"},{"x":433.62698898533256,"y":931.0151269284768,"width":419.02735482243077,"height":323.2177751047951,"type":"table","id":"table-6"},{"x":4.405376608474716,"y":927.2840021433001,"width":416.2957486136783,"height":331.71784628553553,"type":"table","id":"table-7"}],"relations":[{"vislist":[{"vislist":["bar_chart-0","bar_chart-1","bar_chart-2","bar_chart-4"],"relation":null,"id":"group-0"}],"relation":"repeated","id":"relation-0"}]},"1460_0":{"comp":[["comb","comb",["repeated"]],["unit_visualization","bar_chart",["nested"]]],"visType":["comb","unit_visualization","bar_chart"],"compType":["repeated","nested"],"compressed_tree":[{"composite_pattern":"repeated","visualization_type":[[{"composite_pattern":"nested","visualization_type":[["unit_visualization"],["bar_chart"]]}]]}],"coOccurrence":[["unit_visualization","bar_chart",["coOccurrence"]]],"year":2006,"conference":["VAST"],"authors":["Pascale Proulx","Sumeet Tandon","Adam Bodnar","David Schroh","Robert Harpe","William Wright"],"title":"Avian Flu Case Study with nSpace and GeoTime","doi":"10.1109/VAST.2006.261427","abstract":"GeoTime and nSpace are new analysis tools that provide innovative visual analytic capabilities. This paper uses an epidemiology analysis scenario to illustrate and discuss these new investigative methods and techniques. In addition, this case study is an exploration and demonstration of the analytical synergy achieved by combining GeoTime\'s geo-temporal analysis capabilities, with the rapid information triage, scanning and sense-making provided by nSpace. A fictional analyst works through the scenario from the initial brainstorming through to a final collaboration and report. With the efficient knowledge acquisition and insights into large amounts of documents, there is more time for the analyst to reason about the problem and imagine ways to mitigate threats. The use of both nSpace and GeoTime initiated a synergistic exchange of ideas, where hypotheses generated in either software tool could be cross-referenced, refuted, and supported by the other tool","keywords":"visual analytics, information visualization, human information interaction, sense making, geo-spatial information systems, temporal analysis, user centered design","caption":"Figure 1: TRIST interface. Left column: Launch Queries, Query History, and Dimensions panes. Middle column: Displayed dimensions with categorized results and Document Viewer. Right column: Entities pane.","img_size":{"width":1014,"height":834},"subfigures":[{"x":6.3692722056495805,"y":3.4561111770667767,"width":1002.719025896371,"height":827.0877776458656,"type":"interface","id":"interface-0"}],"visualizations":[{"x":170.68390804597698,"y":59.114934910302864,"width":663.0459770114942,"height":103.85058233107642,"type":"bar_chart","id":"bar_chart-0"},{"x":169.0862068965516,"y":193.32183146202698,"width":671.0344827586208,"height":123.02298850574711,"type":"bar_chart","id":"bar_chart-1"},{"x":169.0862068965516,"y":351.49424525513047,"width":656.655172413793,"height":134.20690417015683,"type":"bar_chart","id":"bar_chart-2"},{"x":14.109195402298779,"y":418.59770114942523,"width":145.39080459770122,"height":95.86206896551727,"type":"tree","id":"tree-3"},{"x":10.9137931034482,"y":629.494252873563,"width":132.6091954022989,"height":172.55172413793105,"type":"tree","id":"tree-4"},{"x":169.0862068965516,"y":59.114934910302864,"width":667.8390804597701,"height":100.65517241379308,"type":"unit_visualization","id":"unit_visualization-5"},{"x":170.68390804597698,"y":196.5172337608776,"width":669.4367816091955,"height":116.63218390804596,"type":"unit_visualization","id":"unit_visualization-6"},{"x":165.89080459770105,"y":348.2988429562799,"width":661.448275862069,"height":139,"type":"unit_visualization","id":"unit_visualization-7"}],"relations":[{"vislist":[{"vislist":[{"vislist":[{"vislist":["unit_visualization-5","unit_visualization-6","unit_visualization-7"],"relation":null,"id":"group-0"},{"vislist":["bar_chart-0","bar_chart-1","bar_chart-2"],"relation":null,"id":"group-1"}],"relation":"nested","id":"relation-0"}],"relation":null,"id":"group-2"}],"relation":"repeated","id":"relation-1"}]},"1461_2":{"comp":[["stripe_graph","stripe_graph",["repeated"]],["matrix","bar_chart",["stacked"]],["bar_chart","matrix",["stacked"]]],"visType":["stripe_graph","matrix","bar_chart"],"compType":["repeated","stacked"],"compressed_tree":[{"composite_pattern":"stacked","visualization_type":[["matrix","bar_chart"]]},{"composite_pattern":"repeated","visualization_type":[["stripe_graph"]]}],"coOccurrence":[["matrix","bar_chart",["coOccurrence"]],["matrix","stripe_graph",["coOccurrence"]],["bar_chart","stripe_graph",["coOccurrence"]]],"year":2006,"conference":["VAST"],"authors":["Chris Weaver","David Fyfe","Anthony C. Robinson","Deryck Holdsworth","Donna Peuquet","Alan M. MacEachren"],"title":"Visual Analysis of Historic Hotel Visitation Patterns","doi":"10.1109/VAST.2006.261428","abstract":"Understanding the space and time characteristics of human interaction in complex social networks is a critical component of visual tools for intelligence analysis, consumer behavior analysis, and human geography. Visual identification and comparison of patterns of recurring events is an essential feature of such tools. In this paper, we describe a tool for exploring hotel visitation patterns in and around Rebersburg, Pennsylvania from 1898-1900. The tool uses a wrapping spreadsheet technique, called reruns, to display cyclic patterns of geographic events in multiple overlapping natural and artificial calendars. Implemented as an improvise visualization, the tool is in active development through a iterative process of data collection, hypothesis, design, discovery, and evaluation in close collaboration with historical geographers. Several discoveries have inspired ongoing data collection and plans to expand exploration to include historic weather records and railroad schedules. Distributed online evaluations of usability and usefulness have resulted in numerous feature and design recommendations","keywords":"Geovisualization, exploratory visualization, historical geography, coordinated multiple views, travel pattern analysis","caption":"Figure 3: The hotels visualization. The map shows travel on Sunday, September 2, 1900 (Labor Day weekend) by 42 visitors to the Rebersburg Hotel, including three who came from places unknown. Although many guests may have come from places on rail lines or rivers, the location of the hotel in Rebersburg suggests that a portion of each trip may have been in coaches, by horse, on foot, or by similar means.","img_size":{"width":2115,"height":1350},"subfigures":[{"x":6.0065619140622735,"y":5.627195615351205,"width":2105.346662392237,"height":1343.4689163949868,"type":"interface","id":"interface-0"}],"visualizations":[{"x":14.191884344911214,"y":1050.0164357390327,"width":1170.6258413260261,"height":246.89797333554586,"type":"arc_diagram","id":"arc_diagram-9"},{"x":1072.5389686822998,"y":229.53604810526002,"width":130.36029794830642,"height":694.998986067674,"type":"bar_chart","id":"bar_chart-7"},{"x":400.4596800927713,"y":938.5201300169007,"width":670.4621376870991,"height":99.93227667597667,"type":"bar_chart","id":"bar_chart-8"},{"x":1208.323578753259,"y":202.86969708497742,"width":885.0187308304553,"height":728.6773298037205,"type":"graph","id":"graph-1"},{"x":1203.6206896551728,"y":199.1379310344828,"width":889.1932201136101,"height":733.8540813136361,"type":"map","id":"map-0"},{"x":406.07536764705884,"y":238.23529411764704,"width":672.6561248812998,"height":693.817915301329,"type":"matrix","id":"matrix-2"},{"x":1208.0708419990847,"y":202.94913219044201,"width":882.3928843345271,"height":728.8020283241012,"type":"scatterplot","id":"scatterplot-3"},{"x":224.45381512387033,"y":268.0879825710907,"width":129.5075819349532,"height":302.6840762524387,"type":"stripe_graph","id":"stripe_graph-4"},{"x":216.7818940375134,"y":691.3222958351138,"width":134.69788537425123,"height":296.36152769429805,"type":"stripe_graph","id":"stripe_graph-5"},{"x":1212.360332680412,"y":1045.4931346917654,"width":873.7701820254706,"height":244.94804177882273,"type":"table","id":"table-6"}],"relations":[{"vislist":[{"vislist":["matrix-2","bar_chart-7","bar_chart-8"],"relation":null,"id":"group-0"}],"relation":"stacked","id":"relation-0"},{"vislist":[{"vislist":["stripe_graph-4","stripe_graph-5"],"relation":null,"id":"group-1"}],"relation":"repeated","id":"relation-1"}]},"1461_4":{"comp":[["stripe_graph","stripe_graph",["repeated"]],["bar_chart","matrix",["stacked"]],["matrix","bar_chart",["stacked"]]],"visType":["stripe_graph","bar_chart","matrix"],"compType":["repeated","stacked"],"compressed_tree":[{"composite_pattern":"repeated","visualization_type":[["stripe_graph"]]},{"composite_pattern":"stacked","visualization_type":[["bar_chart","matrix"]]}],"coOccurrence":[["stripe_graph","bar_chart",["coOccurrence"]],["stripe_graph","matrix",["coOccurrence"]],["bar_chart","matrix",["coOccurrence"]]],"year":2006,"conference":["VAST"],"authors":["Chris Weaver","David Fyfe","Anthony C. Robinson","Deryck Holdsworth","Donna Peuquet","Alan M. MacEachren"],"title":"Visual Analysis of Historic Hotel Visitation Patterns","doi":"10.1109/VAST.2006.261428","abstract":"Understanding the space and time characteristics of human interaction in complex social networks is a critical component of visual tools for intelligence analysis, consumer behavior analysis, and human geography. Visual identification and comparison of patterns of recurring events is an essential feature of such tools. In this paper, we describe a tool for exploring hotel visitation patterns in and around Rebersburg, Pennsylvania from 1898-1900. The tool uses a wrapping spreadsheet technique, called reruns, to display cyclic patterns of geographic events in multiple overlapping natural and artificial calendars. Implemented as an improvise visualization, the tool is in active development through a iterative process of data collection, hypothesis, design, discovery, and evaluation in close collaboration with historical geographers. Several discoveries have inspired ongoing data collection and plans to expand exploration to include historic weather records and railroad schedules. Distributed online evaluations of usability and usefulness have resulted in numerous feature and design recommendations","keywords":"Geovisualization, exploratory visualization, historical geography, coordinated multiple views, travel pattern analysis","caption":"Figure 5: Variation in regular visits due to weather. The days high- lighted in the reruns view involve recorded extreme winter conditions.","img_size":{"width":1014,"height":861},"subfigures":[{"x":7.4571024037772355,"y":5.072614689468134,"width":1002.094531704664,"height":853.8671912623367,"type":"interface","id":"interface-0"}],"visualizations":[{"x":902.2838946039224,"y":207.9313875740481,"width":90.21396277356973,"height":543.9249098578159,"type":"bar_chart","id":"bar_chart-4"},{"x":524.6442840213659,"y":754.6539976956333,"width":377.46763348660835,"height":84.29885575808426,"type":"bar_chart","id":"bar_chart-5"},{"x":344.53160919540244,"y":176.48850574712642,"width":557.5057471264367,"height":575.6494252873563,"type":"matrix","id":"matrix-0"},{"x":187.99685163188786,"y":224.59168298488052,"width":106.7281470553329,"height":226.87354688333616,"type":"stripe_graph","id":"stripe_graph-1"},{"x":180.56060880347312,"y":574.3266582627145,"width":114.04664856769863,"height":226.87354688333605,"type":"stripe_graph","id":"stripe_graph-2"}],"relations":[{"vislist":[{"vislist":["stripe_graph-1","stripe_graph-2"],"relation":null,"id":"group-0"}],"relation":"repeated","id":"relation-0"},{"vislist":[{"vislist":["bar_chart-4","bar_chart-5","matrix-0"],"relation":null,"id":"group-1"}],"relation":"stacked","id":"relation-1"}]},"1464_8":{"comp":[["comb","comb",["repeated"]],["stripe_graph","table",["nested"]],["arc_diagram","arc_diagram",["mirrored"]]],"visType":["comb","stripe_graph","table","arc_diagram"],"compType":["repeated","nested","mirrored"],"compressed_tree":[{"composite_pattern":"mirrored","visualization_type":[["arc_diagram"]]},{"composite_pattern":"repeated","visualization_type":[[{"composite_pattern":"nested","visualization_type":[["stripe_graph"],["table"]]}]]}],"coOccurrence":[["arc_diagram","stripe_graph",["coOccurrence"]],["arc_diagram","table",["coOccurrence"]],["stripe_graph","table",["coOccurrence"]]],"year":2006,"conference":["VAST"],"authors":["Chaomei Chen","Fidelia Ibekwe-Sanjuan","Eric SanJuan","Chris Weaver"],"title":"Visual Analysis of Conflicting Opinions","doi":"10.1109/VAST.2006.261431","abstract":"Understanding the nature and dynamics of conflicting opinions is a profound and challenging issue. In this paper we address several aspects of the issue through a study of more than 3,000 Amazon customer reviews of the controversial bestseller The Da Vinci Code, including 1,738 positive and 918 negative reviews. The study is motivated by critical questions such as: what are the differences between positive and negative reviews? What is the origin of a particular opinion? How do these opinions change over time? To what extent can differentiating features be identified from unstructured text? How accurately can these features predict the category of a review? We first analyze terminology variations in these reviews in terms of syntactic, semantic, and statistic associations identified by TermWatch and use term variation patterns to depict underlying topics. We then select the most predictive terms based on log likelihood tests and demonstrate that this small set of terms classifies over 70% of the conflicting reviews correctly. This feature selection process reduces the dimensionality of the feature space from more than 20,000 dimensions to a couple of hundreds. We utilize automatically generated decision trees to facilitate the understanding of conflicting opinions in terms of these highly predictive terms. This study also uses a number of visualization and modeling tools to identify not only what positive and negative reviews have in common, but also they differ and evolve over time","keywords":"Visual Analytics, Intelligence analysis, Problemsolving environments, Visual Knowledge Discovery","caption":"Figure 8: Coordinated views generated by Improvise.","img_size":{"width":1023,"height":630},"subfigures":[{"x":1.8047980551398546,"y":3.7193332443137623,"width":1016.0856958405545,"height":625.8676488493538,"type":"interface","id":"interface-0"}],"visualizations":[{"x":563.5093457943927,"y":74.57943363724469,"width":429.81308411214945,"height":208.03738317757012,"type":"graph","id":"graph-0"},{"x":15.939252336448591,"y":314.0186859736933,"width":989.1588785046729,"height":294.39252336448607,"type":"arc_diagram","id":"arc_diagram-1"},{"x":433.9766355140187,"y":70.65419999238487,"width":86.355140186916,"height":217.8504672897197,"type":"stripe_graph","id":"stripe_graph-2"},{"x":167.06074766355147,"y":66.72896634752506,"width":92.24299065420551,"height":219.81308411214954,"type":"stripe_graph","id":"stripe_graph-3"},{"x":19.534283411226244,"y":68.69158316995495,"width":235.9710620849123,"height":219.81308411214977,"type":"table","id":"table-4"},{"x":282.39038707547127,"y":66.72896634752502,"width":234.75130099441694,"height":225.70093457943912,"type":"table","id":"table-5"}],"relations":[{"vislist":[{"vislist":["arc_diagram-1"],"relation":null,"id":"group-0"}],"relation":"mirrored","id":"relation-0"},{"vislist":[{"vislist":[{"vislist":[{"vislist":["stripe_graph-2"],"relation":null,"id":"group-3"},{"vislist":["table-5"],"relation":null,"id":"group-4"}],"relation":"nested","id":"relation-2"},{"vislist":[{"vislist":["stripe_graph-3"],"relation":null,"id":"group-1"},{"vislist":["table-4"],"relation":null,"id":"group-2"}],"relation":"nested","id":"relation-1"}],"relation":null,"id":"group-5"}],"relation":"repeated","id":"relation-3"}]},"1465_3":{"comp":[["graph","graph",["repeated"]]],"visType":["graph"],"compType":["repeated"],"compressed_tree":[{"composite_pattern":"repeated","visualization_type":[["graph"]]}],"coOccurrence":[],"year":2006,"conference":["VAST"],"authors":["Pak Chung Wong","George Chin Jr.","Harlan Foote","Patrick Mackey","James J. Thomas"],"title":"Have Green - A Visual Analytics Framework for Large Semantic Graphs","doi":"10.1109/VAST.2006.261432","abstract":"A semantic graph is a network of heterogeneous nodes and links annotated with a domain ontology. In intelligence analysis, investigators use semantic graphs to organize concepts and relationships as graph nodes and links in hopes of discovering key trends, patterns, and insights. However, as new information continues to arrive from a multitude of sources, the size and complexity of the semantic graphs will soon overwhelm an investigator\'s cognitive capacity to carry out significant analyses. We introduce a powerful visual analytics framework designed to enhance investigators\' natural analytical capabilities to comprehend and analyze large semantic graphs. The paper describes the overall framework design, presents major development accomplishments to date, and discusses future directions of a new visual analytics system known as Have Green","keywords":"Visual Analytics, Graph and Network Visualization, Information Analytics, Information Visualization","caption":"Figure 4:a) Greenland visualizes a small world network with major hierarchies highlighted by the red rectangles. b) A portion of the graph in a). c) A scatterplot generated by scaling the signatures in b). d) Brushing and linking between the scatterplot and the graph.","img_size":{"width":2034,"height":2201},"subfigures":[{"x":17.41187432993162,"y":26.547231813446796,"width":1986.9966506495362,"height":1458.1944234044506,"type":"single","id":"single-0"}],"visualizations":[{"x":12.493769470404912,"y":20.57009345794393,"width":1988.4423676012461,"height":1460.4766355140187,"type":"graph","id":"graph-0"},{"x":1359.5101754499628,"y":1565.2496084183952,"width":640.3419785116071,"height":587.7535068464026,"type":"graph","id":"graph-1"},{"x":688.2338018411772,"y":1565.2496084183952,"width":646.5288575310426,"height":584.6600673366847,"type":"graph","id":"graph-2"},{"x":19.82437725549744,"y":1569.3395058472074,"width":641.665803592208,"height":577.4992232329871,"type":"graph","id":"graph-3"}],"relations":[{"vislist":[{"vislist":["graph-1","graph-2","graph-3"],"relation":null,"id":"group-0"}],"relation":"repeated","id":"relation-0"}]},"1467_3":{"comp":[["others","others",["repeated"]]],"visType":["others"],"compType":["repeated"],"compressed_tree":[{"composite_pattern":"repeated","visualization_type":[["others"]]}],"coOccurrence":[],"year":2006,"conference":["VAST"],"authors":["Avin Pattath","Brian D. Bue","Yun Jang","David S. Ebert","Xuan Zhong","Aaron Ault","Edward J. Coyle"],"title":"Interactive Visualization and Analysis of Network and Sensor Data on Mobile Devices","doi":"10.1109/VAST.2006.261434","abstract":"Mobile devices are rapidly gaining popularity due to their small size and their wide range of functionality. With the constant improvement in wireless network access, they are an attractive option not only for day to day use. but also for in-field analytics by first responders in widespread areas. However, their limited processing, display, graphics and power resources pose a major challenge in developing effective applications. Nevertheless, they are vital for rapid decision making in emergencies when combined with appropriate analysis tools. In this paper, we present an efficient, interactive visual analytic system using a PDA to visualize network information from Purdue\'s Ross-Ade Stadium during football games as an example of in-held data analytics combined with text and video analysis. With our system, we can monitor the distribution of attendees with mobile devices throughout the stadium through their access of information and association/disassociation from wireless access points, enabling the detection of crowd movement and event activity. Through correlative visualization and analysis of synchronized video (instant replay video) and text information (play statistics) with the network activity, we can provide insightful information to network monitoring personnel, safety personnel and analysts. This work provides a demonstration and testbed for mobile sensor analytics that will help to improve network performance and provide safety personnel with information for better emergency planning and guidance","keywords":"mobile visualization, network visualization, visual analytics","caption":"Figure 4: Different screen modes of our visualization showing (a) Main Screen: Main screen with APs, time slider and screen buttons. The row of four APs at the bottom are the south score board APs, the rightmost column represents the APs mounted outside the pavilion and the remaining are the ones mounted inside the pavilion. (b) Network Event Screen: Association/Disassociation events of the current (blue) and previous time interval (grey). If there are multiple movements in the same direction between two APs, its exploded view is shown in a blue screen inset into the main screen. (c) Video Event Screen: Video Access per AP and Individual video access details. Inset, is the text describing the event corresponding to a selected video from the Video Event SubScreen. (d) Hybrid Screen: Hybrid mode showing both (b) and (c). (e) Video Statistics Screen: Video download statistics in the form of a stacked bar graph, and text description corresponding to a selected video from the graph. Color legend is displayed on the left, with abbreviated names for each play type. (f) Popular Video Screen: Three most popular videos from the current time interval, along with their number of accesses are displayed. Video link plays the associated video and the text description corresponding to the game event is displayed below the video link. (g) Game Text Screen: Game play-by-play events as text. (h) Play by Play Visualization Screen: Visualization of play-by-play events in the current time interval, shown as drives for each team.","img_size":{"width":2058,"height":1461},"subfigures":[{"x":1543.1126002291821,"y":0.29193087643614646,"width":517.5657983034655,"height":672.9852204281918,"type":"single","id":"single-0"},{"x":-1.9516432383830833,"y":740.8070064708628,"width":519.5769667232715,"height":677.9448849773426,"type":"single","id":"single-1"},{"x":1540.3913577177973,"y":743.0492346034895,"width":521.5492302213495,"height":669.4457224022088,"type":"single","id":"single-2"}],"visualizations":[{"x":15.929906542056074,"y":748.7119113573408,"width":476.0046728971963,"height":446.03107929686485,"type":"bar_chart","id":"bar_chart-0"},{"x":1570.7498281913124,"y":741.6831983236518,"width":468.89175163352223,"height":620.2124998400508,"type":"others","id":"others-1"},{"x":28.42585540813156,"y":4.51280136457157,"width":2009.1297360115839,"height":641.7662234389749,"type":"others","id":"others-2"}],"relations":[{"vislist":[{"vislist":["others-2"],"relation":null,"id":"group-0"}],"relation":"repeated","id":"relation-0"}]},"1468_7":{"comp":[["scatterplot","scatterplot",["repeated"]]],"visType":["scatterplot"],"compType":["repeated"],"compressed_tree":[{"composite_pattern":"repeated","visualization_type":[["scatterplot"]]}],"coOccurrence":[["scatterplot","scatterplot",["coOccurrence"]]],"year":2006,"conference":["VAST"],"authors":["Weichao Wang","Aidong Lu"],"title":"Interactive Wormhole Detection in Large Scale Wireless Networks","doi":"10.1109/VAST.2006.261435","abstract":"Wormhole attacks in wireless networks can severely deteriorate the network performance and compromise the security through spoiling the routing protocols and weakening the security enhancements. This paper develops an approach, interactive visualization of wormholes (IVoW), to monitor and detect such attacks in large scale wireless networks in real time. We characterize the topology features of a network under wormhole attacks through the node position changes and visualize the information at dynamically adjusted scales. We integrate an automatic detection algorithm with appropriate user interactions to handle complicated scenarios that include a large number of moving nodes and multiple worm-hole attackers. Various visual forms have been adopted to assist the understanding and analysis of the reconstructed network topology and improve the detection accuracy. Extended simulation has demonstrated that the proposed approach can effectively locate the fake neighbor connections without introducing many false alarms. IVoW does not require the wireless nodes to be equipped with any special hardware, thus avoiding any additional cost. The proposed approach demonstrates that interactive visualization can be successfully combined with network security mechanisms to greatly improve the intrusion detection capabilities","keywords":"Interactive Detection, Wormhole Attacks, Visualization on Network Security, Wireless Networks, Topology Visualization","caption":"Figure 8: Our wormhole detection interface. The left top locates the history window, left bottom includes parameter window and topology interaction window, and the right lists the identities and information of the potential attackers.","img_size":{"width":984,"height":615},"subfigures":[{"x":3.789963083638634,"y":5.742819376088092,"width":689.4596751794928,"height":605.6660902773048,"type":"interface","id":"interface-0"}],"visualizations":[{"x":233.89759036144588,"y":274.9799196787149,"width":420.7028112449799,"height":312.02811244979927,"type":"graph","id":"graph-0"},{"x":22.22789736726481,"y":45.573985742289615,"width":656.5928672226119,"height":165.76756077508003,"type":"scatterplot","id":"scatterplot-1"}],"relations":[{"vislist":[{"vislist":["scatterplot-1"],"relation":null,"id":"group-0"}],"relation":"repeated","id":"relation-0"}]},"1474_1":{"comp":[["others","others",["repeated"]]],"visType":["others"],"compType":["repeated"],"compressed_tree":[{"composite_pattern":"repeated","visualization_type":[["others"]]}],"coOccurrence":[["others","others",["coOccurrence"]]],"year":2006,"conference":["VAST"],"authors":["Bryan Mehta","Srinivasan Parthasarath","Raghu Machiraju"],"title":"Visual Exploration of Spatio-temporal Relationships for Scientific Data","doi":"10.1109/VAST.2006.261451","abstract":"Spatio-temporal relationships among features extracted from temporally-varying scientific datasets can provide useful information about the evolution of an individual feature and its interactions with other features. However, extracting such useful relationships without user guidance is cumbersome and often an error prone process. In this paper, we present a visual analysis system that interactively discovers such relationships from the trajectories of derived features. We describe analysis algorithms to derive various spatial and spatio-temporal relationships. A visual interface is presented using which the user can interactively select spatial and temporal extents to guide the knowledge discovery process. We show the usefulness of our proposed algorithms on datasets originating from computational fluid dynamics. We also demonstrate how the derived relationships can help in explaining the occurrence of critical events like merging and bifurcation of the vortices","keywords":"Knowledge Discovery, Scientific Analytics, Trajectory Analysis, Feature Extraction, Spatio-temporal Predicates, Visual Analytics","caption":"Figure 2: Overview of the Visual Interface","img_size":{"width":1650,"height":1182},"subfigures":[{"x":8.634757679540467,"y":6.935040468205715,"width":1638.9269250175778,"height":1168.1299190635877,"type":"interface","id":"interface-0"}],"visualizations":[{"x":368.9115811371699,"y":173.66826414575374,"width":535.9341752098497,"height":694.2020370547399,"type":"others","id":"others-0"},{"x":926.3140746278245,"y":184.11681383202787,"width":336.70682619619726,"height":343.94709090787563,"type":"scatterplot","id":"scatterplot-1"}],"relations":[{"vislist":[{"vislist":["others-0"],"relation":null,"id":"group-0"}],"relation":"repeated","id":"relation-0"}]},"2906_10":{"comp":[["scivis","scivis",["repeated"]],["comb","comb",["repeated"]],["line_chart","scatterplot",["accompanied"]],["scatterplot","line_chart",["accompanied"]]],"visType":["scivis","comb","line_chart","scatterplot"],"compType":["repeated","accompanied"],"compressed_tree":[{"composite_pattern":"repeated","visualization_type":[["scivis"]]},{"composite_pattern":"repeated","visualization_type":[["scivis"]]},{"composite_pattern":"repeated","visualization_type":[["scivis"]]},{"composite_pattern":"repeated","visualization_type":[["scivis"]]},{"composite_pattern":"repeated","visualization_type":[[{"composite_pattern":"accompanied","visualization_type":[["line_chart","scatterplot"]]}]]}],"coOccurrence":[["scivis","scivis",["coOccurrence"]]],"year":2017,"conference":["SciVis"],"authors":["Julien Tierny","Guillaume Favelier","Joshua A. Levine","Charles Gueunet","Michael Michaux"],"title":"The Topology ToolKit","doi":"10.1109/TVCG.2017.2743938","abstract":"This system paper presents the Topology ToolKit (TTK), a software platform designed for the topological analysis of scalar data in scientific visualization. While topological data analysis has gained in popularity over the last two decades, it has not yet been widely adopted as a standard data analysis tool for end users or developers. TTK aims at addressing this problem by providing a unified, generic, efficient, and robust implementation of key algorithms for the topological analysis of scalar data, including: critical points, integral lines, persistence diagrams, persistence curves, merge trees, contour trees, Morse-Smale complexes, fiber surfaces, continuous scatterplots, Jacobi sets, Reeb spaces, and more. TTK is easily accessible to end users due to a tight integration with ParaView. It is also easily accessible to developers through a variety of bindings (Python, VTK/C++) for fast prototyping or through direct, dependency-free, C++, to ease integration into pre-existing complex systems. While developing TTK, we faced several algorithmic and software engineering challenges, which we document in this paper. In particular, we present an algorithm for the construction of a discrete gradient that complies to the critical points extracted in the piecewise-linear setting. This algorithm guarantees a combinatorial consistency across the topological abstractions supported by TTK, and importantly, a unified implementation of topological data simplification for multi-scale exploration and analysis. We also present a cached triangulation data structure, that supports time efficient and generic traversals, which self-adjusts its memory usage on demand for input simplicial meshes and which implicitly emulates a triangulation for regular grids with no memory overhead. Finally, we describe an original software architecture, which guarantees memory efficient and direct accesses to TTK features, while still allowing for researchers powerful and easy bindings and extensions. TTK is open source (BSD license) and its code. online documentation and video tutorials are available on TTK\'s website [108].","keywords":"Topological data analysis,scalar data,data segmentation,feature extraction,bivariate data,uncertain data","caption":"Fig. 9. Gallery of TTK pipelines executed in ParaView. From top left to bottom right: (i) The contour tree can be used for shape skeletonization. Skeleton noise is removed by imposing the level of simplification dictated by the persistence diagram in the bottom linked view. (ii) The interior 1-separatrices of the Morse-Smale complex emanating from 2-saddles directly capture the atomic and covalent structure of molecules (electron density). (iii) The cells of the Morse-complex (colored regions) enable segmenting and tracking features during viscous fingering [52]. (iv) Fiber surfaces (bottom right) from user strokes in the continuous scatter plot (top) enable an easy classification of the features in molecular systems [74]. (v) The Reeb space (top left) enables peeling continuous scatterplots (bottom left) into layers where the fibers are made of only one connected component in the volume [107]. This enables localized inspections of the scatterplots (bottom right). (vi) Mandatory critical points (colored regions) provide predictions on the location and function values of critical points for uncertain scalar fields with non-uniform error [58]. These regions always admit at least one critical point for any function randomly generated from this error (top and bottom, vortices in computational fluid dynamics). ","img_size":{"width":2151,"height":927},"subfigures":[{"x":1509.3665485322797,"y":0.20738713351991203,"width":639.0048131448044,"height":457.97252674047706,"type":"interface","id":"interface-0"},{"x":764.8983316811673,"y":5.767783196585363,"width":635.7774384477276,"height":442.36740256657015,"type":"interface","id":"interface-1"},{"x":761.5488085899551,"y":459.8750643885598,"width":639.1132303662894,"height":464.65174009592624,"type":"interface","id":"interface-2"},{"x":1517.192892366372,"y":470.9793972982057,"width":630.0786340043419,"height":451.41173837218406,"type":"interface","id":"interface-3"},{"x":17.162681266901632,"y":467.68476851457905,"width":635.7216766130929,"height":456.87991292749535,"type":"interface","id":"interface-4"}],"visualizations":[{"x":1941.1659152881234,"y":53.272248593697746,"width":200.03897577831444,"height":182.89760053942476,"type":"line_chart","id":"line_chart-2"},{"x":1973.7176335412075,"y":512.7141567994528,"width":166.2183058539455,"height":187.65536049803399,"type":"line_chart","id":"line_chart-20"},{"x":1972.36916794946,"y":710.1199268242669,"width":168.91523703744065,"height":195.77795072271857,"type":"line_chart","id":"line_chart-21"},{"x":1939.8417013085354,"y":245.72235859443282,"width":206.76776459598491,"height":202.60143390362532,"type":"line_chart","id":"line_chart-4"},{"x":1976.3980885217657,"y":519.4091519377704,"width":158.13715532049704,"height":178.35227985135361,"type":"scatterplot","id":"scatterplot-11"},{"x":1973.2501946641219,"y":700.6561290474809,"width":164.78428057309938,"height":207.89403022636267,"type":"scatterplot","id":"scatterplot-12"},{"x":860.4620732143139,"y":42.456129919585905,"width":536.1652358922572,"height":399.3391969155638,"type":"scivis","id":"scivis-0"},{"x":1614.4027133688423,"y":39.88531959008723,"width":323.1184680124549,"height":205.58454891668939,"type":"scivis","id":"scivis-1"},{"x":1614.604458657503,"y":706.1069309157131,"width":356.71798458925974,"height":205.16624574981077,"type":"scivis","id":"scivis-10"},{"x":141.02736523721907,"y":503.2030025328255,"width":500.6642616433867,"height":194.41694014141868,"type":"scivis","id":"scivis-13"},{"x":377.3560411040664,"y":700.8164411853055,"width":261.94759913010324,"height":211.96793546204307,"type":"scivis","id":"scivis-14"},{"x":117.03761864669255,"y":702.1012935225036,"width":258.93813387125505,"height":205.3113211576909,"type":"scivis","id":"scivis-15"},{"x":1613.0952662590273,"y":240.33419391636158,"width":332.53396366290997,"height":206.56624720984212,"type":"scivis","id":"scivis-3"},{"x":871.1332933545433,"y":516.7081270369468,"width":286.32258753604754,"height":181.02972323303135,"type":"scivis","id":"scivis-5"},{"x":1170.3133134012896,"y":515.5254059891861,"width":207.52849675765412,"height":194.29359100843587,"type":"scivis","id":"scivis-6"},{"x":1160.818476765521,"y":708.8501263257948,"width":214.2770874537048,"height":203.76676455960305,"type":"scivis","id":"scivis-7"},{"x":865.5591309245635,"y":703.3087275171772,"width":268.90838638653815,"height":210.76265254688272,"type":"scivis","id":"scivis-8"},{"x":1610.5276942673906,"y":508.60505233447464,"width":359.4310322248293,"height":189.06205337806287,"type":"scivis","id":"scivis-9"}],"relations":[{"vislist":[{"vislist":["scivis-1","scivis-3"],"relation":null,"id":"group-0"}],"relation":"repeated","id":"relation-0"},{"vislist":[{"vislist":["scivis-14","scivis-15","scivis-13"],"relation":null,"id":"group-1"}],"relation":"repeated","id":"relation-1"},{"vislist":[{"vislist":["scivis-5","scivis-6","scivis-8","scivis-7"],"relation":null,"id":"group-2"}],"relation":"repeated","id":"relation-2"},{"vislist":[{"vislist":["scivis-9","scivis-10"],"relation":null,"id":"group-3"}],"relation":"repeated","id":"relation-3"},{"vislist":[{"vislist":[{"vislist":[{"vislist":["line_chart-21","scatterplot-12"],"relation":null,"id":"group-4"}],"relation":"accompanied","id":"relation-4"},{"vislist":[{"vislist":["scatterplot-11","line_chart-20"],"relation":null,"id":"group-5"}],"relation":"accompanied","id":"relation-5"}],"relation":null,"id":"group-6"}],"relation":"repeated","id":"relation-6"}]},"2916_10":{"comp":[["others","others",["repeated"]],["bar_chart","line_chart",["accompanied"]],["line_chart","bar_chart",["accompanied"]]],"visType":["others","bar_chart","line_chart"],"compType":["repeated","accompanied"],"compressed_tree":[{"composite_pattern":"accompanied","visualization_type":[["bar_chart","line_chart"]]},{"composite_pattern":"repeated","visualization_type":[["others"]]}],"coOccurrence":[["bar_chart","line_chart",["coOccurrence"]],["bar_chart","others",["coOccurrence"]],["line_chart","others",["coOccurrence"]]],"year":2017,"conference":["SciVis"],"authors":["Tran Minh Quan","Junyoung Choi","Haejin Jeong","Won-Ki Jeong"],"title":"An Intelligent System Approach for Probabilistic Volume Rendering Using Hierarchical 3D Convolutional Sparse Coding","doi":"10.1109/TVCG.2017.2744078","abstract":"In this paper, we propose a novel machine learning-based voxel classification method for highly-accurate volume rendering. Unlike conventional voxel classification methods that incorporate intensity-based features, the proposed method employs dictionary based features learned directly from the input data using hierarchical multi-scale 3D convolutional sparse coding, a novel extension of the state-of-the-art learning-based sparse feature representation method. The proposed approach automatically generates high-dimensional feature vectors in up to 75 dimensions, which are then fed into an intelligent system built on a random forest classifier for accurately classifying voxels from only a handful of selection scribbles made directly on the input data by the user. We apply the probabilistic transfer function to further customize and refine the rendered result. The proposed method is more intuitive to use and more robust to noise in comparison with conventional intensity-based classification methods. We evaluate the proposed method using several synthetic and real-world volume datasets, and demonstrate the methods usability through a user study.","keywords":"Volume Rendering,Machine Learning,Hierarchically Convolutional Sparse Coding","caption":"Fig. 8: Volume rendering and user interface window. The user can use a paint-brush tool to select voxels on the x-y-z plane view (bottom center, three black windows with selections). Each label is assigned with a one-dimensional transfer function (top center). ","img_size":{"width":1056,"height":483},"subfigures":[{"x":1.187055629924278,"y":2.7620611176854117,"width":1053.0755096137539,"height":476.9259528331601,"type":"interface","id":"interface-0"}],"visualizations":[{"x":441.8871834116756,"y":36.83021048750004,"width":406.5988292663004,"height":165.16713787922066,"type":"bar_chart","id":"bar_chart-1"},{"x":438.5726601714791,"y":35.498979050498,"width":412.5601458433053,"height":165.15373838450375,"type":"line_chart","id":"line_chart-2"},{"x":428.71198842293535,"y":295.54925177824487,"width":103.09064696945559,"height":150.79118061725492,"type":"others","id":"others-3"},{"x":571.2343561606326,"y":292.97367295534144,"width":106.50522975824936,"height":159.28716622396195,"type":"others","id":"others-4"},{"x":710.7806877123666,"y":290.0587851385983,"width":146.58746047487813,"height":128.99279987971633,"type":"others","id":"others-5"},{"x":91.71751556655457,"y":77.26957179096168,"width":237.5538307436444,"height":329.1298220102565,"type":"scivis","id":"scivis-0"}],"relations":[{"vislist":[{"vislist":["bar_chart-1","line_chart-2"],"relation":null,"id":"group-0"}],"relation":"accompanied","id":"relation-0"},{"vislist":[{"vislist":["others-3","others-4","others-5"],"relation":null,"id":"group-1"}],"relation":"repeated","id":"relation-1"}]},"2919_0":{"comp":[["comb","comb",["repeated"]],["bar_chart","bar_chart",["repeated","mirrored"]],["bar_chart","table",["nested"]],["bar_chart","parallel_coordinate",["nested"]],["heatmap","heatmap",["repeated"]],["heatmap","matrix",["nested"]],["box_plot","table",["nested"]],["area_chart","parallel_coordinate",["nested"]],["others","map",["coordinated"]]],"visType":["comb","bar_chart","table","parallel_coordinate","heatmap","matrix","box_plot","area_chart","others","map"],"compType":["repeated","mirrored","nested","coordinated"],"compressed_tree":[{"composite_pattern":"repeated","visualization_type":[[{"composite_pattern":"coordinated","visualization_type":[["others"],["map"]]}]]},{"composite_pattern":"repeated","visualization_type":[[{"composite_pattern":"coordinated","visualization_type":[["others"],["map"]]}]]},{"composite_pattern":"nested","visualization_type":[["box_plot","bar_chart"],["table"]]},{"composite_pattern":"nested","visualization_type":[["heatmap"],["matrix"]]},{"composite_pattern":"mirrored","visualization_type":[["bar_chart"]]},{"composite_pattern":"repeated","visualization_type":[["bar_chart"]]},{"composite_pattern":"repeated","visualization_type":[["heatmap"]]},{"composite_pattern":"nested","visualization_type":[["area_chart","bar_chart"],["parallel_coordinate"]]}],"coOccurrence":[["others","map",["coOccurrence"]],["others","area_chart",["coOccurrence"]],["others","bar_chart",["coOccurrence"]],["others","parallel_coordinate",["coOccurrence"]],["map","area_chart",["coOccurrence"]],["map","bar_chart",["coOccurrence"]],["map","parallel_coordinate",["coOccurrence"]],["area_chart","bar_chart",["coOccurrence"]],["area_chart","parallel_coordinate",["coOccurrence"]],["bar_chart","parallel_coordinate",["coOccurrence"]]],"year":2017,"conference":["SciVis"],"authors":["Qiaomu Shen","Wei Zeng","Yu Ye","Stefan M\xfcller Arisona","Simon Schubiger-Banz","Remo Aslak Burkhard","Huamin Qu"],"title":"StreetVizor: Visual Exploration of Human-Scale Urban Forms Based on Street Views","doi":"10.1109/TVCG.2017.2744159","abstract":"Urban forms at human-scale, i.e., urban environments that individuals can sense (e.g., sight, smell, and touch) in their daily lives, can provide unprecedented insights on a variety of applications, such as urban planning and environment auditing. The analysis of urban forms can help planners develop high-quality urban spaces through evidence-based design. However, such analysis is complex because of the involvement of spatial, multi-scale (i.e., city, region, and street), and multivariate (e.g., greenery and sky ratios) natures of urban forms. In addition, current methods either lack quantitative measurements or are limited to a small area. The primary contribution of this work is the design of StreetVizor, an interactive visual analytics system that helps planners leverage their domain knowledge in exploring human-scale urban forms based on street view images. Our system presents two-stage visual exploration: 1) an AOI Explorer for the visual comparison of spatial distributions and quantitative measurements in two areas-of-interest (AOIs) at city- and region-scales; 2) and a Street Explorer with a novel parallel coordinate plot for the exploration of the fine-grained details of the urban forms at the street-scale. We integrate visualization techniques with machine learning models to facilitate the detection of street view patterns. We illustrate the applicability of our approach with case studies on the real-world datasets of four cities, i.e., Hong Kong, Singapore, Greater London and New York City. Interviews with domain experts demonstrate the effectiveness of our system in facilitating various analytical tasks.","keywords":"Urban forms,human scale,street view,visual analytics","caption":"Fig. 1. StreetVizor system. (a) Control panel enables multi-scale navigation, ranking exploration, and feature filtering. (b) Side-by-side map views compare the spatial distribution of human-scale urban forms in two areas-of-interest (AOIs). (c) AOI statistic view presents the quantitative measurements, including correlation, histogram, and diversity in the AOIs shown in (b). (d) Street map views present detailed street views along two streets. (e) Street statistic view extends parallel coordinates with street layouts. ","img_size":{"width":1919,"height":575},"subfigures":[{"x":13.874520949459848,"y":16.033777738542298,"width":1044.108553374826,"height":549.9336376028208,"type":"interface","id":"interface-0"},{"x":1081.0131042371145,"y":15.027335852059744,"width":818.1521757224102,"height":548.946010055827,"type":"single","id":"single-1"}],"visualizations":[{"x":1121.776798567783,"y":274.27171240969756,"width":160.81522279023395,"height":254.8580747023884,"type":"area_chart","id":"area_chart-10"},{"x":1692.7400839888542,"y":268.1741477109266,"width":163.1456449231632,"height":259.7637945407236,"type":"area_chart","id":"area_chart-11"},{"x":39.81695561229358,"y":46.46388571063926,"width":39.86118890051001,"height":246.38131949773188,"type":"bar_chart","id":"bar_chart-13"},{"x":216.6165380207313,"y":52.40875198459294,"width":137.65502661462835,"height":236.9213901362266,"type":"bar_chart","id":"bar_chart-15"},{"x":625.2179269698196,"y":263.46918160190984,"width":149.21950873975453,"height":271.60352994515983,"type":"bar_chart","id":"bar_chart-4"},{"x":1288.8624683619905,"y":268.4539847381544,"width":407.87304506296124,"height":272.5680380114791,"type":"bar_chart","id":"bar_chart-9"},{"x":77.55409762104638,"y":40.495008950013926,"width":136.69283595666337,"height":253.45946664617904,"type":"box_plot","id":"box_plot-14"},{"x":369.4135205841899,"y":263.1720030397373,"width":261.61246712204405,"height":257.61906795109286,"type":"heatmap","id":"heatmap-3"},{"x":771.3637471410137,"y":275.7254719124986,"width":275.55847558336933,"height":264.0995716287962,"type":"heatmap","id":"heatmap-5"},{"x":380.51456618227496,"y":26.88164793327879,"width":323.1364973630756,"height":216.29640423999794,"type":"map","id":"map-0"},{"x":695.4399903223427,"y":30.455663008300892,"width":354.60066623184,"height":211.5781772763556,"type":"map","id":"map-1"},{"x":1103.8839488579017,"y":19.668429314321784,"width":398.0289824792054,"height":218.57382554590137,"type":"map","id":"map-7"},{"x":1492.0224224318717,"y":22.04780106429218,"width":394.70188106309547,"height":215.02998363916234,"type":"map","id":"map-8"},{"x":376.6438647614236,"y":259.6579870384932,"width":253.2188890166484,"height":267.07690313998353,"type":"matrix","id":"matrix-2"},{"x":386.5235223680717,"y":29.238955847269168,"width":311.1185849914806,"height":210.36688681881557,"type":"others","id":"others-16"},{"x":711.1084615273738,"y":36.34111612282828,"width":337.8247884195525,"height":196.16256626769743,"type":"others","id":"others-17"},{"x":1103.8191262363566,"y":17.2359014182827,"width":387.2378292739628,"height":216.1494717787742,"type":"others","id":"others-18"},{"x":1504.1457821713666,"y":26.816664686591466,"width":386.22964823169787,"height":209.13696117416617,"type":"others","id":"others-19"},{"x":1129.765806457224,"y":268.06074762673353,"width":727.2797909223101,"height":264.8502010819144,"type":"parallel_coordinate","id":"parallel_coordinate-6"},{"x":10.389316564809102,"y":48.86717232333618,"width":351.1082533568915,"height":245.2194510519405,"type":"table","id":"table-12"}],"relations":[{"vislist":[{"vislist":[{"vislist":[{"vislist":["others-16"],"relation":null,"id":"group-1"},{"vislist":["map-0"],"relation":null,"id":"group-0"}],"relation":"coordinated","id":"relation-0"},{"vislist":[{"vislist":["others-17"],"relation":null,"id":"group-3"},{"vislist":["map-1"],"relation":null,"id":"group-2"}],"relation":"coordinated","id":"relation-1"}],"relation":null,"id":"group-8"}],"relation":"repeated","id":"relation-4"},{"vislist":[{"vislist":[{"vislist":[{"vislist":["others-19"],"relation":null,"id":"group-7"},{"vislist":["map-8"],"relation":null,"id":"group-6"}],"relation":"coordinated","id":"relation-3"},{"vislist":[{"vislist":["others-18"],"relation":null,"id":"group-5"},{"vislist":["map-7"],"relation":null,"id":"group-4"}],"relation":"coordinated","id":"relation-2"}],"relation":null,"id":"group-9"}],"relation":"repeated","id":"relation-5"},{"vislist":[{"vislist":["box_plot-14","bar_chart-13","bar_chart-15"],"relation":null,"id":"group-11"},{"vislist":["table-12"],"relation":null,"id":"group-10"}],"relation":"nested","id":"relation-6"},{"vislist":[{"vislist":["heatmap-3"],"relation":null,"id":"group-13"},{"vislist":["matrix-2"],"relation":null,"id":"group-12"}],"relation":"nested","id":"relation-7"},{"vislist":[{"vislist":["bar_chart-4"],"relation":null,"id":"group-14"}],"relation":"mirrored","id":"relation-8"},{"vislist":[{"vislist":["bar_chart-4"],"relation":null,"id":"group-15"}],"relation":"repeated","id":"relation-9"},{"vislist":[{"vislist":["heatmap-5"],"relation":null,"id":"group-16"}],"relation":"repeated","id":"relation-10"},{"vislist":[{"vislist":["area_chart-10","area_chart-11","bar_chart-9"],"relation":null,"id":"group-18"},{"vislist":["parallel_coordinate-6"],"relation":null,"id":"group-17"}],"relation":"nested","id":"relation-11"}]},"2927_9":{"comp":[["bar_chart","bar_chart",["repeated"]]],"visType":["bar_chart"],"compType":["repeated"],"compressed_tree":[{"composite_pattern":"repeated","visualization_type":[["bar_chart"]]}],"coOccurrence":[["bar_chart","bar_chart",["coOccurrence"]]],"year":2017,"conference":["SciVis"],"authors":["Oliver R\xfcbel","Benjamin P. Bowen"],"title":"BASTet: Shareable and Reproducible Analysis and Visualization of Mass Spectrometry Imaging Data via OpenMSI","doi":"10.1109/TVCG.2017.2744479","abstract":"Mass spectrometry imaging (MSI) is a transformative imaging method that supports the untargeted, quantitative measurement of the chemical composition and spatial heterogeneity of complex samples with broad applications in life sciences, bioenergy, and health. While MSI data can be routinely collected, its broad application is currently limited by the lack of easily accessible analysis methods that can process data of the size, volume, diversity, and complexity generated by MSI experiments. The development and application of cutting-edge analytical methods is a core driver in MSI research for new scientific discoveries, medical diagnostics, and commercial-innovation. However, the lack of means to share, apply, and reproduce analyses hinders the broad application, validation, and use of novel MSI analysis methods. To address this central challenge, we introduce the Berkeley Analysis and Storage Toolkit (BASTet), a novel framework for shareable and reproducible data analysis that supports standardized data and analysis interfaces, integrated data storage, data provenance, workflow management, and a broad set of integrated tools. Based on BASTet, we describe the extension of the OpenMSI mass spectrometry imaging science gateway to enable web-based sharing, reuse, analysis, and visualization of data analyses and derived data products. We demonstrate the application of BASTet and OpenMSI in practice to identify and compare characteristic substructures in the mouse brain based on their chemical composition measured via MSI.","keywords":"Mass spectrometry imaging,Data provenance,Visualization,Data management,Analysis Workflows,Data sharing","caption":"Fig. 9. Screenshot of the web-based data viewer. The image viewer (left) shows a three-channel image from a non-negative matrix factor- ization (NMF). Each channel represents a select NMF component im- age and is mapped to the red, green, or blue component of the RGB image, respectively. The user selected in the viewer two locations in distinct regions of the sample, marked by two white crosshair symbols. The spectrum viewer (right) shows the corresponding spectra from the raw MSI dataset for which the NMF was computed.","img_size":{"width":1080,"height":502},"subfigures":[{"x":5.7022968721410505,"y":4.721112332680941,"width":1070.2840694844333,"height":494.809388046814,"type":"interface","id":"interface-0"}],"visualizations":[{"x":409.24433858124934,"y":65.9804880483992,"width":657.5965609843518,"height":216.46784169962882,"type":"bar_chart","id":"bar_chart-1"},{"x":409.92549365553594,"y":291.99164861062366,"width":656.9171564187889,"height":202.6352937960403,"type":"bar_chart","id":"bar_chart-2"},{"x":5.638401654649688,"y":99.21167353846018,"width":382.40308576383273,"height":385.48128343165195,"type":"scivis","id":"scivis-0"}],"relations":[{"vislist":[{"vislist":["bar_chart-1","bar_chart-2"],"relation":null,"id":"group-0"}],"relation":"repeated","id":"relation-0"}]},"1757_4":{"comp":[["scivis","scivis",["repeated"]]],"visType":["scivis"],"compType":["repeated"],"compressed_tree":[{"composite_pattern":"repeated","visualization_type":[["scivis"]]}],"coOccurrence":[["scivis","scivis",["coOccurrence"]]],"year":2008,"conference":["Vis"],"authors":["Jorik Blaas","Charl P. Botha","Frits H. Post"],"title":"Extensions of Parallel Coordinates for Interactive Exploration of Large Multi-Timepoint Data Sets","doi":"10.1109/TVCG.2008.131","abstract":"Parallel coordinate plots (PCPs) are commonly used in information visualization to provide insight into multi-variate data. These plots help to spot correlations between variables. PCPs have been successfully applied to unstructured datasets up to a few millions of points. In this paper, we present techniques to enhance the usability of PCPs for the exploration of large, multi-timepoint volumetric data sets, containing tens of millions of points per timestep. The main difficulties that arise when applying PCPs to large numbers of data points are visual clutter and slow performance, making interactive exploration infeasible. Moreover, the spatial context of the volumetric data is usually lost. We describe techniques for preprocessing using data quantization and compression, and for fast GPU-based rendering of PCPs using joint density distributions for each pair of consecutive variables, resulting in a smooth, continuous visualization. Also, fast brushing techniques are proposed for interactive data selection in multiple linked views, including a 3D spatial volume view. These techniques have been successfully applied to three large data sets: Hurricane Isabel (Vis\'04 contest), the ionization front instability data set (Vis\'08 design contest), and data from a large-eddy simulation of cumulus clouds. With these data, we show how PCPs can be extended to successfully visualize and interactively explore multi-timepoint volumetric datasets with an order of magnitude more data points.","keywords":"Parallel coordinate plots, time-varying, multi-field, linked related views","caption":"Fig. 4: The main user interface of the demonstrator application. The top part of the screen contains spatial viewing components (two slice viewers and a 3D isosurface view). The parallel coordinate plot is positioned in the middle, and the control interface is positioned at the bottom. ","img_size":{"width":1512,"height":1156},"subfigures":[{"x":10.92539774317973,"y":14.894770901435567,"width":1483.8360807552185,"height":1130.9474153842357,"type":"interface","id":"interface-0"}],"visualizations":[{"x":23.42558109744361,"y":496.78757534696064,"width":1457.2574331070866,"height":470.3270664681916,"type":"parallel_coordinate","id":"parallel_coordinate-2"},{"x":834.3350802226614,"y":33.0652508401382,"width":648.253118753423,"height":444.0643351438005,"type":"scivis","id":"scivis-0"},{"x":23.784979490425222,"y":22.120847901119365,"width":803.1303273244912,"height":453.32125518954655,"type":"scivis","id":"scivis-1"}],"relations":[{"vislist":[{"vislist":["scivis-1"],"relation":null,"id":"group-0"}],"relation":"repeated","id":"relation-0"}]},"1761_3":{"comp":[["scivis","scivis",["repeated"]]],"visType":["scivis"],"compType":["repeated"],"compressed_tree":[{"composite_pattern":"repeated","visualization_type":[["scivis"]]}],"coOccurrence":[["scivis","scivis",["coOccurrence"]]],"year":2008,"conference":["Vis"],"authors":["Jennis Meyer-Spradow","Lars Stegger","Christian D\xf6ring","Timo Ropinski","Klaus H. Hinrichs"],"title":"Glyph-Based SPECT Visualization for the Diagnosis of Coronary Artery Disease","doi":"10.1109/TVCG.2008.136","abstract":"Myocardial perfusion imaging with single photon emission computed tomography (SPECT) is an established method for the detection and evaluation of coronary artery disease (CAD). State-of-the-art SPECT scanners yield a large number of regional parameters of the left-ventricular myocardium (e.g., blood supply at rest and during stress, wall thickness, and wall thickening during heart contraction) that all need to be assessed by the physician. Today, the individual parameters of this multivariate data set are displayed as stacks of 2D slices, bull\'s eye plots, or, more recently, surfaces in 3D, which depict the left-ventricular wall. In all these visualizations, the data sets are displayed side-by-side rather than in an integrated manner, such that the multivariate data have to be examined sequentially and need to be fused mentally. This is time consuming and error-prone. In this paper we present an interactive 3D glyph visualization, which enables an effective integrated visualization of the multivariate data. Results from semiotic theory are used to optimize the mapping of different variables to glyph properties. This facilitates an improved perception of important information and thus an accelerated diagnosis. The 3D glyphs are linked to the established 2D views, which permit a more detailed inspection, and to relevant meta-information such as known stenoses of coronary vessels supplying the myocardial region. Our method has demonstrated its potential for clinical routine use in real application scenarios assessed by nuclear physicians.","keywords":"Multivariate visualization, glyph techniques, SPECT, myocardial perfusion imaging","caption":"Fig. 3. Glyphs in the 3D visualization are dynamically linked to corre- sponding slice views.","img_size":{"width":960,"height":549},"subfigures":[{"x":41.46737666344249,"y":73.38684390819618,"width":906.3106264503998,"height":466.71613243510274,"type":"interface","id":"interface-0"}],"visualizations":[{"x":609.0266319121479,"y":108.06125411802009,"width":332.9987605776638,"height":420.87410562393234,"type":"scivis","id":"scivis-0"},{"x":172.08463460347136,"y":92.08095244501366,"width":424.4585853563198,"height":439.2967683761035,"type":"scivis","id":"scivis-1"}],"relations":[{"vislist":[{"vislist":["scivis-1"],"relation":null,"id":"group-0"}],"relation":"repeated","id":"relation-0"}]},"1765_2":{"comp":[["scivis","scivis",["repeated"]]],"visType":["scivis"],"compType":["repeated"],"compressed_tree":[{"composite_pattern":"repeated","visualization_type":[["scivis"]]}],"coOccurrence":[],"year":2008,"conference":["Vis"],"authors":["Dominic Schneider","Alexander Wiebel","Hamish A. Carr","Mario Hlawitschka","Gerik Scheuermann"],"title":"Interactive Comparison of Scalar fields Based on Largest Contours with Applications to Flow Visualization","doi":"10.1109/TVCG.2008.143","abstract":"Understanding fluid flow data, especially vortices, is still a challenging task. Sophisticated visualization tools help to gain insight. In this paper, we present a novel approach for the interactive comparison of scalar fields using isosurfaces, and its application to fluid flow datasets. Features in two scalar fields are defined by largest contour segmentation after topological simplification. These features are matched using a volumetric similarity measure based on spatial overlap of individual features. The relationships defined by this similarity measure are ranked and presented in a thumbnail gallery of feature pairs and a graph representation showing all relationships between individual contours. Additionally, linked views of the contour trees are provided to ease navigation. The main render view shows the selected features overlapping each other. Thus, by displaying individual features and their relationships in a structured fashion, we enable exploratory visualization of correlations between similar structures in two scalar fields. We demonstrate the utility of our approach by applying it to a number of complex fluid flow datasets, where the emphasis is put on the comparison of vortex related scalar quantities.","keywords":"Scalar topology, comparative visualization, contour tree, largest contours, flow visualization","caption":"Fig. 2. Interface overviewUp:Figure (b) shows the selected feature pairs in theSimilarity Browserwindow. Figure (a) and (c) show the respective contour tree views with the according largest contours marked in each tree as highlighted in red and green.Bottom: Rendering of matched contours as selected in theSimilarity Browser. The red surfaces represent contours in\u03bb2field, whereas the green surfaces belong to contours in the pressure field.","img_size":{"width":1823,"height":1459},"subfigures":[{"x":12.138579750605029,"y":6.870983216097742,"width":472.9311094926858,"height":709.8946028350181,"type":"single","id":"single-0"},{"x":516.6699264741405,"y":6.892758545593525,"width":781.6854599479223,"height":713.8367618276933,"type":"single","id":"single-1"},{"x":1329.662958528264,"y":10.806300110619869,"width":465.5417526381844,"height":708.0025335234745,"type":"single","id":"single-2"},{"x":15.964753568082347,"y":797.619258235723,"width":1785.089477535989,"height":607.0963335646761,"type":"single","id":"single-3"}],"visualizations":[{"x":920.1590809447024,"y":63.99309077731158,"width":345.5301013333173,"height":637.5003390551058,"type":"graph","id":"graph-2"},{"x":1361.2002919786432,"y":51.91928046935553,"width":392.49872685768173,"height":607.8408793734978,"type":"line_chart","id":"line_chart-0"},{"x":31.684732656828135,"y":63.74043499110159,"width":407.92107059290254,"height":594.162844459175,"type":"line_chart","id":"line_chart-4"},{"x":32.89908744283042,"y":910.278092845032,"width":1579.7650370548765,"height":453.52143807608616,"type":"scivis","id":"scivis-1"},{"x":554.4582469951365,"y":78.92141230759535,"width":289.4314177325836,"height":478.1081323153219,"type":"scivis","id":"scivis-3"}],"relations":[{"vislist":[{"vislist":["scivis-3"],"relation":null,"id":"group-0"}],"relation":"repeated","id":"relation-0"}]},"1770_1":{"comp":[["scivis","scivis",["repeated"]]],"visType":["scivis"],"compType":["repeated"],"compressed_tree":[{"composite_pattern":"repeated","visualization_type":[["scivis"]]}],"coOccurrence":[["scivis","scivis",["coOccurrence"]]],"year":2008,"conference":["Vis"],"authors":["Alark Joshi","Dustin Scheinost","Kenneth P. Vives","Dennis D. Spencer","Lawrence H. Staib","Xenophon Papademetris"],"title":"Novel interaction techniques for neurosurgical planning and stereotactic navigation","doi":"10.1109/TVCG.2008.150","abstract":"Neurosurgical planning and image guided neurosurgery require the visualization of multimodal data obtained from various functional and structural image modalities, such as magnetic resonance imaging (MRI), computed tomography (CT), functional MRI, Single photon emission computed tomography (SPECT) and so on. In the case of epilepsy neurosurgery for example, these images are used to identify brain regions to guide intracranial electrode implantation and resection. Generally, such data is visualized using 2D slices and in some cases using a 3D volume rendering along with the functional imaging results. Visualizing the activation region effectively by still preserving sufficient surrounding brain regions for context is exceedingly important to neurologists and surgeons. We present novel interaction techniques for visualization of multimodal data to facilitate improved exploration and planning for neurosurgery. We extended the line widget from VTK to allow surgeons to control the shape of the region of the brain that they can visually crop away during exploration and surgery. We allow simple spherical, cubical, ellipsoidal and cylindrical (probe aligned cuts) for exploration purposes. In addition we integrate the cropping tool with the image-guided navigation system used for epilepsy neurosurgery. We are currently investigating the use of these new tools in surgical planning and based on further feedback from our neurosurgeons we will integrate them into the setup used for image-guided neurosurgery.","keywords":"User interaction, irregular cropping","caption":"Fig. 2. Conventional visualizations in image guided surgery using the BrainLAB VV Cranial System. The top-left view is a research visual- ization of an overlay of cortical electrode reconstructions shown over a volume rendering of the 3D anatomical MRI data. This is generated in our research software and sent in to the BrainLAB system via the VVLink interface \u2013 see Figure 1. The other views are conventional vi-sualizations from the BrainLAB system, including (bottom left) a volume rendered view of a patient CT image showing the intracranial electrodes as bright dots.","img_size":{"width":1059,"height":848},"subfigures":[{"x":12.76020274771356,"y":8.617920529055667,"width":1038.112038694094,"height":830.7641589418887,"type":"interface","id":"interface-0"}],"visualizations":[{"x":246.5341420242054,"y":77.59889076105976,"width":759.3362608641045,"height":747.2417126097823,"type":"scivis","id":"scivis-0"}],"relations":[{"vislist":[{"vislist":["scivis-0"],"relation":null,"id":"group-0"}],"relation":"repeated","id":"relation-0"}]},"1770_2":{"comp":[["scivis","scivis",["repeated"]]],"visType":["scivis"],"compType":["repeated"],"compressed_tree":[{"composite_pattern":"repeated","visualization_type":[["scivis"]]}],"coOccurrence":[["scivis","scivis",["coOccurrence"]]],"year":2008,"conference":["Vis"],"authors":["Alark Joshi","Dustin Scheinost","Kenneth P. Vives","Dennis D. Spencer","Lawrence H. Staib","Xenophon Papademetris"],"title":"Novel interaction techniques for neurosurgical planning and stereotactic navigation","doi":"10.1109/TVCG.2008.150","abstract":"Neurosurgical planning and image guided neurosurgery require the visualization of multimodal data obtained from various functional and structural image modalities, such as magnetic resonance imaging (MRI), computed tomography (CT), functional MRI, Single photon emission computed tomography (SPECT) and so on. In the case of epilepsy neurosurgery for example, these images are used to identify brain regions to guide intracranial electrode implantation and resection. Generally, such data is visualized using 2D slices and in some cases using a 3D volume rendering along with the functional imaging results. Visualizing the activation region effectively by still preserving sufficient surrounding brain regions for context is exceedingly important to neurologists and surgeons. We present novel interaction techniques for visualization of multimodal data to facilitate improved exploration and planning for neurosurgery. We extended the line widget from VTK to allow surgeons to control the shape of the region of the brain that they can visually crop away during exploration and surgery. We allow simple spherical, cubical, ellipsoidal and cylindrical (probe aligned cuts) for exploration purposes. In addition we integrate the cropping tool with the image-guided navigation system used for epilepsy neurosurgery. We are currently investigating the use of these new tools in surgical planning and based on further feedback from our neurosurgeons we will integrate them into the setup used for image-guided neurosurgery.","keywords":"User interaction, irregular cropping","caption":"Fig. 3. A screenshot of one of the views in BioimageSuite. The top two images and the bottom left image shows the standard two dimensional slices (Axial, Coronal and Sagittal) along with a three-dimensional vol- ume rendering view of the same data. The bottom right image shows a 3D volume rendering of the data. The rectangular region marked in violet on the user interface indicates the synchronized x, y, z location of the cross hairs.","img_size":{"width":1060,"height":882},"subfigures":[{"x":17.20731616661554,"y":13.73206039292149,"width":1031.6108904098676,"height":855.7406070800829,"type":"interface","id":"interface-0"}],"visualizations":[{"x":18.210901496902554,"y":11.306510783620935,"width":711.4561189137519,"height":853.3633391031293,"type":"scivis","id":"scivis-0"}],"relations":[{"vislist":[{"vislist":["scivis-0"],"relation":null,"id":"group-0"}],"relation":"repeated","id":"relation-0"}]},"1775_12":{"comp":[["scivis","scivis",["repeated"]]],"visType":["scivis"],"compType":["repeated"],"compressed_tree":[{"composite_pattern":"repeated","visualization_type":[["scivis"]]}],"coOccurrence":[["scivis","scivis",["coOccurrence"]]],"year":2008,"conference":["Vis"],"authors":["Arno Kr\xfcger","Christoph Kubisch","Gero Strau\xdf","Bernhard Preim"],"title":"Sinus Endoscopy - Application of Advanced GPU Volume Rendering for Virtual Endoscopy","doi":"10.1109/TVCG.2008.161","abstract":"For difficult cases in endoscopic sinus surgery, a careful planning of the intervention is necessary. Due to the reduced field of view during the intervention, the surgeons have less information about the surrounding structures in the working area compared to open surgery. Virtual endoscopy enables the visualization of the operating field and additional information, such as risk structures (e.g., optical nerve and skull base) and target structures to be removed (e.g., mucosal swelling). The Sinus Endoscopy system provides the functional range of a virtual endoscopic system with special focus on a realistic representation. Furthermore, by using direct volume rendering, we avoid time-consuming segmentation steps for the use of individual patient datasets. However, the image quality of the endoscopic view can be adjusted in a way that a standard computer with a modern standard graphics card achieves interactive frame rates with low CPU utilization. Thereby, characteristics of the endoscopic view are systematically used for the optimization of the volume rendering speed. The system design was based on a careful analysis of the endoscopic sinus surgery and the resulting needs for computer support. As a small standalone application it can be instantly used for surgical planning and patient education. First results of a clinical evaluation with ENT surgeons were employed to fine-tune the user interface, in particular to reduce the number of controls by using appropriate default values wherever possible. The system was used for preoperative planning in 102 cases, provides useful information for intervention planning (e.g., anatomic variations of the Rec. Frontalis), and closely resembles the intraoperative situation.","keywords":"medical visualization, sinus surgery, operation planning, virtual endoscopy, volume rendering","caption":"Fig. 13. Screenshot of the prototype\u2019s interface. Slider elements al- low fast changes to values, yet numerical inputs are also allowed for precision. Animation controls are located at the bottom, while main pa- rameters are at the left sidebar. In the upper section there are, e.g., the iso value and secretion level while the lower box contains parameters who influence the visual effects of the GPU shader. ","img_size":{"width":1053,"height":702},"subfigures":[{"x":12.443572511162325,"y":2.364961412914337,"width":1037.7015048061558,"height":691.5168869573001,"type":"interface","id":"interface-0"}],"visualizations":[{"x":256.99703480388143,"y":8.533280811584675,"width":257.0996254349084,"height":594.8001249792009,"type":"heatmap","id":"heatmap-2"},{"x":259.8656660999891,"y":9.485195866598326,"width":257.11555273978166,"height":593.8551599053185,"type":"scivis","id":"scivis-0"},{"x":533.075272748176,"y":24.7216762360289,"width":510.3897351386881,"height":579.6829047809216,"type":"scivis","id":"scivis-1"}],"relations":[{"vislist":[{"vislist":["scivis-0"],"relation":null,"id":"group-0"}],"relation":"repeated","id":"relation-0"}]},"1781_15":{"comp":[["scivis","scivis",["repeated"]]],"visType":["scivis"],"compType":["repeated"],"compressed_tree":[{"composite_pattern":"repeated","visualization_type":[["scivis"]]}],"coOccurrence":[["scivis","scivis",["coOccurrence"]]],"year":2008,"conference":["Vis"],"authors":["Jesus J. Caban","Penny Rheingans"],"title":"Texture-based Transfer Functions for Direct Volume Rendering","doi":"10.1109/TVCG.2008.169","abstract":"Visualization of volumetric data faces the difficult task of finding effective parameters for the transfer functions. Those parameters can determine the effectiveness and accuracy of the visualization. Frequently, volumetric data includes multiple structures and features that need to be differentiated. However, if those features have the same intensity and gradient values, existing transfer functions are limited at effectively illustrating those similar features with different rendering properties. We introduce texture-based transfer functions for direct volume rendering. In our approach, the voxelpsilas resulting opacity and color are based on local textural properties rather than individual intensity values. For example, if the intensity values of the vessels are similar to those on the boundary of the lungs, our texture-based transfer function will analyze the textural properties in those regions and color them differently even though they have the same intensity values in the volume. The use of texture-based transfer functions has several benefits. First, structures and features with the same intensity and gradient values can be automatically visualized with different rendering properties. Second, segmentation or prior knowledge of the specific features within the volume is not required for classifying these features differently. Third, textural metrics can be combined and/or maximized to capture and better differentiate similar structures. We demonstrate our texture-based transfer function for direct volume rendering with synthetic and real-world medical data to show the strength of our technique.","keywords":"visualization, statistical analysis, volume rendering, data variability, medical imaging","caption":"Fig. 14. Changing individual metrics is possible with our graphical in- terface. The user can pick a threshold of individual metrics, then during the raycast function, if the voxel under consideration is within the range, different opacity and/or color properties are assigned. ","img_size":{"width":766,"height":675},"subfigures":[{"x":7.393571389842844,"y":8.681985723715307,"width":746.6011919899901,"height":657.6360285525686,"type":"interface","id":"interface-0"}],"visualizations":[{"x":259.7248165485191,"y":71.77570767951033,"width":486.3569588797667,"height":428.18619613305617,"type":"scivis","id":"scivis-0"},{"x":258.77862955202994,"y":511.78027755524664,"width":483.63766764242285,"height":133.6379197970374,"type":"scivis","id":"scivis-1"}],"relations":[{"vislist":[{"vislist":["scivis-1"],"relation":null,"id":"group-0"}],"relation":"repeated","id":"relation-0"}]},"2631_10":{"comp":[["line_chart","line_chart",["repeated"]]],"visType":["line_chart"],"compType":["repeated"],"compressed_tree":[{"composite_pattern":"repeated","visualization_type":[["line_chart"]]}],"coOccurrence":[["line_chart","line_chart",["coOccurrence"]]],"year":2015,"conference":["SciVis"],"authors":["Jorge Poco","Harish Doraiswamy","Marian Talbert","Jeffrey T. Morisette","Cl\xe1udio T. Silva"],"title":"Using Maximum Topology Matching to Explore Differences in Species Distribution Models","doi":"10.1109/SciVis.2015.7429486","abstract":"Species distribution models (SDM) are used to help understand what drives the distribution of various plant and animal species. These models are typically high dimensional scalar functions, where the dimensions of the domain correspond to predictor variables of the model algorithm. Understanding and exploring the differences between models help ecologists understand areas where their data or understanding of the system is incomplete and will help guide further investigation in these regions. These differences can also indicate an important source of model to model uncertainty. However, it is cumbersome and often impractical to perform this analysis using existing tools, which allows for manual exploration of the models usually as 1-dimensional curves. In this paper, we propose a topology-based framework to help ecologists explore the differences in various SDMs directly in the high dimensional domain. In order to accomplish this, we introduce the concept of maximum topology matching that computes a locality-aware correspondence between similar extrema of two scalar functions. The matching is then used to compute the similarity between two functions. We also design a visualization interface that allows ecologists to explore SDMs using their topological features and to study the differences between pairs of models found using maximum topological matching. We demonstrate the utility of the proposed framework through several use cases using different data sets and report the feedback obtained from ecologists.","keywords":"Function similarity, computational topology, species distribution models, persistence, high dimensional visualization","caption":"Figure 11: Comparing MARS and BRT for the Sagebrush species. (a) Selecting all signi\ufb01cant maxima that are present in BRT but not in MARS. (b) Note that such difference mainly occurs at a relatively low value of the mean summer predictor. (c) The response curve at one of the maximum. (d) This behavior is counter intuitive to the de- fault response curve, in which we see both models having the same pattern. ","img_size":{"width":942,"height":489},"subfigures":[{"x":2.555843029378209,"y":5.912533554658035,"width":929.0812293542056,"height":484.4608085209693,"type":"interface","id":"interface-0"}],"visualizations":[{"x":613.57743129315,"y":19.670839643655814,"width":311.08620802140354,"height":197.45213815305394,"type":"line_chart","id":"line_chart-1"},{"x":612.9771644770346,"y":263.0218190705494,"width":310.4998053780859,"height":205.6228306574152,"type":"line_chart","id":"line_chart-2"},{"x":6.296238749289976,"y":223.12967100578106,"width":595.846084399208,"height":262.7503066042894,"type":"parallel_coordinate","id":"parallel_coordinate-3"},{"x":189.3555884374165,"y":6.663847026965329,"width":385.7864864207764,"height":207.96408852461303,"type":"scatterplot","id":"scatterplot-0"}],"relations":[{"vislist":[{"vislist":["line_chart-1","line_chart-2"],"relation":null,"id":"group-0"}],"relation":"repeated","id":"relation-0"}]},"2631_9":{"comp":[["line_chart","line_chart",["repeated"]]],"visType":["line_chart"],"compType":["repeated"],"compressed_tree":[{"composite_pattern":"repeated","visualization_type":[["line_chart"]]}],"coOccurrence":[["line_chart","line_chart",["coOccurrence"]]],"year":2015,"conference":["SciVis"],"authors":["Jorge Poco","Harish Doraiswamy","Marian Talbert","Jeffrey T. Morisette","Cl\xe1udio T. Silva"],"title":"Using Maximum Topology Matching to Explore Differences in Species Distribution Models","doi":"10.1109/SciVis.2015.7429486","abstract":"Species distribution models (SDM) are used to help understand what drives the distribution of various plant and animal species. These models are typically high dimensional scalar functions, where the dimensions of the domain correspond to predictor variables of the model algorithm. Understanding and exploring the differences between models help ecologists understand areas where their data or understanding of the system is incomplete and will help guide further investigation in these regions. These differences can also indicate an important source of model to model uncertainty. However, it is cumbersome and often impractical to perform this analysis using existing tools, which allows for manual exploration of the models usually as 1-dimensional curves. In this paper, we propose a topology-based framework to help ecologists explore the differences in various SDMs directly in the high dimensional domain. In order to accomplish this, we introduce the concept of maximum topology matching that computes a locality-aware correspondence between similar extrema of two scalar functions. The matching is then used to compute the similarity between two functions. We also design a visualization interface that allows ecologists to explore SDMs using their topological features and to study the differences between pairs of models found using maximum topological matching. We demonstrate the utility of the proposed framework through several use cases using different data sets and report the feedback obtained from ecologists.","keywords":"Function similarity, computational topology, species distribution models, persistence, high dimensional visualization","caption":"Figure 10: Locations of a signi\ufb01cant minimum-saddle pair in MARS is shown using parallel coordinates. Note the moving up of the re- sponse curves of MARS from the minimum to the saddle. At the same location, we see a different behavior for the GLM model. ","img_size":{"width":942,"height":620},"subfigures":[{"x":3.545900684776137,"y":3.5314187556200918,"width":925.0120361824179,"height":612.2773256656831,"type":"interface","id":"interface-0"}],"visualizations":[{"x":465.83838034450145,"y":341.4603766820436,"width":427.281550454741,"height":268.9771686430636,"type":"line_chart","id":"line_chart-1"},{"x":14.809418714768658,"y":342.1070804353271,"width":422.19124931128374,"height":267.02392431342014,"type":"line_chart","id":"line_chart-2"},{"x":8.121526133038815,"y":8.857787798638412,"width":910.5828319802739,"height":320.53410094933656,"type":"parallel_coordinate","id":"parallel_coordinate-0"}],"relations":[{"vislist":[{"vislist":["line_chart-1","line_chart-2"],"relation":null,"id":"group-0"}],"relation":"repeated","id":"relation-0"}]},"2647_3":{"comp":[["polar_plot","glyph_based",["repeated"]],["glyph_based","polar_plot",["repeated"]],["scivis","map",["coordinated"]]],"visType":["polar_plot","glyph_based","scivis","map"],"compType":["repeated","coordinated"],"compressed_tree":[{"composite_pattern":"repeated","visualization_type":[["polar_plot","glyph_based"]]},{"composite_pattern":"coordinated","visualization_type":[["scivis"],["map"]]}],"coOccurrence":[["polar_plot","scivis",["coOccurrence"]],["polar_plot","map",["coOccurrence"]],["scivis","map",["coOccurrence"]]],"year":2015,"conference":["SciVis"],"authors":["Richen Liu","Hanqi Guo","Xiaoru Yuan"],"title":"A bottom-up scheme for user-defined feature exploration in vector field ensembles","doi":"10.1109/SciVis.2015.7429510","abstract":"Most of the existing approaches to visualize vector field ensembles are achieved by visualizing the uncertainty of individual variables from different simulation runs. However, the comparison of the derived feature or user-defined feature, such as the vortex in ensemble flow is also of vital significance since they often make more sense according to the domain knowledge. In this work, we present a framework to extract user-defined feature from different simulation runs. Specially, we use a bottom-up searching scheme to help to extract vortex with a user-defined shape, and further compute the geometry information including the size, and the geo-spatial location of the extracted vortex. Finally we design some linked views to compare the feature between different runs.","keywords":"","caption":"Figure 4: Grouping selection to select one month across all runs.","img_size":{"width":1014,"height":386},"subfigures":[{"x":3.7716648146515683,"y":5.2339176332247,"width":1006.456670370697,"height":379.76293840361683,"type":"interface","id":"interface-0"}],"visualizations":[{"x":508.18095810979514,"y":193.98004084028008,"width":123.30788673420551,"height":183.84258545021376,"type":"polar_plot","id":"polar_plot-5"},{"x":12.011434748636523,"y":8.213023331939,"width":484.0920563672954,"height":172.8794057183712,"type":"map","id":"map-0"},{"x":20.360129521814585,"y":236.96283879403285,"width":457.1359073961406,"height":138.8817160819137,"type":"matrix","id":"matrix-9"},{"x":513.3120314299725,"y":9.55724525422048,"width":122.02215459055002,"height":183.00493891730997,"type":"polar_plot","id":"polar_plot-1"},{"x":636.0943631492539,"y":10.836329557201225,"width":122.66771734717642,"height":183.65026457222433,"type":"polar_plot","id":"polar_plot-2"},{"x":760.2285900097224,"y":9.56161315042532,"width":124.45652460573204,"height":183.63690197707518,"type":"polar_plot","id":"polar_plot-3"},{"x":883.1014978198593,"y":7.653974389315825,"width":125.56210764469736,"height":184.24868523841891,"type":"polar_plot","id":"polar_plot-4"},{"x":632.9090942442583,"y":197.20560533340193,"width":127.11473776501991,"height":180.59495072484555,"type":"polar_plot","id":"polar_plot-6"},{"x":757.0443318597604,"y":195.92729364990262,"width":129.5426959775558,"height":182.51087523966893,"type":"polar_plot","id":"polar_plot-7"},{"x":887.589598262682,"y":195.29434577127685,"width":122.99763139955245,"height":183.77677099692067,"type":"polar_plot","id":"polar_plot-8"},{"x":146.25548814236186,"y":9.269099747033502,"width":344.47961485389084,"height":50.95656753144123,"type":"scivis","id":"scivis-10"}],"relations":[{"vislist":[{"vislist":["polar_plot-1","polar_plot-2","polar_plot-3","polar_plot-4","polar_plot-6","polar_plot-7","polar_plot-8","glyph_based-5"],"relation":null,"id":"group-0"}],"relation":"repeated","id":"relation-0"},{"vislist":[{"vislist":["scivis-10"],"relation":null,"id":"group-2"},{"vislist":["map-0"],"relation":null,"id":"group-1"}],"relation":"coordinated","id":"relation-1"}]},"2654_0":{"comp":[["scivis","scivis",["repeated"]]],"visType":["scivis"],"compType":["repeated"],"compressed_tree":[{"composite_pattern":"repeated","visualization_type":[["scivis"]]},{"composite_pattern":"repeated","visualization_type":[["scivis"]]}],"coOccurrence":[["scivis","scivis",["coOccurrence"]]],"year":2015,"conference":["SciVis"],"authors":["Amin Abbasloo","Vitalis Wiens","Max Hermann","Thomas Schult"],"title":"Visualizing Tensor Normal Distributions at Multiple Levels of Detail","doi":"10.1109/TVCG.2015.2467031","abstract":"Despite the widely recognized importance of symmetric second order tensor fields in medicine and engineering, the visualization of data uncertainty in tensor fields is still in its infancy. A recently proposed tensorial normal distribution, involving a fourth order covariance tensor, provides a mathematical description of how different aspects of the tensor field, such as trace, anisotropy, or orientation, vary and covary at each point. However, this wealth of information is far too rich for a human analyst to take in at a single glance, and no suitable visualization tools are available. We propose a novel approach that facilitates visual analysis of tensor covariance at multiple levels of detail. We start with a visual abstraction that uses slice views and direct volume rendering to indicate large-scale changes in the covariance structure, and locations with high overall variance. We then provide tools for interactive exploration, making it possible to drill down into different types of variability, such as in shape or orientation. Finally, we allow the analyst to focus on specific locations of the field, and provide tensor glyph animations and overlays that intuitively depict confidence intervals at those points. Our system is demonstrated by investigating the effects of measurement noise on diffusion tensor MRI, and by analyzing two ensembles of stress tensor fields from solid mechanics.","keywords":"Uncertainty visualization, tensor visualization, direct volume rendering, interaction, glyph based visualization","caption":"Fig. 1. Normally distributed symmetric tensor fields contain a wealth of information, which is highly relevant to assessing uncertainty in medical imaging and understanding simulation ensembles. We present a collection of complementary visualization techniques that, for the first time, allow users to visually analyze this rich data at multiple levels of detail. ","img_size":{"width":2082,"height":754},"subfigures":[{"x":2.3136426110206125,"y":77.51906895959982,"width":1025.889029568156,"height":626.0917735978313,"type":"interface","id":"interface-0"},{"x":1088.3481021085,"y":93.3500591681837,"width":965.468460850055,"height":560.7887028995448,"type":"single","id":"single-1"}],"visualizations":[{"x":718.3235747289989,"y":112.97499536851561,"width":146.40306199404606,"height":155.60646197870227,"type":"matrix","id":"matrix-4"},{"x":350.76074310048494,"y":77.45191696142196,"width":358.88211297261023,"height":284.5590360385009,"type":"scivis","id":"scivis-0"},{"x":6.110437842458652,"y":83.95368270707084,"width":351.4193365575891,"height":279.4518341716035,"type":"scivis","id":"scivis-1"},{"x":1418.7288226724468,"y":348.85083425016177,"width":320.11485397879716,"height":226.06941842430547,"type":"scivis","id":"scivis-10"},{"x":1725.1151794817692,"y":344.96347276458454,"width":322.143067146158,"height":231.21203152065968,"type":"scivis","id":"scivis-11"},{"x":351.16516161515204,"y":369.6212071510041,"width":360.70625635777776,"height":293.76123242684065,"type":"scivis","id":"scivis-2"},{"x":0.7162744245635796,"y":377.91913527257805,"width":358.5982600671665,"height":281.1135409958939,"type":"scivis","id":"scivis-3"},{"x":851.5985224263044,"y":114.39573380368826,"width":176.0634632308069,"height":168.5576443571608,"type":"scivis","id":"scivis-5"},{"x":1099.337487633428,"y":112.41711723992404,"width":325.66573436932623,"height":240.94973422950116,"type":"scivis","id":"scivis-6"},{"x":1410.8393115455485,"y":114.98899376372712,"width":325.36195457459064,"height":235.80598118189312,"type":"scivis","id":"scivis-7"},{"x":1718.5345114140425,"y":113.71447900478083,"width":326.08897183085276,"height":239.67106563718716,"type":"scivis","id":"scivis-8"},{"x":1104.589204684424,"y":344.9860606370099,"width":321.74475130358707,"height":232.48291071320915,"type":"scivis","id":"scivis-9"}],"relations":[{"vislist":[{"vislist":["scivis-1","scivis-0","scivis-2","scivis-3"],"relation":null,"id":"group-0"}],"relation":"repeated","id":"relation-0"},{"vislist":[{"vislist":["scivis-7","scivis-6","scivis-8","scivis-10","scivis-9","scivis-11"],"relation":null,"id":"group-1"}],"relation":"repeated","id":"relation-1"}]},"2655_4":{"comp":[["glyph_based","glyph_based",["repeated"]]],"visType":["glyph_based"],"compType":["repeated"],"compressed_tree":[{"composite_pattern":"repeated","visualization_type":[["glyph_based"]]}],"coOccurrence":[["glyph_based","glyph_based",["coOccurrence"]]],"year":2015,"conference":["SciVis"],"authors":["David Schroeder","Daniel F. Keefe"],"title":"Visualization-by-Sketching: An Artist\'s Interface for Creating Multivariate Time-Varying Data Visualizations","doi":"10.1109/TVCG.2015.2467153","abstract":"We present Visualization-by-Sketching, a direct-manipulation user interface for designing new data visualizations. The goals are twofold: First, make the process of creating real, animated, data-driven visualizations of complex information more accessible to artists, graphic designers, and other visual experts with traditional, non-technical training. Second, support and enhance the role of human creativity in visualization design, enabling visual experimentation and workflows similar to what is possible with traditional artistic media. The approach is to conceive of visualization design as a combination of processes that are already closely linked with visual creativity: sketching, digital painting, image editing, and reacting to exemplars. Rather than studying and tweaking low-level algorithms and their parameters, designers create new visualizations by painting directly on top of a digital data canvas, sketching data glyphs, and arranging and blending together multiple layers of animated 2D graphics. This requires new algorithms and techniques to interpret painterly user input relative to data \u201cunder\u201d the canvas, balance artistic freedom with the need to produce accurate data visualizations, and interactively explore large (e.g., terabyte-sized) multivariate datasets. Results demonstrate a variety of multivariate data visualization techniques can be rapidly recreated using the interface. More importantly, results and feedback from artists support the potential for interfaces in this style to attract new, creative users to the challenging task of designing more effective data visualizations and to help these users stay \u201cin the creative zone\u201d as they work.","keywords":"Visualization design, multivariate, art, sketch, color map, glyph","caption":"Fig. 5: The glyph design interface with sketching canvas on the left and animated previews on the right.","img_size":{"width":1058,"height":450},"subfigures":[{"x":2.283181683095375,"y":4.1391357788120455,"width":1051.227950589387,"height":443.9268729763216,"type":"interface","id":"interface-0"}],"visualizations":[{"x":532.5130588646307,"y":67.62918804271123,"width":167.58145808714016,"height":120.73467394516516,"type":"glyph_based","id":"glyph_based-1"},{"x":697.4956699945594,"y":70.92133569003425,"width":167.43054570271082,"height":116.15734709847874,"type":"glyph_based","id":"glyph_based-2"},{"x":859.2174834630754,"y":71.59670918572282,"width":167.78027775088574,"height":117.48255803771409,"type":"glyph_based","id":"glyph_based-3"},{"x":534.4976275255464,"y":187.6166745032377,"width":163.61232076530936,"height":114.23703047006046,"type":"glyph_based","id":"glyph_based-4"},{"x":696.1539140682586,"y":186.30312594876574,"width":167.43807938187928,"height":116.19513809635079,"type":"glyph_based","id":"glyph_based-5"},{"x":861.9293377789418,"y":187.61667450323714,"width":167.03953092265718,"height":114.23703047006046,"type":"glyph_based","id":"glyph_based-6"},{"x":532.5042726415174,"y":306.27758771311,"width":166.26104144665157,"height":113.06849142687587,"type":"glyph_based","id":"glyph_based-7"},{"x":696.8165551866588,"y":303.4400702767624,"width":166.11279714508007,"height":116.51512023677611,"type":"glyph_based","id":"glyph_based-8"},{"x":860.8724119445391,"y":304.61128354908874,"width":170.66418205218187,"height":111.49673576150985,"type":"glyph_based","id":"glyph_based-9"},{"x":24.51126780569373,"y":57.90651631155654,"width":490.5066932862674,"height":156.23576499115006,"type":"others","id":"others-0"}],"relations":[{"vislist":[{"vislist":["glyph_based-1","glyph_based-2","glyph_based-3","glyph_based-4","glyph_based-5","glyph_based-6","glyph_based-7","glyph_based-8","glyph_based-9"],"relation":null,"id":"group-0"}],"relation":"repeated","id":"relation-0"}]},"2655_6":{"comp":[["comb","comb",["repeated"]],["contour_graph","map",["coordinated"]]],"visType":["comb","contour_graph","map"],"compType":["repeated","coordinated"],"compressed_tree":[{"composite_pattern":"repeated","visualization_type":[[{"composite_pattern":"coordinated","visualization_type":[["contour_graph"],["map"]]}]]}],"coOccurrence":[["contour_graph","map",["coOccurrence"]]],"year":2015,"conference":["SciVis"],"authors":["David Schroeder","Daniel F. Keefe"],"title":"Visualization-by-Sketching: An Artist\'s Interface for Creating Multivariate Time-Varying Data Visualizations","doi":"10.1109/TVCG.2015.2467153","abstract":"We present Visualization-by-Sketching, a direct-manipulation user interface for designing new data visualizations. The goals are twofold: First, make the process of creating real, animated, data-driven visualizations of complex information more accessible to artists, graphic designers, and other visual experts with traditional, non-technical training. Second, support and enhance the role of human creativity in visualization design, enabling visual experimentation and workflows similar to what is possible with traditional artistic media. The approach is to conceive of visualization design as a combination of processes that are already closely linked with visual creativity: sketching, digital painting, image editing, and reacting to exemplars. Rather than studying and tweaking low-level algorithms and their parameters, designers create new visualizations by painting directly on top of a digital data canvas, sketching data glyphs, and arranging and blending together multiple layers of animated 2D graphics. This requires new algorithms and techniques to interpret painterly user input relative to data \u201cunder\u201d the canvas, balance artistic freedom with the need to produce accurate data visualizations, and interactively explore large (e.g., terabyte-sized) multivariate datasets. Results demonstrate a variety of multivariate data visualization techniques can be rapidly recreated using the interface. More importantly, results and feedback from artists support the potential for interfaces in this style to attract new, creative users to the challenging task of designing more effective data visualizations and to help these users stay \u201cin the creative zone\u201d as they work.","keywords":"Visualization design, multivariate, art, sketch, color map, glyph","caption":"Fig. 7: Three Visualization-by-Sketching scenes are combined to tell a story about Hurricane Katrina. ","img_size":{"width":844,"height":1087},"subfigures":[{"x":4.3887412541522846,"y":8.50354286298983,"width":831.751336874486,"height":1073.4634431128115,"type":"single","id":"single-0"}],"visualizations":[{"x":11.256278935945952,"y":11.057942247383489,"width":819.1733217166333,"height":329.13200168157096,"type":"contour_graph","id":"contour_graph-3"},{"x":7.797063150669928,"y":356.89535367362413,"width":821.4635124642399,"height":316.52398828583404,"type":"contour_graph","id":"contour_graph-4"},{"x":10.103320296012598,"y":704.4832209980289,"width":824.9504196137102,"height":372.13932576211414,"type":"contour_graph","id":"contour_graph-5"},{"x":10.136034657753745,"y":8.768353285332147,"width":824.8849908902298,"height":330.24065076688106,"type":"map","id":"map-0"},{"x":-0.24297085598537377,"y":353.540274087878,"width":831.7582794488659,"height":331.3320480811719,"type":"map","id":"map-1"},{"x":8.819019861018296,"y":695.084551075202,"width":825.2049000722249,"height":382.83876498392453,"type":"map","id":"map-2"}],"relations":[{"vislist":[{"vislist":[{"vislist":[{"vislist":["contour_graph-3"],"relation":null,"id":"group-1"},{"vislist":["map-0"],"relation":null,"id":"group-0"}],"relation":"coordinated","id":"relation-0"},{"vislist":[{"vislist":["contour_graph-4"],"relation":null,"id":"group-5"},{"vislist":["map-1"],"relation":null,"id":"group-4"}],"relation":"coordinated","id":"relation-1"},{"vislist":[{"vislist":["contour_graph-5"],"relation":null,"id":"group-7"},{"vislist":["map-2"],"relation":null,"id":"group-6"}],"relation":"coordinated","id":"relation-2"}],"relation":null,"id":"group-8"}],"relation":"repeated","id":"relation-3"}]},"2656_0":{"comp":[["area_chart","area_chart",["repeated"]],["bar_chart","parallel_coordinate",["nested"]],["heatmap","map",["coordinated"]]],"visType":["area_chart","bar_chart","parallel_coordinate","heatmap","map"],"compType":["repeated","nested","coordinated"],"compressed_tree":[{"composite_pattern":"coordinated","visualization_type":[["heatmap"],["map"]]},{"composite_pattern":"coordinated","visualization_type":[["heatmap"],["map"]]},{"composite_pattern":"repeated","visualization_type":[["area_chart"]]},{"composite_pattern":"nested","visualization_type":[["bar_chart"],["parallel_coordinate"]]}],"coOccurrence":[["heatmap","map",["coOccurrence"]],["heatmap","area_chart",["coOccurrence"]],["heatmap","bar_chart",["coOccurrence"]],["heatmap","parallel_coordinate",["coOccurrence"]],["map","area_chart",["coOccurrence"]],["map","bar_chart",["coOccurrence"]],["map","parallel_coordinate",["coOccurrence"]],["area_chart","bar_chart",["coOccurrence"]],["area_chart","parallel_coordinate",["coOccurrence"]],["bar_chart","parallel_coordinate",["coOccurrence"]]],"year":2015,"conference":["SciVis"],"authors":["Wenchao Wu","Jiayi Xu","Haipeng Zeng","Yixian Zheng","Huamin Qu","Bing Ni","Mingxuan Yuan","Lionel M. Ni"],"title":"TelCoVis: Visual Exploration of Co-occurrence in Urban Human Mobility Based on Telco Data","doi":"10.1109/TVCG.2015.2467194","abstract":"Understanding co-occurrence in urban human mobility (i.e. people from two regions visit an urban place during the same time span) is of great value in a variety of applications, such as urban planning, business intelligence, social behavior analysis, as well as containing contagious diseases. In recent years, the widespread use of mobile phones brings an unprecedented opportunity to capture large-scale and fine-grained data to study co-occurrence in human mobility. However, due to the lack of systematic and efficient methods, it is challenging for analysts to carry out in-depth analyses and extract valuable information. In this paper, we present TelCoVis, an interactive visual analytics system, which helps analysts leverage their domain knowledge to gain insight into the co-occurrence in urban human mobility based on telco data. Our system integrates visualization techniques with new designs and combines them in a novel way to enhance analysts\' perception for a comprehensive exploration. In addition, we propose to study the correlations in co-occurrence (i.e. people from multiple regions visit different places during the same time span) by means of biclustering techniques that allow analysts to better explore coordinated relationships among different regions and identify interesting patterns. The case studies based on a real-world dataset and interviews with domain experts have demonstrated the effectiveness of our system in gaining insights into co-occurrence and facilitating various analytical tasks.","keywords":"Co-occurrence, human mobility, telco data, bicluster, visual analytics","caption":"Fig. 1: A visual analytics system for the exploration of co-occurrence in human mobility of Guangzhou based on telco data. Map View (a-b) supports an intuitive region-based exploration of co-occurrence within spatial context. Contour-based Treemap View (d) provides a visual signature characterizing the spatial and temporal distribution of human mobility at a certain place, which facilitates analysts to gain insights into a co-occurrence pattern and generate explanatory hypotheses. Matrix View (c) provides an overview of correlations in co-occurrence through biclustering. Parallel Coordinates View (e) enables an efficient quantitative analysis based on a wide range of attributes of biclusters. And Extended LineUp View (f) conveys the diversity in those biclusters.","img_size":{"width":1784,"height":1013},"subfigures":[{"x":1.3866844151282236,"y":3.6334867142497638,"width":1774.759898944837,"height":1004.6549383428289,"type":"interface","id":"interface-0"}],"visualizations":[{"x":1289.9813318222682,"y":538.5902726371584,"width":406.54807252139494,"height":177.44941393990607,"type":"area_chart","id":"area_chart-4"},{"x":438.77271423859423,"y":612.510591597844,"width":769.959450438311,"height":373.9879234967494,"type":"bar_chart","id":"bar_chart-6"},{"x":612.8743030391175,"y":50.31689954281925,"width":601.1176302954098,"height":491.20744022788847,"type":"heatmap","id":"heatmap-8"},{"x":8.108401707082072,"y":41.38278341494111,"width":600.2422848299805,"height":505.6883366068099,"type":"heatmap","id":"heatmap-9"},{"x":8.116996316816447,"y":39.13196600900071,"width":603.6092721663256,"height":505.67352358291083,"type":"map","id":"map-0"},{"x":614.008061899478,"y":45.86326868003997,"width":602.2342891305037,"height":501.2438139123928,"type":"map","id":"map-1"},{"x":1256.6333471313383,"y":53.816241491834866,"width":513.8541605730268,"height":283.2268276376534,"type":"matrix","id":"matrix-2"},{"x":1279.8624817618006,"y":740.437933018113,"width":417.76130182682806,"height":184.75084623396666,"type":"matrix","id":"matrix-3"},{"x":424.1600938904153,"y":610.318577285832,"width":781.1357495036609,"height":381.7592879976091,"type":"parallel_coordinate","id":"parallel_coordinate-5"},{"x":25.573349617702,"y":613.3589559494158,"width":392.71938466222457,"height":382.4532024241125,"type":"polar_plot","id":"polar_plot-7"}],"relations":[{"vislist":[{"vislist":["heatmap-9"],"relation":null,"id":"group-1"},{"vislist":["map-0"],"relation":null,"id":"group-0"}],"relation":"coordinated","id":"relation-0"},{"vislist":[{"vislist":["heatmap-8"],"relation":null,"id":"group-3"},{"vislist":["map-1"],"relation":null,"id":"group-2"}],"relation":"coordinated","id":"relation-1"},{"vislist":[{"vislist":["area_chart-4"],"relation":null,"id":"group-4"}],"relation":"repeated","id":"relation-2"},{"vislist":[{"vislist":["bar_chart-6"],"relation":null,"id":"group-6"},{"vislist":["parallel_coordinate-5"],"relation":null,"id":"group-5"}],"relation":"nested","id":"relation-3"}]},"2665_1":{"comp":[["scivis","scivis",["repeated"]]],"visType":["scivis"],"compType":["repeated"],"compressed_tree":[{"composite_pattern":"repeated","visualization_type":[["scivis"]]}],"coOccurrence":[["scivis","scivis",["coOccurrence"]]],"year":2015,"conference":["SciVis"],"authors":["Daniel J\xf6nsson","Martin Falk","Anders Ynnerman"],"title":"Intuitive Exploration of Volumetric Data Using Dynamic Galleries","doi":"10.1109/TVCG.2015.2467294","abstract":"In this work we present a volume exploration method designed to be used by novice users and visitors to science centers and museums. The volumetric digitalization of artifacts in museums is of rapidly increasing interest as enhanced user experience through interactive data visualization can be achieved. This is, however, a challenging task since the vast majority of visitors are not familiar with the concepts commonly used in data exploration, such as mapping of visual properties from values in the data domain using transfer functions. Interacting in the data domain is an effective way to filter away undesired information but it is difficult to predict where the values lie in the spatial domain. In this work we make extensive use of dynamic previews instantly generated as the user explores the data domain. The previews allow the user to predict what effect changes in the data domain will have on the rendered image without being aware that visual parameters are set in the data domain. Each preview represents a subrange of the data domain where overview and details are given on demand through zooming and panning. The method has been designed with touch interfaces as the target platform for interaction. We provide a qualitative evaluation performed with visitors to a science center to show the utility of the approach.","keywords":"Transfer function, scalar fields, volume rendering, touch interaction, visualization, user interfaces","caption":"Fig. 3: The design gallery approach by Marks et al. [22] applied to a scalar field representing the electron density of a protein. Their work focus on changing all parameters at once while we allow the user to focus on one parameter at a time. ","img_size":{"width":749,"height":641},"subfigures":[{"x":5.4520937318138225,"y":4.329857758447439,"width":734.6860505572147,"height":632.3402844831053,"type":"interface","id":"interface-0"}],"visualizations":[{"x":140.67273875051922,"y":155.65739357450505,"width":466.97257010313024,"height":349.4686107609204,"type":"glyph_based","id":"glyph_based-0"},{"x":12.194686096022616,"y":38.23728428908974,"width":715.745246662148,"height":590.4485045451777,"type":"scivis","id":"scivis-1"}],"relations":[{"vislist":[{"vislist":["scivis-1"],"relation":null,"id":"group-0"}],"relation":"repeated","id":"relation-0"}]},"2676_0":{"comp":[["matrix","matrix",["repeated"]],["others","others",["repeated"]]],"visType":["matrix","others"],"compType":["repeated"],"compressed_tree":[{"composite_pattern":"repeated","visualization_type":[["matrix"]]},{"composite_pattern":"repeated","visualization_type":[["others"]]}],"coOccurrence":[["matrix","others",["coOccurrence"]]],"year":2015,"conference":["SciVis"],"authors":["Ali K. Al-Awami","Johanna Beyer","Daniel Haehn","Narayanan Kasthuri","Jeff Lichtman","Hanspeter Pfister","Markus Hadwiger"],"title":"NeuroBlocks - Visual Tracking of Segmentation and Proofreading for Large Connectomics Projects","doi":"10.1109/TVCG.2015.2467441","abstract":"In the field of connectomics, neuroscientists acquire electron microscopy volumes at nanometer resolution in order to reconstruct a detailed wiring diagram of the neurons in the brain. The resulting image volumes, which often are hundreds of terabytes in size, need to be segmented to identify cell boundaries, synapses, and important cell organelles. However, the segmentation process of a single volume is very complex, time-intensive, and usually performed using a diverse set of tools and many users. To tackle the associated challenges, this paper presents NeuroBlocks, which is a novel visualization system for tracking the state, progress, and evolution of very large volumetric segmentation data in neuroscience. NeuroBlocks is a multi-user web-based application that seamlessly integrates the diverse set of tools that neuroscientists currently use for manual and semi-automatic segmentation, proofreading, visualization, and analysis. NeuroBlocks is the first system that integrates this heterogeneous tool set, providing crucial support for the management, provenance, accountability, and auditing of large-scale segmentations. We describe the design of NeuroBlocks, starting with an analysis of the domain-specific tasks, their inherent challenges, and our subsequent task abstraction and visual representation. We demonstrate the utility of our design based on two case studies that focus on different user roles and their respective requirements for performing and tracking the progress of segmentation and proofreading in a large real-world connectomics project.","keywords":"Neuroscience, Segmentation, Proofreading, Data and Provenance Tracking","caption":"Fig. 1. Visualizing large-scale segmentation projects in connectomics. Left: The main view of NeuroBlocks, comprising a scalable \u201cpixel- based\u201d visualization of the current segmentation state on top, and a timeline for exploring the project\u2019s evolution at the bottom. Top right: Detailed view of a segmentation task assigned to a user, showing recent modifications and thumbnails of the corresponding tool states. Bottom right: Linked petascale volume rendering of the underlying microscopy data and the selected segmented object. ","img_size":{"width":1905,"height":692},"subfigures":[{"x":6.323554428934882,"y":21.439380279451548,"width":1894.3386340129343,"height":666.9910917769656,"type":"interface","id":"interface-0"}],"visualizations":[{"x":248.0004939138097,"y":502.8059594292019,"width":707.9395224121745,"height":166.69882629993907,"type":"area_chart","id":"area_chart-1"},{"x":1041.0189739208377,"y":479.8337574555802,"width":146.99126649766228,"height":145.06181886811984,"type":"graph","id":"graph-2"},{"x":256.8517660277323,"y":101.18845238242068,"width":696.259826034505,"height":400.3190873413967,"type":"matrix","id":"matrix-0"},{"x":1300.2850512231257,"y":138.13275325167533,"width":253.6307187411045,"height":104.3772767859648,"type":"others","id":"others-3"},{"x":1617.0564255106249,"y":19.75214675219352,"width":282.60123368520146,"height":283.2115657457304,"type":"others","id":"others-4"},{"x":1295.0502662972349,"y":314.22226255421685,"width":603.7889073426808,"height":362.8445824274187,"type":"others","id":"others-5"},{"x":952.9083013791522,"y":83.6200152123325,"width":319.59890287093026,"height":314.7748699332454,"type":"scivis","id":"scivis-6"}],"relations":[{"vislist":[{"vislist":["matrix-0"],"relation":null,"id":"group-0"}],"relation":"repeated","id":"relation-0"},{"vislist":[{"vislist":["others-3"],"relation":null,"id":"group-1"}],"relation":"repeated","id":"relation-1"}]},"2507_8":{"comp":[["comb","comb",["repeated"]],["line_chart","heatmap",["stacked"]],["heatmap","line_chart",["stacked"]]],"visType":["comb","line_chart","heatmap"],"compType":["repeated","stacked"],"compressed_tree":[{"composite_pattern":"repeated","visualization_type":[[{"composite_pattern":"stacked","visualization_type":[["line_chart","heatmap"]]}]]}],"coOccurrence":[["line_chart","heatmap",["coOccurrence"]]],"year":2014,"conference":["SciVis"],"authors":["Hyungsuk Choi","Woohyuk Choi","Tran Minh Quan","David G. C. Hildebrand","Hanspeter Pfister","Won-Ki Jeong"],"title":"Vivaldi: A Domain-Specific Language for Volume Processing and Visualization on Distributed Heterogeneous Systems","doi":"10.1109/TVCG.2014.2346322","abstract":"As the size of image data from microscopes and telescopes increases, the need for high-throughput processing and visualization of large volumetric data has become more pressing. At the same time, many-core processors and GPU accelerators are commonplace, making high-performance distributed heterogeneous computing systems affordable. However, effectively utilizing GPU clusters is difficult for novice programmers, and even experienced programmers often fail to fully leverage the computing power of new parallel architectures due to their steep learning curve and programming complexity. In this paper, we propose Vivaldi, a new domain-specific language for volume processing and visualization on distributed heterogeneous computing systems. Vivaldi\'s Python-like grammar and parallel processing abstractions provide flexible programming tools for non-experts to easily write high-performance parallel computing code. Vivaldi provides commonly used functions and numerical operators for customized visualization and high-throughput image processing applications. We demonstrate the performance and usability of Vivaldi on several examples ranging from volume rendering to image segmentation.","keywords":"Domain-specific language, volume rendering, GPU computing, distributed heterogeneous systems","caption":"Fig. 8. Vivaldi code and output for a sort-last distributed parallel volume rendering of a two-channel LSFM dataset of a juvenile zebra\ufb01sh on a GPU cluster using an input split task generation scheme and two transfer functions. Brain and nerve systems are rendered in green, while other regions are rendered in gray, blue, and red. ","img_size":{"width":2153,"height":945},"subfigures":[{"x":1044.1881744619366,"y":19.569013804329618,"width":1102.9759903444358,"height":912.1130087460699,"type":"single","id":"single-0"}],"visualizations":[{"x":1293.6319135278202,"y":656.7237205579864,"width":294.9825961749745,"height":140.77811113520877,"type":"heatmap","id":"heatmap-3"},{"x":1600.6462984669233,"y":660.3393974653115,"width":296.25549589759515,"height":129.7465666321163,"type":"heatmap","id":"heatmap-4"},{"x":1285.7312877330792,"y":792.1985045418697,"width":299.3893724014727,"height":111.14065188348606,"type":"line_chart","id":"line_chart-1"},{"x":1598.7872395982877,"y":794.3161959601254,"width":301.87269286202775,"height":110.70545973541883,"type":"line_chart","id":"line_chart-2"},{"x":1091.4212784468757,"y":38.22747557925402,"width":1008.9537803644387,"height":566.4298891103787,"type":"scivis","id":"scivis-0"}],"relations":[{"vislist":[{"vislist":[{"vislist":[{"vislist":["line_chart-2","heatmap-4"],"relation":null,"id":"group-0"}],"relation":"stacked","id":"relation-0"},{"vislist":[{"vislist":["heatmap-3","line_chart-1"],"relation":null,"id":"group-1"}],"relation":"stacked","id":"relation-1"}],"relation":null,"id":"group-2"}],"relation":"repeated","id":"relation-2"}]},"2521_0":{"comp":[["matrix","matrix",["repeated"]],["scivis","scatterplot",["annotated"]]],"visType":["matrix","scivis","scatterplot"],"compType":["repeated","annotated"],"compressed_tree":[{"composite_pattern":"annotated","visualization_type":[["scivis"],["scatterplot"]]},{"composite_pattern":"repeated","visualization_type":[["matrix"]]}],"coOccurrence":[["scivis","scatterplot",["coOccurrence"]],["scivis","matrix",["coOccurrence"]],["scatterplot","matrix",["coOccurrence"]]],"year":2014,"conference":["SciVis"],"authors":["Fan Hong","Chufan Lai","Hanqi Guo","Enya Shen","Xiaoru Yuan","Sikun Li"],"title":"FLDA: Latent Dirichlet Allocation Based Unsteady Flow Analysis","doi":"10.1109/TVCG.2014.2346416","abstract":"In this paper, we present a novel feature extraction approach called FLDA for unsteady flow fields based on Latent Dirichlet allocation (LDA) model. Analogous to topic modeling in text analysis, in our approach, pathlines and features in a given flow field are defined as documents and words respectively. Flow topics are then extracted based on Latent Dirichlet allocation. Different from other feature extraction methods, our approach clusters pathlines with probabilistic assignment, and aggregates features to meaningful topics at the same time. We build a prototype system to support exploration of unsteady flow field with our proposed LDA-based method. Interactive techniques are also developed to explore the extracted topics and to gain insight from the data. We conduct case studies to demonstrate the effectiveness of our proposed approach.","keywords":"Flow visualization, Topic model, Latent Dirichlet allocation (LDA)","caption":"Fig. 1. The user interface of our proposed FLDA system, including: (a) parameter setting panel for adjusting parameters in LDA model; (b) MDS/Heatmap view with thumbnails of pathline previews embedded; (c) pathline view for rendering pathlines in 3D space; (d) feature view. Projection in (b) is rendered as a density map in pseudo color, with distribution of the selected topic highlighted. (d) in the pixel-oriented style consists of two parts: the attribute-time view at the top and the topic-time view at the bottom. Each column represents one time step, while each row denotes a topic or an attribute.","img_size":{"width":1951,"height":1024},"subfigures":[{"x":6.6180971818316845,"y":9.92390010173944,"width":1939.1808710745256,"height":1004.1521997965177,"type":"interface","id":"interface-0"}],"visualizations":[{"x":39.263613424590865,"y":658.9026248148792,"width":1903.4490222448778,"height":352.41011327235225,"type":"matrix","id":"matrix-1"},{"x":356.96681162193806,"y":29.688626872657192,"width":944.512913089998,"height":597.5724201262868,"type":"scivis","id":"scivis-2"},{"x":360.3029990021085,"y":31.505492132344738,"width":937.8405383296565,"height":593.9386896069121,"type":"scatterplot","id":"scatterplot-3"},{"x":1320.2379945019509,"y":16.204418272209654,"width":623.572792038773,"height":614.2013915207472,"type":"scivis","id":"scivis-0"}],"relations":[{"vislist":[{"vislist":["scivis-2"],"relation":null,"id":"group-0"},{"vislist":["scatterplot-3"],"relation":null,"id":"group-1"}],"relation":"annotated","id":"relation-0"},{"vislist":[{"vislist":["matrix-1"],"relation":null,"id":"group-2"}],"relation":"repeated","id":"relation-1"}]},"2524_7":{"comp":[["scivis","scivis",["repeated"]]],"visType":["scivis"],"compType":["repeated"],"compressed_tree":[{"composite_pattern":"repeated","visualization_type":[["scivis"]]},{"composite_pattern":"repeated","visualization_type":[["scivis"]]}],"coOccurrence":[],"year":2014,"conference":["SciVis"],"authors":["Hui Zhan","Jianguang Weng","Guangchen Ruan"],"title":"Visualizing 2-dimensional Manifolds with Curve Handles in 4D","doi":"10.1109/TVCG.2014.2346425","abstract":"In this paper, we present a mathematical visualization paradigm for exploring curves embedded in 3D and surfaces in 4D mathematical world. The basic problem is that, 3D figures of 4D mathematical entities often twist, turn, and fold back on themselves, leaving important properties behind the surface sheets. We propose an interactive system to visualize the topological features of the original 4D surface by slicing its 3D figure into a series of feature diagram. A novel 4D visualization interface is designed to allow users to control 4D topological shapes via the collection of diagram handles using the established curve manipulation mechanism. Our system can support rich mathematical interaction of 4D mathematical objects which is very difficult with any existing approach. We further demonstrate the effectiveness of the proposed visualization tool using various experimental results and cases studies.","keywords":"math visualization, 4D, deformation, Reidemeister theorem","caption":"Fig. 8. Screen images of our interactive 4D visualization interface. The illustrated evolutions that correspond to optimal or saddle critical points of the 1-dimensional double point set of the deformable surfaces. 1\xa9\\u0002\u21922\xa9: a pair of double point arcs in which the top has a minimal point and the bottom has a maximal point are replaced by a pair of parallel double point arcs that bound two strips. 3\xa9\\u0002\u21924\xa9: the removal of a closed loop of double points when two surface sheets are pull apart from each other. Both are found in Roseman\u2019s list of moves to knotted surfaces [26]. The apparent depth order of the evolved arcs indicates which surface sheet is\u201cin front\u201d or \u201cbehind\u201d in the fourth dimension.","img_size":{"width":2193,"height":655},"subfigures":[{"x":94.8373673358886,"y":21.543554893093532,"width":574.5506974978045,"height":560.8515536026343,"type":"single","id":"single-0"},{"x":1525.2197327990673,"y":20.01514973591778,"width":576.1136124925868,"height":567.0996974551849,"type":"single","id":"single-1"}],"visualizations":[{"x":460.5391814471822,"y":61.98589100965273,"width":169.33546676374561,"height":501.9869535816955,"type":"scivis","id":"scivis-0"},{"x":97.40260559709107,"y":68.23861427750728,"width":365.59351201887966,"height":394.61337667592346,"type":"scivis","id":"scivis-1"},{"x":101.24737882739245,"y":481.90605985337703,"width":363.70705066533986,"height":88.08516041289793,"type":"scivis","id":"scivis-2"}],"relations":[{"vislist":[{"vislist":["scivis-0"],"relation":null,"id":"group-0"}],"relation":"repeated","id":"relation-0"},{"vislist":[{"vislist":["scivis-2"],"relation":null,"id":"group-1"}],"relation":"repeated","id":"relation-1"}]},"2530_0":{"comp":[["scivis","scivis",["repeated"]],["comb","comb",["repeated"]],["line_chart","bar_chart",["accompanied"]],["bar_chart","line_chart",["accompanied"]]],"visType":["scivis","comb","line_chart","bar_chart"],"compType":["repeated","accompanied"],"compressed_tree":[{"composite_pattern":"repeated","visualization_type":[["scivis"]]},{"composite_pattern":"repeated","visualization_type":[[{"composite_pattern":"accompanied","visualization_type":[["line_chart","bar_chart"]]}]]}],"coOccurrence":[["scivis","line_chart",["coOccurrence"]],["scivis","bar_chart",["coOccurrence"]],["line_chart","bar_chart",["coOccurrence"]]],"year":2014,"conference":["SciVis"],"authors":["Ismail Demir","Christian Dick","R\xfcdiger Westermann"],"title":"Multi-Charts for Comparative 3D Ensemble Visualization","doi":"10.1109/TVCG.2014.2346448","abstract":"A comparative visualization of multiple volume data sets is challenging due to the inherent occlusion effects, yet it is important to effectively reveal uncertainties, correlations and reliable trends in 3D ensemble fields. In this paper we present bidirectional linking of multi-charts and volume visualization as a means to analyze visually 3D scalar ensemble fields at the data level. Multi-charts are an extension of conventional bar and line charts: They linearize the 3D data points along a space-filling curve and draw them as multiple charts in the same plot area. The bar charts encode statistical information on ensemble members, such as histograms and probability densities, and line charts are overlayed to allow comparing members against the ensemble. Alternative linearizations based on histogram similarities or ensemble variation allow clustering of spatial locations depending on data distribution. Multi-charts organize the data at multiple scales to quickly provide overviews and enable users to select regions exhibiting interesting behavior interactively. They are further put into a spatial context by allowing the user to brush or query value intervals and specific distributions, and to simultaneously visualize the corresponding spatial points via volume rendering. By providing a picking mechanism in 3D and instantly highlighting the corresponding data points in the chart, the user can go back and forth between the abstract and the 3D view to focus the analysis.","keywords":"Ensemble visualization, brushing and linking, statistical analysis","caption":"Fig. 1. Multi-chart visualization of a temperature ensemble forecast from the ECMWF Ensemble Prediction System (EPS), ECMWF\u2019s operational ensemble weather forecast system [30]. The ensemble consists of 51 members of resolution 256 \xd7 128 \xd7 64 each. Each bar in the multi-chart is associated with a distinct 3D subdomain, and encodes the distribution of the ensemble members in this subdomain by means of a histogram. In addition, a few user-selected ensemble members are depicted using polylines. By means of brushing in the multi-chart view (indicated by yellow background color), the user has selected regions where the range over the ensemble members and thus the uncertainty is high. The selected regions are instantly emphasized in the 3D view.","img_size":{"width":1606,"height":949},"subfigures":[{"x":9.247097207357724,"y":12.23476061961674,"width":1587.5058055852828,"height":929.7154526599188,"type":"interface","id":"interface-0"}],"visualizations":[{"x":393.68367016663524,"y":101.10207166086566,"width":933.376561359593,"height":817.6158873698882,"type":"bar_chart","id":"bar_chart-1"},{"x":392.28806428375003,"y":101.04376754364984,"width":937.5843645042861,"height":809.2340919213259,"type":"line_chart","id":"line_chart-2"},{"x":25.0668016447905,"y":118.05910148782408,"width":344.680767730203,"height":810.6134393787877,"type":"scivis","id":"scivis-0"}],"relations":[{"vislist":[{"vislist":["scivis-0"],"relation":null,"id":"group-0"}],"relation":"repeated","id":"relation-0"},{"vislist":[{"vislist":[{"vislist":[{"vislist":["line_chart-2","bar_chart-1"],"relation":null,"id":"group-1"}],"relation":"accompanied","id":"relation-1"}],"relation":null,"id":"group-2"}],"relation":"repeated","id":"relation-2"}]},"2532_0":{"comp":[["others","others",["repeated"]],["scivis","scivis",["repeated"]]],"visType":["others","scivis"],"compType":["repeated"],"compressed_tree":[{"composite_pattern":"repeated","visualization_type":[["others"]]},{"composite_pattern":"repeated","visualization_type":[["others"]]},{"composite_pattern":"repeated","visualization_type":[["others"]]},{"composite_pattern":"repeated","visualization_type":[["others"]]},{"composite_pattern":"repeated","visualization_type":[["scivis"]]}],"coOccurrence":[["others","scivis",["coOccurrence"]]],"year":2014,"conference":["SciVis"],"authors":["David Schroeder","Fedor Korsakov","Carissa Mai-Ping Knipe","Lauren Thorson","Arin M. Ellingson","David J. Nuckley","John V. Carlis","Daniel F. Keefe"],"title":"Trend-Centric Motion Visualization: Designing and Applying a New Strategy for Analyzing Scientific Motion Collections","doi":"10.1109/TVCG.2014.2346451","abstract":"In biomechanics studies, researchers collect, via experiments or simulations, datasets with hundreds or thousands of trials, each describing the same type of motion (e.g., a neck flexion-extension exercise) but under different conditions (e.g., different patients, different disease states, pre- and post-treatment). Analyzing similarities and differences across all of the trials in these collections is a major challenge. Visualizing a single trial at a time does not work, and the typical alternative of juxtaposing multiple trials in a single visual display leads to complex, difficult-to-interpret visualizations. We address this problem via a new strategy that organizes the analysis around motion trends rather than trials. This new strategy matches the cognitive approach that scientists would like to take when analyzing motion collections. We introduce several technical innovations making trend-centric motion visualization possible. First, an algorithm detects a motion collection\'s trends via time-dependent clustering. Second, a 2D graphical technique visualizes how trials leave and join trends. Third, a 3D graphical technique, using a median 3D motion plus a visual variance indicator, visualizes the biomechanics of the set of trials within each trend. These innovations are combined to create an interactive exploratory visualization tool, which we designed through an iterative process in collaboration with both domain scientists and a traditionally-trained graphic designer. We report on insights generated during this design process and demonstrate the tool\'s effectiveness via a validation study with synthetic data and feedback from expert musculoskeletal biomechanics researchers who used the tool to analyze the effects of disc degeneration on human spinal kinematics.","keywords":"Design studies, focus + context techniques, integrating spatial and non-spatial data visualization, visual design, biomedical and medical visualization","caption":"Fig. 1. This trend-centric motion visualization helps scientists analyze human neck kinematic data in a new way. Rather than analyzing a single specific trial in detail, what scientists would most like to do with these data is to identify similarities and differences across the entire collection of trials in order to classify motions as healthy vs. non-healthy or suggest appropriate courses of treatment. Trend-centric motion visualization helps scientists accomplish this analysis by: 1. identifying the trends in a motion collection; 2. displaying the trends in the form of the 2D timeline shown at the bottom of the figure; 3. displaying the 4D anatomical context needed to interpret the trends, as shown at the top of the figure; and 4. combining all these elements into an exploratory visualization system that supports interactive selection and querying.","img_size":{"width":1172,"height":672},"subfigures":[{"x":4.428220820877963,"y":8.663602883437791,"width":1159.4738451217231,"height":658.344345824517,"type":"interface","id":"interface-0"}],"visualizations":[{"x":8.106013204036177,"y":513.4285143810871,"width":1148.5515379302253,"height":155.5279688950046,"type":"others","id":"others-0"},{"x":1052.474084530856,"y":15.81762850202875,"width":91.52436533075581,"height":228.0227529538985,"type":"others","id":"others-2"},{"x":1050.405322506777,"y":255.8563838528424,"width":92.56055980961253,"height":230.5610551586226,"type":"others","id":"others-3"},{"x":480.6224256450553,"y":253.80929204722722,"width":98.07350769194878,"height":232.58836162678563,"type":"others","id":"others-4"},{"x":481.6071939429506,"y":16.864442791137073,"width":94.03641804995766,"height":231.09631723335178,"type":"others","id":"others-5"},{"x":11.1358678503149,"y":16.339434224389716,"width":1129.0527338373624,"height":470.8706443911874,"type":"scivis","id":"scivis-1"}],"relations":[{"vislist":[{"vislist":["others-2"],"relation":null,"id":"group-0"}],"relation":"repeated","id":"relation-0"},{"vislist":[{"vislist":["others-3"],"relation":null,"id":"group-1"}],"relation":"repeated","id":"relation-1"},{"vislist":[{"vislist":["others-4"],"relation":null,"id":"group-2"}],"relation":"repeated","id":"relation-2"},{"vislist":[{"vislist":["others-5"],"relation":null,"id":"group-3"}],"relation":"repeated","id":"relation-3"},{"vislist":[{"vislist":["scivis-1"],"relation":null,"id":"group-4"}],"relation":"repeated","id":"relation-4"}]},"2031_8":{"comp":[["scivis","scivis",["repeated"]],["area_chart","scivis",["large_view"]]],"visType":["scivis","area_chart"],"compType":["repeated","large_view"],"compressed_tree":[{"composite_pattern":"repeated","visualization_type":[["scivis"]]},{"composite_pattern":"large_view","visualization_type":[["area_chart"],["scivis"]]}],"coOccurrence":[["scivis","area_chart",["coOccurrence"]]],"year":2010,"conference":["Vis"],"authors":["Marco Ament","Daniel Weiskopf","Hamish A. Carr"],"title":"Direct Interval Volume Visualization","doi":"10.1109/TVCG.2010.145","abstract":"We extend direct volume rendering with a unified model for generalized isosurfaces, also called interval volumes, allowing a wider spectrum of visual classification. We generalize the concept of scale-invariant opacity-typical for isosurface rendering-to semi-transparent interval volumes. Scale-invariant rendering is independent of physical space dimensions and therefore directly facilitates the analysis of data characteristics. Our model represents sharp isosurfaces as limits of interval volumes and combines them with features of direct volume rendering. Our objective is accurate rendering, guaranteeing that all isosurfaces and interval volumes are visualized in a crack-free way with correct spatial ordering. We achieve simultaneous direct and interval volume rendering by extending preintegration and explicit peak finding with data-driven splitting of ray integration and hybrid computation in physical and data domains. Our algorithm is suitable for efficient parallel processing for interactive applications as demonstrated by our CUDA implementation.","keywords":"Direct volume rendering, interval volume, isosurface, ray casting, preintegration, scale-invariant opacity","caption":"Fig. 8. Multiple renderings of the head data set. The left image shows a rendering with our model. The skull is classified with a constant white interval volume, depicted in the transfer function with the white box. In addition, two DVR contributions classify surrounding tissue. The structure of the skull is clearly visible with proper classification. The right series of images depicts the same interval volume, but modeled with DVR. The physically-based extinction coefficient of the interval is constantly increased, but either opacity is too small in the foreground or too high at the silhouette of the skull.","img_size":{"width":2112,"height":996},"subfigures":[{"x":14.795059378819717,"y":11.602315511031689,"width":2087.0118938596706,"height":971.2599136478002,"type":"single","id":"single-0"}],"visualizations":[{"x":661.580431339958,"y":695.0958103396271,"width":386.4495642601823,"height":267.414749741876,"type":"area_chart","id":"area_chart-2"},{"x":1115.3319972655943,"y":42.54101738364986,"width":967.4152697925279,"height":931.4184443161733,"type":"scivis","id":"scivis-0"},{"x":42.48973306970308,"y":53.63807751856384,"width":1032.2240893513922,"height":924.1337633797772,"type":"scivis","id":"scivis-1"}],"relations":[{"vislist":[{"vislist":["scivis-0"],"relation":null,"id":"group-0"}],"relation":"repeated","id":"relation-0"},{"vislist":[{"vislist":["area_chart-2"],"relation":null,"id":"group-1"},{"vislist":["scivis-1"],"relation":null,"id":"group-2"}],"relation":"large_view","id":"relation-1"}]},"2033_12":{"comp":[["scivis","scivis",["repeated"]]],"visType":["scivis"],"compType":["repeated"],"compressed_tree":[{"composite_pattern":"repeated","visualization_type":[["scivis"]]},{"composite_pattern":"repeated","visualization_type":[["scivis"]]}],"coOccurrence":[["scivis","scivis",["coOccurrence"]]],"year":2010,"conference":["Vis"],"authors":["Zahid Hossai","Torsten M\xf6ller"],"title":"Edge Aware Anisotropic Diffusion for 3D Scalar Data","doi":"10.1109/TVCG.2010.147","abstract":"In this paper we present a novel anisotropic diffusion model targeted for 3D scalar field data. Our model preserves material boundaries as well as fine tubular structures while noise is smoothed out. One of the major novelties is the use of the directional second derivative to define material boundaries instead of the gradient magnitude for thresholding. This results in a diffusion model that has much lower sensitivity to the diffusion parameter and smoothes material boundaries consistently compared to gradient magnitude based techniques. We empirically analyze the stability and convergence of the proposed diffusion and demonstrate its de-noising capabilities for both analytic and real data. We also discuss applications in the context of volume rendering.","keywords":"Anisotropic diffusion, PDE, De-noising, Scale-Space, Principal Curvatures","caption":"Fig. 11: Each of the Figures (11a, 11b, 11c, 11d), was derived from an experiment performed with one particular type of noise, as indicated by the corresponding captions. All the diffusions were performed with identical settings and for 25 iterations. Identical transfer functions were used to render all the 3D images above. The profile plot in each figure is a 1-D plot of the scalar values taken from a slice as indicated by the yellow line in the 2D images. The red curve is a plot of the original scalar values, the green curve is that of the noisy scalar values while the black curve is the plot of the de-noised scalar values. Note how the black curve approximates the red curve for different noise types. SNR (in dB) of the noisy andthe diffused data are also provided for each experiment.","img_size":{"width":2160,"height":2527},"subfigures":[{"x":12.918565472554679,"y":1.4231506505910665,"width":1029.0881753293172,"height":1198.7235742060193,"type":"single","id":"single-0"}],"visualizations":[{"x":26.63137505126235,"y":798.1170917641377,"width":1008.5692730076858,"height":337.08357320932606,"type":"line_chart","id":"line_chart-1"},{"x":23.311560452911877,"y":257.915417579902,"width":1004.8488269507103,"height":506.2537109889986,"type":"scivis","id":"scivis-0"},{"x":26.69676019642451,"y":16.540770903823567,"width":1001.5317858815778,"height":208.93214982195693,"type":"scivis","id":"scivis-2"}],"relations":[{"vislist":[{"vislist":["scivis-0"],"relation":null,"id":"group-0"}],"relation":"repeated","id":"relation-0"},{"vislist":[{"vislist":["scivis-2"],"relation":null,"id":"group-1"}],"relation":"repeated","id":"relation-1"}]},"2046_4":{"comp":[["line_chart","line_chart",["repeated"]]],"visType":["line_chart"],"compType":["repeated"],"compressed_tree":[{"composite_pattern":"repeated","visualization_type":[["line_chart"]]}],"coOccurrence":[["line_chart","line_chart",["coOccurrence"]]],"year":2010,"conference":["Vis"],"authors":["Kresimir Matkovic","Denis Gracanin","Mario Jelovic","Andreas Ammer","Alan Lez","Helwig Hauser"],"title":"Interactive Visual Analysis of Multiple Simulation Runs Using the Simulation Model View: Understanding and Tuning of an Electronic Unit Injector","doi":"10.1109/TVCG.2010.171","abstract":"Multiple simulation runs using the same simulation model with different values of control parameters generate a large data set that captures the behavior of the modeled phenomenon. However, there is a conceptual and visual gap between the simulation model behavior and the data set that makes data analysis more difficult. We propose a simulation model view that helps to bridge that gap by visually combining the simulation model description and the generated data. The simulation model view provides a visual outline of the simulation process and the corresponding simulation model. The view is integrated in a Coordinated Multiple Views; (CMV) system. As the simulation model view provides a limited display space, we use three levels of details. We explored the use of the simulation model view, in close collaboration with a domain expert, to understand and tune an electronic unit injector (EUI). We also developed analysis procedures based on the view. The EUI is mostly used in heavy duty Diesel engines. We were mainly interested in understanding the model and how to tune it for three different operation modes: low emission, low consumption, and high power. Very positive feedback from the domain expert shows that the use of the simulation model view and the corresponding ;analysis procedures within a CMV system represents an effective technique for interactive visual analysis of multiple simulation runs.","keywords":"Visualization in physical sciences and engineering, time series data, coordinated multiple views","caption":"Fig. 3.  Three levels of details for representing blocks in the simulation model  view.   The  first  level  shows  only  histograms,  the  second  level adds a 2D scatter plot and the third level shows curve views. The space required grows as the level increases, so the third level is shown in a separate floating view.","img_size":{"width":1023,"height":782},"subfigures":[{"x":628.1276191053546,"y":9.799621046768554,"width":390.1500470731862,"height":715.4027120892595,"type":"interface","id":"interface-0"}],"visualizations":[{"x":628.2477977079161,"y":210.3343841200334,"width":384.5723158502231,"height":503.39350661648024,"type":"line_chart","id":"line_chart-0"}],"relations":[{"vislist":[{"vislist":["line_chart-0"],"relation":null,"id":"group-0"}],"relation":"repeated","id":"relation-0"}]},"2046_13":{"comp":[["line_chart","line_chart",["repeated"]],["scatterplot","scatterplot",["repeated"]],["bar_chart","flow_diagram",["nested"]]],"visType":["line_chart","scatterplot","bar_chart","flow_diagram"],"compType":["repeated","nested"],"compressed_tree":[{"composite_pattern":"repeated","visualization_type":[["line_chart"]]},{"composite_pattern":"nested","visualization_type":[["bar_chart"],["flow_diagram"]]},{"composite_pattern":"repeated","visualization_type":[["scatterplot"]]}],"coOccurrence":[["line_chart","line_chart",["coOccurrence"]]],"year":2010,"conference":["Vis"],"authors":["Kresimir Matkovic","Denis Gracanin","Mario Jelovic","Andreas Ammer","Alan Lez","Helwig Hauser"],"title":"Interactive Visual Analysis of Multiple Simulation Runs Using the Simulation Model View: Understanding and Tuning of an Electronic Unit Injector","doi":"10.1109/TVCG.2010.171","abstract":"Multiple simulation runs using the same simulation model with different values of control parameters generate a large data set that captures the behavior of the modeled phenomenon. However, there is a conceptual and visual gap between the simulation model behavior and the data set that makes data analysis more difficult. We propose a simulation model view that helps to bridge that gap by visually combining the simulation model description and the generated data. The simulation model view provides a visual outline of the simulation process and the corresponding simulation model. The view is integrated in a Coordinated Multiple Views; (CMV) system. As the simulation model view provides a limited display space, we use three levels of details. We explored the use of the simulation model view, in close collaboration with a domain expert, to understand and tune an electronic unit injector (EUI). We also developed analysis procedures based on the view. The EUI is mostly used in heavy duty Diesel engines. We were mainly interested in understanding the model and how to tune it for three different operation modes: low emission, low consumption, and high power. Very positive feedback from the domain expert shows that the use of the simulation model view and the corresponding ;analysis procedures within a CMV system represents an effective technique for interactive visual analysis of multiple simulation runs.","keywords":"Visualization in physical sciences and engineering, time series data, coordinated multiple views","caption":"Fig. 12. A snapshot from an interactive visual analysis session with the CMV system as used in this study. On the left, six linked \u201cstandard\u201d views are shown with a brush applied to the scatterplot in the upper left. In the middle, the simulation model view is shown with linked histograms, re\ufb02ecting the same selection. On the right, details for D block are shown (as third level of detail view). ","img_size":{"width":2084,"height":769},"subfigures":[{"x":5.398124461210651,"y":6.726425289494083,"width":981.8498233133276,"height":752.5204734139692,"type":"interface","id":"interface-0"},{"x":994.5161295554196,"y":7.678143567127814,"width":797.3092422520066,"height":682.5168267002517,"type":"single","id":"single-1"},{"x":1801.5684117081476,"y":8.22105145745652,"width":274.68565412885573,"height":561.8773086414236,"type":"single","id":"single-2"}],"visualizations":[{"x":1290.9930898965877,"y":542.0443996105414,"width":106.78719921061885,"height":91.69573948421355,"type":"bar_chart","id":"bar_chart-2"},{"x":1523.986150570202,"y":201.97773761290313,"width":137.11965637714002,"height":48.45203311215262,"type":"bar_chart","id":"bar_chart-3"},{"x":1531.7474524794704,"y":317.7216245147903,"width":176.74356128235812,"height":47.046011969745514,"type":"bar_chart","id":"bar_chart-4"},{"x":666.9542624469659,"y":57.42138871205604,"width":319.9487070608166,"height":297.07034244544667,"type":"bar_chart","id":"bar_chart-6"},{"x":338.7904599655085,"y":57.47925745184746,"width":320.03285821110404,"height":302.4765670297363,"type":"bar_chart","id":"bar_chart-7"},{"x":998.0185413702519,"y":29.947095718068507,"width":786.4853610936659,"height":653.8861879251353,"type":"flow_diagram","id":"flow_diagram-1"},{"x":1804.0590371098629,"y":28.811002081583474,"width":273.65811017452853,"height":534.6752097929036,"type":"line_chart","id":"line_chart-0"},{"x":321.30315249461694,"y":357.0459208220837,"width":331.11065270592826,"height":297.87448916623606,"type":"parallel_coordinate","id":"parallel_coordinate-8"},{"x":15.523326359029696,"y":58.65172922073076,"width":299.2943698666842,"height":583.592342770774,"type":"scatterplot","id":"scatterplot-10"},{"x":663.3522680028437,"y":358.8318640856076,"width":327.1526959490609,"height":294.30260263918854,"type":"scatterplot","id":"scatterplot-5"},{"x":112.77071721945366,"y":646.5593781706851,"width":865.8214085335887,"height":99.86295687625633,"type":"table","id":"table-9"}],"relations":[{"vislist":[{"vislist":["line_chart-0"],"relation":null,"id":"group-0"}],"relation":"repeated","id":"relation-0"},{"vislist":[{"vislist":["bar_chart-3","bar_chart-4","bar_chart-2"],"relation":null,"id":"group-1"},{"vislist":["flow_diagram-1"],"relation":null,"id":"group-2"}],"relation":"nested","id":"relation-1"},{"vislist":[{"vislist":["scatterplot-10"],"relation":null,"id":"group-3"}],"relation":"repeated","id":"relation-2"}]},"2065_12":{"comp":[["line_chart","line_chart",["repeated"]]],"visType":["line_chart"],"compType":["repeated"],"compressed_tree":[{"composite_pattern":"repeated","visualization_type":[["line_chart"]]}],"coOccurrence":[["line_chart","line_chart",["coOccurrence"]]],"year":2010,"conference":["Vis"],"authors":["Samuel Gerber","Peer-Timo Bremer","Valerio Pascucci","Ross T. Whitaker"],"title":"Visual Exploration of High Dimensional Scalar Functions","doi":"10.1109/TVCG.2010.213","abstract":"An important goal of scientific data analysis is to understand the behavior of a system or process based on a sample of the system. In many instances it is possible to observe both input parameters and system outputs, and characterize the system as a high-dimensional function. Such data sets arise, for instance, in large numerical simulations, as energy landscapes in optimization problems, or in the analysis of image data relating to biological or medical parameters. This paper proposes an approach to analyze and visualizing such data sets. The proposed method combines topological and geometric techniques to provide interactive visualizations of discretely sampled high-dimensional scalar fields. The method relies on a segmentation of the parameter space using an approximate Morse-Smale complex on the cloud of point samples. For each crystal of the Morse-Smale complex, a regression of the system parameters with respect to the output yields a curve in the parameter space. The result is a simplified geometric representation of the Morse-Smale complex in the high dimensional input domain. Finally, the geometric representation is embedded in 2D, using dimension reduction, to provide a visualization platform. The geometric properties of the regression curves enable the visualization of additional information about each crystal such as local and global shape, width, length, and sampling densities. The method is illustrated on several synthetic examples of two dimensional functions. Two use cases, using data sets from the UCI machine learning repository, demonstrate the utility of the proposed approach on real data. Finally, in collaboration with domain experts the proposed method is applied to two scientific challenges. The analysis of parameters of climate simulations and their relationship to predicted global energy flux and the concentrations of chemical species in a combustion simulation and their integration with temperature.","keywords":"Morse theory, High-dimensional visualization, Morse-Smale complex","caption":"Fig. 12. (a) Visualization of UCI concrete compressive strength data set at coarsest level of detail. The domain inspection window (b) and the corresponding composition as a function of strength (a). Note the inverse relationship between water and cement as well as increasing strength with age. Additionally, we can see that \ufb02y ash tends to zero for strong mixtures. ","img_size":{"width":1050,"height":723},"subfigures":[{"x":709.3404844732905,"y":6.101429293079903,"width":324.5313885689664,"height":661.4196897662016,"type":"single","id":"single-0"}],"visualizations":[{"x":713.4009916087599,"y":9.000486466968635,"width":317.3978562887909,"height":650.6838302536618,"type":"line_chart","id":"line_chart-0"}],"relations":[{"vislist":[{"vislist":["line_chart-0"],"relation":null,"id":"group-0"}],"relation":"repeated","id":"relation-0"}]},"2061_0":{"comp":[["comb","comb",["repeated"]],["scatterplot","scivis",["large_view"]]],"visType":["comb","scatterplot","scivis"],"compType":["repeated","large_view"],"compressed_tree":[{"composite_pattern":"repeated","visualization_type":[[{"composite_pattern":"large_view","visualization_type":[["scatterplot"],["scivis"]]}]]}],"coOccurrence":[["scatterplot","scivis",["coOccurrence"]]],"year":2010,"conference":["Vis"],"authors":["Fernando Vieira Paulovich","Cl\xe1udio T. Silva","Luis Gustavo Nonato"],"title":"Two-Phase Mapping for Projecting Massive Data Sets","doi":"10.1109/TVCG.2010.207","abstract":"Most multidimensional projection techniques rely on distance (dissimilarity) information between data instances to embed high-dimensional data into a visual space. When data are endowed with Cartesian coordinates, an extra computational effort is necessary to compute the needed distances, making multidimensional projection prohibitive in applications dealing with interactivity and massive data. The novel multidimensional projection technique proposed in this work, called Part-Linear Multidimensional Projection (PLMP), has been tailored to handle multivariate data represented in Cartesian high-dimensional spaces, requiring only distance information between pairs of representative samples. This characteristic renders PLMP faster than previous methods when processing large data sets while still being competitive in terms of precision. Moreover, knowing the range of variation for data instances in the high-dimensional space, we can make PLMP a truly streaming data projection technique, a trait absent in previous methods.","keywords":"Dimensionality Reduction,Projection Methods,Visual Data Mining,Streaming Technique","caption":"Fig. 1. Large time-varying multivariate volumetric data projection. The information contained within each simulation cell is represented as a tuple in a high-dimensional Cartesian space. The proposed PLMP technique projects the high-dimensional instances into the visual space (bottom-right) in a streaming way. An inspection window (green rectangles) is delimited on the visual space and instances projected inside the inspection window, which correspond to simulation cells with similar features (mainly characterized by high gradient pressure), are rendered in 3D. The streaming projection enables the analysis/visualization of voxels with similar features (projected close to each other in the visual space) on massive time-varying data. ","img_size":{"width":2004,"height":566},"subfigures":[{"x":12.579348360276501,"y":8.444407602646308,"width":1978.8413032794467,"height":549.1111847947074,"type":"single","id":"single-0"}],"visualizations":[{"x":158.59199607608898,"y":312.8762161795199,"width":127.74693760673317,"height":229.88974339492844,"type":"scatterplot","id":"scatterplot-0"},{"x":469.9506169529679,"y":313.0920150790901,"width":121.94024632252089,"height":234.75647807909107,"type":"scatterplot","id":"scatterplot-1"},{"x":773.451610003065,"y":313.1639480456143,"width":124.77820266357168,"height":236.37872297381205,"type":"scatterplot","id":"scatterplot-2"},{"x":1088.9145423991458,"y":313.0200821125671,"width":116.06584436218287,"height":233.13423318436992,"type":"scatterplot","id":"scatterplot-3"},{"x":1431.7273619882621,"y":307.5581390241424,"width":130.43039998606997,"height":236.99367605014618,"type":"scatterplot","id":"scatterplot-4"},{"x":1785.1266804554336,"y":307.81703094289946,"width":123.62195785384864,"height":248.83866800700855,"type":"scatterplot","id":"scatterplot-5"},{"x":24.441669930341952,"y":13.100899402770349,"width":1958.651964153469,"height":539.7982011944596,"type":"scivis","id":"scivis-6"}],"relations":[{"vislist":[{"vislist":[{"vislist":[{"vislist":["scatterplot-0","scatterplot-1","scatterplot-2","scatterplot-3","scatterplot-4","scatterplot-5"],"relation":null,"id":"group-0"},{"vislist":["scivis-6"],"relation":null,"id":"group-1"}],"relation":"large_view","id":"relation-0"}],"relation":null,"id":"group-2"}],"relation":"repeated","id":"relation-1"}]},"2054_3":{"comp":[["line_chart","line_chart",["repeated"]],["heatmap","heatmap",["repeated"]],["heatmap","matrix",["nested"]],["bar_chart","scatterplot",["accompanied"]],["scatterplot","bar_chart",["accompanied"]],["scatterplot","map",["coordinated"]]],"visType":["line_chart","heatmap","matrix","bar_chart","scatterplot","map"],"compType":["repeated","nested","accompanied","coordinated"],"compressed_tree":[{"composite_pattern":"nested","visualization_type":[["heatmap"],["matrix"]]},{"composite_pattern":"repeated","visualization_type":[["line_chart"]]},{"composite_pattern":"repeated","visualization_type":[["heatmap"]]},{"composite_pattern":"coordinated","visualization_type":[["scatterplot"],["map"]]},{"composite_pattern":"accompanied","visualization_type":[["bar_chart","scatterplot"]]}],"coOccurrence":[["heatmap","matrix",["coOccurrence"]],["heatmap","line_chart",["coOccurrence"]],["heatmap","scatterplot",["coOccurrence"]],["heatmap","map",["coOccurrence"]],["heatmap","bar_chart",["coOccurrence"]],["matrix","line_chart",["coOccurrence"]],["matrix","scatterplot",["coOccurrence"]],["matrix","map",["coOccurrence"]],["matrix","bar_chart",["coOccurrence"]],["line_chart","scatterplot",["coOccurrence"]],["line_chart","map",["coOccurrence"]],["line_chart","bar_chart",["coOccurrence"]],["scatterplot","map",["coOccurrence"]],["scatterplot","bar_chart",["coOccurrence"]],["map","bar_chart",["coOccurrence"]]],"year":2010,"conference":["Vis"],"authors":["Xiaoru Yuan","He Xiao","Hanqi Guo","Peihong Guo","Wesley Kendall","Jian Huan","Yongxian Zhang"],"title":"Scalable Multi-variate Analytics of Seismic and Satellite-based Observational Data","doi":"10.1109/TVCG.2010.192","abstract":"Over the past few years, large human populations around the world have been affected by an increase in significant seismic activities. For both conducting basic scientific research and for setting critical government policies, it is crucial to be able to explore and understand seismic and geographical information obtained through all scientific instruments. In this work, we present a visual analytics system that enables explorative visualization of seismic data together with satellite-based observational data, and introduce a suite of visual analytical tools. Seismic and satellite data are integrated temporally and spatially. Users can select temporal ;and spatial ranges to zoom in on specific seismic events, as well as to inspect changes both during and after the events. Tools for designing high dimensional transfer functions have been developed to enable efficient and intuitive comprehension of the multi-modal data. Spread-sheet style comparisons are used for data drill-down as well as presentation. Comparisons between distinct seismic events are also provided for characterizing event-wise differences. Our system has been designed for scalability in terms of data size, complexity (i.e. number of modalities), and varying form factors of display environments.","keywords":"Earth Science Visualization, Multivariate Visualization, Seismic Data, Scalable Visualization","caption":"Fig. 4. Interface components of our system. Right-top, 3D view of seismic events and associated observational data; right-bottom, time-line control; left-top, image panel array; left-bottom, interface for multi-dimensional transfer function; top-center, comparison of two seismic events. ","img_size":{"width":2144,"height":711},"subfigures":[{"x":10.372273678348515,"y":5.406661981689476,"width":2126.3699460307753,"height":697.0697815679421,"type":"interface","id":"interface-0"}],"visualizations":[{"x":1162.5310471339153,"y":542.3269593929726,"width":974.4248552518942,"height":49.888903990471476,"type":"bar_chart","id":"bar_chart-8"},{"x":65.70237729530584,"y":48.300893097998056,"width":520.4852565860457,"height":396.9543538964688,"type":"heatmap","id":"heatmap-1"},{"x":608.496864832832,"y":498.14333931618677,"width":533.6490109233654,"height":194.980629337313,"type":"heatmap","id":"heatmap-4"},{"x":1168.1093493621352,"y":30.517628336486702,"width":957.5948287847204,"height":485.46373626654395,"type":"heatmap","id":"heatmap-6"},{"x":603.0034842109837,"y":29.97252529127508,"width":542.7446314968189,"height":437.3927218561322,"type":"line_chart","id":"line_chart-3"},{"x":1160.596665662695,"y":28.656649092138327,"width":968.8379148431083,"height":487.2948785821308,"type":"map","id":"map-7"},{"x":24.439345770651936,"y":13.05778766881896,"width":568.9707875709414,"height":437.1875059850824,"type":"matrix","id":"matrix-0"},{"x":35.626150810585806,"y":494.2782702327045,"width":537.1414741398492,"height":193.25668663873284,"type":"parallel_coordinate","id":"parallel_coordinate-2"},{"x":1171.8907352942347,"y":19.385420135882903,"width":955.7054789312601,"height":496.38325562909637,"type":"scatterplot","id":"scatterplot-5"},{"x":1164.378039352599,"y":592.9262468191723,"width":966.9485894740365,"height":77.26582890948491,"type":"scatterplot","id":"scatterplot-9"}],"relations":[{"vislist":[{"vislist":["heatmap-1"],"relation":null,"id":"group-0"},{"vislist":["matrix-0"],"relation":null,"id":"group-1"}],"relation":"nested","id":"relation-0"},{"vislist":[{"vislist":["line_chart-3"],"relation":null,"id":"group-2"}],"relation":"repeated","id":"relation-1"},{"vislist":[{"vislist":["heatmap-4"],"relation":null,"id":"group-3"}],"relation":"repeated","id":"relation-2"},{"vislist":[{"vislist":["scatterplot-5"],"relation":null,"id":"group-4"},{"vislist":["map-7"],"relation":null,"id":"group-5"}],"relation":"coordinated","id":"relation-3"},{"vislist":[{"vislist":["bar_chart-8","scatterplot-9"],"relation":null,"id":"group-6"}],"relation":"accompanied","id":"relation-4"}]},"2053_3":{"comp":[["area_chart","area_chart",["repeated"]],["polar_plot","polar_plot",["repeated"]],["scivis","graph",["nested"]]],"visType":["area_chart","polar_plot","scivis","graph"],"compType":["repeated","nested"],"compressed_tree":[{"composite_pattern":"nested","visualization_type":[["scivis"],["graph"]]},{"composite_pattern":"repeated","visualization_type":[["area_chart"]]},{"composite_pattern":"repeated","visualization_type":[["polar_plot"]]}],"coOccurrence":[["scivis","graph",["coOccurrence"]],["scivis","area_chart",["coOccurrence"]],["scivis","polar_plot",["coOccurrence"]],["graph","area_chart",["coOccurrence"]],["graph","polar_plot",["coOccurrence"]],["area_chart","polar_plot",["coOccurrence"]]],"year":2010,"conference":["Vis"],"authors":["Stefan Bruckner","Torsten M\xf6ller"],"title":"Result-Driven Exploration of Simulation Parameter Spaces for Visual Effects Design","doi":"10.1109/TVCG.2010.190","abstract":"Graphics artists commonly employ physically-based simulation for the generation of effects such as smoke, explosions, and similar phenomena. The task of finding the correct parameters for a desired result, however, is difficult and time-consuming as current tools provide little to no guidance. In this paper, we present a new approach for the visual exploration of such parameter spaces. Given a three-dimensional scene description, we utilize sampling and spatio-temporal clustering techniques to generate a concise overview of the achievable variations and their temporal evolution. Our visualization system then allows the user to explore the simulation space in a goal-oriented manner. Animation sequences with a set of desired characteristics can be composed using a novel search-by-example approach and interactive direct volume rendering is employed to provide instant visual feedback.","keywords":"Visual exploration, visual effects, clustering, time-dependent volume data","caption":"Fig. 3. Screenshot of our interactive exploration environment.","img_size":{"width":791,"height":540},"subfigures":[{"x":75.10103081039342,"y":70.25470970079883,"width":647.434760692086,"height":390.6395187262942,"type":"interface","id":"interface-0"}],"visualizations":[{"x":502.38894476728666,"y":86.12374702111515,"width":209.50388908642867,"height":128.03624692152124,"type":"area_chart","id":"area_chart-0"},{"x":205.7991434078777,"y":276.0778216682716,"width":514.3504335459936,"height":181.83012936048212,"type":"graph","id":"graph-2"},{"x":208.93705079489783,"y":79.46494351933711,"width":289.79690714857816,"height":194.46022515772341,"type":"heatmap","id":"heatmap-1"},{"x":75.07007216701993,"y":73.18933041601922,"width":124.66256466473749,"height":388.4582197425651,"type":"polar_plot","id":"polar_plot-3"},{"x":207.97315365579445,"y":279.0162732945193,"width":507.052714244437,"height":179.6411685546981,"type":"scivis","id":"scivis-4"}],"relations":[{"vislist":[{"vislist":["scivis-4"],"relation":null,"id":"group-0"},{"vislist":["graph-2"],"relation":null,"id":"group-1"}],"relation":"nested","id":"relation-0"},{"vislist":[{"vislist":["area_chart-0"],"relation":null,"id":"group-2"}],"relation":"repeated","id":"relation-1"},{"vislist":[{"vislist":["polar_plot-3"],"relation":null,"id":"group-3"}],"relation":"repeated","id":"relation-2"}]},"3046_3":{"comp":[["line_chart","line_chart",["repeated"]]],"visType":["line_chart"],"compType":["repeated"],"compressed_tree":[{"composite_pattern":"repeated","visualization_type":[["line_chart"]]}],"coOccurrence":[["line_chart","line_chart",["coOccurrence"]]],"year":2018,"conference":["SciVis"],"authors":["Marzieh Berenjkoub","Rodolfo Ostilla Monico","Robert S. Laramee","Guoning Chen"],"title":"Visual Analysis of Spatia-temporal Relations of Pairwise Attributes in Unsteady Flow","doi":"10.1109/TVCG.2018.2864817","abstract":"Despite significant advances in the analysis and visualization of unsteady flow, the interpretation of it\'s behavior still remains a challenge. In this work, we focus on the linear correlation and non-linear dependency of different physical attributes of unsteady flows to aid their study from a new perspective. Specifically, we extend the existing spatial correlation quantification, i.e. the Local Correlation Coefficient (LCC), to the spatio-temporal domain to study the correlation of attribute-pairs from both the Eulerian and Lagrangian views. To study the dependency among attributes, which need not be linear, we extend and compute the mutual information (MI) among attributes over time. To help visualize and interpret the derived correlation and dependency among attributes associated with a particle, we encode the correlation and dependency values on individual pathlines. Finally, to utilize the correlation and MI computation results to identify regions with interesting flow behavior, we propose a segmentation strategy of the flow domain based on the ranking of the strength of the attributes relations. We have applied our correlation and dependency metrics to a number of 2D and 3D unsteady flows with varying spatio-temporal kernel sizes to demonstrate and assess their effectiveness.","keywords":"Unsteady flow,correlation study,mutual information","caption":"Fig. 4: Sampled pathlines colored based on the ST_LCC (a), ST_VEC_LCC (b) and ST MI (c) of acceleration and Q, respectively. Each top plot in (a) and (b) shows the ST_LCC/ST_VEC_LCC values along the respective pathlines indicated by the arrows. The two sub- plots beneath each large plot show the trends of the two given attributes within a kernel. For the MI result (c), the left two histograms show the distributions of the attribute values of Q within kernels on two pathlines (indicated by the arrows), while the right two show the distributions of the values of acceleration within the same kernels. Each histogram shows two distributions of the values of the respective attribute within two different kernels sampled at t=0 (blue) and t=50 (orange) on the corresponding pathline, respectively. Since we used equal-width bins, the number of bins are different for different attributes. ","img_size":{"width":1041,"height":1431},"subfigures":[{"x":13.03040149968687,"y":9.119878725127665,"width":1016.8919664805513,"height":423.7278371906507,"type":"single","id":"single-0"}],"visualizations":[{"x":536.1856263085859,"y":12.941864399081402,"width":488.06542904283236,"height":412.1746468492295,"type":"line_chart","id":"line_chart-0"},{"x":7.147646277856409,"y":1.37894862260255,"width":501.4097173445081,"height":429.43664991191577,"type":"scivis","id":"scivis-1"}],"relations":[{"vislist":[{"vislist":["line_chart-0"],"relation":null,"id":"group-0"}],"relation":"repeated","id":"relation-0"}]},"3055_0":{"comp":[["scivis","scivis",["repeated"]],["polar_plot","polar_plot",["repeated"]]],"visType":["scivis","polar_plot"],"compType":["repeated"],"compressed_tree":[{"composite_pattern":"repeated","visualization_type":[["scivis"]]},{"composite_pattern":"repeated","visualization_type":[["polar_plot"]]}],"coOccurrence":[["scivis","polar_plot",["coOccurrence"]]],"year":2018,"conference":["SciVis"],"authors":["Timothy Luciani","Andrew Burks","Cassiano Sugiyama","Jonathan Komperda","G. Elisabeta Marai"],"title":"Details-First, Show Context, Overview Last: Supporting Exploration of Viscous Fingers in Large-Scale Ensemble Simulations","doi":"10.1109/TVCG.2018.2864849","abstract":"Visualization research often seeks designs that first establish an overview of the data, in accordance to the information seeking mantra: \u201cOverview first, zoom and filter, then details on demand\u201d. However, in computational fluid dynamics (CFD), as well as in other domains, there are many situations where such a spatial overview is not relevant or practical for users, for example when the experts already have a good mental overview of the data, or when an analysis of a large overall structure may not be related to the specific, information-driven tasks of users. Using scientific workflow theory and, as a vehicle, the problem of viscous finger evolution, we advocate an alternative model that allows domain experts to explore features of interest first, then explore the context around those features, and finally move to a potentially unfamiliar summarization overview. In a model instantiation, we show how a computational back-end can identify and track over time low-level, small features, then be used to filter the context of those features while controlling the complexity of the visualization, and finally to summarize and compare simulations. We demonstrate the effectiveness of this approach with an online web-based exploration of a total volume of data approaching half a billion seven-dimensional data points, and report supportive feedback provided by domain experts with respect to both the instantiation and the theoretical model.","keywords":"theory,visualization design,details-first model,discourse paper,computational fluid dynamics","caption":"Fig. 1. The Details-first, Show Context, Overview Last model supports the interactive, web-based exploration of ensemble simulations. From left to right: detail and spatial-context panel comprising two 2D slices and a 3D flow view; a temporal-context panel comprising a time chart and a finger forest; overview panel showing a small multiple of Kiviat diagrams. Linked interaction and a computational back-bone allow users to identify fingers and track their evolution over time, and to analyze the data at multiple levels of detail.","img_size":{"width":1963,"height":941},"subfigures":[{"x":13.747120594231712,"y":13.430410824015668,"width":1938.3573215538938,"height":919.8414835899728,"type":"interface","id":"interface-0"}],"visualizations":[{"x":823.448566328575,"y":167.37478082101686,"width":456.35335241326624,"height":139.26566519629847,"type":"line_chart","id":"line_chart-2"},{"x":1328.1190443042235,"y":218.86521995257755,"width":594.9885890753797,"height":555.1567571128071,"type":"polar_plot","id":"polar_plot-4"},{"x":16.5674893517156,"y":165.24780165491876,"width":343.8224987718548,"height":735.0336695332738,"type":"scivis","id":"scivis-0"},{"x":385.8606701762736,"y":277.84167459335833,"width":401.7203733251073,"height":556.5444009725611,"type":"scivis","id":"scivis-1"},{"x":828.7873386045195,"y":323.33386948549065,"width":473.3796073814583,"height":590.0892840314065,"type":"tree","id":"tree-3"}],"relations":[{"vislist":[{"vislist":["scivis-0"],"relation":null,"id":"group-0"}],"relation":"repeated","id":"relation-0"},{"vislist":[{"vislist":["polar_plot-4"],"relation":null,"id":"group-1"}],"relation":"repeated","id":"relation-1"}]},"3055_4":{"comp":[["scivis","scivis",["repeated"]]],"visType":["scivis"],"compType":["repeated"],"compressed_tree":[{"composite_pattern":"repeated","visualization_type":[["scivis"]]}],"coOccurrence":[["scivis","scivis",["coOccurrence"]]],"year":2018,"conference":["SciVis"],"authors":["Timothy Luciani","Andrew Burks","Cassiano Sugiyama","Jonathan Komperda","G. Elisabeta Marai"],"title":"Details-First, Show Context, Overview Last: Supporting Exploration of Viscous Fingers in Large-Scale Ensemble Simulations","doi":"10.1109/TVCG.2018.2864849","abstract":"Visualization research often seeks designs that first establish an overview of the data, in accordance to the information seeking mantra: \u201cOverview first, zoom and filter, then details on demand\u201d. However, in computational fluid dynamics (CFD), as well as in other domains, there are many situations where such a spatial overview is not relevant or practical for users, for example when the experts already have a good mental overview of the data, or when an analysis of a large overall structure may not be related to the specific, information-driven tasks of users. Using scientific workflow theory and, as a vehicle, the problem of viscous finger evolution, we advocate an alternative model that allows domain experts to explore features of interest first, then explore the context around those features, and finally move to a potentially unfamiliar summarization overview. In a model instantiation, we show how a computational back-end can identify and track over time low-level, small features, then be used to filter the context of those features while controlling the complexity of the visualization, and finally to summarize and compare simulations. We demonstrate the effectiveness of this approach with an online web-based exploration of a total volume of data approaching half a billion seven-dimensional data points, and report supportive feedback provided by domain experts with respect to both the instantiation and the theoretical model.","keywords":"theory,visualization design,details-first model,discourse paper,computational fluid dynamics","caption":"Fig. 5. Three snapshots through the design process. Top: Filter/Context-First, Details- Last iteration.  Middle: Overview-First, Zoom and Fil- ter/Context, Details-on-Demand iteration. Bottom: Details-first, Show Context, Emphasized Overview (through bold, eye-catching colors) itera- tion. The final design (de-emphasized overview) is shown in Figure 1.","img_size":{"width":1056,"height":1535},"subfigures":[{"x":6.784812208178971,"y":638.4825627192732,"width":1038.233491946121,"height":425.7679606563311,"type":"interface","id":"interface-0"}],"visualizations":[{"x":381.7232583558871,"y":972.7560934468505,"width":246.38776327548635,"height":75.91376278144715,"type":"line_chart","id":"line_chart-4"},{"x":19.936596837870006,"y":687.9648265793123,"width":342.52698250201047,"height":339.38341439337086,"type":"scatterplot","id":"scatterplot-0"},{"x":648.6958953729468,"y":707.8920033967771,"width":199.28099119389665,"height":257.5957892347221,"type":"scivis","id":"scivis-1"},{"x":857.8619144517393,"y":655.4035635315664,"width":173.3575731445958,"height":167.58295637984415,"type":"scivis","id":"scivis-2"},{"x":861.9496795889552,"y":843.4833120386141,"width":165.182042870169,"height":170.91956665541275,"type":"scivis","id":"scivis-3"},{"x":392.22080517855784,"y":658.1607365478654,"width":246.37708781775325,"height":310.93172425645275,"type":"tree","id":"tree-5"}],"relations":[{"vislist":[{"vislist":["scivis-2","scivis-3"],"relation":null,"id":"group-0"}],"relation":"repeated","id":"relation-0"}]},"3057_0":{"comp":[["line_chart","line_chart",["repeated"]]],"visType":["line_chart"],"compType":["repeated"],"compressed_tree":[{"composite_pattern":"repeated","visualization_type":[["line_chart"]]}],"coOccurrence":[["line_chart","line_chart",["coOccurrence"]]],"year":2018,"conference":["SciVis"],"authors":["David Duran","Pedro Hermosilla","Timo Ropinski","Barbora Kozl\xedkov\xe1","Alvar Vinacua","Pere-Pau V\xe1zquez"],"title":"Visualization of Large Molecular Trajectories","doi":"10.1109/TVCG.2018.2864851","abstract":"The analysis of protein-ligand interactions is a time-intensive task. Researchers have to analyze multiple physico-chemical properties of the protein at once and combine them to derive conclusions about the protein-ligand interplay. Typically, several charts are inspected, and 3D animations can be played side-by-side to obtain a deeper understanding of the data. With the advances in simulation techniques, larger and larger datasets are available, with up to hundreds of thousands of steps. Unfortunately, such large trajectories are very difficult to investigate with traditional approaches. Therefore, the need for special tools that facilitate inspection of these large trajectories becomes substantial. In this paper, we present a novel system for visual exploration of very large trajectories in an interactive and user-friendly way. Several visualization motifs are automatically derived from the data to give the user the information about interactions between protein and ligand. Our system offers specialized widgets to ease and accelerate data inspection and navigation to interesting parts of the simulation. The system is suitable also for simulations where multiple ligands are involved. We have tested the usefulness of our tool on a set of datasets obtained from protein engineers, and we describe the expert feedback.","keywords":"Molecular visualization,simulation inspection,long trajectories","caption":"Fig. 1. Overview of the system: The 3D exploration of the molecular trajectory appears on top of the enhanced charts of three different ligands involved in a simulation. The plots are linked bidirectionally: researchers can perform selections in 2D or 3D to see relevant information highlighted in the other view. A 3D selection, for instance, will highlight the intervals of the 2D plots where the ligand interacts with the selected region.","img_size":{"width":1942,"height":1062},"subfigures":[{"x":10.204800358762236,"y":7.9415667316627845,"width":1921.5903992824767,"height":1049.0180479280866,"type":"interface","id":"interface-0"}],"visualizations":[{"x":19.049885343881268,"y":856.4816874807453,"width":1559.5944310357481,"height":186.48828166659771,"type":"line_chart","id":"line_chart-0"},{"x":8.760590181039618,"y":639.2513163022566,"width":1571.6082005087837,"height":196.22916544736665,"type":"line_chart","id":"line_chart-1"},{"x":12.165034608625115,"y":424.0617151207473,"width":1566.5122758241428,"height":188.187868634944,"type":"line_chart","id":"line_chart-2"},{"x":24.105691508681783,"y":1.1596501064837588,"width":1556.334675388263,"height":412.32543147329466,"type":"scivis","id":"scivis-3"}],"relations":[{"vislist":[{"vislist":["line_chart-1","line_chart-2","line_chart-0"],"relation":null,"id":"group-0"}],"relation":"repeated","id":"relation-0"}]},"2791_9":{"comp":[["line_chart","line_chart",["repeated"]],["scatterplot","map",["coordinated"]]],"visType":["line_chart","scatterplot","map"],"compType":["repeated","coordinated"],"compressed_tree":[{"composite_pattern":"coordinated","visualization_type":[["scatterplot"],["map"]]},{"composite_pattern":"repeated","visualization_type":[["line_chart"]]}],"coOccurrence":[["scatterplot","map",["coOccurrence"]],["scatterplot","line_chart",["coOccurrence"]],["map","line_chart",["coOccurrence"]]],"year":2016,"conference":["SciVis"],"authors":["F\xe1bio Miranda","Harish Doraiswamy","Marcos Lage","Kai Zhao","Bruno Gon\xe7alves","Luc Wilson","Mondrian Hsieh","Cl\xe1udio T. Silva"],"title":"Urban Pulse: Capturing the Rhythm of Cities","doi":"10.1109/TVCG.2016.2598585","abstract":"Cities are inherently dynamic. Interesting patterns of behavior typically manifest at several key areas of a city over multiple temporal resolutions. Studying these patterns can greatly help a variety of experts ranging from city planners and architects to human behavioral experts. Recent technological innovations have enabled the collection of enormous amounts of data that can help in these studies. However, techniques using these data sets typically focus on understanding the data in the context of the city, thus failing to capture the dynamic aspects of the city. The goal of this work is to instead understand the city in the context of multiple urban data sets. To do so, we define the concept of an \u201curban pulse\u201d which captures the spatio-temporal activity in a city across multiple temporal resolutions. The prominent pulses in a city are obtained using the topology of the data sets, and are characterized as a set of beats. The beats are then used to analyze and compare different pulses. We also design a visual exploration framework that allows users to explore the pulses within and across multiple cities under different conditions. Finally, we present three case studies carried out by experts from two different domains that demonstrate the utility of our framework.","keywords":"Topology-based techniques;urban data;visual exploration","caption":"Fig. 9. Understanding the characteristics of a neighborhood. Locations and beats of the prominent pulses corresponding to two famous neighbor- hoods in NYC and SF indicate a stark difference between their behavior. While Greenwich Village satisfies general expectations, the same is not true with respect to The Western Addition. ","img_size":{"width":2135,"height":658},"subfigures":[{"x":24.1888159768424,"y":75.89934829999709,"width":1038.3425811054394,"height":557.3287266357715,"type":"single","id":"single-0"}],"visualizations":[{"x":622.4088592648927,"y":116.58671421529428,"width":434.4473700450686,"height":513.2125903979105,"type":"line_chart","id":"line_chart-2"},{"x":26.239500350144656,"y":86.78083354799448,"width":574.0761065247486,"height":537.0938334826918,"type":"map","id":"map-0"},{"x":33.70912409616398,"y":94.18422303206775,"width":564.7864653726916,"height":527.9287152908322,"type":"scatterplot","id":"scatterplot-1"}],"relations":[{"vislist":[{"vislist":["scatterplot-1"],"relation":null,"id":"group-0"},{"vislist":["map-0"],"relation":null,"id":"group-1"}],"relation":"coordinated","id":"relation-0"},{"vislist":[{"vislist":["line_chart-2"],"relation":null,"id":"group-2"}],"relation":"repeated","id":"relation-1"}]},"2791_8":{"comp":[["line_chart","line_chart",["repeated"]],["scatterplot","map",["coordinated"]]],"visType":["line_chart","scatterplot","map"],"compType":["repeated","coordinated"],"compressed_tree":[{"composite_pattern":"coordinated","visualization_type":[["scatterplot"],["map"]]},{"composite_pattern":"coordinated","visualization_type":[["scatterplot"],["map"]]},{"composite_pattern":"repeated","visualization_type":[["line_chart"]]}],"coOccurrence":[["scatterplot","map",["coOccurrence"]],["scatterplot","line_chart",["coOccurrence"]],["map","line_chart",["coOccurrence"]]],"year":2016,"conference":["SciVis"],"authors":["F\xe1bio Miranda","Harish Doraiswamy","Marcos Lage","Kai Zhao","Bruno Gon\xe7alves","Luc Wilson","Mondrian Hsieh","Cl\xe1udio T. Silva"],"title":"Urban Pulse: Capturing the Rhythm of Cities","doi":"10.1109/TVCG.2016.2598585","abstract":"Cities are inherently dynamic. Interesting patterns of behavior typically manifest at several key areas of a city over multiple temporal resolutions. Studying these patterns can greatly help a variety of experts ranging from city planners and architects to human behavioral experts. Recent technological innovations have enabled the collection of enormous amounts of data that can help in these studies. However, techniques using these data sets typically focus on understanding the data in the context of the city, thus failing to capture the dynamic aspects of the city. The goal of this work is to instead understand the city in the context of multiple urban data sets. To do so, we define the concept of an \u201curban pulse\u201d which captures the spatio-temporal activity in a city across multiple temporal resolutions. The prominent pulses in a city are obtained using the topology of the data sets, and are characterized as a set of beats. The beats are then used to analyze and compare different pulses. We also design a visual exploration framework that allows users to explore the pulses within and across multiple cities under different conditions. Finally, we present three case studies carried out by experts from two different domains that demonstrate the utility of our framework.","keywords":"Topology-based techniques;urban data;visual exploration","caption":"Fig. 8. Using the pulse similarity, it\u2019s possible to find analogs to famous NYC landmarks. Bryant Park, for instance, is closely related to Mission Dolores Park. This data driven space characterization can significantly change how public spaces are designed. ","img_size":{"width":1025,"height":588},"subfigures":[{"x":4.3969686871598705,"y":8.347773134962093,"width":1003.3559158341852,"height":569.6981499088402,"type":"single","id":"single-0"}],"visualizations":[{"x":429.5261200655278,"y":301.05462762747186,"width":570.9905750632199,"height":273.60562363872083,"type":"line_chart","id":"line_chart-4"},{"x":6.755035712028497,"y":9.755742521191642,"width":404.8298192113014,"height":276.2498172134216,"type":"map","id":"map-0"},{"x":8.576531372102503,"y":299.2463176357213,"width":410.22796215888354,"height":274.5079523119041,"type":"map","id":"map-1"},{"x":9.432628950032063,"y":14.188669324547671,"width":397.66640588175034,"height":265.57443606649775,"type":"scatterplot","id":"scatterplot-2"},{"x":6.758241498588209,"y":302.8323219223414,"width":405.72752106495614,"height":270.05023504898213,"type":"scatterplot","id":"scatterplot-3"},{"x":432.25059016890896,"y":64.399161831701,"width":571.8704288438682,"height":234.82026135034317,"type":"scatterplot","id":"scatterplot-5"}],"relations":[{"vislist":[{"vislist":["scatterplot-2"],"relation":null,"id":"group-0"},{"vislist":["map-0"],"relation":null,"id":"group-1"}],"relation":"coordinated","id":"relation-0"},{"vislist":[{"vislist":["scatterplot-3"],"relation":null,"id":"group-2"},{"vislist":["map-1"],"relation":null,"id":"group-3"}],"relation":"coordinated","id":"relation-1"},{"vislist":[{"vislist":["line_chart-4"],"relation":null,"id":"group-4"}],"relation":"repeated","id":"relation-2"}]},"2812_8":{"comp":[["scivis","scivis",["repeated"]]],"visType":["scivis"],"compType":["repeated"],"compressed_tree":[{"composite_pattern":"repeated","visualization_type":[["scivis"]]},{"composite_pattern":"repeated","visualization_type":[["scivis"]]}],"coOccurrence":[["scivis","scivis",["coOccurrence"]]],"year":2016,"conference":["SciVis"],"authors":["Ingo Wald","Gregory P. Johnson","Jefferson Amstutz","Carson Brownlee","Aaron Knoll","J. Jeffers","J. Gunther","Paul A. Navr\xe1til"],"title":"OSPRay - A CPU Ray Tracing Framework for Scientific Visualization","doi":"10.1109/TVCG.2016.2599041","abstract":"Scientific data is continually increasing in complexity, variety and size, making efficient visualization and specifically rendering an ongoing challenge. Traditional rasterization-based visualization approaches encounter performance and quality limitations, particularly in HPC environments without dedicated rendering hardware. In this paper, we present OSPRay, a turn-key CPU ray tracing framework oriented towards production-use scientific visualization which can utilize varying SIMD widths and multiple device backends found across diverse HPC resources. This framework provides a high-quality, efficient CPU-based solution for typical visualization workloads, which has already been integrated into several prevalent visualization packages. We show that this system delivers the performance, high-level API simplicity, and modular device support needed to provide a compelling new rendering framework for implementing efficient scientific visualization workflows.","keywords":"","caption":"Fig. 8. Though still in Beta release, our OSPRay implementation is already prototypically integrated into three of the most widely used visualization tools, from left to right: VisIt; ParaView; VMD; a prototypical integration into VTK (done by Dave DeMarle at Kitware), showing a simple VTK application using three different VTK renderers\u2014OpenGL points, GL Point Sprites, and OSPRay\u2014side-by-side. Note the improvement in partical locality with ambient occlusion.","img_size":{"width":2109,"height":423},"subfigures":[{"x":3.7226614358053536,"y":11.246411142743757,"width":398.16502968299324,"height":400.5071777145122,"type":"interface","id":"interface-0"},{"x":430.3404992383411,"y":14.25784424499681,"width":562.0613018330849,"height":397.54602009614393,"type":"interface","id":"interface-1"},{"x":1020.3707246682268,"y":9.740788410063038,"width":434.36477884650594,"height":401.9875688868057,"type":"interface","id":"interface-2"},{"x":1487.243810138328,"y":11.201689125617166,"width":612.723719457881,"height":397.5349131626294,"type":"interface","id":"interface-3"}],"visualizations":[{"x":1490.1132763095575,"y":25.561634898481902,"width":602.1061029075022,"height":375.6063081519604,"type":"scivis","id":"scivis-0"},{"x":1023.952781126811,"y":131.64787480687275,"width":425.70706461912647,"height":267.8620109050576,"type":"scivis","id":"scivis-1"},{"x":555.4095679691682,"y":98.7468489123488,"width":438.2400442213702,"height":301.9626501282491,"type":"scivis","id":"scivis-2"},{"x":4.906967371401051,"y":74.82369353666859,"width":389.5993096650745,"height":321.8371262626775,"type":"scivis","id":"scivis-3"}],"relations":[{"vislist":[{"vislist":["scivis-0"],"relation":null,"id":"group-0"}],"relation":"repeated","id":"relation-0"},{"vislist":[{"vislist":["scivis-1"],"relation":null,"id":"group-1"}],"relation":"repeated","id":"relation-1"}]},"2806_8":{"comp":[["others","others",["repeated"]],["graph","scatterplot",["nested"]]],"visType":["others","graph","scatterplot"],"compType":["repeated","nested"],"compressed_tree":[{"composite_pattern":"repeated","visualization_type":[["others"]]},{"composite_pattern":"nested","visualization_type":[["graph"],["scatterplot"]]}],"coOccurrence":[["graph","scatterplot",["coOccurrence"]]],"year":2016,"conference":["SciVis"],"authors":["Ivan Koles\xe1r","Stefan Bruckner","Ivan Viola","Helwig Hauser"],"title":"A Fractional Cartesian Composition Model for Semi-Spatial Comparative Visualization Design","doi":"10.1109/TVCG.2016.2598870","abstract":"The study of spatial data ensembles leads to substantial visualization challenges in a variety of applications. In this paper, we present a model for comparative visualization that supports the design of according ensemble visualization solutions by partial automation. We focus on applications, where the user is interested in preserving selected spatial data characteristics of the data as much as possible-even when many ensemble members should be jointly studied using comparative visualization. In our model, we separate the design challenge into a minimal set of user-specified parameters and an optimization component for the automatic configuration of the remaining design variables. We provide an illustrated formal description of our model and exemplify our approach in the context of several application examples from different domains in order to demonstrate its generality within the class of comparative visualization problems for spatial data ensembles.","keywords":"Visualization Models;Integrating Spatial and Non-Spatial Data Visualization;Design Methodologies","caption":"Fig. 9. An optimized variant of a comparative visualization (right) versus a default solution (left). On the left, we see a partial unrolling of the 3D ensemble (not all of the 125 networks in the ensemble are shown). On the right, a hybrid composition is shown with 5 \xd7 5 juxtaposed superpositions of 5 colored and abstracted networks per patch. The abstraction identifies the centers of the network (represented as disk, sized according to the city center size) as well as their connections (edge width according to the number of street connections between the centers). See also Fig. 8. ","img_size":{"width":2140,"height":925},"subfigures":[{"x":6.578345953341118,"y":14.997583621847781,"width":832.0769362708168,"height":828.0784074827374,"type":"single","id":"single-0"},{"x":886.5893004330811,"y":9.358311163531479,"width":1246.5786217647328,"height":912.5090916518725,"type":"single","id":"single-1"}],"visualizations":[{"x":897.563760115792,"y":18.578934424392962,"width":1016.8625022588488,"height":882.1811797512624,"type":"graph","id":"graph-1"},{"x":15.701603466737561,"y":29.264494898687644,"width":806.1442213856286,"height":813.6354638030908,"type":"others","id":"others-2"},{"x":891.9595357464522,"y":13.053090431032311,"width":1028.070950997528,"height":897.0068353379509,"type":"scatterplot","id":"scatterplot-0"}],"relations":[{"vislist":[{"vislist":["others-2"],"relation":null,"id":"group-0"}],"relation":"repeated","id":"relation-0"},{"vislist":[{"vislist":["graph-1"],"relation":null,"id":"group-1"},{"vislist":["scatterplot-0"],"relation":null,"id":"group-2"}],"relation":"nested","id":"relation-1"}]},"2805_8":{"comp":[["map","map",["repeated"]],["matrix","matrix",["repeated"]],["scatterplot","map",["coordinated"]]],"visType":["map","matrix","scatterplot"],"compType":["repeated","coordinated"],"compressed_tree":[{"composite_pattern":"repeated","visualization_type":[["map"]]},{"composite_pattern":"repeated","visualization_type":[["matrix"]]},{"composite_pattern":"coordinated","visualization_type":[["scatterplot"],["map"]]}],"coOccurrence":[["map","matrix",["coOccurrence"]],["map","scatterplot",["coOccurrence"]],["matrix","scatterplot",["coOccurrence"]]],"year":2016,"conference":["SciVis"],"authors":["Ayan Biswas","Guang Lin","Xiaotong Liu","Han-Wei Shen"],"title":"Visualization of Time-Varying Weather Ensembles across Multiple Resolutions","doi":"10.1109/TVCG.2016.2598869","abstract":"Uncertainty quantification in climate ensembles is an important topic for the domain scientists, especially for decision making in the real-world scenarios. With powerful computers, simulations now produce time-varying and multi-resolution ensemble data sets. It is of extreme importance to understand the model sensitivity given the input parameters such that more computation power can be allocated to the parameters with higher influence on the output. Also, when ensemble data is produced at different resolutions, understanding the accuracy of different resolutions helps the total time required to produce a desired quality solution with improved storage and computation cost. In this work, we propose to tackle these non-trivial problems on the Weather Research and Forecasting (WRF) model output. We employ a moment independent sensitivity measure to quantify and analyze parameter sensitivity across spatial regions and time domain. A comparison of clustering structures across three resolutions enables the users to investigate the sensitivity variation over the spatial regions of the five input parameters. The temporal trend in the sensitivity values is explored via an MDS view linked with a line chart for interactive brushing. The spatial and temporal views are connected to provide a full exploration system for complete spatio-temporal sensitivity analysis. To analyze the accuracy across varying resolutions, we formulate a Bayesian approach to identify which regions are better predicted at which resolutions compared to the observed precipitation. This information is aggregated over the time domain and finally encoded in an output image through a custom color map that guides the domain experts towards an adaptive grid implementation given a cost model. Users can select and further analyze the spatial and temporal error patterns for multi-resolution accuracy analysis via brushing and linking on the produced image. In this work, we collaborate with a domain expert whose feedback shows the effectiveness of our proposed exploration work-flow.","keywords":"Ensemble;time-varying;multi-resolution;sensitivity analysis","caption":"Fig. 8: Visualization of our system: (A) sensitivity exploration mode, (B) accuracy analysis mode.","img_size":{"width":2002,"height":776},"subfigures":[{"x":13.16852162542046,"y":11.620225316320404,"width":1191.8986620741957,"height":758.5679448707664,"type":"interface","id":"interface-0"},{"x":1237.7495450438048,"y":13.059915075128256,"width":762.4928402903465,"height":757.1406642290029,"type":"interface","id":"interface-1"}],"visualizations":[{"x":137.87851404888227,"y":187.23740353120078,"width":472.4625747475178,"height":278.0663960020443,"type":"graph","id":"graph-0"},{"x":679.4284753119047,"y":78.7587278335879,"width":519.5308975440352,"height":459.7498054156836,"type":"heatmap","id":"heatmap-2"},{"x":1245.6760184699378,"y":358.29107715476306,"width":752.0671450316283,"height":174.05815713063168,"type":"heatmap","id":"heatmap-5"},{"x":1233.3093189941053,"y":526.4548714324035,"width":757.3757772668122,"height":225.74393037280407,"type":"heatmap","id":"heatmap-6"},{"x":1251.8049205511397,"y":13.350685767884961,"width":393.69531573918846,"height":322.48393048702997,"type":"heatmap","id":"heatmap-9"},{"x":150.17518052794864,"y":556.8544666487517,"width":451.40101755601717,"height":143.78037475115624,"type":"line_chart","id":"line_chart-1"},{"x":1650.412433218694,"y":18.22867320841808,"width":350.5144165802285,"height":330.36492659675673,"type":"line_chart","id":"line_chart-10"},{"x":1236.8531595173374,"y":354.70949675430444,"width":757.3516477536122,"height":172.40283243615076,"type":"map","id":"map-4"},{"x":1248.274898188917,"y":23.417833185877633,"width":395.457696813684,"height":321.75030374091733,"type":"map","id":"map-7"},{"x":1240.3601586510574,"y":530.0151628852943,"width":752.1035373694862,"height":225.67813586333995,"type":"matrix","id":"matrix-3"},{"x":1244.7304076012065,"y":18.3585487348226,"width":395.4831264558387,"height":323.0503871476304,"type":"scatterplot","id":"scatterplot-8"}],"relations":[{"vislist":[{"vislist":["map-4"],"relation":null,"id":"group-0"}],"relation":"repeated","id":"relation-0"},{"vislist":[{"vislist":["matrix-3"],"relation":null,"id":"group-1"}],"relation":"repeated","id":"relation-1"},{"vislist":[{"vislist":["scatterplot-8"],"relation":null,"id":"group-3"},{"vislist":["map-7"],"relation":null,"id":"group-4"}],"relation":"coordinated","id":"relation-2"}]},"2192_8":{"comp":[["bar_chart","box_plot",["accompanied"]],["box_plot","bar_chart",["accompanied"]]],"visType":["bar_chart","box_plot"],"compType":["accompanied"],"compressed_tree":[{"composite_pattern":"accompanied","visualization_type":[["bar_chart","box_plot"]]},{"composite_pattern":"accompanied","visualization_type":[["bar_chart","box_plot"]]}],"coOccurrence":[["bar_chart","box_plot",["coOccurrence"]]],"year":2011,"conference":["Vis"],"authors":["Matthew L. Parry","Philip A. Legg","David H. S. Chung","Iwan W. Griffiths","Min Chen"],"title":"Hierarchical Event Selection for Video Storyboards with a Case Study on Snooker Video Visualization","doi":"10.1109/TVCG.2011.208","abstract":"Video storyboard, which is a form of video visualization, summarizes the major events in a video using illustrative visualization. There are three main technical challenges in creating a video storyboard, (a) event classification, (b) event selection and (c) event illustration. Among these challenges, (a) is highly application-dependent and requires a significant amount of application specific semantics to be encoded in a system or manually specified by users. This paper focuses on challenges (b) and (c). In particular, we present a framework for hierarchical event representation, and an importance-based selection algorithm for supporting the creation of a video storyboard from a video. We consider the storyboard to be an event summarization for the whole video, whilst each individual illustration on the board is also an event summarization but for a smaller time window. We utilized a 3D visualization template for depicting and annotating events in illustrations. To demonstrate the concepts and algorithms developed, we use Snooker video visualization as a case study, because it has a concrete and agreeable set of semantic definitions for events and can make use of existing techniques of event detection and 3D reconstruction in a reliable manner. Nevertheless, most of our concepts and algorithms developed for challenges (b) and (c) can be applied to other application areas.","keywords":"Multimedia visualization, Time series data, Illustrative visualization","caption":"Fig. 8. Snooker visualization annotations. 8(a) shows the numbered icons used for each shot on the table. 8(b) shows the ball pot icons at the side of each pocket which correspond to the shot icons. 8(c) and 8(d) show the \u2018dashboard\u2019 that represents scoring and video timing information. 8(c) shows the state of play early in a match whilst 8(d) indicates a key moment, \u2018frame ball\u2019.","img_size":{"width":996,"height":852},"subfigures":[{"x":9.079479200507146,"y":5.697174973303502,"width":980.5615625615338,"height":827.0044974745073,"type":"single","id":"single-0"}],"visualizations":[{"x":13.15469668351893,"y":449.44176079022867,"width":824.5961552970609,"height":153.50679308179625,"type":"bar_chart","id":"bar_chart-2"},{"x":15.691909179772916,"y":672.4335067935174,"width":819.5217303045542,"height":154.71841822327372,"type":"bar_chart","id":"bar_chart-5"},{"x":19.650368480956665,"y":518.5728998939136,"width":514.1611864635903,"height":86.87725178989038,"type":"box_plot","id":"box_plot-6"},{"x":18.731277194179132,"y":744.9491877271602,"width":325.56290165877516,"height":82.22653677671438,"type":"box_plot","id":"box_plot-7"},{"x":512.3229524254112,"y":6.448241357748822,"width":475.5573135414319,"height":371.2238685708233,"type":"others","id":"others-0"},{"x":10.790923228749403,"y":7.390433383541259,"width":483.81753996298687,"height":380.2204065823484,"type":"others","id":"others-1"},{"x":828.4787774393775,"y":449.4669280451692,"width":151.57137260228845,"height":155.26994558243268,"type":"pie_chart","id":"pie_chart-3"},{"x":823.9613973191758,"y":674.1853974364303,"width":156.07193123844547,"height":150.30789343218967,"type":"pie_chart","id":"pie_chart-4"}],"relations":[{"vislist":[{"vislist":["bar_chart-2","box_plot-6"],"relation":null,"id":"group-0"}],"relation":"accompanied","id":"relation-0"},{"vislist":[{"vislist":["bar_chart-5","box_plot-7"],"relation":null,"id":"group-1"}],"relation":"accompanied","id":"relation-1"}]},"1925_12":{"comp":[["glyph_based","heatmap",["accompanied"]],["heatmap","glyph_based",["accompanied"]]],"visType":["glyph_based","heatmap"],"compType":["accompanied"],"compressed_tree":[{"composite_pattern":"accompanied","visualization_type":[["glyph_based","heatmap"]]}],"coOccurrence":[["glyph_based","heatmap",["coOccurrence"]]],"year":2009,"conference":["Vis"],"authors":["Colin Ware"],"title":"Quantitative Texton Sequences for Legible Bivariate Maps","doi":"10.1109/TVCG.2009.175","abstract":"Representing bivariate scalar maps is a common but difficult visualization problem. One solution has been to use two dimensional color schemes, but the results are often hard to interpret and inaccurately read. An alternative is to use a color sequence for one variable and a texture sequence for another. This has been used, for example, in geology, but much less studied than the two dimensional color scheme, although theory suggests that it should lead to easier perceptual separation of information relating to the two variables. To make a texture sequence more clearly readable the concept of the quantitative texton sequence (QTonS) is introduced. A QTonS is defined a sequence of small graphical elements, called textons, where each texton represents a different numerical value and sets of textons can be densely displayed to produce visually differentiable textures. An experiment was carried out to compare two bivariate color coding schemes with two schemes using QTonS for one bivariate map component and a color sequence for the other. Two different key designs were investigated (a key being a sequence of colors or textures used in obtaining quantitative values from a map). The first design used two separate keys, one for each dimension, in order to measure how accurately subjects could independently estimate the underlying scalar variables. The second key design was two dimensional and intended to measure the overall integral accuracy that could be obtained. The results show that the accuracy is substantially higher for the QTonS/color sequence schemes. A hypothesis that texture/color sequence combinations are better for independent judgments of mapped quantities was supported. A second experiment probed the limits of spatial resolution for QTonSs.","keywords":"Bivariate maps, texture, texton, legibility, quantitative texton sequence, QTonS","caption":"Fig. 9.  The display screen used in experiment 2. This is the example with 10 textons per degree.  To see this example to scale look at this image from approximately 1.1 meters.  ","img_size":{"width":1529,"height":819},"subfigures":[{"x":4.583499461975974,"y":5.543362957306717,"width":1523.317682405164,"height":810.5281435600596,"type":"single","id":"single-0"}],"visualizations":[{"x":10.442409446698425,"y":13.527770268125728,"width":1504.2479120828077,"height":795.8148473476084,"type":"glyph_based","id":"glyph_based-1"},{"x":6.730920999408409,"y":9.678512705214567,"width":806.861109390475,"height":799.6429745895707,"type":"heatmap","id":"heatmap-0"}],"relations":[{"vislist":[{"vislist":["glyph_based-1","heatmap-0"],"relation":null,"id":"group-0"}],"relation":"accompanied","id":"relation-0"}]},"3184_0":{"comp":[["bar_chart","scatterplot",["accompanied"]],["bar_chart","matrix",["stacked","nested"]],["scatterplot","bar_chart",["accompanied"]],["comb","matrix",["nested"]],["matrix","bar_chart",["stacked"]]],"visType":["bar_chart","scatterplot","matrix","comb"],"compType":["accompanied","stacked","nested"],"compressed_tree":[{"composite_pattern":"nested","visualization_type":[["bar_chart",{"composite_pattern":"accompanied","visualization_type":[["bar_chart","scatterplot"]]}],["matrix"]]},{"composite_pattern":"nested","visualization_type":[["bar_chart"],["matrix"]]},{"composite_pattern":"stacked","visualization_type":[["matrix","bar_chart"]]}],"coOccurrence":[["scatterplot","area_chart",["coOccurrence"]],["scatterplot","bar_chart",["coOccurrence"]],["scatterplot","matrix",["coOccurrence"]],["area_chart","bar_chart",["coOccurrence"]],["area_chart","matrix",["coOccurrence"]],["bar_chart","matrix",["coOccurrence"]]],"year":2019,"conference":["VAST"],"authors":["Salman Mahmood","Klaus Mueller"],"title":"Taxonomizer: A Visual Analytics Framework for Constructing Fully Labeled Hierarchies from Multivariate Data","doi":"10.1109/TVCG.2019.2895642","abstract":"Organizing multivariate data spaces by their dimensions or attributes can be a rather difficult task. Most of the work in this area focuses on the statistical aspects such as correlation clustering, dimension reduction, and the like. These methods typically produce hierarchies in which the leaf nodes are labeled by the attribute names while the inner nodes are often represented by just a statistical measure and criterion, such as a threshold. This makes them difficult to understand for mainstream users. Taxonomies in science, biology, engineering, etc. on the other hand, are easy to comprehend since they provide meaningful labels at the inner nodes as well. Labeling inner nodes of taxonomies automatically requires the identification of hypernyms. Our proposed framework, called Taxonomizer, takes a visual analytics approach to meet this challenge. It appeals to the wisdom of humans to liaise with state of the art data analytics, neural word embeddings, and lexical databases. It consists of a set of visual tools that starts out with an automatically computed hierarchy where the leaf nodes are the original data attributes, and it then allows users to sculpt high-quality taxonomies for any multivariate dataset.","keywords":"hierarchical user pro\ufb01les, user behaviour analytics, visual analytics, cybersecurity","caption":"Fig. 1. The VASABI interface realises our multifaceted, visual user behaviour analysis approach through hierarchical pro\ufb01les. We concurrently visualise and interrelate: clusters of users based on tasks extracted with a topic-modelling based approach (top-left), user pro\ufb01les with multiple features (top-right) and distribution of sessions over time (middle). Selected sessions (brown brush over temporal histogram) are also highlighted both within the user pro\ufb01les as orange dots and analysed further in the session timeline (bottom). ","img_size":{"width":1779,"height":1117},"subfigures":[{"x":5.792266757907006,"y":1.6608125453777596,"width":1766.2275860805732,"height":1114.867145443722,"type":"interface","id":"interface-0"}],"visualizations":[{"x":799.7281851851931,"y":51.405270123543055,"width":540.6592723292891,"height":555.3240334448029,"type":"area_chart","id":"area_chart-7"},{"x":9.305919411944751,"y":645.7395826127397,"width":1749.697237543558,"height":145.30010854882414,"type":"bar_chart","id":"bar_chart-0"},{"x":1557.6632311924045,"y":815.6377084921495,"width":205.7608534676824,"height":242.00626458015466,"type":"bar_chart","id":"bar_chart-2"},{"x":8.547482175463394,"y":32.62316829459656,"width":147.57556713308793,"height":595.2657781716517,"type":"bar_chart","id":"bar_chart-5"},{"x":594.7834057476031,"y":52.53133625023258,"width":200.99629652191803,"height":542.3729663811337,"type":"bar_chart","id":"bar_chart-6"},{"x":1367.7176509428375,"y":38.30598977125093,"width":377.7729433337787,"height":545.8594781150791,"type":"bar_chart","id":"bar_chart-9"},{"x":6.383166980135023,"y":816.6628823505932,"width":1544.1000305632836,"height":238.54352469168737,"type":"matrix","id":"matrix-1"},{"x":525.8482752891564,"y":29.020786312320748,"width":1240.4677837843853,"height":584.6389841190476,"type":"matrix","id":"matrix-3"},{"x":4.811311007901645,"y":30.247619926820807,"width":518.5393129751241,"height":594.0730222348163,"type":"matrix","id":"matrix-4"},{"x":1364.4611945942308,"y":47.764684496721145,"width":379.31578245935657,"height":536.4522529399541,"type":"scatterplot","id":"scatterplot-10"},{"x":797.299617189346,"y":53.74323110560404,"width":533.6376042848093,"height":548.2705704117271,"type":"scatterplot","id":"scatterplot-8"}],"relations":[{"vislist":[{"vislist":["bar_chart-6",{"vislist":[{"vislist":["bar_chart-9","scatterplot-10"],"relation":null,"id":"group-1"}],"relation":"accompanied","id":"relation-1"},{"vislist":[{"vislist":["scatterplot-8","area_chart-7"],"relation":null,"id":"group-0"}],"relation":"accompanied","id":"relation-0"}],"relation":null,"id":"group-3"},{"vislist":["matrix-3"],"relation":null,"id":"group-2"}],"relation":"nested","id":"relation-2"},{"vislist":[{"vislist":["bar_chart-5"],"relation":null,"id":"group-5"},{"vislist":["matrix-4"],"relation":null,"id":"group-4"}],"relation":"nested","id":"relation-3"},{"vislist":[{"vislist":["matrix-1","bar_chart-2"],"relation":null,"id":"group-6"}],"relation":"stacked","id":"relation-4"}]},"3187_0":{"comp":[["contour_graph","graph",["accompanied"]],["graph","contour_graph",["accompanied"]],["bar_chart","table",["nested"]]],"visType":["contour_graph","graph","bar_chart","table"],"compType":["accompanied","nested"],"compressed_tree":[{"composite_pattern":"accompanied","visualization_type":[["contour_graph","graph"]]},{"composite_pattern":"nested","visualization_type":[["bar_chart"],["table"]]},{"composite_pattern":"nested","visualization_type":[["bar_chart"],["table"]]}],"coOccurrence":[["contour_graph","graph",["coOccurrence"]],["contour_graph","bar_chart",["coOccurrence"]],["contour_graph","table",["coOccurrence"]],["graph","bar_chart",["coOccurrence"]],["graph","table",["coOccurrence"]],["bar_chart","table",["coOccurrence"]]],"year":2019,"conference":["VAST"],"authors":["Yao Ming","Panpan Xu","Furui Cheng","Huamin Qu","Liu Ren"],"title":"ProtoSteer: Steering Deep Sequence Model with Prototypes","doi":"10.1109/TVCG.2019.2934267","abstract":"Recently we have witnessed growing adoption of deep sequence models (e.g. LSTMs) in many application domains, including predictive health care, natural language processing, and log analysis. However, the intricate working mechanism of these models confines their accessibility to the domain experts. Their black-box nature also makes it a challenging task to incorporate domain-specific knowledge of the experts into the model. In ProtoSteer (Prototype Steering), we tackle the challenge of directly involving the domain experts to steer a deep sequence model without relying on model developers as intermediaries. Our approach originates in case-based reasoning, which imitates the common human problem-solving process of consulting past experiences to solve new problems. We utilize ProSeNet (Prototype Sequence Network), which learns a small set of exemplar cases (i.e., prototypes) from historical data. In ProtoSteer they serve both as an efficient visual summary of the original data and explanations of model decisions. With ProtoSteer the domain experts can inspect, critique, and revise the prototypes interactively. The system then incorporates user-specified prototypes and incrementally updates the model. We conduct extensive case studies and expert interviews in application domains including sentiment analysis on texts and predictive diagnostics based on vehicle fault logs. The results demonstrate that involvements of domain users can help obtain more interpretable models with concise prototypes while retaining similar accuracy.","keywords":"Sequence Data, Explainable Arti\ufb01cial Intelligence (XAI), Recurrent Neural Networks (RNNs), Prototype Learning","caption":"Fig. 1: The ProtoSteer interface for interactively re\ufb01ning prototype sequence network. The prototype overview (A) presents a list of prototype sequences and their statistics on datasets. The sequence detail view (B) displays the neighboring sequences of selected prototypes. The user can interactively add, delete, and revise prototypes. All edits are traceable in the editing history (C), where the user can easily compare or revert changes. For advanced analysis, the sequence encoder view (D) projects prototypes as trajectories with a contour map showing its neighboring hidden state distribution. ","img_size":{"width":1935,"height":1036},"subfigures":[{"x":12.271275269850278,"y":4.789700086862942,"width":1912.6629355447599,"height":1020.9077695947694,"type":"interface","id":"interface-0"}],"visualizations":[{"x":1275.2402604569713,"y":115.89667950852447,"width":220.1967318974623,"height":490.9524396086732,"type":"bar_chart","id":"bar_chart-3"},{"x":1280.6708678405284,"y":675.7911547423512,"width":45.38126840893414,"height":332.95177929797353,"type":"bar_chart","id":"bar_chart-5"},{"x":1325.6529262234126,"y":489.0115115011621,"width":585.8558807484534,"height":514.398137593787,"type":"contour_graph","id":"contour_graph-0"},{"x":1332.4019793154175,"y":496.3096514154483,"width":572.0417177840071,"height":502.2491562134519,"type":"graph","id":"graph-1"},{"x":37.77675247037277,"y":104.98911113528608,"width":1471.5845783078391,"height":504.2020317863251,"type":"table","id":"table-2"},{"x":37.308207336044596,"y":669.7537151968875,"width":1291.437871481198,"height":339.7329172780275,"type":"table","id":"table-4"}],"relations":[{"vislist":[{"vislist":["contour_graph-0","graph-1"],"relation":null,"id":"group-0"}],"relation":"accompanied","id":"relation-0"},{"vislist":[{"vislist":["bar_chart-3"],"relation":null,"id":"group-2"},{"vislist":["table-2"],"relation":null,"id":"group-1"}],"relation":"nested","id":"relation-1"},{"vislist":[{"vislist":["bar_chart-5"],"relation":null,"id":"group-4"},{"vislist":["table-4"],"relation":null,"id":"group-3"}],"relation":"nested","id":"relation-2"}]},"3198_4":{"comp":[["scatterplot","heatmap",["accompanied"]],["scatterplot","line_chart",["accompanied"]],["heatmap","scatterplot",["accompanied"]],["line_chart","scatterplot",["accompanied"]]],"visType":["scatterplot","heatmap","line_chart"],"compType":["accompanied"],"compressed_tree":[{"composite_pattern":"accompanied","visualization_type":[["scatterplot","heatmap"]]},{"composite_pattern":"accompanied","visualization_type":[["scatterplot","line_chart"]]}],"coOccurrence":[["scatterplot","heatmap",["coOccurrence"]],["scatterplot","line_chart",["coOccurrence"]],["heatmap","line_chart",["coOccurrence"]]],"year":2019,"conference":["VAST"],"authors":["Jiachen Wang","Kejian Zhao","Dazhen Deng","Anqi Cao","Xiao Xie","Zheng Zhou","Hui Zhang","Yingcai Wu"],"title":"Tac-Simur: Visual Analytics for Tactic-based Match Simulation of Table Tennis","doi":"10.1109/TVCG.2019.2934630","abstract":"Simulative analysis in competitive sports can provide prospective insights, which can help improve the performance of players in future matches. However, adequately simulating the complex competition process and effectively explaining the simulation result to domain experts are typically challenging. This work presents a design study to address these challenges in table tennis. We propose a well-established hybrid second-order Markov chain model to characterize and simulate the competition process in table tennis. Compared with existing methods, our approach is the first to support the effective simulation of tactics, which represent high-level competition strategies in table tennis. Furthermore, we introduce a visual analytics system called Tac-Simur based on the proposed model for simulative visual analytics. Tac-Simur enables users to easily navigate different players and their tactics based on their respective performance in matches to identify the player and the tactics of interest for further analysis. Then, users can utilize the system to interactively explore diverse simulation tasks and visually explain the simulation results. The effectiveness and usefulness of this work are demonstrated by two case studies, in which domain experts utilize Tac-Simur to find interesting and valuable insights. The domain experts also provide positive feedback on the usability of Tac-Simur. Our work can be extended to other similar sports such as tennis and badminton.","keywords":"Radio monitoring and management, radio signal data, radio spectrum data, situation awareness, visual analytics","caption":"Figure 5. Exploring module provides four coordinated visualization views to help users achieve situation understanding. The situation exploring view (a) provides the situation information of the explored time period and frequency band. The signal exploring view (b) uses an STF diagram with a scatter visualization mode to support a multi-perspective and interactive SigData exploration. The spectrum time-frequency view (c) and spectrum amplitude-frequency view (d) present the corresponding SpeData to facilitate a joint analysis of SigData and SpeData for high-risk situation understanding. ","img_size":{"width":2146,"height":1128},"subfigures":[{"x":5.351356938869837,"y":11.223739947179293,"width":2130.4963163204343,"height":1113.9558613233933,"type":"interface","id":"interface-0"}],"visualizations":[{"x":411.15166802361955,"y":133.06087185613558,"width":1694.146385297323,"height":96.99691787877396,"type":"heatmap","id":"heatmap-0"},{"x":409.72920478056653,"y":263.93550033353387,"width":1688.8495596659693,"height":308.55189337916227,"type":"heatmap","id":"heatmap-2"},{"x":411.1469604992906,"y":600.4455955813884,"width":1706.368428522179,"height":289.2068892542275,"type":"heatmap","id":"heatmap-3"},{"x":413.7948793261499,"y":928.0283538026605,"width":1686.1460453197762,"height":173.95734111029557,"type":"line_chart","id":"line_chart-1"},{"x":415.1531801854413,"y":258.58521165853995,"width":1686.1433609736837,"height":316.54012555748903,"type":"scatterplot","id":"scatterplot-4"},{"x":423.27093407904783,"y":932.1025925185185,"width":1676.6926466176892,"height":175.30207177940045,"type":"scatterplot","id":"scatterplot-5"}],"relations":[{"vislist":[{"vislist":["scatterplot-4","heatmap-2"],"relation":null,"id":"group-2"}],"relation":"accompanied","id":"relation-0"},{"vislist":[{"vislist":["scatterplot-5","line_chart-1"],"relation":null,"id":"group-3"}],"relation":"accompanied","id":"relation-1"}]},"3225_0":{"comp":[["area_chart","bar_chart",["accompanied"]],["bar_chart","area_chart",["accompanied"]]],"visType":["area_chart","bar_chart"],"compType":["accompanied"],"compressed_tree":[{"composite_pattern":"accompanied","visualization_type":[["area_chart","bar_chart"]]}],"coOccurrence":[["area_chart","bar_chart",["coOccurrence"]]],"year":2019,"conference":["VAST"],"authors":["Anjul Tyagi","Zhen Cao","Tyler Estro","Erez Zadok","Klaus Mueller"],"title":"ICE: An Interactive Configuration Explorer for High Dimensional Parameter Spaces","doi":"10.1109/VAST47406.2019.8986923","abstract":"There are many applications where users seek to explore the impact of the settings of several categorical variables with respect to one dependent numerical variable. For example, a computer systems analyst might want to study how the type of file system or storage device affects system performance. A usual choice is the method of Parallel Sets designed to visualize multivariate categorical variables, However, we found that the magnitude of the parameter impacts on the numerical variable cannot be easily observed here. We also attempted a dimension reduction approach based on Multiple Correspondence Analysis but found that the SVD-generated 2D layout resulted in a loss of information. We hence propose a novel approach, the Interactive Configuration Explorer (ICE), which directly addresses the need of analysts to learn how the dependent numerical variable is affected by the parameter settings given multiple optimization objectives. No information is lost as ICE shows the complete distribution and statistics of the dependent variable in context with each categorical variable. Analysts can interactively filter the variables to optimize for certain goals such as achieving a system with maximum performance, low variance, etc. Our system was developed in tight collaboration with a group of systems performance researchers and its final effectiveness was evaluated with expert interviews, a comparative user study, and two case studies.","keywords":": Data Clustering\u2014Illustrative Visualization\u2014UserInterfaces\u2014High Dimensional Data;","caption":"Figure 1: A B C: Interface of our Interactive Configuration Explorer (ICE) tool used to explore high dimensional parameter spaces. This example shows the use of the ICE in a computer systems performance optimization scenario.A is the Parameter Explorer. It shows the distribution and statistics of the numerical target variable in the context of the various categorical variables (or parameters), labeled by the green buttons at the bottom of the interface (e.g., Workload, File System). Each parameter has levels e.g., Workload has 4 levels (dbsrvr, filesrvr, mailsrvr, and websrvr), and each level has an associated bar displaying the statistical information about the numerical target variable (here, system throughput) for this level. Analysts can interactively deselect (and select) parameter levels to filter out the associated parameter configurations throughout. B is the Aggregate View, which visualizes the joint distributions of all currently selected parameter levels.C is the Provenance Terminal, to keep track of the changes in the target variable over the course of the user interactions. D shows the information contained in each bar inside the Parameter Explorer and Aggregate View.","img_size":{"width":1910,"height":866},"subfigures":[{"x":17.00937793292122,"y":27.636755603846552,"width":1873.9902893398064,"height":819.685026870506,"type":"interface","id":"interface-0"}],"visualizations":[{"x":17.564084981555368,"y":50.8551399445127,"width":1042.745053937158,"height":525.2809914120586,"type":"area_chart","id":"area_chart-1"},{"x":16.92900386098877,"y":49.76291394874704,"width":1040.3920226684195,"height":526.2583286121819,"type":"bar_chart","id":"bar_chart-0"},{"x":298.29657667476926,"y":677.2481123831384,"width":668.4784018939214,"height":163.69289236307898,"type":"line_chart","id":"line_chart-2"}],"relations":[{"vislist":[{"vislist":["area_chart-1","bar_chart-0"],"relation":null,"id":"group-0"}],"relation":"accompanied","id":"relation-0"}]},"1618_10":{"comp":[["graph","graph",["accompanied"]]],"visType":["graph"],"compType":["accompanied"],"compressed_tree":[{"composite_pattern":"accompanied","visualization_type":[["graph"]]}],"coOccurrence":[["graph","graph",["coOccurrence"]]],"year":2007,"conference":["Vis"],"authors":["Huamin Qu","Wing-Yi Chan","Anbang Xu","Kai-Lun Chung","Alexis Kai-Hon Lau","Ping Guo"],"title":"Visual Analysis of the Air Pollution Problem in Hong Kong","doi":"10.1109/TVCG.2007.70523","abstract":"We present a comprehensive system for weather data visualization. Weather data are multivariate and contain vector fields formed by wind speed and direction. Several well-established visualization techniques such as parallel coordinates and polar systems are integrated into our system. We also develop various novel methods, including circular pixel bar charts embedded into polar systems, enhanced parallel coordinates with S-shape axis, and weighted complete graphs. Our system was used to analyze the air pollution problem in Hong Kong and some interesting patterns have been found.","keywords":"Weather data visualization, polar system, parallel coordinates, air pollution, visual analytics","caption":"Fig. 10. Detecting the correlation between the Air Pollution Index (API) and other attributes when API is high: (a) Initial polar system with color denoting API value. The northwest sector is chosen, plotting RSP against solar radiation. (b) Plotting RSP against SO2 instead, high API value (red pixels) are not found when SO2 is high, revealing SO2 con- tributed little to API. (c) Y-position now becomes O3 clearly correlated with API. For (b) and (c), suspicious clusters (blue clusters behind green ones) are shown. ","img_size":{"width":981,"height":667},"subfigures":[{"x":114.31386088970596,"y":-1.3943738540240869,"width":760.8872630762093,"height":272.2689893930641,"type":"single","id":"single-0"}],"visualizations":[{"x":382.4906968531796,"y":9.839005748052639,"width":264.9797692134607,"height":254.06137045657138,"type":"graph","id":"graph-0"},{"x":377.04377605882337,"y":9.54449705460359,"width":184.33752360424808,"height":186.50414356090084,"type":"graph","id":"graph-1"}],"relations":[{"vislist":[{"vislist":["graph-0","graph-1"],"relation":null,"id":"group-0"}],"relation":"accompanied","id":"relation-0"}]},"1660_14":{"comp":[["heatmap","scivis",["accompanied"]],["scivis","heatmap",["accompanied"]]],"visType":["heatmap","scivis"],"compType":["accompanied"],"compressed_tree":[{"composite_pattern":"accompanied","visualization_type":[["heatmap","scivis"]]}],"coOccurrence":[["heatmap","scivis",["coOccurrence"]]],"year":2007,"conference":["Vis"],"authors":["Christoph Heinzl","Johann Kastner","M. Eduard Gr\xf6ller"],"title":"Surface Extraction from Multi-Material Components for Metrology using Dual Energy CT","doi":"10.1109/TVCG.2007.70598","abstract":"This paper describes a novel method for creating surface models of multi-material components using dual energy computed tomography (DECT). The application scenario is metrology and dimensional measurement in industrial high resolution 3D X-ray computed tomography (3DCT). Based on the dual source / dual exposure technology this method employs 3DCT scans of a high precision micro-focus and a high energy macro-focus X-ray source. The presented work makes use of the advantages of dual X-ray exposure technology in order to facilitate dimensional measurements of multi-material components with high density material within low density material. We propose a workflow which uses image fusion and local surface extraction techniques: a prefiltering step reduces noise inherent in the data. For image fusion the datasets have to be registered. In the fusion step the benefits of both scans are combined. The structure of the specimen is taken from the low precision, blurry, high energy dataset while the sharp edges are adopted and fused into the resulting image from the high precision, crisp, low energy dataset. In the final step a reliable surface model is extracted from the fused dataset using a local adaptive technique. The major contribution of this paper is the development of a specific workflow for dimensional measurements of multi-material industrial components, which takes two X-ray CT datasets with complementary strengths and weaknesses into account. The performance of the workflow is discussed using a test specimen as well as two real world industrial parts. As result, a significant improvement in overall measurement precision, surface geometry and mean deviation to reference measurement compared to single exposure scans was facilitated.","keywords":"DECT image fusion, local surface extraction, Dual Energy CT, metrology, dimensional measurement, variance comparison","caption":"Fig. 11. Variance comparison of specimen one between CAD model and extracted surface models. Deviations are colorcoded using the same scale. (a) shows the variance comparison using a global threshold ap- plied to the LE dataset and in (b) to the HE dataset. The result when applying the DECT workflow to specimen one is depicted in (c). Arte- facts of the LE measurement can be avoided to a high extent. The smoother characteristic of the DECT surface is indicated by the large low deviation area (green).","img_size":{"width":1013,"height":664},"subfigures":[{"x":357.27319813191457,"y":3.072849124373374,"width":648.9416821540527,"height":655.0276459414314,"type":"single","id":"single-0"}],"visualizations":[{"x":368.39703267495463,"y":14.990247491327002,"width":630.9337882101248,"height":634.7261689698012,"type":"heatmap","id":"heatmap-1"},{"x":406.4536992948482,"y":12.847072636753522,"width":594.3916896304214,"height":629.1192233445719,"type":"scivis","id":"scivis-0"}],"relations":[{"vislist":[{"vislist":["heatmap-1","scivis-0"],"relation":null,"id":"group-0"}],"relation":"accompanied","id":"relation-0"}]},"3250_12":{"comp":[["line_chart","scatterplot",["accompanied"]],["scatterplot","line_chart",["accompanied"]]],"visType":["line_chart","scatterplot"],"compType":["accompanied"],"compressed_tree":[{"composite_pattern":"accompanied","visualization_type":[["line_chart","scatterplot"]]}],"coOccurrence":[],"year":2020,"conference":["InfoVis"],"authors":["Jiayun Fu","Bin Zhu","Weiwei Cui","Song Ge","Yun Wang","Haidong Zhang","He Huang","Yuanyuan Tang"],"title":"Chartem: Reviving Chart Images with Data Embedding","doi":"10.1109/TVCG.2020.3030351","abstract":"In practice, charts are widely stored as bitmap images. Although easily consumed by humans, they are not convenient for other uses. For example, changing the chart style or type or a data value in a chart image practically requires creating a completely new chart, which is often a time-consuming and error-prone process. To assist these tasks, many approaches have been proposed to automatically extract information from chart images with computer vision and machine learning techniques. Although they have achieved promising preliminary results, there are still a lot of challenges to overcome in terms of robustness and accuracy. In this paper, we propose a novel alternative approach called Chartem to address this issue directly from the root. Specifically, we design a data-embedding schema to encode a significant amount of information into the background of a chart image without interfering human perception of the chart. The embedded information, when extracted from the image, can enable a variety of visualization applications to reuse or repurpose chart images. To evaluate the effectiveness of Chartem, we conduct a user study and performance experiments on Chartem embedding and extraction algorithms. We further present several prototype applications to demonstrate the utility of Chartem.","keywords":"Chart embedding, background embedding, data embedding, chart image, chart reuse.","caption":"Fig. 8. Sample applications: (a) A Excel add-in to help users embed information into typical charts; (b) A PowerPoint add-in to help users convert chart images into chart objects; (c) A voice-over mobile app that reads embedded information. ","img_size":{"width":1998,"height":600},"subfigures":[{"x":1.7793531166745324,"y":8.153727130244361,"width":769.6260947894452,"height":547.4568337643873,"type":"interface","id":"interface-0"},{"x":789.6063637894518,"y":8.181797750197514,"width":656.7845385730652,"height":550.2995494824909,"type":"interface","id":"interface-1"},{"x":1473.8504602639641,"y":15.24413281468476,"width":276.56548129167027,"height":533.2760223955061,"type":"interface","id":"interface-2"}],"visualizations":[{"x":807.7023641577597,"y":130.84444742477726,"width":232.79470264170254,"height":146.51399522971326,"type":"bar_chart","id":"bar_chart-3"},{"x":1040.4411762192588,"y":281.2873754944023,"width":368.2817143256141,"height":238.02039149709816,"type":"bar_chart","id":"bar_chart-4"},{"x":840.4954550069912,"y":349.8467075066711,"width":163.68380167164503,"height":197.6800856894429,"type":"bar_chart","id":"bar_chart-5"},{"x":1478.2721553052033,"y":116.90311939588675,"width":268.0579959045781,"height":207.8291750351444,"type":"donut_chart","id":"donut_chart-6"},{"x":15.49029678631101,"y":118.70260861740533,"width":456.67719854901355,"height":320.3642264523658,"type":"line_chart","id":"line_chart-1"},{"x":17.239141854019163,"y":117.00089377674516,"width":454.94186804939335,"height":323.76765613368786,"type":"scatterplot","id":"scatterplot-0"}],"relations":[{"vislist":[{"vislist":["line_chart-1","scatterplot-0"],"relation":null,"id":"group-0"}],"relation":"accompanied","id":"relation-0"}]},"3254_0":{"comp":[["line_chart","scatterplot",["accompanied"]],["scatterplot","line_chart",["accompanied"]]],"visType":["line_chart","scatterplot"],"compType":["accompanied"],"compressed_tree":[{"composite_pattern":"accompanied","visualization_type":[["line_chart","scatterplot"]]}],"coOccurrence":[["line_chart","scatterplot",["coOccurrence"]]],"year":2020,"conference":["InfoVis"],"authors":["Aoyu Wu","Wai Tong","Tim Dwyer","Bongshin Lee","Petra Isenberg","Huamin Qu"],"title":"MobileVisFixer: Tailoring Web Visualizations for Mobile Phones Leveraging an Explainable Reinforcement Learning Framework","doi":"10.1109/TVCG.2020.3030423","abstract":"We contribute MobileVisFixer, a new method to make visualizations more mobile-friendly. Although mobile devices have become the primary means of accessing information on the web, many existing visualizations are not optimized for small screens and can lead to a frustrating user experience. Currently, practitioners and researchers have to engage in a tedious and time-consuming process to ensure that their designs scale to screens of different sizes, and existing toolkits and libraries provide little support in diagnosing and repairing issues. To address this challenge, MobileVisFixer automates a mobile-friendly visualization re-design process with a novel reinforcement learning framework. To inform the design of MobileVisFixer, we first collected and analyzed SVG-based visualizations on the web, and identified five common mobile-friendly issues. MobileVisFixer addresses four of these issues on single-view Cartesian visualizations with linear or discrete scales by a Markov Decision Process model that is both generalizable across various visualizations and fully explainable. MobileVisFixer deconstructs charts into declarative formats, and uses a greedy heuristic based on Policy Gradient methods to find solutions to this difficult, multi-criteria optimization problem in reasonable time. In addition, MobileVisFixer can be easily extended with the incorporation of optimization algorithms for data visualizations. Quantitative evaluation on two real-world datasets demonstrates the effectiveness and generalizability of our method.","keywords":"Mobile visualization; Responsive visualization; Machine learning for visualizations; Reinforcement learning.","caption":"Fig. 1. MobileVisFixer automatically transforms SVG-based visualizations from mobile or desktop versions into mobile-friendly designs with several modifications: (A) resize the view and modify axes; and (B) resize the view, reposition the legend, modify the title and axes. ","img_size":{"width":1782,"height":606},"subfigures":[{"x":449.712545658594,"y":68.5970382006867,"width":252.24299300576843,"height":397.6601780040003,"type":"interface","id":"interface-0"},{"x":1516.1155771931415,"y":60.91768920607315,"width":248.0768978455581,"height":403.9639629175474,"type":"interface","id":"interface-1"},{"x":857.7580597591931,"y":63.21838037978581,"width":463.8389074073877,"height":246.72261729437767,"type":"interface","id":"interface-2"}],"visualizations":[{"x":453.15108049804127,"y":77.44910692556797,"width":242.2486282885215,"height":385.02230942182877,"type":"bar_chart","id":"bar_chart-0"},{"x":859.557464004084,"y":70.66000553293796,"width":454.2718051633756,"height":234.97514126395603,"type":"line_chart","id":"line_chart-1"},{"x":862.7377922041312,"y":73.73148693166733,"width":451.0548173028118,"height":230.40549934095066,"type":"scatterplot","id":"scatterplot-2"}],"relations":[{"vislist":[{"vislist":["line_chart-1","scatterplot-2"],"relation":null,"id":"group-0"}],"relation":"accompanied","id":"relation-0"}]},"3264_9":{"comp":[["parallel_coordinate","sankey_diagram",["accompanied"]],["sankey_diagram","parallel_coordinate",["accompanied"]],["matrix","sankey_diagram",["nested"]]],"visType":["parallel_coordinate","sankey_diagram","matrix"],"compType":["accompanied","nested"],"compressed_tree":[{"composite_pattern":"accompanied","visualization_type":[["parallel_coordinate","sankey_diagram"]]},{"composite_pattern":"nested","visualization_type":[["matrix"],["sankey_diagram"]]}],"coOccurrence":[["parallel_coordinate","sankey_diagram",["coOccurrence"]],["parallel_coordinate","matrix",["coOccurrence"]],["sankey_diagram","matrix",["coOccurrence"]]],"year":2020,"conference":["InfoVis"],"authors":["Tariq Yousef","Stefan Janicke"],"title":"A Survey of Text Alignment Visualization","doi":"10.1109/TVCG.2020.3028975","abstract":"Text alignment is one of the fundamental techniques text-related domains like natural language processing, computational linguistics, and digital humanities. It compares two or more texts with each other aiming to find similar textual patterns, or to estimate in general how different or similar the texts are. Visualizing alignment results is an essential task, because it helps researchers getting a comprehensive overview of individual findings and the overall pattern structure. Different approaches have been developed to visualize and help making sense of these patterns depending on text size, alignment methods, and, most importantly, the underlying research tasks demanding for alignment. On the basis of those tasks, we reviewed existing text alignment visualization approaches, and discuss their advantages and drawbacks. We finally derive design implications and shed light on related future challenges.","keywords":"Text Alignment, Text Visualization, Collation, Text Re-Use, Plagiarism Analysis, Translation Studies","caption":"Fig. 8. Iteal combines aligned barcodes with a side-by-side view [58].","img_size":{"width":978,"height":465},"subfigures":[{"x":6.143163035768941,"y":5.829322567582093,"width":967.134371005396,"height":452.63177188043164,"type":"single","id":"single-0"}],"visualizations":[{"x":245.5498783446351,"y":30.86735633095643,"width":63.33589276486511,"height":411.0267504052021,"type":"matrix","id":"matrix-3"},{"x":914.5137466441068,"y":88.26187052601473,"width":58.212477129995214,"height":363.50373526341497,"type":"matrix","id":"matrix-4"},{"x":16.976775263655597,"y":50.606063804902604,"width":208.20043925757267,"height":400.87041815529943,"type":"parallel_coordinate","id":"parallel_coordinate-0"},{"x":16.133219228358115,"y":49.74326872287487,"width":212.47552088343727,"height":400.87123874888533,"type":"sankey_diagram","id":"sankey_diagram-1"},{"x":247.4628206821154,"y":30.101909069656244,"width":723.755527275884,"height":425.49341670632685,"type":"sankey_diagram","id":"sankey_diagram-2"}],"relations":[{"vislist":[{"vislist":["parallel_coordinate-0","sankey_diagram-1"],"relation":null,"id":"group-0"}],"relation":"accompanied","id":"relation-0"},{"vislist":[{"vislist":["matrix-4","matrix-3"],"relation":null,"id":"group-1"},{"vislist":["sankey_diagram-2"],"relation":null,"id":"group-2"}],"relation":"nested","id":"relation-1"}]},"3283_3":{"comp":[["area_chart","line_chart",["accompanied"]],["line_chart","area_chart",["accompanied"]]],"visType":["area_chart","line_chart"],"compType":["accompanied"],"compressed_tree":[{"composite_pattern":"accompanied","visualization_type":[["area_chart","line_chart"]]}],"coOccurrence":[["area_chart","line_chart",["coOccurrence"]]],"year":2020,"conference":["InfoVis"],"authors":["Jen Rogers","Austin H. Patton","Luke Harmon","Alexander Lex","Miriah Meyer"],"title":"Insights From Experiments With Rigor in an EvoBio Design Study","doi":"10.1109/TVCG.2020.3030405","abstract":"Design study is an established approach of conducting problem-driven visualization research. The academic visualization community has produced a large body of work for reporting on design studies, informed by a handful of theoretical frameworks, and applied to a broad range of application areas. The result is an abundance of reported insights into visualization design, with an emphasis on novel visualization techniques and systems as the primary contribution of these studies. In recent work we proposed a new, interpretivist perspective on design study and six companion criteria for rigor that highlight the opportunities for researchers to contribute knowledge that extends beyond visualization idioms and software. In this work we conducted a year-long collaboration with evolutionary biologists to develop an interactive tool for visual exploration of multivariate datasets and phylogenetic trees. During this design study we experimented with methods to support three of the rigor criteria: ABUNDANT, REFLEXIVE, and TRANSPARENT. As a result we contribute two novel visualization techniques for the analysis of multivariate phylogenetic datasets, three methodological recommendations for conducting design studies drawn from reflections over our process of experimentation, and two writing devices for reporting interpretivist design study. We offer this work as an example for implementing the rigor criteria to produce a diverse range of knowledge contributions.","keywords":"Methodologies, Application Motivated Visualization, Guidelines, Life Sciences Visualization, Health, Medicine, Biology,Bioinformatics, Genomics","caption":"Fig. 4. Pattern view components. (a) The user interface allows selection of a preset pattern, re\ufb01ned by adjusting the parameters for Distance, Delta, and Closeness. This interface also sorts rank pairs by top score or top rank frequency. (b) The \ufb01rst-ranked pair of paths (the species Anolis insolitus and A. angusticeps) for a convergence pattern for the trait \u201csnout vent length\u201d. The line/area chart shows the most likely values and the associated uncertainty of the trait of consecutive species, with the \u201cdelta\u201d between the species in the trait being evident in the middle. Individual species in the two extant species\u2019 ancestry are shown as rectangles. The heat map on the right show where other traits rank based on the selected pattern. ","img_size":{"width":2004,"height":420},"subfigures":[{"x":14.059720897411408,"y":9.239524381099619,"width":1987.5250446762439,"height":401.5209512378001,"type":"interface","id":"interface-0"}],"visualizations":[{"x":88.61907732442414,"y":98.7653329567557,"width":1167.4276467117818,"height":315.89589624362475,"type":"area_chart","id":"area_chart-0"},{"x":90.37634500776178,"y":100.42097114973967,"width":1165.6807633521819,"height":310.82185453393777,"type":"line_chart","id":"line_chart-1"}],"relations":[{"vislist":[{"vislist":["area_chart-0","line_chart-1"],"relation":null,"id":"group-0"}],"relation":"accompanied","id":"relation-0"}]},"3296_0":{"comp":[["graph","pie_chart",["accompanied"]],["graph","matrix",["nested"]],["pie_chart","graph",["accompanied"]],["comb","proportional_area_chart",["nested"]]],"visType":["graph","pie_chart","matrix","comb","proportional_area_chart"],"compType":["accompanied","nested"],"compressed_tree":[{"composite_pattern":"nested","visualization_type":[["graph"],["matrix"]]},{"composite_pattern":"nested","visualization_type":[[{"composite_pattern":"accompanied","visualization_type":[["graph","pie_chart"]]}],["proportional_area_chart"]]}],"coOccurrence":[["graph","matrix",["coOccurrence"]],["graph","pie_chart",["coOccurrence"]],["graph","proportional_area_chart",["coOccurrence"]],["matrix","pie_chart",["coOccurrence"]],["matrix","proportional_area_chart",["coOccurrence"]],["pie_chart","proportional_area_chart",["coOccurrence"]]],"year":2020,"conference":["VAST"],"authors":["Zhibin Niu","Runlin Li","Junqi Wu","Dawei Cheng","Jiawan Zhang"],"title":"iConViz: Interactive Visual Exploration of the Default Contagion Risk of Networked-Guarantee Loans","doi":"10.1109/VAST50239.2020.00013","abstract":"Groups of enterprises can serve as guarantees for one another and form complex networks when obtaining loans from commercial banks. During economic slowdowns, corporate default may spread like a virus and lead to large-scale defaults or even systemic financial crises. To help financial regulatory authorities and banks manage the risk associated with networked loans, we identified the default contagion risk, a pivotal issue in developing preventive measures, and established iConViz, an interactive visual analysis tool that facilitates the closed-loop analysis process. A novel financial metric, the contagion effect, was formulated to quantify the infectious consequences of guarantee chains in this type of network. Based on this metric, we designed and implemented a series of novel and coordinated views that address the analysis of financial problems. Experts evaluated the system using real-world financial data. The proposed approach grants practitioners the ability to avoid previous ad hoc analysis methodologies and extend coverage of the conventional Capital Accord to the banking industry.","keywords":" Visualization analytics, Regulatory visualization","caption":"Figure 1: System interface of iConViz: (a) Guarantee Network Explorer. It facilitates an overview of and zooming in on levels of detail regarding guarantee networks using a network tessellation layout. It also offers intuitive metaphorical symbols (Contagion Effect Badges) of contagion risk to support the selection of interesting networks. (b) Contagion Effect Matrix. This gives detailed contagion risk patterns and quanti\ufb01es severity. (c) Chain Instance Explorer. This supports further narrowing of the search space for instances of contagion from a \ufb01nancial perspective. (d) Node Instance Explorer. This visualizes the \ufb01nest-grain information on demand. ","img_size":{"width":1862,"height":915},"subfigures":[{"x":11.695878908590752,"y":11.780500876237987,"width":1841.3130867198856,"height":896.8433650410453,"type":"interface","id":"interface-0"}],"visualizations":[{"x":8.700939778854142,"y":12.628395621632231,"width":652.2162866151945,"height":883.1766250154864,"type":"graph","id":"graph-2"},{"x":660.9853408751296,"y":18.70635041099788,"width":648.4276667794755,"height":550.8997580508681,"type":"graph","id":"graph-6"},{"x":657.7409599645131,"y":21.651702879804585,"width":654.9164286007106,"height":553.2172827898179,"type":"matrix","id":"matrix-5"},{"x":10.314247612437118,"y":12.604702420946388,"width":645.7048725077318,"height":879.9407195462338,"type":"pie_chart","id":"pie_chart-0"},{"x":11.956625432966826,"y":14.256370167782487,"width":647.3473145271141,"height":881.5623218584972,"type":"proportional_area_chart","id":"proportional_area_chart-1"},{"x":661.0177277623221,"y":576.5631208918672,"width":1191.9970348739212,"height":328.24160589898776,"type":"scatterplot","id":"scatterplot-3"},{"x":1315.644019507627,"y":20.329358923699367,"width":538.0617402221706,"height":550.937032896091,"type":"scatterplot","id":"scatterplot-4"}],"relations":[{"vislist":[{"vislist":["graph-6"],"relation":null,"id":"group-0"},{"vislist":["matrix-5"],"relation":null,"id":"group-1"}],"relation":"nested","id":"relation-0"},{"vislist":[{"vislist":[{"vislist":[{"vislist":["graph-2","pie_chart-0"],"relation":null,"id":"group-2"}],"relation":"accompanied","id":"relation-1"}],"relation":null,"id":"group-3"},{"vislist":["proportional_area_chart-1"],"relation":null,"id":"group-4"}],"relation":"nested","id":"relation-2"}]},"3297_1":{"comp":[["bar_chart","line_chart",["accompanied"]],["line_chart","bar_chart",["accompanied"]]],"visType":["bar_chart","line_chart"],"compType":["accompanied"],"compressed_tree":[{"composite_pattern":"accompanied","visualization_type":[["bar_chart","line_chart"]]}],"coOccurrence":[["bar_chart","line_chart",["coOccurrence"]]],"year":2020,"conference":["VAST"],"authors":["Zengsheng Zhong","Shuirun Wei","Yeting Xu","Ying Zhao","Fangfang Zhou","Feng Luo","Ronghua Shi"],"title":"SilkViser: A Visual Explorer of Blockchain-based Cryptocurrency Transaction Data","doi":"10.1109/VAST50239.2020.00014","abstract":"Many blockchain-based cryptocurrencies provide users with online blockchain explorers for viewing online transaction data. However, traditional blockchain explorers mostly present transaction information in textual and tabular forms. Such forms make understanding cryptocurrency transaction mechanisms difficult for novice users (NUsers). They are also insufficiently informative for experienced users (EUsers) to recognize advanced transaction information. This study introduces a new online cryptocurrency transaction data viewing tool called SilkViser. Guided by detailed scenario and requirement analyses, we create a series of appreciating visualization designs, such as paper ledger-inspired block and blockchain visualizations and ancient copper coin-inspired transaction visualizations, to help users understand cryptocurrency transaction mechanisms and recognize advanced transaction information. We also provide a set of lightweight interactions to facilitate easy and free data exploration. Moreover, a controlled user study is conducted to quantitatively evaluate the usability and effectiveness of SilkViser. Results indicate that SilkViser can satisfy the requirements of NUsers and EUsers. Our visualization designs can compensate for the inexperience of NUsers in data viewing and attract potential users to participate in cryptocurrency transactions.","keywords":" visualization, visual analytics, blockchain, cryptocur-rency, interactive interface","caption":"Figure 2: Visualization design of the blockchain page.","img_size":{"width":2025,"height":1143},"subfigures":[{"x":8.884377127134426,"y":8.55580898981892,"width":2008.7926600413891,"height":1130.572068927685,"type":"interface","id":"interface-0"}],"visualizations":[{"x":38.71884472162842,"y":608.8124720095598,"width":1911.8388044257133,"height":464.72735697042054,"type":"bar_chart","id":"bar_chart-1"},{"x":42.27078054440887,"y":227.0717228486606,"width":1906.5211080867068,"height":360.24455634878626,"type":"flow_diagram","id":"flow_diagram-0"},{"x":38.69714183157829,"y":610.607623466117,"width":1906.5236842861618,"height":464.70892360028324,"type":"line_chart","id":"line_chart-2"}],"relations":[{"vislist":[{"vislist":["bar_chart-1","line_chart-2"],"relation":null,"id":"group-0"}],"relation":"accompanied","id":"relation-0"}]},"3311_0":{"comp":[["bar_chart","line_chart",["accompanied"]],["bar_chart","tree",["nested"]],["bar_chart","flow_diagram",["nested"]],["line_chart","bar_chart",["accompanied"]]],"visType":["bar_chart","line_chart","tree","flow_diagram"],"compType":["accompanied","nested"],"compressed_tree":[{"composite_pattern":"nested","visualization_type":[["bar_chart"],["tree"]]},{"composite_pattern":"nested","visualization_type":[["bar_chart"],["flow_diagram"]]},{"composite_pattern":"accompanied","visualization_type":[["bar_chart","line_chart"]]},{"composite_pattern":"accompanied","visualization_type":[["line_chart","bar_chart"]]}],"coOccurrence":[["bar_chart","tree",["coOccurrence"]],["bar_chart","flow_diagram",["coOccurrence"]],["bar_chart","line_chart",["coOccurrence"]],["tree","flow_diagram",["coOccurrence"]],["tree","line_chart",["coOccurrence"]],["flow_diagram","line_chart",["coOccurrence"]]],"year":2020,"conference":["VAST"],"authors":["Tiankai Xie","Yuxin Ma","Hanghang Tong","My T. Thai","Ross Maciejewski"],"title":"Auditing the Sensitivity of Graph-based Ranking with Visual Analytics","doi":"10.1109/TVCG.2020.3028958","abstract":"Graph mining plays a pivotal role across a number of disciplines, and a variety of algorithms have been developed to answer who/what type questions. For example, what items shall we recommend to a given user on an e-commerce platform? The answers to such questions are typically returned in the form of a ranked list, and graph-based ranking methods are widely used in industrial information retrieval settings. However, these ranking algorithms have a variety of sensitivities, and even small changes in rank can lead to vast reductions in product sales and page hits. As such, there is a need for tools and methods that can help model developers and analysts explore the sensitivities of graph ranking algorithms with respect to perturbations within the graph structure. In this paper, we present a visual analytics framework for explaining and exploring the sensitivity of any graph-based ranking algorithm by performing perturbation-based what-if analysis. We demonstrate our framework through three case studies inspecting the sensitivity of two classic graph-based ranking algorithms (PageRank and HITS) as applied to rankings in political news media and social networks.","keywords":"visualization, model pruning, convolutional neural network, explainable arti\ufb01cial intelligence","caption":"Fig. 1. CNNPruner: (a) the Tree view helps to track different pruning plans; (b) the Statistics view presents model-critic statistics to monitor the pruned models; (c) the Model view enables users to interactively conduct the pruning with informative visual hints from different criteria; (d) the Filter view presents details of individual \ufb01lters for users to investigate and interactively prune them. ","img_size":{"width":1813,"height":968},"subfigures":[{"x":66.1058295752993,"y":15.085618355016736,"width":1688.7215538061703,"height":941.7953502770963,"type":"interface","id":"interface-0"}],"visualizations":[{"x":905.9950002431324,"y":750.531995901273,"width":813.3925190372289,"height":203.58433074663066,"type":"area_chart","id":"area_chart-6"},{"x":63.30495303143202,"y":64.67883201169684,"width":381.46069249782346,"height":646.8900611264953,"type":"bar_chart","id":"bar_chart-0"},{"x":1508.4298885216554,"y":39.21140429388625,"width":240.19812675533825,"height":197.6710663280771,"type":"bar_chart","id":"bar_chart-11"},{"x":1256.295355853425,"y":43.912963037637326,"width":245.52359742383038,"height":189.86588446432634,"type":"bar_chart","id":"bar_chart-13"},{"x":736.3885401077648,"y":36.09509222253874,"width":231.4788029978617,"height":205.50162609452383,"type":"bar_chart","id":"bar_chart-16"},{"x":904.433295294665,"y":750.5549803129251,"width":819.7142853102401,"height":205.13629754707847,"type":"bar_chart","id":"bar_chart-7"},{"x":469.6665162223078,"y":239.0502515166451,"width":1284.655761881243,"height":175.1061790877752,"type":"bar_chart","id":"bar_chart-8"},{"x":469.6665162223096,"y":238.95627579021732,"width":1284.6557618812442,"height":176.89206616438395,"type":"flow_diagram","id":"flow_diagram-9"},{"x":1513.235984538657,"y":34.48719350145502,"width":238.58182566152811,"height":202.3256810416868,"type":"line_chart","id":"line_chart-12"},{"x":981.4341091150527,"y":45.476278644586,"width":230.736190523027,"height":186.73925325042788,"type":"line_chart","id":"line_chart-14"},{"x":733.2032047693034,"y":39.189219362533564,"width":233.05193911066743,"height":194.51956494328024,"type":"line_chart","id":"line_chart-15"},{"x":457.7493484535615,"y":39.25577415659172,"width":251.4333151253736,"height":203.97406909766937,"type":"matrix","id":"matrix-17"},{"x":469.39646238918635,"y":407.20466461140643,"width":357.67252048523125,"height":251.0647438259925,"type":"polar_plot","id":"polar_plot-4"},{"x":69.78937088344448,"y":712.4832568782948,"width":509.219537341174,"height":244.5272250700669,"type":"scatterplot","id":"scatterplot-3"},{"x":907.8283759260216,"y":424.53677717437654,"width":848.106044184371,"height":230.78193931381136,"type":"scatterplot","id":"scatterplot-5"},{"x":61.71825533055155,"y":64.69028814984904,"width":383.034909711543,"height":648.4650844739424,"type":"tree","id":"tree-1"}],"relations":[{"vislist":[{"vislist":["bar_chart-0"],"relation":null,"id":"group-0"},{"vislist":["tree-1"],"relation":null,"id":"group-1"}],"relation":"nested","id":"relation-0"},{"vislist":[{"vislist":["bar_chart-8"],"relation":null,"id":"group-2"},{"vislist":["flow_diagram-9"],"relation":null,"id":"group-3"}],"relation":"nested","id":"relation-1"},{"vislist":[{"vislist":["bar_chart-11","line_chart-12"],"relation":null,"id":"group-4"}],"relation":"accompanied","id":"relation-2"},{"vislist":[{"vislist":["line_chart-15","bar_chart-16"],"relation":null,"id":"group-5"}],"relation":"accompanied","id":"relation-3"}]},"3385_7":{"comp":[["line_chart","bar_chart",["accompanied"]],["bar_chart","line_chart",["accompanied"]],["comb","scivis",["large_view"]]],"visType":["line_chart","bar_chart","comb","scivis"],"compType":["accompanied","large_view"],"compressed_tree":[{"composite_pattern":"large_view","visualization_type":[[{"composite_pattern":"accompanied","visualization_type":[["line_chart","bar_chart"]]}],["scivis"]]}],"coOccurrence":[["line_chart","bar_chart",["coOccurrence"]],["line_chart","scivis",["coOccurrence"]],["bar_chart","scivis",["coOccurrence"]]],"year":2020,"conference":["SciVis"],"authors":["Oskar Elek","Joseph N. Burchett","J. Xavier Prochaska","Angus G. Forbes"],"title":"Polyphorm: Structural Analysis of Cosmological Datasets via Interactive Physarum Polycephalum Visualization","doi":"10.1109/TVCG.2020.3030407","abstract":"This paper introduces Polyphorm, an interactive visualization and model fitting tool that provides a novel approach for investigating cosmological datasets. Through a fast computational simulation method inspired by the behavior of Physarum polycephalum, an unicellular slime mold organism that efficiently forages for nutrients, astrophysicists are able to extrapolate from sparse datasets, such as galaxy maps archived in the Sloan Digital Sky Survey, and then use these extrapolations to inform analyses of a wide range of other data, such as spectroscopic observations captured by the Hubble Space Telescope. Researchers can interactively update the simulation by adjusting model parameters, and then investigate the resulting visual output to form hypotheses about the data. We describe details of Polyphorm\'s simulation model and its interaction and visualization modalities, and we evaluate Polyphorm through three scientific use cases that demonstrate the effectiveness of our approach.","keywords":"Astrophysics visualization, agent-based modeling, intergalactic media, Physarum polycephalum, Cosmic Web.","caption":"Fig. 6. The initial view of Polyphorm using our example SDSS dataset. Input data are depicted as red points and the MCPM agents as white points. The \ufb01tting starts automatically, interactively responding to the current parametrization, which is controlled via the sliders on the top-left of the screen. The display in the bottom-left corner provides a statistical summary of the \ufb01tting, and the display in the bottom-right corner shows the current trimming state. (See Sec. 5 for details.) ","img_size":{"width":987,"height":603},"subfigures":[{"x":8.272350431872859,"y":10.215802384629079,"width":969.6317584522124,"height":585.8629571498038,"type":"interface","id":"interface-0"}],"visualizations":[{"x":9.373743622402127,"y":507.177493312212,"width":222.1525331876542,"height":81.6913624692563,"type":"bar_chart","id":"bar_chart-1"},{"x":12.832436233243532,"y":508.89476246158836,"width":219.58812334267859,"height":79.12639445109313,"type":"line_chart","id":"line_chart-2"},{"x":11.142852572474132,"y":9.329285864045737,"width":958.6201293276617,"height":584.3414282719083,"type":"scivis","id":"scivis-0"}],"relations":[{"vislist":[{"vislist":[{"vislist":[{"vislist":["line_chart-2","bar_chart-1"],"relation":null,"id":"group-0"}],"relation":"accompanied","id":"relation-0"}],"relation":null,"id":"group-1"},{"vislist":["scivis-0"],"relation":null,"id":"group-2"}],"relation":"large_view","id":"relation-1"}]},"2626_0":{"comp":[["box_plot","scatterplot",["accompanied"]],["box_plot","line_chart",["accompanied"]],["scatterplot","box_plot",["accompanied"]],["scatterplot","line_chart",["accompanied"]],["line_chart","box_plot",["accompanied"]],["line_chart","scatterplot",["accompanied"]],["bar_chart","bar_chart",["stacked"]]],"visType":["box_plot","scatterplot","line_chart","bar_chart"],"compType":["accompanied","stacked"],"compressed_tree":[{"composite_pattern":"accompanied","visualization_type":[["box_plot","scatterplot","line_chart"]]},{"composite_pattern":"accompanied","visualization_type":[["scatterplot","box_plot"]]},{"composite_pattern":"stacked","visualization_type":[["bar_chart"]]}],"coOccurrence":[["box_plot","scatterplot",["coOccurrence"]],["box_plot","line_chart",["coOccurrence"]],["box_plot","bar_chart",["coOccurrence"]],["scatterplot","line_chart",["coOccurrence"]],["scatterplot","bar_chart",["coOccurrence"]],["line_chart","bar_chart",["coOccurrence"]]],"year":2015,"conference":["InfoVis"],"authors":["Hendrik Strobelt","Bilal Alsallakh","Joseph Botros","Brant Peterson","Mark Borowsky","Hanspeter Pfister","Alexander Lex"],"title":"Vials: Visualizing Alternative Splicing of Genes","doi":"10.1109/TVCG.2015.2467911","abstract":"Alternative splicing is a process by which the same DNA sequence is used to assemble different proteins, called protein isoforms. Alternative splicing works by selectively omitting some of the coding regions (exons) typically associated with a gene. Detection of alternative splicing is difficult and uses a combination of advanced data acquisition methods and statistical inference. Knowledge about the abundance of isoforms is important for understanding both normal processes and diseases and to eventually improve treatment through targeted therapies. The data, however, is complex and current visualizations for isoforms are neither perceptually efficient nor scalable. To remedy this, we developed Vials, a novel visual analysis tool that enables analysts to explore the various datasets that scientists use to make judgments about isoforms: the abundance of reads associated with the coding regions of the gene, evidence for junctions, i.e., edges connecting the coding regions, and predictions of isoform frequencies. Vials is scalable as it allows for the simultaneous analysis of many samples in multiple groups. Our tool thus enables experts to (a) identify patterns of isoform abundance in groups of samples and (b) evaluate the quality of the data. We demonstrate the value of our tool in case studies using publicly available datasets.","keywords":"Biology visualization, protein isoforms, mRNA-seq, directed acyclic graphs, multivariate networks","caption":"Fig. 1. Vials showing isoforms for the gene EGFR and data from The Cancer Genome Atlas.","img_size":{"width":1980,"height":842},"subfigures":[{"x":20.973632995824868,"y":5.325291281996578,"width":1927.9858314079856,"height":829.9102447488859,"type":"interface","id":"interface-0"}],"visualizations":[{"x":18.399388620922934,"y":410.65113125431697,"width":1689.371742870127,"height":256.38700568264284,"type":"bar_chart","id":"bar_chart-0"},{"x":61.725417565294485,"y":712.9955810826948,"width":1663.8050286661773,"height":125.19342605662222,"type":"bar_chart","id":"bar_chart-4"},{"x":68.5293795188879,"y":6.740717553656674,"width":1399.8800447547806,"height":198.27148384026194,"type":"box_plot","id":"box_plot-1"},{"x":1711.397550131072,"y":432.44481842858363,"width":238.08395766608277,"height":269.0538420398795,"type":"box_plot","id":"box_plot-5"},{"x":1710.2007635486514,"y":429.9427032735701,"width":247.9870426310521,"height":270.2991434370691,"type":"line_chart","id":"line_chart-6"},{"x":63.5387282860286,"y":1.8001184200584117,"width":1403.6034207203975,"height":204.3937531946215,"type":"scatterplot","id":"scatterplot-2"},{"x":1712.6014936540405,"y":432.6754894711262,"width":229.4181441200435,"height":261.0746421291194,"type":"scatterplot","id":"scatterplot-3"}],"relations":[{"vislist":[{"vislist":["box_plot-5","scatterplot-3","line_chart-6"],"relation":null,"id":"group-0"}],"relation":"accompanied","id":"relation-0"},{"vislist":[{"vislist":["scatterplot-2","box_plot-1"],"relation":null,"id":"group-2"}],"relation":"accompanied","id":"relation-2"},{"vislist":[{"vislist":["bar_chart-0","bar_chart-4"],"relation":null,"id":"group-3"}],"relation":"stacked","id":"relation-3"}]},"2716_2":{"comp":[["area_chart","sankey_diagram",["accompanied"]],["sankey_diagram","area_chart",["accompanied"]],["donut_chart","matrix",["nested"]],["graph","scatterplot",["coordinated"]],["comb","comb",["stacked"]]],"visType":["area_chart","sankey_diagram","donut_chart","matrix","graph","scatterplot","comb"],"compType":["accompanied","nested","coordinated","stacked"],"compressed_tree":[{"composite_pattern":"stacked","visualization_type":[[{"composite_pattern":"nested","visualization_type":[["donut_chart"],["matrix"]]},{"composite_pattern":"accompanied","visualization_type":[["area_chart","sankey_diagram"]]}]]},{"composite_pattern":"coordinated","visualization_type":[["graph"],["scatterplot"]]}],"coOccurrence":[["donut_chart","matrix",["coOccurrence"]],["donut_chart","area_chart",["coOccurrence"]],["donut_chart","sankey_diagram",["coOccurrence"]],["donut_chart","graph",["coOccurrence"]],["donut_chart","scatterplot",["coOccurrence"]],["matrix","area_chart",["coOccurrence"]],["matrix","sankey_diagram",["coOccurrence"]],["matrix","graph",["coOccurrence"]],["matrix","scatterplot",["coOccurrence"]],["area_chart","sankey_diagram",["coOccurrence"]],["area_chart","graph",["coOccurrence"]],["area_chart","scatterplot",["coOccurrence"]],["sankey_diagram","graph",["coOccurrence"]],["sankey_diagram","scatterplot",["coOccurrence"]],["graph","scatterplot",["coOccurrence"]]],"year":2015,"conference":["VAST"],"authors":["Yanhong Wu","Naveen Pitipornvivat","Jian Zhao","Sixiao Yang","Guowei Huang","Huamin Qu"],"title":"egoSlider: Visual Analysis of Egocentric Network Evolution","doi":"10.1109/TVCG.2015.2468151","abstract":"Ego-network, which represents relationships between a specific individual, i.e., the ego, and people connected to it, i.e., alters, is a critical target to study in social network analysis. Evolutionary patterns of ego-networks along time provide huge insights to many domains such as sociology, anthropology, and psychology. However, the analysis of dynamic ego-networks remains challenging due to its complicated time-varying graph structures, for example: alters come and leave, ties grow stronger and fade away, and alter communities merge and split. Most of the existing dynamic graph visualization techniques mainly focus on topological changes of the entire network, which is not adequate for egocentric analytical tasks. In this paper, we present egoSlider, a visual analysis system for exploring and comparing dynamic ego-networks. egoSlider provides a holistic picture of the data through multiple interactively coordinated views, revealing ego-network evolutionary patterns at three different layers: a macroscopic level for summarizing the entire ego-network data, a mesoscopic level for overviewing specific individuals\' ego-network evolutions, and a microscopic level for displaying detailed temporal information of egos and their alters. We demonstrate the effectiveness of egoSlider with a usage scenario with the DBLP publication records. Also, a controlled user study indicates that in general egoSlider outperforms a baseline visualization of dynamic networks for completing egocentric analytical tasks.","keywords":"Egocentric network, dynamic graph, network visualization, glyph-based design, visual analytics","caption":"Fig. 3. The egoSlider interface consists of the following components: a) a Data Overview showing patterns of the entire dynamic ego-network data, b) a main canvas displaying detailed ego-network evolutionary history of selected individuals, c) a control panel with a search bar and a data table, and d) a toolbar for selecting datasets. Currently, the main canvas shows the Summary Timeline Views of the top 10 researchers in a DBLP collaboration network dataset based on their publication numbers, where Kwan-Liu Ma\u2019s timeline is expanded and shown in the Alter Timeline View.","img_size":{"width":1954,"height":918},"subfigures":[{"x":15.090272844855221,"y":17.085166824023304,"width":1925.238698731727,"height":886.6684746670686,"type":"interface","id":"interface-0"}],"visualizations":[{"x":366.54794413715916,"y":324.29471998038673,"width":1059.099416984479,"height":271.8849745347882,"type":"area_chart","id":"area_chart-4"},{"x":282.97592997811836,"y":50.218818380743976,"width":1151.015317286652,"height":265.1553610503283,"type":"donut_chart","id":"donut_chart-0"},{"x":282.97592997811836,"y":600.6170678336981,"width":1146.9978118161928,"height":301.3129102844638,"type":"donut_chart","id":"donut_chart-1"},{"x":19.637874876835323,"y":47.24035142396201,"width":244.39710365213432,"height":854.6846474899778,"type":"graph","id":"graph-11"},{"x":280.3819767227352,"y":50.680641932974886,"width":1153.5387161973235,"height":267.5244916223611,"type":"matrix","id":"matrix-7"},{"x":284.0756438312878,"y":608.2218903502027,"width":1148.6224884787462,"height":295.1932187716909,"type":"matrix","id":"matrix-8"},{"x":361.6265244954017,"y":321.8215513072691,"width":1064.001654901848,"height":271.88248288990053,"type":"sankey_diagram","id":"sankey_diagram-5"},{"x":17.820568927790013,"y":48.21006564551423,"width":249.0853391684902,"height":857.7374179431074,"type":"scatterplot","id":"scatterplot-2"},{"x":1546.4814004376367,"y":186.81400437636762,"width":383.67177242888397,"height":570.4857768052517,"type":"table","id":"table-3"}],"relations":[{"vislist":[{"vislist":[{"vislist":[{"vislist":["donut_chart-0"],"relation":null,"id":"group-5"},{"vislist":["matrix-7"],"relation":null,"id":"group-4"}],"relation":"nested","id":"relation-4"},{"vislist":[{"vislist":["donut_chart-1"],"relation":null,"id":"group-7"},{"vislist":["matrix-8"],"relation":null,"id":"group-6"}],"relation":"nested","id":"relation-5"},{"vislist":[{"vislist":["area_chart-4","sankey_diagram-5"],"relation":null,"id":"group-8"}],"relation":"accompanied","id":"relation-6"}],"relation":null,"id":"group-9"}],"relation":"stacked","id":"relation-7"},{"vislist":[{"vislist":["graph-11"],"relation":null,"id":"group-10"},{"vislist":["scatterplot-2"],"relation":null,"id":"group-11"}],"relation":"coordinated","id":"relation-8"}]},"2734_1":{"comp":[["error_bar","line_chart",["accompanied"]],["line_chart","error_bar",["accompanied"]]],"visType":["error_bar","line_chart"],"compType":["accompanied"],"compressed_tree":[{"composite_pattern":"accompanied","visualization_type":[["error_bar","line_chart"]]},{"composite_pattern":"accompanied","visualization_type":[["error_bar","line_chart"]]}],"coOccurrence":[["error_bar","line_chart",["coOccurrence"]]],"year":2015,"conference":["VAST"],"authors":["Markus B\xf6gl","Peter Filzmoser","Theresia Gschwandtner","Silvia Miksch","Wolfgang Aigner","Alexander Rind","Tim Lammarsch"],"title":"Visually and statistically guided imputation of missing values in univariate seasonal time series","doi":"10.1109/VAST.2015.7347672","abstract":"Missing values are a problem in many real world applications, for example failing sensor measurements. For further analysis these missing values need to be imputed. Thus, imputation of such missing values is important in a wide range of applications. We propose a visually and statistically guided imputation approach, that allows applying different imputation techniques to estimate the missing values as well as evaluating and fine tuning the imputation by visual guidance. In our approach we include additional visual information about uncertainty and employ the cyclic structure of time inherent in the data. Including this cyclic structure enables visually judging the adequateness of the estimated values with respect to the uncertainty/error boundaries and according to the patterns of the neighbouring time points in linear and cyclic (e.g., the months of the year) time.","keywords":"","caption":"Figure 1: Overview of our approach for visually and statistically guided imputation. Coordinated views with (a) a time series line plot using a linear time axis, (b) the corresponding cycle plot (for details cf. supplementary), and (c) a configuration panel. The estimated values (black dots) of missing values and boundaries (red bars) are displayed. Upon request, more details are shown in (a) and (b), either by explicitly selecting the level of detail in (c), or by interaction as described in Figure 2. The latter allows the user to adjust the estimated value by dragging the dot up/down. When clicking a point in one window, (a) or (b), the corresponding point in the other window gets highlighted as well.","img_size":{"width":2109,"height":447},"subfigures":[{"x":973.3546975325154,"y":7.9257044073578085,"width":1121.2131942342646,"height":421.95269552184436,"type":"interface","id":"interface-0"},{"x":8.407479819305085,"y":8.051564629049448,"width":955.5707252494441,"height":430.8968707419017,"type":"interface","id":"interface-1"}],"visualizations":[{"x":6.031458531935176,"y":21.4461391801716,"width":954.9809342230697,"height":400.0867492850334,"type":"error_bar","id":"error_bar-0"},{"x":961.0123927550048,"y":9.383222116301255,"width":940.9075309818875,"height":424.212583412774,"type":"error_bar","id":"error_bar-1"},{"x":10.052430886558627,"y":17.42516682554816,"width":954.9809342230695,"height":400.08674928503336,"type":"line_chart","id":"line_chart-2"},{"x":961.0123927550048,"y":7.372735938989508,"width":940.9075309818875,"height":430.2440419447092,"type":"line_chart","id":"line_chart-3"}],"relations":[{"vislist":[{"vislist":["error_bar-0","line_chart-2"],"relation":null,"id":"group-0"}],"relation":"accompanied","id":"relation-0"},{"vislist":[{"vislist":["error_bar-1","line_chart-3"],"relation":null,"id":"group-1"}],"relation":"accompanied","id":"relation-1"}]},"2735_0":{"comp":[["stripe_graph","area_chart",["accompanied"]],["area_chart","stripe_graph",["accompanied"]],["pie_chart","scatterplot",["nested"]],["line_chart","comb",["stacked"]],["comb","line_chart",["stacked"]]],"visType":["stripe_graph","area_chart","pie_chart","scatterplot","line_chart","comb"],"compType":["accompanied","nested","stacked"],"compressed_tree":[{"composite_pattern":"stacked","visualization_type":[["line_chart",{"composite_pattern":"accompanied","visualization_type":[["stripe_graph","area_chart"]]}]]},{"composite_pattern":"nested","visualization_type":[["pie_chart"],["scatterplot"]]}],"coOccurrence":[["stripe_graph","area_chart",["coOccurrence"]],["stripe_graph","line_chart",["coOccurrence"]],["stripe_graph","pie_chart",["coOccurrence"]],["stripe_graph","scatterplot",["coOccurrence"]],["area_chart","line_chart",["coOccurrence"]],["area_chart","pie_chart",["coOccurrence"]],["area_chart","scatterplot",["coOccurrence"]],["line_chart","pie_chart",["coOccurrence"]],["line_chart","scatterplot",["coOccurrence"]],["pie_chart","scatterplot",["coOccurrence"]]],"year":2015,"conference":["VAST"],"authors":["Shenghui Cheng","Yue Wang","Dan Zhang","Zhifang Jiang","Klaus Mueller"],"title":"StreamVisND: Visualizing relationships in streaming multivariate data","doi":"10.1109/VAST.2015.7347673","abstract":"In streaming acquisitions the data changes over time. ThemeRiver and line charts are common methods to display data over time. However, these methods can only show the values of the variables (or attributes) but not the relationships among them over time. We propose a framework we call StreamVis&lt;sup&gt;ND&lt;/sup&gt; that can display these types of streaming data relations. It first slices the data stream into different time slices, then it visualizes each slice with a sequence of multivariate 2D data layouts, and finally it flattens this series of displays into a parallel coordinate type display. Our framework is fully interactive and lends itself well to real-time displays.","keywords":"","caption":"Fig.1 Visualization  of  pollution  data  with StreamVisND:  (a) The Time  Slice  Similarity  Plot whichshows the  similarity of time  slices  over time  (mapped  to  brightness),  (b)  theconfiguration  control panelwith  pollutant color  map;  (c)  the weight  function, (d)  the local  change displayof pollutant relations; (e) the Themeriver display of pollutant concentrations over time; and (f) the relationsdisplay which plots the relations of pollutant concentrations over time. Closer lines indicatehigher temporal correlation in terms of the pollutant distribution.","img_size":{"width":2053,"height":1324},"subfigures":[{"x":16.687803225786748,"y":9.861264688439801,"width":2012.3908105028902,"height":1300.6605552161227,"type":"interface","id":"interface-0"}],"visualizations":[{"x":17.507320644216634,"y":870.3894582723279,"width":1981.1537335285507,"height":195.7891654465592,"type":"area_chart","id":"area_chart-0"},{"x":1424.863103953148,"y":3.8770131771595904,"width":571.8594436310395,"height":220.98975109809663,"type":"line_chart","id":"line_chart-1"},{"x":19.445827232796432,"y":1085.5636896046851,"width":1975.338213762811,"height":222.9282576866765,"type":"line_chart","id":"line_chart-2"},{"x":208.25763327778955,"y":286.6018471199298,"width":365.2232155856356,"height":354.928617624025,"type":"pie_chart","id":"pie_chart-4"},{"x":62.092972181552,"y":0,"width":746.3250366032212,"height":835.4963396778917,"type":"scatterplot","id":"scatterplot-5"},{"x":1484.9568081991215,"y":374.13177159590043,"width":348.9311859443628,"height":358.62371888726204,"type":"scatterplot","id":"scatterplot-6"},{"x":13.057984266694806,"y":871.6898881922921,"width":1989.6122277167049,"height":198.55621648245506,"type":"stripe_graph","id":"stripe_graph-3"}],"relations":[{"vislist":[{"vislist":["line_chart-2",{"vislist":[{"vislist":["stripe_graph-3","area_chart-0"],"relation":null,"id":"group-0"}],"relation":"accompanied","id":"relation-0"}],"relation":null,"id":"group-1"}],"relation":"stacked","id":"relation-1"},{"vislist":[{"vislist":["pie_chart-4"],"relation":null,"id":"group-3"},{"vislist":["scatterplot-5"],"relation":null,"id":"group-2"}],"relation":"nested","id":"relation-2"}]},"2739_1":{"comp":[["line_chart","scatterplot",["accompanied"]],["scatterplot","line_chart",["accompanied"]],["comb","matrix",["nested"]]],"visType":["line_chart","scatterplot","comb","matrix"],"compType":["accompanied","nested"],"compressed_tree":[{"composite_pattern":"nested","visualization_type":[[{"composite_pattern":"accompanied","visualization_type":[["line_chart","scatterplot"]]}],["matrix"]]}],"coOccurrence":[],"year":2015,"conference":["VAST"],"authors":["Masahiko Itoh","Daisaku Yokoyama","Masashi Toyoda","Masaru Kitsuregawa"],"title":"A System for visual exploration of caution spots from vehicle recorder data","doi":"10.1109/VAST.2015.7347677","abstract":"It is vital for the transportation industry, which performs most of its work by automobiles, to reduce its accident rate. This paper proposes a 3D visual interaction method for exploring caution areas from large-scale vehicle recorder data. Our method provides (i) a flexible filtering interface for driving operations such as braking or handling operations by various combinations of their attribute values such as velocity and acceleration, and (ii) a 3D visual environment for spatio-temporal exploration of caution areas. The proposed method was able to extract caution areas where some accidents have actually occurred or that are on very narrow roads with bad visibility by using real data given by one of the biggest transportation companies in Japan.","keywords":"","caption":"Figure 1: (I) Standard Exploration View (SEV): Scatter Plot Matrix based exploration interface for caution degree standards. (a) Measuring the distance of each driving operation from a standard-line as a caution degree. (b) Rotating and determining the slope of the standard-line to have a high correlation coef\ufb01cient between the sum of caution degrees and the number of accidents. This example shows SEV for handling operation that includes four attributes: speed, yaw velocity, yaw angular acceleration, and lateral acceleration. (II) Filtering View: Exploring caution spots by \ufb01ltering driving operations, such as braking or handling operations, on the basis of caution degrees de\ufb01ned by (I) and/or attribute values using parallel coordinates view (PCV). Filtered results are shown in (III) 3D Spatio-temporal View. In this example, extracted results are almost the same spots as the actual accident places.","img_size":{"width":1995,"height":750},"subfigures":[{"x":4.097332492659907,"y":32.59938272197819,"width":653.7033846029127,"height":657.3052420587319,"type":"single","id":"single-0"},{"x":709.4023771444836,"y":8.231368281885134,"width":526.9284345001639,"height":681.4395934413234,"type":"single","id":"single-1"},{"x":1247.8365686106843,"y":9.687119980138167,"width":739.6912862052305,"height":682.8695625443928,"type":"single","id":"single-2"}],"visualizations":[{"x":354.3339587242025,"y":117.35928705440905,"width":284.46529080675424,"height":283.21763602251406,"type":"line_chart","id":"line_chart-0"},{"x":325.6378986866794,"y":524.094746716698,"width":170.92870544090056,"height":167.18574108818012,"type":"line_chart","id":"line_chart-1"},{"x":4.990619136960601,"y":202.19981238273928,"width":162.19512195121956,"height":164.6904315196998,"type":"line_chart","id":"line_chart-2"},{"x":4.990619136960601,"y":365.6425891181988,"width":167.18574108818018,"height":164.69043151969964,"type":"line_chart","id":"line_chart-3"},{"x":172.17636022514083,"y":361.8996247654782,"width":155.9568480300188,"height":165.93808630393994,"type":"line_chart","id":"line_chart-4"},{"x":4.990619136960601,"y":525.3424015009379,"width":168.43339587242033,"height":165.93808630394005,"type":"line_chart","id":"line_chart-5"},{"x":167.18574108818018,"y":529.0853658536586,"width":157.20450281425894,"height":158.45215759849896,"type":"line_chart","id":"line_chart-6"},{"x":1319.3454682977701,"y":317.00503770528366,"width":643.8584773874452,"height":376.10057409288044,"type":"map","id":"map-17"},{"x":6.2382739212007525,"y":43.2697523226571,"width":632.5609756097564,"height":653.7801897613871,"type":"matrix","id":"matrix-16"},{"x":718.4768893180269,"y":17.667998484715415,"width":529.3566964445273,"height":669.1585535985981,"type":"parallel_coordinate","id":"parallel_coordinate-7"},{"x":0,"y":199.70450281425897,"width":169.68105065666043,"height":163.4427767354596,"type":"scatterplot","id":"scatterplot-10"},{"x":3.7429643527204512,"y":363.1472795497186,"width":169.68105065666043,"height":167.18574108818007,"type":"scatterplot","id":"scatterplot-11"},{"x":168.43339587242033,"y":360.6519699812383,"width":164.6904315196998,"height":168.43339587242016,"type":"scatterplot","id":"scatterplot-12"},{"x":1.2476547842401502,"y":527.8377110694184,"width":167.18574108818018,"height":165.93808630393994,"type":"scatterplot","id":"scatterplot-13"},{"x":165.93808630394005,"y":527.8377110694184,"width":158.4521575984991,"height":167.18574108818007,"type":"scatterplot","id":"scatterplot-14"},{"x":329.3808630393996,"y":526.5900562851783,"width":165.93808630394014,"height":167.18574108818007,"type":"scatterplot","id":"scatterplot-15"},{"x":1237.673545966228,"y":2.2351323457289207,"width":754.8311444652901,"height":684.5140712530141,"type":"scatterplot","id":"scatterplot-8"},{"x":356.82926829268314,"y":114.86397748592873,"width":281.96998123827393,"height":281.9699812382739,"type":"scatterplot","id":"scatterplot-9"}],"relations":[{"vislist":[{"vislist":[{"vislist":[{"vislist":["line_chart-0","scatterplot-9"],"relation":null,"id":"group-0"}],"relation":"accompanied","id":"relation-0"},{"vislist":[{"vislist":["line_chart-2","scatterplot-10"],"relation":null,"id":"group-1"}],"relation":"accompanied","id":"relation-1"},{"vislist":[{"vislist":["line_chart-1","scatterplot-15"],"relation":null,"id":"group-2"}],"relation":"accompanied","id":"relation-2"},{"vislist":[{"vislist":["line_chart-3","scatterplot-11"],"relation":null,"id":"group-3"}],"relation":"accompanied","id":"relation-3"},{"vislist":[{"vislist":["line_chart-4","scatterplot-12"],"relation":null,"id":"group-4"}],"relation":"accompanied","id":"relation-4"},{"vislist":[{"vislist":["scatterplot-13","line_chart-5"],"relation":null,"id":"group-5"}],"relation":"accompanied","id":"relation-5"},{"vislist":[{"vislist":["scatterplot-14","line_chart-6"],"relation":null,"id":"group-13"}],"relation":"accompanied","id":"relation-6"}],"relation":null,"id":"group-16"},{"vislist":["matrix-16"],"relation":null,"id":"group-17"}],"relation":"nested","id":"relation-10"}]},"2953_0":{"comp":[["area_chart","bar_chart",["accompanied","stacked"]],["bar_chart","area_chart",["accompanied","stacked"]],["bar_chart","bar_chart",["mirrored"]]],"visType":["area_chart","bar_chart"],"compType":["accompanied","stacked","mirrored"],"compressed_tree":[{"composite_pattern":"accompanied","visualization_type":[["area_chart","bar_chart"]]},{"composite_pattern":"stacked","visualization_type":[["area_chart","bar_chart"]]},{"composite_pattern":"mirrored","visualization_type":[["bar_chart"]]}],"coOccurrence":[["area_chart","bar_chart",["coOccurrence"]]],"year":2017,"conference":["VAST"],"authors":["Mennatallah El-Assady","Rita Sevastjanova","Fabian Sperrle","Daniel A. Keim","Christopher Collins"],"title":"Progressive Learning of Topic Modeling Parameters: A Visual Analytics Framework","doi":"10.1109/TVCG.2017.2745080","abstract":"Topic modeling algorithms are widely used to analyze the thematic composition of text corpora but remain difficult to interpret and adjust. Addressing these limitations, we present a modular visual analytics framework, tackling the understandability and adaptability of topic models through a user-driven reinforcement learning process which does not require a deep understanding of the underlying topic modeling algorithms. Given a document corpus, our approach initializes two algorithm configurations based on a parameter space analysis that enhances document separability. We abstract the model complexity in an interactive visual workspace for exploring the automatic matching results of two models, investigating topic summaries, analyzing parameter distributions, and reviewing documents. The main contribution of our work is an iterative decision-making technique in which users provide a document-based relevance feedback that allows the framework to converge to a user-endorsed topic distribution. We also report feedback from a two-stage study which shows that our technique results in topic model quality improvements on two independent measures.","keywords":"Topic Model Configuration,Reinforcement Learning,Feature Detection and Tracking,Iterative Optimization","caption":"Fig. 1. Parameter Distribution View using comparative bar charts. This compact visualization technique enhances the comparison of two parameter distributions using mirrored bar-charts as a baseline and two asymmetrical violin-style plots as distribution estimates. The plots are scaled using the ratio between the two compared assortments (on both sides). The larger value is scaled to the full width of the baseline and the smaller value is scaled proportionally. This figure depicts the comparison of the utterance descriptor features of the second US presidential debate between Obama and Romney in 2012. All utterances are sorted according to their topic coherence.","img_size":{"width":1849,"height":432},"subfigures":[{"x":7.5988534875760445,"y":5.01559654412699,"width":1832.4593130170504,"height":420.6246597982046,"type":"single","id":"single-0"}],"visualizations":[{"x":0,"y":10.304355820817873,"width":1836.9076979805918,"height":415.5579903097954,"type":"area_chart","id":"area_chart-0"},{"x":2.4871353364189304,"y":10.304355820817873,"width":1833.3629481571238,"height":415.3712929418482,"type":"bar_chart","id":"bar_chart-1"}],"relations":[{"vislist":[{"vislist":["area_chart-0","bar_chart-1"],"relation":null,"id":"group-0"}],"relation":"accompanied","id":"relation-0"},{"vislist":[{"vislist":["area_chart-0","bar_chart-1"],"relation":null,"id":"group-1"}],"relation":"stacked","id":"relation-1"},{"vislist":[{"vislist":["bar_chart-1"],"relation":null,"id":"group-2"}],"relation":"mirrored","id":"relation-2"}]},"1943_9":{"comp":[["scatterplot","line_chart",["accompanied"]],["line_chart","scatterplot",["accompanied"]]],"visType":["scatterplot","line_chart"],"compType":["accompanied"],"compressed_tree":[{"composite_pattern":"accompanied","visualization_type":[["scatterplot","line_chart"]]}],"coOccurrence":[["scatterplot","line_chart",["coOccurrence"]]],"year":2010,"conference":["InfoVis"],"authors":["Justin Talbot","Sharon Lin","Pat Hanrahan"],"title":"An Extension of Wilkinson\'s Algorithm for Positioning Tick Labels on Axes","doi":"10.1109/TVCG.2010.130","abstract":"The non-data components of a visualization, such as axes and legends, can often be just as important as the data itself. They provide contextual information essential to interpreting the data. In this paper, we describe an automated system for choosing positions and labels for axis tick marks. Our system extends Wilkinson\'s optimization-based labeling approach to create a more robust, full-featured axis labeler. We define an expanded space of axis labelings by automatically generating additional nice numbers as needed and by permitting the extreme labels to occur inside the data range. These changes provide flexibility in problematic cases, without degrading quality elsewhere. We also propose an additional optimization criterion, legibility, which allows us to simultaneously optimize over label formatting, font size, and orientation. To solve this revised optimization problem, we describe the optimization function and an efficient search algorithm. Finally, we compare our method to previous work using both quantitative and qualitative metrics. This paper is a good example of how ideas from automated graphic design can be applied to information visualization.","keywords":"Axis labeling, nice numbers","caption":"Fig. 6. By changing the target font size and target density input parameters to our algorithm, we can format axes for three different display scenarios. Optimization over the appearance dimensions ensures that labels remain legible in each.","img_size":{"width":2133,"height":726},"subfigures":[{"x":4.098366716394062,"y":12.640658031484438,"width":816.328491602726,"height":651.8153708554016,"type":"interface","id":"interface-0"}],"visualizations":[{"x":186.5016977928693,"y":96.82767402376906,"width":595.7190152801361,"height":537.776740237691,"type":"line_chart","id":"line_chart-0"},{"x":190.12308998302208,"y":104.07045840407471,"width":590.2869269949067,"height":526.9125636672327,"type":"scatterplot","id":"scatterplot-3"}],"relations":[{"vislist":[{"vislist":["scatterplot-3","line_chart-0"],"relation":null,"id":"group-0"}],"relation":"accompanied","id":"relation-0"}]},"1996_9":{"comp":[["area_chart","line_chart",["accompanied"]],["line_chart","area_chart",["accompanied"]],["stripe_graph","comb",["stacked"]],["comb","stripe_graph",["stacked"]]],"visType":["area_chart","line_chart","stripe_graph","comb"],"compType":["accompanied","stacked"],"compressed_tree":[{"composite_pattern":"stacked","visualization_type":[["stripe_graph",{"composite_pattern":"accompanied","visualization_type":[["area_chart","line_chart"]]}]]}],"coOccurrence":[["area_chart","line_chart",["coOccurrence"]],["area_chart","stripe_graph",["coOccurrence"]],["line_chart","stripe_graph",["coOccurrence"]]],"year":2010,"conference":["VAST"],"authors":["Gennady L. Andrienko","Natalia V. Andrienko","Martin Mladenov","Michael Mock","Christian P\xf6litz"],"title":"Discovering bits of place histories from people\'s activity traces","doi":"10.1109/VAST.2010.5652478","abstract":"Events that happened in the past are important for understanding the ongoing processes, predicting future developments, and making informed decisions. Significant and/or interesting events tend to attract many people. Some people leave traces of their attendance in the form of computer-processable data, such as records in the databases of mobile phone operators or photos on photo sharing web sites. We developed a suite of visual analytics methods for reconstructing past events from these activity traces. Our tools combine geocomputations, interactive geovisualizations and statistical methods to enable integrated analysis of the spatial, temporal, and thematic components of the data, including numeric attributes and texts. We demonstrate the utility of our approach on two large real data sets, mobile phone calls in Milano during 9 days and flickr photos made on British Isles during 5 years.","keywords":"event detection, spatio-temporal data, time series analysis, scalable visualization, geovisualization","caption":"Figure 12. The time graph highlights the time series that had peaks in the week starting on 19.07.2008.","img_size":{"width":1014,"height":492},"subfigures":[{"x":4.828292728276925,"y":2.7525640415112274,"width":1006.4573707334689,"height":485.4380187852605,"type":"single","id":"single-0"}],"visualizations":[{"x":6.988505747126524,"y":2.8275862068965516,"width":971.7471264367816,"height":338.36781609195407,"type":"area_chart","id":"area_chart-0"},{"x":6.597701149425291,"y":2.2357257509745474,"width":972.1379310344828,"height":337.42528735632186,"type":"line_chart","id":"line_chart-1"},{"x":51.28735632183917,"y":374.18390804597703,"width":906.7126436781609,"height":31.103448275862092,"type":"stripe_graph","id":"stripe_graph-2"}],"relations":[{"vislist":[{"vislist":["stripe_graph-2",{"vislist":[{"vislist":["area_chart-0","line_chart-1"],"relation":null,"id":"group-0"}],"relation":"accompanied","id":"relation-0"}],"relation":null,"id":"group-1"}],"relation":"stacked","id":"relation-1"}]},"2249_0":{"comp":[["glyph_based","area_chart",["accompanied"]],["area_chart","glyph_based",["accompanied"]],["line_chart","comb",["stacked"]],["comb","line_chart",["stacked"]]],"visType":["glyph_based","area_chart","line_chart","comb"],"compType":["accompanied","stacked"],"compressed_tree":[{"composite_pattern":"stacked","visualization_type":[["line_chart",{"composite_pattern":"accompanied","visualization_type":[["glyph_based","area_chart"]]}]]}],"coOccurrence":[["glyph_based","area_chart",["coOccurrence"]],["glyph_based","line_chart",["coOccurrence"]],["area_chart","line_chart",["coOccurrence"]]],"year":2012,"conference":["InfoVis"],"authors":["Conglei Shi","Weiwei Cui","Shixia Liu","Panpan Xu","Wei Che","Huamin Qu"],"title":"RankExplorer: Visualization of Ranking Changes in Large Time Series Data","doi":"10.1109/TVCG.2012.253","abstract":"For many applications involving time series data, people are often interested in the changes of item values over time as well as their ranking changes. For example, people search many words via search engines like Google and Bing every day. Analysts are interested in both the absolute searching number for each word as well as their relative rankings. Both sets of statistics may change over time. For very large time series data with thousands of items, how to visually present ranking changes is an interesting challenge. In this paper, we propose RankExplorer, a novel visualization method based on ThemeRiver to reveal the ranking changes. Our method consists of four major components: 1) a segmentation method which partitions a large set of time series curves into a manageable number of ranking categories; 2) an extended ThemeRiver view with embedded color bars and changing glyphs to show the evolution of aggregation values related to each ranking category over time as well as the content changes in each ranking category; 3) a trend curve to show the degree of ranking changes over time; 4) rich user interactions to support interactive exploration of ranking changes. We have applied our method to some real time series data and the case studies demonstrate that our method can reveal the underlying patterns related to ranking changes which might otherwise be obscured in traditional visualizations.","keywords":"Time-series data, ranking change, Themeriver, interaction techniques","caption":"Fig. 1. RankExplorer visualization of the top 2000 Bing search queries from Nov. 20 to Dec. 29 in 2011. All queries are divided into seven categories. The width of each layer at a time point encodes the total query count at that time. The color bar and glyphs encode the content changes in each ranking category. From the color bar, we can observe: 1) the change between layers (the bar segments with the colors of other layers in B and F); 2) new queries coming in (the white segment in D); 3) recurring queries (the dark green segment in E). From the changing glyphs, we can see: 1) a non-change pattern (only red line in G); 2) a swap pattern (the two equal-height segments in A represent that the two queries swap their rankings); 3) a shift pattern (the increasing part is significantly larger than the decreasing part in C). From the trend curve (H), we can see the degree of ranking change over time.","img_size":{"width":1722,"height":854},"subfigures":[{"x":18.334439434441936,"y":5.780258810183067,"width":1684.4224573858119,"height":845.1660984130531,"type":"single","id":"single-0"}],"visualizations":[{"x":41.02827763496142,"y":137.56206459496505,"width":1411.6246786632391,"height":520.3033419023138,"type":"area_chart","id":"area_chart-0"},{"x":39.69176388162463,"y":138.41632626407812,"width":1411.7420675760134,"height":517.8661309578123,"type":"glyph_based","id":"glyph_based-9"},{"x":16.879177377892006,"y":5.839699556404644,"width":1468.704370179949,"height":136.11311053984576,"type":"line_chart","id":"line_chart-8"},{"x":58.591259640102805,"y":668.8422702504921,"width":190.9974293059126,"height":158.06683804627244,"type":"glyph_based","id":"glyph_based-1"},{"x":245.19794344473004,"y":673.2330157517775,"width":197.5835475578406,"height":153.6760925449871,"type":"glyph_based","id":"glyph_based-2"},{"x":447.1722365038559,"y":673.2330157517775,"width":197.5835475578407,"height":158.06683804627255,"type":"glyph_based","id":"glyph_based-3"},{"x":631.5835475578406,"y":671.0376430011347,"width":206.36503856041134,"height":160.26221079691527,"type":"glyph_based","id":"glyph_based-4"},{"x":831.3624678663239,"y":671.0376430011347,"width":208.56041131105403,"height":164.6529562982006,"type":"glyph_based","id":"glyph_based-5"},{"x":1031.1413881748074,"y":671.0376430011347,"width":199.7789203084833,"height":169.04370179948592,"type":"glyph_based","id":"glyph_based-6"},{"x":1228.7249357326477,"y":673.2330157517775,"width":193.19280205655534,"height":153.6760925449871,"type":"glyph_based","id":"glyph_based-7"}],"relations":[{"vislist":[{"vislist":["line_chart-8",{"vislist":[{"vislist":["glyph_based-9","area_chart-0"],"relation":null,"id":"group-0"}],"relation":"accompanied","id":"relation-0"}],"relation":null,"id":"group-1"}],"relation":"stacked","id":"relation-1"}]},"2314_6":{"comp":[["scatterplot","line_chart",["accompanied"]],["line_chart","scatterplot",["accompanied"]]],"visType":["scatterplot","line_chart"],"compType":["accompanied"],"compressed_tree":[{"composite_pattern":"accompanied","visualization_type":[["scatterplot","line_chart"]]}],"coOccurrence":[["scatterplot","line_chart",["coOccurrence"]]],"year":2012,"conference":["VAST"],"authors":["Gennady L. Andrienko","Natalia V. Andrienko","Michael Burch","Daniel Weiskopf"],"title":"Visual Analytics Methodology for Eye Movement Studies","doi":"10.1109/TVCG.2012.276","abstract":"Eye movement analysis is gaining popularity as a tool for evaluation of visual displays and interfaces. However, the existing methods and tools for analyzing eye movements and scanpaths are limited in terms of the tasks they can support and effectiveness for large data and data with high variation. We have performed an extensive empirical evaluation of a broad range of visual analytics methods used in analysis of geographic movement data. The methods have been tested for the applicability to eye tracking data and the capability to extract useful knowledge about users\' viewing behaviors. This allowed us to select the suitable methods and match them to possible analysis tasks they can support. The paper describes how the methods work in application to eye tracking data and provides guidelines for method selection depending on the analysis tasks.","keywords":"Visual analytics, eye tracking, movement data, trajectory analysis","caption":"Fig. 7. Analysis of attendance of particular AOIs. A: The trajectories are represented in a temporal view by horizontal segmented bars. The colors encode distances to selected AOIs. B: Only trajectory segments satisfying a filter are visible on a map. C: A scatterplot of the counts of the visits of the selected AOIs against the task completion times. D: The shape of the highlighted trajectory is close to theoretically optimal.","img_size":{"width":1061,"height":615},"subfigures":[{"x":8.422859107315272,"y":3.489014347395564,"width":1045.4627454630643,"height":604.0948779549669,"type":"single","id":"single-0"}],"visualizations":[{"x":664.328903654485,"y":380.0332225913621,"width":385.1411960132891,"height":223.72923588039865,"type":"graph","id":"graph-0"},{"x":8.465116279069719,"y":386.1627906976743,"width":386.16279069767444,"height":226.49785523744993,"type":"graph","id":"graph-1"},{"x":14.59468438538201,"y":5.107973421926911,"width":1038.9617940199337,"height":345.2990033222591,"type":"heatmap","id":"heatmap-4"},{"x":10.508305647840501,"y":386.1627906976743,"width":383.09800664451825,"height":226.49785523744993,"type":"heatmap","id":"heatmap-6"},{"x":407.9086378737542,"y":369.8172757475083,"width":243.13953488372087,"height":239.05315614617945,"type":"line_chart","id":"line_chart-10"},{"x":407.9086378737542,"y":369.8172757475083,"width":244.16112956810628,"height":240.07475083056482,"type":"scatterplot","id":"scatterplot-12"},{"x":12.551495016611256,"y":384.1196013289036,"width":381.05481727574744,"height":228.54104460622062,"type":"tree","id":"tree-14"},{"x":661.2641196013288,"y":380.0332225913621,"width":392.2923588039867,"height":222.70764119601324,"type":"tree","id":"tree-15"}],"relations":[{"vislist":[{"vislist":["scatterplot-12","line_chart-10"],"relation":null,"id":"group-0"}],"relation":"accompanied","id":"relation-0"}]},"2334_0":{"comp":[["line_chart","scatterplot",["accompanied"]],["scatterplot","line_chart",["accompanied"]]],"visType":["line_chart","scatterplot"],"compType":["accompanied"],"compressed_tree":[{"composite_pattern":"accompanied","visualization_type":[["line_chart","scatterplot"]]}],"coOccurrence":[],"year":2012,"conference":["VAST"],"authors":["Johannes Kehrer","Roland N. Boubela","Peter Filzmoser","Harald Piringer"],"title":"A generic model for the integration of interactive visualization and statistical computing using R","doi":"10.1109/VAST.2012.6400537","abstract":"This poster describes general concepts of integrating the statistical computation package R into a coordinated multiple views framework. The integration is based on a cyclic analysis workflow. In this model, interactive selections are a key aspect to trigger and control computations in R. Dynamic updates of data columns are a generic mechanism to transfer computational results back to the interactive visualization. Further aspects include the integration of the R console and an R object browser as views in our system. We illustrate our approach by means of an interactive modeling process.","keywords":"","caption":"Figure 1: (a) The integration of visplore and R enables an iterative analysis workflow. (b) The integrated R object browser shows all objects in the R workspace and allows synchronization between both environments. R commands and scripts can then be written using the R console.","img_size":{"width":2046,"height":916},"subfigures":[{"x":970.6754993855268,"y":3.447112234043632,"width":1076.1025580141004,"height":904.8410399212506,"type":"interface","id":"interface-0"}],"visualizations":[{"x":44.62091084028223,"y":629.2655548428479,"width":401.58819756254,"height":224.4169339320076,"type":"box_plot","id":"box_plot-0"},{"x":41.996151379089156,"y":29.508017960230937,"width":871.4201411161,"height":425.21103271327763,"type":"flow_diagram","id":"flow_diagram-1"},{"x":489.51763951250797,"y":591.2065426555484,"width":410.7748556767159,"height":269.0378447722899,"type":"line_chart","id":"line_chart-2"},{"x":1311.0673508659395,"y":129.24887748556768,"width":724.4336112892883,"height":349.0930083386786,"type":"scatterplot","id":"scatterplot-3"},{"x":489.51763951250797,"y":589.8941629249517,"width":413.39961513790894,"height":270.3502245028865,"type":"scatterplot","id":"scatterplot-4"}],"relations":[{"vislist":[{"vislist":["line_chart-2","scatterplot-4"],"relation":null,"id":"group-0"}],"relation":"accompanied","id":"relation-0"}]},"1802_5":{"comp":[["map","heatmap",["accompanied"]],["heatmap","map",["accompanied"]]],"visType":["map","heatmap"],"compType":["accompanied"],"compressed_tree":[{"composite_pattern":"accompanied","visualization_type":[["map","heatmap"]]}],"coOccurrence":[],"year":2009,"conference":["InfoVis"],"authors":["Aidan Slingsby","Jason Dykes","Jo Wood"],"title":"Configuring Hierarchical Layouts to Address Research Questions","doi":"10.1109/TVCG.2009.128","abstract":"We explore the effects of selecting alternative layouts in hierarchical displays that show multiple aspects of large multivariate datasets, including spatial and temporal characteristics. Hierarchical displays of this type condition a dataset by multiple discrete variable values, creating nested graphical summaries of the resulting subsets in which size, shape and colour can be used to show subset properties. These \'small multiples\' are ordered by the conditioning variable values and are laid out hierarchically using dimensional stacking. Crucially, we consider the use of different layouts at different hierarchical levels, so that the coordinates of the plane can be used more effectively to draw attention to trends and anomalies in the data. We argue that these layouts should be informed by the type of conditioning variable and by the research question being explored. We focus on space-filling rectangular layouts that provide data-dense and rich overviews of data to address research questions posed in our exploratory analysis of spatial and temporal aspects of property sales in London. We develop a notation (\'HiVE\') that describes visualisation and layout states and provides reconfiguration operators, demonstrate its use for reconfiguring layouts to pursue research questions and provide guidelines for this process. We demonstrate how layouts can be related through animated transitions to reduce the cognitive load associated with their reconfiguration whilst supporting the exploratory process.","keywords":"Geovisualization, hierarchical, layout, guidelines, exploratory, notation","caption":"Fig. 5. Cartograms and maps. A: Rectanglar cartogram: sHier(/,$br); sLayout(/,SP); sSize(/,$sal); sColor(/,$prc). B: Hi- erarchical rectangular cartogram: oInsert(/,2,$wd); oLayout(/,2,SP)]; oColor(/,1,\xd8); oColor(/,2,$prc). C: As B, but using absolute positioning: oCut(/,2); oLayout(/,1,SA). D: Gastner cartogram (polygon layout; sized by sales): oLayout(/,1,PG). E: Map (as D, but using geographical shape): oSize(/,$abr). $abr is the borough area.","img_size":{"width":1767,"height":1197},"subfigures":[{"x":13.25635766437338,"y":-0.6253896258277629,"width":863.1697616775987,"height":671.3357828638483,"type":"single","id":"single-0"}],"visualizations":[{"x":57.53271028037374,"y":22.37383177570094,"width":812.9158878504672,"height":645.1121495327102,"type":"heatmap","id":"heatmap-0"},{"x":926.3831775700935,"y":7.457943925233645,"width":790.5420560747663,"height":652.5700934579438,"type":"heatmap","id":"heatmap-1"},{"x":1217.2429906542054,"y":723.4205607476634,"width":522.0560747663553,"height":425.1028037383178,"type":"heatmap","id":"heatmap-2"},{"x":627.3007064938432,"y":721.873885223244,"width":531.6218452657057,"height":425.6339457348846,"type":"heatmap","id":"heatmap-3"},{"x":38.041764262007916,"y":727.5052170801004,"width":511.7152450837865,"height":406.10225955541364,"type":"heatmap","id":"heatmap-4"},{"x":625.5933172472145,"y":722.6641780971611,"width":534.9865404889064,"height":425.6339457348847,"type":"map","id":"map-5"},{"x":1211.050286084131,"y":722.6641780971611,"width":533.3041928773058,"height":430.6809885696855,"type":"map","id":"map-6"},{"x":41.97775893848197,"y":731.288924222413,"width":511.4336739265017,"height":403.76342678408025,"type":"map","id":"map-7"},{"x":61.26168224299057,"y":22.37383177570094,"width":805.4579439252337,"height":637.6542056074766,"type":"treemap","id":"treemap-8"},{"x":918.9252336448598,"y":7.457943925233645,"width":805.4579439252338,"height":656.2990654205607,"type":"treemap","id":"treemap-9"}],"relations":[{"vislist":[{"vislist":["map-6","heatmap-2"],"relation":null,"id":"group-0"}],"relation":"accompanied","id":"relation-0"}]},"1813_1":{"comp":[["sankey_diagram","tree",["accompanied"]],["tree","sankey_diagram",["accompanied"]],["sunburst_icicle","comb",["nested"]]],"visType":["sankey_diagram","tree","sunburst_icicle","comb"],"compType":["accompanied","nested"],"compressed_tree":[{"composite_pattern":"nested","visualization_type":[["sunburst_icicle"],[{"composite_pattern":"accompanied","visualization_type":[["sankey_diagram","tree"]]}]]}],"coOccurrence":[["sankey_diagram","tree",["coOccurrence"]],["sankey_diagram","sunburst_icicle",["coOccurrence"]],["tree","sunburst_icicle",["coOccurrence"]]],"year":2009,"conference":["InfoVis"],"authors":["Matthew Tobiasz","Petra Isenberg","Sheelagh Carpendale"],"title":"Lark: Coordinating Co-located Collaboration with Information Visualization","doi":"10.1109/TVCG.2009.162","abstract":"Large multi-touch displays are expanding the possibilities of multiple-coordinated views by allowing multiple people to interact with data in concert or independently. We present Lark, a system that facilitates the coordination of interactions with information visualizations on shared digital workspaces. We focus on supporting this coordination according to four main criteria: scoped interaction, temporal flexibility, spatial flexibility, and changing collaboration styles. These are achieved by integrating a representation of the information visualization pipeline into the shared workspace, thus explicitly indicating coordination points on data, representation, presentation, and view levels. This integrated meta-visualization supports both the awareness of how views are linked and the freedom to work in concert or independently. Lark incorporates these four main criteria into a coherent visualization collaboration interaction environment by providing direct visual and algorithmic support for the coordination of data analysis actions over shared large displays.","keywords":"Information visualization, Meta-visualization, Collaboration, Coordination, Co-located work, Workspace awareness","caption":"Fig. 1. Lark\u2019s collaborative visualization environment: single data set \u201cExternal Causes of Mortality\u201d, four views, plus the meta-visualization.","img_size":{"width":2178,"height":1006},"subfigures":[{"x":5.433033223263813,"y":-0.5297126616047927,"width":2163.560236685333,"height":1001.101855177005,"type":"single","id":"single-0"}],"visualizations":[{"x":7.7088122605363765,"y":3.854406130268216,"width":2122.944444444445,"height":994.4367816091956,"type":"sankey_diagram","id":"sankey_diagram-0"},{"x":73.93688350222013,"y":56.5146979138335,"width":2025.367443023322,"height":894.2458389328713,"type":"sunburst_icicle","id":"sunburst_icicle-1"},{"x":8.8026819923371,"y":3.8544061302682007,"width":2123.7777777777783,"height":994.4367816091956,"type":"tree","id":"tree-2"}],"relations":[{"vislist":[{"vislist":["sunburst_icicle-1"],"relation":null,"id":"group-3"},{"vislist":[{"vislist":[{"vislist":["sankey_diagram-0","tree-2"],"relation":null,"id":"group-1"}],"relation":"accompanied","id":"relation-0"}],"relation":null,"id":"group-2"}],"relation":"nested","id":"relation-1"}]},"1819_8":{"comp":[["parallel_coordinate","scatterplot",["accompanied"]],["scatterplot","parallel_coordinate",["accompanied"]]],"visType":["parallel_coordinate","scatterplot"],"compType":["accompanied"],"compressed_tree":[{"composite_pattern":"accompanied","visualization_type":[["parallel_coordinate","scatterplot"]]}],"coOccurrence":[["parallel_coordinate","scatterplot",["coOccurrence"]]],"year":2009,"conference":["InfoVis"],"authors":["Xiaoru Yuan","Peihong Guo","He Xiao","Hong Zhou","Huamin Qu"],"title":"Scattering Points in Parallel Coordinates","doi":"10.1109/TVCG.2009.179","abstract":"In this paper, we present a novel parallel coordinates design integrated with points (scattering points in parallel coordinates, SPPC), by taking advantage of both parallel coordinates and scatterplots. Different from most multiple views visualization frameworks involving parallel coordinates where each visualization type occupies an individual window, we convert two selected neighboring coordinate axes into a scatterplot directly. Multidimensional scaling is adopted to allow converting multiple axes into a single subplot. The transition between two visual types is designed in a seamless way. In our work, a series of interaction tools has been developed. Uniform brushing functionality is implemented to allow the user to perform data selection on both points and parallel coordinate polylines without explicitly switching tools. A GPU accelerated dimensional incremental multidimensional scaling (DIMDS) has been developed to significantly improve the system performance. Our case study shows that our scheme is more efficient than traditional multi-view methods in performing visual analysis tasks.","keywords":"Parallel Coordinates, Scatterplots, Information Visualization, Multidimensional Scaling","caption":"Fig. 6. Interface of Scattering Points in Parallel Coordinates.","img_size":{"width":1095,"height":488},"subfigures":[{"x":19.46889269886948,"y":9.646242874386362,"width":1075.8258412215198,"height":474.0968241750599,"type":"interface","id":"interface-0"}],"visualizations":[{"x":36.52798982188297,"y":36.01017811704835,"width":1040.5699745547074,"height":440.81424936386765,"type":"parallel_coordinate","id":"parallel_coordinate-0"},{"x":36.52798982188297,"y":34.76844783715013,"width":1040.5699745547074,"height":439.5725190839695,"type":"scatterplot","id":"scatterplot-1"}],"relations":[{"vislist":[{"vislist":["parallel_coordinate-0","scatterplot-1"],"relation":null,"id":"group-0"}],"relation":"accompanied","id":"relation-0"}]},"1834_4":{"comp":[["contour_graph","graph",["accompanied"]],["graph","contour_graph",["accompanied"]]],"visType":["contour_graph","graph"],"compType":["accompanied"],"compressed_tree":[{"composite_pattern":"accompanied","visualization_type":[["contour_graph","graph"]]}],"coOccurrence":[],"year":2009,"conference":["VAST"],"authors":["Tarik Crnovrsanin","Chris Muelder","Carlos D. Correa","Kwan-Liu Ma"],"title":"Proximity-based visualization of movement trace data","doi":"10.1109/VAST.2009.5332593","abstract":"The increasing availability of motion sensors and video cameras in living spaces has made possible the analysis of motion patterns and collective behavior in a number of situations. The visualization of this movement data, however, remains a challenge. Although maintaining the actual layout of the data space is often desirable, direct visualization of movement traces becomes cluttered and confusing as the spatial distribution of traces may be disparate and uneven. We present proximity-based visualization as a novel approach to the visualization of movement traces in an abstract space rather than the given spatial layout. This abstract space is obtained by considering proximity data, which is computed as the distance between entities and some number of important locations. These important locations can range from a single fixed point, to a moving point, several points, or even the proximities between the entities themselves. This creates a continuum of proximity spaces, ranging from the fixed absolute reference frame to completely relative reference frames. By combining these abstracted views with the concrete spatial views, we provide a way to mentally map the abstract spaces back to the real space. We demonstrate the effectiveness of this approach, and its applicability to visual analytics problems such as hazard prevention, migration patterns, and behavioral studies.","keywords":"Spatio-temporal visualization, proximity, linked views, principal component analysis, temporal trajectories, movement patterns","caption":"Figure 5: 2D proximity visualization. (a) Points of interest (blue circles) are placed on the physical space. (b) Proximity visualization with respect to the blue circles using interpolation. The user can \u201cstretch\u201d any part of the abstract space to highlight the trajectories of small regions. In this case, we see three trajectories merging. From (b), it is more clear that one of the three came from the left when merging. This is difficult to see in a traditional space due to the small size of this region (c) PCA-based proximity visualization. In this case, PCA automatically finds a dispersion of the 2D proximity data so that the overall variance is maximized, in the hopes of a better screen use. Here, a larger part of the screen is devoted to the trajectories, especially noticed for the regions in the middle. Compare this to the density in (a)","img_size":{"width":2082,"height":825},"subfigures":[{"x":507.06108449784244,"y":3.804076727588345,"width":759.2830354218711,"height":780.9397071484677,"type":"single","id":"single-0"},{"x":1272.0149175277775,"y":4.941879938204218,"width":804.2336803971394,"height":780.9423594395081,"type":"single","id":"single-1"}],"visualizations":[{"x":518.3774019286136,"y":121.49193250176448,"width":481.7873874395412,"height":496.45387809468536,"type":"contour_graph","id":"contour_graph-1"},{"x":509.55651720820885,"y":7.7668383012733155,"width":753.5117668797058,"height":775.2414206367386,"type":"graph","id":"graph-0"}],"relations":[{"vislist":[{"vislist":["contour_graph-1","graph-0"],"relation":null,"id":"group-0"}],"relation":"accompanied","id":"relation-0"}]},"1849_2":{"comp":[["area_chart","line_chart",["accompanied"]],["line_chart","area_chart",["accompanied"]]],"visType":["area_chart","line_chart"],"compType":["accompanied"],"compressed_tree":[{"composite_pattern":"accompanied","visualization_type":[["area_chart","line_chart"]]}],"coOccurrence":[["area_chart","line_chart",["coOccurrence"]]],"year":2009,"conference":["VAST"],"authors":["Ming C. Hao","Halld\xf3r Janetzko","Ratnesh K. Sharma","Umeshwar Dayal","Daniel A. Keim","Mal\xfa Castellanos"],"title":"Poster: Visual prediction of time series","doi":"10.1109/VAST.2009.5333420","abstract":"Many well-known time series prediction methods have been used daily by analysts making decisions. To reach a good prediction, we introduce several new visual analysis techniques of smoothing, multi-scaling, and weighted average with the involvement of human expert knowledge. We combine them into a well-fitted method to perform prediction. We have applied this approach to predict resource consumption in data center for next day planning.","keywords":"","caption":"Figure 3. Two Predictions of Next Day\u2019s Chiller Utilization","img_size":{"width":774,"height":840},"subfigures":[{"x":2.1744434808281485,"y":1.1129667601233664,"width":766.8720818225594,"height":412.68050888274826,"type":"single","id":"single-0"}],"visualizations":[{"x":24.12643678160919,"y":38.62068965517242,"width":730.5747126436781,"height":344.36781609195407,"type":"area_chart","id":"area_chart-0"},{"x":20.908045977011515,"y":448.96551724137925,"width":746.6666666666667,"height":345.9770114942529,"type":"area_chart","id":"area_chart-1"},{"x":25.73563218390802,"y":33.793103448275865,"width":735.4022988505748,"height":350.8045977011494,"type":"line_chart","id":"line_chart-2"},{"x":19.298850574712677,"y":447.35632183908046,"width":749.8850574712644,"height":355.6321839080461,"type":"line_chart","id":"line_chart-3"}],"relations":[{"vislist":[{"vislist":["area_chart-0","line_chart-2"],"relation":null,"id":"group-0"}],"relation":"accompanied","id":"relation-0"}]},"1856_1":{"comp":[["parallel_coordinate","word_cloud",["accompanied"]],["word_cloud","parallel_coordinate",["accompanied"]]],"visType":["parallel_coordinate","word_cloud"],"compType":["accompanied"],"compressed_tree":[{"composite_pattern":"accompanied","visualization_type":[["parallel_coordinate","word_cloud"]]}],"coOccurrence":[["parallel_coordinate","word_cloud",["coOccurrence"]]],"year":2009,"conference":["VAST"],"authors":["Christopher Collins","Fernanda B. Vi\xe9gas","Martin Wattenberg"],"title":"Parallel Tag Clouds to explore and analyze faceted text corpora","doi":"10.1109/VAST.2009.5333443","abstract":"Do court cases differ from place to place? What kind of picture do we get by looking at a country\'s collection of law cases? We introduce parallel tag clouds: a new way to visualize differences amongst facets of very large metadata-rich text corpora. We have pointed parallel tag clouds at a collection of over 600,000 US Circuit Court decisions spanning a period of 50 years and have discovered regional as well as linguistic differences between courts. The visualization technique combines graphical elements from parallel coordinates and traditional tag clouds to provide rich overviews of a document collection while acting as an entry point for exploration of individual texts. We augment basic parallel tag clouds with a details-in-context display and an option to visualize changes over a second facet of the data, such as time. We also address text mining challenges such as selecting the best words to visualize, and how to do so in reasonable time periods to maintain interactivity.","keywords":"Text visualization, corpus visualization, information retrieval, text mining, tag clouds","caption":"Figure 1: A PTC revealing the differences in drug prevalence amongst the circuits.","img_size":{"width":1894,"height":1158},"subfigures":[{"x":5.169842480906608,"y":-0.9694264200792543,"width":1881.1048337092036,"height":1154.8319087619625,"type":"single","id":"single-0"}],"visualizations":[{"x":472.61682242990673,"y":79.36448598130842,"width":649.3457943925233,"height":292.2056074766356,"type":"parallel_coordinate","id":"parallel_coordinate-0"},{"x":3.080377093485987,"y":3.080377093485987,"width":1887.8392458130281,"height":1151.8392458130281,"type":"word_cloud","id":"word_cloud-1"}],"relations":[{"vislist":[{"vislist":["parallel_coordinate-0","word_cloud-1"],"relation":null,"id":"group-0"}],"relation":"accompanied","id":"relation-0"}]},"1684_5":{"comp":[["graph","scatterplot",["accompanied"]],["scatterplot","graph",["accompanied"]]],"visType":["graph","scatterplot"],"compType":["accompanied"],"compressed_tree":[{"composite_pattern":"accompanied","visualization_type":[["graph","scatterplot"]]}],"coOccurrence":[["graph","scatterplot",["coOccurrence"]]],"year":2008,"conference":["InfoVis"],"authors":["Yuntao Jia","Jared Hoberock","Michael Garland","John C. Hart"],"title":"On the Visualization of Social and other Scale-Free Networks","doi":"10.1109/TVCG.2008.151","abstract":"This paper proposes novel methods for visualizing specifically the large power-law graphs that arise in sociology and the sciences. In such cases a large portion of edges can be shown to be less important and removed while preserving component connectedness and other features (e.g. cliques) to more clearly reveal the networkpsilas underlying connection pathways. This simplification approach deterministically filters (instead of clustering) the graph to retain important node and edge semantics, and works both automatically and interactively. The improved graph filtering and layout is combined with a novel computer graphics anisotropic shading of the dense crisscrossing array of edges to yield a full social network and scale-free graph visualization system. Both quantitative analysis and visual results demonstrate the effectiveness of this approach.","keywords":"Scale-free network, edge filtering, betweenness centrality, anisotropic shading","caption":"Fig. 7. Graph \u201csp500-38\u201d simpli\ufb01ed by interactive graph strati\ufb01cation and our method.","img_size":{"width":2145,"height":1017},"subfigures":[{"x":0.47257598608905604,"y":6.3080291885160555,"width":1182.4654024813283,"height":962.614193920113,"type":"single","id":"single-0"}],"visualizations":[{"x":11.663793103448256,"y":89.62068965517238,"width":1167.0172413793102,"height":922.6498904869968,"type":"graph","id":"graph-0"},{"x":1184.5258620689656,"y":4.729419857830774,"width":955.7447180732038,"height":1007.5411602843385,"type":"graph","id":"graph-1"},{"x":7.767241379310348,"y":85.72413793103448,"width":1167.0172413793102,"height":926.5464422111348,"type":"scatterplot","id":"scatterplot-2"},{"x":1184.5258620689656,"y":4.729419857830774,"width":955.7447180732036,"height":1007.5411602843385,"type":"scatterplot","id":"scatterplot-3"}],"relations":[{"vislist":[{"vislist":["graph-0","scatterplot-2"],"relation":null,"id":"group-2"}],"relation":"accompanied","id":"relation-0"}]},"1685_14":{"comp":[["others","graph",["accompanied"]],["graph","others",["accompanied"]]],"visType":["others","graph"],"compType":["accompanied"],"compressed_tree":[{"composite_pattern":"accompanied","visualization_type":[["others","graph"]]}],"coOccurrence":[["others","graph",["coOccurrence"]]],"year":2008,"conference":["InfoVis"],"authors":["Martin Luboschik","Heidrun Schumann","Hilko Cords"],"title":"Particle-based labeling: Fast point-feature labeling without obscuring other visual features","doi":"10.1109/TVCG.2008.152","abstract":"In many information visualization techniques, labels are an essential part to communicate the visualized data. To preserve the expressiveness of the visual representation, a placed label should neither occlude other labels nor visual representatives (e.g., icons, lines) that communicate crucial information. Optimal, non-overlapping labeling is an NP-hard problem. Thus, only a few approaches achieve a fast non-overlapping labeling in highly interactive scenarios like information visualization. These approaches generally target the point-feature label placement (PFLP) problem, solving only label-label conflicts. This paper presents a new, fast, solid and flexible 2D labeling approach for the PFLP problem that additionally respects other visual elements and the visual extent of labeled features. The results (number of placed labels, processing time) of our particle-based method compare favorably to those of existing techniques. Although the esthetic quality of non-real-time approaches may not be achieved with our method, it complies with practical demands and thus supports the interactive exploration of information spaces. In contrast to the known adjacent techniques, the flexibility of our technique enables labeling of dense point clouds by the use of non-occluding distant labels. Our approach is independent of the underlying visualization technique, which enables us to demonstrate the application of our labeling method within different information visualization scenarios.","keywords":"Interactive labeling, dynamic labeling, automatic label placement, occlusion-free, information visualization","caption":"Fig. 10. Comparison of adjacent labeling only and the inclusion of dis- tant labeling. (a) pipeline con\ufb01guration A and (b) pipeline con\ufb01gura- tion D as described in Table 2.","img_size":{"width":975,"height":474},"subfigures":[{"x":505.873816365141,"y":-0.29606052306520786,"width":466.65466256143316,"height":436.7377083089929,"type":"single","id":"single-0"}],"visualizations":[{"x":5.781609195402311,"y":2.7241379310344827,"width":440.4022988505747,"height":420.42528735632186,"type":"graph","id":"graph-0"},{"x":524.2758620689657,"y":2.1497362990139877,"width":446.7586206896552,"height":424.05747126436785,"type":"graph","id":"graph-1"},{"x":4.8735632183907995,"y":2.1497362990139877,"width":441.3103448275862,"height":422.24137931034477,"type":"others","id":"others-2"},{"x":524.2758620689657,"y":2.724137931034477,"width":446.7586206896552,"height":422.2413793103448,"type":"others","id":"others-3"}],"relations":[{"vislist":[{"vislist":["others-3","graph-1"],"relation":null,"id":"group-0"}],"relation":"accompanied","id":"relation-0"}]},"1723_0":{"comp":[["line_chart","matrix",["accompanied"]],["matrix","line_chart",["accompanied"]]],"visType":["line_chart","matrix"],"compType":["accompanied"],"compressed_tree":[{"composite_pattern":"accompanied","visualization_type":[["line_chart","matrix"]]}],"coOccurrence":[["line_chart","matrix",["coOccurrence"]]],"year":2008,"conference":["VAST"],"authors":["Ye Zhao","Jamal Alsakran","Xinlei Zhao"],"title":"Visual analysis for mutual fund performance","doi":"10.1109/VAST.2008.4677376","abstract":"Mutual funds are one of the most important investment instruments available. However, choosing among mutual funds is not an easy task because they vary in many different dimensions, such as asset size, turnover and fee structure, and these characteristics may affect fund returns. It is thus important to understand the relation between fund performance and these properties. In this work, we use a new visual analytical tool, the density-based distribution map, to assist in this task. By visualizing various important fund characteristics from a real-world database of the US stock funds, our new visual representations greatly help understand the relation between fund characteristics and returns.","keywords":"","caption":"Figure 1: Distribution map with different resolutions.","img_size":{"width":1047,"height":531},"subfigures":[{"x":3.9457967307392394,"y":1.0513563299480138,"width":508.5238745294675,"height":484.08307279867864,"type":"single","id":"single-0"}],"visualizations":[{"x":51.975109809663266,"y":5.44216691068814,"width":415.9370424597364,"height":431.4860907759883,"type":"heatmap","id":"heatmap-0"},{"x":559.6515373352853,"y":3.8872620790629573,"width":443.9253294289896,"height":457.9194729136164,"type":"heatmap","id":"heatmap-1"},{"x":55.084919472913654,"y":42.75988286969253,"width":413.6046852122986,"height":392.6134699853586,"type":"line_chart","id":"line_chart-2"},{"x":560.428989751098,"y":43.53733528550512,"width":444.7027818448022,"height":419.04685212298676,"type":"line_chart","id":"line_chart-3"},{"x":53.85536275620364,"y":42.608229278107764,"width":415.6541216189819,"height":397.77051237284337,"type":"matrix","id":"matrix-4"},{"x":561.0443791146188,"y":46.42480929463228,"width":439.31120675809217,"height":414.143866875264,"type":"matrix","id":"matrix-5"}],"relations":[{"vislist":[{"vislist":["line_chart-2","matrix-4"],"relation":null,"id":"group-0"}],"relation":"accompanied","id":"relation-0"}]},"1543_11":{"comp":[["map","treemap",["accompanied"]],["treemap","map",["accompanied"]]],"visType":["map","treemap"],"compType":["accompanied"],"compressed_tree":[{"composite_pattern":"accompanied","visualization_type":[["map","treemap"]]},{"composite_pattern":"accompanied","visualization_type":[["treemap","map"]]}],"coOccurrence":[["treemap","map",["coOccurrence"]]],"year":2007,"conference":["InfoVis"],"authors":["Ying Tu","Han-Wei Shen"],"title":"Visualizing Changes of Hierarchical Data using Treemaps","doi":"10.1109/TVCG.2007.70529","abstract":"While the treemap is a popular method for visualizing hierarchical data, it is often difficult for users to track layout and attribute changes when the data evolve over time. When viewing the treemaps side by side or back and forth, there exist several problems that can prevent viewers from performing effective comparisons. Those problems include abrupt layout changes, a lack of prominent visual patterns to represent layouts, and a lack of direct contrast to highlight differences. In this paper, we present strategies to visualize changes of hierarchical data using treemaps. A new treemap layout algorithm is presented to reduce abrupt layout changes and produce consistent visual patterns. Techniques are proposed to effectively visualize the difference and contrast between two treemap snapshots in terms of the map items\' colors, sizes, and positions. Experimental data show that our algorithm can achieve a good balance in maintaining a treemap\'s stability, continuity, readability, and average aspect ratio. A software tool is created to compare treemaps and generate the visualizations. User studies show that the users can better understand the changes in the hierarchy and layout, and more quickly notice the color and size differences using our method.","keywords":"Treemap, tree comparison, visualize changes, treemap layout algorithm","caption":"Fig. 12. An Example of the Contrast Treemap - Texture Image","img_size":{"width":1046,"height":834},"subfigures":[{"x":3.6354937833197294,"y":419.6203721670681,"width":513.158164526748,"height":384.1960074072697,"type":"single","id":"single-0"}],"visualizations":[{"x":522.116525423729,"y":21.20338983050847,"width":517.7161016949151,"height":376.3601694915254,"type":"map","id":"map-0"},{"x":525.6504237288135,"y":425.83474576271186,"width":510.6483050847457,"height":374.59322033898303,"type":"map","id":"map-1"},{"x":6.167372881356073,"y":422.30084745762707,"width":503.5805084745763,"height":374.593220338983,"type":"map","id":"map-2"},{"x":4.40042372881362,"y":19.436440677966097,"width":505.3474576271188,"height":379.89406779661016,"type":"treemap","id":"treemap-3"},{"x":525.6504237288135,"y":22.970338983050844,"width":507.114406779661,"height":372.8262711864407,"type":"treemap","id":"treemap-4"},{"x":2.2185099274329128,"y":422.30084745762707,"width":508.8813559322034,"height":376.3601694915254,"type":"treemap","id":"treemap-5"}],"relations":[{"vislist":[{"vislist":["map-0","treemap-4"],"relation":null,"id":"group-0"}],"relation":"accompanied","id":"relation-0"},{"vislist":[{"vislist":["treemap-5","map-2"],"relation":null,"id":"group-1"}],"relation":"accompanied","id":"relation-1"}]},"1545_7":{"comp":[["bar_chart","tree",["accompanied"]],["tree","bar_chart",["accompanied"]]],"visType":["bar_chart","tree"],"compType":["accompanied"],"compressed_tree":[{"composite_pattern":"accompanied","visualization_type":[["bar_chart","tree"]]}],"coOccurrence":[["bar_chart","tree",["coOccurrence"]]],"year":2007,"conference":["InfoVis"],"authors":["Desney S. Tan","Greg Smith","Bongshin Lee","George G. Robertson"],"title":"AdaptiviTree: Adaptive Tree Visualization for Tournament-Style Brackets","doi":"10.1109/TVCG.2007.70537","abstract":"Online pick\'em games, such as the recent NCAA college basketball March Madness tournament, form a large and rapidly growing industry. In these games, players make predictions on a tournament bracket that defines which competitors play each other and how they proceed toward a single champion. Throughout the course of the tournament, players monitor the brackets to track progress and to compare predictions made by multiple players. This is often a complex sense making task. The classic bracket visualization was designed for use on paper and utilizes an incrementally additive system in which the winner of each match-up is rewritten in the next round as the tournament progresses. Unfortunately, this representation requires a significant amount of space and makes it relatively difficult to get a quick overview of the tournament state since competitors take arbitrary paths through the static bracket. In this paper, we present AdaptiviTree, a novel visualization that adaptively deforms the representation of the tree and uses its shape to convey outcome information. AdaptiviTree not only provides a more compact and understandable representation, but also allows overlays that display predictions as well as other statistics. We describe results from a lab study we conducted to explore the efficacy of AdaptiviTree, as well as from a deployment of the system in a recent real-world sports tournament.","keywords":"Online fantasy sports, tournament, bracket, picks, adaptive tree visualization","caption":"Figure 7: Example of a 64-team bracket with 58 games already played to illustrate complexity or clutter at this stage.","img_size":{"width":925,"height":1121},"subfigures":[{"x":25.064788660215264,"y":12.538308690282278,"width":876.1070469581448,"height":1093.4514982016203,"type":"single","id":"single-0"}],"visualizations":[{"x":51.157309174883096,"y":27.61388190131124,"width":803.6127184135867,"height":1053.8419607349902,"type":"bar_chart","id":"bar_chart-1"},{"x":44.809386973179926,"y":27.917624521072792,"width":824.6436781609194,"height":1069.4597701149423,"type":"tree","id":"tree-0"}],"relations":[{"vislist":[{"vislist":["bar_chart-1","tree-0"],"relation":null,"id":"group-2"}],"relation":"accompanied","id":"relation-1"}]},"1551_7":{"comp":[["map","treemap",["accompanied"]],["treemap","map",["accompanied"]]],"visType":["map","treemap"],"compType":["accompanied"],"compressed_tree":[{"composite_pattern":"accompanied","visualization_type":[["map","treemap"]]}],"coOccurrence":[["map","treemap",["coOccurrence"]]],"year":2007,"conference":["InfoVis"],"authors":["Danyel Fisher"],"title":"Hotmap: Looking at Geographic Attention","doi":"10.1109/TVCG.2007.70561","abstract":"Understanding how people use online maps allows data acquisition teams to concentrate their efforts on the portions of the map that are most seen by users. Online maps represent vast databases, and so it is insufficient to simply look at a list of the most-accessed URLs. Hotmap takes advantage of the design of a mapping system\'s imagery pyramid to superpose a heatmap of the log files over the original maps. Users\' behavior within the system can be observed and interpreted. This paper discusses the imagery acquisition task that motivated Hotmap, and presents several examples of information that Hotmap makes visible. We discuss the design choices behind Hotmap, including logarithmic color schemes; low-saturation background images; and tuning images to explore both infrequently-viewed and frequently-viewed spaces.","keywords":"Geographical visualization, GIS, heatmap, server log analysis, online mapping systems, social navigation","caption":"Figure 6. The tile pyramid. Tile 032 (highlighted) is at location x=2, y=3, level=3, and is one-fourth the size of tile 0 in each dimension.","img_size":{"width":723,"height":720},"subfigures":[{"x":5.625335949849594,"y":4.132411480235796,"width":714.131394342359,"height":712.5290025439111,"type":"single","id":"single-0"}],"visualizations":[{"x":10.47196261682268,"y":13.457937507985912,"width":702.0560747663551,"height":695.3271028037384,"type":"map","id":"map-0"},{"x":10.471962616822566,"y":8.971956199574695,"width":702.0560747663552,"height":704.2990654205609,"type":"treemap","id":"treemap-1"}],"relations":[{"vislist":[{"vislist":["map-0","treemap-1"],"relation":null,"id":"group-0"}],"relation":"accompanied","id":"relation-0"}]},"1562_1":{"comp":[["heatmap","scatterplot",["accompanied"]],["scatterplot","heatmap",["accompanied"]]],"visType":["heatmap","scatterplot"],"compType":["accompanied"],"compressed_tree":[{"composite_pattern":"accompanied","visualization_type":[["heatmap","scatterplot"]]}],"coOccurrence":[["heatmap","scatterplot",["coOccurrence"]]],"year":2007,"conference":["InfoVis"],"authors":["Melanie Tory","David W. Sprague","Fuqu Wu","Wing Yan So","Tamara Munzner"],"title":"Spatialization Design: Comparing Points and Landscapes","doi":"10.1109/TVCG.2007.70596","abstract":"Spatializations represent non-spatial data using a spatial layout similar to a map. We present an experiment comparing different visual representations of spatialized data, to determine which representations are best for a non-trivial search and point estimation task. Primarily, we compare point-based displays to 2D and 3D information landscapes. We also compare a colour (hue) scale to a grey (lightness) scale. For the task we studied, point-based spatializations were far superior to landscapes, and 2D landscapes were superior to 3D landscapes. Little or no benefit was found for redundantly encoding data using colour or greyscale combined with landscape height. 3D landscapes with no colour scale (height-only) were particularly slow and inaccurate. A colour scale was found to be better than a greyscale for all display types, but a greyscale was helpful compared to height-only. These results suggest that point-based spatializations should be chosen over landscape representations, at least for tasks involving only point data itself rather than derived information about the data space.","keywords":"Spatialization, Information Landscape, User Study, Numerosity, 3D, 2D, Colour, Greyscale, Surface, Points","caption":"Fig. 2 Example trials from our experiment. Target levels are 5 (blue) in the left example and 1 (red) in the right example. Correct answers are highlighted with black outlines.","img_size":{"width":1038,"height":510},"subfigures":[{"x":3.8315177319888836,"y":5.198338510519579,"width":490.15115633610617,"height":500.7379588353123,"type":"single","id":"single-0"},{"x":553.4477750996621,"y":4.522353626888248,"width":479.38292928448504,"height":498.9325210554122,"type":"single","id":"single-1"}],"visualizations":[{"x":7.879941434846231,"y":3.7335285505124456,"width":479.385065885798,"height":496.5592972181552,"type":"heatmap","id":"heatmap-0"},{"x":551.4816983894583,"y":5.2269399707174236,"width":481.6251830161053,"height":495.0658857979503,"type":"heatmap","id":"heatmap-1"},{"x":10.120058565153698,"y":6.720351390922402,"width":477.89165446559315,"height":491.3323572474378,"type":"scatterplot","id":"scatterplot-2"},{"x":549.9882869692534,"y":5.973645680819914,"width":483.1185944363103,"height":498.0527086383602,"type":"scatterplot","id":"scatterplot-3"}],"relations":[{"vislist":[{"vislist":["heatmap-1","scatterplot-3"],"relation":null,"id":"group-0"}],"relation":"accompanied","id":"relation-0"}]},"2091_0":{"comp":[["line_chart","area_chart",["accompanied"]],["area_chart","line_chart",["accompanied"]]],"visType":["line_chart","area_chart"],"compType":["accompanied"],"compressed_tree":[{"composite_pattern":"accompanied","visualization_type":[["line_chart","area_chart"]]}],"coOccurrence":[["line_chart","area_chart",["coOccurrence"]]],"year":2011,"conference":["InfoVis"],"authors":["Jian Zhao","Fanny Chevalier","Emmanuel Pietriga","Ravin Balakrishnan"],"title":"Exploratory Analysis of Time-Series with ChronoLenses","doi":"10.1109/TVCG.2011.195","abstract":"Visual representations of time-series are useful for tasks such as identifying trends, patterns and anomalies in the data. Many techniques have been devised to make these visual representations more scalable, enabling the simultaneous display of multiple variables, as well as the multi-scale display of time-series of very high resolution or that span long time periods. There has been comparatively little research on how to support the more elaborate tasks associated with the exploratory visual analysis of timeseries, e.g., visualizing derived values, identifying correlations, or discovering anomalies beyond obvious outliers. Such tasks typically require deriving new time-series from the original data, trying different functions and parameters in an iterative manner. We introduce a novel visualization technique called ChronoLenses, aimed at supporting users in such exploratory tasks. ChronoLenses perform on-the-fly transformation of the data points in their focus area, tightly integrating visual analysis with user actions, and enabling the progressive construction of advanced visual analysis pipelines.","keywords":"Time-series Data, Exploratory Visualization, Focus+Context, Lens, Interaction Techniques","caption":"Fig. 1. The ChronoLenses interface includes (A) a charts panel showing the time-series; (B) a lens creation toolbar; (C) a lens analysis pipeline view of (D) the currently selected lens; (E) a property panel showing details of the currently selected lens. A context menu (F) can be invoked to perform lens-based operations, and (G) the lens toolbar allows quick access to a lens\u2019 parameters.","img_size":{"width":1922,"height":950},"subfigures":[{"x":22.50644759598138,"y":11.464824299518147,"width":1244.006648681883,"height":936.1697140417679,"type":"interface","id":"interface-0"}],"visualizations":[{"x":317.65708812260544,"y":447.7011494252874,"width":212.93103448275866,"height":225.67049808429113,"type":"area_chart","id":"area_chart-0"},{"x":51.94827586206907,"y":163.79310344827587,"width":917.2413793103449,"height":240.22988505747125,"type":"area_chart","id":"area_chart-1"},{"x":51.94827586206907,"y":165.6130268199234,"width":917.2413793103449,"height":240.22988505747125,"type":"line_chart","id":"line_chart-2"},{"x":57.4080459770116,"y":447.7011494252874,"width":909.9616858237548,"height":251.14942528735628,"type":"line_chart","id":"line_chart-3"},{"x":1296.7758620689656,"y":107.37547892720306,"width":604.2145593869731,"height":334.8659003831417,"type":"line_chart","id":"line_chart-4"},{"x":1369.572796934866,"y":500.47892720306515,"width":529.5977011494255,"height":384.0038314176245,"type":"line_chart","id":"line_chart-5"}],"relations":[{"vislist":[{"vislist":["line_chart-3","area_chart-0"],"relation":null,"id":"group-0"}],"relation":"accompanied","id":"relation-0"}]},"2129_8":{"comp":[["scatterplot","contour_graph",["accompanied"]],["contour_graph","scatterplot",["accompanied"]],["comb","matrix",["nested"]],["comb","comb",["large_view"]],["bar_chart","heatmap",["stacked"]],["bar_chart","bar_chart",["mirrored"]],["heatmap","bar_chart",["stacked"]]],"visType":["scatterplot","contour_graph","comb","matrix","bar_chart","heatmap"],"compType":["accompanied","nested","large_view","stacked","mirrored"],"compressed_tree":[{"composite_pattern":"mirrored","visualization_type":[["bar_chart"]]},{"composite_pattern":"stacked","visualization_type":[["bar_chart","heatmap"]]},{"composite_pattern":"accompanied","visualization_type":[["scatterplot","contour_graph"]]},{"composite_pattern":"large_view","visualization_type":[[{"composite_pattern":"accompanied","visualization_type":[["contour_graph","scatterplot"]]}],[{"composite_pattern":"nested","visualization_type":[[{"composite_pattern":"accompanied","visualization_type":[["contour_graph","scatterplot"]]}],["matrix"]]}]]}],"coOccurrence":[["bar_chart","heatmap",["coOccurrence"]],["bar_chart","scatterplot",["coOccurrence"]],["bar_chart","contour_graph",["coOccurrence"]],["bar_chart","matrix",["coOccurrence"]],["heatmap","scatterplot",["coOccurrence"]],["heatmap","contour_graph",["coOccurrence"]],["heatmap","matrix",["coOccurrence"]],["scatterplot","contour_graph",["coOccurrence"]],["scatterplot","matrix",["coOccurrence"]],["contour_graph","matrix",["coOccurrence"]]],"year":2011,"conference":["VAST"],"authors":["Malgorzata Migut","Jan C. van Gemert","Marcel Worring"],"title":"Interactive decision making using dissimilarity to visually represented prototypes","doi":"10.1109/VAST.2011.6102451","abstract":"To make informed decisions, an expert has to reason with multi-dimensional, heterogeneous data and analysis results of these. Items in such datasets are typically represented by features. However, as argued in cognitive science, features do not yield an optimal space for human reasoning. In fact, humans tend to organize complex information in terms of prototypes or known cases rather than in absolute terms. When confronted with unknown data items, humans assess them in terms of similarity to these prototypical elements. Interestingly, an analogues similarity-to-prototype approach, where prototypes are taken from the data, has been successfully applied in machine learning. Combining such a machine learning approach with human prototypical reasoning in a Visual Analytics context requires to integrate similarity-based classification with interactive visualizations. To that end, the data prototypes should be visually represented to trigger direct associations to cases familiar to the domain experts. In this paper, we propose a set of highly interactive visualizations to explore data and classification results in terms of dissimilarities to visually represented prototypes. We argue that this approach not only supports human reasoning processes, but is also suitable to enhance understanding of heterogeneous data. The proposed framework is applied to a risk assessment case study in Forensic Psychiatry.","keywords":"dissimilarity based classication, dissimilarity based visualization, prototypes, interactive visualization, visual analytics","caption":"Figure 8: Screenshot of the system.","img_size":{"width":1648,"height":1317},"subfigures":[{"x":9.060969227954747,"y":3.31729447674765,"width":1631.2793714590393,"height":1304.758926556241,"type":"interface","id":"interface-0"}],"visualizations":[{"x":1277.0618823611103,"y":50.62866588837551,"width":108.39471016321365,"height":610.2423432747584,"type":"bar_chart","id":"bar_chart-2"},{"x":12.523585547326977,"y":44.105486205594744,"width":1004.9751564119698,"height":1015.7426169587865,"type":"contour_graph","id":"contour_graph-0"},{"x":1044.5578416804112,"y":750.7919984424723,"width":580.9641400486245,"height":541.6488089843727,"type":"contour_graph","id":"contour_graph-11"},{"x":499.1312310051082,"y":59.325888585245785,"width":511.22458046639207,"height":517.3226799761517,"type":"contour_graph","id":"contour_graph-9"},{"x":1393.2998343925697,"y":51.044454504332805,"width":242.15581305329889,"height":614.0919825211352,"type":"heatmap","id":"heatmap-12"},{"x":16.706996276884265,"y":1071.692820800669,"width":996.3808075523579,"height":229.42269464241116,"type":"line_chart","id":"line_chart-21"},{"x":4.150901528334986,"y":51.03003260615211,"width":1014.7139748752005,"height":1010.303250893068,"type":"matrix","id":"matrix-8"},{"x":1040.3155349625988,"y":423.7798686390085,"width":232.23112618708086,"height":236.11245360734196,"type":"polar_plot","id":"polar_plot-20"},{"x":498.5635809904755,"y":59.9776284704793,"width":513.544466353852,"height":515.8568774919881,"type":"scatterplot","id":"scatterplot-1"},{"x":6.581482530869873,"y":49.99367075065752,"width":1012.2577416489111,"height":1011.392526716407,"type":"scatterplot","id":"scatterplot-16"},{"x":1042.3517761079058,"y":751.210065330257,"width":579.2461361236388,"height":539.2179897060813,"type":"scatterplot","id":"scatterplot-7"}],"relations":[{"vislist":[{"vislist":["bar_chart-2"],"relation":null,"id":"group-0"}],"relation":"mirrored","id":"relation-0"},{"vislist":[{"vislist":["bar_chart-2","heatmap-12"],"relation":null,"id":"group-8"}],"relation":"stacked","id":"relation-5"},{"vislist":[{"vislist":["scatterplot-7","contour_graph-11"],"relation":null,"id":"group-9"}],"relation":"accompanied","id":"relation-6"},{"vislist":[{"vislist":[{"vislist":[{"vislist":["contour_graph-9","scatterplot-1"],"relation":null,"id":"group-10"}],"relation":"accompanied","id":"relation-7"}],"relation":null,"id":"group-20"},{"vislist":[{"vislist":[{"vislist":[{"vislist":[{"vislist":["contour_graph-0","scatterplot-16"],"relation":null,"id":"group-17"}],"relation":"accompanied","id":"relation-11"}],"relation":null,"id":"group-18"},{"vislist":["matrix-8"],"relation":null,"id":"group-19"}],"relation":"nested","id":"relation-12"}],"relation":null,"id":"group-21"}],"relation":"large_view","id":"relation-13"}]},"3061_0":{"comp":[["contour_graph","scatterplot",["accompanied"]],["scatterplot","contour_graph",["accompanied"]]],"visType":["contour_graph","scatterplot"],"compType":["accompanied"],"compressed_tree":[{"composite_pattern":"accompanied","visualization_type":[["contour_graph","scatterplot"]]}],"coOccurrence":[["contour_graph","scatterplot",["coOccurrence"]]],"year":2018,"conference":["VAST"],"authors":["Marco Cavallo","\xc7agatay Demiralp"],"title":"Clustrophile 2: Guided Visual Clustering Analysis","doi":"10.1109/TVCG.2018.2864477","abstract":"Data clustering is a common unsupervised learning method frequently used in exploratory data analysis. However, identifying relevant structures in unlabeled, high-dimensional data is nontrivial, requiring iterative experimentation with clustering parameters as well as data features and instances. The number of possible clusterings for a typical dataset is vast, and navigating in this vast space is also challenging. The absence of ground-truth labels makes it impossible to define an optimal solution, thus requiring user judgment to establish what can be considered a satisfiable clustering result. Data scientists need adequate interactive tools to effectively explore and navigate the large clustering space so as to improve the effectiveness of exploratory clustering analysis. We introduce Clustrophile 2, a new interactive tool for guided clustering analysis. Clustrophile 2 guides users in clustering-based exploratory analysis, adapts user feedback to improve user guidance, facilitates the interpretation of clusters, and helps quickly reason about differences between clusterings. To this end, Clustrophile 2 contributes a novel feature, the Clustering Tour, to help users choose clustering parameters and assess the quality of different clustering results in relation to current analysis goals and user expectations. We evaluate Clustrophile 2 through a user study with 12 data scientists, who used our tool to explore and interpret sub-cohorts in a dataset of Parkinson\'s disease patients. Results suggest that Clustrophile 2 improves the speed and effectiveness of exploratory clustering analysis for both experts and non-experts.","keywords":"Clustering tour,Guided data analysis,Unsupervised learning,Exploratory data analysis,Interactive clustering analysis,Interpretability,Explainability,Visual data exploration recommendation,Dimensionality reduction,What-if analysis,Clustrophile","caption":"Fig. 1: Clustrophile 2 is an interactive tool for guided exploratory clustering analysis. Its interface includes two collapsible sidebars (a, e) and a main view where users can perform operations on the data. Clustrophile 2 tightly couples b) a dynamic data table that supports a rich set of \ufb01ltering interactions and statistics and c) multiple resizable Clustering Views, which can be used to work simultaneously on different clustering instances. Each Clustering View provides several ways to guide users during their analysis, such as d) the Clustering Tour.","img_size":{"width":1917,"height":1003},"subfigures":[{"x":8.831509167709818,"y":17.39984608029319,"width":1890.9486358515533,"height":971.7969940164515,"type":"interface","id":"interface-0"}],"visualizations":[{"x":393.39858529598433,"y":656.6534508289884,"width":248.79008282229546,"height":225.40282258004942,"type":"contour_graph","id":"contour_graph-13"},{"x":670.3929499948664,"y":597.8092897577126,"width":256.0898380115707,"height":280.2761004904411,"type":"heatmap","id":"heatmap-0"},{"x":976.2780342864646,"y":771.3812910766659,"width":243.2853461109923,"height":110.97226313834734,"type":"heatmap","id":"heatmap-1"},{"x":395.8077347935709,"y":655.2606480684926,"width":246.13078875556505,"height":220.9883404443546,"type":"scatterplot","id":"scatterplot-5"},{"x":976.2780342864646,"y":589.2729618239935,"width":251.82167404471113,"height":174.9947226412399,"type":"scatterplot","id":"scatterplot-6"},{"x":395.5513833992095,"y":152.63042533067846,"width":1119.9505928853757,"height":325.08300395256913,"type":"table","id":"table-7"},{"x":1238.4021813774712,"y":604.6493753003915,"width":279.7949213972551,"height":258.1573043608923,"type":"table","id":"table-8"}],"relations":[{"vislist":[{"vislist":["contour_graph-13","scatterplot-5"],"relation":null,"id":"group-4"}],"relation":"accompanied","id":"relation-2"}]},"3061_1":{"comp":[["contour_graph","scatterplot",["accompanied"]],["scatterplot","contour_graph",["accompanied"]]],"visType":["contour_graph","scatterplot"],"compType":["accompanied"],"compressed_tree":[{"composite_pattern":"accompanied","visualization_type":[["contour_graph","scatterplot"]]}],"coOccurrence":[["contour_graph","scatterplot",["coOccurrence"]]],"year":2018,"conference":["VAST"],"authors":["Marco Cavallo","\xc7agatay Demiralp"],"title":"Clustrophile 2: Guided Visual Clustering Analysis","doi":"10.1109/TVCG.2018.2864477","abstract":"Data clustering is a common unsupervised learning method frequently used in exploratory data analysis. However, identifying relevant structures in unlabeled, high-dimensional data is nontrivial, requiring iterative experimentation with clustering parameters as well as data features and instances. The number of possible clusterings for a typical dataset is vast, and navigating in this vast space is also challenging. The absence of ground-truth labels makes it impossible to define an optimal solution, thus requiring user judgment to establish what can be considered a satisfiable clustering result. Data scientists need adequate interactive tools to effectively explore and navigate the large clustering space so as to improve the effectiveness of exploratory clustering analysis. We introduce Clustrophile 2, a new interactive tool for guided clustering analysis. Clustrophile 2 guides users in clustering-based exploratory analysis, adapts user feedback to improve user guidance, facilitates the interpretation of clusters, and helps quickly reason about differences between clusterings. To this end, Clustrophile 2 contributes a novel feature, the Clustering Tour, to help users choose clustering parameters and assess the quality of different clustering results in relation to current analysis goals and user expectations. We evaluate Clustrophile 2 through a user study with 12 data scientists, who used our tool to explore and interpret sub-cohorts in a dataset of Parkinson\'s disease patients. Results suggest that Clustrophile 2 improves the speed and effectiveness of exploratory clustering analysis for both experts and non-experts.","keywords":"Clustering tour,Guided data analysis,Unsupervised learning,Exploratory data analysis,Interactive clustering analysis,Interpretability,Explainability,Visual data exploration recommendation,Dimensionality reduction,What-if analysis,Clustrophile","caption":"Fig. 2: Clustering View, representing a clustering instance. a) A scatterplot shows the rows of the dataset projected on a 2D plane, where distance encodes the similarity between data points, whereas b) a heatmap allows easy comparison of clusters (represented by columns) by feature (row). Clustrophile 2 supports displaying multiple Clustering Views at a time, allowing users to compare different clustering results.","img_size":{"width":1080,"height":564},"subfigures":[{"x":10.364803038711385,"y":13.62906080347594,"width":1060.6206306731638,"height":542.1426243913007,"type":"interface","id":"interface-0"}],"visualizations":[{"x":18.560335220958937,"y":160.19095305774846,"width":511.58234515460106,"height":315.79355903984856,"type":"contour_graph","id":"contour_graph-4"},{"x":554.4901185770751,"y":125.95256385501666,"width":519.4150197628458,"height":334.3873517786562,"type":"heatmap","id":"heatmap-0"},{"x":15.224011713030762,"y":159.37335285505128,"width":515.8589922395383,"height":319.915179379412,"type":"scatterplot","id":"scatterplot-3"}],"relations":[{"vislist":[{"vislist":["contour_graph-4","scatterplot-3"],"relation":null,"id":"group-0"}],"relation":"accompanied","id":"relation-0"}]},"2551_0":{"comp":[["line_chart","scatterplot",["accompanied"]],["scatterplot","line_chart",["accompanied"]],["bar_chart","sankey_diagram",["nested"]]],"visType":["line_chart","scatterplot","bar_chart","sankey_diagram"],"compType":["accompanied","nested"],"compressed_tree":[{"composite_pattern":"accompanied","visualization_type":[["line_chart","scatterplot"]]},{"composite_pattern":"nested","visualization_type":[["bar_chart"],["sankey_diagram"]]}],"coOccurrence":[["line_chart","scatterplot",["coOccurrence"]],["line_chart","bar_chart",["coOccurrence"]],["line_chart","sankey_diagram",["coOccurrence"]],["scatterplot","bar_chart",["coOccurrence"]],["scatterplot","sankey_diagram",["coOccurrence"]],["bar_chart","sankey_diagram",["coOccurrence"]]],"year":2014,"conference":["VAST"],"authors":["David Gotz","Harry Stavropoulos"],"title":"DecisionFlow: Visual Analytics for High-Dimensional Temporal Event Sequence Data","doi":"10.1109/TVCG.2014.2346682","abstract":"Temporal event sequence data is increasingly commonplace, with applications ranging from electronic medical records to financial transactions to social media activity. Previously developed techniques have focused on low-dimensional datasets (e.g., with less than 20 distinct event types). Real-world datasets are often far more complex. This paper describes DecisionFlow, a visual analysis technique designed to support the analysis of high-dimensional temporal event sequence data (e.g., thousands of event types). DecisionFlow combines a scalable and dynamic temporal event data structure with interactive multi-view visualizations and ad hoc statistical analytics. We provide a detailed review of our methods, and present the results from a 12-person user study. The study results demonstrate that DecisionFlow enables the quick and accurate completion of a range of sequence analysis tasks for datasets containing thousands of event types and millions of individual events.","keywords":"Information Visualization, Temporal Event Sequences, Visual Analytics, Flow Diagrams, Medical Informatics","caption":"Fig. 1. A screenshot of DecisionFlow being used to analyze electronic medical data. This view (b-d) summarizes the medical records for 514 cardiology patients that match (a) the user-de\ufb01ned query. The query results include over 113,000 individual events of more than 1,600 distinct event types. (e) Highlighted is a subgroup of patients who developed heart failure at signi\ufb01cantly higher rates (p < 0.01) than peers who received (f) a particular type of lab test earlier in the episode.","img_size":{"width":1776,"height":985},"subfigures":[{"x":118.14250405379005,"y":18.076667944588213,"width":1510.1120354011957,"height":964.9916565997593,"type":"interface","id":"interface-0"}],"visualizations":[{"x":403.68106312292343,"y":117.80730897009965,"width":940.8222591362126,"height":350.1495016611295,"type":"bar_chart","id":"bar_chart-0"},{"x":1381.3394467552619,"y":405.3055953179301,"width":227.0777202460836,"height":63.204389650307604,"type":"bar_chart","id":"bar_chart-7"},{"x":374.2292358803986,"y":503.95348837209286,"width":932.6411960132888,"height":458.139534883721,"type":"line_chart","id":"line_chart-2"},{"x":403.68106312292343,"y":117.80730897009965,"width":940.8222591362126,"height":350.1495016611295,"type":"sankey_diagram","id":"sankey_diagram-1"},{"x":372.5930232558138,"y":507.2259136212624,"width":934.2774086378737,"height":451.59468438538215,"type":"scatterplot","id":"scatterplot-4"},{"x":805.7268931077501,"y":33.84450445889074,"width":260.08060531889214,"height":112.39843146377639,"type":"table","id":"table-6"}],"relations":[{"vislist":[{"vislist":["line_chart-2","scatterplot-4"],"relation":null,"id":"group-0"}],"relation":"accompanied","id":"relation-0"},{"vislist":[{"vislist":["bar_chart-0"],"relation":null,"id":"group-1"},{"vislist":["sankey_diagram-1"],"relation":null,"id":"group-2"}],"relation":"nested","id":"relation-1"}]},"2557_0":{"comp":[["line_chart","stripe_graph",["accompanied"]],["stripe_graph","line_chart",["accompanied"]]],"visType":["line_chart","stripe_graph"],"compType":["accompanied"],"compressed_tree":[{"composite_pattern":"accompanied","visualization_type":[["line_chart","stripe_graph"]]}],"coOccurrence":[["line_chart","stripe_graph",["coOccurrence"]]],"year":2014,"conference":["VAST"],"authors":["Christian Partl","Alexander Lex","Marc Streit","Hendrik Strobelt","Anne Mai Wassermann","Hanspeter Pfister","Dieter Schmalstieg"],"title":"ConTour: Data-Driven Exploration of Multi-Relational Datasets for Drug Discovery","doi":"10.1109/TVCG.2014.2346752","abstract":"Large scale data analysis is nowadays a crucial part of drug discovery. Biologists and chemists need to quickly explore and evaluate potentially effective yet safe compounds based on many datasets that are in relationship with each other. However, there is a lack of tools that support them in these processes. To remedy this, we developed ConTour, an interactive visual analytics technique that enables the exploration of these complex, multi-relational datasets. At its core ConTour lists all items of each dataset in a column. Relationships between the columns are revealed through interaction: selecting one or multiple items in one column highlights and re-sorts the items in other columns. Filters based on relationships enable drilling down into the large data space. To identify interesting items in the first place, ConTour employs advanced sorting strategies, including strategies based on connectivity strength and uniqueness, as well as sorting based on item attributes. ConTour also introduces interactive nesting of columns, a powerful method to show the related items of a child column for each item in the parent column. Within the columns, ConTour shows rich attribute data about the items as well as information about the connection strengths to other datasets. Finally, ConTour provides a number of detail views, which can show items from multiple datasets and their associated data at the same time. We demonstrate the utility of our system in case studies conducted with a team of chemical biologists, who investigate the effects of chemical compounds on cells and need to understand the underlying mechanisms.","keywords":"Multi-relational data, visual data analysis, drug discovery","caption":"Fig. 1. ConTour shows a multitude of heterogeneous data items in several columns in the relationship view (bottom). The detail views display a selected pathway and selected chemical structures of compounds (top).","img_size":{"width":1980,"height":1130},"subfigures":[{"x":50.723529853077416,"y":26.78454534925299,"width":1864.657628694196,"height":1084.1482703473891,"type":"interface","id":"interface-0"}],"visualizations":[{"x":85.55335968379448,"y":674.4268774703557,"width":317.1146245059289,"height":415.37549407114625,"type":"bar_chart","id":"bar_chart-0"},{"x":407.13438735177874,"y":678.8932806324111,"width":332.7470355731224,"height":415.37549407114625,"type":"bar_chart","id":"bar_chart-1"},{"x":1447.8063241106722,"y":685.5928853754941,"width":317.11462450592853,"height":408.67588932806314,"type":"bar_chart","id":"bar_chart-2"},{"x":739.8814229249011,"y":681.1264822134387,"width":321.58102766798436,"height":413.1422924901185,"type":"box_plot","id":"box_plot-3"},{"x":246.34387351778662,"y":111.66007905138342,"width":895.5138339920948,"height":518.102766798419,"type":"flow_diagram","id":"flow_diagram-4"},{"x":1061.4624505928855,"y":678.8932806324111,"width":379.6442687747035,"height":415.37549407114625,"type":"line_chart","id":"line_chart-5"},{"x":1060.818825164767,"y":678.6294164606871,"width":378.6798099879254,"height":413.71489196270596,"type":"stripe_graph","id":"stripe_graph-6"}],"relations":[{"vislist":[{"vislist":["line_chart-5","stripe_graph-6"],"relation":null,"id":"group-0"}],"relation":"accompanied","id":"relation-0"}]},"2568_5":{"comp":[["heatmap","comb",["accompanied"]],["comb","heatmap",["accompanied"]],["pie_chart","tree",["nested"]],["pie_chart","scatterplot",["nested"]],["proportional_area_chart","area_chart",["coordinated"]]],"visType":["heatmap","comb","pie_chart","tree","scatterplot","proportional_area_chart","area_chart"],"compType":["accompanied","nested","coordinated"],"compressed_tree":[{"composite_pattern":"nested","visualization_type":[["pie_chart"],["tree"]]},{"composite_pattern":"nested","visualization_type":[["pie_chart"],["scatterplot"]]},{"composite_pattern":"accompanied","visualization_type":[["heatmap",{"composite_pattern":"coordinated","visualization_type":[["proportional_area_chart"],["area_chart"]]}]]}],"coOccurrence":[],"year":2014,"conference":["VAST"],"authors":["Jian Zhao","Nan Cao","Zhen Wen","Yale Song","Yu-Ru Lin","Christopher Collins"],"title":"#FluxFlow: Visual Analysis of Anomalous Information Spreading on Social Media","doi":"10.1109/TVCG.2014.2346922","abstract":"We present FluxFlow, an interactive visual analysis system for revealing and analyzing anomalous information spreading in social media. Everyday, millions of messages are created, commented, and shared by people on social media websites, such as Twitter and Facebook. This provides valuable data for researchers and practitioners in many application domains, such as marketing, to inform decision-making. Distilling valuable social signals from the huge crowd\'s messages, however, is challenging, due to the heterogeneous and dynamic crowd behaviors. The challenge is rooted in data analysts\' capability of discerning the anomalous information behaviors, such as the spreading of rumors or misinformation, from the rest that are more conventional patterns, such as popular topics and newsworthy events, in a timely fashion. FluxFlow incorporates advanced machine learning algorithms to detect anomalies, and offers a set of novel visualization designs for presenting the detected threads for deeper analysis. We evaluated FluxFlow with real datasets containing the Twitter feeds captured during significant events such as Hurricane Sandy. Through quantitative measurements of the algorithmic performance and qualitative interviews with domain experts, the results show that the back-end anomaly detection model is effective in identifying anomalous retweeting threads, and its front-end interactive visualizations are intuitive and useful for analysts to discover insights in data and comprehend the underlying analytical model.","keywords":"Retweeting threads, anomaly detection, social media, visual analytics, machine learning, information visualization","caption":"Fig. 5. The FluxFlow visual interface contains four interactively coordinated UI components, including a) a cluster view, b) a MDS view, c) a threads view, and a detail information panel with three subviews: d) a features view, e) a states view and f) a tweets view. Extra information such as the meta-data of a thread or the tweet contents can be assessed through g) informative tooltips and h) context menus. The analyst can also perform \ufb02exible exploration of retweeting threads at multiple scales, such as i) aggregating tree branches in the cluster view, and j) zooming the timelines using the time window in the threads view.","img_size":{"width":2157,"height":983},"subfigures":[{"x":4.78840506925004,"y":21.60388977042716,"width":1277.9108201294564,"height":875.5105573128335,"type":"interface","id":"interface-0"},{"x":1149.1188158773477,"y":592.535773024216,"width":982.0783486018315,"height":175.77920561647014,"type":"single","id":"single-1"}],"visualizations":[{"x":365.699911933414,"y":22.05516685984648,"width":915.8329803659765,"height":712.6285444234387,"type":"area_chart","id":"area_chart-17"},{"x":325.69452962660125,"y":733.704009184915,"width":675.6967984934089,"height":168.4613935969868,"type":"matrix","id":"matrix-4"},{"x":318.5034508164824,"y":733.7040091849177,"width":54.09778850536042,"height":168.46139359698688,"type":"pie_chart","id":"pie_chart-10"},{"x":7.283983487241565,"y":17.28028037135584,"width":309.15442561205276,"height":540.557438794727,"type":"pie_chart","id":"pie_chart-7"},{"x":9.113793872245196,"y":566.0424196326506,"width":307.3246152270491,"height":336.122983149251,"type":"pie_chart","id":"pie_chart-8"},{"x":318.4414266749902,"y":20.982728582278583,"width":51.06651439573429,"height":709.0188323917132,"type":"pie_chart","id":"pie_chart-9"},{"x":320.1408573102171,"y":17.28028037135584,"width":962.6365348399248,"height":714.5725047080978,"type":"proportional_area_chart","id":"proportional_area_chart-13"},{"x":10.7091870364697,"y":562.8516333042016,"width":309.4316702737473,"height":341.1649935831614,"type":"scatterplot","id":"scatterplot-12"},{"x":1160.5966011896894,"y":591.1597530643879,"width":977.4463276836154,"height":177.71751412429376,"type":"scatterplot","id":"scatterplot-14"},{"x":322.2749529190207,"y":16.661016949152543,"width":953.0975428092755,"height":711.4893199193784,"type":"stripe_graph","id":"stripe_graph-6"},{"x":11.269303201506546,"y":18.51224105461394,"width":305.4519774011299,"height":538.7062146892655,"type":"tree","id":"tree-15"},{"x":373.3721566648378,"y":20.36346516007533,"width":913.7013866075488,"height":703.4651600753297,"type":"unit_visualization","id":"unit_visualization-16"}],"relations":[{"vislist":[{"vislist":["pie_chart-7"],"relation":null,"id":"group-0"},{"vislist":["tree-15"],"relation":null,"id":"group-1"}],"relation":"nested","id":"relation-0"},{"vislist":[{"vislist":["pie_chart-8"],"relation":null,"id":"group-2"},{"vislist":["scatterplot-12"],"relation":null,"id":"group-3"}],"relation":"nested","id":"relation-1"},{"vislist":[{"vislist":["heatmap-6",{"vislist":[{"vislist":["proportional_area_chart-13"],"relation":null,"id":"group-4"},{"vislist":["area_chart-17"],"relation":null,"id":"group-5"}],"relation":"coordinated","id":"relation-2"}],"relation":null,"id":"group-6"}],"relation":"accompanied","id":"relation-3"}]},"2591_2":{"comp":[["line_chart","area_chart",["accompanied"]],["area_chart","line_chart",["accompanied"]],["area_chart","glyph_based",["accompanied"]],["glyph_based","area_chart",["accompanied"]]],"visType":["line_chart","area_chart","glyph_based"],"compType":["accompanied"],"compressed_tree":[{"composite_pattern":"accompanied","visualization_type":[["line_chart","area_chart"]]},{"composite_pattern":"accompanied","visualization_type":[["glyph_based","area_chart"]]}],"coOccurrence":[["line_chart","area_chart",["coOccurrence"]],["line_chart","glyph_based",["coOccurrence"]],["area_chart","glyph_based",["coOccurrence"]]],"year":2014,"conference":["VAST"],"authors":["Jian Zhao","Liang Gou","Fei Wang","Michelle X. Zhou"],"title":"PEARL: An Interactive Visual Analytic Tool for Understanding Personal Emotion Style Derived from Social Media","doi":"10.1109/VAST.2014.7042496","abstract":"Hundreds of millions of people leave digital footprints on social media (e.g., Twitter and Facebook). Such data not only disclose a person\'s demographics and opinions, but also reveal one\'s emotional style. Emotional style captures a person\'s patterns of emotions over time, including his overall emotional volatility and resilience. Understanding one\'s emotional style can provide great benefits for both individuals and businesses alike, including the support of self-reflection and delivery of individualized customer care. We present PEARL, a timeline-based visual analytic tool that allows users to interactively discover and examine a person\'s emotional style derived from this person\'s social media text. Compared to other visual text analytic systems, our work offers three unique contributions. First, it supports multi-dimensional emotion analysis from social media text to automatically detect a person\'s expressed emotions at different time points and summarize those emotions to reveal the person\'s emotional style. Second, it effectively visualizes complex, multi-dimensional emotion analysis results to create a visual emotional profile of an individual, which helps users browse and interpret one\'s emotional style. Third, it supports rich visual interactions that allow users to interactively explore and validate emotion analysis results. We have evaluated our work extensively through a series of studies. The results demonstrate the effectiveness of our tool both in emotion analysis from social media and in support of interactive visualization of the emotion analysis results.","keywords":"Personal emotion analytics, affective and mood modeling, social media text, Twitter, information visualization","caption":"Fig. 3. The PEARL user interface consists of several interactively coordinated views: (a) emotional pro\ufb01le overview, (b) emotional pro\ufb01le detail view, (c) mood word view, and (d) raw tweets view. The overview and detail views are coupled with direct manipulations of (e) a time window. A toolbar on top contains a search box, (f) an action menu, for (j) highlighting important data points, and (g) an interactive legend, for data \ufb01ltering. PEARL also provides (i) informative tooltips on many of the visualization elements.","img_size":{"width":2130,"height":897},"subfigures":[{"x":8.459820103588894,"y":11.305378730091721,"width":1481.8724928505533,"height":872.8418816667479,"type":"interface","id":"interface-0"}],"visualizations":[{"x":4.695767195767196,"y":142.78705440900563,"width":1493.2645403377112,"height":355.66604127579734,"type":"area_chart","id":"area_chart-0"},{"x":41.29455909943715,"y":69.52251407129457,"width":1437.317073170732,"height":77.2607879924953,"type":"area_chart","id":"area_chart-3"},{"x":5.328330206378987,"y":136.1266416510319,"width":1487.9362101313325,"height":356.9981238273922,"type":"glyph_based","id":"glyph_based-9"},{"x":41.29455909943715,"y":66.85834896810508,"width":1434.6529080675423,"height":77.2607879924953,"type":"line_chart","id":"line_chart-7"},{"x":15.701568647039965,"y":503.78142589118175,"width":374.1631392478063,"height":382.30769230769215,"type":"scatterplot","id":"scatterplot-8"}],"relations":[{"vislist":[{"vislist":["line_chart-7","area_chart-3"],"relation":null,"id":"group-0"}],"relation":"accompanied","id":"relation-0"},{"vislist":[{"vislist":["glyph_based-9","area_chart-0"],"relation":null,"id":"group-1"}],"relation":"accompanied","id":"relation-1"}]},"2589_2":{"comp":[["contour_graph","comb",["accompanied"]],["comb","contour_graph",["accompanied"]],["comb","donut_chart",["nested"]],["pie_chart","graph",["nested"]]],"visType":["contour_graph","comb","donut_chart","pie_chart","graph"],"compType":["accompanied","nested"],"compressed_tree":[{"composite_pattern":"nested","visualization_type":[[{"composite_pattern":"accompanied","visualization_type":[["contour_graph",{"composite_pattern":"nested","visualization_type":[["pie_chart"],["graph"]]}]]}],["donut_chart"]]}],"coOccurrence":[["pie_chart","graph",["coOccurrence"]],["pie_chart","contour_graph",["coOccurrence"]],["pie_chart","donut_chart",["coOccurrence"]],["graph","contour_graph",["coOccurrence"]],["graph","donut_chart",["coOccurrence"]],["contour_graph","donut_chart",["coOccurrence"]]],"year":2014,"conference":["VAST"],"authors":["Shixia Liu","Xiting Wang","Jianfei Chen","Jim Zhu","Baining Guo"],"title":"TopicPanorama: A Full Picture of Relevant Topics","doi":"10.1109/VAST.2014.7042494","abstract":"We present a visual analytics approach to developing a full picture of relevant topics discussed in multiple sources such as news, blogs, or micro-blogs. The full picture consists of a number of common topics among multiple sources as well as distinctive topics. The key idea behind our approach is to jointly match the topics extracted from each source together in order to interactively and effectively analyze common and distinctive topics. We start by modeling each textual corpus as a topic graph. These graphs are then matched together with a consistent graph matching method. Next, we develop an LOD-based visualization for better understanding and analysis of the matched graph. The major feature of this visualization is that it combines a radially stacked tree visualization with a density-based graph visualization to facilitate the examination of the matched topic graph from multiple perspectives. To compensate for the deficiency of the graph matching algorithm and meet different users\' needs, we allow users to interactively modify the graph matching result. We have applied our approach to various data including news, tweets, and blog data. Qualitative evaluation and a real-world case study with domain experts demonstrate the promise of our approach, especially in support of analyzing a topic-graph-based full picture at different levels of detail.","keywords":"Topic graph, graph matching, graph visualization, user interactions, level-of-detail","caption":"Figure 3. User interface: (a) TopicPanorama visualization; (b) controlpanel; (c) information panel.","img_size":{"width":993,"height":704},"subfigures":[{"x":13.874971978356085,"y":12.866471453964587,"width":967.1741976193565,"height":680.1902507828003,"type":"interface","id":"interface-0"}],"visualizations":[{"x":61.00951683748178,"y":40.199121522694,"width":630.8169838945826,"height":627.7247437774525,"type":"contour_graph","id":"contour_graph-2"},{"x":61.00951683748178,"y":40.199121522694,"width":629.7862371888726,"height":627.7247437774525,"type":"graph","id":"graph-1"},{"x":63.07101024890199,"y":40.199121522694,"width":627.7247437774524,"height":629.7862371888726,"type":"pie_chart","id":"pie_chart-0"},{"x":61.00951683748178,"y":40.199121522694,"width":629.7862371888726,"height":626.6939970717424,"type":"donut_chart","id":"donut_chart-3"}],"relations":[{"vislist":[{"vislist":[{"vislist":[{"vislist":["contour_graph-2",{"vislist":[{"vislist":["pie_chart-0"],"relation":null,"id":"group-5"},{"vislist":["graph-1"],"relation":null,"id":"group-6"}],"relation":"nested","id":"relation-3"}],"relation":null,"id":"group-7"}],"relation":"accompanied","id":"relation-4"}],"relation":null,"id":"group-8"},{"vislist":["donut_chart-3"],"relation":null,"id":"group-9"}],"relation":"nested","id":"relation-5"}]},"2454_4":{"comp":[["scatterplot","line_chart",["accompanied"]],["line_chart","scatterplot",["accompanied"]],["bar_chart","bar_chart",["mirrored"]]],"visType":["scatterplot","line_chart","bar_chart"],"compType":["accompanied","mirrored"],"compressed_tree":[{"composite_pattern":"accompanied","visualization_type":[["scatterplot","line_chart"]]},{"composite_pattern":"mirrored","visualization_type":[["bar_chart"]]},{"composite_pattern":"mirrored","visualization_type":[["bar_chart"]]}],"coOccurrence":[["scatterplot","line_chart",["coOccurrence"]],["scatterplot","bar_chart",["coOccurrence"]],["line_chart","bar_chart",["coOccurrence"]]],"year":2013,"conference":["VAST"],"authors":["Markus B\xf6gl","Wolfgang Aigner","Peter Filzmoser","Tim Lammarsch","Silvia Miksch","Alexander Rind"],"title":"Visual Analytics for Model Selection in Time Series Analysis","doi":"10.1109/TVCG.2013.222","abstract":"Model selection in time series analysis is a challenging task for domain experts in many application areas such as epidemiology, economy, or environmental sciences. The methodology used for this task demands a close combination of human judgement and automated computation. However, statistical software tools do not adequately support this combination through interactive visual interfaces. We propose a Visual Analytics process to guide domain experts in this task. For this purpose, we developed the TiMoVA prototype that implements this process based on user stories and iterative expert feedback on user experience. The prototype was evaluated by usage scenarios with an example dataset from epidemiology and interviews with two external domain experts in statistics. The insights from the experts\' feedback and the usage scenarios show that TiMoVA is able to support domain experts in model selection tasks through interactive visual interfaces with short feedback cycles.","keywords":"Visual analytics, model selection, visual interaction, time series analysis, coordinated & multiple views","caption":"Fig. 5. TiMoVA Overview. The figure is showing the coordinated and multiple views in the user interface, where (1) is the time series plot (input data), (2) the model selection toolbox, (3) the ACF/PACF plot as well as further model selection, (4a-d) the residual analysis plots, and (5) the model history including the information criteria. The plots in the area for the residual analysis are (4a) the standardized residuals over time, (4b) the ACF of the residuals over the lags, (4c) the quantile of the standardized residuals against the quantile of the standard normal distribution, and (4d) the p-values of the Ljung-Box statistics over lags.","img_size":{"width":2166,"height":943},"subfigures":[{"x":3.5504463960407837,"y":3.8594140127747547,"width":2154.383496648166,"height":937.537738872326,"type":"interface","id":"interface-0"}],"visualizations":[{"x":1107.3136626042335,"y":393.0016035920462,"width":472.3797305965364,"height":240.35792174470808,"type":"bar_chart","id":"bar_chart-0"},{"x":20.840282232200135,"y":409.67382937780627,"width":1022.5631815266198,"height":526.5644644002565,"type":"bar_chart","id":"bar_chart-1"},{"x":1643.6035920461838,"y":391.6122514432329,"width":461.26491340602934,"height":243.13662604233483,"type":"line_chart","id":"line_chart-2"},{"x":1117.0391276459272,"y":106.79506093649776,"width":1001.7228992944193,"height":243.13662604233483,"type":"line_chart","id":"line_chart-3"},{"x":11.114817190506738,"y":66.50384862091084,"width":1042.0141116100065,"height":268.144964720975,"type":"line_chart","id":"line_chart-4"},{"x":1105.9243104554203,"y":675.0400898011545,"width":479.32649134060307,"height":251.47273893521492,"type":"scatterplot","id":"scatterplot-5"},{"x":1643.6035920461838,"y":390.22289929441956,"width":462.6542655548428,"height":244.52597819114814,"type":"scatterplot","id":"scatterplot-6"},{"x":1622.7633098139834,"y":661.1465683130211,"width":514.0602950609366,"height":133.3778062860808,"type":"table","id":"table-7"}],"relations":[{"vislist":[{"vislist":["scatterplot-6","line_chart-2"],"relation":null,"id":"group-0"}],"relation":"accompanied","id":"relation-0"},{"vislist":[{"vislist":["bar_chart-1"],"relation":null,"id":"group-1"}],"relation":"mirrored","id":"relation-1"},{"vislist":[{"vislist":["bar_chart-0"],"relation":null,"id":"group-2"}],"relation":"mirrored","id":"relation-2"}]},"1443_0":{"comp":[["arc_diagram","tree",["accompanied"]],["arc_diagram","bar_chart",["accompanied"]],["tree","arc_diagram",["accompanied"]],["bar_chart","arc_diagram",["accompanied"]]],"visType":["arc_diagram","tree","bar_chart"],"compType":["accompanied"],"compressed_tree":[{"composite_pattern":"accompanied","visualization_type":[["arc_diagram","tree"]]},{"composite_pattern":"accompanied","visualization_type":[["arc_diagram","bar_chart"]]}],"coOccurrence":[["arc_diagram","tree",["coOccurrence"]],["arc_diagram","bar_chart",["coOccurrence"]],["tree","bar_chart",["coOccurrence"]]],"year":2006,"conference":["InfoVis"],"authors":["A. Johannes Pretorius","Jarke J. van Wijk"],"title":"Visual Analysis of Multivariate State Transition Graphs","doi":"10.1109/TVCG.2006.192","abstract":"We present a new approach for the visual analysis of state transition graphs. We deal with multivariate graphs where a number of attributes are associated with every node. Our method provides an interactive attribute-based clustering facility. Clustering results in metric, hierarchical and relational data, represented in a single visualization. To visualize hierarchically structured quantitative data, we introduce a novel technique: the bar tree. We combine this with a node-link diagram to visualize the hierarchy and an arc diagram to visualize relational data. Our method enables the user to gain significant insight into large state transition graphs containing tens of thousands of nodes. We illustrate the effectiveness of our approach by applying it to a real-world use case. The graph we consider models the behavior of an industrial wafer stepper and contains 55 043 nodes and 289 443 edges","keywords":"Graph visualization, multivariate visualization, interactive clustering, state spaces, transition systems, finite state machines","caption":"Fig. 1. Visualization of multivariate state transition graphs. The user can (a) select a subset of state attributes and (b) view their associated types. (c) Every type also has a domain of values. Attribute-based clustering results in three types of data: (d) a clustering hierarchy, visualized as a node-link diagram, (e) an abstract graph, visualized as an arc diagram and (f) metric data, visualized as a bar tree. All data are represented in a single visualization, enabling the identi\ufb01cation of correlations. Subtle cushioning is used (g) to clearly distinguish levels in the hierarchy and (h) to give a layered effect illustrating the hierarchical nature of the bar tree.","img_size":{"width":2148,"height":1671},"subfigures":[{"x":0.9765269592492601,"y":4.024905479901425,"width":2143.1260105991496,"height":1660.0269864318539,"type":"interface","id":"interface-0"}],"visualizations":[{"x":13.162110094199592,"y":490.4651546419194,"width":1626.366243736168,"height":359.1178332621008,"type":"arc_diagram","id":"arc_diagram-2"},{"x":1.802794448756257,"y":847.2112479115293,"width":1633.1071480568814,"height":366.8724533124198,"type":"arc_diagram","id":"arc_diagram-3"},{"x":11.252538775158882,"y":939.382558475839,"width":1628.1433147852044,"height":688.3836342797301,"type":"bar_chart","id":"bar_chart-0"},{"x":5.706499467256783,"y":93.43661154657053,"width":1632.139534883721,"height":760.5548172757473,"type":"tree","id":"tree-1"}],"relations":[{"vislist":[{"vislist":["arc_diagram-2","tree-1"],"relation":null,"id":"group-0"}],"relation":"accompanied","id":"relation-0"},{"vislist":[{"vislist":["arc_diagram-3","bar_chart-0"],"relation":null,"id":"group-1"}],"relation":"accompanied","id":"relation-1"}]},"2633_3":{"comp":[["bar_chart","line_chart",["accompanied"]],["line_chart","bar_chart",["accompanied"]],["matrix","map",["coordinated"]]],"visType":["bar_chart","line_chart","matrix","map"],"compType":["accompanied","coordinated"],"compressed_tree":[{"composite_pattern":"accompanied","visualization_type":[["bar_chart","line_chart"]]},{"composite_pattern":"coordinated","visualization_type":[["matrix"],["map"]]}],"coOccurrence":[["bar_chart","line_chart",["coOccurrence"]],["bar_chart","matrix",["coOccurrence"]],["bar_chart","map",["coOccurrence"]],["line_chart","matrix",["coOccurrence"]],["line_chart","map",["coOccurrence"]],["matrix","map",["coOccurrence"]]],"year":2015,"conference":["SciVis"],"authors":["Hongsen Liao","Yingcai Wu","Li Chen","Thomas M. Hamill","Yunhai Wang","Kan Dai","Hui Zhang","Wei Che"],"title":"A Visual Voting Framework for Weather Forecast Calibration","doi":"10.1109/SciVis.2015.7429488","abstract":"Numerical weather predictions have been widely used for weather forecasting. Many large meteorological centers are producing highly accurate ensemble forecasts routinely to provide effective weather forecast services. However, biases frequently exist in forecast products because of various reasons, such as the imperfection of the weather forecast models. Failure to identify and neutralize the biases would result in unreliable forecast products that might mislead analysts; consequently, unreliable weather predictions are produced. The analog method has been commonly used to overcome the biases. Nevertheless, this method has some serious limitations including the difficulties in finding effective similar past forecasts, the large search space for proper parameters and the lack of support for interactive, real-time analysis. In this study, we develop a visual analytics system based on a novel voting framework to circumvent the problems. The framework adopts the idea of majority voting to combine judiciously the different variants of analog methods towards effective retrieval of the proper analogs for calibration. The system seamlessly integrates the analog methods into an interactive visualization pipeline with a set of coordinated views that characterizes the different methods. Instant visual hints are provided in the views to guide users in finding and refining analogs. We have worked closely with the domain experts in the meteorological research to develop the system. The effectiveness of the system is demonstrated using two case studies. An informal evaluation with the experts proves the usability and usefulness of the system.","keywords":"Weather forecast, analog method, calibration, majority voting, visual analytics","caption":"Figure 4: Coordinated views for the calibration stage: (a) The geographical view. (b) The region RMS difference view. (c) The small region RMS difference view (d) The small region variable RMS difference view. (e) The user guide. ","img_size":{"width":2115,"height":1074},"subfigures":[{"x":3.8265623505173156,"y":2.7149062142374016,"width":2100.493044370169,"height":1066.2841722554497,"type":"interface","id":"interface-0"}],"visualizations":[{"x":494.62464586298444,"y":759.9003530564622,"width":1596.500290163505,"height":248.88180402863355,"type":"area_chart","id":"area_chart-7"},{"x":429.27554331162526,"y":431.13731839470915,"width":1660.3306569296506,"height":301.4049936142126,"type":"bar_chart","id":"bar_chart-4"},{"x":21.831616326483992,"y":9.320588791817903,"width":276.60398639341645,"height":775.6119156348906,"type":"flow_diagram","id":"flow_diagram-0"},{"x":1233.6887431372038,"y":108.15642141644365,"width":868.6292417514151,"height":307.56285722842233,"type":"line_chart","id":"line_chart-1"},{"x":421.29595921477335,"y":431.1092492721169,"width":1674.9524683566221,"height":298.78412796675127,"type":"line_chart","id":"line_chart-5"},{"x":379.5753690583744,"y":92.41914889170144,"width":759.3881439210206,"height":351.083919794813,"type":"map","id":"map-2"},{"x":384.8750180375905,"y":97.6810063130282,"width":747.4514891958574,"height":339.22170300583593,"type":"matrix","id":"matrix-3"}],"relations":[{"vislist":[{"vislist":["bar_chart-4","line_chart-5"],"relation":null,"id":"group-0"}],"relation":"accompanied","id":"relation-0"},{"vislist":[{"vislist":["matrix-3"],"relation":null,"id":"group-2"},{"vislist":["map-2"],"relation":null,"id":"group-1"}],"relation":"coordinated","id":"relation-1"}]},"2068_3":{"comp":[["area_chart","line_chart",["accompanied"]],["line_chart","area_chart",["accompanied"]],["line_chart","others",["accompanied"]],["others","line_chart",["accompanied"]]],"visType":["area_chart","line_chart","others"],"compType":["accompanied"],"compressed_tree":[{"composite_pattern":"accompanied","visualization_type":[["area_chart","line_chart"]]},{"composite_pattern":"accompanied","visualization_type":[["line_chart","others"]]}],"coOccurrence":[["area_chart","line_chart",["coOccurrence"]],["area_chart","others",["coOccurrence"]],["line_chart","others",["coOccurrence"]]],"year":2010,"conference":["Vis"],"authors":["Chad Jones","Kwan-Liu Ma"],"title":"Visualizing Flow Trajectories Using Locality-based Rendering and Warped Curve Plots","doi":"10.1109/TVCG.2010.218","abstract":"In flow simulations the behavior and properties of particle trajectories often depend on the physical geometry contained in the simulated environment. Understanding the flow in and around the geometry itself is an important part of analyzing the data. Previous work has often utilized focus+context rendering techniques, with an emphasis on showing trajectories while simplifying or illustratively rendering the physical areas. Our research instead emphasizes the local relationship between particle paths and geometry by using a projected multi-field visualization technique. The correlation between a particle path and its surrounding area is calculated on-the-fly and displayed in a non-intrusive manner. In addition, we support visual exploration and comparative analysis through the use of linked information visualization, such as manipulatable curve plots and one-on-one similarity plots. Our technique is demonstrated on particle trajectories from a groundwater simulation and a computer room airflow simulation, where the flow of particles is highly influenced by the dense geometry.","keywords":"Flow visualization, Multi-field visualization, Focus+context visualization, Coordinated linked views","caption":"Fig. 4. The similarity signature plot, shown below the curve plot, visual- izes difference between values over time for pairs of trajectories. With the area graph in this example, we can see when the velocity of one tra- jectory overtakes the velocity of the other by tracking the corresponding color under the area graph. ","img_size":{"width":1055,"height":568},"subfigures":[{"x":10.309025784163126,"y":11.169075720247362,"width":1035.9340507414224,"height":551.0926852884398,"type":"single","id":"single-0"}],"visualizations":[{"x":11.933355986948587,"y":483.7520241904621,"width":1030.202712742937,"height":78.25117618699035,"type":"area_chart","id":"area_chart-2"},{"x":22.104882972013787,"y":18.730966537093263,"width":1013.5819599054727,"height":453.2404379996205,"type":"line_chart","id":"line_chart-1"},{"x":11.925742753485622,"y":481.95700799985303,"width":1028.356788643531,"height":83.7038020363098,"type":"line_chart","id":"line_chart-3"},{"x":13.765019801585403,"y":16.859295076194016,"width":1022.8170839809977,"height":456.0524841873676,"type":"others","id":"others-0"}],"relations":[{"vislist":[{"vislist":["area_chart-2","line_chart-3"],"relation":null,"id":"group-0"}],"relation":"accompanied","id":"relation-0"},{"vislist":[{"vislist":["line_chart-1","others-0"],"relation":null,"id":"group-1"}],"relation":"accompanied","id":"relation-1"}]},"2197_3":{"comp":[["glyph_based","chord_diagram",["nested"]],["heatmap","scivis",["coordinated"]]],"visType":["glyph_based","chord_diagram","heatmap","scivis"],"compType":["nested","coordinated"],"compressed_tree":[{"composite_pattern":"nested","visualization_type":[["glyph_based"],["chord_diagram"]]},{"composite_pattern":"coordinated","visualization_type":[["heatmap"],["scivis"]]}],"coOccurrence":[["glyph_based","chord_diagram",["coOccurrence"]],["glyph_based","heatmap",["coOccurrence"]],["glyph_based","scivis",["coOccurrence"]],["chord_diagram","heatmap",["coOccurrence"]],["chord_diagram","scivis",["coOccurrence"]],["heatmap","scivis",["coOccurrence"]]],"year":2011,"conference":["Vis"],"authors":["Steffen Oeltze-Jafra","Wolfgang Freiler","Reyk Hillert","Helmut Doleisch","Bernhard Preim","Walter Schubert"],"title":"Interactive, Graph-based Visual Analysis of High-dimensional, Multi-parameter Fluorescence Microscopy Data in Toponomics","doi":"10.1109/TVCG.2011.217","abstract":"In Toponomics, the function protein pattern in cells or tissue (the toponome) is imaged and analyzed for applications in toxicology, new drug development and patient-drug-interaction. The most advanced imaging technique is robot-driven multi-parameter fluorescence microscopy. This technique is capable of co-mapping hundreds of proteins and their distribution and assembly in protein clusters across a cell or tissue sample by running cycles of fluorescence tagging with monoclonal antibodies or other affinity reagents, imaging, and bleaching in situ. The imaging results in complex multi-parameter data composed of one slice or a 3D volume per affinity reagent. Biologists are particularly interested in the localization of co-occurring proteins, the frequency of co-occurrence and the distribution of co-occurring proteins across the cell. We present an interactive visual analysis approach for the evaluation of multi-parameter fluorescence microscopy data in toponomics. Multiple, linked views facilitate the definition of features by brushing multiple dimensions. The feature specification result is linked to all views establishing a focus+context visualization in 3D. In a new attribute view, we integrate techniques from graph visualization. Each node in the graph represents an affinity reagent while each edge represents two co-occurring affinity reagent bindings. The graph visualization is enhanced by glyphs which encode specific properties of the binding. The graph view is equipped with brushing facilities. By brushing in the spatial and attribute domain, the biologist achieves a better understanding of the function protein patterns of a cell. Furthermore, an interactive table view is integrated which summarizes unique fluorescence patterns. We discuss our approach with respect to a cell probe containing lymphocytes and a prostate tissue section.","keywords":"Visual Analytics, Fluorescence Microscopy, Toponomics, Protein Interaction, Graph Visualization","caption":"Fig. 4. Local investigation of a mononuclear immune cell toponome. CD15 binds to almost every part of the cell\u2019s surface (almost fully filled glyph). If it co-maps with another PAR, this is CONA in the majority of cases. A smooth brush is applied to the histogram which plots the number of PAR bindings per voxel (logarithmic scaling). The focus is on a high number. Thereby, corresponding regions are assigned a higher opacity in the 3D view (red regions, see arrows). Green indicates single- 1-CMPs, yellow indicates two and red three concurrently binding PARs.","img_size":{"width":1045,"height":748},"subfigures":[{"x":6.917292367908858,"y":3.461583049745889,"width":1033.5531635757038,"height":737.8925891026968,"type":"interface","id":"interface-0"}],"visualizations":[{"x":819.425342928789,"y":545.2902821127605,"width":219.57557226679702,"height":151.9231890541381,"type":"bar_chart","id":"bar_chart-4"},{"x":491.6537503085454,"y":25.38747391827264,"width":534.4666650638093,"height":480.6964059122948,"type":"chord_diagram","id":"chord_diagram-0"},{"x":493.23194140485344,"y":29.330274164293538,"width":531.3102828711924,"height":474.4029278191582,"type":"glyph_based","id":"glyph_based-1"},{"x":16.63620614366865,"y":25.369845814840815,"width":448.21898619401406,"height":476.75135612189354,"type":"heatmap","id":"heatmap-3"},{"x":11.664164944003844,"y":565.9317512858242,"width":767.7744329870642,"height":154.4236166779143,"type":"others","id":"others-5"},{"x":10.326729674665193,"y":23.792023360668978,"width":456.0624425089828,"height":479.1109398307846,"type":"scivis","id":"scivis-2"}],"relations":[{"vislist":[{"vislist":["glyph_based-1"],"relation":null,"id":"group-1"},{"vislist":["chord_diagram-0"],"relation":null,"id":"group-0"}],"relation":"nested","id":"relation-0"},{"vislist":[{"vislist":["heatmap-3"],"relation":null,"id":"group-3"},{"vislist":["scivis-2"],"relation":null,"id":"group-2"}],"relation":"coordinated","id":"relation-1"}]},"1908_0":{"comp":[["scivis","matrix",["nested"]]],"visType":["scivis","matrix"],"compType":["nested"],"compressed_tree":[{"composite_pattern":"nested","visualization_type":[["scivis"],["matrix"]]}],"coOccurrence":[["scivis","matrix",["coOccurrence"]]],"year":2009,"conference":["Vis"],"authors":["Daniel F. Keefe","Marcus Ewert","William Ribarsky","Remco Chang"],"title":"Interactive Coordinated Multiple-View Visualization of Biomechanical Motion Data","doi":"10.1109/TVCG.2009.152","abstract":"We present an interactive framework for exploring space-time and form-function relationships in experimentally collected high-resolution biomechanical data sets. These data describe complex 3D motions (e.g. chewing, walking, flying) performed by animals and humans and captured via high-speed imaging technologies, such as biplane fluoroscopy. In analyzing these 3D biomechanical motions, interactive 3D visualizations are important, in particular, for supporting spatial analysis. However, as researchers in information visualization have pointed out, 2D visualizations can also be effective tools for multi-dimensional data analysis, especially for identifying trends over time. Our approach, therefore, combines techniques from both 3D and 2D visualizations. Specifically, it utilizes a multi-view visualization strategy including a small multiples view of motion sequences, a parallel coordinates view, and detailed 3D inspection views. The resulting framework follows an overview first, zoom and filter, then details-on-demand style of analysis, and it explicitly targets a limitation of current tools, namely, supporting analysis and comparison at the level of a collection of motions rather than sequential analysis of a single or small number of motions. Scientific motion collections appropriate for this style of analysis exist in clinical work in orthopedics and physical rehabilitation, in the study of functional morphology within evolutionary biology, and in other contexts. An application is described based on a collaboration with evolutionary biologists studying the mechanics of chewing motions in pigs. Interactive exploration of data describing a collection of more than one hundred experimentally captured pig chewing cycles is described.","keywords":"Scientific visualization, information visualization, coordinated multiple views, biomechanics","caption":"Fig. 1. When data are first loaded into the visualization framework, an overview of the motion database is presented using three coordinated data views: 1. A small multiples view generated from snapshots of 3D renderings (top-left window in the figure). 2. A parallel coordinates view (top- right), data dimensions plotted in this example are: trial number, chew cycle number, cycle duration, average angular velocity for the cycle, average translational velocity for the cycle, average distance of separation of the teeth for the cycle, then frame number and the same set of descriptive statistics but calculated at the single frame level rather than as averages over a cycle. 3. A 2D plot of data values over time (bottom), here angular velocity over time. All views are linked through both visual and interactive strategies. In this case, 108 chewing motions cycles from five different trials are displayed in this overview. ","img_size":{"width":2154,"height":1036},"subfigures":[{"x":9.148339433328005,"y":3.565280222673723,"width":2144.6845077868124,"height":1031.1148046237029,"type":"interface","id":"interface-0"}],"visualizations":[{"x":18.800403123342353,"y":789.7301925901598,"width":2120.485245491669,"height":216.57083812967215,"type":"line_chart","id":"line_chart-3"},{"x":16.511591954644633,"y":52.98453733532919,"width":1227.493502637305,"height":668.1520588857627,"type":"matrix","id":"matrix-0"},{"x":1252.3619564220583,"y":63.8455686988499,"width":888.7117811232581,"height":664.1613777408393,"type":"parallel_coordinate","id":"parallel_coordinate-2"},{"x":15.138161443920616,"y":51.60887873498018,"width":1222.0682601820442,"height":665.4475663688862,"type":"scivis","id":"scivis-1"}],"relations":[{"vislist":[{"vislist":["scivis-1"],"relation":null,"id":"group-1"},{"vislist":["matrix-0"],"relation":null,"id":"group-0"}],"relation":"nested","id":"relation-0"}]},"1934_6":{"comp":[["scivis","graph",["nested"]]],"visType":["scivis","graph"],"compType":["nested"],"compressed_tree":[{"composite_pattern":"nested","visualization_type":[["scivis"],["graph"]]}],"coOccurrence":[["scivis","graph",["coOccurrence"]]],"year":2009,"conference":["Vis"],"authors":["Emanuele Santos","Lauro Didier Lins","James P. Ahrens","Juliana Freire","Cl\xe1udio T. Silva"],"title":"VisMashup: Streamlining the Creation of Custom Visualization Applications","doi":"10.1109/TVCG.2009.195","abstract":"Visualization is essential for understanding the increasing volumes of digital data. However, the process required to create insightful visualizations is involved and time consuming. Although several visualization tools are available, including tools with sophisticated visual interfaces, they are out of reach for users who have little or no knowledge of visualization techniques and/or who do not have programming expertise. In this paper, we propose VisMashup, a new framework for streamlining the creation of customized visualization applications. Because these applications can be customized for very specific tasks, they can hide much of the complexity in a visualization specification and make it easier for users to explore visualizations by manipulating a small set of parameters. We describe the framework and how it supports the various tasks a designer needs to carry out to develop an application, from mining and exploring a set of visualization specifications (pipelines), to the creation of simplified views of the pipelines, and the automatic generation of the application and its interface. We also describe the implementation of the system and demonstrate its use in two real application scenarios.","keywords":"Scientific Visualization, Dataflow, Visualization Systems","caption":"Fig. 7: VisMashup Mining Interface: (a) Relevant pipelines organized in a Hasse Diagram; (b) Examining the parameters returned from the mining process using the Template/Pipeline View Editor.","img_size":{"width":1009,"height":992},"subfigures":[{"x":6.761237749146741,"y":5.663746909395838,"width":996.5331424838455,"height":982.7839840150511,"type":"interface","id":"interface-0"}],"visualizations":[{"x":25.417181972247008,"y":37.42531405513822,"width":919.1077707163879,"height":770.4016624376557,"type":"graph","id":"graph-0"},{"x":405.0557361843871,"y":464.19428409977166,"width":584.1890911117231,"height":478.516826150548,"type":"graph","id":"graph-3"},{"x":36.91922712453859,"y":40.5408316842547,"width":896.1036804118033,"height":759.9476715117371,"type":"scivis","id":"scivis-1"},{"x":403.22715586390626,"y":239.97016385560397,"width":582.568161841993,"height":227.010164720026,"type":"table","id":"table-2"}],"relations":[{"vislist":[{"vislist":["scivis-1"],"relation":null,"id":"group-1"},{"vislist":["graph-0"],"relation":null,"id":"group-0"}],"relation":"nested","id":"relation-0"}]},"3175_0":{"comp":[["bar_chart","graph",["nested"]],["bar_chart","bar_chart",["mirrored"]]],"visType":["bar_chart","graph"],"compType":["nested","mirrored"],"compressed_tree":[{"composite_pattern":"mirrored","visualization_type":[["bar_chart"]]},{"composite_pattern":"nested","visualization_type":[["bar_chart"],["graph"]]}],"coOccurrence":[["bar_chart","graph",["coOccurrence"]]],"year":2019,"conference":["SciVis"],"authors":["Katar\xedna Furmanov\xe1","Adam Jur\u010d\xedk","Barbora Kozl\xedkov\xe1","Helwig Hauser","Jan By\u0161ka"],"title":"Multiscale Visual Drilldown for the Analysis of Large Ensembles of Multi-Body Protein Complexes","doi":"10.1109/TVCG.2019.2934333","abstract":"When studying multi-body protein complexes, biochemists use computational tools that can suggest hundreds or thousands of their possible spatial configurations. However, it is not feasible to experimentally verify more than only a very small subset of them. In this paper, we propose a novel multiscale visual drilldown approach that was designed in tight collaboration with proteomic experts, enabling a systematic exploration of the configuration space. Our approach takes advantage of the hierarchical structure of the data - from the whole ensemble of protein complex configurations to the individual configurations, their contact interfaces, and the interacting amino acids. Our new solution is based on interactively linked 2D and 3D views for individual hierarchy levels. At each level, we offer a set of selection and filtering operations that enable the user to narrow down the number of configurations that need to be manually scrutinized. Furthermore, we offer a dedicated filter interface, which provides the users with an overview of the applied filtering operations and enables them to examine their impact on the explored ensemble. This way, we maintain the history of the exploration process and thus enable the user to return to an earlier point of the exploration. We demonstrate the effectiveness of our approach on two case studies conducted by collaborating proteomic experts.","keywords":"Molecular visualization, data \ufb01ltering, coordinated and multiple views","caption":"Fig. 1. Exploration of an ensemble of 500 possible human nucleosome con\ufb01gurations, based on the following components: a) Overview Graph with main application controls; b) 3D View, showing the exploded Complex Con\ufb01guration, amino acids from contact interfaces are colored according to the frequency of their interactions; c) Property View, showing properties of all Complex Con\ufb01gurations; d) Protein View with range \ufb01lter panel; e) Residue Matrix, which also can be switched to Contact Zone List View, and f) Filter View. ","img_size":{"width":1964,"height":1029},"subfigures":[{"x":5.317479617750188,"y":10.238677664581113,"width":1948.9849291371668,"height":1016.1884586008628,"type":"interface","id":"interface-0"}],"visualizations":[{"x":16.00652983326088,"y":259.5027110135577,"width":523.6990470465263,"height":482.6667309022233,"type":"bar_chart","id":"bar_chart-1"},{"x":9.846339375532239,"y":255.8573989013697,"width":536.0194279619839,"height":493.68387972714606,"type":"graph","id":"graph-0"},{"x":582.055980419476,"y":36.29509853726489,"width":475.7582859442097,"height":452.086806985118,"type":"heatmap","id":"heatmap-2"},{"x":1082.1231675631761,"y":65.7625747311523,"width":564.7495575233504,"height":642.8290028338239,"type":"matrix","id":"matrix-3"},{"x":15.020817650224387,"y":838.1872777006989,"width":1611.070487931819,"height":185.883487940655,"type":"matrix","id":"matrix-4"}],"relations":[{"vislist":[{"vislist":["bar_chart-1"],"relation":null,"id":"group-0"}],"relation":"mirrored","id":"relation-0"},{"vislist":[{"vislist":["bar_chart-1"],"relation":null,"id":"group-2"},{"vislist":["graph-0"],"relation":null,"id":"group-1"}],"relation":"nested","id":"relation-1"}]},"3182_2":{"comp":[["bar_chart","table",["nested"]]],"visType":["bar_chart","table"],"compType":["nested"],"compressed_tree":[{"composite_pattern":"nested","visualization_type":[["bar_chart"],["table"]]},{"composite_pattern":"nested","visualization_type":[["bar_chart"],["table"]]}],"coOccurrence":[["bar_chart","table",["coOccurrence"]]],"year":2019,"conference":["VAST"],"authors":["James Wexler","Mahima Pushkarna","Tolga Bolukbasi","Martin Wattenberg","Fernanda Vi\xe9gas","Jimbo Wilson"],"title":"The What-If Tool: Interactive Probing of Machine Learning Models","doi":"10.1109/TVCG.2019.2934619","abstract":"A key challenge in developing and deploying Machine Learning (ML) systems is understanding their performance across a wide range of inputs. To address this challenge, we created the What-If Tool, an open-source application that allows practitioners to probe, visualize, and analyze ML systems, with minimal coding. The What-If Tool lets practitioners test performance in hypothetical situations, analyze the importance of different data features, and visualize model behavior across multiple models and subsets of input data. It also lets practitioners measure systems according to multiple ML fairness metrics. We describe the design of the tool, and report on real-life usage at different organizations.","keywords":"Interactive Machine Learning, Model Debugging, Model Comparison","caption":"Fig. 3: Features tab in WIT, showing summary statistics for the UCI Census dataset. Features are sorted by non-uniformity of the distributions of their values. Capital gains and capital loss have a large percentage of zeros and a long tail of non-zero values. ","img_size":{"width":2154,"height":661},"subfigures":[{"x":4.64836800131119,"y":9.602211642706393,"width":2140.212670670643,"height":644.0413505695205,"type":"interface","id":"interface-0"}],"visualizations":[{"x":838.5281257335549,"y":240.11839170167502,"width":290.3473858147245,"height":412.37543488312775,"type":"bar_chart","id":"bar_chart-2"},{"x":1777.0020845016793,"y":237.78940023187906,"width":326.0235093759729,"height":388.9903576810822,"type":"bar_chart","id":"bar_chart-3"},{"x":18.973458953493356,"y":146.9084344736844,"width":1127.2285614113464,"height":508.87531165141723,"type":"table","id":"table-0"},{"x":1183.5949704556965,"y":158.98964691788032,"width":937.7146320583116,"height":488.8001612033755,"type":"table","id":"table-1"}],"relations":[{"vislist":[{"vislist":["bar_chart-2"],"relation":null,"id":"group-1"},{"vislist":["table-0"],"relation":null,"id":"group-0"}],"relation":"nested","id":"relation-0"},{"vislist":[{"vislist":["bar_chart-3"],"relation":null,"id":"group-3"},{"vislist":["table-1"],"relation":null,"id":"group-2"}],"relation":"nested","id":"relation-1"}]},"3185_5":{"comp":[["others","table",["nested"]]],"visType":["others","table"],"compType":["nested"],"compressed_tree":[{"composite_pattern":"nested","visualization_type":[["others"],["table"]]}],"coOccurrence":[["others","table",["coOccurrence"]]],"year":2019,"conference":["VAST"],"authors":["Michael Behrisch","Tobias Schreck","Hanspeter Pfister"],"title":"GUIRO: User-Guided Matrix Reordering","doi":"10.1109/TVCG.2019.2934300","abstract":"Matrix representations are one of the main established and empirically proven to be effective visualization techniques for relational (or network) data. However, matrices-similar to node-link diagrams-are most effective if their layout reveals the underlying data topology. Given the many developed algorithms, a practical problem arises: \u201cWhich matrix reordering algorithm should I choose for my dataset at hand?\u201d To make matters worse, different reordering algorithms applied to the same dataset may let significantly different visual matrix patterns emerge. This leads to the question of trustworthiness and explainability of these fully automated, often heuristic, black-box processes. We present GUIRO, a Visual Analytics system that helps novices, network analysts, and algorithm designers to open the black-box. Users can investigate the usefulness and expressiveness of 70 accessible matrix reordering algorithms. For network analysts, we introduce a novel model space representation and two interaction techniques for a user-guided reordering of rows or columns, and especially groups thereof (submatrix reordering). These novel techniques contribute to the understanding of the global and local dataset topology. We support algorithm designers by giving them access to 16 reordering quality metrics and visual exploration means for comparing reordering implementations on a row/column permutation level. We evaluated GUIRO in a guided explorative user study with 12 subjects, a case study demonstrating its usefulness in a real-world scenario, and through an expert study gathering feedback on our design decisions. We found that our proposed methods help even inexperienced users to understand matrix patterns and allow a user-guided steering of reordering algorithms. GUIRO helps to increase the transparency of matrix reordering algorithms, thus helping a broad range of users to get a better insight into the complex reordering process, in turn supporting data and reordering algorithm ...","keywords":"Visual Analytics, matrix, black-box algorithms, seriation, ordering, sorting, steerable algorithm, interaction, 2D projection","caption":"Fig. 6: GUIRO allows algorithm designers to compare 16 quality metrics (T8), as well as the row/column index (dis-)similarity. We see that the hierarchical clustering algorithms HC_Ward and HC_AVG produce in the identical index list independent of their linkage method (T9,T10)","img_size":{"width":1061,"height":559},"subfigures":[{"x":5.565603055111398,"y":6.133736056291136,"width":1049.8687938897774,"height":546.7325278874176,"type":"interface","id":"interface-0"}],"visualizations":[{"x":60.90819212183109,"y":53.97953076889316,"width":67.69555295577177,"height":283.2032578194545,"type":"others","id":"others-1"},{"x":35.90593830297455,"y":359.36742333085704,"width":975.7702933278374,"height":130.74279338242903,"type":"parallel_coordinate","id":"parallel_coordinate-2"},{"x":21.26751590382446,"y":32.048961291427965,"width":1019.8067511989718,"height":312.9660316003928,"type":"table","id":"table-0"}],"relations":[{"vislist":[{"vislist":["others-1"],"relation":null,"id":"group-1"},{"vislist":["table-0"],"relation":null,"id":"group-0"}],"relation":"nested","id":"relation-0"}]},"3194_0":{"comp":[["bar_chart","table",["nested"]]],"visType":["bar_chart","table"],"compType":["nested"],"compressed_tree":[{"composite_pattern":"nested","visualization_type":[["bar_chart"],["table"]]},{"composite_pattern":"nested","visualization_type":[["bar_chart"],["table"]]}],"coOccurrence":[["bar_chart","table",["coOccurrence"]]],"year":2019,"conference":["VAST"],"authors":["Subhashis Hazarika","Haoyu Li","Ko-Chih Wang","Han-Wei Shen","Ching-Shan Chou"],"title":"NNVA: Neural Network Assisted Visual Analysis of Yeast Cell Polarization Simulation (J) (Best Paper Honorable Ment","doi":"10.1109/TVCG.2019.2934591","abstract":"Complex computational models are often designed to simulate real-world physical phenomena in many scientific disciplines. However, these simulation models tend to be computationally very expensive and involve a large number of simulation input parameters, which need to be analyzed and properly calibrated before the models can be applied for real scientific studies. We propose a visual analysis system to facilitate interactive exploratory analysis of high-dimensional input parameter space for a complex yeast cell polarization simulation. The proposed system can assist the computational biologists, who designed the simulation model, to visually calibrate the input parameters by modifying the parameter values and immediately visualizing the predicted simulation outcome without having the need to run the original expensive simulation for every instance. Our proposed visual analysis system is driven by a trained neural network-based surrogate model as the backend analysis framework. In this work, we demonstrate the advantage of using neural networks as surrogate models for visual analysis by incorporating some of the recent advances in the field of uncertainty quantification, interpretability and explainability of neural network-based models. We utilize the trained network to perform interactive parameter sensitivity analysis of the original simulation as well as recommend optimal parameter configurations using the activation maximization framework of neural networks. We also facilitate detail analysis of the trained network to extract useful insights about the simulation model, learned by the network, during the training process. We performed two case studies, and discovered multiple new parameter configurations, which can trigger high cell polarization results in the original simulation model. We evaluated our results by comparing with the original simulation model outcomes as well as the findings from previous parameter analysis performed by our experts.","keywords":"Temporal event sequence visualization, visual analytics, hierarchical aggregation, medical informatics","caption":"Fig. 1. The Cadence system for temporal event sequence visualization. (a) Interactive bar charts and histograms summarize non- temporal attributes and a variety of temporal event statistics. (b) An interactive \ufb02ow-based timeline allows users to dynamically de\ufb01ne and explore pathways within the temporal event data. Selections within the timeline link to (c) a Kaplan-Meier chart to summarize outcomes-over-time. Timeline selections also link to (d and e) a novel scatter-and-focus visualization which leverages dynamic hierarchical aggregation, scenting, and optimization-based layout to support navigation of high-dimensional hierarchical event data. ","img_size":{"width":1959,"height":533},"subfigures":[{"x":-1.8808270622415195,"y":7.076383428664181,"width":1954.5935275440966,"height":520.8888719046442,"type":"interface","id":"interface-0"}],"visualizations":[{"x":1134.6753596476865,"y":366.9270592048395,"width":292.9034122578741,"height":119.9756989823579,"type":"area_chart","id":"area_chart-6"},{"x":191.435922760796,"y":296.64639704333126,"width":116.92206213811565,"height":209.8299047082253,"type":"bar_chart","id":"bar_chart-7"},{"x":129.77833177906967,"y":109.30114925356153,"width":138.662626468373,"height":137.20712384301876,"type":"bar_chart","id":"bar_chart-8"},{"x":1499.4000548017336,"y":108.94077014515102,"width":443.2615417358795,"height":399.28114191905803,"type":"glyph_based","id":"glyph_based-5"},{"x":313.4128407110343,"y":90.56907066209364,"width":811.9140819201033,"height":420.012080848835,"type":"proportional_area_chart","id":"proportional_area_chart-1"},{"x":1234.0411534017821,"y":104.4351229744825,"width":168.4947157007983,"height":238.63220259760743,"type":"scatterplot","id":"scatterplot-4"},{"x":64.52473378586858,"y":103.45380505208578,"width":202.27922059876695,"height":134.0326728627662,"type":"table","id":"table-0"},{"x":53.56973228027272,"y":294.214471376485,"width":261.35066908552125,"height":213.45466109331628,"type":"table","id":"table-2"}],"relations":[{"vislist":[{"vislist":["bar_chart-8"],"relation":null,"id":"group-1"},{"vislist":["table-0"],"relation":null,"id":"group-0"}],"relation":"nested","id":"relation-0"},{"vislist":[{"vislist":["bar_chart-7"],"relation":null,"id":"group-3"},{"vislist":["table-2"],"relation":null,"id":"group-2"}],"relation":"nested","id":"relation-1"}]},"3195_6":{"comp":[["graph","map",["nested"]],["bar_chart","table",["nested"]],["word_cloud","comb",["large_view"]],["comb","comb",["large_view"]]],"visType":["graph","map","bar_chart","table","word_cloud","comb"],"compType":["nested","large_view"],"compressed_tree":[{"composite_pattern":"large_view","visualization_type":[["word_cloud",{"composite_pattern":"nested","visualization_type":[["bar_chart"],["table"]]}],[{"composite_pattern":"nested","visualization_type":[["graph"],["map"]]}]]}],"coOccurrence":[["graph","map",["coOccurrence"]],["graph","bar_chart",["coOccurrence"]],["graph","table",["coOccurrence"]],["graph","word_cloud",["coOccurrence"]],["map","bar_chart",["coOccurrence"]],["map","table",["coOccurrence"]],["map","word_cloud",["coOccurrence"]],["bar_chart","table",["coOccurrence"]],["bar_chart","word_cloud",["coOccurrence"]],["table","word_cloud",["coOccurrence"]]],"year":2019,"conference":["VAST"],"authors":["Luke S. Snyder","Yi-Shan Lin","Morteza Karimzadeh","Dan Goldwasser","David S. Ebert"],"title":"Interactive Learning for Identifying Relevant Tweets to Support Real-time Situational Awareness","doi":"10.1109/TVCG.2019.2934614","abstract":"Various domain users are increasingly leveraging real-time social media data to gain rapid situational awareness. However, due to the high noise in the deluge of data, effectively determining semantically relevant information can be difficult, further complicated by the changing definition of relevancy by each end user for different events. The majority of existing methods for short text relevance classification fail to incorporate users\' knowledge into the classification process. Existing methods that incorporate interactive user feedback focus on historical datasets. Therefore, classifiers cannot be interactively retrained for specific events or user-dependent needs in real-time. This limits real-time situational awareness, as streaming data that is incorrectly classified cannot be corrected immediately, permitting the possibility for important incoming data to be incorrectly classified as well. We present a novel interactive learning framework to improve the classification process in which the user iteratively corrects the relevancy of tweets in real-time to train the classification model on-the-fly for immediate predictive improvements. We computationally evaluate our classification model adapted to learn at interactive rates. Our results show that our approach outperforms state-of-the-art machine learning models. In addition, we integrate our framework with the extended Social Media Analytics and Reporting Toolkit (SMART) 2.0 system, allowing the use of our interactive learning framework within a visual analytics system tailored for real-time situational awareness. To demonstrate our framework\'s effectiveness, we provide domain expert feedback from first responders who used the extended SMART 2.0 system.","keywords":"Interactive machine learning, human-computer interaction, social media analytics, emergency/disaster management,situational awareness","caption":"Fig. 7. SMART 2.0 overview: (a) The control panel provides several \ufb01lters, visualizations, and views. (b) The content lens visualization provides the most frequently used words within a selected area. (c) The tweet classi\ufb01er visualization provides keyword-based \ufb01lters to help reduce noisy data. (d)(e) Clicking a tweet on the map with the tweet tooltip visualization displays the tweet\u2019s time, message, and relevance label. (f) The topic-modeling view, based on Latent Dirichlet Allocation, extracts trending topics and the most frequently used words associated with each topic among tweets with speci\ufb01ed relevancy. (g)\u2013(j) The message table aggregates the tweets for ef\ufb01cient exploration with (g) the model\u2019s estimated classi\ufb01cation performance (F1 score), (h) a drop down box to \ufb01lter data by their relevance labels, (i) color-coded relevance labels that can be changed by clicking on the label itself, and (j) associated relevance probabilities. Tweet map symbols are colored orange and purple to distinguish Twitter data from Instagram-linked tweets, respectively, since the latter contains potentially useful images for situational awareness. ","img_size":{"width":2151,"height":1154},"subfigures":[{"x":4.127071253288791,"y":4.139233631040686,"width":2137.833647557773,"height":1144.493384844643,"type":"interface","id":"interface-0"}],"visualizations":[{"x":1848.8753270156176,"y":756.7185064701002,"width":263.920784391944,"height":380.7056146776126,"type":"bar_chart","id":"bar_chart-2"},{"x":1185.3870308903875,"y":597.416550939918,"width":929.5275800288092,"height":57.13621576605524,"type":"bar_chart","id":"bar_chart-3"},{"x":246.58879692643237,"y":72.34464055003598,"width":1875.4416519335643,"height":1062.3774326247863,"type":"graph","id":"graph-6"},{"x":241.19102486526143,"y":71.03958065091068,"width":1890.3175569144034,"height":1073.1516622268614,"type":"map","id":"map-0"},{"x":1185.9912060375525,"y":601.9604371196586,"width":925.5989891621455,"height":536.5343466687281,"type":"table","id":"table-1"},{"x":1816.115045059855,"y":74.37195343421652,"width":284.206041322698,"height":142.58182386079721,"type":"word_cloud","id":"word_cloud-4"},{"x":1809.623529352633,"y":211.01492809383922,"width":290.73980884364164,"height":145.5149229042751,"type":"word_cloud","id":"word_cloud-5"}],"relations":[{"vislist":[{"vislist":["word_cloud-4","word_cloud-5",{"vislist":[{"vislist":["bar_chart-2"],"relation":null,"id":"group-4"},{"vislist":["table-1"],"relation":null,"id":"group-3"}],"relation":"nested","id":"relation-1"}],"relation":null,"id":"group-6"},{"vislist":[{"vislist":[{"vislist":["graph-6"],"relation":null,"id":"group-1"},{"vislist":["map-0"],"relation":null,"id":"group-0"}],"relation":"nested","id":"relation-0"}],"relation":null,"id":"group-5"}],"relation":"large_view","id":"relation-2"}]},"3202_0":{"comp":[["glyph_based","table",["nested"]],["table","scatterplot",["annotated"]]],"visType":["glyph_based","table","scatterplot"],"compType":["nested","annotated"],"compressed_tree":[{"composite_pattern":"annotated","visualization_type":[["table"],["scatterplot"]]},{"composite_pattern":"nested","visualization_type":[["glyph_based"],["table"]]},{"composite_pattern":"nested","visualization_type":[["glyph_based"],["table"]]}],"coOccurrence":[["table","scatterplot",["coOccurrence"]],["table","glyph_based",["coOccurrence"]],["scatterplot","glyph_based",["coOccurrence"]]],"year":2019,"conference":["VAST"],"authors":["Dylan Cashman","Adam Perer","Remco Chang","Hendrik Strobelt"],"title":"Ablate, Variate, and Contemplate: Visual Analytics for Discovering Neural Architectures","doi":"10.1109/TVCG.2019.2934261","abstract":"The performance of deep learning models is dependent on the precise configuration of many layers and parameters. However, there are currently few systematic guidelines for how to configure a successful model. This means model builders often have to experiment with different configurations by manually programming different architectures (which is tedious and time consuming) or rely on purely automated approaches to generate and train the architectures (which is expensive). In this paper, we present Rapid Exploration of Model Architectures and Parameters, or REMAP, a visual analytics tool that allows a model builder to discover a deep learning model quickly via exploration and rapid experimentation of neural network architectures. In REMAP, the user explores the large and complex parameter space for neural network architectures using a combination of global inspection and local experimentation. Through a visual overview of a set of models, the user identifies interesting clusters of architectures. Based on their findings, the user can run ablation and variation experiments to identify the effects of adding, removing, or replacing layers in a given architecture and generate new models accordingly. They can also handcraft new models using a simple graphical interface. As a result, a model builder can build deep learning models quickly, efficiently, and without manual programming. We inform the design of REMAP through a design study with four deep learning model builders. Through a use case, we demonstrate that REMAP allows users to discover performant neural network architectures efficiently using visual exploration and user-defined semi-automated searches through the model space.","keywords":"visual analytics, neural networks, parameter space exploration","caption":"Fig. 1: A screenshot of the REMAP system. In the Model Overview, section A, a visual overview of the set of sampled models is shown. Darkness of circles encodes performance of the models, and radius encodes the number of parameters. In the Model Drawer, section B, users can save models during their exploration for comparison or to return to later. In section C, four tabs help the user explore the model space and generate new models. The Generate Models tab, currently selected, allows for users to create new models via ablations, variations, or handcrafted templates. ","img_size":{"width":1888,"height":1032},"subfigures":[{"x":6.752567122057211,"y":11.370884456505978,"width":1874.4948657558828,"height":1020.241321432379,"type":"interface","id":"interface-0"}],"visualizations":[{"x":1068.2599109522082,"y":82.32334750641927,"width":273.1795750376107,"height":208.08562144903198,"type":"glyph_based","id":"glyph_based-5"},{"x":543.7064021926662,"y":514.0127161380814,"width":87.87657782430061,"height":513.9515620549616,"type":"glyph_based","id":"glyph_based-6"},{"x":1.4229185347992455,"y":566.9746311301341,"width":161.27789477413464,"height":459.3837291580665,"type":"glyph_based","id":"glyph_based-7"},{"x":2.177719273541434,"y":56.70967328360374,"width":458.2233258721782,"height":311.8632924955273,"type":"scatterplot","id":"scatterplot-0"},{"x":16.43727831976821,"y":517.5516880370313,"width":448.80532986456296,"height":505.67929274340526,"type":"table","id":"table-1"},{"x":529.7086210101768,"y":452.80821958092076,"width":1337.1501334883505,"height":565.8953498635774,"type":"table","id":"table-2"},{"x":334.87054584867707,"y":198.48129836446162,"width":254.8460631488317,"height":159.69584883597494,"type":"table","id":"table-3"}],"relations":[{"vislist":[{"vislist":["table-3"],"relation":null,"id":"group-1"},{"vislist":["scatterplot-0"],"relation":null,"id":"group-0"}],"relation":"annotated","id":"relation-0"},{"vislist":[{"vislist":["glyph_based-7"],"relation":null,"id":"group-3"},{"vislist":["table-1"],"relation":null,"id":"group-2"}],"relation":"nested","id":"relation-1"},{"vislist":[{"vislist":["glyph_based-6"],"relation":null,"id":"group-5"},{"vislist":["table-2"],"relation":null,"id":"group-4"}],"relation":"nested","id":"relation-2"}]},"3202_1":{"comp":[["others","matrix",["nested"]]],"visType":["others","matrix"],"compType":["nested"],"compressed_tree":[{"composite_pattern":"nested","visualization_type":[["others"],["matrix"]]}],"coOccurrence":[["others","matrix",["coOccurrence"]]],"year":2019,"conference":["VAST"],"authors":["Dylan Cashman","Adam Perer","Remco Chang","Hendrik Strobelt"],"title":"Ablate, Variate, and Contemplate: Visual Analytics for Discovering Neural Architectures","doi":"10.1109/TVCG.2019.2934261","abstract":"The performance of deep learning models is dependent on the precise configuration of many layers and parameters. However, there are currently few systematic guidelines for how to configure a successful model. This means model builders often have to experiment with different configurations by manually programming different architectures (which is tedious and time consuming) or rely on purely automated approaches to generate and train the architectures (which is expensive). In this paper, we present Rapid Exploration of Model Architectures and Parameters, or REMAP, a visual analytics tool that allows a model builder to discover a deep learning model quickly via exploration and rapid experimentation of neural network architectures. In REMAP, the user explores the large and complex parameter space for neural network architectures using a combination of global inspection and local experimentation. Through a visual overview of a set of models, the user identifies interesting clusters of architectures. Based on their findings, the user can run ablation and variation experiments to identify the effects of adding, removing, or replacing layers in a given architecture and generate new models accordingly. They can also handcraft new models using a simple graphical interface. As a result, a model builder can build deep learning models quickly, efficiently, and without manual programming. We inform the design of REMAP through a design study with four deep learning model builders. Through a use case, we demonstrate that REMAP allows users to discover performant neural network architectures efficiently using visual exploration and user-defined semi-automated searches through the model space.","keywords":"visual analytics, neural networks, parameter space exploration","caption":"Fig. 2: (a) The model inspection tab lets users see more granular information about a highlighted model. This includes a confusion matrix showing which classes the model performs best on or misclassi\ufb01es most frequently. Users can also view training curves to determine if an architecture might be able to continue to improve if trained further. (b) By selecting individual classes from the validation data, users can update the darkness of circles in the the Model Overview to see how all models perform on a given class. ","img_size":{"width":2141,"height":664},"subfigures":[{"x":6.824794919611125,"y":5.41944678938126,"width":1053.8807466669714,"height":592.9179347368669,"type":"interface","id":"interface-0"},{"x":1098.131839557725,"y":7.609083809649965,"width":1039.4075681687766,"height":587.423046405879,"type":"interface","id":"interface-1"}],"visualizations":[{"x":547.981182071286,"y":247.4825915390333,"width":508.93398967372514,"height":325.03642159064344,"type":"line_chart","id":"line_chart-1"},{"x":6.285630913371401,"y":256.89832363294914,"width":428.05959775221925,"height":308.918028788354,"type":"matrix","id":"matrix-0"},{"x":1105.6173813998296,"y":55.60997785599984,"width":993.8497470498112,"height":535.145080281972,"type":"matrix","id":"matrix-2"},{"x":1115.0984957048934,"y":63.679833763160985,"width":980.3027067849723,"height":528.5011183170492,"type":"others","id":"others-3"}],"relations":[{"vislist":[{"vislist":["others-3"],"relation":null,"id":"group-1"},{"vislist":["matrix-2"],"relation":null,"id":"group-0"}],"relation":"nested","id":"relation-0"}]},"3204_3":{"comp":[["others","sankey_diagram",["nested"]]],"visType":["others","sankey_diagram"],"compType":["nested"],"compressed_tree":[{"composite_pattern":"nested","visualization_type":[["others"],["sankey_diagram"]]}],"coOccurrence":[["others","sankey_diagram",["coOccurrence"]]],"year":2019,"conference":["VAST"],"authors":["Sebastian Gehrmann","Hendrik Strobelt","Robert Kr\xfcger","Hanspeter Pfister","Alexander M. Rush"],"title":"Visual Interaction with Deep Learning Models through Collaborative Semantic Inference","doi":"10.1109/TVCG.2019.2934595","abstract":"Automation of tasks can have critical consequences when humans lose agency over decision processes. Deep learning models are particularly susceptible since current black-box approaches lack explainable reasoning. We argue that both the visual interface and model structure of deep learning systems need to take into account interaction design. We propose a framework of collaborative semantic inference (CSI) for the co-design of interactions and models to enable visual collaboration between humans and algorithms. The approach exposes the intermediate reasoning process of models which allows semantic interactions with the visual metaphors of a problem, which means that a user can both understand and control parts of the model reasoning process. We demonstrate the feasibility of CSI with a co-designed case study of a document summarization system.","keywords":"Human-Computer Collaboration, Deep Learning, Neural Networks, Interaction Design, Human-Centered Design","caption":"Fig. 3. Overview of the CSI:Summarization visual interface. (a) shows the input and overlays the currently selected content selection (blue) and the current content of the summary (red). (b) shows a connection between the input and the current summary through the attention, which shows explicitly where words in the summary came from. (c) shows the current summary, (d) shows proxy elements for both input and output groups. This enables an overview of a document, even when the text does not \ufb01t on one page. (e) allows the user to request suggestions from the model, (f) enters the edit mode and adds a new sentence to the summary. (g) toggles whether the text should be aggregated into sentences. (h) provides quick selections for the content selection (blue) by being able to match the red highlights, or (de-)select everything. ","img_size":{"width":2130,"height":1176},"subfigures":[{"x":6.046023281359714,"y":10.439859456099304,"width":2115.4041977795723,"height":1158.87496546169,"type":"interface","id":"interface-0"}],"visualizations":[{"x":23.895460169294637,"y":168.3373090667892,"width":2066.046980863461,"height":956.4562324630048,"type":"others","id":"others-1"},{"x":22.549181044828966,"y":167.18562879902245,"width":2066.045855979402,"height":991.071551783804,"type":"sankey_diagram","id":"sankey_diagram-0"}],"relations":[{"vislist":[{"vislist":["others-1"],"relation":null,"id":"group-2"},{"vislist":["sankey_diagram-0"],"relation":null,"id":"group-3"}],"relation":"nested","id":"relation-1"}]},"3205_0":{"comp":[["stripe_graph","table",["nested"]],["line_chart","table",["nested"]],["glyph_based","graph",["nested"]],["bar_chart","table",["nested"]],["word_cloud","sankey_diagram",["nested"]]],"visType":["stripe_graph","table","line_chart","glyph_based","graph","bar_chart","word_cloud","sankey_diagram"],"compType":["nested"],"compressed_tree":[{"composite_pattern":"nested","visualization_type":[["stripe_graph","line_chart"],["table"]]},{"composite_pattern":"nested","visualization_type":[["glyph_based"],["graph"]]},{"composite_pattern":"nested","visualization_type":[["bar_chart"],["table"]]},{"composite_pattern":"nested","visualization_type":[["word_cloud"],["sankey_diagram"]]}],"coOccurrence":[["stripe_graph","line_chart",["coOccurrence"]],["stripe_graph","table",["coOccurrence"]],["stripe_graph","glyph_based",["coOccurrence"]],["stripe_graph","graph",["coOccurrence"]],["stripe_graph","bar_chart",["coOccurrence"]],["stripe_graph","word_cloud",["coOccurrence"]],["stripe_graph","sankey_diagram",["coOccurrence"]],["line_chart","table",["coOccurrence"]],["line_chart","glyph_based",["coOccurrence"]],["line_chart","graph",["coOccurrence"]],["line_chart","bar_chart",["coOccurrence"]],["line_chart","word_cloud",["coOccurrence"]],["line_chart","sankey_diagram",["coOccurrence"]],["table","glyph_based",["coOccurrence"]],["table","graph",["coOccurrence"]],["table","bar_chart",["coOccurrence"]],["table","word_cloud",["coOccurrence"]],["table","sankey_diagram",["coOccurrence"]],["glyph_based","graph",["coOccurrence"]],["glyph_based","bar_chart",["coOccurrence"]],["glyph_based","word_cloud",["coOccurrence"]],["glyph_based","sankey_diagram",["coOccurrence"]],["graph","bar_chart",["coOccurrence"]],["graph","word_cloud",["coOccurrence"]],["graph","sankey_diagram",["coOccurrence"]],["bar_chart","word_cloud",["coOccurrence"]],["bar_chart","sankey_diagram",["coOccurrence"]],["word_cloud","sankey_diagram",["coOccurrence"]]],"year":2019,"conference":["VAST"],"authors":["Haipeng Zeng","Xingbo Wang","Aoyu Wu","Yong Wang","Quan Li","Alex Endert","Huamin Qu"],"title":"EmoCo: Visual Analysis of Emotion Coherence in Presentation Videos","doi":"10.1109/TVCG.2019.2934656","abstract":"Emotions play a key role in human communication and public presentations. Human emotions are usually expressed through multiple modalities. Therefore, exploring multimodal emotions and their coherence is of great value for understanding emotional expressions in presentations and improving presentation skills. However, manually watching and studying presentation videos is often tedious and time-consuming. There is a lack of tool support to help conduct an efficient and in-depth multi-level analysis. Thus, in this paper, we introduce EmoCo, an interactive visual analytics system to facilitate efficient analysis of emotion coherence across facial, text, and audio modalities in presentation videos. Our visualization system features a channel coherence view and a sentence clustering view that together enable users to obtain a quick overview of emotion coherence and its temporal evolution. In addition, a detail view and word view enable detailed exploration and comparison from the sentence level and word level, respectively. We thoroughly evaluate the proposed system and visualization techniques through two usage scenarios based on TED Talk videos and interviews with two domain experts. The results demonstrate the effectiveness of our system in gaining insights into emotion coherence in presentations.","keywords":"Emotion, coherence, video analysis, visual analysis","caption":"Fig. 1: Our visualization system supports emotion analysis across three modalities (i.e., face, text, and audio) at different levels of details. The video view (a) summarizes each video in the collection and enables quick identi\ufb01cation of videos of interest. The channel coherence view (b) shows emotion coherence of the three modalities at the sentence level and provides extracted features for channel exploration. The detail view (c) supports detail exploration for a selected sentence with some highlighted features and transition points. The sentence clustering view (d) provides a summary of the video and reveals the temporal patterns of emotion information. The word view (e) enables ef\ufb01cient quantitative analysis at the word level in the video transcript. ","img_size":{"width":1920,"height":934},"subfigures":[{"x":16.141217636879492,"y":5.656265394664541,"width":1901.7272152163362,"height":919.683826458841,"type":"interface","id":"interface-0"}],"visualizations":[{"x":504.1614764406826,"y":702.3079151846742,"width":928.6738082958194,"height":176.8140580741826,"type":"area_chart","id":"area_chart-5"},{"x":1260.9968348326033,"y":78.5513007912053,"width":165.2886920476133,"height":96.6708739741042,"type":"bar_chart","id":"bar_chart-12"},{"x":1260.8095002507941,"y":171.43902272821256,"width":155.95092625284187,"height":93.09896343316478,"type":"bar_chart","id":"bar_chart-13"},{"x":1256.0757296792103,"y":265.60598184753604,"width":165.41846739601198,"height":94.25671986091828,"type":"bar_chart","id":"bar_chart-14"},{"x":1263.4352801723028,"y":352.62419231942016,"width":164.05396447761387,"height":97.56507136134468,"type":"bar_chart","id":"bar_chart-15"},{"x":1605.8904722096574,"y":531.9213065178354,"width":303.80010422414165,"height":368.83652896121174,"type":"bar_chart","id":"bar_chart-3"},{"x":1443.2057525730922,"y":83.83063261230252,"width":454.03210751837685,"height":376.4231734426115,"type":"glyph_based","id":"glyph_based-1"},{"x":1442.0293354567748,"y":87.47433709027732,"width":455.48449410908756,"height":378.8532862644257,"type":"graph","id":"graph-0"},{"x":504.2365213378325,"y":743.8874021404473,"width":947.9485884182985,"height":80.29349171821133,"type":"line_chart","id":"line_chart-6"},{"x":249.73088387162366,"y":185.05679743119322,"width":246.54765666134116,"height":482.50216024883974,"type":"line_chart","id":"line_chart-8"},{"x":494.16322862718323,"y":93.45867506688423,"width":226.30795389254843,"height":368.09930053343214,"type":"others","id":"others-16"},{"x":748.5903974421277,"y":88.63394408433842,"width":483.521923605682,"height":370.4606211652016,"type":"sankey_diagram","id":"sankey_diagram-10"},{"x":506.54744994055386,"y":543.627646686528,"width":917.8315894470795,"height":121.26469684877951,"type":"stripe_graph","id":"stripe_graph-4"},{"x":249.7197669101723,"y":177.81939041695125,"width":242.9277274748477,"height":488.47414272177923,"type":"stripe_graph","id":"stripe_graph-9"},{"x":1434.7690288189135,"y":513.3480108866368,"width":469.6915006569355,"height":395.60944755937106,"type":"table","id":"table-2"},{"x":20.41577322294258,"y":154.935245204663,"width":483.00592828552783,"height":512.3780091463867,"type":"table","id":"table-7"},{"x":866.1400902390998,"y":90.98865416568356,"width":242.35226616274568,"height":359.67774989140815,"type":"word_cloud","id":"word_cloud-11"}],"relations":[{"vislist":[{"vislist":["stripe_graph-9","line_chart-8"],"relation":null,"id":"group-1"},{"vislist":["table-7"],"relation":null,"id":"group-0"}],"relation":"nested","id":"relation-0"},{"vislist":[{"vislist":["glyph_based-1"],"relation":null,"id":"group-5"},{"vislist":["graph-0"],"relation":null,"id":"group-4"}],"relation":"nested","id":"relation-2"},{"vislist":[{"vislist":["bar_chart-3"],"relation":null,"id":"group-7"},{"vislist":["table-2"],"relation":null,"id":"group-6"}],"relation":"nested","id":"relation-3"},{"vislist":[{"vislist":["word_cloud-11"],"relation":null,"id":"group-9"},{"vislist":["sankey_diagram-10"],"relation":null,"id":"group-10"}],"relation":"nested","id":"relation-4"}]},"3210_0":{"comp":[["bar_chart","table",["nested"]],["glyph_based","graph",["nested"]]],"visType":["bar_chart","table","glyph_based","graph"],"compType":["nested"],"compressed_tree":[{"composite_pattern":"nested","visualization_type":[["bar_chart"],["table"]]},{"composite_pattern":"nested","visualization_type":[["glyph_based"],["graph"]]},{"composite_pattern":"nested","visualization_type":[["bar_chart"],["table"]]}],"coOccurrence":[["bar_chart","table",["coOccurrence"]],["bar_chart","glyph_based",["coOccurrence"]],["bar_chart","graph",["coOccurrence"]],["table","glyph_based",["coOccurrence"]],["table","graph",["coOccurrence"]],["glyph_based","graph",["coOccurrence"]]],"year":2019,"conference":["VAST"],"authors":["Yuxin Ma","Tiankai Xie","Jundong Li","Ross Maciejewski"],"title":"Explaining Vulnerabilities to Adversarial Machine Learning through Visual Analytics","doi":"10.1109/TVCG.2019.2934631","abstract":"Machine learning models are currently being deployed in a variety of real-world applications where model predictions are used to make decisions about healthcare, bank loans, and numerous other critical tasks. As the deployment of artificial intelligence technologies becomes ubiquitous, it is unsurprising that adversaries have begun developing methods to manipulate machine learning models to their advantage. While the visual analytics community has developed methods for opening the black box of machine learning models, little work has focused on helping the user understand their model vulnerabilities in the context of adversarial attacks. In this paper, we present a visual analytics framework for explaining and exploring model vulnerabilities to adversarial attacks. Our framework employs a multi-faceted visualization scheme designed to support the analysis of data poisoning attacks from the perspective of models, data instances, features, and local structures. We demonstrate our framework through two case studies on binary classifiers and illustrate model vulnerabilities with respect to varying attack strategies.","keywords":"Adversarial machine learning, data poisoning, visual analytics","caption":"Fig. 1. Reliability attack on spam \ufb01lters. (1) Poisoning instance #40 has the largest impact on the recall value, which is (2) also depicted in the model overview. (3) There is heavy overlap among instances in the two classes as well the poisoning instances. (4) Instance #40 has been successfully attacked causing a number of innocent instances to have their labels \ufb02ipped. (5) The \ufb02ipped instances are very close to the decision boundary. (6) On the feature of words \u201cwill\u201d and \u201cemail\u201d, the variances of poisoning instances are large. (7) A sub-optimal target (instance #80) has less impact on the recall value, but the cost of insertions is 40% lower than that of instance #40. ","img_size":{"width":1921,"height":1062},"subfigures":[{"x":11.802595178876526,"y":6.063406469534646,"width":1898.5248216175542,"height":1052.133660306435,"type":"interface","id":"interface-0"}],"visualizations":[{"x":870.9450387694932,"y":81.58977694272099,"width":164.53368218361692,"height":158.6304043634034,"type":"bar_chart","id":"bar_chart-4"},{"x":1291.0079518953007,"y":79.22787698433385,"width":100.59265070336484,"height":169.43129821902144,"type":"bar_chart","id":"bar_chart-5"},{"x":1642.189373347715,"y":64.82016916369082,"width":177.15774601417104,"height":188.52336355815675,"type":"bar_chart","id":"bar_chart-6"},{"x":670.3353016829635,"y":399.07152232849853,"width":279.08709756787937,"height":223.74813534663403,"type":"bar_chart","id":"bar_chart-9"},{"x":1219.2202831309683,"y":370.2026718910433,"width":665.6642695867432,"height":675.2815234586118,"type":"glyph_based","id":"glyph_based-7"},{"x":1224.291233248108,"y":373.43577809167743,"width":657.0508261069576,"height":661.6617996199075,"type":"graph","id":"graph-11"},{"x":154.52011740946813,"y":345.1333527808231,"width":357.1884146351844,"height":296.37732959669233,"type":"polar_plot","id":"polar_plot-0"},{"x":702.8896663119367,"y":690.6398431825716,"width":488.49756020089796,"height":358.9239972098076,"type":"scatterplot","id":"scatterplot-8"},{"x":534.8666413853953,"y":348.74503278966125,"width":644.7699799660924,"height":292.8002259423216,"type":"table","id":"table-1"},{"x":671.1750702273768,"y":20.32507705295515,"width":1220.0044317506904,"height":236.18930899549127,"type":"table","id":"table-2"},{"x":23.375436792583685,"y":690.3771713639535,"width":687.5002304968016,"height":362.01917971175675,"type":"table","id":"table-3"}],"relations":[{"vislist":[{"vislist":["bar_chart-4","bar_chart-5","bar_chart-6"],"relation":null,"id":"group-1"},{"vislist":["table-2"],"relation":null,"id":"group-0"}],"relation":"nested","id":"relation-0"},{"vislist":[{"vislist":["glyph_based-7"],"relation":null,"id":"group-3"},{"vislist":["graph-11"],"relation":null,"id":"group-2"}],"relation":"nested","id":"relation-1"},{"vislist":[{"vislist":["bar_chart-9"],"relation":null,"id":"group-5"},{"vislist":["table-1"],"relation":null,"id":"group-4"}],"relation":"nested","id":"relation-2"}]},"3211_2":{"comp":[["bar_chart","table",["nested"]],["bar_chart","matrix",["nested"]],["glyph_based","table",["nested"]],["matrix","stripe_graph",["stacked"]],["stripe_graph","matrix",["stacked"]]],"visType":["bar_chart","table","matrix","glyph_based","stripe_graph"],"compType":["nested","stacked"],"compressed_tree":[{"composite_pattern":"nested","visualization_type":[["bar_chart"],["table"]]},{"composite_pattern":"nested","visualization_type":[["glyph_based"],["table"]]},{"composite_pattern":"stacked","visualization_type":[["matrix","stripe_graph"]]},{"composite_pattern":"nested","visualization_type":[["bar_chart"],["matrix"]]}],"coOccurrence":[["bar_chart","table",["coOccurrence"]],["bar_chart","glyph_based",["coOccurrence"]],["bar_chart","matrix",["coOccurrence"]],["bar_chart","stripe_graph",["coOccurrence"]],["table","glyph_based",["coOccurrence"]],["table","matrix",["coOccurrence"]],["table","stripe_graph",["coOccurrence"]],["glyph_based","matrix",["coOccurrence"]],["glyph_based","stripe_graph",["coOccurrence"]],["matrix","stripe_graph",["coOccurrence"]]],"year":2019,"conference":["VAST"],"authors":["Yongsu Ahn","Yu-Ru Lin"],"title":"FairSight: Visual Analytics for Fairness in Decision Making","doi":"10.1109/TVCG.2019.2934262","abstract":"Data-driven decision making related to individuals has become increasingly pervasive, but the issue concerning the potential discrimination has been raised by recent studies. In response, researchers have made efforts to propose and implement fairness measures and algorithms, but those efforts have not been translated to the real-world practice of data-driven decision making. As such, there is still an urgent need to create a viable tool to facilitate fair decision making. We propose FairSight, a visual analytic system to address this need; it is designed to achieve different notions of fairness in ranking decisions through identifying the required actions - understanding, measuring, diagnosing and mitigating biases - that together lead to fairer decision making. Through a case study and user study, we demonstrate that the proposed visual analytic and diagnostic modules in the system are effective in understanding the fairness-aware decision pipeline and obtaining more fair outcomes.","keywords":"Fairness in Machine Learning, Visual Analytic","caption":"Fig. 2. The work\ufb02ow of fair decision making in FairSight. (a) It starts with setting up inputs including the sensitive attribute and protected group. (b) After running a model, the ranking outcome and measures are represented in Ranking View. (c) Global Inspection View visualizes the two spaces and the mapping process of Individual and Group fairness provided in the separate tap. (d) When an individual is hovered, Local Inspection View provides the instance- and group-level exploration. (e) In Feature Inspection View, users can investigate the feature distortion and feature perturbation to identify features as the possible source of bias. (f) All generated ranking outcomes are listed and plotted in the Ranking List View. ","img_size":{"width":1978,"height":1130},"subfigures":[{"x":804.5092782545162,"y":5.2396170111151985,"width":1167.3046713674573,"height":1117.115554332364,"type":"interface","id":"interface-0"}],"visualizations":[{"x":946.1859784674126,"y":338.61159314806395,"width":91.88168770960861,"height":185.96312659906513,"type":"bar_chart","id":"bar_chart-1"},{"x":1166.3993881953788,"y":866.6201175929586,"width":238.04673590141408,"height":249.81197569846464,"type":"bar_chart","id":"bar_chart-12"},{"x":1533.9403912269897,"y":882.4754195699916,"width":373.47206434315666,"height":231.83201946592501,"type":"bar_chart","id":"bar_chart-5"},{"x":1040.9620777391551,"y":169.7321289199296,"width":570.2187371914799,"height":89.05374789398155,"type":"glyph_based","id":"glyph_based-6"},{"x":1639.0216516482128,"y":86.76979640765323,"width":319.6506596115162,"height":183.577567073586,"type":"glyph_based","id":"glyph_based-8"},{"x":1276.8713119909266,"y":445.9379929556998,"width":356.3735083029907,"height":313.28279918854355,"type":"matrix","id":"matrix-2"},{"x":1045.9469810138487,"y":835.4443999899247,"width":899.519550634764,"height":280.84725044621933,"type":"matrix","id":"matrix-4"},{"x":1297.9708006917615,"y":470.7832116424616,"width":234.12787945258754,"height":39.36865293351866,"type":"stripe_graph","id":"stripe_graph-3"},{"x":807.2931787566556,"y":316.3103520324793,"width":234.58856281138418,"height":208.01797330024957,"type":"table","id":"table-0"},{"x":1633.8655860350698,"y":85.45826016645833,"width":321.20768833559936,"height":188.70593239264147,"type":"table","id":"table-7"}],"relations":[{"vislist":[{"vislist":["bar_chart-1"],"relation":null,"id":"group-1"},{"vislist":["table-0"],"relation":null,"id":"group-0"}],"relation":"nested","id":"relation-0"},{"vislist":[{"vislist":["glyph_based-8"],"relation":null,"id":"group-3"},{"vislist":["table-7"],"relation":null,"id":"group-2"}],"relation":"nested","id":"relation-1"},{"vislist":[{"vislist":["matrix-2","stripe_graph-3"],"relation":null,"id":"group-4"}],"relation":"stacked","id":"relation-2"},{"vislist":[{"vislist":["bar_chart-12","bar_chart-5"],"relation":null,"id":"group-6"},{"vislist":["matrix-4"],"relation":null,"id":"group-5"}],"relation":"nested","id":"relation-3"}]},"3212_0":{"comp":[["others","graph",["nested"]]],"visType":["others","graph"],"compType":["nested"],"compressed_tree":[{"composite_pattern":"nested","visualization_type":[["others"],["graph"]]},{"composite_pattern":"nested","visualization_type":[["others"],["graph"]]}],"coOccurrence":[["others","graph",["coOccurrence"]]],"year":2019,"conference":["VAST"],"authors":["Fred Hohman","Haekyu Park","Caleb Robinson","Duen Horng Polo Chau"],"title":"Summit: Scaling Deep Learning Interpretability by Visualizing Activation and Attribution Summarizations","doi":"10.1109/TVCG.2019.2934659","abstract":"Deep learning is increasingly used in decision-making tasks. However, understanding how neural networks produce final predictions remains a fundamental challenge. Existing work on interpreting neural network predictions for images often focuses on explaining predictions for single images or neurons. As predictions are often computed from millions of weights that are optimized over millions of images, such explanations can easily miss a bigger picture. We present Summit, an interactive system that scalably and systematically summarizes and visualizes what features a deep learning model has learned and how those features interact to make predictions. Summit introduces two new scalable summarization techniques: (1) activation aggregation discovers important neurons, and (2) neuron-influence aggregation identifies relationships among such neurons. Summit combines these techniques to create the novel attribution graph that reveals and summarizes crucial neuron associations and substructures that contribute to a model\'s outcomes. Summit scales to large data, such as the ImageNet dataset with 1.2M images, and leverages neural network feature visualization and dataset examples to help users distill large, complex neural network models into compact, interactive visualizations. We present neural network exploration scenarios where Summit helps us discover multiple surprising insights into a prevalent, large-scale image classifier\'s learned representations and informs future neural network architecture design. The Summit visualization runs in modern web browsers and is open-sourced.","keywords":"Deep learning interpretability, visual analytics, scalable summarization, attribution graph","caption":"Fig. 1. With Summit, users can scalably summarize and interactively interpret deep neural networks by visualizing what features a network detects and how they are related. In this example, INCEPTIONV1 accurately classi\ufb01es images of tench (yellow-brown \ufb01sh). However, SUMMIT reveals surprising associations in the network (e.g., using parts of people) that contribute to its \ufb01nal outcome: the \u201ctench\u201d prediction is dependent on an intermediate \u201chands holding \ufb01sh\u201d feature (right callout), which is in\ufb02uenced by lower-level features like \u201cscales,\u201d \u201cperson,\u201d and \u201c\ufb01sh\u201d. (A) Embedding View summarizes all classes\u2019 aggregated activations using dimensionality reduction. (B) Class Sidebar enables users to search, sort, and compare all classes within a model. (C) Attribution Graph View visualizes highly activated neurons as vertices (\u201cscales,\u201d \u201c\ufb01sh\u201d) and their most in\ufb02uential connections as edges (dashed purple edges). ","img_size":{"width":1825,"height":906},"subfigures":[{"x":3.401921677075827,"y":4.196870159775605,"width":1812.4093585008284,"height":894.7136201883189,"type":"interface","id":"interface-0"}],"visualizations":[{"x":448.14805194758964,"y":225.55765576318066,"width":602.4245219571893,"height":632.7434762924764,"type":"others","id":"others-2"},{"x":1154.2438835894382,"y":206.0175302722128,"width":633.8668067611641,"height":652.1899649827207,"type":"others","id":"others-4"},{"x":443.632981282004,"y":156.8062193001142,"width":625.0043812155624,"height":730.9788246352291,"type":"graph","id":"graph-1"},{"x":1133.217834151467,"y":165.91561495241902,"width":673.6109376945188,"height":709.2952517497337,"type":"graph","id":"graph-3"},{"x":22.65908070574723,"y":173.8317978033262,"width":382.20724935256004,"height":345.82980076564485,"type":"scatterplot","id":"scatterplot-0"}],"relations":[{"vislist":[{"vislist":["others-2"],"relation":null,"id":"group-5"},{"vislist":["graph-1"],"relation":null,"id":"group-6"}],"relation":"nested","id":"relation-2"},{"vislist":[{"vislist":["others-4"],"relation":null,"id":"group-7"},{"vislist":["graph-3"],"relation":null,"id":"group-8"}],"relation":"nested","id":"relation-3"}]},"3219_0":{"comp":[["bar_chart","table",["nested"]]],"visType":["bar_chart","table"],"compType":["nested"],"compressed_tree":[{"composite_pattern":"nested","visualization_type":[["bar_chart"],["table"]]},{"composite_pattern":"coordinated","visualization_type":[["hierarchical_edge_bundling"],["map"]]},{"composite_pattern":"nested","visualization_type":[["bar_chart"],["table"]]}],"coOccurrence":[["bar_chart","table",["coOccurrence"]],["bar_chart","map",["coOccurrence"]],["table","map",["coOccurrence"]]],"year":2019,"conference":["VAST"],"authors":["Zhaosong Huang","Ye Zhao","Wei Chen","Shengjie Gao","Kejie Yu","Weixia Xu","Mingjie Tang","Minfeng Zhu","Mingliang Xu"],"title":"A Natural-language-based Visual Query Approach of Uncertain Human Trajectories","doi":"10.1109/TVCG.2019.2934671","abstract":"Visual querying is essential for interactively exploring massive trajectory data. However, the data uncertainty imposes profound challenges to fulfill advanced analytics requirements. On the one hand, many underlying data does not contain accurate geographic coordinates, e.g., positions of a mobile phone only refer to the regions (i.e., mobile cell stations) in which it resides, instead of accurate GPS coordinates. On the other hand, domain experts and general users prefer a natural way, such as using a natural language sentence, to access and analyze massive movement data. In this paper, we propose a visual analytics approach that can extract spatial-temporal constraints from a textual sentence and support an effective query method over uncertain mobile trajectory data. It is built up on encoding massive, spatially uncertain trajectories by the semantic information of the POIs and regions covered by them, and then storing the trajectory documents in text database with an effective indexing scheme. The visual interface facilitates query condition specification, situation-aware visualization, and semantic exploration of large trajectory data. Usage scenarios on real-world human mobility datasets demonstrate the effectiveness of our approach.","keywords":"Natural-language-based Visual Query, Spatial Uncertaity, Trajectory Exploration","caption":"Fig. 1. (a) The query condition specification view. (b) The relevance tree with the spatial keyword \u2018tourist attractions\u2019. (c) The drop-down menu for changing the type of the input keyword. (d) The semantics view shows that the major region functional topic is \u2018residential related\u2019. (e) The map view shows that the queried trajectories are mainly distributed in the northwest (named \u2018Jiangxin island\u2019), the middle, and the east (named \u2018Wuhua building\u2019) of the city. (f) Most trajectories land the island from its east through ferry. (g) The region functional topics. (h) The rendering parameter widget. (i) The temporal graph view. (j) The detail result view of the queried trajectories. (k) Detail study of urban areas.","img_size":{"width":1840,"height":1029},"subfigures":[{"x":5.185919819497764,"y":5.8563561113048985,"width":1828.533611832845,"height":1015.097055225955,"type":"interface","id":"interface-0"}],"visualizations":[{"x":1641.7270822637295,"y":545.0452288475856,"width":155.1519269050701,"height":455.7271382314126,"type":"bar_chart","id":"bar_chart-3"},{"x":187.85553905210463,"y":914.6507918192078,"width":1273.4800434424149,"height":108.77476316345333,"type":"bar_chart","id":"bar_chart-5"},{"x":301.70556539251186,"y":167.31787466953114,"width":162.7071935292229,"height":247.38687040010788,"type":"bar_chart","id":"bar_chart-7"},{"x":42.11304063955062,"y":466.65996712603703,"width":324.7073303205999,"height":277.26462647888866,"type":"graph","id":"graph-4"},{"x":390.8341108200233,"y":465.2664651100439,"width":1096.7262478048408,"height":402.2720079259453,"type":"hierarchical_edge_bundling","id":"hierarchical_edge_bundling-1"},{"x":390.8463451221751,"y":463.0102997681377,"width":1100.192185513709,"height":410.27634939304704,"type":"map","id":"map-0"},{"x":1492.256713403761,"y":467.9244769602001,"width":343.5631313745766,"height":533.1444047738544,"type":"table","id":"table-2"},{"x":60.66166649803953,"y":135.08896175793438,"width":648.2853976313363,"height":286.236617145857,"type":"table","id":"table-6"}],"relations":[{"vislist":[{"vislist":["bar_chart-7"],"relation":null,"id":"group-1"},{"vislist":["table-6"],"relation":null,"id":"group-0"}],"relation":"nested","id":"relation-0"},{"vislist":[{"vislist":["hierarchical_edge_bundling-1"],"relation":null,"id":"group-3"},{"vislist":["map-0"],"relation":null,"id":"group-2"}],"relation":"coordinated","id":"relation-1"},{"vislist":[{"vislist":["bar_chart-3"],"relation":null,"id":"group-5"},{"vislist":["table-2"],"relation":null,"id":"group-4"}],"relation":"nested","id":"relation-2"}]},"3223_10":{"comp":[["bar_chart","table",["nested"]]],"visType":["bar_chart","table"],"compType":["nested"],"compressed_tree":[{"composite_pattern":"nested","visualization_type":[["bar_chart"],["table"]]}],"coOccurrence":[["bar_chart","table",["coOccurrence"]]],"year":2019,"conference":["VAST"],"authors":["Melanie Tory","Vidya Setlur"],"title":"Do What I Mean, Not What I Say! Design Considerations for Supporting Intent and Context in Analytical Conversation","doi":"10.1109/VAST47406.2019.8986918","abstract":"Natural language can be a useful modality for creating and interacting with visualizations but users often have unrealistic expectations about the intelligence of natural language systems. The gulf between user expectations and system capabilities may lead to a disappointing user experience. So - if we want to engineer a natural language system, what are the requirements around system intelligence? This work takes a retrospective look at how we answered this question in the design of Ask Data, a natural language interaction feature for Tableau. We examine two factors contributing to perceived system intelligence: the system\'s ability to understand the analytic intent behind an input utterance and the ability to interpret an utterance contextually (i.e. taking into account the current visualization state and recent actions). Our aim was to understand the ways in which a system would need to support these two aspects of intelligence to enable a positive user experience. We first describe a pre-design Wizard of Oz study that offered insight into this question and narrowed the space of designs under consideration. We then reflect on the impact of this study on system development, examining how design implications from the study played out in practice. Our work contributes insights for the design of natural language interaction in visual analytics as well as a reflection on the value of pre-design empirical studies in the development of visual analytic systems.","keywords":":Human-centered computing\u2014Visualization\u2014Empirical studies in visualization; Human-centered computing\u2014Interaction paradigms\u2014Natural language interfaces","caption":"Figure  10:  Response  to,  \u201cWhat  is  the  age  distribution  of  those  who survived and didn\u2019t survive?\u201d [P11.I] The distribution target and implied comparison action suggest two histograms. The target attribute survived? is redundantly encoded using position and color.","img_size":{"width":997,"height":498},"subfigures":[{"x":6.727945428639692,"y":8.092199883505407,"width":981.4240191325489,"height":482.3455981973299,"type":"single","id":"single-0"}],"visualizations":[{"x":192.6765498785471,"y":90.08079110164324,"width":540.4090984950416,"height":382.20723047386764,"type":"bar_chart","id":"bar_chart-1"},{"x":8.052196171058695,"y":49.95158740415145,"width":728.0959749066119,"height":428.38803115741666,"type":"table","id":"table-0"}],"relations":[{"vislist":[{"vislist":["bar_chart-1"],"relation":null,"id":"group-1"},{"vislist":["table-0"],"relation":null,"id":"group-0"}],"relation":"nested","id":"relation-0"}]},"3242_10":{"comp":[["unit_visualization","bar_chart",["nested"]]],"visType":["unit_visualization","bar_chart"],"compType":["nested"],"compressed_tree":[{"composite_pattern":"nested","visualization_type":[["unit_visualization"],["bar_chart"]]}],"coOccurrence":[["unit_visualization","bar_chart",["coOccurrence"]]],"year":2020,"conference":["InfoVis"],"authors":["Xi Chen","Wei Zeng","Yanna Lin","Hayder Mahdi AI-maneea","Jonathan Roberts","Remco Chang"],"title":"Composition and Configuration Patterns in Multiple-View Visualizations","doi":"10.1109/TVCG.2020.3030338","abstract":"Multiple-view visualization (MV) is a layout design technique often employed to help users see a large number of data attributes and values in a single cohesive representation. Because of its generalizability, the MV design has been widely adopted by the visualization community to help users examine and interact with large, complex, and high-dimensional data. However, although ubiquitous, there has been little work to categorize and analyze MVs in order to better understand its design space. As a result, there has been little to no guideline in how to use the MV design effectively. In this paper, we present an in-depth study of how MVs are designed in practice. We focus on two fundamental measures of multiple-view patterns: composition, which quantifies what view types and how many are there; and configuration, which characterizes spatial arrangement of view layouts in the display space. We build a new dataset containing 360 images of MVs collected from IEEE VIS, EuroVis, and PacificVis publications 2011 to 2019, and make fine-grained annotations of view types and layouts for these visualization images. From this data we conduct composition and configuration analyses using quantitative metrics of term frequency and layout topology. We identify common practices around MVs, including relationship of view types, popular view layouts, and correlation between view types and layouts. We combine the findings into a MV recommendation system, providing interactive tools to explore the design space, and support example-based design.","keywords":"Multiple views, design pattern, quantitative analysis, example-based design","caption":"Fig. 9. Exploration mode mainly consists of Query Panel (a) that enables multi-faceted query, and Exploration View (b) that depicts the query results using unit-based visualization. ","img_size":{"width":997,"height":462},"subfigures":[{"x":6.977884399485761,"y":10.75623590430086,"width":983.0442312010289,"height":444.8317864242384,"type":"interface","id":"interface-0"}],"visualizations":[{"x":216.318780653284,"y":12.98345145904304,"width":771.9045425102681,"height":443.06189653918483,"type":"bar_chart","id":"bar_chart-1"},{"x":218.95767185873498,"y":15.582695760792289,"width":771.0238385700625,"height":438.7420078678454,"type":"unit_visualization","id":"unit_visualization-0"}],"relations":[{"vislist":[{"vislist":["unit_visualization-0"],"relation":null,"id":"group-0"},{"vislist":["bar_chart-1"],"relation":null,"id":"group-1"}],"relation":"nested","id":"relation-0"}]},"3261_0":{"comp":[["proportional_area_chart","scatterplot",["nested"]]],"visType":["proportional_area_chart","scatterplot"],"compType":["nested"],"compressed_tree":[{"composite_pattern":"nested","visualization_type":[["proportional_area_chart"],["scatterplot"]]}],"coOccurrence":[["proportional_area_chart","scatterplot",["coOccurrence"]]],"year":2020,"conference":["InfoVis"],"authors":["Wenbo Tao","Xinli Hou","Adam Sah","Leilani Battle","Remco Chang","Michael Stonebraker"],"title":"Kyrix-S: Authoring Scalable Scatterplot Visualizations of Big Data","doi":"10.1109/TVCG.2020.3030372","abstract":"Static scatterplots often suffer from the overdraw problem on big datasets where object overlap causes undesirable visual clutter. The use of zooming in scatterplots can help alleviate this problem. With multiple zoom levels, more screen real estate is available, allowing objects to be placed in a less crowded way. We call this type of visualization scalable scatterplot visualizations, or SSV for short. Despite the potential of SSVs, existing systems and toolkits fall short in supporting the authoring of SSVs due to three limitations. First, many systems have limited scalability, assuming that data fits in the memory of one computer. Second, too much developer work, e.g., using custom code to generate mark layouts or render objects, is required. Third, many systems focus on only a small subset of the SSV design space (e.g. supporting a specific type of visual marks). To address these limitations, we have developed Kyrix-S, a system for easy authoring of SSVs at scale. Kyrix-S derives a declarative grammar that enables specification of a variety of SSVs in a few tens of lines of code, based on an existing survey of scatterplot tasks and designs. The declarative grammar is supported by a distributed layout algorithm which automatically places visual marks onto zoom levels. We store data in a multi-node database and use multi-node spatial indexes to achieve interactive browsing of large SSVs. Extensive experiments show that 1) Kyrix-S enables interactive browsing of SSVs of billions of objects, with response times under 500ms and 2) Kyrix-S achieves 4X-9X reduction in specification compared to a state-of-the-art authoring system.","keywords":"pan/zoom visualization, declarative grammar, scalability, performance optimization","caption":"Figure 1. A scalable scatterplot visualization created by Kyrix-S and its Kyrix-S speci\ufb01cations. One billion comments made by users on Reddit.com from Jan 2013 to Feb 2015 are visualized on 15 zoom levels. On every level, X and Y axes are respectively the posting time and length of the comments. Each circle represents a cluster of comments. The number inside each circle is the size of the cluster and also encodes the radius of the circle. Using pan or zoom, the user can get either an overview (left) or inspect an area of interest (middle). One can hover over a circle to see three highest-scored comments in the cluster, as well as a bounding box showing the boundary of the cluster. ","img_size":{"width":1720,"height":438},"subfigures":[{"x":11.25710057486621,"y":23.434157482481783,"width":580.6261458540986,"height":386.1438600765186,"type":"single","id":"single-0"}],"visualizations":[{"x":13.992824050764193,"y":31.782645849369548,"width":576.9117234825227,"height":371.3980512801703,"type":"proportional_area_chart","id":"proportional_area_chart-1"},{"x":18.511656809684897,"y":33.25891323388184,"width":572.4254972643383,"height":368.44551651114557,"type":"scatterplot","id":"scatterplot-0"}],"relations":[{"vislist":[{"vislist":["proportional_area_chart-1"],"relation":null,"id":"group-0"},{"vislist":["scatterplot-0"],"relation":null,"id":"group-1"}],"relation":"nested","id":"relation-0"}]},"3267_7":{"comp":[["glyph_based","scatterplot",["nested"]]],"visType":["glyph_based","scatterplot"],"compType":["nested"],"compressed_tree":[{"composite_pattern":"nested","visualization_type":[["glyph_based"],["scatterplot"]]},{"composite_pattern":"nested","visualization_type":[["glyph_based"],["scatterplot"]]}],"coOccurrence":[["glyph_based","scatterplot",["coOccurrence"]]],"year":2020,"conference":["InfoVis"],"authors":["Rongzheng Bian","Yumeng Xue","Liang Zhou","Jian Zhang","Baoquan Chen","Daniel Weiskopf","Yunhai Wang"],"title":"Implicit Multidimensional Projection of Local Subspaces","doi":"10.1109/TVCG.2020.3030368","abstract":"We propose a visualization method to understand the effect of multidimensional projection on local subspaces, using implicit function differentiation. Here, we understand the local subspace as the multidimensional local neighborhood of data points. Existing methods focus on the projection of multidimensional data points, and the neighborhood information is ignored. Our method is able to analyze the shape and directional information of the local subspace to gain more insights into the global structure of the data through the perception of local structures. Local subspaces are fitted by multidimensional ellipses that are spanned by basis vectors. An accurate and efficient vector transformation method is proposed based on analytical differentiation of multidimensional projections formulated as implicit functions. The results are visualized as glyphs and analyzed using a full set of specifically-designed interactions supported in our efficient web-based visualization tool. The usefulness of our method is demonstrated using various multi- and high-dimensional benchmark datasets. Our implicit differentiation vector transformation is evaluated through numerical comparisons; the overall method is evaluated through exploration examples and use cases.","keywords":"High-dimensional data visualization, dimensionality reduction, local linear subspaces, user interaction","caption":"Fig. 7. Main modules in our web-based interactive visualization system: (a) control panel, (b) local subspace projection view with (c) zoomable glyphs of interest, and (d) point-based dimensionality reduction view with option to show image data for reference. This example shows the COIL dataset with PCA. ","img_size":{"width":1598,"height":709},"subfigures":[{"x":14.664678925083004,"y":9.365809999107798,"width":1575.6346726067106,"height":687.9468017024546,"type":"interface","id":"interface-0"}],"visualizations":[{"x":895.924641294855,"y":17.026531539559446,"width":689.929089606814,"height":676.3560874038826,"type":"glyph_based","id":"glyph_based-2"},{"x":183.6510601215337,"y":17.03793190799265,"width":696.4841587641358,"height":677.7424371500183,"type":"glyph_based","id":"glyph_based-3"},{"x":182.26953983786032,"y":10.069531700168932,"width":704.8853388670271,"height":688.860936599662,"type":"scatterplot","id":"scatterplot-0"},{"x":892.5566774521208,"y":11.475529814602663,"width":692.4364126406246,"height":686.0489403707948,"type":"scatterplot","id":"scatterplot-1"}],"relations":[{"vislist":[{"vislist":["glyph_based-3"],"relation":null,"id":"group-0"},{"vislist":["scatterplot-0"],"relation":null,"id":"group-1"}],"relation":"nested","id":"relation-0"},{"vislist":[{"vislist":["glyph_based-2"],"relation":null,"id":"group-2"},{"vislist":["scatterplot-1"],"relation":null,"id":"group-3"}],"relation":"nested","id":"relation-1"}]},"3274_4":{"comp":[["proportional_area_chart","graph",["nested"]]],"visType":["proportional_area_chart","graph"],"compType":["nested"],"compressed_tree":[{"composite_pattern":"nested","visualization_type":[["proportional_area_chart"],["graph"]]}],"coOccurrence":[],"year":2020,"conference":["InfoVis"],"authors":["Eytan Adar","Elsie Lee"],"title":"Communicative Visualizations as a Learning Problem","doi":"10.1109/TVCG.2020.3030375","abstract":"Significant research has provided robust task and evaluation languages for the analysis of exploratory visualizations. Unfortunately, these taxonomies fail when applied to communicative visualizations. Instead, designers often resort to evaluating communicative visualizations from the cognitive efficiency perspective: \u201ccan the recipient accurately decode my message/insight?\u201d However, designers are unlikely to be satisfied if the message went `in one ear and out the other.\' The consequence of this inconsistency is that it is difficult to design or select between competing options in a principled way. The problem we address is the fundamental mismatch between how designers want to describe their intent, and the language they have. We argue that visualization designers can address this limitation through a learning lens: that the recipient is a student and the designer a teacher. By using learning objectives, designers can better define, assess, and compare communicative visualizations. We illustrate how the learning-based approach provides a framework for understanding a wide array of communicative goals. To understand how the framework can be applied (and its limitations), we surveyed and interviewed members of the Data Visualization Society using their own visualizations as a probe. Through this study we identified the broad range of objectives in communicative visualizations and the prevalence of certain objective types.","keywords":"Learning objectives, communicative visualization, visualization design","caption":"Fig. 4. Example of communicative visualizations: (1) The Babesia life cycle in humans [98], (2) Prison expenditures by census block from [21], (3) The \ufb01nal image from the \u2018scrollytelling\u2019 vis: \u201cThe Clubs That Connect the World Cup\u201d [3], (4) Interactive climate change calculator [20], (5) Annotated Tensorboard example [42], and (6) An interactive lesson on \u201chow to use t-SNE effectively\u201d [99] ","img_size":{"width":1725,"height":981},"subfigures":[{"x":1004.8928224765958,"y":5.939230434991859,"width":705.3220018559365,"height":474.67909529940323,"type":"single","id":"single-0"},{"x":1086.1132848256564,"y":523.4880322293237,"width":599.1524183837759,"height":413.7269027266074,"type":"single","id":"single-1"},{"x":41.85122397168198,"y":527.00688862475,"width":499.793201472902,"height":445.5478101826057,"type":"single","id":"single-2"}],"visualizations":[{"x":74.3246558037407,"y":536.2264849751267,"width":451.9202555979136,"height":230.66374311863262,"type":"area_chart","id":"area_chart-3"},{"x":1235.4871551738504,"y":5.762182315895194,"width":477.35731071706726,"height":469.5869627282859,"type":"graph","id":"graph-0"},{"x":69.53713564174384,"y":766.6727115980315,"width":446.279728495729,"height":195.20845807701423,"type":"others","id":"others-4"},{"x":1235.4984646756486,"y":4.288144241008578,"width":478.8562484560861,"height":475.57387579380344,"type":"proportional_area_chart","id":"proportional_area_chart-1"},{"x":1089.0912637933102,"y":650.1281297749913,"width":315.2036274354058,"height":288.51112359886105,"type":"scatterplot","id":"scatterplot-2"}],"relations":[{"vislist":[{"vislist":["proportional_area_chart-1"],"relation":null,"id":"group-0"},{"vislist":["graph-0"],"relation":null,"id":"group-1"}],"relation":"nested","id":"relation-0"}]},"3297_8":{"comp":[["proportional_area_chart","sankey_diagram",["nested"]]],"visType":["proportional_area_chart","sankey_diagram"],"compType":["nested"],"compressed_tree":[{"composite_pattern":"nested","visualization_type":[["proportional_area_chart"],["sankey_diagram"]]}],"coOccurrence":[["proportional_area_chart","sankey_diagram",["coOccurrence"]]],"year":2020,"conference":["VAST"],"authors":["Zengsheng Zhong","Shuirun Wei","Yeting Xu","Ying Zhao","Fangfang Zhou","Feng Luo","Ronghua Shi"],"title":"SilkViser: A Visual Explorer of Blockchain-based Cryptocurrency Transaction Data","doi":"10.1109/VAST50239.2020.00014","abstract":"Many blockchain-based cryptocurrencies provide users with online blockchain explorers for viewing online transaction data. However, traditional blockchain explorers mostly present transaction information in textual and tabular forms. Such forms make understanding cryptocurrency transaction mechanisms difficult for novice users (NUsers). They are also insufficiently informative for experienced users (EUsers) to recognize advanced transaction information. This study introduces a new online cryptocurrency transaction data viewing tool called SilkViser. Guided by detailed scenario and requirement analyses, we create a series of appreciating visualization designs, such as paper ledger-inspired block and blockchain visualizations and ancient copper coin-inspired transaction visualizations, to help users understand cryptocurrency transaction mechanisms and recognize advanced transaction information. We also provide a set of lightweight interactions to facilitate easy and free data exploration. Moreover, a controlled user study is conducted to quantitatively evaluate the usability and effectiveness of SilkViser. Results indicate that SilkViser can satisfy the requirements of NUsers and EUsers. Our visualization designs can compensate for the inexperience of NUsers in data viewing and attract potential users to participate in cryptocurrency transactions.","keywords":" visualization, visual analytics, blockchain, cryptocur-rency, interactive interface","caption":"Figure 6: Visualization design of the transaction page.","img_size":{"width":975,"height":849},"subfigures":[{"x":6.417804018443371,"y":9.793163239922928,"width":959.8440669609054,"height":832.8926325615517,"type":"interface","id":"interface-0"}],"visualizations":[{"x":76.22717744779473,"y":320.2878352611569,"width":783.1001200668679,"height":203.78571742248863,"type":"proportional_area_chart","id":"proportional_area_chart-0"},{"x":78.5280904147731,"y":318.0344442088651,"width":779.6584566340154,"height":209.45215254087162,"type":"sankey_diagram","id":"sankey_diagram-1"}],"relations":[{"vislist":[{"vislist":["proportional_area_chart-0"],"relation":null,"id":"group-0"},{"vislist":["sankey_diagram-1"],"relation":null,"id":"group-1"}],"relation":"nested","id":"relation-0"}]},"3302_3":{"comp":[["proportional_area_chart","scatterplot",["nested"]]],"visType":["proportional_area_chart","scatterplot"],"compType":["nested"],"compressed_tree":[{"composite_pattern":"nested","visualization_type":[["proportional_area_chart"],["scatterplot"]]}],"coOccurrence":[["proportional_area_chart","scatterplot",["coOccurrence"]]],"year":2020,"conference":["VAST"],"authors":["Dylan Cashman","Shenyu Xu","Subhajit Das","Florian Heimerl","Cong Liu","Shah Rukh Humayoun","Michael Gleicher"],"title":"CAVA: A Visual Analytics System for Exploratory Columnar Data Augmentation Using Knowledge Graphs","doi":"10.1109/TVCG.2020.3030443","abstract":"Most visual analytics systems assume that all foraging for data happens before the analytics process; once analysis begins, the set of data attributes considered is fixed. Such separation of data construction from analysis precludes iteration that can enable foraging informed by the needs that arise in-situ during the analysis. The separation of the foraging loop from the data analysis tasks can limit the pace and scope of analysis. In this paper, we present CAVA, a system that integrates data curation and data augmentation with the traditional data exploration and analysis tasks, enabling information foraging in-situ during analysis. Identifying attributes to add to the dataset is difficult because it requires human knowledge to determine which available attributes will be helpful for the ensuing analytical tasks. CAVA crawls knowledge graphs to provide users with a a broad set of attributes drawn from external data to choose from. Users can then specify complex operations on knowledge graphs to construct additional attributes. CAVA shows how visual analytics can help users forage for attributes by letting users visually explore the set of available data, and by serving as an interface for query construction. It also provides visualizations of the knowledge graph itself to help users understand complex joins such as multi-hop aggregations. We assess the ability of our system to enable users to perform complex data combinations without programming in a user study over two datasets. We then demonstrate the generalizability of CAVA through two additional usage scenarios. The results of the evaluation confirm that CAVA is effective in helping the user perform data foraging that leads to improved analysis outcomes, and offer evidence in support of integrating data augmentation as a part of the visual analytics pipeline.","keywords":"Visual Analytics, Information Foraging, Data Augmentation","caption":"Fig. 4. Visualizing the number of records in the ACLED dataset in April 2018 by per capita GDP, a \ufb01eld extracted from Wikidata. Magnitude of marks encodes number of fatalities, while color encodes event type. Visualization generated with Tableau. ","img_size":{"width":920,"height":608},"subfigures":[{"x":12.64867214340082,"y":10.286726210983003,"width":891.3796907770669,"height":588.2570175808487,"type":"interface","id":"interface-0"}],"visualizations":[{"x":14.277942129520738,"y":13.538251621604198,"width":883.967444634664,"height":576.7711467427166,"type":"proportional_area_chart","id":"proportional_area_chart-1"},{"x":13.3778716306851,"y":13.509627361890974,"width":886.5983268663665,"height":579.3198052705873,"type":"scatterplot","id":"scatterplot-0"}],"relations":[{"vislist":[{"vislist":["proportional_area_chart-1"],"relation":null,"id":"group-0"},{"vislist":["scatterplot-0"],"relation":null,"id":"group-1"}],"relation":"nested","id":"relation-0"}]},"3306_0":{"comp":[["polar_plot","graph",["nested"]],["area_chart","table",["nested"]],["bar_chart","table",["nested"]],["bar_chart","matrix",["stacked"]],["comb","map",["coordinated"]],["matrix","bar_chart",["stacked"]]],"visType":["polar_plot","graph","area_chart","table","bar_chart","matrix","comb","map"],"compType":["nested","stacked","coordinated"],"compressed_tree":[{"composite_pattern":"coordinated","visualization_type":[[{"composite_pattern":"nested","visualization_type":[["polar_plot"],["graph"]]}],["map"]]},{"composite_pattern":"stacked","visualization_type":[["matrix","bar_chart"]]},{"composite_pattern":"nested","visualization_type":[["area_chart","bar_chart"],["table"]]}],"coOccurrence":[["polar_plot","graph",["coOccurrence"]],["polar_plot","map",["coOccurrence"]],["polar_plot","matrix",["coOccurrence"]],["polar_plot","bar_chart",["coOccurrence"]],["polar_plot","area_chart",["coOccurrence"]],["polar_plot","table",["coOccurrence"]],["graph","map",["coOccurrence"]],["graph","matrix",["coOccurrence"]],["graph","bar_chart",["coOccurrence"]],["graph","area_chart",["coOccurrence"]],["graph","table",["coOccurrence"]],["map","matrix",["coOccurrence"]],["map","bar_chart",["coOccurrence"]],["map","area_chart",["coOccurrence"]],["map","table",["coOccurrence"]],["matrix","bar_chart",["coOccurrence"]],["matrix","area_chart",["coOccurrence"]],["matrix","table",["coOccurrence"]],["bar_chart","area_chart",["coOccurrence"]],["bar_chart","table",["coOccurrence"]],["area_chart","table",["coOccurrence"]]],"year":2020,"conference":["VAST"],"authors":["Di Weng","Chengbo Zheng","Zikun Deng","Mingze Ma","Jie Bao","Yu Zheng","Mingliang Xu","Yingcai Wu"],"title":"Towards Better Bus Networks: A Visual Analytics Approach","doi":"10.1109/TVCG.2020.3030458","abstract":"Bus routes are typically updated every 3-5 years to meet constantly changing travel demands. However, identifying deficient bus routes and finding their optimal replacements remain challenging due to the difficulties in analyzing a complex bus network and the large solution space comprising alternative routes. Most of the automated approaches cannot produce satisfactory results in real-world settings without laborious inspection and evaluation of the candidates. The limitations observed in these approaches motivate us to collaborate with domain experts and propose a visual analytics solution for the performance analysis and incremental planning of bus routes based on an existing bus network. Developing such a solution involves three major challenges, namely, a) the in-depth analysis of complex bus route networks, b) the interactive generation of improved route candidates, and c) the effective evaluation of alternative bus routes. For challenge a, we employ an overview-to-detail approach by dividing the analysis of a complex bus network into three levels to facilitate the efficient identification of deficient routes. For challenge b, we improve a route generation model and interpret the performance of the generation with tailored visualizations. For challenge c, we incorporate a conflict resolution strategy in the progressive decision-making process to assist users in evaluating the alternative routes and finding the most optimal one. The proposed system is evaluated with two usage scenarios based on real-world data and received positive feedback from the experts.","keywords":"Bus route planning, spatial decision-making, urban data visual analytics.","caption":"Fig. 1. The interface of BNVA. A, C, G, H) The pattern indicated by the transfers from Route #683 to #696 suggests that Route #683 can be extended farther into the west. B) The network-level analysis, comprising the map, route, and aggregation layers, facilitates the exploration of network performance. D) The zone glyph summarizes the statistics and passenger flows of a transportation zone. E) The toolbox provides fine-grained controls for the model. F) The route ranking view depicts the performance criteria of the routes. ","img_size":{"width":1959,"height":1112},"subfigures":[{"x":10.300611139641246,"y":12.810166108034982,"width":1936.8793676385785,"height":1087.8985537101305,"type":"interface","id":"interface-0"}],"visualizations":[{"x":244.34545856782955,"y":690.4323267566406,"width":1321.704589730543,"height":123.566222639058,"type":"area_chart","id":"area_chart-18"},{"x":1153.7077294750907,"y":81.4900119048118,"width":372.14353682649534,"height":349.13665449494994,"type":"bar_chart","id":"bar_chart-13"},{"x":1654.4423195297222,"y":79.85710497266787,"width":288.2207038573139,"height":348.94492760018716,"type":"bar_chart","id":"bar_chart-14"},{"x":242.60421451479615,"y":812.999358921114,"width":1318.2752409466639,"height":288.15073825770787,"type":"bar_chart","id":"bar_chart-17"},{"x":1131.5825598889926,"y":496.6552629648786,"width":421.5777536661484,"height":177.46766697411744,"type":"bar_chart","id":"bar_chart-8"},{"x":1623.4083075805643,"y":508.79827205862927,"width":314.00158408342423,"height":177.38443409997512,"type":"bar_chart","id":"bar_chart-9"},{"x":469.0572381198841,"y":84.66898077758674,"width":654.558168593194,"height":532.9434584972295,"type":"graph","id":"graph-1"},{"x":469.08387600895327,"y":89.8097208972545,"width":659.6887704825122,"height":529.5770597759964,"type":"map","id":"map-2"},{"x":18.74243899121027,"y":50.94973122719838,"width":1923.243081240065,"height":638.4149059475717,"type":"map","id":"map-6"},{"x":1597.5677534016897,"y":895.4131131181879,"width":338.0353448813933,"height":202.84666732174168,"type":"matrix","id":"matrix-12"},{"x":1445.1787103041827,"y":286.55384697968134,"width":378.4356700360441,"height":364.2864977085381,"type":"matrix","id":"matrix-7"},{"x":1594.1515896454944,"y":696.4489103954976,"width":344.8676723937875,"height":178.95510016284652,"type":"pie_chart","id":"pie_chart-11"},{"x":470.7643256720542,"y":88.63331148879406,"width":647.6880750438797,"height":523.2860266952885,"type":"polar_plot","id":"polar_plot-0"},{"x":116.21226050847888,"y":289.4761954043907,"width":314.83279421195596,"height":320.4088525095555,"type":"polar_plot","id":"polar_plot-3"},{"x":10.474126934551963,"y":691.0252724775862,"width":1557.9007171839678,"height":409.35621419843676,"type":"table","id":"table-16"}],"relations":[{"vislist":[{"vislist":[{"vislist":[{"vislist":["polar_plot-0"],"relation":null,"id":"group-0"},{"vislist":["graph-1"],"relation":null,"id":"group-1"}],"relation":"nested","id":"relation-0"}],"relation":null,"id":"group-2"},{"vislist":["map-2"],"relation":null,"id":"group-3"}],"relation":"coordinated","id":"relation-1"},{"vislist":[{"vislist":["matrix-7","bar_chart-14","bar_chart-9","bar_chart-8","bar_chart-13"],"relation":null,"id":"group-5"}],"relation":"stacked","id":"relation-3"},{"vislist":[{"vislist":["area_chart-18","bar_chart-17"],"relation":null,"id":"group-6"},{"vislist":["table-16"],"relation":null,"id":"group-7"}],"relation":"nested","id":"relation-4"}]},"3331_0":{"comp":[["line_chart","pie_chart",["nested"]],["matrix","pie_chart",["nested"]]],"visType":["line_chart","pie_chart","matrix"],"compType":["nested"],"compressed_tree":[{"composite_pattern":"nested","visualization_type":[["line_chart","matrix"],["pie_chart"]]}],"coOccurrence":[["line_chart","matrix",["coOccurrence"]],["line_chart","pie_chart",["coOccurrence"]],["matrix","pie_chart",["coOccurrence"]]],"year":2020,"conference":["VAST"],"authors":["Joseph F. DeRose","Jiayao Wang","Matthew Berger"],"title":"Attention Flows: Analyzing and Comparing Attention Mechanisms in Language Models","doi":"10.1109/TVCG.2020.3028976","abstract":"Advances in language modeling have led to the development of deep attention-based models that are performant across a wide variety of natural language processing (NLP) problems. These language models are typified by a pre-training process on large unlabeled text corpora and subsequently fine-tuned for specific tasks. Although considerable work has been devoted to understanding the attention mechanisms of pre-trained models, it is less understood how a model\'s attention mechanisms change when trained for a target NLP task. In this paper, we propose a visual analytics approach to understanding fine-tuning in attention-based language models. Our visualization, Attention Flows, is designed to support users in querying, tracing, and comparing attention within layers, across layers, and amongst attention heads in Transformer-based language models. To help users gain insight on how a classification decision is made, our design is centered on depicting classification-based attention at the deepest layer and how attention from prior layers flows throughout words in the input. Attention Flows supports the analysis of a single model, as well as the visual comparison between pre-trained and fine-tuned models via their similarities and differences. We use Attention Flows to study attention mechanisms in various sentence understanding tasks and highlight how attention evolves to address the nuances of solving these tasks.","keywords":"NLP, Transformer, Visual Analytics","caption":"Fig. 1: Our approach supports the comparison of attention mechanisms in language models. We compare the BERT model (turquoise) and its \ufb01ne-tuned counterpart (purple) tasked with determining question-answer pair validity (a). By selecting the word \u201cwhat\u201d, in contrast to BERT the \ufb01ne-tuned model attends to the answer \u201cjacksonvillians or jaxons\u201d (c), with full sentence context shown in (b). ","img_size":{"width":1338,"height":1097},"subfigures":[{"x":62.23817874133615,"y":9.593871486509899,"width":1226.9970253732492,"height":1064.326680813505,"type":"single","id":"single-0"}],"visualizations":[{"x":69.61624022733635,"y":110.8139341918427,"width":1204.755689703516,"height":950.2919994689529,"type":"line_chart","id":"line_chart-1"},{"x":66.66810028793977,"y":106.38538302509826,"width":1213.6460546614012,"height":960.6474991594935,"type":"matrix","id":"matrix-0"},{"x":68.0787877836129,"y":106.3544606688431,"width":1197.3512968141306,"height":956.2141518008466,"type":"pie_chart","id":"pie_chart-2"}],"relations":[{"vislist":[{"vislist":["line_chart-1","matrix-0"],"relation":null,"id":"group-0"},{"vislist":["pie_chart-2"],"relation":null,"id":"group-1"}],"relation":"nested","id":"relation-0"}]},"3353_2":{"comp":[["stripe_graph","table",["nested"]]],"visType":["stripe_graph","table"],"compType":["nested"],"compressed_tree":[{"composite_pattern":"nested","visualization_type":[["stripe_graph"],["table"]]}],"coOccurrence":[["stripe_graph","table",["coOccurrence"]]],"year":2020,"conference":["VAST"],"authors":["Johannes Knittel","Andres Lalama","Steffen Koch","Thomas Ertl"],"title":"Visual Neural Decomposition to Explain Multivariate Data Sets","doi":"10.1109/TVCG.2020.3030420","abstract":"Investigating relationships between variables in multi-dimensional data sets is a common task for data analysts and engineers. More specifically, it is often valuable to understand which ranges of which input variables lead to particular values of a given target variable. Unfortunately, with an increasing number of independent variables, this process may become cumbersome and time-consuming due to the many possible combinations that have to be explored. In this paper, we propose a novel approach to visualize correlations between input variables and a target output variable that scales to hundreds of variables. We developed a visual model based on neural networks that can be explored in a guided way to help analysts find and understand such correlations. First, we train a neural network to predict the target from the input variables. Then, we visualize the inner workings of the resulting model to help understand relations within the data set. We further introduce a new regularization term for the backpropagation algorithm that encourages the neural network to learn representations that are easier to interpret visually. We apply our method to artificial and real-world data sets to show its utility.","keywords":"Visual Analytics, Multivariate Data Analysis, Machine Learning","caption":"Fig. 3. All available variables of the automobiles data set with previews of the data, scale, and histogram.","img_size":{"width":975,"height":624},"subfigures":[{"x":7.113914479950219,"y":8.600436188026753,"width":958.2146310838008,"height":558.2166324592663,"type":"interface","id":"interface-0"}],"visualizations":[{"x":681.1034920719422,"y":76.48217467975289,"width":276.72099276537284,"height":479.6266957838413,"type":"stripe_graph","id":"stripe_graph-1"},{"x":17.005851004824336,"y":71.3842071827119,"width":940.9882979903513,"height":488.10442174925316,"type":"table","id":"table-0"}],"relations":[{"vislist":[{"vislist":["stripe_graph-1"],"relation":null,"id":"group-0"},{"vislist":["table-0"],"relation":null,"id":"group-1"}],"relation":"nested","id":"relation-0"}]},"3351_0":{"comp":[["heatmap","graph",["nested"]],["others","graph",["nested"]]],"visType":["heatmap","graph","others"],"compType":["nested"],"compressed_tree":[{"composite_pattern":"nested","visualization_type":[["heatmap","others"],["graph"]]}],"coOccurrence":[["heatmap","others",["coOccurrence"]],["heatmap","graph",["coOccurrence"]],["others","graph",["coOccurrence"]]],"year":2020,"conference":["VAST"],"authors":["Mohammad Raji","Jeremiah Duncan","Tanner Hobson","Jian Huang"],"title":"Dataless Sharing of Interactive Visualization","doi":"10.1109/TVCG.2020.2984708","abstract":"Interactive visualization has become a powerful insight-revealing medium. However, the close dependency of interactive visualization on its data inhibits its shareability. Users have to choose between the two extremes of (i) sharing non-interactive dataless formats such as images and videos, or (ii) giving access to their data and software to others with no control over how the data will be used. In this work, we fill the gap between the two extremes and present a new system, called Loom. Loom captures interactive visualizations as standalone dataless objects. Users can interact with Loom objects as if they still have the original software and data that created those visualizations. Yet, Loom objects are completely independent and can therefore be shared online without requiring the data or the visualization software. Loom objects are efficient to store and use, and provide privacy preserving mechanisms. We demonstrate Loom\'s efficacy with examples of scientific visualization using Paraview, information visualization using Tableau, and journalistic visualization from New York Times.","keywords":"Deep learning, machine learning, convolutional neural networks, visual analytics","caption":"Fig. 1.  With CNN EXPLAINER, learners can visually examine howConvolutional Neural Networks(CNNs) transform input images into classification predictions (e.g., predicting espresso for an image of a coffee cup), and interactively learn about their underlying mathematical operations. In this example, a learner uses CNN EXPLAINER to understand how convolutional layers work through three tightly integrated views, each explaining the convolutional process in increasing levels of detail. (A) The Overview visualizes a CNN architecture where each neuron is encoded as a square with a heatmap representing the neuron\u2019s output. (B) Clicking a neuron reveals how its activations are computed by the previous layer\u2019s neurons, displaying the often-overlooked intermediate computation through animations of sliding kernels. (C) Convolutional Interactive Formula View for inspecting underlying mathematics of the dot-product operation core to convolution. For clarity, some annotations are removed and views are re-positioned.","img_size":{"width":1813,"height":853},"subfigures":[{"x":7.466208060541343,"y":10.956137536585118,"width":1802.018080505424,"height":836.3562098585243,"type":"interface","id":"interface-0"}],"visualizations":[{"x":215.24802905937574,"y":128.14009111281342,"width":152.7359152797373,"height":703.7582880868722,"type":"heatmap","id":"heatmap-0"},{"x":468.8508742632345,"y":120.08342992253552,"width":242.0236890103356,"height":697.5053629394445,"type":"heatmap","id":"heatmap-1"},{"x":815.2029413709323,"y":121.62476053943472,"width":278.54480854043555,"height":691.227523487362,"type":"heatmap","id":"heatmap-2"},{"x":1229.4233114963963,"y":112.06024173036062,"width":294.4701515737713,"height":344.5086551120379,"type":"heatmap","id":"heatmap-3"},{"x":37.6385303101534,"y":266.4069247345512,"width":77.77598019586098,"height":454.38363569880795,"type":"others","id":"others-4"},{"x":18.921196528414796,"y":113.83008192268599,"width":1773.55842875513,"height":713.207237157426,"type":"graph","id":"graph-5"}],"relations":[{"vislist":[{"vislist":["heatmap-0","heatmap-1","heatmap-2","heatmap-3","others-4"],"relation":null,"id":"group-4"},{"vislist":["graph-5"],"relation":null,"id":"group-5"}],"relation":"nested","id":"relation-1"}]},"3350_0":{"comp":[["bar_chart","table",["nested"]],["others","table",["nested"]],["proportional_area_chart","table",["nested"]]],"visType":["bar_chart","table","others","proportional_area_chart"],"compType":["nested"],"compressed_tree":[{"composite_pattern":"nested","visualization_type":[["bar_chart","others","proportional_area_chart"],["table"]]}],"coOccurrence":[["bar_chart","others",["coOccurrence"]],["bar_chart","proportional_area_chart",["coOccurrence"]],["bar_chart","table",["coOccurrence"]],["others","proportional_area_chart",["coOccurrence"]],["others","table",["coOccurrence"]],["proportional_area_chart","table",["coOccurrence"]]],"year":2020,"conference":["VAST"],"authors":["Alexis Pister","Paolo Buono","Jean-Daniel Fekete","Catherine Plaisant","Paola Valdivia"],"title":"Integrating Prior Knowledge in Mixed Initiative Social Network Clustering","doi":"10.1109/TVCG.2020.3030347","abstract":"We propose a new approach-called PK-clustering-to help social scientists create meaningful clusters in social networks. Many clustering algorithms exist but most social scientists find them difficult to understand, and tools do not provide any guidance to choose algorithms, or to evaluate results taking into account the prior knowledge of the scientists. Our work introduces a new clustering approach and a visual analytics user interface that address this issue. It is based on a process that 1) captures the prior knowledge of the scientists as a set of incomplete clusters, 2) runs multiple clustering algorithms (similarly to clustering ensemble methods), 3) visualizes the results of all the algorithms ranked and summarized by how well each algorithm matches the prior knowledge, 4) evaluates the consensus between user-selected algorithms and 5) allows users to review details and iteratively update the acquired knowledge. We describe our approach using an initial functional prototype, then provide two examples of use and early feedback from social scientists. We believe our clustering approach offers a novel constructive method to iteratively build knowledge while avoiding being overly influenced by the results of often randomly selected black-box clustering algorithms.","keywords":"Social network analysis, network visualization, clustering, mixed-initiative, prior knowledge, user interface","caption":"Fig. 1. Two main phases of PK-clustering. On the left, the user has specified the Prior Knowledge (PK) groups (top left) and then reviews the list of algorithms ranked according to how well they match the PK. On the right, the user compared the detailed results of selected algorithms and consolidated the results. From the initial specification of three groups and three people, 4 relevant clusters were obtained with 37 people in total, plus one unclassified node (Othersgroup).","img_size":{"width":1815,"height":680},"subfigures":[{"x":3.638875492824376,"y":8.357774472862104,"width":941.6090931473653,"height":665.9215177196658,"type":"interface","id":"interface-0"},{"x":962.0326282353252,"y":9.654352329306743,"width":841.4181307136658,"height":663.3283620067768,"type":"interface","id":"interface-1"}],"visualizations":[{"x":958.4142787729717,"y":148.37005687997916,"width":66.27038519283907,"height":519.3839310790244,"type":"bar_chart","id":"bar_chart-2"},{"x":1349.4245885207217,"y":140.34978389185434,"width":456.1395379334239,"height":521.0113428958524,"type":"others","id":"others-4"},{"x":1021.5181324869078,"y":148.35142166356079,"width":119.36821668633496,"height":514.6168234587211,"type":"proportional_area_chart","id":"proportional_area_chart-3"},{"x":167.01706502865758,"y":197.5926168968741,"width":778.152195063392,"height":467.3811322255939,"type":"table","id":"table-0"},{"x":956.9666531968631,"y":94.46616783255833,"width":844.0217152552573,"height":577.5464692914131,"type":"table","id":"table-1"}],"relations":[{"vislist":[{"vislist":["bar_chart-2","others-4","proportional_area_chart-3"],"relation":null,"id":"group-0"},{"vislist":["table-1"],"relation":null,"id":"group-1"}],"relation":"nested","id":"relation-0"}]},"3346_9":{"comp":[["area_chart","graph",["nested"]],["matrix","comb",["stacked"]],["comb","matrix",["stacked"]]],"visType":["area_chart","graph","matrix","comb"],"compType":["nested","stacked"],"compressed_tree":[{"composite_pattern":"stacked","visualization_type":[["matrix",{"composite_pattern":"nested","visualization_type":[["area_chart"],["graph"]]}]]}],"coOccurrence":[["area_chart","graph",["coOccurrence"]],["area_chart","matrix",["coOccurrence"]],["graph","matrix",["coOccurrence"]]],"year":2020,"conference":["VAST"],"authors":["Qianwen Wang","William Alexander","Jack Pegg","Huamin Qu","Min Chen"],"title":"HypoML: Visual Analysis for Hypothesis-based Evaluation of Machine Learning Models","doi":"10.1109/TVCG.2020.3030449","abstract":"In this paper, we present a visual analytics tool for enabling hypothesis-based evaluation of machine learning (ML) models. We describe a novel ML-testing framework that combines the traditional statistical hypothesis testing (commonly used in empirical research) with logical reasoning about the conclusions of multiple hypotheses. The framework defines a controlled configuration for testing a number of hypotheses as to whether and how some extra information about a \u201cconcept\u201d or \u201cfeature\u201d may benefit or hinder an ML model. Because reasoning multiple hypotheses is not always straightforward, we provide HypoML as a visual analysis tool, with which, the multi-thread testing results are first transformed to analytical results using statistical and logical inferences, and then to a visual representation for rapid observation of the conclusions and the logical flow between the testing results and hypotheses. We have applied HypoML to a number of hypothesized concepts, demonstrating the intuitive and explainable nature of the visual analysis.","keywords":"Visual analytics, model-developmental visualization, machine learning, neural network, hypothesis test, HypoML.","caption":"Fig. 9. Testing the combined concept of average intensity. For each sample, the stimulus in D contains an original object. The stimulus in D+ contains an extra piece of information about the average intensity of the object.","img_size":{"width":1774,"height":528},"subfigures":[{"x":8.882419347699031,"y":17.519883098861584,"width":1753.658150451346,"height":503.523616877044,"type":"interface","id":"interface-0"}],"visualizations":[{"x":1083.2213270871491,"y":228.6026798048587,"width":89.50890044162243,"height":291.74359635619413,"type":"area_chart","id":"area_chart-1"},{"x":1174.3357739067012,"y":247.1509396580009,"width":246.8367839182806,"height":271.8842292429956,"type":"graph","id":"graph-2"},{"x":484.11445675134684,"y":21.14318600532484,"width":594.5260869091587,"height":498.24973896613915,"type":"matrix","id":"matrix-0"}],"relations":[{"vislist":[{"vislist":["matrix-0",{"vislist":[{"vislist":["area_chart-1"],"relation":null,"id":"group-0"},{"vislist":["graph-2"],"relation":null,"id":"group-1"}],"relation":"nested","id":"relation-0"}],"relation":null,"id":"group-2"}],"relation":"stacked","id":"relation-1"}]},"1516_7":{"comp":[["proportional_area_chart","graph",["nested"]]],"visType":["proportional_area_chart","graph"],"compType":["nested"],"compressed_tree":[{"composite_pattern":"nested","visualization_type":[["proportional_area_chart"],["graph"]]}],"coOccurrence":[["proportional_area_chart","graph",["coOccurrence"]]],"year":2006,"conference":["Vis"],"authors":["Natascha Sauber","Holger Theisel","Hans-Peter Seidel"],"title":"Multifield-Graphs: An Approach to Visualizing Correlations in Multifield Scalar Data","doi":"10.1109/TVCG.2006.165","abstract":"We present an approach to visualizing correlations in 3D multifield scalar data. The core of our approach is the computation of correlation fields, which are scalar fields containing the local correlations of subsets of the multiple fields. While the visualization of the correlation fields can be done using standard 3D volume visualization techniques, their huge number makes selection and handling a challenge. We introduce the multifield-graph to give an overview of which multiple fields correlate and to show the strength of their correlation. This information guides the selection of informative correlation fields for visualization. We use our approach to visually analyze a number of real and synthetic multifield datasets","keywords":"Visualization, multifield, correlation","caption":"Fig. 8. Multi\ufb01eld-Graph of the ABC-\ufb02ow-feature multi\ufb01eld computed with LCC and \u03b8 = 0.8, focused on nodes with acN > 0.87 and rcN > 0.11 ","img_size":{"width":1059,"height":329},"subfigures":[{"x":7.414058482336781,"y":12.385522869647119,"width":1044.9410641214579,"height":308.0767970099779,"type":"single","id":"single-0"}],"visualizations":[{"x":10.125191827260956,"y":14.240178595277605,"width":1037.815512814792,"height":301.45295768352315,"type":"graph","id":"graph-1"},{"x":11.992397121680517,"y":10.577579084130763,"width":1037.8175163486949,"height":306.91152695766,"type":"proportional_area_chart","id":"proportional_area_chart-0"}],"relations":[{"vislist":[{"vislist":["proportional_area_chart-0"],"relation":null,"id":"group-0"},{"vislist":["graph-1"],"relation":null,"id":"group-1"}],"relation":"nested","id":"relation-0"}]},"2592_4":{"comp":[["bar_chart","parallel_coordinate",["nested"]]],"visType":["bar_chart","parallel_coordinate"],"compType":["nested"],"compressed_tree":[{"composite_pattern":"nested","visualization_type":[["bar_chart"],["parallel_coordinate"]]}],"coOccurrence":[["bar_chart","parallel_coordinate",["coOccurrence"]]],"year":2015,"conference":["InfoVis"],"authors":["Matthew Brehmer","Jocelyn Ng","Kevin Tate","Tamara Munzner"],"title":"Matches, Mismatches, and Methods: Multiple-View Workflows for Energy Portfolio Analysis","doi":"10.1109/TVCG.2015.2466971","abstract":"The energy performance of large building portfolios is challenging to analyze and monitor, as current analysis tools are not scalable or they present derived and aggregated data at too coarse of a level. We conducted a visualization design study, beginning with a thorough work domain analysis and a characterization of data and task abstractions. We describe generalizable visual encoding design choices for time-oriented data framed in terms of matches and mismatches, as well as considerations for workflow design. Our designs address several research questions pertaining to scalability, view coordination, and the inappropriateness of line charts for derived and aggregated data due to a combination of data semantics and domain convention. We also present guidelines relating to familiarity and trust, as well as methodological considerations for visualization design studies. Our designs were adopted by our collaborators and incorporated into the design of an energy analysis software application that will be deployed to tens of thousands of energy workers in their client base.","keywords":"Design study, design methodologies, time series data, task and requirements analysis, coordinated and multiple views","caption":"Fig. 4. A bar + bump plot of energy intensity, encoding rank change for the top 7 building groups (buildings aggregated by tag) across four seasons. The alpha channel encodes rank variation to highlight incon- sistent buildings. A potential match {?} for the Overview task (T1).","img_size":{"width":1032,"height":570},"subfigures":[{"x":6.137946604033852,"y":8.085438529499655,"width":1015.8321665213932,"height":550.7148604304437,"type":"single","id":"single-0"}],"visualizations":[{"x":20.282942331224966,"y":34.060124862622075,"width":174.21368007034602,"height":461.540761869946,"type":"bar_chart","id":"bar_chart-0"},{"x":310.5219586688899,"y":22.415478328266396,"width":128.9560493057928,"height":493.1690399169318,"type":"bar_chart","id":"bar_chart-1"},{"x":549.2860870288935,"y":27.05524195006724,"width":148.42785137352882,"height":449.8895090326352,"type":"bar_chart","id":"bar_chart-2"},{"x":768.5517848834997,"y":26.180590122517348,"width":94.8965629489951,"height":468.63881450808316,"type":"bar_chart","id":"bar_chart-3"},{"x":14.826965273556356,"y":17.136532796506277,"width":997.1256356627523,"height":528.5378787868437,"type":"parallel_coordinate","id":"parallel_coordinate-4"}],"relations":[{"vislist":[{"vislist":["bar_chart-0","bar_chart-1","bar_chart-2","bar_chart-3"],"relation":null,"id":"group-1"},{"vislist":["parallel_coordinate-4"],"relation":null,"id":"group-0"}],"relation":"nested","id":"relation-0"}]},"2595_3":{"comp":[["pie_chart","matrix",["nested"]]],"visType":["pie_chart","matrix"],"compType":["nested"],"compressed_tree":[{"composite_pattern":"nested","visualization_type":[["pie_chart"],["matrix"]]}],"coOccurrence":[["pie_chart","matrix",["coOccurrence"]]],"year":2015,"conference":["InfoVis"],"authors":["Mehmet Adil Yal\xe7in","Niklas Elmqvist","Benjamin B. Bederson"],"title":"AggreSet: Rich and Scalable Set Exploration using Visualizations of Element Aggregations","doi":"10.1109/TVCG.2015.2467051","abstract":"Datasets commonly include multi-value (set-typed) attributes that describe set memberships over elements, such as genres per movie or courses taken per student. Set-typed attributes describe rich relations across elements, sets, and the set intersections. Increasing the number of sets results in a combinatorial growth of relations and creates scalability challenges. Exploratory tasks (e.g. selection, comparison) have commonly been designed in separation for set-typed attributes, which reduces interface consistency. To improve on scalability and to support rich, contextual exploration of set-typed data, we present AggreSet. AggreSet creates aggregations for each data dimension: sets, set-degrees, set-pair intersections, and other attributes. It visualizes the element count per aggregate using a matrix plot for set-pair intersections, and histograms for set lists, set-degrees and other attributes. Its non-overlapping visual design is scalable to numerous and large sets. AggreSet supports selection, filtering, and comparison as core exploratory tasks. It allows analysis of set relations inluding subsets, disjoint sets and set intersection strength, and also features perceptual set ordering for detecting patterns in set matrices. Its interaction is designed for rich and rapid data exploration. We demonstrate results on a wide range of datasets from different domains with varying characteristics, and report on expert reviews and a case study using student enrollment and degree data with assistant deans at a major public university.","keywords":"Multi-valued attributes, sets, visualization, set visualization, data exploration, interaction, design, scalability","caption":"Fig. 4.  Character co-occurrences  in  Les  Miserables,  with  80  characters  (sets)  in  356  book  chapters  (elements).  Data  is  filtered  to  chapters  that  have  at  least  4  characters.  The  related  64  characters  are  reordered  by  the  number  of  book  chapters  they  occur.  Th\xe9nardier  and  Cosette,  have  ghost-bars  (gray  extensions),  showing  that  these  characters  also  appeared  in  chapters  with  <4  characters  while  Joly  and  Bahorel appear only in the chapters with \u22654  characters.  Th\xe9nardier is one of the common characters, yet he does not appear with Bahorel, Feuilly, and some other characters outside of the view (disjoint set pairs). The legend shows circle size mapping.","img_size":{"width":2151,"height":414},"subfigures":[{"x":19.65724136687858,"y":25.568387663360138,"width":2092.937545410503,"height":378.48527420483606,"type":"interface","id":"interface-0"}],"visualizations":[{"x":533.6717226435536,"y":24.0601233433799,"width":801.6728060671722,"height":389.1841820151677,"type":"bar_chart","id":"bar_chart-0"},{"x":1344.6663055254603,"y":24.0601233433799,"width":780.6988082340195,"height":358.8884073672805,"type":"bar_chart","id":"bar_chart-1"},{"x":20.97399783315276,"y":24.0601233433799,"width":522.0195016251354,"height":386.8537378114841,"type":"matrix","id":"matrix-2"},{"x":14.700208454712167,"y":29.82940940451799,"width":527.5386077049776,"height":367.98283676977667,"type":"pie_chart","id":"pie_chart-3"}],"relations":[{"vislist":[{"vislist":["pie_chart-3"],"relation":null,"id":"group-1"},{"vislist":["matrix-2"],"relation":null,"id":"group-0"}],"relation":"nested","id":"relation-0"}]},"2595_4":{"comp":[["pie_chart","matrix",["nested"]]],"visType":["pie_chart","matrix"],"compType":["nested"],"compressed_tree":[{"composite_pattern":"nested","visualization_type":[["pie_chart"],["matrix"]]}],"coOccurrence":[["pie_chart","matrix",["coOccurrence"]]],"year":2015,"conference":["InfoVis"],"authors":["Mehmet Adil Yal\xe7in","Niklas Elmqvist","Benjamin B. Bederson"],"title":"AggreSet: Rich and Scalable Set Exploration using Visualizations of Element Aggregations","doi":"10.1109/TVCG.2015.2467051","abstract":"Datasets commonly include multi-value (set-typed) attributes that describe set memberships over elements, such as genres per movie or courses taken per student. Set-typed attributes describe rich relations across elements, sets, and the set intersections. Increasing the number of sets results in a combinatorial growth of relations and creates scalability challenges. Exploratory tasks (e.g. selection, comparison) have commonly been designed in separation for set-typed attributes, which reduces interface consistency. To improve on scalability and to support rich, contextual exploration of set-typed data, we present AggreSet. AggreSet creates aggregations for each data dimension: sets, set-degrees, set-pair intersections, and other attributes. It visualizes the element count per aggregate using a matrix plot for set-pair intersections, and histograms for set lists, set-degrees and other attributes. Its non-overlapping visual design is scalable to numerous and large sets. AggreSet supports selection, filtering, and comparison as core exploratory tasks. It allows analysis of set relations inluding subsets, disjoint sets and set intersection strength, and also features perceptual set ordering for detecting patterns in set matrices. Its interaction is designed for rich and rapid data exploration. We demonstrate results on a wide range of datasets from different domains with varying characteristics, and report on expert reviews and a case study using student enrollment and degree data with assistant deans at a major public university.","keywords":"Multi-valued attributes, sets, visualization, set visualization, data exploration, interaction, design, scalability","caption":"Fig. 5.  313  ingredients  (sets)  in  5,000  recipes  (elements).  The  relative-mode  is  active;  each  aggregate  glyph  is  scaled  to  its  maximum  size  (length or radius), creating a shared percent scale. The orange result-preview shows the distribution of selected  corn among all aggregations in  percentage.  Corn  is  rarely  used  with  soybean;  2%  of  recipes  with  soybean  have  corn.  Corn  is  popular  in  recipes  with  high  number  of  ingredients. At  the  peak,  44%  of  recipes  with  20  to  25  ingredients  have  corn.  In  the  matrix,  recipes  with  the  second  rightmost  ingredient  (positioned above the view, tomato) frequently have corn, such as half of vinegar-tomato, and  half of soybean-tomato recipes.Fig. 4.  Character co-occurrences  in  Les  Miserables,  with  80  characters  (sets)  in  356  book  chapters  (elements).  Data  is  filtered  to  chapters  that  have  at  least  4  characters.  The  related  64  characters  are  reordered  by  the  number  of  book  chapters  they  occur.  Th\xe9nardier  and  Cosette,  have  ghost-bars  (gray  extensions),  showing  that  these  characters  also  appeared  in  chapters  with  <4  characters  while  Joly  and  Bahorel appear only in the chapters with \u22654  characters.  Th\xe9nardier is one of the common characters, yet he does not appear with Bahorel, Feuilly, and some other characters outside of the view (disjoint set pairs). The legend shows circle size mapping.","img_size":{"width":2151,"height":368},"subfigures":[{"x":15.053114543906855,"y":9.441832926403947,"width":2120.8937709121874,"height":347.55118164878655,"type":"interface","id":"interface-0"}],"visualizations":[{"x":1336.6146010186758,"y":3.401887723471286,"width":801.6035653650257,"height":339.20797962648555,"type":"bar_chart","id":"bar_chart-0"},{"x":679.263157894737,"y":3.401887723471286,"width":646.3955857385399,"height":361.19622455305745,"type":"bar_chart","id":"bar_chart-1"},{"x":7.303904923599322,"y":3.401887723471286,"width":535.0110356536502,"height":361.19622455305745,"type":"matrix","id":"matrix-2"},{"x":7.303904923599322,"y":3.401887723471286,"width":538.6629881154499,"height":361.19622455305745,"type":"pie_chart","id":"pie_chart-3"}],"relations":[{"vislist":[{"vislist":["pie_chart-3"],"relation":null,"id":"group-1"},{"vislist":["matrix-2"],"relation":null,"id":"group-0"}],"relation":"nested","id":"relation-0"}]},"2595_5":{"comp":[["pie_chart","matrix",["nested"]]],"visType":["pie_chart","matrix"],"compType":["nested"],"compressed_tree":[{"composite_pattern":"nested","visualization_type":[["pie_chart"],["matrix"]]},{"composite_pattern":"nested","visualization_type":[["pie_chart"],["matrix"]]}],"coOccurrence":[["pie_chart","matrix",["coOccurrence"]]],"year":2015,"conference":["InfoVis"],"authors":["Mehmet Adil Yal\xe7in","Niklas Elmqvist","Benjamin B. Bederson"],"title":"AggreSet: Rich and Scalable Set Exploration using Visualizations of Element Aggregations","doi":"10.1109/TVCG.2015.2467051","abstract":"Datasets commonly include multi-value (set-typed) attributes that describe set memberships over elements, such as genres per movie or courses taken per student. Set-typed attributes describe rich relations across elements, sets, and the set intersections. Increasing the number of sets results in a combinatorial growth of relations and creates scalability challenges. Exploratory tasks (e.g. selection, comparison) have commonly been designed in separation for set-typed attributes, which reduces interface consistency. To improve on scalability and to support rich, contextual exploration of set-typed data, we present AggreSet. AggreSet creates aggregations for each data dimension: sets, set-degrees, set-pair intersections, and other attributes. It visualizes the element count per aggregate using a matrix plot for set-pair intersections, and histograms for set lists, set-degrees and other attributes. Its non-overlapping visual design is scalable to numerous and large sets. AggreSet supports selection, filtering, and comparison as core exploratory tasks. It allows analysis of set relations inluding subsets, disjoint sets and set intersection strength, and also features perceptual set ordering for detecting patterns in set matrices. Its interaction is designed for rich and rapid data exploration. We demonstrate results on a wide range of datasets from different domains with varying characteristics, and report on expert reviews and a case study using student enrollment and degree data with assistant deans at a major public university.","keywords":"Multi-valued attributes, sets, visualization, set visualization, data exploration, interaction, design, scalability","caption":"Fig. 6. Character co-occurrences in Les Miserables. This dataset has 82 subset relations. Left: The circle area maps the number of chapters both characters occurs in. Intersections with few chapters appear small and are hard to observe. Right: The circles are full and color denotes the character relation strength by the chapters they occur in together. The border is shown when one character always appearswith the other character.  For  example,  all  of  Feuilly\u2019s  chapters  (7)  also  include  Bossuet,  who  appears  in  16  chapters.  This  suggests  a  proper-subset relationship, and the border is half. When two characters  always  appear  together,  their   border is full (not visible in this cross section).  We  can  also observe that while intersection of Madame Thenardier was one of the largest in number of chapters , it is not one of the strongest . ","img_size":{"width":2037,"height":570},"subfigures":[{"x":5.392447876256362,"y":6.996705418146399,"width":999.4215447758716,"height":548.6148708163947,"type":"interface","id":"interface-0"},{"x":1038.0790643499083,"y":15.760707825234388,"width":992.0740196455977,"height":539.9569280189936,"type":"interface","id":"interface-1"}],"visualizations":[{"x":1547.3847415914681,"y":66.09351927809678,"width":479.58900738310103,"height":503.9064807219032,"type":"bar_chart","id":"bar_chart-0"},{"x":544.7596390484001,"y":41.02789171452009,"width":431.1287940935191,"height":524.707136997539,"type":"bar_chart","id":"bar_chart-1"},{"x":5.013125512715337,"y":47.71205906480719,"width":509.66776045939275,"height":522.2879409351929,"type":"matrix","id":"matrix-2"},{"x":1044.4011484823625,"y":51.054142739950784,"width":504.6546349466774,"height":518.9458572600493,"type":"matrix","id":"matrix-3"},{"x":3.6827468341510294,"y":45.662957488692854,"width":513.6163603646818,"height":503.1962454946168,"type":"pie_chart","id":"pie_chart-4"},{"x":1031.6507945777548,"y":49.534569744259336,"width":523.6897008427194,"height":503.1968611325374,"type":"pie_chart","id":"pie_chart-5"}],"relations":[{"vislist":[{"vislist":["pie_chart-4"],"relation":null,"id":"group-1"},{"vislist":["matrix-2"],"relation":null,"id":"group-0"}],"relation":"nested","id":"relation-0"},{"vislist":[{"vislist":["pie_chart-5"],"relation":null,"id":"group-3"},{"vislist":["matrix-3"],"relation":null,"id":"group-2"}],"relation":"nested","id":"relation-1"}]},"2598_4":{"comp":[["bar_chart","matrix",["nested"]],["scatterplot","matrix",["nested"]]],"visType":["bar_chart","matrix","scatterplot"],"compType":["nested"],"compressed_tree":[{"composite_pattern":"nested","visualization_type":[["bar_chart","scatterplot"],["matrix"]]},{"composite_pattern":"nested","visualization_type":[["bar_chart","scatterplot"],["matrix"]]}],"coOccurrence":[["bar_chart","scatterplot",["coOccurrence"]],["bar_chart","matrix",["coOccurrence"]],["scatterplot","matrix",["coOccurrence"]]],"year":2015,"conference":["InfoVis"],"authors":["Dirk J. Lehmann","Holger Theisel"],"title":"Optimal Sets of Projections of High-Dimensional Data","doi":"10.1109/TVCG.2015.2467132","abstract":"Finding good projections of n-dimensional datasets into a 2D visualization domain is one of the most important problems in Information Visualization. Users are interested in getting maximal insight into the data by exploring a minimal number of projections. However, if the number is too small or improper projections are used, then important data patterns might be overlooked. We propose a data-driven approach to find minimal sets of projections that uniquely show certain data patterns. For this we introduce a dissimilarity measure of data projections that discards affine transformations of projections and prevents repetitions of the same data patterns. Based on this, we provide complete data tours of at most n/2 projections. Furthermore, we propose optimal paths of projection matrices for an interactive data exploration. We illustrate our technique with a set of state-of-the-art real high-dimensional benchmark datasets.","keywords":"Multivariate Projections, Star Coordinates, Radial Visualization, High-dimensional Data","caption":"Fig. 4. Optimal set of projections compared to a subset of projections of the PCA tour for the test data Iris (top) and Wine (bottom): For each successor projection, the dissimilarity d is labeled with respect to the amount of all predecessor projections of the same sequence, which is graphically summarized at the end of each sequence.","img_size":{"width":2029,"height":2284},"subfigures":[{"x":18.05790999550598,"y":13.996499925134335,"width":1967.8983575882262,"height":2262.2464524077227,"type":"single","id":"single-0"}],"visualizations":[{"x":1581.3199121522694,"y":170.54758418740826,"width":277.5578330893123,"height":240.77306002928262,"type":"bar_chart","id":"bar_chart-0"},{"x":1594.6961932650072,"y":521.6749633967786,"width":377.8799414348464,"height":230.74084919472915,"type":"bar_chart","id":"bar_chart-1"},{"x":1547.8792093704244,"y":1203.865300146413,"width":341.09516837481715,"height":307.6544655929722,"type":"bar_chart","id":"bar_chart-2"},{"x":1547.8792093704244,"y":1892.7437774524149,"width":354.47144948755516,"height":327.7188872620794,"type":"bar_chart","id":"bar_chart-3"},{"x":87.95684130686568,"y":66.78245786889633,"width":1425.3010092726538,"height":699.2751158244282,"type":"scatterplot","id":"scatterplot-8"},{"x":82.46050319273088,"y":823.9014076904836,"width":1902.9685670794124,"height":1399.4538514355531,"type":"scatterplot","id":"scatterplot-9"},{"x":36.509891949738716,"y":11.405258262998169,"width":1948.688421075858,"height":751.6914258527919,"type":"matrix","id":"matrix-6"},{"x":51.04807968948397,"y":775.3866142565603,"width":1941.4874306703582,"height":1447.868363983879,"type":"matrix","id":"matrix-7"}],"relations":[{"vislist":[{"vislist":["bar_chart-0","bar_chart-1","scatterplot-8"],"relation":null,"id":"group-5"},{"vislist":["matrix-6"],"relation":null,"id":"group-6"}],"relation":"nested","id":"relation-2"},{"vislist":[{"vislist":["bar_chart-2","bar_chart-3","scatterplot-9"],"relation":null,"id":"group-9"},{"vislist":["matrix-7"],"relation":null,"id":"group-10"}],"relation":"nested","id":"relation-3"}]},"2601_8":{"comp":[["heatmap","matrix",["nested"]],["heatmap","comb",["stacked"]],["scatterplot","matrix",["nested"]],["comb","heatmap",["stacked"]]],"visType":["heatmap","matrix","comb","scatterplot"],"compType":["nested","stacked"],"compressed_tree":[{"composite_pattern":"nested","visualization_type":[["heatmap","scatterplot"],["matrix"]]},{"composite_pattern":"stacked","visualization_type":[["heatmap",{"composite_pattern":"nested","visualization_type":[["heatmap","scatterplot"],["matrix"]]}]]}],"coOccurrence":[["heatmap","scatterplot",["coOccurrence"]],["heatmap","matrix",["coOccurrence"]],["scatterplot","matrix",["coOccurrence"]]],"year":2015,"conference":["InfoVis"],"authors":["Sarah Goodwin","Jason Dykes","Aidan Slingsby","Cagatay Turkay"],"title":"Visualizing Multiple Variables Across Scale and Geography","doi":"10.1109/TVCG.2015.2467199","abstract":"Comparing multiple variables to select those that effectively characterize complex entities is important in a wide variety of domains - geodemographics for example. Identifying variables that correlate is a common practice to remove redundancy, but correlation varies across space, with scale and over time, and the frequently used global statistics hide potentially important differentiating local variation. For more comprehensive and robust insights into multivariate relations, these local correlations need to be assessed through various means of defining locality. We explore the geography of this issue, and use novel interactive visualization to identify interdependencies in multivariate data sets to support geographically informed multivariate analysis. We offer terminology for considering scale and locality, visual techniques for establishing the effects of scale on correlation and a theoretical framework through which variation in geographic correlation with scale and locality are addressed explicitly. Prototype software demonstrates how these contributions act together. These techniques enable multiple variables and their geographic characteristics to be considered concurrently as we extend visual parameter space analysis (vPSA) to the spatial domain. We find variable correlations to be sensitive to scale and geography to varying degrees in the context of energy-based geodemographics. This sensitivity depends upon the calculation of locality as well as the geographical and statistical structure of the variable.","keywords":"Scale, Geography, Multivariate, Sensitivity Analysis, Variable Selection, Local Statistics, Geodemographics, Energy","caption":"Fig. 9: Software prototype showing all three panels and MicroMulti information in an asymmetrical matrix. Seven energy \u2013 consumption (Con), fuel poverty and central heating (CH) \u2013 variables displaying locality information, based on an adaptive moving window with 25 neighbors (N=25). Pairwise correlation examples 1-4 are highlighted and discussed in the text.","img_size":{"width":1845,"height":782},"subfigures":[{"x":259.190163808761,"y":24.250899982741117,"width":1334.6601205632874,"height":745.5665101606,"type":"interface","id":"interface-0"}],"visualizations":[{"x":1046.5384615384614,"y":38.5,"width":267.6923076923076,"height":268.8461538461538,"type":"heatmap","id":"heatmap-0"},{"x":260.62976223630284,"y":36.16058448407559,"width":49.13331965715601,"height":729.2810180777374,"type":"heatmap","id":"heatmap-11"},{"x":1315.384615384615,"y":301.5769230769231,"width":268.8461538461538,"height":280.3846153846153,"type":"heatmap","id":"heatmap-2"},{"x":1045.384615384615,"y":310.8076923076923,"width":272.3076923076924,"height":268.8461538461538,"type":"heatmap","id":"heatmap-3"},{"x":310.9232950259723,"y":36.19230769230769,"width":726.6543523780861,"height":732.6923076923076,"type":"heatmap","id":"heatmap-4"},{"x":310.68397272824234,"y":35.03846153846156,"width":728.0400220769861,"height":736.1538461538458,"type":"matrix","id":"matrix-10"},{"x":1045.4545711718802,"y":40.26861515529582,"width":539.8651592421771,"height":536.2443360169185,"type":"matrix","id":"matrix-12"},{"x":1317.6923076923078,"y":40.80769230769231,"width":266.53846153846143,"height":263.076923076923,"type":"scatterplot","id":"scatterplot-6"},{"x":312.07753742436097,"y":38.50000000000003,"width":727.8074060428476,"height":732.6923076923076,"type":"scatterplot","id":"scatterplot-9"}],"relations":[{"vislist":[{"vislist":["heatmap-0","heatmap-2","heatmap-3","scatterplot-6"],"relation":null,"id":"group-6"},{"vislist":["matrix-12"],"relation":null,"id":"group-7"}],"relation":"nested","id":"relation-5"},{"vislist":[{"vislist":["heatmap-11",{"vislist":[{"vislist":["heatmap-4","scatterplot-9"],"relation":null,"id":"group-9"},{"vislist":["matrix-10"],"relation":null,"id":"group-10"}],"relation":"nested","id":"relation-6"}],"relation":null,"id":"group-11"}],"relation":"stacked","id":"relation-7"}]},"2697_1":{"comp":[["glyph_based","chord_diagram",["nested"]]],"visType":["glyph_based","chord_diagram"],"compType":["nested"],"compressed_tree":[{"composite_pattern":"nested","visualization_type":[["glyph_based"],["chord_diagram"]]}],"coOccurrence":[["glyph_based","chord_diagram",["coOccurrence"]]],"year":2015,"conference":["VAST"],"authors":["Hua Guo","Steven R. Gomez","Caroline Ziemkiewicz","David H. Laidlaw"],"title":"A Case Study Using Visualization Interaction Logs and Insight Metrics to Understand How Analysts Arrive at Insights","doi":"10.1109/TVCG.2015.2467613","abstract":"We present results from an experiment aimed at using logs of interactions with a visual analytics application to better understand how interactions lead to insight generation. We performed an insight-based user study of a visual analytics application and ran post hoc quantitative analyses of participants\' measured insight metrics and interaction logs. The quantitative analyses identified features of interaction that were correlated with insight characteristics, and we confirmed these findings using a qualitative analysis of video captured during the user study. Results of the experiment include design guidelines for the visual analytics application aimed at supporting insight generation. Furthermore, we demonstrated an analysis method using interaction logs that identified which interaction patterns led to insights, going beyond insight-based evaluations that only quantify insight characteristics. We also discuss choices and pitfalls encountered when applying this analysis method, such as the benefits and costs of applying an abstraction framework to application-specific actions before further analysis. Our method can be applied to evaluations of other visualization tools to inform the design of insight-promoting interactions and to better understand analyst behaviors.","keywords":"Evaluation, visual analytics, interaction, intelligence analysis, insight-based evaluation","caption":"Fig. 2. The Overview tab shows recommended searches (left) and the relationships between information types in the dataset (right). Selecting either a recommended search or exploring an information type launches the Explorer, which displays additional views of the dataset.","img_size":{"width":1296,"height":753},"subfigures":[{"x":8.659036186135252,"y":7.6524695263902185,"width":1277.6532894323639,"height":737.6950609472194,"type":"interface","id":"interface-0"}],"visualizations":[{"x":519.5600292825769,"y":110.24890190336752,"width":637.2386530014643,"height":566.679355783309,"type":"chord_diagram","id":"chord_diagram-0"},{"x":513.3542979105728,"y":112.68520817791084,"width":648.2914398768895,"height":562.583455980718,"type":"glyph_based","id":"glyph_based-2"},{"x":516.2525622254759,"y":110.24890190336752,"width":646.0585651537335,"height":569.9868228404101,"type":"hierarchical_edge_bundling","id":"hierarchical_edge_bundling-1"}],"relations":[{"vislist":[{"vislist":["glyph_based-2"],"relation":null,"id":"group-1"},{"vislist":["chord_diagram-0"],"relation":null,"id":"group-0"}],"relation":"nested","id":"relation-0"}]},"2702_0":{"comp":[["comb","sankey_diagram",["nested"]],["comb","line_chart",["stacked"]],["comb","scatterplot",["stacked"]],["word_cloud","area_chart",["coordinated"]],["line_chart","scatterplot",["stacked"]],["line_chart","comb",["stacked"]],["scatterplot","line_chart",["stacked"]],["scatterplot","comb",["stacked"]]],"visType":["comb","sankey_diagram","line_chart","scatterplot","word_cloud","area_chart"],"compType":["nested","stacked","coordinated"],"compressed_tree":[{"composite_pattern":"nested","visualization_type":[[{"composite_pattern":"coordinated","visualization_type":[["word_cloud"],["area_chart"]]}],["sankey_diagram"]]},{"composite_pattern":"stacked","visualization_type":[["line_chart","scatterplot",{"composite_pattern":"coordinated","visualization_type":[["word_cloud"],["area_chart"]]}]]}],"coOccurrence":[["word_cloud","area_chart",["coOccurrence"]],["word_cloud","sankey_diagram",["coOccurrence"]],["word_cloud","line_chart",["coOccurrence"]],["word_cloud","scatterplot",["coOccurrence"]],["area_chart","sankey_diagram",["coOccurrence"]],["area_chart","line_chart",["coOccurrence"]],["area_chart","scatterplot",["coOccurrence"]],["sankey_diagram","line_chart",["coOccurrence"]],["sankey_diagram","scatterplot",["coOccurrence"]],["line_chart","scatterplot",["coOccurrence"]]],"year":2015,"conference":["VAST"],"authors":["Florian Heimerl","Qi Han","Steffen Koch","Thomas Ertl"],"title":"CiteRivers: Visual Analytics of Citation Patterns","doi":"10.1109/TVCG.2015.2467621","abstract":"The exploration and analysis of scientific literature collections is an important task for effective knowledge management. Past interest in such document sets has spurred the development of numerous visualization approaches for their interactive analysis. They either focus on the textual content of publications, or on document metadata including authors and citations. Previously presented approaches for citation analysis aim primarily at the visualization of the structure of citation networks and their exploration. We extend the state-of-the-art by presenting an approach for the interactive visual analysis of the contents of scientific documents, and combine it with a new and flexible technique to analyze their citations. This technique facilitates user-steered aggregation of citations which are linked to the content of the citing publications using a highly interactive visualization approach. Through enriching the approach with additional interactive views of other important aspects of the data, we support the exploration of the dataset over time and enable users to analyze citation patterns, spot trends, and track long-term developments. We demonstrate the strengths of our approach through a use case and discuss it based on expert user feedback.","keywords":"scientific literature, visual document analysis, visual citation analysis, streamgraph, clustering","caption":"Fig. 1: CiteRivers consists of (a) the stream panel, (b) the level slider, (c) the citation aggregation panel, (d) the author panel, (e) the citation flow panel, (f) the categories slider, (g) the document trend plot.","img_size":{"width":1924,"height":1150},"subfigures":[{"x":8.746197042579816,"y":10.100371693270663,"width":1893.937907555863,"height":1123.5160954079502,"type":"interface","id":"interface-0"}],"visualizations":[{"x":9.538293216630223,"y":7.549234135667395,"width":1001.5317286652079,"height":588.8402625820569,"type":"area_chart","id":"area_chart-0"},{"x":12.26152434725727,"y":592.345225535111,"width":1014.0928677948557,"height":111.20702697276998,"type":"line_chart","id":"line_chart-5"},{"x":7.245900891578613,"y":1.754298888150768,"width":1905.859637433145,"height":702.6688219584645,"type":"sankey_diagram","id":"sankey_diagram-4"},{"x":14.57111597374182,"y":709.6280087527347,"width":981.4004376367615,"height":387.5273522975929,"type":"scatterplot","id":"scatterplot-1"},{"x":1096.6280087527352,"y":724.7264770240697,"width":797.7024070021879,"height":412.69146608315094,"type":"scatterplot","id":"scatterplot-2"},{"x":7.021881838074421,"y":5.032822757111597,"width":1006.5645514223193,"height":591.3566739606125,"type":"word_cloud","id":"word_cloud-3"}],"relations":[{"vislist":[{"vislist":[{"vislist":[{"vislist":["word_cloud-3"],"relation":null,"id":"group-3"},{"vislist":["area_chart-0"],"relation":null,"id":"group-2"}],"relation":"coordinated","id":"relation-1"}],"relation":null,"id":"group-5"},{"vislist":["sankey_diagram-4"],"relation":null,"id":"group-4"}],"relation":"nested","id":"relation-2"},{"vislist":[{"vislist":["line_chart-5","scatterplot-1",{"vislist":[{"vislist":["word_cloud-3"],"relation":null,"id":"group-3"},{"vislist":["area_chart-0"],"relation":null,"id":"group-2"}],"relation":"coordinated","id":"relation-1"}],"relation":null,"id":"group-6"}],"relation":"stacked","id":"relation-3"}]},"2707_0":{"comp":[["bar_chart","graph",["nested"]]],"visType":["bar_chart","graph"],"compType":["nested"],"compressed_tree":[{"composite_pattern":"nested","visualization_type":[["bar_chart"],["graph"]]}],"coOccurrence":[["bar_chart","graph",["coOccurrence"]]],"year":2015,"conference":["VAST"],"authors":["Maoyuan Sun","Peng Mi","Chris North","Naren Ramakrishnan"],"title":"BiSet: Semantic Edge Bundling with Biclusters for Sensemaking","doi":"10.1109/TVCG.2015.2467813","abstract":"Identifying coordinated relationships is an important task in data analytics. For example, an intelligence analyst might want to discover three suspicious people who all visited the same four cities. Existing techniques that display individual relationships, such as between lists of entities, require repetitious manual selection and significant mental aggregation in cluttered visualizations to find coordinated relationships. In this paper, we present BiSet, a visual analytics technique to support interactive exploration of coordinated relationships. In BiSet, we model coordinated relationships as biclusters and algorithmically mine them from a dataset. Then, we visualize the biclusters in context as bundled edges between sets of related entities. Thus, bundles enable analysts to infer task-oriented semantic insights about potentially coordinated activities. We make bundles as first class objects and add a new layer, \u201cin-between\u201d, to contain these bundle objects. Based on this, bundles serve to organize entities represented in lists and visually reveal their membership. Users can interact with edge bundles to organize related entities, and vice versa, for sensemaking purposes. With a usage scenario, we demonstrate how BiSet supports the exploration of coordinated relationships in text analytics.","keywords":"Bicluster, coordinated relationship, semantic edge bundling","caption":"Fig. 1. An overview of BiSet. Entities are represented in lists. In the space between each neighboring pair of lists, BiSet adds a \u201cin-between\u201d layer, displaying edges. BiSet bundles edges based on biclusters and allows users to directly manipulate bundles. The bundles can reveal task-oriented semantic insights about coordinated relationships. BiSet also applies accumulated highlighting to entities, bundles and edges to indicate highly shared entities and relationships.","img_size":{"width":1814,"height":599},"subfigures":[{"x":10.085086960184842,"y":9.500020894072378,"width":1796.4649431527985,"height":583.9466403305543,"type":"interface","id":"interface-0"}],"visualizations":[{"x":13.021578561308129,"y":5.986462775547774,"width":205.49719280848524,"height":586.2343230426112,"type":"bar_chart","id":"bar_chart-0"},{"x":542.523547761086,"y":7.247181749832959,"width":201.71503588562973,"height":584.973604068326,"type":"bar_chart","id":"bar_chart-1"},{"x":335.7656359783156,"y":92.97607200122557,"width":60.514510765688904,"height":356.7834697227074,"type":"bar_chart","id":"bar_chart-2"},{"x":871.5712000495195,"y":31.200842261251477,"width":69.33954358568519,"height":201.71503588562965,"type":"bar_chart","id":"bar_chart-3"},{"x":1070.7647979865783,"y":7.247181749832959,"width":202.975754859915,"height":248.36163793418157,"type":"bar_chart","id":"bar_chart-4"},{"x":1592.3125196685453,"y":3.140365057608732,"width":216.3303836457269,"height":584.2215749953459,"type":"bar_chart","id":"bar_chart-5"},{"x":11.760859587022946,"y":7.247181749832959,"width":1796.882043727249,"height":584.000932859632,"type":"graph","id":"graph-6"}],"relations":[{"vislist":[{"vislist":["bar_chart-0","bar_chart-1","bar_chart-2","bar_chart-3","bar_chart-4","bar_chart-5"],"relation":null,"id":"group-2"},{"vislist":["graph-6"],"relation":null,"id":"group-3"}],"relation":"nested","id":"relation-1"}]},"2711_0":{"comp":[["glyph_based","graph",["nested"]],["word_cloud","sunburst_icicle",["nested"]],["heatmap","map",["coordinated"]],["scatterplot","map",["coordinated"]],["table","comb",["annotated"]]],"visType":["glyph_based","graph","word_cloud","sunburst_icicle","heatmap","map","scatterplot","table","comb"],"compType":["nested","coordinated","annotated"],"compressed_tree":[{"composite_pattern":"annotated","visualization_type":[["table"],[{"composite_pattern":"coordinated","visualization_type":[["heatmap","scatterplot"],["map"]]}]]},{"composite_pattern":"nested","visualization_type":[["glyph_based"],["graph"]]},{"composite_pattern":"nested","visualization_type":[["word_cloud"],["sunburst_icicle"]]}],"coOccurrence":[["heatmap","scatterplot",["coOccurrence"]],["heatmap","map",["coOccurrence"]],["heatmap","table",["coOccurrence"]],["heatmap","glyph_based",["coOccurrence"]],["heatmap","graph",["coOccurrence"]],["heatmap","word_cloud",["coOccurrence"]],["heatmap","sunburst_icicle",["coOccurrence"]],["scatterplot","map",["coOccurrence"]],["scatterplot","table",["coOccurrence"]],["scatterplot","glyph_based",["coOccurrence"]],["scatterplot","graph",["coOccurrence"]],["scatterplot","word_cloud",["coOccurrence"]],["scatterplot","sunburst_icicle",["coOccurrence"]],["map","table",["coOccurrence"]],["map","glyph_based",["coOccurrence"]],["map","graph",["coOccurrence"]],["map","word_cloud",["coOccurrence"]],["map","sunburst_icicle",["coOccurrence"]],["table","glyph_based",["coOccurrence"]],["table","graph",["coOccurrence"]],["table","word_cloud",["coOccurrence"]],["table","sunburst_icicle",["coOccurrence"]],["glyph_based","graph",["coOccurrence"]],["glyph_based","word_cloud",["coOccurrence"]],["glyph_based","sunburst_icicle",["coOccurrence"]],["graph","word_cloud",["coOccurrence"]],["graph","sunburst_icicle",["coOccurrence"]],["word_cloud","sunburst_icicle",["coOccurrence"]]],"year":2015,"conference":["VAST"],"authors":["Isaac Cho","Wenwen Dou","Xiaoyu Wang","Eric Sauda","William Ribarsky"],"title":"VAiRoma: A Visual Analytics System for Making Sense of Places, Times, and Events in Roman History","doi":"10.1109/TVCG.2015.2467971","abstract":"Learning and gaining knowledge of Roman history is an area of interest for students and citizens at large. This is an example of a subject with great sweep (with many interrelated sub-topics over, in this case, a 3,000 year history) that is hard to grasp by any individual and, in its full detail, is not available as a coherent story. In this paper, we propose a visual analytics approach to construct a data driven view of Roman history based on a large collection of Wikipedia articles. Extracting and enabling the discovery of useful knowledge on events, places, times, and their connections from large amounts of textual data has always been a challenging task. To this aim, we introduce VAiRoma, a visual analytics system that couples state-of-the-art text analysis methods with an intuitive visual interface to help users make sense of events, places, times, and more importantly, the relationships between them. VAiRoma goes beyond textual content exploration, as it permits users to compare, make connections, and externalize the findings all within the visual interface. As a result, VAiRoma allows users to learn and create new knowledge regarding Roman history in an informed way. We evaluated VAiRoma with 16 participants through a user study, with the task being to learn about roman piazzas through finding relevant articles and new relationships. Our study results showed that the VAiRoma system enables the participants to find more relevant articles and connections compared to Web searches and literature search conducted in a roman library. Subjective feedback on VAiRoma was also very positive. In addition, we ran two case studies that demonstrate how VAiRoma can be used for deeper analysis, permitting the rapid discovery and analysis of a small number of key documents even when the original collection contains hundreds of thousands of documents.","keywords":"Visual Analytics, Text Analytics, Wikipedia","caption":"Fig. 1.  Overview of VAiRoma Interface.  The interface has three main views: Timeline view (A), Geographic view (B) and Topic view(C). A user-generated annotation is shown in the Timeline view.","img_size":{"width":1935,"height":1092},"subfigures":[{"x":42.80705774427206,"y":13.92240689040075,"width":1873.2494588654622,"height":1041.7816687091472,"type":"interface","id":"interface-0"}],"visualizations":[{"x":67.85448577680526,"y":673.8380743982495,"width":1816.0175054704591,"height":332.14004376367615,"type":"area_chart","id":"area_chart-0"},{"x":980.6422319474838,"y":112.30634573304152,"width":936.6827133479212,"height":580.6477024070022,"type":"glyph_based","id":"glyph_based-1"},{"x":980.6422319474838,"y":112.30634573304152,"width":941.4617067833697,"height":580.6477024070022,"type":"graph","id":"graph-2"},{"x":232.72975929978122,"y":124.25382932166303,"width":738.3544857768053,"height":559.1422319474835,"type":"heatmap","id":"heatmap-3"},{"x":230.3402625820569,"y":121.86433260393875,"width":745.522975929978,"height":561.5317286652079,"type":"map","id":"map-4"},{"x":232.53801071897604,"y":120.44219705445727,"width":748.271272618111,"height":561.297415572723,"type":"scatterplot","id":"scatterplot-5"},{"x":1261.7778487591956,"y":454.2613040269826,"width":491.4770810383849,"height":270.30056288529204,"type":"sunburst_icicle","id":"sunburst_icicle-10"},{"x":697.056791327562,"y":235.08873080060866,"width":265.6798769425267,"height":349.1244099557668,"type":"table","id":"table-6"},{"x":1352.415297369628,"y":536.4101012188031,"width":322.433585613178,"height":174.4832160030344,"type":"word_cloud","id":"word_cloud-9"}],"relations":[{"vislist":[{"vislist":["table-6"],"relation":null,"id":"group-3"},{"vislist":[{"vislist":[{"vislist":["heatmap-3","scatterplot-5"],"relation":null,"id":"group-1"},{"vislist":["map-4"],"relation":null,"id":"group-0"}],"relation":"coordinated","id":"relation-0"}],"relation":null,"id":"group-2"}],"relation":"annotated","id":"relation-1"},{"vislist":[{"vislist":["glyph_based-1"],"relation":null,"id":"group-5"},{"vislist":["graph-2"],"relation":null,"id":"group-4"}],"relation":"nested","id":"relation-2"},{"vislist":[{"vislist":["word_cloud-9"],"relation":null,"id":"group-7"},{"vislist":["sunburst_icicle-10"],"relation":null,"id":"group-6"}],"relation":"nested","id":"relation-3"}]},"2713_0":{"comp":[["sunburst_icicle","sankey_diagram",["nested"]]],"visType":["sunburst_icicle","sankey_diagram"],"compType":["nested"],"compressed_tree":[{"composite_pattern":"nested","visualization_type":[["sunburst_icicle"],["sankey_diagram"]]}],"coOccurrence":[["sunburst_icicle","sankey_diagram",["coOccurrence"]]],"year":2015,"conference":["VAST"],"authors":["Johannes Sorger","Thomas Ortner","Christian Luksch","Michael Schw\xe4rzler","M. Eduard Gr\xf6ller","Harald Piringer"],"title":"LiteVis: Integrated Visualization for Simulation-Based Decision Support in Lighting Design","doi":"10.1109/TVCG.2015.2468011","abstract":"State-of-the-art lighting design is based on physically accurate lighting simulations of scenes such as offices. The simulation results support lighting designers in the creation of lighting configurations, which must meet contradicting customer objectives regarding quality and price while conforming to industry standards. However, current tools for lighting design impede rapid feedback cycles. On the one side, they decouple analysis and simulation specification. On the other side, they lack capabilities for a detailed comparison of multiple configurations. The primary contribution of this paper is a design study of LiteVis, a system for efficient decision support in lighting design. LiteVis tightly integrates global illumination-based lighting simulation, a spatial representation of the scene, and non-spatial visualizations of parameters and result indicators. This enables an efficient iterative cycle of simulation parametrization and analysis. Specifically, a novel visualization supports decision making by ranking simulated lighting configurations with regard to a weight-based prioritization of objectives that considers both spatial and non-spatial characteristics. In the spatial domain, novel concepts support a detailed comparison of illumination scenarios. We demonstrate LiteVis using a real-world use case and report qualitative feedback of lighting designers. This feedback indicates that LiteVis successfully supports lighting designers to achieve key tasks more efficiently and with greater certainty.","keywords":"Integrating Spatial and Non-Spatial Data Visualization, Visualization in Physical Sciences and Engineering, Coordinated and Multiple Views, Visual Knowledge Discovery","caption":"Fig. 1. Comparing lighting parametrizations according to different metrics in the LiteVis workspace. Left: the Simulation View displays a false color rendering encoding illumination quality. For each table, floating annotations show a binned histogram of illumination values from selected simulation runs. Right: the Simulation Ranking View shows a ranking of simulated lighting parametrizations according to user defined importance values for spatial measurement surfaces and abstracted result indicators.","img_size":{"width":2033,"height":768},"subfigures":[{"x":8.316427354357602,"y":12.352534216859238,"width":2001.6009021552554,"height":731.486044722743,"type":"interface","id":"interface-0"}],"visualizations":[{"x":1189.0806451612907,"y":501.64973686896025,"width":830.1129032258068,"height":247.87578051866686,"type":"bar_chart","id":"bar_chart-0"},{"x":1195.061754080688,"y":17.983708998128282,"width":819.1149649781116,"height":471.869254269379,"type":"sankey_diagram","id":"sankey_diagram-2"},{"x":1185.3754425870816,"y":10.616881201631287,"width":828.7129503147193,"height":480.8368057421965,"type":"sunburst_icicle","id":"sunburst_icicle-1"}],"relations":[{"vislist":[{"vislist":["sunburst_icicle-1"],"relation":null,"id":"group-1"},{"vislist":["sankey_diagram-2"],"relation":null,"id":"group-0"}],"relation":"nested","id":"relation-0"}]},"2727_3":{"comp":[["graph","area_chart",["nested"]],["area_chart","comb",["stacked"]],["comb","area_chart",["stacked"]]],"visType":["graph","area_chart","comb"],"compType":["nested","stacked"],"compressed_tree":[{"composite_pattern":"stacked","visualization_type":[["area_chart",{"composite_pattern":"nested","visualization_type":[["graph"],["area_chart"]]}]]}],"coOccurrence":[["graph","area_chart",["coOccurrence"]]],"year":2015,"conference":["VAST"],"authors":["Qingsong Liu","Yifan Hu","Lei Shi","Xinzhu Mu","Yutao Zhang","Jie Tan"],"title":"EgoNetCloud: Event-based egocentric dynamic network visualization","doi":"10.1109/VAST.2015.7347632","abstract":"Event-based egocentric dynamic networks are an important class of networks widely seen in many domains. In this paper, we present a visual analytics approach for these networks by combining data-driven network simplifications with a novel visualization design - EgoNetCloud. In particular, an integrated data processing pipeline is proposed to prune, compress and filter the networks into smaller but salient abstractions. To accommodate the simplified network into the visual design, we introduce a constrained graph layout algorithm on the dynamic network. Through a real-life case study as well as conversations with the domain expert, we demonstrate the effectiveness of the EgoNetCloud design and system in completing analysis tasks on event-based dynamic networks. The user study comparing EgoNetCloud with a working system on academic search confirms the effectiveness and convenience of our visual analytics based approach.","keywords":"","caption":"Figure 4: The EgoNetCloud system interface of Prof. Tang\u2019s egocentric network from AMiner: (a) the control panel in the Left; (b) the main EgoNetCloud visualization in the center; (c) the static egocentric network view in the top-right; (d) the detail panel in the bottom-right. The NetCloud mode is selected in this figure, so that only the connections among alter nodes are drawn.","img_size":{"width":1611,"height":789},"subfigures":[{"x":10.109030657399837,"y":10.321619467727666,"width":1589.611824681653,"height":769.5279132577875,"type":"interface","id":"interface-0"}],"visualizations":[{"x":334.00328947368433,"y":550.2236842105265,"width":847.8289473684213,"height":224.93421052631584,"type":"area_chart","id":"area_chart-0"},{"x":318.43092105263173,"y":34.60526315789469,"width":868.5921052631579,"height":512.1578947368424,"type":"area_chart","id":"area_chart-1"},{"x":320.1611842105265,"y":34.60526315789469,"width":865.1315789473688,"height":510.4276315789476,"type":"graph","id":"graph-2"},{"x":1249.3125000000002,"y":103.81578947368419,"width":349.5131578947371,"height":344.32236842105283,"type":"graph","id":"graph-3"}],"relations":[{"vislist":[{"vislist":["area_chart-0",{"vislist":[{"vislist":["graph-2"],"relation":null,"id":"group-1"},{"vislist":["area_chart-1"],"relation":null,"id":"group-0"}],"relation":"nested","id":"relation-0"}],"relation":null,"id":"group-2"}],"relation":"stacked","id":"relation-1"}]},"2733_0":{"comp":[["heatmap","matrix",["nested"]],["map","matrix",["nested"]]],"visType":["heatmap","matrix","map"],"compType":["nested"],"compressed_tree":[{"composite_pattern":"nested","visualization_type":[["heatmap","map"],["matrix"]]}],"coOccurrence":[["heatmap","map",["coOccurrence"]],["heatmap","matrix",["coOccurrence"]],["map","matrix",["coOccurrence"]]],"year":2015,"conference":["VAST"],"authors":["Sujan Anreddy","Song Zhan","Andrew Merce","Jamie Dyer","J. Edward Swan"],"title":"Visual scalability of spatial ensemble uncertainty","doi":"10.1109/VAST.2015.7347671","abstract":"Weather Research and Forecasting (WRF) models simulate weather conditions by generating 2D numerical weather prediction ensemble members either through perturbing initial conditions or by changing different parameterization schemes, e.g., cumulus and microphysics schemes. These simulations are often used by weather analysts to analyze the nature of uncertainty attributed by these simulations to forecast weather conditions with good accuracy. The number of simulations used for forecasting is growing with the advent of increase in computing power. Hence, there is a need for providing better visual insights of uncertainty with growing number of ensemble members. We propose a geo visual analytical framework that uses visual analytics approach to resolve visual scalability of these ensemble members. Our approach naturally fits with the workflow of an analyst analyzing ensemble spatial uncertainty. Meteorologists evaluated our framework qualitatively and found it to be effective in acquiring insights of spatial uncertainty associated with multiple ensemble runs that are simulated using multiple parameterization schemes.","keywords":"","caption":"Figure 1: This figure demonstrates flow of insights using our analytical approach with respect to an ensemble dataset that contains 30 ensemble members of 850mb Temerature simulated for 73 hours as described previously. (a) This figure shows an interactive dendrogram where node at- tributes like node\u2019s shape and color are mapped to Cumulus while their corresponding edge colors are mapped to Planetary boundary layer(PBL) parameterization schemes. It provides insight on uncertainty with reference to parameterization schemes. The pattern in this dendrogram draws towards an insight that uncertainty is primarily driven by cumulus followed by PBL. Color Brewer scheme \u201cSet1\u201d is used for encoding categorical qualitative data like parameters belonging to parameterization schemes.[1] (b) This shows the spatial uncertainty between ensemble members 8, 14 and 22 based on the insights gained in the overview space. The pairwise comparisons of ensemble members (8, 22) and (14, 22), exhibit greater uncertainty compared to the pairwise comparison of ensemble members (8, 14). It presents spatial characteristics of uncertainty using knowledge gained from the insight in the analysis phase (a). The color Brewer scheme \u201cReds\u201d is used to encode sequential quantitative scalar spatial data. The color scale for ensemble members and pairwise comparisons is different even though we used the same color scheme to encode spatial data. The color scale for pairwise comparisons is normalized to its timestep.","img_size":{"width":1903,"height":891},"subfigures":[{"x":11.891232826122428,"y":6.271729928388428,"width":926.880558748131,"height":832.8947303304258,"type":"interface","id":"interface-0"},{"x":1020.7688317432459,"y":4.825224505764733,"width":873.2339854814661,"height":823.3617930449112,"type":"interface","id":"interface-1"}],"visualizations":[{"x":1034.361050328228,"y":13.64770240700219,"width":855.9059080962796,"height":818.8621444201314,"type":"heatmap","id":"heatmap-0"},{"x":1032.4113785557988,"y":17.547045951859957,"width":852.0065645514222,"height":805.2144420131293,"type":"map","id":"map-2"},{"x":1030.46170678337,"y":15.597374179431073,"width":855.9059080962803,"height":811.0634573304159,"type":"matrix","id":"matrix-1"},{"x":8.833698030634636,"y":13.64770240700219,"width":931.9431072210066,"height":440.62582056892785,"type":"tree","id":"tree-3"}],"relations":[{"vislist":[{"vislist":["heatmap-0","map-2"],"relation":null,"id":"group-2"},{"vislist":["matrix-1"],"relation":null,"id":"group-3"}],"relation":"nested","id":"relation-1"}]},"2737_2":{"comp":[["word_cloud","proportional_area_chart",["nested"]]],"visType":["word_cloud","proportional_area_chart"],"compType":["nested"],"compressed_tree":[{"composite_pattern":"nested","visualization_type":[["word_cloud"],["proportional_area_chart"]]}],"coOccurrence":[],"year":2015,"conference":["VAST"],"authors":["Haoling Dong","Siliang Tang","Si Li","Fei W","Yueting Zhuang"],"title":"HTMVS: Visualizing hierarchical topics and their evolution","doi":"10.1109/VAST.2015.7347675","abstract":"Topic model has been an active research area for many years, it can be used for discovering latent semantics and finding hidden knowledge in unstructured data corpus. In this paper, we investigated the problems in visualizing hierarchical topic and their evolution. The contribution of this paper is threefold, first we explore the static visualization of hierarchical topics using the `nested circle\' layout, and then in order to present the topic evolution over time, we extended a hierarchical topic model and employ topic transformation visualizations to track the arising, splitting and disappearing of certain topics under the dynamic topical hierarchy. Finally, a Hierarchical Topic Model Visualization System (HTMVS) is designed to take advantage of both static and dynamic hierarchical topic visualization.","keywords":"","caption":"Figure 3: the interface of HTMVS. (a) static visualization view. (b) dynamic visualization view. (c) representative image of active topic. (d) topic words of active topic. (e) word cloud of topic words. (f) timeline. (g) topic words search box. (h) representative docu- ments.","img_size":{"width":1024,"height":720},"subfigures":[{"x":19.720700233225333,"y":10.685325308943243,"width":423.04021920648023,"height":429.16368794239156,"type":"single","id":"single-0"},{"x":483.3373090746334,"y":9.591310568906493,"width":527.3880539984361,"height":408.73233708263535,"type":"single","id":"single-1"},{"x":644.3278471766515,"y":449.15365954783454,"width":368.6504999210076,"height":243.59329680812817,"type":"single","id":"single-2"},{"x":63.83355847377304,"y":460.2009756207386,"width":345.6318445530534,"height":206.74689487547334,"type":"single","id":"single-3"}],"visualizations":[{"x":15.472457031209844,"y":14.316344127229074,"width":432.11212931635185,"height":420.8767844020623,"type":"proportional_area_chart","id":"proportional_area_chart-4"},{"x":10.740849194729151,"y":0,"width":436.42752562225473,"height":438.5358711566618,"type":"word_cloud","id":"word_cloud-0"},{"x":481.9560761346999,"y":5.27086383601757,"width":406.91068814055626,"height":377.393850658858,"type":"word_cloud","id":"word_cloud-1"},{"x":845.6456808199121,"y":267.75988286969255,"width":138.09663250366043,"height":142.31332357247436,"type":"word_cloud","id":"word_cloud-2"},{"x":60.28696925329427,"y":455.40263543191804,"width":354.2020497803807,"height":213.99707174231332,"type":"word_cloud","id":"word_cloud-3"}],"relations":[{"vislist":[{"vislist":["word_cloud-0"],"relation":null,"id":"group-1"},{"vislist":["proportional_area_chart-4"],"relation":null,"id":"group-0"}],"relation":"nested","id":"relation-0"}]},"2743_0":{"comp":[["bar_chart","chord_diagram",["nested"]]],"visType":["bar_chart","chord_diagram"],"compType":["nested"],"compressed_tree":[{"composite_pattern":"nested","visualization_type":[["bar_chart"],["chord_diagram"]]}],"coOccurrence":[["bar_chart","chord_diagram",["coOccurrence"]]],"year":2015,"conference":["VAST"],"authors":["Jessica Peter","Steve James Szigeti","Ana Jofre","Sara Diamond"],"title":"Topicks: Visualizing complex topic models for user comprehension","doi":"10.1109/VAST.2015.7347681","abstract":"The interactive visualization of topic models is a promising approach to summarizing large sets of textual data. Topicks is the working title for a means to visualize topic modelling outputs. Incorporating a radial layout, users can view the relationships between topics, terms and the corpus as a whole. Interacting with topic and term nodes, as well as a related bar chart, provides the user with various ways to manipulate the visualization and explore the data. We describe the visualization and potential user interactions before discussing future work.","keywords":"","caption":"Figure 1: Topicks as is it appears after selecting terms.","img_size":{"width":909,"height":531},"subfigures":[{"x":8.526555383802316,"y":3.2231416012053513,"width":891.2216433503492,"height":520.9272400583211,"type":"interface","id":"interface-0"}],"visualizations":[{"x":657.7006578947371,"y":0,"width":243.375,"height":521.6842105263158,"type":"bar_chart","id":"bar_chart-0"},{"x":0,"y":0,"width":604.1348684210528,"height":507.7105263157897,"type":"bar_chart","id":"bar_chart-1"},{"x":0.9374999999999999,"y":0,"width":603.1973684210528,"height":505.3815789473687,"type":"chord_diagram","id":"chord_diagram-2"},{"x":0.9374999999999999,"y":1.1644736842105265,"width":603.1973684210528,"height":505.3815789473688,"type":"proportional_area_chart","id":"proportional_area_chart-3"}],"relations":[{"vislist":[{"vislist":["bar_chart-1"],"relation":null,"id":"group-2"},{"vislist":["chord_diagram-2"],"relation":null,"id":"group-1"}],"relation":"nested","id":"relation-0"}]},"2720_0":{"comp":[["others","graph",["nested"]]],"visType":["others","graph"],"compType":["nested"],"compressed_tree":[{"composite_pattern":"nested","visualization_type":[["others"],["graph"]]}],"coOccurrence":[],"year":2015,"conference":["VAST"],"authors":["Kristin A. Cook","Nick Cramer","David J. Israel","Michael Wolverton","Joe Bruce","Russ Burtner","Alex Endert"],"title":"Mixed-initiative visual analytics using task-driven recommendations","doi":"10.1109/VAST.2015.7347625","abstract":"Visual data analysis is composed of a collection of cognitive actions and tasks to decompose, internalize, and recombine data to produce knowledge and insight. Visual analytic tools provide interactive visual interfaces to data to support discovery and sensemaking tasks, including forming hypotheses, asking questions, and evaluating and organizing evidence. Myriad analytic models can be incorporated into visual analytic systems at the cost of increasing complexity in the analytic discourse between user and system. Techniques exist to increase the usability of interacting with analytic models, such as inferring data models from user interactions to steer the underlying models of the system via semantic interaction, shielding users from having to do so explicitly. Such approaches are often also referred to as mixed-initiative systems. Sensemaking researchers have called for development of tools that facilitate analytic sensemaking through a combination of human and automated activities. However, design guidelines do not exist for mixed-initiative visual analytic systems to support iterative sensemaking. In this paper, we present candidate design guidelines and introduce the Active Data Environment (ADE) prototype, a spatial workspace supporting the analytic process via task recommendations invoked by inferences about user interactions within the workspace. ADE recommends data and relationships based on a task model, enabling users to co-reason with the system about their data in a single, spatial workspace. This paper provides an illustrative use case, a technical description of ADE, and a discussion of the strengths and limitations of the approach.","keywords":"mixed-initiative visual analytics, task modeling, recommender systems, sensemaking","caption":"Figure 1: The ADE Canvas supports externalization of analytic thinking and displays recommendations in context of the ongoing analysis. a) In response to the user\u2019s entry of seeds, shown in green, ADE recommends data and relationships, shown in recommendation cards and dottedline connections. This Canvas shows the state after the user has entered some seeds directly on the Canvas and has \u201cpinned\u201d other locations from Google Earth. b) Vehicle route recommendations for Isia Vann are displayed in Google Earth. Each geospatial recommendation from ADE appears in a separate layer. c) The user suppresses other layers to show vehicle travel at night, revealing suspicious visits to the homes of Willem Vasco-Pais and Ada Campo-Corrente. The user \u201cpins to Canvas\u201d to create new seeds for these locations","img_size":{"width":1695,"height":671},"subfigures":[{"x":9.211633320949348,"y":10.622812445289949,"width":1148.4238790747488,"height":647.2926364112554,"type":"interface","id":"interface-0"},{"x":1220.969681442936,"y":15.331625859579344,"width":463.25703748834025,"height":246.45855657463477,"type":"interface","id":"interface-1"}],"visualizations":[{"x":50.09056244041945,"y":79.39180171591991,"width":1077.7550047664442,"height":584.9285033365112,"type":"graph","id":"graph-0"},{"x":1304.8484051170274,"y":370.5193543778575,"width":380.4076681095453,"height":268.8658135653896,"type":"graph","id":"graph-1"},{"x":1302.3546234509058,"y":22.83794089609149,"width":384.5662535748333,"height":243.98951382268834,"type":"graph","id":"graph-2"},{"x":60.32250207266472,"y":86.23511379776484,"width":1060.9712390257782,"height":577.7820034088609,"type":"others","id":"others-3"}],"relations":[{"vislist":[{"vislist":["others-3"],"relation":null,"id":"group-1"},{"vislist":["graph-0"],"relation":null,"id":"group-0"}],"relation":"nested","id":"relation-0"}]},"2752_10":{"comp":[["treemap","bar_chart",["nested"]]],"visType":["treemap","bar_chart"],"compType":["nested"],"compressed_tree":[{"composite_pattern":"nested","visualization_type":[["treemap"],["bar_chart"]]}],"coOccurrence":[["treemap","bar_chart",["coOccurrence"]]],"year":2016,"conference":["InfoVis"],"authors":["Bilal Alsallakh","Liu Ren"],"title":"PowerSet: A Comprehensive Visualization of Set Intersections","doi":"10.1109/TVCG.2016.2598496","abstract":"When analyzing a large amount of data, analysts often define groups over data elements that share certain properties. Using these groups as the unit of analysis not only reduces the data volume, but also allows detecting various patterns in the data. This involves analyzing intersection relations between these groups, and how the element attributes vary between these intersections. This kind of set-based analysis has various applications in a variety of domains, due to the generic and powerful notion of sets. However, visualizing intersections relations is challenging because their number grows exponentially with the number of sets. We present a novel technique based on Treemaps to provide a comprehensive overview of non-empty intersections in a set system in a scalable way. It enables gaining insight about how elements are distributed across these intersections as well as performing fine-grained analysis to explore and compare their attributes both in overview and in detail. Interaction allows querying and filtering these elements based on their set memberships. We demonstrate how our technique supports various use cases in data exploration and analysis by providing insights into set-based data, beyond the limits of state-of-the-art techniques.","keywords":"scalability;Set visualization;treemaps;interaction","caption":"Fig. 7. UsingPowerSetto support association rule mining:  each tilerepresents a potential rule, whose support and confidence are encodedin size and color respectively. Dark and large tiles correspond to signifi-cant and highly-predictive rules.","img_size":{"width":1045,"height":799},"subfigures":[{"x":10.80191205532277,"y":5.903320242366789,"width":1027.759911615626,"height":776.2797816822194,"type":"single","id":"single-0"}],"visualizations":[{"x":17.302188451456963,"y":8.036176297150881,"width":1018.0321606180585,"height":767.6486384394337,"type":"bar_chart","id":"bar_chart-2"},{"x":13.829162655838616,"y":2.728601480752944,"width":1028.4422358634085,"height":779.1444304748097,"type":"heatmap","id":"heatmap-0"},{"x":15.76588366137389,"y":2.728601480752944,"width":1026.505514857873,"height":779.9318930888364,"type":"treemap","id":"treemap-1"}],"relations":[{"vislist":[{"vislist":["treemap-1"],"relation":null,"id":"group-0"},{"vislist":["bar_chart-2"],"relation":null,"id":"group-1"}],"relation":"nested","id":"relation-0"}]},"2753_2":{"comp":[["stripe_graph","bar_chart",["nested"]],["comb","comb",["mirrored"]]],"visType":["stripe_graph","bar_chart","comb"],"compType":["nested","mirrored"],"compressed_tree":[{"composite_pattern":"nested","visualization_type":[["stripe_graph"],["bar_chart"]]},{"composite_pattern":"mirrored","visualization_type":[[{"composite_pattern":"nested","visualization_type":[["stripe_graph"],["bar_chart"]]}]]},{"composite_pattern":"mirrored","visualization_type":[[{"composite_pattern":"nested","visualization_type":[["stripe_graph"],["bar_chart"]]}]]},{"composite_pattern":"mirrored","visualization_type":[[{"composite_pattern":"nested","visualization_type":[["stripe_graph"],["bar_chart"]]}]]}],"coOccurrence":[["stripe_graph","bar_chart",["coOccurrence"]]],"year":2016,"conference":["InfoVis"],"authors":["Faisal Taher","Yvonne Jansen","Jonathan Woodruff","John Hardy","Kasper Hornb\xe6k","Jason Alexander"],"title":"Investigating the Use of a Dynamic Physical Bar Chart for Data Exploration and Presentation","doi":"10.1109/TVCG.2016.2598498","abstract":"Physical data representations, or data physicalizations, are a promising new medium to represent and communicate data. Previous work mostly studied passive physicalizations which require humans to perform all interactions manually. Dynamic shape-changing displays address this limitation and facilitate data exploration tasks such as sorting, navigating in data sets which exceed the fixed size of a given physical display, or preparing \u201cviews\u201d to communicate insights about data. However, it is currently unclear how people approach and interact with such data representations. We ran an exploratory study to investigate how non-experts made use of a dynamic physical bar chart for an open-ended data exploration and presentation task. We asked 16 participants to explore a data set on European values and to prepare a short presentation of their insights using a physical display. We analyze: (1) users\' body movements to understand how they approach and react to the physicalization, (2) their hand-gestures to understand how they interact with physical data, (3) system interactions to understand which subsets of the data they explored and which features they used in the process, and (4) strategies used to explore the data and present observations. We discuss the implications of our findings for the use of dynamic data physicalizations and avenues for future work.","keywords":"Shape-changing displays;physicalization;physical visualization;bar charts;user behaviour;data presentation","caption":"Fig. 3. Top: cinematic log visualization for all participants and both phases. Bottom: detailed breakdown of the different interactions, movements, and gestures averaged over all participants.","img_size":{"width":2074,"height":2584},"subfigures":[{"x":25.401203354942346,"y":15.79642256094598,"width":2030.262296806426,"height":2552.407154878106,"type":"interface","id":"interface-0"}],"visualizations":[{"x":42.423848236108995,"y":2098.929071879756,"width":636.9561316267532,"height":467.8208876354683,"type":"bar_chart","id":"bar_chart-0"},{"x":679.3799798628621,"y":1658.0978508386418,"width":741.3161757915884,"height":903.2541753577123,"type":"bar_chart","id":"bar_chart-1"},{"x":65.10444326965865,"y":1655.3300329099905,"width":666.3852664814107,"height":433.9252898018492,"type":"bar_chart","id":"bar_chart-2"},{"x":1454.822600053532,"y":1664.349546075891,"width":592.9807213394715,"height":496.9452831790945,"type":"bar_chart","id":"bar_chart-3"},{"x":1440.3110484932688,"y":2169.561667026541,"width":607.2302242616668,"height":405.61391967400306,"type":"bar_chart","id":"bar_chart-4"},{"x":108.1976573938507,"y":60.532942898975115,"width":1876.5212298682286,"height":503.18008784773065,"type":"bar_chart","id":"bar_chart-5"},{"x":104.41434846266452,"y":582.6295754026354,"width":1872.7379209370424,"height":533.4465592972182,"type":"bar_chart","id":"bar_chart-6"},{"x":108.1976573938507,"y":1097.1595900439238,"width":1865.1713030746707,"height":541.01317715959,"type":"bar_chart","id":"bar_chart-7"},{"x":105.10546139359735,"y":72.99435028248587,"width":1878.387947269303,"height":506.0941619585687,"type":"stripe_graph","id":"stripe_graph-8"},{"x":105.10546139359735,"y":583.954802259887,"width":1883.2542372881353,"height":515.8267419962335,"type":"stripe_graph","id":"stripe_graph-9"},{"x":103.34212383404855,"y":1109.5318606440503,"width":1876.665874761289,"height":522.6737048582197,"type":"stripe_graph","id":"stripe_graph-10"}],"relations":[{"vislist":[{"vislist":["stripe_graph-9"],"relation":null,"id":"group-2"},{"vislist":["bar_chart-6"],"relation":null,"id":"group-3"}],"relation":"nested","id":"relation-1"},{"vislist":[{"vislist":[{"vislist":[{"vislist":["stripe_graph-8"],"relation":null,"id":"group-0"},{"vislist":["bar_chart-5"],"relation":null,"id":"group-1"}],"relation":"nested","id":"relation-0"}],"relation":null,"id":"group-6"}],"relation":"mirrored","id":"relation-3"},{"vislist":[{"vislist":[{"vislist":[{"vislist":["stripe_graph-10"],"relation":null,"id":"group-4"},{"vislist":["bar_chart-7"],"relation":null,"id":"group-5"}],"relation":"nested","id":"relation-2"}],"relation":null,"id":"group-7"}],"relation":"mirrored","id":"relation-4"},{"vislist":[{"vislist":[{"vislist":[{"vislist":["stripe_graph-10"],"relation":null,"id":"group-4"},{"vislist":["bar_chart-7"],"relation":null,"id":"group-5"}],"relation":"nested","id":"relation-2"}],"relation":null,"id":"group-8"}],"relation":"mirrored","id":"relation-5"}]},"2760_5":{"comp":[["bar_chart","table",["nested"]]],"visType":["bar_chart","table"],"compType":["nested"],"compressed_tree":[{"composite_pattern":"nested","visualization_type":[["bar_chart"],["table"]]}],"coOccurrence":[["bar_chart","table",["coOccurrence"]]],"year":2016,"conference":["InfoVis"],"authors":["Stephan Pajer","Marc Streit","Thomas Torsney-Weir","Florian Spechtenhauser","Torsten M\xf6ller","Harald Piringer"],"title":"WeightLifter: Visual Weight Space Exploration for Multi-Criteria Decision Making","doi":"10.1109/TVCG.2016.2598589","abstract":"A common strategy in Multi-Criteria Decision Making (MCDM) is to rank alternative solutions by weighted summary scores. Weights, however, are often abstract to the decision maker and can only be set by vague intuition. While previous work supports a point-wise exploration of weight spaces, we argue that MCDM can benefit from a regional and global visual analysis of weight spaces. Our main contribution is WeightLifter, a novel interactive visualization technique for weight-based MCDM that facilitates the exploration of weight spaces with up to ten criteria. Our technique enables users to better understand the sensitivity of a decision to changes of weights, to efficiently localize weight regions where a given solution ranks high, and to filter out solutions which do not rank high enough for any plausible combination of weights. We provide a comprehensive requirement analysis for weight-based MCDM and describe an interactive workflow that meets these requirements. For evaluation, we describe a usage scenario of WeightLifter in automotive engineering and report qualitative feedback from users of a deployed version as well as preliminary feedback from decision makers in multiple domains. This feedback confirms that WeightLifter increases both the efficiency of weight-based MCDM and the awareness of uncertainty in the ultimate decisions.","keywords":"Visual analysis;decision making;multi-objective optimization;interactive ranking;rank sensitivity","caption":"Fig. 6: Integration of WeightLifter with other views. The Ranked Solution Details involves multiple columns (a, b, c) and the current weighting (d) to list a reduced set of decision-relevant solutions . Solutions can be filtered, e.g., by brushes in a linked parallel coordinate plot (e). Excluded solutions are shown as context (f). All views highlight the current solution (blue) and a comparison solution (purple).","img_size":{"width":2130,"height":867},"subfigures":[{"x":7.024609412490963,"y":6.652291015323452,"width":2114.4037030697677,"height":850.5984445247909,"type":"interface","id":"interface-0"}],"visualizations":[{"x":718.7988560533842,"y":540.1015252621544,"width":424.375595805529,"height":225.38608198284075,"type":"bar_chart","id":"bar_chart-0"},{"x":962.4594852240228,"y":820.3112488083887,"width":265.9961868446138,"height":32.488083889418476,"type":"bar_chart","id":"bar_chart-1"},{"x":1165.5100095328878,"y":542.132030505243,"width":310.6673021925644,"height":229.44709246901806,"type":"bar_chart","id":"bar_chart-2"},{"x":1133.1618885414848,"y":47.862801969947405,"width":335.2529657029934,"height":369.7268011074169,"type":"others","id":"others-6"},{"x":1535.0619637750237,"y":4.696346991692097,"width":588.8465204957101,"height":857.6073060166158,"type":"parallel_coordinate","id":"parallel_coordinate-3"},{"x":239.43458759265408,"y":58.87178265014294,"width":781.9228673335854,"height":361.42993326978024,"type":"parallel_coordinate","id":"parallel_coordinate-4"},{"x":89.92949628809222,"y":540.1015252621537,"width":1388.73763444652,"height":282.240228789323,"type":"table","id":"table-5"}],"relations":[{"vislist":[{"vislist":["bar_chart-2","bar_chart-0"],"relation":null,"id":"group-0"},{"vislist":["table-5"],"relation":null,"id":"group-1"}],"relation":"nested","id":"relation-0"}]},"2763_1":{"comp":[["bar_chart","table",["nested"]],["comb","table",["nested"]],["proportional_area_chart","matrix",["coordinated"]]],"visType":["bar_chart","table","comb","proportional_area_chart","matrix"],"compType":["nested","coordinated"],"compressed_tree":[{"composite_pattern":"nested","visualization_type":[["bar_chart",{"composite_pattern":"coordinated","visualization_type":[["proportional_area_chart"],["matrix"]]}],["table"]]}],"coOccurrence":[["proportional_area_chart","matrix",["coOccurrence"]],["proportional_area_chart","bar_chart",["coOccurrence"]],["proportional_area_chart","table",["coOccurrence"]],["matrix","bar_chart",["coOccurrence"]],["matrix","table",["coOccurrence"]],["bar_chart","table",["coOccurrence"]]],"year":2016,"conference":["InfoVis"],"authors":["Clemens Arbesser","Florian Spechtenhauser","Thomas M\xfchlbacher","Harald Piringer"],"title":"Visplause: Visual Data Quality Assessment of Many Time Series Using Plausibility Checks","doi":"10.1109/TVCG.2016.2598592","abstract":"Trends like decentralized energy production lead to an exploding number of time series from sensors and other sources that need to be assessed regarding their data quality (DQ). While the identification of DQ problems for such routinely collected data is typically based on existing automated plausibility checks, an efficient inspection and validation of check results for hundreds or thousands of time series is challenging. The main contribution of this paper is the validated design of Visplause, a system to support an efficient inspection of DQ problems for many time series. The key idea of Visplause is to utilize meta-information concerning the semantics of both the time series and the plausibility checks for structuring and summarizing results of DQ checks in a flexible way. Linked views enable users to inspect anomalies in detail and to generate hypotheses about possible causes. The design of Visplause was guided by goals derived from a comprehensive task analysis with domain experts in the energy sector. We reflect on the design process by discussing design decisions at four stages and we identify lessons learned. We also report feedback from domain experts after using Visplause for a period of one month. This feedback suggests significant efficiency gains for DQ assessment, increased confidence in the DQ, and the applicability of Visplause to summarize indicators also outside the context of DQ.","keywords":"Data Quality Assessment;High-Dimensional Data;Hierarchical Aggregation;Linked Views","caption":"Fig. 2. Visplause consists of multiple linked parts. The DQ overview provides a hierarchical overview of check results (a). In this example, checks are aggregated by \u2018Sub-class\u2019 and \u2018Time Series\u2019 to reveal the most prevalent types of DQ issues and their source. DQ overview columns show additional information such as (b) the number of checks and time series, (c) the percentage of affected data, (d) the distribution of check indications over time and (e) the severity of check indications. (f) The current filter shows only checks with at least one check indication. (g) Non-zero at night anomalies at power plant PV 94 in January 2011 have been selected. (h, i) Linked views provide details of the selected data anomalies for validation.","img_size":{"width":2149,"height":1037},"subfigures":[{"x":35.254603694540414,"y":10.285495090012176,"width":2095.6604542682007,"height":1008.6301418526589,"type":"interface","id":"interface-0"}],"visualizations":[{"x":505.89604685212294,"y":71.36017569546121,"width":757.6325036603225,"height":446.380673499268,"type":"bar_chart","id":"bar_chart-0"},{"x":267.5226939970717,"y":71.36017569546121,"width":110.83601756954619,"height":453.97218155197663,"type":"bar_chart","id":"bar_chart-1"},{"x":378.3587115666179,"y":74.39677891654466,"width":113.87262079062953,"height":450.9355783308931,"type":"bar_chart","id":"bar_chart-2"},{"x":26.11273792093701,"y":554.1800878477306,"width":1641.284040995608,"height":478.08167286346827,"type":"line_chart","id":"line_chart-3"},{"x":1262.0102489019032,"y":74.39677891654466,"width":882.1332357247445,"height":464.60029282576863,"type":"matrix","id":"matrix-4"},{"x":1269.5844922079007,"y":73.25915727312297,"width":868.4768660677763,"height":459.57246125748463,"type":"proportional_area_chart","id":"proportional_area_chart-10"},{"x":35.66959573559961,"y":73.25915727312295,"width":2096.6163183252406,"height":459.5724612574859,"type":"table","id":"table-11"},{"x":1755.4582723279655,"y":543.5519765739385,"width":384.13030746705726,"height":488.7097841372603,"type":"table","id":"table-5"}],"relations":[{"vislist":[{"vislist":["bar_chart-0","bar_chart-1","bar_chart-2",{"vislist":[{"vislist":["proportional_area_chart-10"],"relation":null,"id":"group-7"},{"vislist":["matrix-4"],"relation":null,"id":"group-8"}],"relation":"coordinated","id":"relation-3"}],"relation":null,"id":"group-9"},{"vislist":["table-11"],"relation":null,"id":"group-10"}],"relation":"nested","id":"relation-4"}]},"2824_0":{"comp":[["glyph_based","scatterplot",["nested"]],["area_chart","comb",["stacked"]],["comb","area_chart",["stacked"]]],"visType":["glyph_based","scatterplot","area_chart","comb"],"compType":["nested","stacked"],"compressed_tree":[{"composite_pattern":"stacked","visualization_type":[["area_chart",{"composite_pattern":"nested","visualization_type":[["glyph_based"],["scatterplot"]]}]]}],"coOccurrence":[["glyph_based","scatterplot",["coOccurrence"]],["glyph_based","area_chart",["coOccurrence"]],["scatterplot","area_chart",["coOccurrence"]]],"year":2016,"conference":["VAST"],"authors":["Bum Chul Kwon","Hannah Kim","Emily Wall","Jaegul Choo","Haesun Park","Alex Endert"],"title":"AxiSketcher: Interactive Nonlinear Axis Mapping of Visualizations through User Drawings","doi":"10.1109/TVCG.2016.2598446","abstract":"Visual analytics techniques help users explore high-dimensional data. However, it is often challenging for users to express their domain knowledge in order to steer the underlying data model, especially when they have little attribute-level knowledge. Furthermore, users\' complex, high-level domain knowledge, compared to low-level attributes, posits even greater challenges. To overcome these challenges, we introduce a technique to interpret a user\'s drawings with an interactive, nonlinear axis mapping approach called AxiSketcher. This technique enables users to impose their domain knowledge on a visualization by allowing interaction with data entries rather than with data attributes. The proposed interaction is performed through directly sketching lines over the visualization. Using this technique, users can draw lines over selected data points, and the system forms the axes that represent a nonlinear, weighted combination of multidimensional attributes. In this paper, we describe our techniques in three areas: 1) the design space of sketching methods for eliciting users\' nonlinear domain knowledge; 2) the underlying model that translates users\' input, extracts patterns behind the selected data points, and results in nonlinear axes reflecting users\' complex intent; and 3) the interactive visualization for viewing, assessing, and reconstructing the newly formed, nonlinear axes.","keywords":"axis mapping;interactive model steering;sketch;axis visualization;human-centered visual analytics","caption":"Fig. 1: An overview of our visual analytics system, called AxiSketcher. (a) Dashboard allows users to choose a sketching method, to change axes to previously constructed axes, and to change other peripheral settings; (b) Axis Rainbow visualizes nonlinear progression of data attributes in ThemeRiver-style visualizations; (c) Scatterplot shows data points mapped to user-defined axes; (d) Detail View shows the original attribute values of selected data items as a table (top) and an aster plot (bottom).","img_size":{"width":1868,"height":1047},"subfigures":[{"x":29.949441764403712,"y":20.61189098437759,"width":1820.9720534012404,"height":1020.0772392968265,"type":"interface","id":"interface-0"}],"visualizations":[{"x":346.8210749646394,"y":53.31258840169732,"width":143.64780763790657,"height":728.6053748231966,"type":"area_chart","id":"area_chart-0"},{"x":542.3005657708628,"y":780.4370579915136,"width":783.3988684582745,"height":235.4639321074966,"type":"area_chart","id":"area_chart-1"},{"x":517.8074712643677,"y":44.12642721746159,"width":818.344827586207,"height":766.1954022988505,"type":"glyph_based","id":"glyph_based-2"},{"x":523.0487977369165,"y":50.35077793493637,"width":807.0933521923623,"height":753.7807637906649,"type":"scatterplot","id":"scatterplot-3"},{"x":1365.6838755304102,"y":533.1258840169731,"width":438.34794908062264,"height":451.67609618104683,"type":"sector_chart","id":"sector_chart-4"}],"relations":[{"vislist":[{"vislist":["area_chart-0","area_chart-1",{"vislist":[{"vislist":["glyph_based-2"],"relation":null,"id":"group-0"},{"vislist":["scatterplot-3"],"relation":null,"id":"group-1"}],"relation":"nested","id":"relation-0"}],"relation":null,"id":"group-2"}],"relation":"stacked","id":"relation-1"}]},"2828_0":{"comp":[["others","graph",["nested"]],["others","area_chart",["stacked"]],["others","bar_chart",["stacked"]],["comb","graph",["nested"]],["graph","donut_chart",["nested"]],["area_chart","others",["stacked"]],["area_chart","bar_chart",["stacked"]],["bar_chart","area_chart",["stacked"]],["bar_chart","others",["stacked"]]],"visType":["others","graph","area_chart","bar_chart","comb","donut_chart"],"compType":["nested","stacked"],"compressed_tree":[{"composite_pattern":"nested","visualization_type":[["others",{"composite_pattern":"stacked","visualization_type":[["area_chart","others","bar_chart"]]}],["graph"]]},{"composite_pattern":"nested","visualization_type":[["graph"],["donut_chart"]]}],"coOccurrence":[["area_chart","bar_chart",["coOccurrence"]],["area_chart","others",["coOccurrence"]],["area_chart","graph",["coOccurrence"]],["area_chart","donut_chart",["coOccurrence"]],["bar_chart","others",["coOccurrence"]],["bar_chart","graph",["coOccurrence"]],["bar_chart","donut_chart",["coOccurrence"]],["others","graph",["coOccurrence"]],["others","donut_chart",["coOccurrence"]],["graph","donut_chart",["coOccurrence"]]],"year":2016,"conference":["VAST"],"authors":["Qiaomu Shen","Tongshuang Wu","Haiyan Yang","Yanhong Wu","Huamin Qu","Weiwei Cui"],"title":"NameClarifier: A Visual Analytics System for Author Name Disambiguation","doi":"10.1109/TVCG.2016.2598465","abstract":"In this paper, we present a novel visual analytics system called NameClarifier to interactively disambiguate author names in publications by keeping humans in the loop. Specifically, NameClarifier quantifies and visualizes the similarities between ambiguous names and those that have been confirmed in digital libraries. The similarities are calculated using three key factors, namely, co-authorships, publication venues, and temporal information. Our system estimates all possible allocations, and then provides visual cues to users to help them validate every ambiguous case. By looping users in the disambiguation process, our system can achieve more reliable results than general data mining models for highly ambiguous cases. In addition, once an ambiguous case is resolved, the result is instantly added back to our system and serves as additional cues for all the remaining unidentified names. In this way, we open up the black box in traditional disambiguation processes, and help intuitively and comprehensively explain why the corresponding classifications should hold. We conducted two use cases and an expert review to demonstrate the effectiveness of NameClarifier.","keywords":"Name disambiguation;analytical reasoning","caption":"Fig. 1. Interface for the NameClarifier, which contains the following: (A) a relation view that contrasts papers containing ambiguous author names with confirmed authors, resulting in easier classification of ambiguous names; (B) a group view that supports the relation view by assessing whether the ambiguous names have been correctly and comprehensively classified; (C) a temporal view that verifies whether a specific paper fits into a confirmed author\u2019s publication trajectory; and (D) a list containing all papers with ambiguous author names so that the users can always refer back to the original metadata.","img_size":{"width":1935,"height":940},"subfigures":[{"x":37.32732121193052,"y":22.154503842898702,"width":1872.9943553239946,"height":906.9189315832257,"type":"interface","id":"interface-0"}],"visualizations":[{"x":356.5629183400268,"y":51.59303882195448,"width":445.4618473895581,"height":51.59303882195448,"type":"area_chart","id":"area_chart-0"},{"x":159.87120629043235,"y":190.67615658362962,"width":82.03521928065699,"height":398.0782918149464,"type":"area_chart","id":"area_chart-8"},{"x":45.364672972813125,"y":191.80147058823516,"width":115.57450260587972,"height":397.4264705882351,"type":"bar_chart","id":"bar_chart-1"},{"x":352.8202846975089,"y":110.39145907473308,"width":461.6370106761565,"height":811.2099644128111,"type":"bar_chart","id":"bar_chart-2"},{"x":1297.8212851405622,"y":59.143239625167325,"width":538.5809906291834,"height":538.5809906291834,"type":"donut_chart","id":"donut_chart-3"},{"x":47.00468540829988,"y":47.81793842034806,"width":1096.037483266399,"height":874.5649263721552,"type":"graph","id":"graph-4"},{"x":1438.7583668005354,"y":115.76974564926371,"width":251.67336010709508,"height":354.859437751004,"type":"graph","id":"graph-5"},{"x":907.727576974565,"y":156.0374832663989,"width":213.9223560910308,"height":430.3614457831324,"type":"others","id":"others-6"},{"x":351.14768683273866,"y":108.64504921824938,"width":463.3096085409236,"height":814.7027841257787,"type":"others","id":"others-7"}],"relations":[{"vislist":[{"vislist":["others-6",{"vislist":[{"vislist":["area_chart-0","others-7","bar_chart-2"],"relation":null,"id":"group-3"}],"relation":"stacked","id":"relation-3"},{"vislist":[{"vislist":["bar_chart-1",{"vislist":[{"vislist":["area_chart-8"],"relation":null,"id":"group-1"}],"relation":"repeated","id":"relation-1"}],"relation":null,"id":"group-2"}],"relation":"stacked","id":"relation-2"}],"relation":null,"id":"group-4"},{"vislist":["graph-4"],"relation":null,"id":"group-5"}],"relation":"nested","id":"relation-4"},{"vislist":[{"vislist":["graph-5"],"relation":null,"id":"group-8"},{"vislist":["donut_chart-3"],"relation":null,"id":"group-9"}],"relation":"nested","id":"relation-6"}]},"2846_5":{"comp":[["bar_chart","parallel_coordinate",["nested"]],["line_chart","parallel_coordinate",["nested"]]],"visType":["bar_chart","parallel_coordinate","line_chart"],"compType":["nested"],"compressed_tree":[{"composite_pattern":"nested","visualization_type":[["bar_chart","line_chart"],["parallel_coordinate"]]}],"coOccurrence":[["bar_chart","line_chart",["coOccurrence"]],["bar_chart","parallel_coordinate",["coOccurrence"]],["line_chart","parallel_coordinate",["coOccurrence"]]],"year":2016,"conference":["VAST"],"authors":["Donghao Ren","Saleema Amershi","Bongshin Lee","Jina Suh","Jason D. Williams"],"title":"Squares: Supporting Interactive Performance Analysis for Multiclass Classifiers","doi":"10.1109/TVCG.2016.2598828","abstract":"Performance analysis is critical in applied machine learning because it influences the models practitioners produce. Current performance analysis tools suffer from issues including obscuring important characteristics of model behavior and dissociating performance from data. In this work, we present Squares, a performance visualization for multiclass classification problems. Squares supports estimating common performance metrics while displaying instance-level distribution information necessary for helping practitioners prioritize efforts and access data. Our controlled study shows that practitioners can assess performance significantly faster and more accurately with Squares than a confusion matrix, a common performance analysis tool in machine learning.","keywords":"Performance analysis;classification;usable machine learning","caption":"Fig. 6. Bi-directional coupling between the visualization and table allows users to view instance properties in the table by selecting boxes, strips, or stacks from the visualization, or locate interesting instances found in the table in the visualization.","img_size":{"width":2151,"height":852},"subfigures":[{"x":15.06513680612128,"y":27.270203279086598,"width":2123.9943883637166,"height":803.7155744048185,"type":"interface","id":"interface-0"}],"visualizations":[{"x":20.17823639774859,"y":140.14165103189492,"width":2019.1688555347093,"height":400.8742964352721,"type":"bar_chart","id":"bar_chart-0"},{"x":18.353442473394818,"y":134.95261887703626,"width":2019.427359883038,"height":56.73926284865785,"type":"line_chart","id":"line_chart-3"},{"x":13.452157598499063,"y":140.14165103189492,"width":2023.2045028142588,"height":395.49343339587244,"type":"parallel_coordinate","id":"parallel_coordinate-1"},{"x":185.6397748592871,"y":593.4793621013132,"width":1937.110694183865,"height":235.41275797373365,"type":"table","id":"table-2"}],"relations":[{"vislist":[{"vislist":["bar_chart-0","line_chart-3"],"relation":null,"id":"group-1"},{"vislist":["parallel_coordinate-1"],"relation":null,"id":"group-2"}],"relation":"nested","id":"relation-0"}]},"2847_0":{"comp":[["matrix","parallel_coordinate",["nested"]]],"visType":["matrix","parallel_coordinate"],"compType":["nested"],"compressed_tree":[{"composite_pattern":"nested","visualization_type":[["matrix"],["parallel_coordinate"]]}],"coOccurrence":[["matrix","parallel_coordinate",["coOccurrence"]]],"year":2016,"conference":["VAST"],"authors":["Gary K. L. Tam","Vivek Kothari","Min Chen"],"title":"An Analysis of Machine- and Human-Analytics in Classification","doi":"10.1109/TVCG.2016.2598829","abstract":"In this work, we present a study that traces the technical and cognitive processes in two visual analytics applications to a common theoretic model of soft knowledge that may be added into a visual analytics process for constructing a decision-tree model. Both case studies involved the development of classification models based on the \u201cbag of features\u201d approach. Both compared a visual analytics approach using parallel coordinates with a machine-learning approach using information theory. Both found that the visual analytics approach had some advantages over the machine learning approach, especially when sparse datasets were used as the ground truth. We examine various possible factors that may have contributed to such advantages, and collect empirical evidence for supporting the observation and reasoning of these factors. We propose an information-theoretic model as a common theoretic basis to explain the phenomena exhibited in these two case studies. Together we provide interconnected empirical and theoretical evidence to support the usefulness of visual analytics.","keywords":"information theory;Visual analytics;classification;decision tree;model;facial expression;visualization image","caption":"Fig. 1: A parallel coordinate plot used to aid model-developers in constructing a decision tree for classifying facial expressions. On the left, a model-developer can select facial features and time series attributes to investigate. On the main panel, each polyline represents a video and its attribute values are shown on the axes. The first axis indicates the classification labels. Scatterplots show the distributions of values and labels. Brushing is used to create and highlight decisions. The above example shows the three decisions used to obtain the smile classification.","img_size":{"width":2151,"height":660},"subfigures":[{"x":4.176401459995538,"y":12.613082340394785,"width":2139.5225351040517,"height":636.3342940783245,"type":"interface","id":"interface-0"}],"visualizations":[{"x":266.28800513149463,"y":80.95862732520845,"width":1866.7754971135341,"height":520.158434894163,"type":"parallel_coordinate","id":"parallel_coordinate-0"},{"x":533.9557408595253,"y":114.07216164207824,"width":74.50545221295705,"height":458.07055805003205,"type":"matrix","id":"matrix-1"},{"x":767.1302116741501,"y":112.69243104554198,"width":71.74599101988451,"height":458.0705580500321,"type":"matrix","id":"matrix-2"},{"x":996.1654906991663,"y":114.07216164207824,"width":63.46760744066705,"height":456.69082745349584,"type":"matrix","id":"matrix-3"},{"x":1221.0615779345733,"y":112.69243104554198,"width":64.84733803720337,"height":458.0705580500321,"type":"matrix","id":"matrix-4"},{"x":1336.958948043618,"y":115.4518922386145,"width":62.08787684413074,"height":455.3110968569596,"type":"matrix","id":"matrix-5"},{"x":1454.2360487491983,"y":114.07216164207824,"width":60.708146247594634,"height":458.07055805003205,"type":"matrix","id":"matrix-6"},{"x":1568.7536882617062,"y":114.07216164207824,"width":60.708146247594634,"height":456.69082745349584,"type":"matrix","id":"matrix-7"},{"x":33.11353431686979,"y":93.37620269403466,"width":175.22578576010264,"height":520.158434894163,"type":"tree","id":"tree-8"}],"relations":[{"vislist":[{"vislist":["matrix-1","matrix-2","matrix-3","matrix-4","matrix-5","matrix-6","matrix-7"],"relation":null,"id":"group-0"},{"vislist":["parallel_coordinate-0"],"relation":null,"id":"group-1"}],"relation":"nested","id":"relation-0"}]},"2849_0":{"comp":[["others","graph",["nested"]]],"visType":["others","graph"],"compType":["nested"],"compressed_tree":[{"composite_pattern":"nested","visualization_type":[["others"],["graph"]]}],"coOccurrence":[["others","graph",["coOccurrence"]]],"year":2016,"conference":["VAST"],"authors":["Mengchen Liu","Jiaxin Shi","Zhen Li","Chongxuan Li","Jun Zh","Shixia Liu"],"title":"Towards Better Analysis of Deep Convolutional Neural Networks","doi":"10.1109/TVCG.2016.2598831","abstract":"Deep convolutional neural networks (CNNs) have achieved breakthrough performance in many pattern recognition tasks such as image classification. However, the development of high-quality deep models typically relies on a substantial amount of trial-and-error, as there is still no clear understanding of when and why a deep model works. In this paper, we present a visual analytics approach for better understanding, diagnosing, and refining deep CNNs. We formulate a deep CNN as a directed acyclic graph. Based on this formulation, a hybrid visualization is developed to disclose the multiple facets of each neuron and the interactions between them. In particular, we introduce a hierarchical rectangle packing algorithm and a matrix reordering algorithm to show the derived features of a neuron cluster. We also propose a biclustering-based edge bundling method to reduce visual clutter caused by a large number of connections between neurons. We evaluated our method on a set of CNNs and the results are generally favorable.","keywords":"Deep convolutional neural networks;rectangle packing;matrix reordering;edge bundling;biclustering","caption":"Fig. 1. CNNVis, a visual analytics system that helps experts understand, diagnose, and refine deep CNNs.","img_size":{"width":1729,"height":1025},"subfigures":[{"x":9.965403990041823,"y":9.00250520487167,"width":1704.8681971885107,"height":1001.3947806896937,"type":"interface","id":"interface-0"}],"visualizations":[{"x":17.09900990099004,"y":20.2970297029703,"width":1697.701555869873,"height":998.9038189533238,"type":"graph","id":"graph-0"},{"x":16.54194845114991,"y":22.060195942277165,"width":1697.4411880878401,"height":997.64877861085,"type":"others","id":"others-1"}],"relations":[{"vislist":[{"vislist":["others-1"],"relation":null,"id":"group-0"},{"vislist":["graph-0"],"relation":null,"id":"group-1"}],"relation":"nested","id":"relation-0"}]},"2851_0":{"comp":[["bar_chart","area_chart",["nested"]],["bar_chart","comb",["stacked"]],["glyph_based","others",["nested"]],["proportional_area_chart","matrix",["coordinated"]],["matrix","comb",["stacked"]],["comb","matrix",["stacked"]],["comb","bar_chart",["stacked"]]],"visType":["bar_chart","area_chart","comb","glyph_based","others","proportional_area_chart","matrix"],"compType":["nested","stacked","coordinated"],"compressed_tree":[{"composite_pattern":"nested","visualization_type":[["bar_chart"],["area_chart"]]},{"composite_pattern":"stacked","visualization_type":[["matrix",{"composite_pattern":"nested","visualization_type":[["glyph_based"],["others"]]}]]},{"composite_pattern":"stacked","visualization_type":[["bar_chart",{"composite_pattern":"coordinated","visualization_type":[["proportional_area_chart"],["matrix"]]}]]}],"coOccurrence":[["bar_chart","area_chart",["coOccurrence"]],["bar_chart","glyph_based",["coOccurrence"]],["bar_chart","others",["coOccurrence"]],["bar_chart","matrix",["coOccurrence"]],["bar_chart","proportional_area_chart",["coOccurrence"]],["area_chart","glyph_based",["coOccurrence"]],["area_chart","others",["coOccurrence"]],["area_chart","matrix",["coOccurrence"]],["area_chart","proportional_area_chart",["coOccurrence"]],["glyph_based","others",["coOccurrence"]],["glyph_based","matrix",["coOccurrence"]],["glyph_based","proportional_area_chart",["coOccurrence"]],["others","matrix",["coOccurrence"]],["others","proportional_area_chart",["coOccurrence"]],["matrix","proportional_area_chart",["coOccurrence"]]],"year":2016,"conference":["VAST"],"authors":["Po-Ming Law","Wenchao Wu","Yixian Zheng","Huamin Qu"],"title":"VisMatchmaker: Cooperation of the User and the Computer in Centralized Matching Adjustment","doi":"10.1109/TVCG.2016.2599378","abstract":"Centralized matching is a ubiquitous resource allocation problem. In a centralized matching problem, each agent has a preference list ranking the other agents and a central planner is responsible for matching the agents manually or with an algorithm. While algorithms can find a matching which optimizes some performance metrics, they are used as a black box and preclude the central planner from applying his domain knowledge to find a matching which aligns better with the user tasks. Furthermore, the existing matching visualization techniques (i.e. bipartite graph and adjacency matrix) fail in helping the central planner understand the differences between matchings. In this paper, we present VisMatchmaker, a visualization system which allows the central planner to explore alternatives to an algorithm-generated matching. We identified three common tasks in the process of matching adjustment: problem detection, matching recommendation and matching evaluation. We classified matching comparison into three levels and designed visualization techniques for them, including the number line view and the stacked graph view. Two types of algorithmic support, namely direct assignment and range search, and their interactive operations are also provided to enable the user to apply his domain knowledge in matching adjustment.","keywords":"Centralized matching;matching visualization;interaction techniques;visual analytics","caption":"Fig. 1. An overview of the interface of VisMatchmaker. (a) The stacked graph view enables the comparison amongst multiple matchings. (b) The summary view provides different summary statistics of a selected matching. (c) The number line view shows different aspects of each agent\u2019s goodness of match in multiple matchings. (d) The visual preference list shows the states of the items in each agent\u2019s preference list. (e) The scatterplot gives an overview of the popularity and the welfare of the agents.","img_size":{"width":1917,"height":1021},"subfigures":[{"x":11.399803541617946,"y":11.769512454365897,"width":1885.8351857567548,"height":1000.2501523046714,"type":"interface","id":"interface-0"}],"visualizations":[{"x":32.33596837944666,"y":68.60474308300395,"width":805.096837944664,"height":336.97035573122537,"type":"area_chart","id":"area_chart-0"},{"x":1785.792490118577,"y":76.67588932806325,"width":66.586956521739,"height":181.600790513834,"type":"bar_chart","id":"bar_chart-1"},{"x":1097.7272727272727,"y":343.0237154150198,"width":629.5494071146245,"height":621.4782608695652,"type":"others","id":"others-2"},{"x":978.6778656126482,"y":90.800395256917,"width":108.96047430830049,"height":112.99604743083006,"type":"donut_chart","id":"donut_chart-3"},{"x":36.37154150197634,"y":70.62252964426878,"width":801.0612648221344,"height":334.95256916996055,"type":"bar_chart","id":"bar_chart-4"},{"x":1119.9229249011858,"y":80.71146245059289,"width":641.6561264822135,"height":181.600790513834,"type":"proportional_area_chart","id":"proportional_area_chart-5"},{"x":1735.3478260869567,"y":338.9881422924902,"width":115.01383399209499,"height":625.5138339920949,"type":"matrix","id":"matrix-7"},{"x":1101.7628458498023,"y":338.9881422924902,"width":629.5494071146245,"height":625.5138339920949,"type":"glyph_based","id":"glyph_based-8"},{"x":1119.9229249011858,"y":84.74703557312255,"width":643.6739130434785,"height":173.52964426877475,"type":"matrix","id":"matrix-11"},{"x":94.88735177865615,"y":661.8339920948617,"width":750.6166007905138,"height":351.094861660079,"type":"scatterplot","id":"scatterplot-12"}],"relations":[{"vislist":[{"vislist":["bar_chart-4"],"relation":null,"id":"group-0"},{"vislist":["area_chart-0"],"relation":null,"id":"group-1"}],"relation":"nested","id":"relation-0"},{"vislist":[{"vislist":["matrix-7",{"vislist":[{"vislist":["glyph_based-8"],"relation":null,"id":"group-2"},{"vislist":["others-2"],"relation":null,"id":"group-3"}],"relation":"nested","id":"relation-1"}],"relation":null,"id":"group-4"}],"relation":"stacked","id":"relation-2"},{"vislist":[{"vislist":["bar_chart-1",{"vislist":[{"vislist":["proportional_area_chart-5"],"relation":null,"id":"group-5"},{"vislist":["matrix-11"],"relation":null,"id":"group-6"}],"relation":"coordinated","id":"relation-3"}],"relation":null,"id":"group-7"}],"relation":"stacked","id":"relation-4"}]},"2866_0":{"comp":[["matrix","table",["nested"]]],"visType":["matrix","table"],"compType":["nested"],"compressed_tree":[{"composite_pattern":"nested","visualization_type":[["matrix"],["table"]]}],"coOccurrence":[["matrix","table",["coOccurrence"]]],"year":2016,"conference":["VAST"],"authors":["Tanja Blascheck","Fabian Bec","Sebastian Baltes","Thomas Ertl","Daniel Weiskopf"],"title":"Visual analysis and coding of data-rich user behavior","doi":"10.1109/VAST.2016.7883520","abstract":"Investigating user behavior involves abstracting low-level events to higher-level concepts. This requires an analyst to study individual user activities, assign codes which categorize behavior, and develop a consistent classification scheme. To better support this reasoning process of an analyst, we suggest a novel visual analytics approach which integrates rich user data including transcripts, videos, eye movement data, and interaction logs. Word-sized visualizations embedded into a tabular representation provide a space-efficient and detailed overview of user activities. An analyst assigns codes, grouped into code categories, as part of an interactive process. Filtering and searching helps to select specific activities and focus an analysis. A comparison visualization summarizes results of coding and reveals relationships between codes. Editing features support efficient assignment, refinement, and aggregation of codes. We demonstrate the practical applicability and usefulness of our approach in a case study and describe expert feedback.","keywords":"","caption":"Figure 1: Interactive coding of user behavior for transcribed user studies: (A) Selection Panel, which lists recorded users, codes, and code categories, as well as options for searching and filtering; (B) Selected Activities Panel, which represents all selected user activities in a visually enriched tabular representation including transcript, word-sized visualizations of eye movement and interaction data, and assigned codes; (C) Sidebar, which provides additional information of a selected activity such as video, enlarged visualizations, statistics, and a legend; (D) Comparison Panel, which allows contrasting codes of different categories and other categorical attributes of activities.","img_size":{"width":1903,"height":1064},"subfigures":[{"x":14.320650821874661,"y":15.153564926792457,"width":1881.6241663709504,"height":1039.50616016612,"type":"interface","id":"interface-0"}],"visualizations":[{"x":408.9861660079053,"y":735.9683794466404,"width":1021.9446640316208,"height":285.97628458498036,"type":"graph","id":"graph-0"},{"x":1441.5105152467274,"y":444.17304680333,"width":438.3653443561236,"height":254.54096594718865,"type":"matrix","id":"matrix-3"},{"x":868.7780529119011,"y":75.65841725163776,"width":257.7649008232108,"height":608.8840638106255,"type":"matrix","id":"matrix-5"},{"x":5.683794054803126,"y":46.699368987196074,"width":234.8899835157972,"height":282.4375510239469,"type":"others","id":"others-4"},{"x":251.27865612648228,"y":39.95256916996048,"width":1173.3438735177867,"height":647.6521739130435,"type":"table","id":"table-1"},{"x":1439.3418972332015,"y":71.49407114624506,"width":319.620553359684,"height":271.25691699604755,"type":"table","id":"table-2"}],"relations":[{"vislist":[{"vislist":["matrix-5"],"relation":null,"id":"group-0"},{"vislist":["table-1"],"relation":null,"id":"group-1"}],"relation":"nested","id":"relation-0"}]},"2869_0":{"comp":[["unit_visualization","bar_chart",["nested"]]],"visType":["unit_visualization","bar_chart"],"compType":["nested"],"compressed_tree":[{"composite_pattern":"nested","visualization_type":[["unit_visualization"],["bar_chart"]]}],"coOccurrence":[],"year":2017,"conference":["InfoVis"],"authors":["Jessica Hullman","Matthew Kay","Yea-Seul Kim","Samana Shrestha"],"title":"Imagining Replications: Graphical Prediction & Discrete Visualizations Improve Recall & Estimation of Effect Uncertainty","doi":"10.1109/TVCG.2017.2743898","abstract":"People often have erroneous intuitions about the results of uncertain processes, such as scientific experiments. Many uncertainty visualizations assume considerable statistical knowledge, but have been shown to prompt erroneous conclusions even when users possess this knowledge. Active learning approaches been shown to improve statistical reasoning, but are rarely applied in visualizing uncertainty in scientific reports. We present a controlled study to evaluate the impact of an interactive, graphical uncertainty prediction technique for communicating uncertainty in experiment results. Using our technique, users sketch their prediction of the uncertainty in experimental effects prior to viewing the true sampling distribution from an experiment. We find that having a user graphically predict the possible effects from experiment replications is an effective way to improve one\'s ability to make predictions about replications of new experiments. Additionally, visualizing uncertainty as a set of discrete outcomes, as opposed to a continuous probability distribution, can improve recall of a sampling distribution from a single experiment. Our work has implications for various applications where it is important to elicit peoples\' estimates of probability distributions and to communicate uncertainty effectively.","keywords":"Graphical prediction,interactive uncertainty visualization,replication crisis,probability distribution","caption":"Fig. 1. Discrete and continuous elicitation interface used by participants in our study to predict replication uncertainty.","img_size":{"width":1051,"height":448},"subfigures":[{"x":13.383988864635784,"y":16.768235737390402,"width":503.61336572717016,"height":423.6245353353981,"type":"single","id":"single-0"},{"x":531.4855181765118,"y":15.269373558207983,"width":481.1662834814918,"height":427.38567692794544,"type":"single","id":"single-1"}],"visualizations":[{"x":551.3735144312394,"y":65.19015280135821,"width":441.63412563667237,"height":373.8276740237691,"type":"area_chart","id":"area_chart-0"},{"x":26.765704584040748,"y":48.2385398981324,"width":478.213921901528,"height":390.7792869269949,"type":"bar_chart","id":"bar_chart-1"},{"x":25.87351443123939,"y":50.02292020373512,"width":478.213921901528,"height":388.10271646859087,"type":"unit_visualization","id":"unit_visualization-3"}],"relations":[{"relation":"nested","vislist":[{"id":"group-0","relation":null,"vislist":["unit_visualization-3"]},{"id":"group-1","relation":null,"vislist":["bar_chart-1"]}],"id":"relation-0"}]},"2884_8":{"comp":[["scatterplot","sunburst_icicle",["nested"]],["heatmap","sunburst_icicle",["nested"]],["heatmap","scatterplot",["coordinated"]],["heatmap","matrix",["coordinated"]],["tree","comb",["stacked"]],["comb","tree",["stacked"]]],"visType":["scatterplot","sunburst_icicle","heatmap","matrix","tree","comb"],"compType":["nested","coordinated","stacked"],"compressed_tree":[{"composite_pattern":"coordinated","visualization_type":[["heatmap"],["scatterplot"]]},{"composite_pattern":"nested","visualization_type":[["scatterplot","heatmap"],["sunburst_icicle"]]},{"composite_pattern":"stacked","visualization_type":[["tree",{"composite_pattern":"coordinated","visualization_type":[["heatmap"],["matrix"]]}]]}],"coOccurrence":[["heatmap","matrix",["coOccurrence"]],["heatmap","scatterplot",["coOccurrence"]],["heatmap","sunburst_icicle",["coOccurrence"]],["heatmap","tree",["coOccurrence"]],["matrix","scatterplot",["coOccurrence"]],["matrix","sunburst_icicle",["coOccurrence"]],["matrix","tree",["coOccurrence"]],["scatterplot","sunburst_icicle",["coOccurrence"]],["scatterplot","tree",["coOccurrence"]],["sunburst_icicle","tree",["coOccurrence"]]],"year":2017,"conference":["InfoVis"],"authors":["Thomas H\xf6llt","Nicola Pezzotti","Vincent van Unen","Frits Koning","Boudewijn P. F. Lelieveldt","Anna Vilanova"],"title":"CyteGuide: Visual Guidance for Hierarchical Single-Cell Analysis","doi":"10.1109/TVCG.2017.2744318","abstract":"Single-cell analysis through mass cytometry has become an increasingly important tool for immunologists to study the immune system in health and disease. Mass cytometry creates a high-dimensional description vector for single cells by time-of-flight measurement. Recently, t-Distributed Stochastic Neighborhood Embedding (t-SNE) has emerged as one of the state-of-the-art techniques for the visualization and exploration of single-cell data. Ever increasing amounts of data lead to the adoption of Hierarchical Stochastic Neighborhood Embedding (HSNE), enabling the hierarchical representation of the data. Here, the hierarchy is explored selectively by the analyst, who can request more and more detail in areas of interest. Such hierarchies are usually explored by visualizing disconnected plots of selections in different levels of the hierarchy. This poses problems for navigation, by imposing a high cognitive load on the analyst. In this work, we present an interactive summary-visualization to tackle this problem. CyteGuide guides the analyst through the exploration of hierarchically represented single-cell data, and provides a complete overview of the current state of the analysis. We conducted a two-phase user study with domain experts that use HSNE for data exploration. We first studied their problems with their current workflow using HSNE and the requirements to ease this workflow in a field study. These requirements have been the basis for our visual design. In the second phase, we verified our proposed solution in a user evaluation.","keywords":"Hierarchical Data,HSNE,Single-Cell Analysis,Visual Guidance","caption":"Fig. 8. A Screenshot of Cytosplore with CyteGuide. CyteGuide is integrated in the Cytosplore framework and linked to other available views. The views from left to right are: settings, heatmap, embedding and CyteGuide. As indicated in the breadcrumbs view, CyteGuide shows the subtree corresponding to the T-Cells, a major cell population that was selected on the highest level, with the corresponding embedding in the center. Marker expression was selected to be visualized in the embedded heatmaps. The embedding view also shows the T-Cell embedding with a marker overlaid using color-coding. The heatmap view shows the median expressions of the created clusters, each column corresponds to a cluster, each row to a marker. The matplotlib viridis colormap [12] is used to show marker expression in all views.","img_size":{"width":2118,"height":1032},"subfigures":[{"x":25.492673898323307,"y":48.53057770315455,"width":2056.246116997509,"height":878.0146121645025,"type":"interface","id":"interface-0"}],"visualizations":[{"x":1225.9633967789164,"y":64.97218155197658,"width":858.2371888726207,"height":859.7481698389462,"type":"heatmap","id":"heatmap-1"},{"x":527.8901903367496,"y":66.48316251830161,"width":695.0512445095169,"height":770.6002928257687,"type":"heatmap","id":"heatmap-2"},{"x":285.14833583717683,"y":173.68389375514775,"width":186.35546108813935,"height":741.8918011652836,"type":"heatmap","id":"heatmap-3"},{"x":285.211877765407,"y":173.39127924406526,"width":189.44233777796157,"height":741.8980561723149,"type":"matrix","id":"matrix-4"},{"x":529.4011713030745,"y":63.46120058565154,"width":692.0292825768668,"height":781.177159590044,"type":"scatterplot","id":"scatterplot-5"},{"x":1242.3288126584766,"y":106.04820419735393,"width":726.0889604190087,"height":799.006395343606,"type":"scatterplot","id":"scatterplot-7"},{"x":1224.4524158125917,"y":66.48316251830161,"width":864.2811127379206,"height":861.2591508052709,"type":"sunburst_icicle","id":"sunburst_icicle-0"},{"x":302.63674602592727,"y":84.96420941587621,"width":159.472712610027,"height":87.26784285048926,"type":"tree","id":"tree-6"}],"relations":[{"vislist":[{"vislist":["heatmap-2"],"relation":null,"id":"group-4"},{"vislist":["scatterplot-5"],"relation":null,"id":"group-5"}],"relation":"coordinated","id":"relation-2"},{"vislist":[{"vislist":["scatterplot-7","heatmap-1"],"relation":null,"id":"group-1"},{"vislist":["sunburst_icicle-0"],"relation":null,"id":"group-6"}],"relation":"nested","id":"relation-3"},{"vislist":[{"vislist":["tree-6",{"vislist":[{"vislist":["heatmap-3"],"relation":null,"id":"group-1"},{"vislist":["matrix-4"],"relation":null,"id":"group-2"}],"relation":"coordinated","id":"relation-0"}],"relation":null,"id":"group-7"}],"relation":"stacked","id":"relation-4"}]},"2898_0":{"comp":[["matrix","parallel_coordinate",["nested"]],["comb","parallel_coordinate",["nested"]],["heatmap","matrix",["coordinated","nested"]],["others","bar_chart",["stacked"]],["bar_chart","others",["stacked"]]],"visType":["matrix","parallel_coordinate","comb","heatmap","others","bar_chart"],"compType":["nested","coordinated","stacked"],"compressed_tree":[{"composite_pattern":"stacked","visualization_type":[["others","bar_chart"]]},{"composite_pattern":"stacked","visualization_type":[["others","bar_chart"]]},{"composite_pattern":"nested","visualization_type":[["matrix",{"composite_pattern":"coordinated","visualization_type":[["heatmap"],["matrix"]]},{"composite_pattern":"nested","visualization_type":[["heatmap"],["matrix"]]}],["parallel_coordinate"]]}],"coOccurrence":[["heatmap","matrix",["coOccurrence"]],["heatmap","others",["coOccurrence"]],["heatmap","bar_chart",["coOccurrence"]],["heatmap","parallel_coordinate",["coOccurrence"]],["matrix","others",["coOccurrence"]],["matrix","bar_chart",["coOccurrence"]],["matrix","parallel_coordinate",["coOccurrence"]],["others","bar_chart",["coOccurrence"]],["others","parallel_coordinate",["coOccurrence"]],["bar_chart","parallel_coordinate",["coOccurrence"]]],"year":2017,"conference":["InfoVis"],"authors":["Christina Stoiber","Holger Stitz","Reem Hourieh","Florian Grassinger","Wolfgang Aigner","Marc Streit"],"title":"TACO: Visualizing Changes in Tables Over Time","doi":"10.1109/TVCG.2017.2745298","abstract":"Multivariate, tabular data is one of the most common data structures used in many different domains. Over time, tables can undergo changes in both structure and content, which results in multiple versions of the same table. A challenging task when working with such derived tables is to understand what exactly has changed between versions in terms of additions/deletions, reorder, merge/split, and content changes. For textual data, a variety of commonplace \u201cdiff\u201d tools exist that support the task of investigating changes between revisions of a text. Although there are some comparison tools which assist users in inspecting differences between multiple table instances, the resulting visualizations are often difficult to interpret or do not scale to large tables with thousands of rows and columns. To address these challenges, we developed TACO, an interactive comparison tool that visualizes the differences between multiple tables at various levels of detail. With TACO we show (1) the aggregated differences between multiple table versions over time, (2) the aggregated changes between two selected table versions, and (3) detailed changes between the selected tables. To demonstrate the effectiveness of our approach, we show its application by means of two usage scenarios.","keywords":"Table comparison,matrix,difference visualization","caption":"Fig. 1: TACO visualizes differences between Summer Olympic Games medal tables over time at multiple levels of detail. The interface is structured along three levels following an overview+detail concept. (a) Change switches in the header bar allow users to hide and show specific types of changes in the visualizations. (b) At the overview level, we present a timeline that shows stacked bar charts for indicating the temporal progression of the medal table between 1896 and 2012. (c) The second level visualizes aggregated changes for the two selected time points, 1936 and 1948, as a 2D ratio chart with attached diff histograms. (d) At the third and most detailed level, we show a difference heatmap together with raw heatmaps for the two selected medal tables. Link to TACO state shown in this figure: http://vistories.org/taco-olympic-games","img_size":{"width":1953,"height":1222},"subfigures":[{"x":9.926613018784737,"y":14.068190448052011,"width":1934.8160755800557,"height":1193.8636191038956,"type":"interface","id":"interface-0"}],"visualizations":[{"x":853.942166910688,"y":397.194729136164,"width":177.12737920937045,"height":75.14494875549047,"type":"bar_chart","id":"bar_chart-0"},{"x":1032.858711566618,"y":221.85651537335283,"width":66.19912152269396,"height":178.91654465592973,"type":"bar_chart","id":"bar_chart-1"},{"x":27.347730600292778,"y":69.77745241581259,"width":1901.8828696925332,"height":144.92240117130308,"type":"bar_chart","id":"bar_chart-2"},{"x":43.45021961932644,"y":409.7188872620791,"width":654.8345534407031,"height":608.316251830161,"type":"heatmap","id":"heatmap-4"},{"x":1320.914348462665,"y":411.5080527086383,"width":632.085651537335,"height":647.6778916544657,"type":"heatmap","id":"heatmap-5"},{"x":41.66105417276719,"y":411.5080527086383,"width":658.4128843338216,"height":606.5270863836018,"type":"matrix","id":"matrix-7"},{"x":1320.914348462665,"y":416.8755490483162,"width":631.5754026354318,"height":644.099560761347,"type":"matrix","id":"matrix-8"},{"x":671.4472913616398,"y":572.5329428989752,"width":604.737920937043,"height":638.7320644216688,"type":"matrix","id":"matrix-9"},{"x":852.153001464129,"y":221.85651537335283,"width":171.75988286969252,"height":173.54904831625183,"type":"others","id":"others-3"},{"x":41.46062737296258,"y":403.3592497068109,"width":1897.3838629580148,"height":810.6386969263781,"type":"parallel_coordinate","id":"parallel_coordinate-10"}],"relations":[{"vislist":[{"vislist":["others-3","bar_chart-0"],"relation":null,"id":"group-10"}],"relation":"stacked","id":"relation-5"},{"vislist":[{"vislist":["others-3","bar_chart-1"],"relation":null,"id":"group-11"}],"relation":"stacked","id":"relation-6"},{"vislist":[{"vislist":["matrix-9",{"vislist":[{"vislist":["heatmap-4"],"relation":null,"id":"group-0"},{"vislist":["matrix-7"],"relation":null,"id":"group-1"}],"relation":"coordinated","id":"relation-1"},{"vislist":[{"vislist":["heatmap-5"],"relation":null,"id":"group-2"},{"vislist":["matrix-8"],"relation":null,"id":"group-3"}],"relation":"nested","id":"relation-2"}],"relation":null,"id":"group-13"},{"vislist":["parallel_coordinate-10"],"relation":null,"id":"group-12"}],"relation":"nested","id":"relation-7"}]},"2904_0":{"comp":[["matrix","table",["nested"]],["matrix","scatterplot",["nested"]]],"visType":["matrix","table","scatterplot"],"compType":["nested"],"compressed_tree":[{"composite_pattern":"nested","visualization_type":[["matrix"],["table"]]},{"composite_pattern":"nested","visualization_type":[["matrix"],["scatterplot"]]}],"coOccurrence":[["matrix","table",["coOccurrence"]],["matrix","scatterplot",["coOccurrence"]],["table","scatterplot",["coOccurrence"]]],"year":2017,"conference":["InfoVis"],"authors":["Fritz Lekschas","Benjamin Bach","Peter Kerpedjiev","Nils Gehlenborg","Hanspeter Pfister"],"title":"HiPiler: Visual Exploration of Large Genome Interaction Matrices with Interactive Small Multiples","doi":"10.1109/TVCG.2017.2745978","abstract":"This paper presents an interactive visualization interface-HiPiler-for the exploration and visualization of regions-of-interest in large genome interaction matrices. Genome interaction matrices approximate the physical distance of pairs of regions on the genome to each other and can contain up to 3 million rows and columns with many sparse regions. Regions of interest (ROIs) can be defined, e.g., by sets of adjacent rows and columns, or by specific visual patterns in the matrix. However, traditional matrix aggregation or pan-and-zoom interfaces fail in supporting search, inspection, and comparison of ROIs in such large matrices. In HiPiler, ROIs are first-class objects, represented as thumbnail-like \u201csnippets\u201d. Snippets can be interactively explored and grouped or laid out automatically in scatterplots, or through dimension reduction methods. Snippets are linked to the entire navigable genome interaction matrix through brushing and linking. The design of HiPiler is based on a series of semi-structured interviews with 10 domain experts involved in the analysis and interpretation of genome interaction matrices. We describe six exploration tasks that are crucial for analysis of interaction matrices and demonstrate how HiPiler supports these tasks. We report on a user study with a series of data exploration sessions with domain experts to assess the usability of HiPiler as well as to demonstrate respective findings in the data.","keywords":"Interactive Small Multiples,Matrix Comparison,Biomedical Visualization,Genomics","caption":"Fig. 1. HiPiler\u2019s interface: the matrix view (1) with an overview (1A) and detail (1B) matrix. The snippet view (2) presents regions of the matrix as interactive small multiples. In this example, snippets are arranged with t-SNE (2C) and a pile of snippets with a well-pronounced average pattern is highlighted (2A). View menus for operation are located at the bottom (1C and 2B).","img_size":{"width":1980,"height":1011},"subfigures":[{"x":12.374220611450768,"y":13.171441268498643,"width":1936.555882519281,"height":984.6571174630016,"type":"interface","id":"interface-0"}],"visualizations":[{"x":718.9989059080965,"y":117.24945295404817,"width":1223.3763676148803,"height":834.019693654267,"type":"heatmap","id":"heatmap-0"},{"x":33.20021881838085,"y":553.0634573304158,"width":659.2516411378558,"height":395.99343544857766,"type":"heatmap","id":"heatmap-1"},{"x":77.44529540481412,"y":230.074398249453,"width":121.67396061269147,"height":112.82494529540482,"type":"heatmap","id":"heatmap-2"},{"x":244.2064309433237,"y":397.54541550448647,"width":129.02264645933204,"height":133.16363327674094,"type":"heatmap","id":"heatmap-24"},{"x":79.65754923413579,"y":402.6301969365428,"width":121.67396061269152,"height":119.46170678336988,"type":"heatmap","id":"heatmap-3"},{"x":250.00109409190384,"y":223.437636761488,"width":126.0984682713348,"height":121.67396061269147,"type":"heatmap","id":"heatmap-4"},{"x":435.8304157549236,"y":223.437636761488,"width":115.03719912472633,"height":123.88621444201313,"type":"heatmap","id":"heatmap-5"},{"x":429.19365426695856,"y":395.99343544857766,"width":123.88621444201311,"height":132.7352297592998,"type":"heatmap","id":"heatmap-6"},{"x":561.9288840262585,"y":221.22538293216633,"width":134.94748358862125,"height":128.31072210065642,"type":"heatmap","id":"heatmap-7"},{"x":559.7166301969369,"y":400.41794310722105,"width":134.94748358862148,"height":128.31072210065642,"type":"heatmap","id":"heatmap-8"},{"x":79.65754923413579,"y":402.6301969365428,"width":126.0984682713348,"height":123.88621444201313,"type":"heatmap","id":"heatmap-9"},{"x":716.7866520787748,"y":115.0371991247265,"width":1227.8008752735227,"height":834.019693654267,"type":"matrix","id":"matrix-10"},{"x":28.775711159737547,"y":550.8512035010941,"width":663.6761487964992,"height":398.20568927789935,"type":"matrix","id":"matrix-11"},{"x":77.44529540481412,"y":227.8621444201313,"width":126.0984682713348,"height":112.82494529540486,"type":"matrix","id":"matrix-12"},{"x":79.65754923413579,"y":402.6301969365428,"width":123.88621444201311,"height":119.46170678336988,"type":"matrix","id":"matrix-13"},{"x":250.00109409190384,"y":223.437636761488,"width":123.88621444201311,"height":121.67396061269147,"type":"matrix","id":"matrix-14"},{"x":252.21334792122545,"y":400.41794310722105,"width":119.46170678336983,"height":126.09846827133477,"type":"matrix","id":"matrix-15"},{"x":433.618161925602,"y":221.22538293216633,"width":119.46170678336975,"height":123.88621444201316,"type":"matrix","id":"matrix-16"},{"x":429.19365426695856,"y":398.20568927789935,"width":123.88621444201311,"height":130.52297592997803,"type":"matrix","id":"matrix-17"},{"x":559.7166301969369,"y":223.437636761488,"width":139.37199124726476,"height":123.88621444201313,"type":"matrix","id":"matrix-18"},{"x":559.7166301969369,"y":400.41794310722105,"width":134.94748358862148,"height":130.52297592997814,"type":"matrix","id":"matrix-19"},{"x":721.211159737418,"y":117.24945295404817,"width":1218.9518599562366,"height":829.5951859956239,"type":"scatterplot","id":"scatterplot-20"},{"x":18.528738070550542,"y":180.91636039572987,"width":684.0350883505515,"height":352.7878149228247,"type":"table","id":"table-25"}],"relations":[{"vislist":[{"vislist":["matrix-19","matrix-18","matrix-17","matrix-16","matrix-15","matrix-14","matrix-13","matrix-12"],"relation":null,"id":"group-26"},{"vislist":["table-25"],"relation":null,"id":"group-25"}],"relation":"nested","id":"relation-12"},{"vislist":[{"vislist":["matrix-10"],"relation":null,"id":"group-28"},{"vislist":["scatterplot-20"],"relation":null,"id":"group-27"}],"relation":"nested","id":"relation-13"}]},"2942_8":{"comp":[["unit_visualization","bar_chart",["nested"]],["bar_chart","bar_chart",["stacked"]],["bar_chart","comb",["stacked"]],["comb","bar_chart",["stacked"]]],"visType":["unit_visualization","bar_chart","comb"],"compType":["nested","stacked"],"compressed_tree":[{"composite_pattern":"stacked","visualization_type":[["bar_chart"]]},{"composite_pattern":"stacked","visualization_type":[["bar_chart",{"composite_pattern":"nested","visualization_type":[["unit_visualization"],["bar_chart"]]}]]},{"composite_pattern":"stacked","visualization_type":[["bar_chart",{"composite_pattern":"nested","visualization_type":[["unit_visualization"],["bar_chart"]]}]]},{"composite_pattern":"stacked","visualization_type":[["bar_chart",{"composite_pattern":"nested","visualization_type":[["unit_visualization"],["bar_chart"]]}]]}],"coOccurrence":[["bar_chart","unit_visualization",["coOccurrence"]]],"year":2017,"conference":["VAST"],"authors":["Andrea Unger","Nadine Drager","Mike Sips","Dirk J. Lehmann"],"title":"Understanding a Sequence of Sequences: Visual Exploration of Categorical States in Lake Sediment Cores","doi":"10.1109/TVCG.2017.2744686","abstract":"This design study focuses on the analysis of a time sequence of categorical sequences. Such data is relevant for the geoscientific research field of landscape and climate development. It results from microscopic analysis of lake sediment cores. The goal is to gain hypotheses about landscape evolution and climate conditions in the past. To this end, geoscientists identify which categorical sequences are similar in the sense that they indicate similar conditions. Categorical sequences are similar if they have similar meaning (semantic similarity) and appear in similar time periods (temporal similarity). For data sets with many different categorical sequences, the task to identify similar sequences becomes a challenge. Our contribution is a tailored visual analysis concept that effectively supports the analytical process. Our visual interface comprises coupled visualizations of semantics and temporal context for the exploration and assessment of the similarity of categorical sequences. Integrated automatic methods reduce the analytical effort substantially. They (1) extract unique sequences in the data and (2) rank sequences by a similarity measure during the search for similar sequences. We evaluated our concept by demonstrations of our prototype to a larger audience and hands-on analysis sessions for two different lakes. According to geoscientists, our approach fills an important methodological gap in the application domain.","keywords":"Visualization in Earth Science,Time Series Data,Categorical Data,Design Study","caption":"Fig. 9. Our visual interface is composed of two components: A time visualization component on the left and a semantics visualization component on the right. The time visualization shows the temporal distribution of all groups of unique sequences in separate histograms. The component also provides the time overview for the analytical step 1 that is shown in Fig. 5 on the left. The user can switch between both views on demand. The semantics visualization component shows the frequency-sorted set of unique sequences that have not been assigned to a group (left side of component). Beside, the sets of unique sequences that have been grouped are shown in separate lists. The bar chart shows the computational similarity of each unique sequence to the unique sequence of interest (highlighted in yellow). The screenshot was derived during the analysis session that we describe in Sec. 8.1.1. It depicts the process of generating a new group of categorical sequences from the reference sequence MO.","img_size":{"width":2159,"height":1142},"subfigures":[{"x":36.90272052956701,"y":92.79890081821647,"width":2077.353850891015,"height":1028.5006335058242,"type":"interface","id":"interface-0"}],"visualizations":[{"x":49.76166902404539,"y":182.52616690240447,"width":1020.8543140028286,"height":300.4413012729844,"type":"bar_chart","id":"bar_chart-0"},{"x":56.222772277227826,"y":478.121640735502,"width":1017.6237623762374,"height":258.4441301272984,"type":"bar_chart","id":"bar_chart-1"},{"x":49.76166902404539,"y":733.3352192362092,"width":1020.8543140028286,"height":319.8246110325317,"type":"bar_chart","id":"bar_chart-2"},{"x":1114.2284299858554,"y":159.91230551626586,"width":83.99434229137206,"height":949.7821782178214,"type":"bar_chart","id":"bar_chart-3"},{"x":1635.96251768034,"y":975.6265912305515,"width":45.22772277227705,"height":109.83875530410171,"type":"bar_chart","id":"bar_chart-4"},{"x":1637.5777934936352,"y":293.9801980198019,"width":75.91796322489404,"height":599.2673267326732,"type":"bar_chart","id":"bar_chart-5"},{"x":1202.3945827232799,"y":170.54758418740846,"width":356.14348462664725,"height":934.6676427525624,"type":"bar_chart","id":"bar_chart-6"},{"x":1719.0534407027817,"y":310.9985358711566,"width":138.7789165446561,"height":578.5241581259152,"type":"bar_chart","id":"bar_chart-7"},{"x":1715.7093704245974,"y":996.532942898975,"width":113.69838945827225,"height":93.63396778916557,"type":"bar_chart","id":"bar_chart-8"},{"x":1718.3415841584158,"y":306.90240452616695,"width":137.29844413012734,"height":584.7298444130125,"type":"unit_visualization","id":"unit_visualization-10"},{"x":1715.1110325318245,"y":995.0099009900988,"width":108.22347949080634,"height":90.45544554455432,"type":"unit_visualization","id":"unit_visualization-11"},{"x":1201.4533239038187,"y":171.21923620933518,"width":356.975954738331,"height":935.2446958981609,"type":"unit_visualization","id":"unit_visualization-9"}],"relations":[{"vislist":[{"vislist":["bar_chart-0","bar_chart-1","bar_chart-2"],"relation":null,"id":"group-3"}],"relation":"stacked","id":"relation-0"},{"vislist":[{"vislist":["bar_chart-3",{"vislist":[{"vislist":["unit_visualization-9"],"relation":null,"id":"group-4"},{"vislist":["bar_chart-6"],"relation":null,"id":"group-5"}],"relation":"nested","id":"relation-2"}],"relation":null,"id":"group-19"}],"relation":"stacked","id":"relation-8"},{"vislist":[{"vislist":["bar_chart-5",{"vislist":[{"vislist":["unit_visualization-10"],"relation":null,"id":"group-9"},{"vislist":["bar_chart-7"],"relation":null,"id":"group-10"}],"relation":"nested","id":"relation-4"}],"relation":null,"id":"group-20"}],"relation":"stacked","id":"relation-9"},{"vislist":[{"vislist":["bar_chart-4",{"vislist":[{"vislist":["unit_visualization-11"],"relation":null,"id":"group-14"},{"vislist":["bar_chart-8"],"relation":null,"id":"group-15"}],"relation":"nested","id":"relation-6"}],"relation":null,"id":"group-21"}],"relation":"stacked","id":"relation-10"}]},"2944_0":{"comp":[["glyph_based","scatterplot",["nested"]],["polar_plot","graph",["nested"]],["sector_chart","graph",["nested"]],["bar_chart","area_chart",["stacked"]],["area_chart","bar_chart",["stacked"]]],"visType":["glyph_based","scatterplot","polar_plot","graph","sector_chart","bar_chart","area_chart"],"compType":["nested","stacked"],"compressed_tree":[{"composite_pattern":"nested","visualization_type":[["glyph_based"],["scatterplot"]]},{"composite_pattern":"nested","visualization_type":[["polar_plot","sector_chart"],["graph"]]},{"composite_pattern":"stacked","visualization_type":[["bar_chart","heatmap_matrix","area_chart"]]}],"coOccurrence":[["glyph_based","scatterplot",["coOccurrence"]],["glyph_based","polar_plot",["coOccurrence"]],["glyph_based","sector_chart",["coOccurrence"]],["glyph_based","graph",["coOccurrence"]],["glyph_based","bar_chart",["coOccurrence"]],["glyph_based","area_chart",["coOccurrence"]],["scatterplot","polar_plot",["coOccurrence"]],["scatterplot","sector_chart",["coOccurrence"]],["scatterplot","graph",["coOccurrence"]],["scatterplot","bar_chart",["coOccurrence"]],["scatterplot","area_chart",["coOccurrence"]],["polar_plot","sector_chart",["coOccurrence"]],["polar_plot","graph",["coOccurrence"]],["polar_plot","bar_chart",["coOccurrence"]],["polar_plot","area_chart",["coOccurrence"]],["sector_chart","graph",["coOccurrence"]],["sector_chart","bar_chart",["coOccurrence"]],["sector_chart","area_chart",["coOccurrence"]],["graph","bar_chart",["coOccurrence"]],["graph","area_chart",["coOccurrence"]],["bar_chart","area_chart",["coOccurrence"]]],"year":2017,"conference":["VAST"],"authors":["Xun Zhao","Yanhong Wu","Weiwei Cui","Xinnan Du","Yuan Chen","Yong Wan","Dik Lun Lee","Huamin Qu"],"title":"SkyLens: Visual Analysis of Skyline on Multi-Dimensional Data","doi":"10.1109/TVCG.2017.2744738","abstract":"Skyline queries have wide-ranging applications in fields that involve multi-criteria decision making, including tourism, retail industry, and human resources. By automatically removing incompetent candidates, skyline queries allow users to focus on a subset of superior data items (i.e., the skyline), thus reducing the decision-making overhead. However, users are still required to interpret and compare these superior items manually before making a successful choice. This task is challenging because of two issues. First, people usually have fuzzy, unstable, and inconsistent preferences when presented with multiple candidates. Second, skyline queries do not reveal the reasons for the superiority of certain skyline points in a multi-dimensional space. To address these issues, we propose SkyLens, a visual analytic system aiming at revealing the superiority of skyline points from different perspectives and at different scales to aid users in their decision making. Two scenarios demonstrate the usefulness of SkyLens on two datasets with a dozen of attributes. A qualitative study is also conducted to show that users can efficiently accomplish skyline understanding and comparison tasks with SkyLens.","keywords":"Skyline query,skyline visualization,multi-dimensional data,visual analytics,multi-criteria decision making","caption":"Figure 1. Analyzing the skyline of NBA statistics using SkyLens: (a) a Projection View showing an overview of clusters and outliers; (b) a Tabular View depicting the attributes of four skyline players and reveals the factors making a player in skyline; (c) a Comparison View examining the differences between skyline players from the attribute and domination perspectives; (d) a Control Panel for refining skyline queries; (e) a pop-up window showing a detailed comparison between LeBron James and Chris Paul.","img_size":{"width":1974,"height":1045},"subfigures":[{"x":19.518960296711082,"y":9.456130725800634,"width":1936.3958503829954,"height":1018.9185058021706,"type":"interface","id":"interface-0"}],"visualizations":[{"x":222.11487964989055,"y":585.3829321663018,"width":1728.7089715536104,"height":59.452954048139986,"type":"area_chart","id":"area_chart-0"},{"x":1273.636285846445,"y":108.23269079351755,"width":461.65459067433335,"height":465.70821956074093,"type":"area_chart","id":"area_chart-18"},{"x":55.18927789934363,"y":672.275711159737,"width":1904.781181619256,"height":50.30634573304156,"type":"bar_chart","id":"bar_chart-1"},{"x":57.47592997811828,"y":896.3676148796495,"width":1897.9212253829314,"height":144.05908096280098,"type":"bar_chart","id":"bar_chart-2"},{"x":18.60284463894977,"y":12.1929430572949,"width":640.2625820568933,"height":488.5695021774145,"type":"glyph_based","id":"glyph_based-4"},{"x":665.7253829321663,"y":16.00656455142232,"width":603.6761487964986,"height":484.7702407002187,"type":"graph","id":"graph-5"},{"x":52.90262582056901,"y":724.8687089715535,"width":1916.2144420131292,"height":164.63894967177242,"type":"heatmap_matrix","id":"heatmap_matrix-6"},{"x":1125.3424507658644,"y":20.579868708971553,"width":141.77242888402637,"height":166.92560175054695,"type":"polar_plot","id":"polar_plot-10"},{"x":908.1105032822759,"y":361.2910284463895,"width":134.91247264770237,"height":137.199124726477,"type":"polar_plot","id":"polar_plot-11"},{"x":1271.68818380744,"y":107.79460627558542,"width":459.6170678336979,"height":461.20911862681015,"type":"polar_plot","id":"polar_plot-8"},{"x":670.2986870897155,"y":36.58643326039386,"width":164.63894967177245,"height":166.92560175054695,"type":"polar_plot","id":"polar_plot-9"},{"x":20.889496717724352,"y":9.166686811218423,"width":635.6892778993432,"height":493.82600788377226,"type":"scatterplot","id":"scatterplot-12"},{"x":940.1236323851203,"y":38.873085339168476,"width":77.74617067833697,"height":70.88621444201313,"type":"sector_chart","id":"sector_chart-13"},{"x":807.4978118161927,"y":249.2450765864332,"width":70.88621444201318,"height":80.03282275711159,"type":"sector_chart","id":"sector_chart-14"},{"x":921.8304157549233,"y":171.49890590809622,"width":116.61925601750569,"height":96.0393873085339,"type":"sector_chart","id":"sector_chart-15"},{"x":1084.1827133479212,"y":256.1050328227571,"width":89.17943107221004,"height":86.89277899343539,"type":"sector_chart","id":"sector_chart-16"},{"x":1635.265864332603,"y":50.30634573304156,"width":315.55798687089714,"height":375.0109409190371,"type":"table","id":"table-17"}],"relations":[{"vislist":[{"vislist":["glyph_based-4"],"relation":null,"id":"group-0"},{"vislist":["scatterplot-12"],"relation":null,"id":"group-1"}],"relation":"nested","id":"relation-0"},{"vislist":[{"vislist":["polar_plot-9","sector_chart-13","polar_plot-10","sector_chart-15","sector_chart-16","sector_chart-14","polar_plot-11"],"relation":null,"id":"group-0"},{"vislist":["graph-5"],"relation":null,"id":"group-2"}],"relation":"nested","id":"relation-1"},{"vislist":[{"vislist":["bar_chart-2","heatmap_matrix-6","bar_chart-1","area_chart-0"],"relation":null,"id":"group-7"}],"relation":"stacked","id":"relation-2"}]},"2946_9":{"comp":[["line_chart","matrix",["nested"]],["comb","tree",["nested"]],["comb","comb",["large_view"]]],"visType":["line_chart","matrix","comb","tree"],"compType":["nested","large_view"],"compressed_tree":[{"composite_pattern":"large_view","visualization_type":[[{"composite_pattern":"nested","visualization_type":[[{"composite_pattern":"nested","visualization_type":[["line_chart"],["matrix"]]}],["tree"]]}],[{"composite_pattern":"nested","visualization_type":[[{"composite_pattern":"nested","visualization_type":[["line_chart"],["matrix"]]}],["tree"]]}]]}],"coOccurrence":[["line_chart","matrix",["coOccurrence"]],["line_chart","tree",["coOccurrence"]],["matrix","tree",["coOccurrence"]]],"year":2017,"conference":["VAST"],"authors":["Dominik Sacha","Matthias Kraus","J\xfcrgen Bernard","Michael Behrisch","Tobias Schreck","Yuki Asano","Daniel A. Keim"],"title":"SOMFlow: Guided Exploratory Cluster Analysis with Self-Organizing Maps and Analytic Provenance","doi":"10.1109/TVCG.2017.2744805","abstract":"Clustering is a core building block for data analysis, aiming to extract otherwise hidden structures and relations from raw datasets, such as particular groups that can be effectively related, compared, and interpreted. A plethora of visual-interactive cluster analysis techniques has been proposed to date, however, arriving at useful clusterings often requires several rounds of user interactions to fine-tune the data preprocessing and algorithms. We present a multi-stage Visual Analytics (VA) approach for iterative cluster refinement together with an implementation (SOMFlow) that uses Self-Organizing Maps (SOM) to analyze time series data. It supports exploration by offering the analyst a visual platform to analyze intermediate results, adapt the underlying computations, iteratively partition the data, and to reflect previous analytical activities. The history of previous decisions is explicitly visualized within a flow graph, allowing to compare earlier cluster refinements and to explore relations. We further leverage quality and interestingness measures to guide the analyst in the discovery of useful patterns, relations, and data partitions. We conducted two pair analytics experiments together with a subject matter expert in speech intonation research to demonstrate that the approach is effective for interactive data analysis, supporting enhanced understanding of clustering results as well as the interactive process itself.","keywords":"Visual Analytics,Interaction,Visual Cluster Analysis,Quality Metrics,Guidance,Self-Organizing Maps,Time Series","caption":"Fig. 10. A part of the SOMFlow graph that has been produced during the first study. An unexpected finding was that some metadata is only present for one of the speaker groups and requires different labels (branch A). The the system automatically pointed the analyst to speaker differences within the \u201csumimasen\u201d utterances (C \u2013 SOM #5) revealing a steeper pitch fall for Japanese native speakers. Further splits and investigations (E) revealed stronger pitch variations (G) for German speakers (because they use pitch to express emotions, in contrast to Japanese native speakers). H) overlays a 2D colormap to compare all SOM cells within the flow graph.","img_size":{"width":1959,"height":770},"subfigures":[{"x":9.448311252825706,"y":9.544923395390178,"width":1932.9889971934406,"height":745.2211529723265,"type":"interface","id":"interface-0"}],"visualizations":[{"x":19.939824573941742,"y":21.873755911257625,"width":1889.0105472961818,"height":718.9492369535952,"type":"line_chart","id":"line_chart-0"},{"x":21.6188455008489,"y":519.7020294216978,"width":518.8522920203734,"height":219.51443123938873,"type":"line_chart","id":"line_chart-1"},{"x":22.27335128849256,"y":13.184963111358298,"width":1887.4936944774533,"height":735.5940860107862,"type":"matrix","id":"matrix-10"},{"x":21.6188455008489,"y":519.7020294216978,"width":518.8522920203734,"height":219.51443123938873,"type":"matrix","id":"matrix-11"},{"x":14.573221095674107,"y":18.013363671605934,"width":1910.0341202216857,"height":746.3797913667249,"type":"tree","id":"tree-20"},{"x":19.051063476573788,"y":517.6422664030416,"width":518.4564903351234,"height":224.32961967892206,"type":"tree","id":"tree-23"}],"relations":[{"vislist":[{"vislist":[{"vislist":[{"vislist":[{"vislist":[{"vislist":["line_chart-1"],"relation":null,"id":"group-8"},{"vislist":["matrix-11"],"relation":null,"id":"group-9"}],"relation":"nested","id":"relation-4"}],"relation":null,"id":"group-10"},{"vislist":["tree-23"],"relation":null,"id":"group-11"}],"relation":"nested","id":"relation-5"}],"relation":null,"id":"group-12"},{"vislist":[{"vislist":[{"vislist":[{"vislist":[{"vislist":["line_chart-0"],"relation":null,"id":"group-4"},{"vislist":["matrix-10"],"relation":null,"id":"group-5"}],"relation":"nested","id":"relation-2"}],"relation":null,"id":"group-6"},{"vislist":["tree-20"],"relation":null,"id":"group-7"}],"relation":"nested","id":"relation-3"}],"relation":null,"id":"group-13"}],"relation":"large_view","id":"relation-6"}]},"2951_0":{"comp":[["line_chart","graph",["nested"]]],"visType":["line_chart","graph"],"compType":["nested"],"compressed_tree":[{"composite_pattern":"nested","visualization_type":[["line_chart"],["graph"]]},{"composite_pattern":"nested","visualization_type":[["heatmap_matrix"],["chord_diagram"]]}],"coOccurrence":[["line_chart","graph",["coOccurrence"]],["line_chart","chord_diagram",["coOccurrence"]],["graph","chord_diagram",["coOccurrence"]]],"year":2017,"conference":["VAST"],"authors":["Mengchen Liu","Jiaxin Shi","Kelei Cao","Jun Zh","Shixia Liu"],"title":"Analyzing the Training Processes of Deep Generative Models","doi":"10.1109/TVCG.2017.2744938","abstract":"Among the many types of deep models, deep generative models (DGMs) provide a solution to the important problem of unsupervised and semi-supervised learning. However, training DGMs requires more skill, experience, and know-how because their training is more complex than other types of deep models such as convolutional neural networks (CNNs). We develop a visual analytics approach for better understanding and diagnosing the training process of a DGM. To help experts understand the overall training process, we first extract a large amount of time series data that represents training dynamics (e.g., activation changes over time). A blue-noise polyline sampling scheme is then introduced to select time series samples, which can both preserve outliers and reduce visual clutter. To further investigate the root cause of a failed training process, we propose a credit assignment algorithm that indicates how other neurons contribute to the output of the neuron causing the training failure. Two case studies are conducted with machine learning experts to demonstrate how our approach helps understand and diagnose the training processes of DGMs. We also show how our approach can be directly used to analyze other types of deep models, such as CNNs.","keywords":"deep learning,deep generative models,blue noise sampling,credit assignment","caption":"Fig. 1. DGMTracker, a visual analytics tool that helps experts understand and diagnose the training processes of deep generative models (DGMs): (a) the loss changes; (b) the data flow visualization to illustrate how data flows through a DGM and disclose how other neurons influence the output of the neuron of interest; (c) visualization of the training dynamics (e.g., activation changes).","img_size":{"width":1956,"height":1076},"subfigures":[{"x":13.348063696042802,"y":10.854418589223174,"width":1932.2440438715491,"height":1039.5940292191044,"type":"interface","id":"interface-0"}],"visualizations":[{"x":10.817538896746834,"y":114.96922039387033,"width":1929.7991513437044,"height":477.0518379559982,"type":"graph","id":"graph-0"},{"x":627.1966053748233,"y":722.913719943423,"width":117.18811881188115,"height":126.31966053748242,"type":"heatmap_matrix","id":"heatmap_matrix-1"},{"x":268.02263083451214,"y":523.5417256011316,"width":112.62234794908056,"height":108.05657708628007,"type":"heatmap_matrix","id":"heatmap_matrix-18"},{"x":271.0664780763791,"y":643.7736916548797,"width":106.53465346534654,"height":114.14427157001424,"type":"heatmap_matrix","id":"heatmap_matrix-19"},{"x":269.54455445544556,"y":768.571428571429,"width":109.5785007072136,"height":111.10042432814718,"type":"heatmap_matrix","id":"heatmap_matrix-20"},{"x":252.67454313401294,"y":496.3421156453249,"width":488.4065959090926,"height":431.20377554635263,"type":"chord_diagram","id":"chord_diagram-21"},{"x":1030.5063649222063,"y":307.42857142857156,"width":105.01272984441286,"height":80.6619519094767,"type":"line_chart","id":"line_chart-10"},{"x":1232.9222065063648,"y":243.50777934936366,"width":105.01272984441286,"height":80.6619519094767,"type":"line_chart","id":"line_chart-11"},{"x":1436.8599717114566,"y":191.76237623762387,"width":100.44695898161261,"height":80.66195190947664,"type":"line_chart","id":"line_chart-12"},{"x":1637.7538896746817,"y":115.66619519094769,"width":98.92503536067898,"height":76.09618104667615,"type":"line_chart","id":"line_chart-13"},{"x":1636.231966053748,"y":272.4243281471005,"width":101.96888260254603,"height":80.6619519094767,"type":"line_chart","id":"line_chart-14"},{"x":1637.7538896746817,"y":490.0594059405941,"width":100.44695898161238,"height":82.18387553041018,"type":"line_chart","id":"line_chart-15"},{"x":1432.294200848656,"y":491.5813295615278,"width":105.01272984441309,"height":79.14002828854319,"type":"line_chart","id":"line_chart-16"},{"x":16.90523338048092,"y":596.5940594059407,"width":1922.1895332390382,"height":470.2743988684584,"type":"line_chart","id":"line_chart-17"},{"x":9.295615275813304,"y":18.263083451202263,"width":1937.4087694483735,"height":97.40311173974541,"type":"line_chart","id":"line_chart-2"},{"x":219.32107496463934,"y":308.950495049505,"width":103.49080622347948,"height":77.6181046676096,"type":"line_chart","id":"line_chart-3"},{"x":421.7369165487978,"y":231.33239038189538,"width":101.96888260254603,"height":82.18387553041018,"type":"line_chart","id":"line_chart-4"},{"x":622.6308345120227,"y":305.9066478076379,"width":108.05657708628006,"height":82.1838755304102,"type":"line_chart","id":"line_chart-5"},{"x":421.7369165487978,"y":386.56859971711475,"width":103.49080622347944,"height":79.14002828854319,"type":"line_chart","id":"line_chart-6"},{"x":558.7100424328148,"y":553.9801980198023,"width":126.31966053748235,"height":100.44695898161241,"type":"line_chart","id":"line_chart-7"},{"x":828.0905233380481,"y":243.50777934936366,"width":100.44695898161238,"height":80.6619519094767,"type":"line_chart","id":"line_chart-8"},{"x":1027.4625176803395,"y":150.67043847241868,"width":101.96888260254603,"height":83.70579915134375,"type":"line_chart","id":"line_chart-9"}],"relations":[{"vislist":[{"vislist":["line_chart-3","line_chart-4","line_chart-5","line_chart-6","line_chart-8","line_chart-9","line_chart-10","line_chart-11","line_chart-12","line_chart-13","line_chart-14","line_chart-15","line_chart-16"],"relation":null,"id":"group-1"},{"vislist":["graph-0"],"relation":null,"id":"group-1"}],"relation":"nested","id":"relation-0"},{"vislist":[{"vislist":["heatmap_matrix-18","heatmap_matrix-19","heatmap_matrix-20","heatmap_matrix-1"],"relation":null,"id":"group-3"},{"vislist":["chord_diagram-21"],"relation":null,"id":"group-2"}],"relation":"nested","id":"relation-1"}]},"2954_0":{"comp":[["proportional_area_chart","table",["nested"]],["scatterplot","donut_chart",["nested"]]],"visType":["proportional_area_chart","table","scatterplot","donut_chart"],"compType":["nested"],"compressed_tree":[{"composite_pattern":"nested","visualization_type":[["proportional_area_chart"],["table"]]},{"composite_pattern":"nested","visualization_type":[["scatterplot"],["donut_chart"]]}],"coOccurrence":[["proportional_area_chart","table",["coOccurrence"]],["proportional_area_chart","scatterplot",["coOccurrence"]],["proportional_area_chart","donut_chart",["coOccurrence"]],["table","scatterplot",["coOccurrence"]],["table","donut_chart",["coOccurrence"]],["scatterplot","donut_chart",["coOccurrence"]]],"year":2017,"conference":["VAST"],"authors":["Yuanzhe Chen","Panpan Xu","Liu Ren"],"title":"Sequence Synopsis: Optimize Visual Summary of Temporal Event Data","doi":"10.1109/TVCG.2017.2745083","abstract":"Event sequences analysis plays an important role in many application domains such as customer behavior analysis, electronic health record analysis and vehicle fault diagnosis. Real-world event sequence data is often noisy and complex with high event cardinality, making it a challenging task to construct concise yet comprehensive overviews for such data. In this paper, we propose a novel visualization technique based on the minimum description length (MDL) principle to construct a coarse-level overview of event sequence data while balancing the information loss in it. The method addresses a fundamental trade-off in visualization design: reducing visual clutter vs. increasing the information content in a visualization. The method enables simultaneous sequence clustering and pattern extraction and is highly tolerant to noises such as missing or additional events in the data. Based on this approach we propose a visual analytics framework with multiple levels-of-detail to facilitate interactive data exploration. We demonstrate the usability and effectiveness of our approach through case studies with two real-world datasets. One dataset showcases a new application domain for event sequence visualization, i.e., fault development path analysis in vehicles for predictive maintenance. We also discuss the strengths and limitations of the proposed method based on user feedback.","keywords":"Time Series Data,Data Transformation and Representation,Visual Knowledge Representation,Visual Analytics","caption":"Fig. 1. A screenshot of the proposed visual analytics system for event sequence data exploration. The system contains an overview (A) which shows a set of sequential patterns that can best summarize the entire dataset based on the Minimum Description Length (MDL) principle. It also supports level-of-detail exploration (A.0 \u2192 A.1). A tabular display (B) shows the detailed information of the sequences linked with the summary view. Two panels (C and D) support data filtering. The event filter (C) shows the co-occurrence of events with a focus event at the center and allows users to select a set of highly correlated events. The sequence filter (D) supports sequence filtering based on their attribute values. The usage scenario in this figure is described in Section. 6.","img_size":{"width":2178,"height":951},"subfigures":[{"x":12.085750120686429,"y":10.59980814324729,"width":2149.082674247028,"height":917.1502546199125,"type":"interface","id":"interface-0"}],"visualizations":[{"x":1600.0258620689654,"y":149.39080459770113,"width":489.30238220584374,"height":794.4069053259631,"type":"proportional_area_chart","id":"proportional_area_chart-0"},{"x":40.6412213740458,"y":302.7748091603053,"width":454.44274809160305,"height":456.29007633587787,"type":"scatterplot","id":"scatterplot-1"},{"x":1296.824427480916,"y":147.59923664122135,"width":788.8091603053433,"height":794.351145038168,"type":"table","id":"table-2"},{"x":37.57702909715552,"y":303.75707521223893,"width":455.29965955986165,"height":454.2980234885654,"type":"donut_chart","id":"donut_chart-4"}],"relations":[{"vislist":[{"id":"group-0","relation":null,"vislist":["proportional_area_chart-0"]},{"id":"group-1","relation":null,"vislist":["table-2"]}],"relation":"nested","id":"relation-0"},{"vislist":[{"id":"group-2","relation":null,"vislist":["scatterplot-1"]},{"id":"group-3","relation":null,"vislist":["donut_chart-4"]}],"relation":"nested","id":"relation-1"}]},"2957_0":{"comp":[["area_chart","matrix",["nested"]],["scatterplot","matrix",["nested"]],["bar_chart","matrix",["nested"]],["proportional_area_chart","matrix",["nested"]],["heatmap","graph",["nested"]]],"visType":["area_chart","matrix","scatterplot","bar_chart","proportional_area_chart","heatmap","graph"],"compType":["nested"],"compressed_tree":[{"composite_pattern":"nested","visualization_type":[["area_chart","scatterplot","bar_chart","proportional_area_chart"],["matrix"]]},{"composite_pattern":"nested","visualization_type":[["heatmap"],["graph"]]}],"coOccurrence":[["area_chart","scatterplot",["coOccurrence"]],["area_chart","bar_chart",["coOccurrence"]],["area_chart","proportional_area_chart",["coOccurrence"]],["area_chart","matrix",["coOccurrence"]],["area_chart","heatmap",["coOccurrence"]],["area_chart","graph",["coOccurrence"]],["scatterplot","bar_chart",["coOccurrence"]],["scatterplot","proportional_area_chart",["coOccurrence"]],["scatterplot","matrix",["coOccurrence"]],["scatterplot","heatmap",["coOccurrence"]],["scatterplot","graph",["coOccurrence"]],["bar_chart","proportional_area_chart",["coOccurrence"]],["bar_chart","matrix",["coOccurrence"]],["bar_chart","heatmap",["coOccurrence"]],["bar_chart","graph",["coOccurrence"]],["proportional_area_chart","matrix",["coOccurrence"]],["proportional_area_chart","heatmap",["coOccurrence"]],["proportional_area_chart","graph",["coOccurrence"]],["matrix","heatmap",["coOccurrence"]],["matrix","graph",["coOccurrence"]],["heatmap","graph",["coOccurrence"]]],"year":2017,"conference":["VAST"],"authors":["Xu-Meng Wang","Jia-Kai Chou","Wei Che","Huihua Guan","Wenlong Chen","Tianyi Lao","Kwan-Liu Ma"],"title":"A Utility-Aware Visual Approach for Anonymizing Multi-Attribute Tabular Data","doi":"10.1109/TVCG.2017.2745139","abstract":"Sharing data for public usage requires sanitization to prevent sensitive information from leaking. Previous studies have presented methods for creating privacy preserving visualizations. However, few of them provide sufficient feedback to users on how much utility is reduced (or preserved) during such a process. To address this, we design a visual interface along with a data manipulation pipeline that allows users to gauge utility loss while interactively and iteratively handling privacy issues in their data. Widely known and discussed types of privacy models, i.e., syntactic anonymity and differential privacy, are integrated and compared under different use case scenarios. Case study results on a variety of examples demonstrate the effectiveness of our approach.","keywords":"Privacy preserving visualization,utility aware anonymization,syntactic anonymity,differential privacy","caption":"Fig. 1. Our utility-aware visual data-anonymizing process follows (a) a 5-step pipeline and is facilitated with two main visualization components: (b) utility preservation degree matrix (UPD-Matrix) and (c) privacy exposure risk tree (PER-Tree). The PER-Tree helps our users identify privacy issues in the underlying data and provides interactions to address the detected privacy issues. The UPD-Matrix presents the difference between the processed data and the original data. Users can use the chart to examine how utility of data changes during the anonymization process.","img_size":{"width":1904,"height":1079},"subfigures":[{"x":13.756764923498723,"y":13.733540933216323,"width":1877.960646549903,"height":1051.5329181335662,"type":"interface","id":"interface-0"}],"visualizations":[{"x":409.8003124357952,"y":147.09160402273997,"width":330.31136298880324,"height":336.43877586873026,"type":"area_chart","id":"area_chart-7"},{"x":11.121444201312956,"y":80.27571115973743,"width":748.4529540481398,"height":816.9234135667396,"type":"bar_chart","id":"bar_chart-0"},{"x":874.6992619029062,"y":160.55142231947505,"width":938.6031165019275,"height":705.9540481400438,"type":"graph","id":"graph-1"},{"x":875.3689313528566,"y":161.1964517444227,"width":932.3641006373092,"height":704.5946046816825,"type":"heatmap","id":"heatmap-9"},{"x":13.48249452954053,"y":77.91466083150988,"width":750.8140043763673,"height":819.284463894967,"type":"matrix","id":"matrix-6"},{"x":8.760393873085379,"y":80.27571115973743,"width":753.1750547045949,"height":809.840262582057,"type":"proportional_area_chart","id":"proportional_area_chart-4"},{"x":576.0679540340224,"y":490.01836302571166,"width":168.2404197013019,"height":161.15764392176663,"type":"scatterplot","id":"scatterplot-8"}],"relations":[{"vislist":[{"vislist":["area_chart-7","scatterplot-8","bar_chart-0","proportional_area_chart-4"],"relation":null,"id":"group-0"},{"vislist":["matrix-6"],"relation":null,"id":"group-2"}],"relation":"nested","id":"relation-1"},{"vislist":[{"vislist":["heatmap-9"],"relation":null,"id":"group-3"},{"vislist":["graph-1"],"relation":null,"id":"group-4"}],"relation":"nested","id":"relation-2"}]},"2970_1":{"comp":[["others","scatterplot",["nested"]]],"visType":["others","scatterplot"],"compType":["nested"],"compressed_tree":[{"composite_pattern":"nested","visualization_type":[["others"],["scatterplot"]]},{"composite_pattern":"repeated","visualization_type":[["heatmap_matrix"]]}],"coOccurrence":[],"year":2017,"conference":["VAST"],"authors":["Yen-Ting Kuan","Yu-Shuen Wang","Jung-Hong Chuang"],"title":"Visualizing Real-Time Strategy Games: The Example of StarCraft II","doi":"10.1109/VAST.2017.8585594","abstract":"We present a visualization system for users to examine real-time strategy games, which have become very popular globally in recent years. Unlike previous systems that focus on showing statistics and build order, our system can depict the most important part - battles in the games. Specifically, we visualize detailed movements of armies belonging to respective nations on a map and enable users to examine battles from a global view to a local view. In the global view, battles are depicted by curved arrows revealing how the armies enter and escape from the battlefield. By observing the arrows and the height map, users can make sense of offensive and defensive strategies easily. In the local view, units of each type are rendered on the map, and their movements are represented by animation. We also render an attack line between a pair of units if one of them can attack the other to help users analyze the advantages and disadvantages of a particular formation. Accordingly, users can utilize our system to discover statistics, build order, and battles, and learn strategies from games played by professionals.","keywords":"real-time strategy games,StarCraft,game visualization,trajectories","caption":"Figure 2: Left and right are the status and the battle views in the presented visualization system, respectively. When users select a time span in the status view, the system would switch to the battle view for the examination of offensive and defensive strategies. Color shadings and arrows are used to depict the movements of armies. (a) The status view shows the relative economic strengths of two nations over time. (b) The build order indicates the time that the techniques and buildings are constructed. (c) The death ThemeRiver shows the number of deaths in battles over time. (d) The status bar indicates the transfer function and the related information in the game play. (e) The small map conveys the distributions of armies and buildings. (f) The map is used to reveal geographic features and show the process of a battle. (g) The line charts show the strengths of armies in each type. (h) The context view of the map and the current techniques owned by the two nations.","img_size":{"width":2112,"height":645},"subfigures":[{"x":5.818299684162603,"y":11.592459624506152,"width":1113.9986963217766,"height":617.2189110133365,"type":"interface","id":"interface-0"},{"x":1138.0405060082926,"y":13.10768506349801,"width":966.4800876356634,"height":615.7205167145698,"type":"interface","id":"interface-1"}],"visualizations":[{"x":185.70857226860798,"y":529.4307658786361,"width":923.3446157055771,"height":67.48175182481799,"type":"area_chart","id":"area_chart-11"},{"x":7.171477079796263,"y":32.05517826825123,"width":1107.993208828523,"height":186.45840407470286,"type":"heatmap_matrix","id":"heatmap_matrix-6"},{"x":1163.2483121491846,"y":382.7511623404568,"width":130.0520058505207,"height":142.30395396139372,"type":"map","id":"map-12"},{"x":6.881209190122574,"y":331.98302866790397,"width":167.16270101783047,"height":194.48066643459254,"type":"map","id":"map-13"},{"x":186.5874208546261,"y":225.27182656409425,"width":919.984490612445,"height":301.9563468718101,"type":"others","id":"others-9"},{"x":1159.9864176570456,"y":381.6646859083191,"width":123.70797962648568,"height":143.42954159592531,"type":"scatterplot","id":"scatterplot-1"},{"x":184.11981464784913,"y":225.31131802062592,"width":920.1124192627232,"height":306.69079679456917,"type":"scatterplot","id":"scatterplot-10"},{"x":7.171477079796263,"y":331.4643463497452,"width":168.5297113752122,"height":191.83701188455007,"type":"scatterplot","id":"scatterplot-2"},{"x":1296.2444821731747,"y":49.983870967741886,"width":815.7555178268253,"height":580.8896434634974,"type":"scatterplot","id":"scatterplot-8"}],"relations":[{"vislist":[{"vislist":["others-9"],"relation":null,"id":"group-0"},{"vislist":["scatterplot-10"],"relation":null,"id":"group-1"}],"relation":"nested","id":"relation-0"},{"vislist":[{"vislist":["heatmap_matrix-6"],"relation":null,"id":"group-6"}],"relation":"repeated","id":"relation-3"}]},"2978_2":{"comp":[["bar_chart","table",["nested"]],["error_bar","table",["nested"]]],"visType":["bar_chart","table","error_bar"],"compType":["nested"],"compressed_tree":[{"composite_pattern":"nested","visualization_type":[["bar_chart","error_bar"],["table"]]}],"coOccurrence":[["bar_chart","error_bar",["coOccurrence"]],["bar_chart","table",["coOccurrence"]],["error_bar","table",["coOccurrence"]]],"year":2017,"conference":["VAST"],"authors":["Josua Krause","Aritra Dasgupta","Jordan Swartz","Yindalon Aphinyanagphongs","Enrico Bertini"],"title":"A Workflow for Visual Diagnostics of Binary Classifiers using Instance-Level Explanations","doi":"10.1109/VAST.2017.8585720","abstract":"Human-in-the-loop data analysis applications necessitate greater transparency in machine learning models for experts to understand and trust their decisions. To this end, we propose a visual analytics workflow to help data scientists and domain experts explore, diagnose, and understand the decisions made by a binary classifier. The approach leverages \u201cinstance-level explanations\u201d, measures of local feature relevance that explain single instances, and uses them to build a set of visual representations that guide the users in their investigation. The workflow is based on three main visual representations and steps: one based on aggregate statistics to see how data distributes across correct / incorrect decisions; one based on explanations to understand which features are used to make these decisions; and one based on raw data, to derive insights on potential root causes for the observed patterns. The workflow is derived from a long-term collaboration with a group of machine learning and healthcare professionals who used our method to make sense of machine learning models they developed. The case study from this collaboration demonstrates that the proposed workflow helps experts derive useful knowledge about the model and the phenomena it describes, thus experts can generate useful hypotheses on how a model can be improved.","keywords":"Machine Learning,Interpretation,Visual Analytics","caption":"Figure 3: In the Explanation Explorer each row represents a group of data items explained by a set of features (E). An indicator is shown for explanations longer than 3 features. Column (F) shows the distribution of true / false positive / negative data items within the group. Colors show the predicted label (\u201cblue\u201d for positive and \u201corange\u201d for negative) and a hatching pattern indicates incorrect predictions. Column (G) shows the number of items captured by the explanation. The bars are relative to the size of the largest explanation. Column (H) shows the odds ratio of the group on a logarithmic scale. Whiskers show the con\ufb01dence interval. The arrows on the right (I) navigate to the Item Level Inspector focusing on the given explanation. The controls of the Explanation Explorer are shown on the left. The \ufb01rst entry of the list of \ufb01ltered data items (B) represents the full dataset and following entries show sizes after \ufb01lter steps are applied. The \u201c+\u201d creates a new \ufb01lter according to the current selection of explanations. Explanations can be selected satisfying a condition (C) or by searching for features in the search box (A). The sort order of explanations is de\ufb01ned by the list at the bottom (D).","img_size":{"width":1902,"height":1173},"subfigures":[{"x":11.5521038302896,"y":5.569912782475391,"width":1880.4981012325131,"height":1158.6557622202408,"type":"interface","id":"interface-0"}],"visualizations":[{"x":1234.2009345794397,"y":120.58878504672899,"width":168.09345794392536,"height":982.9813084112151,"type":"bar_chart","id":"bar_chart-0"},{"x":1066.107476635514,"y":124.2429906542056,"width":160.7850467289718,"height":972.0186915887851,"type":"bar_chart","id":"bar_chart-1"},{"x":1077.3460220134857,"y":43.850467289719624,"width":497.5193552853633,"height":65.77570093457943,"type":"bar_chart","id":"bar_chart-2"},{"x":10.996071137284213,"y":668.4342928028328,"width":315.69222798339786,"height":431.29890207906277,"type":"bar_chart","id":"bar_chart-4"},{"x":1410.6096981177466,"y":123.62385563495201,"width":159.77815234954372,"height":987.2546490379452,"type":"error_bar","id":"error_bar-3"},{"x":810.8203689351874,"y":37.51253640411394,"width":787.1298918461181,"height":1076.752659306359,"type":"table","id":"table-5"}],"relations":[{"vislist":[{"vislist":["bar_chart-0","bar_chart-1","bar_chart-2","bar_chart-4","error_bar-3"],"relation":null,"id":"group-2"},{"vislist":["table-5"],"relation":null,"id":"group-0"}],"relation":"nested","id":"relation-0"}]},"1945_10":{"comp":[["matrix","sankey_diagram",["nested"]]],"visType":["matrix","sankey_diagram"],"compType":["nested"],"compressed_tree":[{"composite_pattern":"nested","visualization_type":[["matrix"],["sankey_diagram"]]}],"coOccurrence":[["matrix","sankey_diagram",["coOccurrence"]]],"year":2010,"conference":["InfoVis"],"authors":["Alexander Lex","Marc Streit","Christian Partl","Karl Kashofer","Dieter Schmalstieg"],"title":"Comparative Analysis of Multidimensional; Quantitative Data","doi":"10.1109/TVCG.2010.138","abstract":"When analyzing multidimensional, quantitative data, the comparison of two or more groups of dimensions is a common task. Typical sources of such data are experiments in biology, physics or engineering, which are conducted in different configurations and use replicates to ensure statistically significant results. One common way to analyze this data is to filter it using statistical methods and then run clustering algorithms to group similar values. The clustering results can be visualized using heat maps, which show differences between groups as changes in color. However, in cases where groups of dimensions have an a priori meaning, it is not desirable to cluster all dimensions combined, since a clustering algorithm can fragment continuous blocks of records. Furthermore, identifying relevant elements in heat maps becomes more difficult as the number of dimensions increases. To aid in such situations, we have developed Matchmaker, a visualization technique that allows researchers to arbitrarily arrange and compare multiple groups of dimensions at the same time. We create separate groups of dimensions which can be clustered individually, and place them in an arrangement of heat maps reminiscent of parallel coordinates. To identify relations, we render bundled curves and ribbons between related records in different groups. We then allow interactive drill-downs using enlarged detail views of the data, which enable in-depth comparisons of clusters between groups. To reduce visual clutter, we minimize crossings between the views. This paper concludes with two case studies. The first demonstrates the value of our technique for the comparison of clustering algorithms. In the second, biologists use our system to investigate why certain strains of mice develop liver disease while others remain healthy, informally showing the efficacy of our system when analyzing multidimensional data containing distinct groups of dimensions.","keywords":"Multidimensional data, cluster comparison, bioinformatics visualization","caption":"Fig. 11. Screenshots of the Caleydo Matchmaker taken during an analysis session by a biologist. (a) We see four groups (1-4). The \ufb01rst two, C57 and AJ are homogeneous. Each consisting of 9 experiments: control, 7 days of intoxication and 8 weeks of intoxication, with 3 replicates per category (from left to right). The third (Combined AJ and C57) contains all experiments from the \ufb01rst two groups. The fourth group is a copy of the \ufb01rst to enable better comparisons. Notice the inhomogeneous clusters for the combined group (5). Clustering the single columns yields more consistent results, allowing a biologist to assign meaning to a cluster. The biologist brushed the bottom cluster in AJ (6), identifying that the genes in this cluster are split into two groups in C57, one being similarly regulated over time to AJ (7), the other (8) containing genes not-deregulated (equally regulated) in C57 while upregulated (going up over time) in AJ (6). Since this difference may be important, he chose to explore this cluster in detail. (b) We see the deregulated cluster in AJ on the right, and the not-deregulated cluster for C57 containing the same genes on the left. By exploring the genes and using Caleydo\u2019s built-in features to \ufb01nd contextual information on genes, he was able to hypothesize that these genes are involved in apoptosis and thus alter the phenotype of the liver tissue by removal of cells damaged by oxidative stress.","img_size":{"width":2169,"height":689},"subfigures":[{"x":30.589362817198637,"y":9.547583657584823,"width":1056.4876925539052,"height":639.3610450865723,"type":"interface","id":"interface-0"}],"visualizations":[{"x":42.050656660412756,"y":541.8667917448405,"width":109.87429643527202,"height":93.59662288930578,"type":"bar_chart","id":"bar_chart-0"},{"x":1110.951219512195,"y":540.5103189493433,"width":103.09193245778624,"height":93.59662288930578,"type":"bar_chart","id":"bar_chart-1"},{"x":154.63789868667914,"y":72.52720450281433,"width":43.40712945590994,"height":523.5984990619136,"type":"heatmap","id":"heatmap-2"},{"x":462.55722326454026,"y":73.88367729831145,"width":50.18949343339585,"height":526.311444652908,"type":"heatmap","id":"heatmap-3"},{"x":675.5234521575984,"y":69.81425891181992,"width":120.72607879924954,"height":529.0243902439023,"type":"heatmap","id":"heatmap-4"},{"x":1033.6322701688555,"y":67.10131332082554,"width":46.120075046904276,"height":534.4502814258911,"type":"heatmap","id":"heatmap-5"},{"x":1241.1726078799247,"y":72.52720450281427,"width":67.82363977485944,"height":526.311444652908,"type":"heatmap","id":"heatmap-6"},{"x":1410.731707317073,"y":278.71106941838644,"width":118.01313320825513,"height":316.0581613508442,"type":"heatmap","id":"heatmap-7"},{"x":1823.0994371482175,"y":87.44840525328331,"width":109.87429643527207,"height":497.825515947467,"type":"heatmap","id":"heatmap-8"},{"x":2050.9868667917444,"y":69.81425891181992,"width":65.11069418386523,"height":529.0243902439023,"type":"heatmap","id":"heatmap-9"},{"x":1368.6810506566603,"y":84.73545966228895,"width":160.06378986866775,"height":193.97560975609753,"type":"heatmap","id":"heatmap-10"},{"x":153.281425891182,"y":68.45778611632272,"width":46.12007504690419,"height":524.9549718574109,"type":"matrix","id":"matrix-11"},{"x":463.9136960600375,"y":73.88367729831148,"width":50.18949343339585,"height":523.5984990619136,"type":"matrix","id":"matrix-12"},{"x":676.8799249530955,"y":67.10131332082554,"width":113.94371482176359,"height":522.2420262664164,"type":"matrix","id":"matrix-13"},{"x":1025.4934333958724,"y":69.81425891181992,"width":48.833020637898926,"height":524.9549718574107,"type":"matrix","id":"matrix-14"},{"x":1414.8011257035646,"y":274.64165103189504,"width":109.87429643527207,"height":302.49343339587233,"type":"matrix","id":"matrix-15"},{"x":1364.6116322701685,"y":84.73545966228892,"width":164.13320825515962,"height":187.19324577861167,"type":"matrix","id":"matrix-16"},{"x":1233.0337711069417,"y":72.5272045028143,"width":78.67542213883667,"height":523.5984990619136,"type":"matrix","id":"matrix-17"},{"x":1823.0994371482175,"y":88.80487804878048,"width":112.58724202626651,"height":496.46904315196974,"type":"matrix","id":"matrix-18"},{"x":2050.9868667917444,"y":68.45778611632272,"width":73.2495309568485,"height":535.8067542213882,"type":"matrix","id":"matrix-19"},{"x":149.21200750469032,"y":68.45778611632272,"width":930.5403377110699,"height":569.7185741088178,"type":"sankey_diagram","id":"sankey_diagram-20"},{"x":1222.1819887429642,"y":69.81425891181992,"width":918.3320825515948,"height":561.5797373358348,"type":"sankey_diagram","id":"sankey_diagram-21"}],"relations":[{"vislist":[{"vislist":["matrix-14","matrix-13","matrix-12","matrix-11"],"relation":null,"id":"group-0"},{"vislist":["sankey_diagram-20"],"relation":null,"id":"group-1"}],"relation":"nested","id":"relation-0"}]},"1948_4":{"comp":[["matrix","matrix",["nested"]]],"visType":["matrix"],"compType":["nested"],"compressed_tree":[{"composite_pattern":"nested","visualization_type":[["matrix"],["matrix"]]}],"coOccurrence":[["matrix","matrix",["coOccurrence"]]],"year":2010,"conference":["InfoVis"],"authors":["Rita Borgo","Karl J. Proctor","Min Chen","Heike Leitte","Tavi Murray","Ian M. Thornton"],"title":"Evaluating the impact of task demands and block resolution on the effectiveness of pixel-based visualization","doi":"10.1109/TVCG.2010.150","abstract":"Pixel-based visualization is a popular method of conveying large amounts of numerical data graphically. Application scenarios include business and finance, bioinformatics and remote sensing. In this work, we examined how the usability of such visual representations varied across different tasks and block resolutions. The main stimuli consisted of temporal pixel-based visualization with a white-red color map, simulating monthly temperature variation over a six-year period. In the first study, we included 5 separate tasks to exert different perceptual loads. We found that performance varied considerably as a function of task, ranging from 75% correct in low-load tasks to below 40% in high-load tasks. There was a small but consistent effect of resolution, with the uniform patch improving performance by around 6% relative to higher block resolution. In the second user study, we focused on a high-load task for evaluating month-to-month changes across different regions of the temperature range. We tested both CIE L*u*v* and RGB color spaces. We found that the nature of the change-evaluation errors related directly to the distance between the compared regions in the mapped color space. We were able to reduce such errors by using multiple color bands for the same data range. In a final study, we examined more fully the influence of block resolution on performance, and found block resolution had a limited impact on the effectiveness of pixel-based visualization.","keywords":"Pixel-based visualization, evaluation, user study, visual search, change detection","caption":"Fig. 4. User Study 1. User Interface Description.","img_size":{"width":1062,"height":732},"subfigures":[{"x":124.91917736804602,"y":3.109477842838727,"width":816.0545802869292,"height":657.226126902623,"type":"interface","id":"interface-1"}],"visualizations":[{"x":173.63037705195944,"y":126.46856386540755,"width":745.7342718062192,"height":422.0718683260031,"type":"matrix","id":"matrix-1"},{"x":150.73719037878018,"y":103.650978732655,"width":768.5243356063457,"height":443.7108264049045,"type":"matrix","id":"matrix-2"},{"x":2.954198473282418,"y":3.725190839694657,"width":1056.5460064279553,"height":724.5496183206108,"type":"small_multiple","id":"small_multiple-0"}],"relations":[{"vislist":[{"vislist":["matrix-1"],"relation":null,"id":"group-0"},{"vislist":["matrix-2"],"relation":null,"id":"group-1"}],"relation":"nested","id":"relation-0"}]},"1961_9":{"comp":[["scatterplot","donut_chart",["nested"]],["bar_chart","donut_chart",["nested"]]],"visType":["scatterplot","donut_chart","bar_chart"],"compType":["nested"],"compressed_tree":[{"composite_pattern":"nested","visualization_type":[["scatterplot","bar_chart"],["donut_chart"]]}],"coOccurrence":[["scatterplot","bar_chart",["coOccurrence"]],["scatterplot","donut_chart",["coOccurrence"]],["bar_chart","donut_chart",["coOccurrence"]]],"year":2010,"conference":["InfoVis"],"authors":["Yingcai Wu","Furu Wei","Shixia Liu","Norman Au","Weiwei Cui","Hong Zhou","Huamin Qu"],"title":"OpinionSeer: Interactive Visualization of Hotel Customer Feedback","doi":"10.1109/TVCG.2010.183","abstract":"The rapid development of Web technology has resulted in an increasing number of hotel customers sharing their opinions on the hotel services. Effective visual analysis of online customer opinions is needed, as it has a significant impact on building a successful business. In this paper, we present OpinionSeer, an interactive visualization system that could visually analyze a large collection of online hotel customer reviews. The system is built on a new visualization-centric opinion mining technique that considers uncertainty for faithfully modeling and analyzing customer opinions. A new visual representation is developed to convey customer opinions by augmenting well-established scatterplots and radial visualization. To provide multiple-level exploration, we introduce subjective logic to handle and organize subjective opinions with degrees of uncertainty. Several case studies illustrate the effectiveness and usefulness of OpinionSeer on analyzing relationships among multiple data dimensions and comparing opinions of different groups. Aside from data on hotel customer feedback, OpinionSeer could also be applied to visually analyze customer opinions on other products or services.","keywords":"opinion visualization, radial visualization, uncertainty visualization","caption":"Fig. 10. (a) and (b): OpinionSeer showing the opinions of the customers from US and China; (c) and (d): OpinionSeer showing temporal patterns of customer opinions.","img_size":{"width":1051,"height":943},"subfigures":[{"x":20.99180389024272,"y":456.8913568854707,"width":507.06112478418373,"height":459.7576205272262,"type":"single","id":"single-0"}],"visualizations":[{"x":82.88840262582073,"y":20.634573304157552,"width":435.3894967177244,"height":396.18380743982505,"type":"bar_chart","id":"bar_chart-0"},{"x":588.4354485776806,"y":24.761487964989065,"width":435.3894967177246,"height":389.99343544857777,"type":"bar_chart","id":"bar_chart-1"},{"x":29.238512035011016,"y":458.0875273522976,"width":499.35667396061285,"height":458.0875273522976,"type":"bar_chart","id":"bar_chart-2"},{"x":530.6586433260396,"y":460.15098468271344,"width":499.35667396061257,"height":458.0875273522976,"type":"bar_chart","id":"bar_chart-3"},{"x":82.88840262582073,"y":18.571115973741797,"width":437.4529540481401,"height":398.2472647702408,"type":"donut_chart","id":"donut_chart-4"},{"x":590.4989059080965,"y":28.888402625820575,"width":427.1356673960616,"height":385.8665207877462,"type":"donut_chart","id":"donut_chart-5"},{"x":29.238512035011016,"y":456.02407002188187,"width":497.2932166301971,"height":464.27789934354496,"type":"donut_chart","id":"donut_chart-6"},{"x":530.6586433260396,"y":458.0875273522976,"width":497.29321663019704,"height":458.0875273522976,"type":"donut_chart","id":"donut_chart-7"},{"x":84.95185995623638,"y":22.698030634573307,"width":431.262582056893,"height":389.99343544857777,"type":"scatterplot","id":"scatterplot-8"},{"x":590.4989059080965,"y":24.761487964989065,"width":431.2625820568931,"height":389.99343544857777,"type":"scatterplot","id":"scatterplot-9"},{"x":29.238512035011016,"y":451.89715536105035,"width":499.35667396061285,"height":466.3413566739607,"type":"scatterplot","id":"scatterplot-10"},{"x":530.6586433260396,"y":458.0875273522976,"width":499.35667396061257,"height":460.15098468271344,"type":"scatterplot","id":"scatterplot-11"}],"relations":[{"vislist":[{"vislist":["scatterplot-10","bar_chart-2"],"relation":null,"id":"group-1"},{"vislist":["donut_chart-6"],"relation":null,"id":"group-2"}],"relation":"nested","id":"relation-0"}]},"1967_4":{"comp":[["word_cloud","parallel_coordinate",["nested"]]],"visType":["word_cloud","parallel_coordinate"],"compType":["nested"],"compressed_tree":[{"composite_pattern":"nested","visualization_type":[["word_cloud"],["parallel_coordinate"]]}],"coOccurrence":[["word_cloud","parallel_coordinate",["coOccurrence"]]],"year":2010,"conference":["InfoVis"],"authors":["Bongshin Lee","Nathalie Henry Riche","Amy K. Karlson","Sheelagh Carpendale"],"title":"SparkClouds: Visualizing Trends in Tag Clouds","doi":"10.1109/TVCG.2010.194","abstract":"Tag clouds have proliferated over the web over the last decade. They provide a visual summary of a collection of texts by visually depicting the tag frequency by font size. In use, tag clouds can evolve as the associated data source changes over time. Interesting discussions around tag clouds often include a series of tag clouds and consider how they evolve over time. However, since tag clouds do not explicitly represent trends or support comparisons, the cognitive demands placed on the person for perceiving trends in multiple tag clouds are high. In this paper, we introduce SparkClouds, which integrate sparklines into a tag cloud to convey trends between multiple tag clouds. We present results from a controlled study that compares SparkClouds with two traditional trend visualizations-multiple line graphs and stacked bar charts-as well as Parallel Tag Clouds. Results show that SparkClouds\' ability to show trends compares favourably to the alternative visualizations.","keywords":"Tag clouds, trend visualization, multiple line graphs, stacked bar charts, evaluation","caption":"Fig. 4. ParallelCloud displays a gradient line that links the same word occurring in multiple tag clouds when people move the cursor over a word.","img_size":{"width":1917,"height":867},"subfigures":[{"x":8.135507577911053,"y":4.306624583726586,"width":1905.7246135624628,"height":845.3965969839658,"type":"interface","id":"interface-1"}],"visualizations":[{"x":16.674600615345636,"y":12.142861033282173,"width":1888.7235366399152,"height":768.2959325339779,"type":"parallel_coordinate","id":"parallel_coordinate-1"},{"x":12.768052516411402,"y":4.226712292522887,"width":1897.1553610503283,"height":779.730853391685,"type":"word_cloud","id":"word_cloud-0"}],"relations":[{"vislist":[{"vislist":["word_cloud-0"],"relation":null,"id":"group-0"},{"vislist":["parallel_coordinate-1"],"relation":null,"id":"group-1"}],"relation":"nested","id":"relation-0"}]},"1969_0":{"comp":[["scatterplot","matrix",["nested"]],["scatterplot","graph",["large_view"]]],"visType":["scatterplot","matrix","graph"],"compType":["nested","large_view"],"compressed_tree":[{"composite_pattern":"large_view","visualization_type":[["scatterplot"],["graph"]]},{"composite_pattern":"nested","visualization_type":[["scatterplot"],["matrix"]]}],"coOccurrence":[["scatterplot","graph",["coOccurrence"]],["scatterplot","matrix",["coOccurrence"]],["graph","matrix",["coOccurrence"]]],"year":2010,"conference":["InfoVis"],"authors":["Christophe Viau","Michael J. McGuffin","Yves Chiricota","Igor Jurisica"],"title":"The FlowVizMenu and Parallel Scatterplot Matrix: Hybrid Multidimensional Visualizations for Network Exploration","doi":"10.1109/TVCG.2010.205","abstract":"A standard approach for visualizing multivariate networks is to use one or more multidimensional views (for example, scatterplots) for selecting nodes by various metrics, possibly coordinated with a node-link view of the network. In this paper, we present three novel approaches for achieving a tighter integration of these views through hybrid techniques for multidimensional visualization, graph selection and layout. First, we present the FlowVizMenu, a radial menu containing a scatterplot that can be popped up transiently and manipulated with rapid, fluid gestures to select and modify the axes of its scatterplot. Second, the FlowVizMenu can be used to steer an attribute-driven layout of the network, causing certain nodes of a node-link diagram to move toward their corresponding positions in a scatterplot while others can be positioned manually or by force-directed layout. Third, we describe a novel hybrid approach that combines a scatterplot matrix (SPLOM) and parallel coordinates called the Parallel Scatterplot Matrix (P-SPLOM), which can be used to visualize and select features within the network. We also describe a novel arrangement of scatterplots called the Scatterplot Staircase (SPLOS) that requires less space than a traditional scatterplot matrix. Initial user feedback is reported.","keywords":"Interactive graph drawing, network layout, attribute-driven layout, parallel coordinates, scatterplot matrix, radial menu","caption":"Fig. 1. The user interface. At left: the node-link diagram, here with nodes positioned according to an attribute-driven layout, i.e., adopting their corresponding positions within a degree \xd7 s-mean scatterplot. Top middle: the FlowVizMenu is popped up and contains the same scatterplot. Fluid gestures within the menu select dimensions to drive the attribute-driven layout with smoothly animated transitions. At right: the P-SPLOM, here showing a SPLOM of the nodes\u2019 metrics.","img_size":{"width":1917,"height":1001},"subfigures":[{"x":15.27801354388786,"y":9.928163995651085,"width":1887.509170389706,"height":981.1436720086969,"type":"interface","id":"interface-0"}],"visualizations":[{"x":22.115973741794278,"y":26.284463894967185,"width":944.0503282275712,"height":946.2407002188183,"type":"graph","id":"graph-0"},{"x":968.3566739606129,"y":61.33041575492343,"width":933.0984682713348,"height":928.7177242888403,"type":"scatterplot","id":"scatterplot-1"},{"x":583.3107238195802,"y":27.853050719687566,"width":378.4705405828364,"height":382.3486372460792,"type":"scatterplot","id":"scatterplot-2"},{"x":970.54704595186,"y":61.33041575492343,"width":928.7177242888403,"height":926.5273522975931,"type":"matrix","id":"matrix-3"}],"relations":[{"vislist":[{"vislist":["scatterplot-2"],"relation":null,"id":"group-1"},{"vislist":["graph-0"],"relation":null,"id":"group-2"}],"relation":"large_view","id":"relation-1"},{"vislist":[{"vislist":["scatterplot-1"],"relation":null,"id":"group-5"},{"vislist":["matrix-3"],"relation":null,"id":"group-6"}],"relation":"nested","id":"relation-3"}]},"1978_0":{"comp":[["others","stripe_graph",["nested"]]],"visType":["others","stripe_graph"],"compType":["nested"],"compressed_tree":[{"composite_pattern":"nested","visualization_type":[["others"],["stripe_graph"]]}],"coOccurrence":[["others","stripe_graph",["coOccurrence"]]],"year":2010,"conference":["VAST"],"authors":["Tobias Ruppert","J\xf6rn Kohlhammer"],"title":"A radial visualization tool for depicting hierarchically structured video content","doi":"10.1109/VAST.2010.5650177","abstract":"The visual analysis of video content is an important research topic due to the huge amount of video data that is generated every day. Annotating this data will become a major problem since the amount of videos further increases. With this work we introduce a system that combines a visualization tool with automatic video segmentation techniques and a characteristic key-frame extraction. A summary of the content of a whole video in one view is realized. Furthermore, the user can interactively browse through the video via our visualization interface to get more detailed information. The system is adapted to two application scenarios and a third application is discussed for future work.","keywords":"","caption":"Figure 1: Video content visualization showing the divided video seg- ments in the outer circular rings.","img_size":{"width":957,"height":909},"subfigures":[{"x":4.531566041507684,"y":5.177515562675274,"width":948.9046243245919,"height":897.6775629517854,"type":"single","id":"single-0"}],"visualizations":[{"x":25.881477549943785,"y":25.200903950362097,"width":897.7840162488964,"height":861.0814066800609,"type":"others","id":"others-1"},{"x":19.74140072179143,"y":19.05993828778733,"width":910.0641699052017,"height":872.1217307148162,"type":"stripe_graph","id":"stripe_graph-0"}],"relations":[{"vislist":[{"vislist":["others-1"],"relation":null,"id":"group-0"},{"vislist":["stripe_graph-0"],"relation":null,"id":"group-1"}],"relation":"nested","id":"relation-0"}]},"1990_6":{"comp":[["proportional_area_chart","matrix",["nested"]],["scatterplot","matrix",["nested"]]],"visType":["proportional_area_chart","matrix","scatterplot"],"compType":["nested"],"compressed_tree":[{"composite_pattern":"nested","visualization_type":[["proportional_area_chart"],["matrix"]]},{"composite_pattern":"nested","visualization_type":[["scatterplot"],["matrix"]]}],"coOccurrence":[["proportional_area_chart","matrix",["coOccurrence"]],["proportional_area_chart","scatterplot",["coOccurrence"]],["matrix","scatterplot",["coOccurrence"]]],"year":2010,"conference":["VAST"],"authors":["Malgorzata Migut","Marcel Worring"],"title":"Visual exploration of classification models for risk assessment","doi":"10.1109/VAST.2010.5652398","abstract":"In risk assessment applications well informed decisions are made based on huge amounts of multi-dimensional data. In many domains not only the risk of a wrong decision, but in particular the trade-off between the costs of possible decisions are of utmost importance. In this paper we describe a framework tightly integrating interactive visual exploration with machine learning to support the decision making process. The proposed approach uses a series of interactive 2D visualizations of numeric and ordinal data combined with visualization of classification models. These series of visual elements are further linked to the classifier\'s performance visualized using an interactive performance curve. An interactive decision point on the performance curve allows the decision maker to steer the classification model and instantly identify the critical, cost changing data elements, in the various linked visualizations. The critical data elements are represented as images in order to trigger associations related to the knowledge of the expert. In this context the data visualization and classification results are not only linked together, but are also linked back to the classification model. Such a visual analytics framework allows the user to interactively explore the costs of his decisions for different settings of the model and accordingly use the most suitable classification model and make more informed and reliable decisions. A case study on data from the Forensic Psychiatry domain reveals the usefulness of the suggested approach.","keywords":"Visual Analytics, Interactive Visual Exploration, Decision Boundary Visualization, Multi-dimensional Space, Classification","caption":"Figure 6: Screenshot of the system.","img_size":{"width":1074,"height":789},"subfigures":[{"x":6.1757462670012275,"y":3.665594271101483,"width":1064.166496636722,"height":781.6688114577973,"type":"interface","id":"interface-0"}],"visualizations":[{"x":704.3329048843186,"y":176.46015424164526,"width":322.4961439588689,"height":208.91259640102828,"type":"line_chart","id":"line_chart-0"},{"x":44.84921989039813,"y":396.507123957009,"width":299.1675681165189,"height":217.99169195035574,"type":"matrix","id":"matrix-7"},{"x":47.17095115681234,"y":399.5706940874036,"width":294.1002570694087,"height":214.99742930591268,"type":"proportional_area_chart","id":"proportional_area_chart-1"},{"x":387.92159383033413,"y":429.9948586118251,"width":253.53470437017987,"height":194.7146529562982,"type":"proportional_area_chart","id":"proportional_area_chart-2"},{"x":365.6105398457584,"y":139.9511568123393,"width":334.6658097686375,"height":243.39331619537273,"type":"scatterplot","id":"scatterplot-3"},{"x":706.3611825192802,"y":395.51413881748067,"width":342.77892030848324,"height":243.39331619537273,"type":"scatterplot","id":"scatterplot-4"},{"x":61.76710481905485,"y":158.81348233090876,"width":257.0703152538396,"height":193.734150626082,"type":"scatterplot","id":"scatterplot-5"},{"x":61.36889460154242,"y":160.23393316195373,"width":267.73264781491,"height":194.71465295629818,"type":"matrix","id":"matrix-6"}],"relations":[{"vislist":[{"vislist":["proportional_area_chart-1"],"relation":null,"id":"group-0"},{"vislist":["matrix-7"],"relation":null,"id":"group-1"}],"relation":"nested","id":"relation-0"},{"vislist":[{"vislist":["scatterplot-5"],"relation":null,"id":"group-2"},{"vislist":["matrix-6"],"relation":null,"id":"group-3"}],"relation":"nested","id":"relation-1"}]},"2234_7":{"comp":[["line_chart","table",["nested"]]],"visType":["line_chart","table"],"compType":["nested"],"compressed_tree":[{"composite_pattern":"nested","visualization_type":[["line_chart"],["table"]]},{"composite_pattern":"nested","visualization_type":[["line_chart"],["table"]]}],"coOccurrence":[["line_chart","table",["coOccurrence"]]],"year":2012,"conference":["InfoVis"],"authors":["Nadia Boukhelifa","Anastasia Bezerianos","Tobias Isenber","Jean-Daniel Fekete"],"title":"Evaluating Sketchiness as a Visual Variable for the Depiction of Qualitative Uncertainty","doi":"10.1109/TVCG.2012.220","abstract":"We report on results of a series of user studies on the perception of four visual variables that are commonly used in the literature to depict uncertainty. To the best of our knowledge, we provide the first formal evaluation of the use of these variables to facilitate an easier reading of uncertainty in visualizations that rely on line graphical primitives. In addition to blur, dashing and grayscale, we investigate the use of `sketchiness\' as a visual variable because it conveys visual impreciseness that may be associated with data quality. Inspired by work in non-photorealistic rendering and by the features of hand-drawn lines, we generate line trajectories that resemble hand-drawn strokes of various levels of proficiency-ranging from child to adult strokes-where the amount of perturbations in the line corresponds to the level of uncertainty in the data. Our results show that sketchiness is a viable alternative for the visualization of uncertainty in lines and is as intuitive as blur; although people subjectively prefer dashing style over blur, grayscale and sketchiness. We discuss advantages and limitations of each technique and conclude with design considerations on how to deploy these visual variables to effectively depict various levels of uncertainty for line marks.","keywords":"Uncertainty visualization, qualitative evaluation, quantitative evaluation, perception","caption":"Fig. 8. The user interface for the sketchiness levels study showing the instructions and legend (left) and a magnitude estimation task (right).","img_size":{"width":1074,"height":418},"subfigures":[{"x":10.120157205730386,"y":24.67539335823052,"width":522.5468868380099,"height":390.45482660416747,"type":"interface","id":"interface-0"},{"x":532.9542288917222,"y":27.43280974335777,"width":530.9079321354112,"height":386.61734870473003,"type":"interface","id":"interface-1"}],"visualizations":[{"x":23.50844277673546,"y":234.187617260788,"width":494.3489681050658,"height":113.51219512195127,"type":"line_chart","id":"line_chart-0"},{"x":549.4258911819888,"y":40.74671669793622,"width":492.33395872420266,"height":143.7373358348968,"type":"line_chart","id":"line_chart-1"},{"x":546.0675422138837,"y":247.62101313320832,"width":474.87054409005634,"height":40.30018761726075,"type":"line_chart","id":"line_chart-2"},{"x":24.18011257035647,"y":232.17260787992495,"width":493.0056285178237,"height":116.87054409005628,"type":"table","id":"table-3"},{"x":546.7392120075048,"y":40.0750469043152,"width":496.36397748592884,"height":143.7373358348968,"type":"table","id":"table-4"}],"relations":[{"vislist":[{"vislist":["line_chart-0"],"relation":null,"id":"group-0"},{"vislist":["table-3"],"relation":null,"id":"group-1"}],"relation":"nested","id":"relation-0"},{"vislist":[{"vislist":["line_chart-1"],"relation":null,"id":"group-2"},{"vislist":["table-4"],"relation":null,"id":"group-3"}],"relation":"nested","id":"relation-1"}]},"2236_9":{"comp":[["bar_chart","sankey_diagram",["nested"]]],"visType":["bar_chart","sankey_diagram"],"compType":["nested"],"compressed_tree":[{"composite_pattern":"nested","visualization_type":[["bar_chart"],["sankey_diagram"]]}],"coOccurrence":[["bar_chart","sankey_diagram",["coOccurrence"]]],"year":2012,"conference":["InfoVis"],"authors":["Krist Wongsuphasawat","David Gotz"],"title":"Exploring Flow, Factors, and Outcomes of Temporal Event Sequences with the Outflow Visualization","doi":"10.1109/TVCG.2012.225","abstract":"Event sequence data is common in many domains, ranging from electronic medical records (EMRs) to sports events. Moreover, such sequences often result in measurable outcomes (e.g., life or death, win or loss). Collections of event sequences can be aggregated together to form event progression pathways. These pathways can then be connected with outcomes to model how alternative chains of events may lead to different results. This paper describes the Outflow visualization technique, designed to (1) aggregate multiple event sequences, (2) display the aggregate pathways through different event states with timing and cardinality, (3) summarize the pathways\' corresponding outcomes, and (4) allow users to explore external factors that correlate with specific pathway state transitions. Results from a user study with twelve participants show that users were able to learn how to use Outflow easily with limited training and perform a range of tasks both accurately and rapidly.","keywords":"Outflow, information visualization, temporal event sequences, state diagram, state transition","caption":"Fig. 10. Outflow highlights factors that are strongly correlated with specific event pathways. In this screenshot, a physician has focused on a group of patients transitioning from the current state due to the onset of the \u201cNYHA\u201d symptom. This transition seems to be deadly, as seen from the color-coding in red. The right sidebar displays medications (factors) with high correlations to this transition. The factor with the highest correlation in this example is prescribing antiarrhythmic agents. This correlation, which may or may not be causal, can help clinicians generate hypotheses about how best to treat a patient.","img_size":{"width":2080,"height":1184},"subfigures":[{"x":7.657322651836548,"y":16.802079031637888,"width":1994.13700508797,"height":1165.516747714565,"type":"interface","id":"interface-0"}],"visualizations":[{"x":1650.7193675889323,"y":25.739130434782606,"width":301.8498023715415,"height":575.6205533596838,"type":"bar_chart","id":"bar_chart-0"},{"x":29.154150197628383,"y":105.29644268774703,"width":1619.2252964426877,"height":1059.98418972332,"type":"bar_chart","id":"bar_chart-1"},{"x":26.81422924901176,"y":105.29644268774703,"width":1623.9051383399208,"height":1059.98418972332,"type":"sankey_diagram","id":"sankey_diagram-2"}],"relations":[{"vislist":[{"vislist":["bar_chart-1"],"relation":null,"id":"group-0"},{"vislist":["sankey_diagram-2"],"relation":null,"id":"group-1"}],"relation":"nested","id":"relation-0"}]},"2236_8":{"comp":[["bar_chart","sankey_diagram",["nested"]]],"visType":["bar_chart","sankey_diagram"],"compType":["nested"],"compressed_tree":[{"composite_pattern":"nested","visualization_type":[["bar_chart"],["sankey_diagram"]]}],"coOccurrence":[["bar_chart","sankey_diagram",["coOccurrence"]]],"year":2012,"conference":["InfoVis"],"authors":["Krist Wongsuphasawat","David Gotz"],"title":"Exploring Flow, Factors, and Outcomes of Temporal Event Sequences with the Outflow Visualization","doi":"10.1109/TVCG.2012.225","abstract":"Event sequence data is common in many domains, ranging from electronic medical records (EMRs) to sports events. Moreover, such sequences often result in measurable outcomes (e.g., life or death, win or loss). Collections of event sequences can be aggregated together to form event progression pathways. These pathways can then be connected with outcomes to model how alternative chains of events may lead to different results. This paper describes the Outflow visualization technique, designed to (1) aggregate multiple event sequences, (2) display the aggregate pathways through different event states with timing and cardinality, (3) summarize the pathways\' corresponding outcomes, and (4) allow users to explore external factors that correlate with specific pathway state transitions. Results from a user study with twelve participants show that users were able to learn how to use Outflow easily with limited training and perform a range of tasks both accurately and rapidly.","keywords":"Outflow, information visualization, temporal event sequences, state diagram, state transition","caption":"Fig. 9. Using the same dataset as illustrated in Fig. 1, a user has adjusted the simplification slider to group states with similar outcomes. Clustered states are represented with gray nodes. This simplified view shows that as more events occur (i.e., as more goals are scored), the paths diverge into two distinct sets of clustered states. The simplified states more clearly separate winning scorelines from losing scorelines. As more goals are scored, the probable outcomes of the games become more obvious.","img_size":{"width":1992,"height":1140},"subfigures":[{"x":10.70979234944366,"y":2.897166781553966,"width":1979.0755395859962,"height":1135.418914789,"type":"interface","id":"interface-0"}],"visualizations":[{"x":344.8932806324111,"y":4.392076623216271,"width":1642.7146427443727,"height":1128.7351778656127,"type":"bar_chart","id":"bar_chart-0"},{"x":342.6403162055336,"y":6.758893280632411,"width":1644.9676071712502,"height":1121.9762845849802,"type":"sankey_diagram","id":"sankey_diagram-1"}],"relations":[{"vislist":[{"vislist":["bar_chart-0"],"relation":null,"id":"group-0"},{"vislist":["sankey_diagram-1"],"relation":null,"id":"group-1"}],"relation":"nested","id":"relation-0"}]},"2237_3":{"comp":[["bar_chart","table",["nested"]],["others","table",["nested"]],["tree","table",["nested"]]],"visType":["bar_chart","table","others","tree"],"compType":["nested"],"compressed_tree":[{"composite_pattern":"nested","visualization_type":[["bar_chart","others","tree"],["table"]]}],"coOccurrence":[["bar_chart","others",["coOccurrence"]],["bar_chart","tree",["coOccurrence"]],["bar_chart","table",["coOccurrence"]],["others","tree",["coOccurrence"]],["others","table",["coOccurrence"]],["tree","table",["coOccurrence"]]],"year":2012,"conference":["InfoVis"],"authors":["Jian Zhao","Fanny Chevalier","Christopher Collins","Ravin Balakrishnan"],"title":"Facilitating Discourse Analysis with Interactive Visualization","doi":"10.1109/TVCG.2012.226","abstract":"A discourse parser is a natural language processing system which can represent the organization of a document based on a rhetorical structure tree-one of the key data structures enabling applications such as text summarization, question answering and dialogue generation. Computational linguistics researchers currently rely on manually exploring and comparing the discourse structures to get intuitions for improving parsing algorithms. In this paper, we present DAViewer, an interactive visualization system for assisting computational linguistics researchers to explore, compare, evaluate and annotate the results of discourse parsers. An iterative user-centered design process with domain experts was conducted in the development of DAViewer. We report the results of an informal formative study of the system to better understand how the proposed visualization and interaction techniques are used in the real research environment.","keywords":"Discourse structure, tree comparison, computational linguisitics, visual analytics, interaction techniques","caption":"Fig. 4. The DAViewer interface is comprised of: (a) an overview which displays the overall performance of all the parsers over all the documents in the dataset, (b) a detail panel which visualizes the discourse tree structures of the focused algorithms and documents as node-link or icicle dendrograms, (c) a status panel which provides the basic properties of the currently selected items as well as an interactive legend for filtering operations, (d) an annotation panel which allows users to edit notes, (e) a text panel which shows the content of the active document as parsed by the focused algorithm, and (f) a search window which for querying based on keyword and structure over the data in the detail panel.","img_size":{"width":2145,"height":1224},"subfigures":[{"x":5.814898931408821,"y":0.5291586853577556,"width":2132.0686009869696,"height":1224.2443282283878,"type":"interface","id":"interface-0"}],"visualizations":[{"x":834.0822932038292,"y":110.48476764873837,"width":51.13029886425407,"height":993.5716249868615,"type":"bar_chart","id":"bar_chart-15"},{"x":398.9663266854071,"y":689.7284946721048,"width":429.43632154864304,"height":36.06514224602807,"type":"others","id":"others-16"},{"x":882.1242740449821,"y":685.6347663544306,"width":424.2679747489072,"height":41.907261604369886,"type":"others","id":"others-17"},{"x":22.666007905138205,"y":101.59683794466395,"width":256.4110671936758,"height":435.4150197628458,"type":"table","id":"table-0"},{"x":309.09625249364854,"y":110.47164843946216,"width":1000.8251754820012,"height":991.706095462282,"type":"table","id":"table-14"},{"x":404.8636363636361,"y":128.20553359683788,"width":188.67984189723327,"height":147.55731225296444,"type":"tree","id":"tree-1"},{"x":598.381422924901,"y":730.5296442687745,"width":234.64031620553362,"height":370.102766798419,"type":"tree","id":"tree-10"},{"x":878.982213438735,"y":730.5296442687745,"width":212.86956521739114,"height":370.102766798419,"type":"tree","id":"tree-11"},{"x":1091.851778656126,"y":730.5296442687745,"width":210.45059288537553,"height":372.52173913043504,"type":"tree","id":"tree-12"},{"x":1805.44861660079,"y":343.494071146245,"width":292.695652173913,"height":171.74703557312247,"type":"tree","id":"tree-13"},{"x":603.2193675889326,"y":128.20553359683788,"width":229.80237154150203,"height":149.97628458498028,"type":"tree","id":"tree-2"},{"x":878.982213438735,"y":123.36758893280623,"width":215.28853754940712,"height":152.39525691699606,"type":"tree","id":"tree-3"},{"x":1096.689723320158,"y":130.6245059288537,"width":200.77470355731205,"height":142.7193675889328,"type":"tree","id":"tree-4"},{"x":1099.1086956521738,"y":270.9249011857707,"width":195.93675889328097,"height":423.3201581027667,"type":"tree","id":"tree-5"},{"x":878.982213438735,"y":275.7628458498023,"width":215.28853754940712,"height":416.0632411067192,"type":"tree","id":"tree-6"},{"x":598.381422924901,"y":278.18181818181813,"width":232.22134387351767,"height":411.2252964426876,"type":"tree","id":"tree-7"},{"x":404.8636363636361,"y":278.18181818181813,"width":193.51778656126487,"height":413.64426877470345,"type":"tree","id":"tree-8"},{"x":409.7015810276678,"y":732.9486166007904,"width":188.67984189723327,"height":365.2648221343873,"type":"tree","id":"tree-9"}],"relations":[{"vislist":[{"vislist":["bar_chart-15","others-16","others-17","tree-1","tree-10","tree-11","tree-12","tree-2","tree-3","tree-4","tree-5","tree-6","tree-7","tree-8","tree-9"],"relation":null,"id":"group-0"},{"vislist":["table-14"],"relation":null,"id":"group-1"}],"relation":"nested","id":"relation-0"}]},"2255_0":{"comp":[["chord_diagram","sector_chart",["nested"]],["others","map",["coordinated"]],["comb","comb",["large_view"]]],"visType":["chord_diagram","sector_chart","others","map","comb"],"compType":["nested","coordinated","large_view"],"compressed_tree":[{"composite_pattern":"large_view","visualization_type":[[{"composite_pattern":"nested","visualization_type":[["chord_diagram"],["sector_chart"]]}],[{"composite_pattern":"coordinated","visualization_type":[["others"],["map"]]}]]}],"coOccurrence":[["chord_diagram","sector_chart",["coOccurrence"]],["chord_diagram","others",["coOccurrence"]],["chord_diagram","map",["coOccurrence"]],["sector_chart","others",["coOccurrence"]],["sector_chart","map",["coOccurrence"]],["others","map",["coOccurrence"]]],"year":2012,"conference":["InfoVis"],"authors":["Christian Tominski","Heidrun Schumann","Gennady L. Andrienko","Natalia V. Andrienko"],"title":"Stacking-Based Visualization of Trajectory Attribute Data","doi":"10.1109/TVCG.2012.265","abstract":"Visualizing trajectory attribute data is challenging because it involves showing the trajectories in their spatio-temporal context as well as the attribute values associated with the individual points of trajectories. Previous work on trajectory visualization addresses selected aspects of this problem, but not all of them. We present a novel approach to visualizing trajectory attribute data. Our solution covers space, time, and attribute values. Based on an analysis of relevant visualization tasks, we designed the visualization solution around the principle of stacking trajectory bands. The core of our approach is a hybrid 2D/3D display. A 2D map serves as a reference for the spatial context, and the trajectories are visualized as stacked 3D trajectory bands along which attribute values are encoded by color. Time is integrated through appropriate ordering of bands and through a dynamic query mechanism that feeds temporally aggregated information to a circular time display. An additional 2D time graph shows temporal information in full detail by stacking 2D trajectory bands. Our solution is equipped with analytical and interactive mechanisms for selecting and ordering of trajectories, and adjusting the color mapping, as well as coordinated highlighting and dedicated 3D navigation. We demonstrate the usefulness of our novel visualization by three examples related to radiation surveillance, traffic analysis, and maritime navigation. User feedback obtained in a small experiment indicates that our hybrid 2D/3D solution can be operated quite well.","keywords":"Visualization, interaction, exploratory analysis, trajectory attribute data, spatio-temporal data","caption":"Fig. 1. Visualization of radiation (CPM values) along the Tokio-Fukushima highway.","img_size":{"width":1902,"height":679},"subfigures":[{"x":2.138049060716241,"y":8.600220258085608,"width":1896.732594020226,"height":667.7469572528731,"type":"single","id":"single-0"}],"visualizations":[{"x":1509.1600489938955,"y":294.91018348169246,"width":353.32906712887245,"height":352.0341478802822,"type":"chord_diagram","id":"chord_diagram-5"},{"x":4.193639426384211,"y":4.193639426384211,"width":1893.6127211472317,"height":670.6127211472316,"type":"heatmap","id":"heatmap-3"},{"x":4.193639426384211,"y":4.193639426384211,"width":1893.6127211472317,"height":670.6127211472316,"type":"map","id":"map-2"},{"x":11.497403642424398,"y":11.336348246859991,"width":1870.6167842384557,"height":659.675768663524,"type":"others","id":"others-8"},{"x":1510.7369525788401,"y":291.4325026179355,"width":348.4975782636417,"height":352.2925792933065,"type":"sector_chart","id":"sector_chart-4"}],"relations":[{"vislist":[{"vislist":[{"vislist":[{"vislist":["chord_diagram-5"],"relation":null,"id":"group-2"},{"vislist":["sector_chart-4"],"relation":null,"id":"group-3"}],"relation":"nested","id":"relation-1"}],"relation":null,"id":"group-6"},{"vislist":[{"vislist":[{"vislist":["others-8"],"relation":null,"id":"group-4"},{"vislist":["map-2"],"relation":null,"id":"group-5"}],"relation":"coordinated","id":"relation-2"}],"relation":null,"id":"group-7"}],"relation":"large_view","id":"relation-3"}]},"2263_0":{"comp":[["unit_visualization","graph",["nested"]],["comb","map",["coordinated"]]],"visType":["unit_visualization","graph","comb","map"],"compType":["nested","coordinated"],"compressed_tree":[{"composite_pattern":"coordinated","visualization_type":[[{"composite_pattern":"nested","visualization_type":[["unit_visualization"],["graph"]]}],["map"]]}],"coOccurrence":[["unit_visualization","graph",["coOccurrence"]],["unit_visualization","map",["coOccurrence"]],["graph","map",["coOccurrence"]]],"year":2012,"conference":["InfoVis"],"authors":["Nan Cao","Yu-Ru Lin","Xiaohua Sun","David Lazer","Shixia Liu","Huamin Qu"],"title":"Whisper: Tracing the Spatiotemporal Process of Information Diffusion in Real Time","doi":"10.1109/TVCG.2012.291","abstract":"When and where is an idea dispersed? Social media, like Twitter, has been increasingly used for exchanging information, opinions and emotions about events that are happening across the world. Here we propose a novel visualization design, \u201cWhisper\u201d, for tracing the process of information diffusion in social media in real time. Our design highlights three major characteristics of diffusion processes in social media: the temporal trend, social-spatial extent, and community response of a topic of interest. Such social, spatiotemporal processes are conveyed based on a sunflower metaphor whose seeds are often dispersed far away. In Whisper, we summarize the collective responses of communities on a given topic based on how tweets were retweeted by groups of users, through representing the sentiments extracted from the tweets, and tracing the pathways of retweets on a spatial hierarchical layout. We use an efficient flux line-drawing algorithm to trace multiple pathways so the temporal and spatial patterns can be identified even for a bursty event. A focused diffusion series highlights key roles such as opinion leaders in the diffusion process. We demonstrate how our design facilitates the understanding of when and where a piece of information is dispersed and what are the social responses of the crowd, for large-scale events including political campaigns and natural disasters. Initial feedback from domain experts suggests promising use for today\'s information consumption and dispersion in the wild.","keywords":"Information visualization, Information diffusion, Contagion, Social media, Microblogging, Spatiotemporal patterns","caption":"Fig. 1. The figure shows a diffusion of information on Twitter regarding a recent 6.8 magnitude earthquake and a series of aftershocks and tsunamis that hit the northern coast of Hokkaido island (a demo on youtube: http://www.youtube.com/watch?v=aHYU66Z-4FM). The event caught global attention because the location was one of the areas in northeast Japan devastated by last year\u2019s disaster. Other countries, including Australia, were initially concerned about the Pacific-wide tsunami threat triggered by the earthquake. Our visualization \u201cWhisper\u201d traced this event in real time. In this figure, original tweets are placed at the center of a circle and pathways are created to connect to geo-groups once the tweets got re-broadcasted (retweeted) by the groups. The retweeting activity is shown as a sequence of color-coded retweet glyphs moving along pathways indicating the timing and sentiments of the retweets. The numbering annotations from 0 to 8 correspond to major design components and functionality which will be described in detail in the paper.","img_size":{"width":1377,"height":957},"subfigures":[{"x":53.267142271938894,"y":48.86874341602283,"width":1276.5741821256959,"height":864.3549634879827,"type":"interface","id":"interface-0"}],"visualizations":[{"x":168.3913043478261,"y":837.8478260869564,"width":593.8695652173915,"height":35.93478260869563,"type":"area_chart","id":"area_chart-0"},{"x":68.15217391304351,"y":754.6304347826085,"width":938.086956521739,"height":88.89130434782612,"type":"graph","id":"graph-2"},{"x":62.47826086956526,"y":56.739130434782595,"width":945.6521739130435,"height":696,"type":"graph","id":"graph-3"},{"x":62.47826086956526,"y":54.84782608695652,"width":947.5434782608695,"height":697.8913043478261,"type":"map","id":"map-1"},{"x":235.046241301673,"y":181.46984669568508,"width":643.1997208498381,"height":558.0313570406115,"type":"unit_visualization","id":"unit_visualization-4"}],"relations":[{"vislist":[{"vislist":[{"vislist":[{"vislist":["unit_visualization-4"],"relation":null,"id":"group-2"},{"vislist":["graph-3"],"relation":null,"id":"group-3"}],"relation":"nested","id":"relation-1"}],"relation":null,"id":"group-4"},{"vislist":["map-1"],"relation":null,"id":"group-5"}],"relation":"coordinated","id":"relation-2"}]},"2310_9":{"comp":[["bar_chart","donut_chart",["nested"]]],"visType":["bar_chart","donut_chart"],"compType":["nested"],"compressed_tree":[{"composite_pattern":"nested","visualization_type":[["bar_chart"],["donut_chart"]]}],"coOccurrence":[["bar_chart","donut_chart",["coOccurrence"]]],"year":2012,"conference":["VAST"],"authors":["Bilal Alsallakh","Wolfgang Aigner","Silvia Miksch","M. Eduard Gr\xf6ller"],"title":"Reinventing the Contingency Wheel: Scalable Visual Analytics of Large Categorical Data","doi":"10.1109/TVCG.2012.254","abstract":"Contingency tables summarize the relations between categorical variables and arise in both scientific and business domains. Asymmetrically large two-way contingency tables pose a problem for common visualization methods. The Contingency Wheel has been recently proposed as an interactive visual method to explore and analyze such tables. However, the scalability and readability of this method are limited when dealing with large and dense tables. In this paper we present Contingency Wheel++, new visual analytics methods that overcome these major shortcomings: (1) regarding automated methods, a measure of association based on Pearson\'s residuals alleviates the bias of the raw residuals originally used, (2) regarding visualization methods, a frequency-based abstraction of the visual elements eliminates overlapping and makes analyzing both positive and negative associations possible, and (3) regarding the interactive exploration environment, a multi-level overview+detail interface enables exploring individual data items that are aggregated in the visualization or in the table using coordinated views. We illustrate the applicability of these new methods with a use case and show how they enable discovering and analyzing nontrivial patterns and associations in large categorical data.","keywords":"Large categorical data, contingency table analysis, information interfaces and representation, visual analytics","caption":"Fig. 10. Visual exploration of the Godfather trilogy: (a) search box, (b) search result, (c, d) star plot of associations of selected item to user occupations, (e) row of selected movie in contingency table, (f) raw data of user ratings, (g-i) rating histograms for the three movies of the trilogy.","img_size":{"width":1728,"height":900},"subfigures":[{"x":9.029064438590755,"y":7.032477612750236,"width":1708.983945655011,"height":886.8928724208994,"type":"interface","id":"interface-0"}],"visualizations":[{"x":20.00292825768662,"y":89.60468521229866,"width":210.83455344070276,"height":276.72035139092236,"type":"bar_chart","id":"bar_chart-0"},{"x":197.89458272327957,"y":554.758418740849,"width":121.22986822840411,"height":85.65153733528551,"type":"bar_chart","id":"bar_chart-1"},{"x":378.4216691068814,"y":741.8740849194728,"width":118.59443631039528,"height":96.19326500732063,"type":"bar_chart","id":"bar_chart-2"},{"x":694.6734992679354,"y":715.5197657393849,"width":114.64128843338209,"height":92.24011713030745,"type":"bar_chart","id":"bar_chart-3"},{"x":250.60322108345528,"y":80.38067349926793,"width":760.3221083455344,"height":589.0190336749633,"type":"bar_chart","id":"bar_chart-4"},{"x":253.546244674087,"y":81.74702838069169,"width":754.5014146051203,"height":585.7685677745676,"type":"donut_chart","id":"donut_chart-8"},{"x":18.685212298682217,"y":707.6134699853586,"width":220.05856515373353,"height":175.2562225475842,"type":"table","id":"table-5"},{"x":1017.5139092240115,"y":208.19912152269399,"width":673.3528550512447,"height":660.1756954612005,"type":"table","id":"table-6"},{"x":1022.7847730600294,"y":55.344070278184475,"width":686.5300146412883,"height":72.47437774524158,"type":"table","id":"table-7"}],"relations":[{"vislist":[{"vislist":["bar_chart-4"],"relation":null,"id":"group-0"},{"vislist":["donut_chart-8"],"relation":null,"id":"group-1"}],"relation":"nested","id":"relation-0"}]},"2317_0":{"comp":[["area_chart","area_chart",["nested"]]],"visType":["area_chart"],"compType":["nested"],"compressed_tree":[{"composite_pattern":"nested","visualization_type":[["area_chart"],["area_chart"]]}],"coOccurrence":[["area_chart","area_chart",["coOccurrence"]]],"year":2012,"conference":["VAST"],"authors":["Wenwen Dou","Xiaoyu Wang","Drew Skau","William Ribarsky","Michelle X. Zhou"],"title":"LeadLine: Interactive visual analysis of text data through event identification and exploration","doi":"10.1109/VAST.2012.6400485","abstract":"Text data such as online news and microblogs bear valuable insights regarding important events and responses to such events. Events are inherently temporal, evolving over time. Existing visual text analysis systems have provided temporal views of changes based on topical themes extracted from text data. But few have associated topical themes with events that cause the changes. In this paper, we propose an interactive visual analytics system, LeadLine, to automatically identify meaningful events in news and social media data and support exploration of the events. To characterize events, LeadLine integrates topic modeling, event detection, and named entity recognition techniques to automatically extract information regarding the investigative 4 Ws: who, what, when, and where for each event. To further support analysis of the text corpora through events, LeadLine allows users to interactively examine meaningful events using the 4 Ws to develop an understanding of how and why. Through representing large-scale text corpora in the form of meaningful events, LeadLine provides a concise summary of the corpora. LeadLine also supports the construction of simple narratives through the exploration of events. To demonstrate the efficacy of LeadLine in identifying events and supporting exploration, two case studies were conducted using news and social media data.","keywords":"","caption":"Figure 1:  Overview of Leadline.  Top right:  people and entities related to President Obama (selected) are shown in the graph.  Bottom right: locations mentioned in news articles related to the president. Left view: highlighted bursts indicate events that are related to President Obama.","img_size":{"width":2131,"height":952},"subfigures":[{"x":3.468965260826198,"y":14.065807380931108,"width":2109.623477680467,"height":911.6551782700026,"type":"interface","id":"interface-0"}],"visualizations":[{"x":4.698551849434675,"y":6.969253294289897,"width":1318.483894582723,"height":929.6983894582722,"type":"area_chart","id":"area_chart-0"},{"x":1315.696193265007,"y":379.12737920937036,"width":770.7994143484625,"height":497.6046852122986,"type":"area_chart","id":"area_chart-1"},{"x":4.698551849434675,"y":5.575402635431917,"width":1315.696193265007,"height":929.6983894582722,"type":"heatmap","id":"heatmap-2"},{"x":1314.3023426061493,"y":377.7335285505124,"width":773.5871156661783,"height":503.18008784773036,"type":"map","id":"map-3"}],"relations":[{"vislist":[{"vislist":["area_chart-0"],"relation":null,"id":"group-0"},{"vislist":["area_chart-1"],"relation":null,"id":"group-1"}],"relation":"nested","id":"relation-0"}]},"2355_7":{"comp":[["chord_diagram","flow_diagram",["nested"]],["chord_diagram","donut_chart",["nested"]],["bar_chart","flow_diagram",["nested"]]],"visType":["chord_diagram","flow_diagram","donut_chart","bar_chart"],"compType":["nested"],"compressed_tree":[{"composite_pattern":"nested","visualization_type":[["chord_diagram","bar_chart"],["flow_diagram"]]},{"composite_pattern":"nested","visualization_type":[["chord_diagram"],["donut_chart"]]}],"coOccurrence":[["chord_diagram","bar_chart",["coOccurrence"]],["chord_diagram","flow_diagram",["coOccurrence"]],["chord_diagram","donut_chart",["coOccurrence"]],["bar_chart","flow_diagram",["coOccurrence"]],["bar_chart","donut_chart",["coOccurrence"]],["flow_diagram","donut_chart",["coOccurrence"]]],"year":2012,"conference":["VAST"],"authors":["Liang Gou","Xiaolong Zhan","Airong Luo","Patricia F. Anderson"],"title":"SocialNetSense: Supporting sensemaking of social and structural features in networks with interactive visualization","doi":"10.1109/VAST.2012.6400558","abstract":"Increasingly, social network datasets contain social attribute information about actors and their relationship. Analyzing such network with social attributes requires making sense of not only its structural features, but also the relationship between social features in attributes and network structures. Existing social network analysis tools are usually weak in supporting complex analytical tasks involving both structural and social features, and often overlook users\' needs for sensemaking tools that help to gather, synthesize, and organize information of these features. To address these challenges, we propose a sensemaking framework of social-network visual analytics in this paper. This framework considers both bottom-up processes, which are about constructing new understandings based on collected information, and top-down processes, which concern using prior knowledge to guide information collection, in analyzing social networks from both social and structural perspectives. The framework also emphasizes the externalization of sensemaking processes through interactive visualization. Guided by the framework, we develop a system, SocialNetSense, to support the sensemaking in visual analytics of social networks with social attributes. The example of using our system to analyze a scholar collaboration network shows that our approach can help users gain insight into social networks both structurally and socially, and enhance their process awareness in visual analytics.","keywords":"Social network, visualization, sensemaking, visual analytics, SocialNetSense","caption":"Figure 7:  Representation  Building  Space  (RBS):  Panel  1  is  the  main  working  space; Panel 2 is the process view; Panel 3 lists the elements in the working space; and Toolbar  and  Popup  menu  provide  tools  of  representation  building,  such  as  add note, group/ungroup elements and link element. ","img_size":{"width":1332,"height":1035},"subfigures":[{"x":0.7933660307964319,"y":4.813159647458068,"width":1322.7011978267885,"height":1026.4751824984453,"type":"interface","id":"interface-0"}],"visualizations":[{"x":855.1083150984686,"y":237.800875273523,"width":269.5076586433262,"height":190.24070021881843,"type":"bar_chart","id":"bar_chart-0"},{"x":958.9316517062249,"y":898.0013362223415,"width":69.0664985433882,"height":39.23870356044676,"type":"bar_chart","id":"bar_chart-7"},{"x":834.7253829321666,"y":466.5426695842452,"width":264.97811816192564,"height":258.183807439825,"type":"chord_diagram","id":"chord_diagram-1"},{"x":501.80175795486485,"y":869.5334436774131,"width":51.33524918813243,"height":45.50169814402648,"type":"chord_diagram","id":"chord_diagram-2"},{"x":659.3076361457258,"y":863.6998926333072,"width":58.33551044105957,"height":64.16906148516557,"type":"chord_diagram","id":"chord_diagram-3"},{"x":836.9778972713967,"y":464.3533401617169,"width":268.7327783362078,"height":267.4564045978599,"type":"donut_chart","id":"donut_chart-11"},{"x":293.44529540481403,"y":774.5514223194749,"width":937.6148796498909,"height":208.3588621444202,"type":"flow_diagram","id":"flow_diagram-5"},{"x":313.83219285584704,"y":56.735705944139795,"width":508.2110003805057,"height":350.3660984597922,"type":"graph","id":"graph-4"},{"x":436.10685766388997,"y":440.32084449183463,"width":283.0824152049171,"height":278.7649028853983,"type":"graph","id":"graph-9"},{"x":14.878555798687103,"y":97.38512035010943,"width":246.85995623632394,"height":405.39387308533924,"type":"tree","id":"tree-8"}],"relations":[{"vislist":[{"vislist":["chord_diagram-3","chord_diagram-2","bar_chart-7"],"relation":null,"id":"group-0"},{"vislist":["flow_diagram-5"],"relation":null,"id":"group-1"}],"relation":"nested","id":"relation-0"},{"vislist":[{"vislist":["chord_diagram-1"],"relation":null,"id":"group-2"},{"vislist":["donut_chart-11"],"relation":null,"id":"group-3"}],"relation":"nested","id":"relation-1"}]},"2355_4":{"comp":[["chord_diagram","donut_chart",["nested"]]],"visType":["chord_diagram","donut_chart"],"compType":["nested"],"compressed_tree":[{"composite_pattern":"nested","visualization_type":[["chord_diagram"],["donut_chart"]]}],"coOccurrence":[["chord_diagram","donut_chart",["coOccurrence"]]],"year":2012,"conference":["VAST"],"authors":["Liang Gou","Xiaolong Zhan","Airong Luo","Patricia F. Anderson"],"title":"SocialNetSense: Supporting sensemaking of social and structural features in networks with interactive visualization","doi":"10.1109/VAST.2012.6400558","abstract":"Increasingly, social network datasets contain social attribute information about actors and their relationship. Analyzing such network with social attributes requires making sense of not only its structural features, but also the relationship between social features in attributes and network structures. Existing social network analysis tools are usually weak in supporting complex analytical tasks involving both structural and social features, and often overlook users\' needs for sensemaking tools that help to gather, synthesize, and organize information of these features. To address these challenges, we propose a sensemaking framework of social-network visual analytics in this paper. This framework considers both bottom-up processes, which are about constructing new understandings based on collected information, and top-down processes, which concern using prior knowledge to guide information collection, in analyzing social networks from both social and structural perspectives. The framework also emphasizes the externalization of sensemaking processes through interactive visualization. Guided by the framework, we develop a system, SocialNetSense, to support the sensemaking in visual analytics of social networks with social attributes. The example of using our system to analyze a scholar collaboration network shows that our approach can help users gain insight into social networks both structurally and socially, and enhance their process awareness in visual analytics.","keywords":"Social network, visualization, sensemaking, visual analytics, SocialNetSense","caption":"Figure 4:  Network Exploring Space (NES) in SocialNetSense: (a) Coordinated node-link views, including a network visualization (Panel 1-1), a tree  visualization  (Panel  1-2)  to  show  the  social  hierarchy  of  actors,  a  network  overview  panel  (Panel  1-3)  to  support  quick  navigation, and a control panel (Panel 2) with a set of analytical tools of different aggregation metrics, analytic plots and so on; (b) A TreeNetViz viewto reveal hybrid features of network patterns over a social hierarchy.","img_size":{"width":2109,"height":969},"subfigures":[{"x":2.0865048529168027,"y":1.7350434636279133,"width":1215.578497629164,"height":912.7505952895625,"type":"interface","id":"interface-0"},{"x":1211.1491043786323,"y":2.823537380265902,"width":893.6175451935039,"height":910.5736074562855,"type":"interface","id":"interface-1"}],"visualizations":[{"x":900.2243631887654,"y":689.1659551195072,"width":292.7221736427974,"height":173.14612231812524,"type":"bar_chart","id":"bar_chart-0"},{"x":1244.2713347921228,"y":103.89715536105032,"width":826.9365426695841,"height":723.0393873085341,"type":"chord_diagram","id":"chord_diagram-1"},{"x":1253.0230258458214,"y":107.06966003294812,"width":813.9887447071294,"height":721.3776769937413,"type":"donut_chart","id":"donut_chart-6"},{"x":18.708971553610482,"y":258.6827133479212,"width":843.8993435448577,"height":595.8183807439825,"type":"graph","id":"graph-2"},{"x":728.1509707455489,"y":94.86717863660478,"width":118.96256207947408,"height":122.31362016621983,"type":"graph","id":"graph-3"},{"x":893.5203991696975,"y":202.09751197463288,"width":287.68833674712255,"height":428.68410574694997,"type":"table","id":"table-4"},{"x":277.3916849015317,"y":91.17505470459518,"width":163.26695842450772,"height":133.582056892779,"type":"tree","id":"tree-5"}],"relations":[{"vislist":[{"vislist":["chord_diagram-1"],"relation":null,"id":"group-1"},{"vislist":["donut_chart-6"],"relation":null,"id":"group-2"}],"relation":"nested","id":"relation-0"}]},"1799_8":{"comp":[["scatterplot","others",["nested"]]],"visType":["scatterplot","others"],"compType":["nested"],"compressed_tree":[{"composite_pattern":"nested","visualization_type":[["scatterplot"],["others"]]}],"coOccurrence":[["scatterplot","others",["coOccurrence"]]],"year":2009,"conference":["InfoVis"],"authors":["Christopher Collins","Gerald Penn","Sheelagh Carpendale"],"title":"Bubble Sets: Revealing Set Relations with Isocontours over Existing Visualizations","doi":"10.1109/TVCG.2009.122","abstract":"While many data sets contain multiple relationships, depicting more than one data relationship within a single visualization is challenging. We introduce Bubble Sets as a visualization technique for data that has both a primary data relation with a semantically significant spatial organization and a significant set membership relation in which members of the same set are not necessarily adjacent in the primary layout. In order to maintain the spatial rights of the primary data relation, we avoid layout adjustment techniques that improve set cluster continuity and density. Instead, we use a continuous, possibly concave, isocontour to delineate set membership, without disrupting the primary layout. Optimizations minimize cluster overlap and provide for calculation of the isocontours at interactive speeds. Case studies show how this technique can be used to indicate multiple sets on a variety of common visualizations.","keywords":"clustering, spatial layout, graph visualization, tree visualization","caption":"Fig. 10: A scatterplot of fertility rate by life expectancy by country. Hovering on a set member causes all non-members and other sets to be made transparent, clarifying set membership. Here, enclosure eases discovery of the outliers in the upper left, as well as giving a general impression about the spatial distribution of the set.","img_size":{"width":1098,"height":1271},"subfigures":[{"x":52.87108020838646,"y":11.942983256260383,"width":1036.6625625463946,"height":1255.0546872058817,"type":"single","id":"single-0"}],"visualizations":[{"x":64.87031504981861,"y":38.14559500552111,"width":989.3710678545748,"height":1222.8560808113468,"type":"others","id":"others-1"},{"x":60.809386973180274,"y":26.78352490421456,"width":995.8601532567048,"height":1234.4770114942528,"type":"scatterplot","id":"scatterplot-0"}],"relations":[{"vislist":[{"vislist":["scatterplot-0"],"relation":null,"id":"group-0"},{"vislist":["others-1"],"relation":null,"id":"group-1"}],"relation":"nested","id":"relation-0"}]},"1803_10":{"comp":[["scatterplot","matrix",["nested"]]],"visType":["scatterplot","matrix"],"compType":["nested"],"compressed_tree":[{"composite_pattern":"nested","visualization_type":[["scatterplot"],["matrix"]]}],"coOccurrence":[["scatterplot","matrix",["coOccurrence"]]],"year":2009,"conference":["InfoVis"],"authors":["Chris Weaver"],"title":"Conjunctive Visual Forms","doi":"10.1109/TVCG.2009.129","abstract":"Visual exploration of multidimensional data is a process of isolating and extracting relationships within and between dimensions. Coordinated multiple view approaches are particularly effective for visual exploration because they support precise expression of heterogeneous multidimensional queries using simple interactions. Recent visual analytics research has made significant progress in identifying and understanding patterns of composed views and coordinations that support fast, flexible, and open-ended data exploration. What is missing is formalization of the space of expressible queries in terms of visual representation and interaction. This paper introduces the conjunctive visual form model in which visual exploration consists of interactively-driven sequences of transitions between visual states that correspond to conjunctive normal forms in boolean logic. The model predicts several new and useful ways to extend the space of rapidly expressible queries through addition of simple interactive capabilities to existing compositional patterns. Two recent related visual tools offer a subset of these capabilities, providing a basis for conjecturing about such extensions.","keywords":"Boolean query, brushing, conjunctive normal form, exploratory visualization, multiple views, visual abstraction","caption":"Fig. 12. Cross-\ufb01ltering seven dimensions of census data using toggled range selections in a parallel coordinate plot and a scatter plot matrix.","img_size":{"width":1059,"height":491},"subfigures":[{"x":4.95135363403202,"y":-0.9310039624637171,"width":1049.0972927319356,"height":486.4907662183425,"type":"interface","id":"interface-0"}],"visualizations":[{"x":663.3395638629286,"y":260.0311526479751,"width":385.4579439252336,"height":224.85046728971957,"type":"matrix","id":"matrix-0"},{"x":5.546192329942196,"y":252.9911983786112,"width":643.4529898814659,"height":234.9391059433885,"type":"matrix","id":"matrix-8"},{"x":40.79439252336459,"y":4.588785046728972,"width":133.0747663551402,"height":226.38006230529595,"type":"parallel_coordinate","id":"parallel_coordinate-1"},{"x":210.57943925233653,"y":3.059190031152647,"width":131.5451713395639,"height":229.43925233644862,"type":"parallel_coordinate","id":"parallel_coordinate-2"},{"x":377.305295950156,"y":1.6748484886825155,"width":136.13395638629274,"height":230.96884735202494,"type":"parallel_coordinate","id":"parallel_coordinate-3"},{"x":544.0311526479752,"y":3.059190031152647,"width":136.13395638629285,"height":226.38006230529595,"type":"parallel_coordinate","id":"parallel_coordinate-4"},{"x":713.8161993769472,"y":1.6748484886825155,"width":134.60436137071656,"height":232.4984423676012,"type":"parallel_coordinate","id":"parallel_coordinate-5"},{"x":883.6012461059192,"y":1.6748484886825155,"width":134.60436137071656,"height":229.43925233644862,"type":"parallel_coordinate","id":"parallel_coordinate-6"},{"x":42.32398753894091,"y":287.56386292834884,"width":605.7196261682243,"height":198.84735202492215,"type":"scatterplot","id":"scatterplot-7"}],"relations":[{"vislist":[{"vislist":["scatterplot-7"],"relation":null,"id":"group-3"},{"vislist":["matrix-8"],"relation":null,"id":"group-2"}],"relation":"nested","id":"relation-1"}]},"1812_11":{"comp":[["scatterplot","matrix",["nested"]],["parallel_coordinate","comb",["stacked"]],["comb","parallel_coordinate",["stacked"]]],"visType":["scatterplot","matrix","parallel_coordinate","comb"],"compType":["nested","stacked"],"compressed_tree":[{"composite_pattern":"stacked","visualization_type":[["parallel_coordinate",{"composite_pattern":"nested","visualization_type":[["scatterplot"],["matrix"]]}]]}],"coOccurrence":[["scatterplot","matrix",["coOccurrence"]],["scatterplot","parallel_coordinate",["coOccurrence"]],["matrix","parallel_coordinate",["coOccurrence"]]],"year":2009,"conference":["InfoVis"],"authors":["Sara Johansson","Jimmy Johansson"],"title":"Interactive Dimensionality Reduction Through User-defined Combinations of Quality Metrics","doi":"10.1109/TVCG.2009.153","abstract":"Multivariate data sets including hundreds of variables are increasingly common in many application areas. Most multivariate visualization techniques are unable to display such data effectively, and a common approach is to employ dimensionality reduction prior to visualization. Most existing dimensionality reduction systems focus on preserving one or a few significant structures in data. For many analysis tasks, however, several types of structures can be of high significance and the importance of a certain structure compared to the importance of another is often task-dependent. This paper introduces a system for dimensionality reduction by combining user-defined quality metrics using weight functions to preserve as many important structures as possible. The system aims at effective visualization and exploration of structures within large multivariate data sets and provides enhancement of diverse structures by supplying a range of automatic variable orderings. Furthermore it enables a quality-guided reduction of variables through an interactive display facilitating investigation of trade-offs between loss of structure and the number of variables to keep. The generality and interactivity of the system is demonstrated through a case scenario.","keywords":"dimensionality reduction, interactivity, quality metrics, variable ordering","caption":"Fig. 8. The data set reduced to 15 variables, displayed using a scatterplot matrix and parallel coordinates. In the scatter plot matrix the corre-lation of variable pairs is displayed using text information and colour.","img_size":{"width":1036,"height":950},"subfigures":[{"x":5.766128918330048,"y":3.354529812648289,"width":1029.7100422245596,"height":939.1013057682388,"type":"interface","id":"interface-0"}],"visualizations":[{"x":2.5270796535506794,"y":434.9616858237547,"width":1030.9458406928986,"height":507.7586206896551,"type":"parallel_coordinate","id":"parallel_coordinate-0"},{"x":3.871647509578566,"y":7.279693486590006,"width":1010.0574712643675,"height":396.743295019157,"type":"scatterplot","id":"scatterplot-1"},{"x":5.691570881226084,"y":5.459770114942528,"width":1008.2375478927203,"height":398.5632183908046,"type":"matrix","id":"matrix-2"}],"relations":[{"vislist":[{"vislist":["parallel_coordinate-0",{"vislist":[{"vislist":["scatterplot-1"],"relation":null,"id":"group-4"},{"vislist":["matrix-2"],"relation":null,"id":"group-5"}],"relation":"nested","id":"relation-2"}],"relation":null,"id":"group-6"}],"relation":"stacked","id":"relation-3"}]},"1815_0":{"comp":[["donut_chart","chord_diagram",["nested"]]],"visType":["donut_chart","chord_diagram"],"compType":["nested"],"compressed_tree":[{"composite_pattern":"nested","visualization_type":[["donut_chart"],["chord_diagram"]]}],"coOccurrence":[["donut_chart","chord_diagram",["coOccurrence"]]],"year":2009,"conference":["InfoVis"],"authors":["Miriah D. Meyer","Tamara Munzner","Hanspeter Pfister"],"title":"MizBee: A Multiscale Synteny Browser","doi":"10.1109/TVCG.2009.167","abstract":"In the field of comparative genomics, scientists seek to answer questions about evolution and genomic function by comparing the genomes of species to find regions of shared sequences. Conserve dsyntenic blocks are an important biological data abstraction for indicating regions of shared sequences. The goal of this work is to show multiple types of relationships at multiple scales in a way that is visually comprehensible in accordance with known perceptual principles. We present a task analysis for this domain where the fundamental questions asked by biologists can be understood by a characterization of relationships into the four types of proximity/location, size, orientation, and similarity/strength, and the four scales of genome, chromosome, block, and genomic feature. We also propose a new taxonomy of the design space for visually encoding conservation data. We present MizBee, a multiscale synteny browser with the unique property of providing interactive side-by-side views of the data across the range of scales supporting exploration of all of these relationship types. We conclude with case studies from two biologists who used MizBee to augment their previous automatic analysis work flow, providing anecdotal evidence about the efficacy of the system for the visualization of syntenic data, the analysis of conservation relationships, and the communication of scientific insights.","keywords":"Information visualization, design study, bioinformatics, synteny","caption":"Fig. 1. The multiscale MizBee browser allows biologists to explore many kinds of conserved synteny relationships with linked views at the genome, chromosome, and block levels. Here we compare the genomes of two \ufb01sh, the stickleback and the puffer\ufb01sh.","img_size":{"width":1530,"height":979},"subfigures":[{"x":10.298479801665291,"y":8.80235469369581,"width":1508.3228243257024,"height":957.0777618971039,"type":"single","id":"single-0"}],"visualizations":[{"x":21.37260536398469,"y":20.63026819923371,"width":937.7394636015325,"height":915.2337164750958,"type":"chord_diagram","id":"chord_diagram-0"},{"x":19.497126436781624,"y":18.75478927203065,"width":941.4904214559385,"height":917.1091954022988,"type":"donut_chart","id":"donut_chart-1"},{"x":1281.6944444444443,"y":103.15134099616857,"width":181.9214559386971,"height":515.7567049808429,"type":"parallel_coordinate","id":"parallel_coordinate-2"},{"x":1026.6293103448274,"y":71.26819923371647,"width":195.04980842911866,"height":813.9578544061301,"type":"stripe_graph","id":"stripe_graph-3"}],"relations":[{"vislist":[{"vislist":["donut_chart-1"],"relation":null,"id":"group-1"},{"vislist":["chord_diagram-0"],"relation":null,"id":"group-0"}],"relation":"nested","id":"relation-0"}]},"1826_12":{"comp":[["glyph_based","graph",["nested"]]],"visType":["glyph_based","graph"],"compType":["nested"],"compressed_tree":[{"composite_pattern":"nested","visualization_type":[["glyph_based"],["graph"]]}],"coOccurrence":[["glyph_based","graph",["coOccurrence"]]],"year":2009,"conference":["InfoVis"],"authors":["Bryan McDonnel","Niklas Elmqvist"],"title":"Towards Utilizing GPUs in Information Visualization: A Model and Implementation of Image-Space Operations","doi":"10.1109/TVCG.2009.191","abstract":"Modern programmable GPUs represent a vast potential in terms of performance and visual flexibility for information visualization research, but surprisingly few applications even begin to utilize this potential. In this paper, we conjecture that this may be due to the mismatch between the high-level abstract data types commonly visualized in our field, and the low-level floating-point model supported by current GPU shader languages. To help remedy this situation, we present a refinement of the traditional information visualization pipeline that is amenable to implementation using GPU shaders. The refinement consists of a final image-space step in the pipeline where the multivariate data of the visualization is sampled in the resolution of the current view. To concretize the theoretical aspects of this work, we also present a visual programming environment for constructing visualization shaders using a simple drag-and-drop interface. Finally, we give some examples of the use of shaders for well-known visualization techniques.","keywords":"GPU-acceleration, shader programming, interaction, high-performance visualization","caption":"Fig. 11. Node-link visualization with a polar barchart glyph IVO.","img_size":{"width":1065,"height":644},"subfigures":[{"x":9.399497114339619,"y":6.534501209852919,"width":1048.3321401965657,"height":637.3212928905754,"type":"single","id":"single-0"}],"visualizations":[{"x":12.220101781170515,"y":16.38676844783715,"width":927.4910941475825,"height":624.3358778625952,"type":"glyph_based","id":"glyph_based-0"},{"x":13.858778625954185,"y":14.748091603053433,"width":922.5750636132314,"height":625.974554707379,"type":"graph","id":"graph-1"}],"relations":[{"vislist":[{"vislist":["glyph_based-0"],"relation":null,"id":"group-2"},{"vislist":["graph-1"],"relation":null,"id":"group-1"}],"relation":"nested","id":"relation-0"}]},"1826_5":{"comp":[["bar_chart","scatterplot",["nested"]]],"visType":["bar_chart","scatterplot"],"compType":["nested"],"compressed_tree":[{"composite_pattern":"nested","visualization_type":[["bar_chart"],["scatterplot"]]}],"coOccurrence":[["bar_chart","scatterplot",["coOccurrence"]]],"year":2009,"conference":["InfoVis"],"authors":["Bryan McDonnel","Niklas Elmqvist"],"title":"Towards Utilizing GPUs in Information Visualization: A Model and Implementation of Image-Space Operations","doi":"10.1109/TVCG.2009.191","abstract":"Modern programmable GPUs represent a vast potential in terms of performance and visual flexibility for information visualization research, but surprisingly few applications even begin to utilize this potential. In this paper, we conjecture that this may be due to the mismatch between the high-level abstract data types commonly visualized in our field, and the low-level floating-point model supported by current GPU shader languages. To help remedy this situation, we present a refinement of the traditional information visualization pipeline that is amenable to implementation using GPU shaders. The refinement consists of a final image-space step in the pipeline where the multivariate data of the visualization is sampled in the resolution of the current view. To concretize the theoretical aspects of this work, we also present a visual programming environment for constructing visualization shaders using a simple drag-and-drop interface. Finally, we give some examples of the use of shaders for well-known visualization techniques.","keywords":"GPU-acceleration, shader programming, interaction, high-performance visualization","caption":"Fig. 6. Scatterplot visualization for a car dataset (9 dimensions, 406 cases) with a barchart glyph IVO.","img_size":{"width":1056,"height":636},"subfigures":[{"x":4.754961179156774,"y":2.949569059857358,"width":1047.1916188759824,"height":629.3996493514128,"type":"single","id":"single-0"}],"visualizations":[{"x":7.709923664122215,"y":4.854961832061068,"width":928.9160305343511,"height":623.0534351145038,"type":"bar_chart","id":"bar_chart-0"},{"x":6.091603053435193,"y":4.854961832061068,"width":930.5343511450383,"height":619.8167938931298,"type":"glyph_based","id":"glyph_based-1"},{"x":4.473282442748144,"y":8.091603053435115,"width":932.1526717557254,"height":619.8167938931298,"type":"scatterplot","id":"scatterplot-2"}],"relations":[{"vislist":[{"vislist":["bar_chart-0"],"relation":null,"id":"group-1"},{"vislist":["scatterplot-2"],"relation":null,"id":"group-0"}],"relation":"nested","id":"relation-0"}]},"1828_3":{"comp":[["others","graph",["nested"]]],"visType":["others","graph"],"compType":["nested"],"compressed_tree":[{"composite_pattern":"nested","visualization_type":[["others"],["graph"]]}],"coOccurrence":[["others","graph",["coOccurrence"]]],"year":2009,"conference":["InfoVis"],"authors":["Michel Crampes","Jeremy de Oliveira-Kumar","Sylvie Ranwez","Jean Villerd"],"title":"Visualizing Social Photos on a Hasse Diagram for Eliciting Relations and Indexing New Photos","doi":"10.1109/TVCG.2009.201","abstract":"Social photos, which are taken during family events or parties, represent individuals or groups of people. We show in this paper how a Hasse diagram is an efficient visualization strategy for eliciting different groups and navigating through them. However, we do not limit this strategy to these traditional uses. Instead we show how it can also be used for assisting in indexing new photos. Indexing consists of identifying the event and people in photos. It is an integral phase that takes place before searching and sharing. In our method we use existing indexed photos to index new photos. This is performed through a manual drag and drop procedure followed by a content fusion process that we call \'propagation\'. At the core of this process is the necessity to organize and visualize the photos that will be used for indexing in a manner that is easily recognizable and accessible by the user. In this respect we make use of an object Galois sub-hierarchy and display it using a Hasse diagram. The need for an incremental display that maintains the user\'s mental map also leads us to propose a novel way of building the Hasse diagram. To validate the approach, we present some tests conducted with a sample of users that confirm the interest of this organization, visualization and indexation approach. Finally, we conclude by considering scalability, the possibility to extract social networks and automatically create personalised albums.","keywords":"Information visualization, Hasse Diagram, indexation, social photos, formal concept analysis, Galois sub-hierarchy","caption":"Fig. 4. Self organizing photo Hasse Diagram; for practical reasons, the Hasse Diagram is organized from left to right.","img_size":{"width":1014,"height":829},"subfigures":[{"x":6.884165547675049,"y":3.8157595547360406,"width":1002.9756959680171,"height":824.1104864869164,"type":"single","id":"single-0"}],"visualizations":[{"x":94.60941475826974,"y":37.969465648854964,"width":869.0788804071248,"height":778.3740458015268,"type":"graph","id":"graph-0"},{"x":92.75633382613411,"y":38.04571024673895,"width":862.9022558837787,"height":776.729753072501,"type":"others","id":"others-1"}],"relations":[{"vislist":[{"vislist":["others-1"],"relation":null,"id":"group-1"},{"vislist":["graph-0"],"relation":null,"id":"group-0"}],"relation":"nested","id":"relation-0"}]},"1838_6":{"comp":[["bar_chart","scatterplot",["nested"]],["bar_chart","bar_chart",["mirrored"]]],"visType":["bar_chart","scatterplot"],"compType":["nested","mirrored"],"compressed_tree":[{"composite_pattern":"mirrored","visualization_type":[["bar_chart"]]},{"composite_pattern":"nested","visualization_type":[["bar_chart"],["scatterplot"]]}],"coOccurrence":[["bar_chart","scatterplot",["coOccurrence"]]],"year":2009,"conference":["VAST"],"authors":["Carlos D. Correa","Yu-Hsuan Chan","Kwan-Liu Ma"],"title":"A framework for uncertainty-aware visual analytics","doi":"10.1109/VAST.2009.5332611","abstract":"Visual analytics has become an important tool for gaining insight on large and complex collections of data. Numerous statistical tools and data transformations, such as projections, binning and clustering, have been coupled with visualization to help analysts understand data better and faster. However, data is inherently uncertain, due to error, noise or unreliable sources. When making decisions based on uncertain data, it is important to quantify and present to the analyst both the aggregated uncertainty of the results and the impact of the sources of that uncertainty. In this paper, we present a new framework to support uncertainty in the visual analytics process, through statistic methods such as uncertainty modeling, propagation and aggregation. We show that data transformations, such as regression, principal component analysis and k-means clustering, can be adapted to account for uncertainty. This framework leads to better visualizations that improve the decision-making process and help analysts gain insight on the analytic process itself.","keywords":"Uncertainty, Data Transformations, Principal Component Analysis, Model fitting","caption":"Figure 6: Detail uncertainty information. The different sensitivity pa- rameters are shown for each data point as a bar or tornado chart [24] to represent both the magnitude and sign of the sensitivity. Bars to the left indicate a negative sensitivity, while bars to the right indicate a positive sensitivity.","img_size":{"width":999,"height":708},"subfigures":[{"x":0.9922939312222643,"y":0.1975721408050999,"width":993.8915049241521,"height":708.3854507976991,"type":"single","id":"single-0"}],"visualizations":[{"x":778.2241379310343,"y":94.94252873563218,"width":213.3561679963079,"height":427.59665787696565,"type":"bar_chart","id":"bar_chart-0"},{"x":258.7528735632184,"y":103.08045977011496,"width":49.76720675806671,"height":115.8592992660296,"type":"bar_chart","id":"bar_chart-1"},{"x":7.517681749737607,"y":7.009220934783216,"width":983.2113539441352,"height":690.9675938030932,"type":"bar_chart","id":"bar_chart-11"},{"x":329.2816091954022,"y":151.90804597701148,"width":47.47126436781616,"height":120.71264367816089,"type":"bar_chart","id":"bar_chart-2"},{"x":668.3620689655171,"y":268.551724137931,"width":65.10344827586208,"height":128.85057471264372,"type":"bar_chart","id":"bar_chart-3"},{"x":588.33908045977,"y":301.10344827586204,"width":88.16091954022988,"height":151.9080459770115,"type":"bar_chart","id":"bar_chart-4"},{"x":375.3965517241379,"y":203.44827586206895,"width":46.858468356183316,"height":115.00955546323223,"type":"bar_chart","id":"bar_chart-5"},{"x":422.8678160919539,"y":147.83908045977012,"width":59.67816091954024,"height":120.71264367816089,"type":"bar_chart","id":"bar_chart-6"},{"x":243.83333333333323,"y":282.1149425287356,"width":96.29885057471266,"height":160.04597701149427,"type":"bar_chart","id":"bar_chart-7"},{"x":4.712237093690276,"y":2.7074466508387616,"width":992.4044235434529,"height":703.4092139863046,"type":"scatterplot","id":"scatterplot-8"},{"x":233.64457831325294,"y":100.46586345381526,"width":507.06827309236934,"height":367.74297188755025,"type":"scatterplot","id":"scatterplot-9"}],"relations":[{"vislist":[{"vislist":["bar_chart-0"],"relation":null,"id":"group-0"}],"relation":"mirrored","id":"relation-0"},{"vislist":[{"vislist":["bar_chart-11"],"relation":null,"id":"group-3"},{"vislist":["scatterplot-8"],"relation":null,"id":"group-2"}],"relation":"nested","id":"relation-1"}]},"1842_0":{"comp":[["matrix","flow_diagram",["nested"]]],"visType":["matrix","flow_diagram"],"compType":["nested"],"compressed_tree":[{"composite_pattern":"nested","visualization_type":[["matrix"],["flow_diagram"]]}],"coOccurrence":[["matrix","flow_diagram",["coOccurrence"]]],"year":2009,"conference":["VAST"],"authors":["Yedendra Babu Shrinivasan","David Gotz","Jie Lu"],"title":"Connecting the dots in visual analysis","doi":"10.1109/VAST.2009.5333023","abstract":"During visual analysis, users must often connect insights discovered at various points of time. This process is often called ldquoconnecting the dots.rdquo When analysts interactively explore complex datasets over multiple sessions, they may uncover a large number of findings. As a result, it is often difficult for them to recall the past insights, views and concepts that are most relevant to their current line of inquiry. This challenge is even more difficult during collaborative analysis tasks where they need to find connections between their own discoveries and insights found by others. In this paper, we describe a context-based retrieval algorithm to identify notes, views and concepts from users\' past analyses that are most relevant to a view or a note based on their line of inquiry. We then describe a related notes recommendation feature that surfaces the most relevant items to the user as they work based on this algorithm. We have implemented this recommendation feature in HARVEST, a Web based visual analytic system. We evaluate the related notes recommendation feature of HARVEST through a case study and discuss the implications of our approach.","keywords":"","caption":"Figure 1: A context-based retrieval system that retrieves related notes, views and concepts for a view or a note based on the users\u2019 line of inquiry. This retrieval system is used to support the \u2018connecting the dot\u2019 process during a visual analysis.","img_size":{"width":1422,"height":906},"subfigures":[{"x":5.117855976209343,"y":1.2203665821225707,"width":1415.762708762974,"height":899.5636784636941,"type":"single","id":"single-0"}],"visualizations":[{"x":6.717557251908261,"y":9.221374045801527,"width":1410.8702290076333,"height":889.8625954198473,"type":"flow_diagram","id":"flow_diagram-0"},{"x":257.99999999999994,"y":248.97709923664124,"width":726.1832061068701,"height":467.98473282442745,"type":"matrix","id":"matrix-1"}],"relations":[{"vislist":[{"vislist":["matrix-1"],"relation":null,"id":"group-1"},{"vislist":["flow_diagram-0"],"relation":null,"id":"group-0"}],"relation":"nested","id":"relation-0"}]},"1843_0":{"comp":[["line_chart","matrix",["nested"]]],"visType":["line_chart","matrix"],"compType":["nested"],"compressed_tree":[{"composite_pattern":"nested","visualization_type":[["line_chart"],["matrix"]]}],"coOccurrence":[["line_chart","matrix",["coOccurrence"]]],"year":2009,"conference":["VAST"],"authors":["Suvi Tarkkanen","Kaisa Miettinen","Jussi Hakanen"],"title":"Interactive poster: Interactive multiobjective optimization - a new application area for visual analytics","doi":"10.1109/VAST.2009.5333081","abstract":"The poster introduces interactive multiobjective optimization (IMO) as a field offering new application possibilities and challenges for visual analytics (VA), and aims at inspiring collaboration between the two fields. Our aim is to collect new ideas in order to be able to utilize VA techniques more effectively in our user interface development. Simulation-based IMO methods are developed for complex problem solving, where the expert decision maker (analyst) should be supported during the iterative process of eliciting preference information and examining the resulting output data. IMO is a subfield of multiple criteria decision making (MCDM). In simulation-based IMO, the optimization task is formulated in a mathematical model containing several conflicting objectives and constraints depending on decision variables. While using IMO methods the analyst progressively provides preference information in order to find the most satisfactory compromise between the conflicting objectives. In the poster, the implementations of two new IMO methods are used as examples to demonstrate concrete challenges of interaction design. One of them is described in this summary.","keywords":"","caption":"Figure 2. Pareto Navigator\u2019s user interface sketch.","img_size":{"width":1962,"height":792},"subfigures":[{"x":7.032599655709761,"y":6.451120922070354,"width":1945.7886135887074,"height":778.0251126794349,"type":"interface","id":"interface-0"}],"visualizations":[{"x":478.78504672897196,"y":103.63551401869158,"width":283.196261682243,"height":130.39252336448598,"type":"line_chart","id":"line_chart-0"},{"x":796.6168224299066,"y":105.67289719626167,"width":332.09345794392516,"height":126.31775700934578,"type":"line_chart","id":"line_chart-1"},{"x":1169.4579439252336,"y":431.6542056074766,"width":478.78504672897196,"height":158.9158878504673,"type":"line_chart","id":"line_chart-10"},{"x":1169.4579439252336,"y":604.8317757009346,"width":476.74766355140196,"height":156.87850467289718,"type":"line_chart","id":"line_chart-11"},{"x":480.8224299065421,"y":274.7757009345795,"width":285.233644859813,"height":132.42990654205607,"type":"line_chart","id":"line_chart-2"},{"x":796.6168224299066,"y":272.7383177570093,"width":332.09345794392516,"height":130.392523364486,"type":"line_chart","id":"line_chart-3"},{"x":482.8598130841121,"y":445.91588785046736,"width":281.1588785046729,"height":132.42990654205613,"type":"line_chart","id":"line_chart-4"},{"x":478.78504672897196,"y":619.0934579439253,"width":283.196261682243,"height":128.35514018691595,"type":"line_chart","id":"line_chart-5"},{"x":798.6542056074765,"y":443.8785046728971,"width":330.056074766355,"height":134.46728971962625,"type":"line_chart","id":"line_chart-6"},{"x":800.6915887850465,"y":617.0560747663552,"width":325.98130841121485,"height":134.46728971962614,"type":"line_chart","id":"line_chart-7"},{"x":1169.4579439252336,"y":81.22429906542057,"width":476.74766355140196,"height":162.9906542056075,"type":"line_chart","id":"line_chart-8"},{"x":1165.3831775700933,"y":260.5140186915888,"width":476.7476635514016,"height":158.9158878504673,"type":"line_chart","id":"line_chart-9"},{"x":5.9622348790870605,"y":15.938251284030459,"width":1931.4663531047495,"height":755.159366185831,"type":"matrix","id":"matrix-12"}],"relations":[{"vislist":[{"vislist":["line_chart-0","line_chart-1","line_chart-10","line_chart-11","line_chart-2","line_chart-3","line_chart-4","line_chart-5","line_chart-6","line_chart-7","line_chart-8","line_chart-9"],"relation":null,"id":"group-4"},{"vislist":["matrix-12"],"relation":null,"id":"group-3"}],"relation":"nested","id":"relation-3"}]},"1851_0":{"comp":[["scatterplot","matrix",["nested"]],["graph","matrix",["nested"]],["matrix","matrix",["nested"]]],"visType":["scatterplot","matrix","graph"],"compType":["nested"],"compressed_tree":[{"composite_pattern":"nested","visualization_type":[["scatterplot"],["matrix"]]},{"composite_pattern":"nested","visualization_type":[["graph","matrix"],["matrix"]]}],"coOccurrence":[["scatterplot","matrix",["coOccurrence"]],["scatterplot","graph",["coOccurrence"]],["matrix","graph",["coOccurrence"]]],"year":2009,"conference":["VAST"],"authors":["Patricia Crossno","Daniel M. Dunlavy","Timothy M. Shead"],"title":"LSAView: A tool for visual exploration of latent semantic modeling","doi":"10.1109/VAST.2009.5333428","abstract":"Latent Semantic Analysis (LSA) is a commonly-used method for automated processing, modeling, and analysis of unstructured text data. One of the biggest challenges in using LSA is determining the appropriate model parameters to use for different data domains and types of analyses. Although automated methods have been developed to make rank and scaling parameter choices, these approaches often make choices with respect to noise in the data, without an understanding of how those choices impact analysis and problem solving. Further, no tools currently exist to explore the relationships between an LSA model and analysis methods. Our work focuses on how parameter choices impact analysis and problem solving. In this paper, we present LSAView, a system for interactively exploring parameter choices for LSA models. We illustrate the use of LSAView\'s small multiple views, linked matrix-graph views, and data views to analyze parameter selection and application in the context of graph layout and clustering.","keywords":"","caption":"Figure 1: Examples of different views in the LSAView application: (1a) and (2a) G RAPH V IEW, (1b) and (2b) M ATRIX V IEW, (1c) and (2c) YOU A RE H ERE V IEW (3a) S MALL M ULTIPLES V IEW, (3b) D IFFERENCE M ATRIX V IEW (4) D OCUMENT V IEW. The C ORPUS V IEW and TABLE V IEW are not shown here.","img_size":{"width":2115,"height":1278},"subfigures":[{"x":3.637589178378111,"y":8.755567491381841,"width":2107.724821643242,"height":1267.5340663686338,"type":"interface","id":"interface-0"}],"visualizations":[{"x":782.5272364673295,"y":378.4547882426575,"width":133.69052226646,"height":129.30722645444493,"type":"graph","id":"graph-10"},{"x":508.96230713697537,"y":120.72672472888189,"width":133.7085363264133,"height":136.38270705294153,"type":"graph","id":"graph-11"},{"x":648.0191849164452,"y":249.08691960223868,"width":131.03436559988495,"height":125.68602414682854,"type":"graph","id":"graph-12"},{"x":20.369158878504777,"y":187.1214953271028,"width":485.71962616822447,"height":378.22429906542044,"type":"graph","id":"graph-4"},{"x":1198.8963439552858,"y":157.88530340675658,"width":481.73831775700955,"height":418.0373831775706,"type":"graph","id":"graph-5"},{"x":87.67202355958044,"y":641.6295837966,"width":105.199099488362,"height":111.77404320638459,"type":"graph","id":"graph-6"},{"x":1260.306479976974,"y":643.6441848695699,"width":107.39074739436931,"height":111.77404320638459,"type":"graph","id":"graph-7"},{"x":920.6010545458046,"y":505.57036679109495,"width":136.1876707529275,"height":116.87229072183683,"type":"graph","id":"graph-8"},{"x":1060.866520530287,"y":641.4525369635624,"width":131.49887436045242,"height":122.73228273642239,"type":"graph","id":"graph-9"},{"x":639.9966727368604,"y":128.7492369084667,"width":550.8791696648228,"height":492.047413681201,"type":"matrix","id":"matrix-0"},{"x":514.0514018691591,"y":764.411214953271,"width":684.7850467289719,"height":485.7196261682242,"type":"matrix","id":"matrix-1"},{"x":504.57962327547887,"y":123.92683992563879,"width":685.016969841304,"height":630.653079873533,"type":"matrix","id":"matrix-15"},{"x":323.00771435910235,"y":638.451585980847,"width":123.4558272157216,"height":116.73087586417178,"type":"matrix","id":"matrix-16"},{"x":4.443925233645018,"y":768.3925233644859,"width":493.6822429906543,"height":465.81308411214945,"type":"matrix","id":"matrix-2"},{"x":1490.8675941166503,"y":632.7575114280712,"width":131.03436559988518,"height":120.33768269377208,"type":"matrix","id":"matrix-3"},{"x":1198.5759187778704,"y":759.8910004257657,"width":481.3507307750879,"height":427.86731624452244,"type":"scatterplot","id":"scatterplot-13"},{"x":508.63987133357705,"y":767.9135126053508,"width":690.196577264554,"height":478.23602010492976,"type":"scatterplot","id":"scatterplot-14"}],"relations":[{"vislist":[{"vislist":["scatterplot-14"],"relation":null,"id":"group-5"},{"vislist":["matrix-1"],"relation":null,"id":"group-4"}],"relation":"nested","id":"relation-3"},{"vislist":[{"vislist":["graph-8","graph-10","graph-12","graph-11","graph-9","matrix-0"],"relation":null,"id":"group-8"},{"vislist":["matrix-15"],"relation":null,"id":"group-7"}],"relation":"nested","id":"relation-4"}]},"1852_2":{"comp":[["heatmap","matrix",["nested"]]],"visType":["heatmap","matrix"],"compType":["nested"],"compressed_tree":[{"composite_pattern":"nested","visualization_type":[["heatmap"],["matrix"]]}],"coOccurrence":[["heatmap","matrix",["coOccurrence"]]],"year":2009,"conference":["VAST"],"authors":["Zhenyu Guo","Matthew O. Ward","Elke A. Rundensteiner"],"title":"Model space visualization for multivariate linear trend discovery","doi":"10.1109/VAST.2009.5333431","abstract":"Discovering and extracting linear trends and correlations in datasets is very important for analysts to understand multivariate phenomena. However, current widely used multivariate visualization techniques, such as parallel coordinates and scatterplot matrices, fail to reveal and illustrate such linear relationships intuitively, especially when more than 3 variables are involved or multiple trends coexist in the dataset. We present a novel multivariate model parameter space visualization system that helps analysts discover single and multiple linear patterns and extract subsets of data that fit a model well. Using this system, analysts are able to explore and navigate in model parameter space, interactively select and tune patterns, and refine the model for accuracy using computational techniques. We build connections between model space and data space visually, allowing analysts to employ their domain knowledge during exploration to better interpret the patterns they discover and their validity. Case studies with real datasets are used to investigate the effectiveness of the visualizations.","keywords":"Knowledge Discovery, visual analysis, multivariate linear model construction, model space visualization","caption":"Figure 4: The Model Space interface overview.","img_size":{"width":1044,"height":798},"subfigures":[{"x":2.583547958339641,"y":1.0748924200152663,"width":1034.4311612440952,"height":792.3309220905383,"type":"interface","id":"interface-0"}],"visualizations":[{"x":523.2861289462045,"y":362.6813731637753,"width":273.55194398206254,"height":100.0799795056326,"type":"bar_chart","id":"bar_chart-0"},{"x":10.63793103448279,"y":58.0919540229885,"width":482.2535280402504,"height":502.77993209800786,"type":"heatmap","id":"heatmap-1"},{"x":147.6074784334911,"y":600.2348915863374,"width":254.55978610099615,"height":145.93298082514002,"type":"line_chart","id":"line_chart-2"},{"x":527.2074124103772,"y":55.848857928581594,"width":244.1366216084388,"height":235.47370922878451,"type":"line_chart","id":"line_chart-3"},{"x":522.3729569371726,"y":534.2593459678468,"width":255.54785959600156,"height":212.66690226459045,"type":"scatterplot","id":"scatterplot-4"},{"x":148.1251622850537,"y":600.4403161590977,"width":253.81889157506916,"height":145.40623192137582,"type":"scatterplot","id":"scatterplot-5"},{"x":13.695402298850638,"y":61.149425287356316,"width":477.77612795025976,"height":496.8826031823945,"type":"matrix","id":"matrix-6"}],"relations":[{"vislist":[{"vislist":["heatmap-1"],"relation":null,"id":"group-3"},{"vislist":["matrix-6"],"relation":null,"id":"group-4"}],"relation":"nested","id":"relation-2"}]},"1860_0":{"comp":[["donut_chart","proportional_area_chart",["nested"]]],"visType":["donut_chart","proportional_area_chart"],"compType":["nested"],"compressed_tree":[{"composite_pattern":"nested","visualization_type":[["donut_chart"],["proportional_area_chart"]]},{"composite_pattern":"nested","visualization_type":[["donut_chart"],["proportional_area_chart"]]},{"composite_pattern":"nested","visualization_type":[["donut_chart"],["proportional_area_chart"]]}],"coOccurrence":[["donut_chart","proportional_area_chart",["coOccurrence"]]],"year":2009,"conference":["VAST"],"authors":["Dong Hyun Jeong","Tera Marie Green","William Ribarsky","Remco Chang"],"title":"Comparing two interface tools in performing visual analytics tasks","doi":"10.1109/VAST.2009.5333469","abstract":"In visual analytics, menu systems are commonly adopted as supporting tools because of the complex nature of data. However, it is still unknown how much the interaction implicit to the interface impacts the performance of visual analysis. To show the effectiveness of two interface tools, one a floating text-based menu (Floating Menu) and the other a more interactive iconic tool (Interactive-Icon), we evaluated the use and human performance of both tools within one highly interactive visual analytics system. We asked participants to answer similarly constructed, straightforward questions in a genomic visualization, first with one tool, and then the other. During task performance we tracked completion times, task errors, and captured coarse-grained interactive behaviors. Based on the participants accuracy, speed, behaviors and post-task qualitative feedback, we observed that although the Interactive-Icon tool supports continuous interactions, task-oriented user evaluation did not find a significant difference between the two tools because there is a familiarity effect on the performance of solving the task questions with using Floating-Menu interface tool.","keywords":"","caption":"Figure 1: The system overview (a). (b) and (c) show two different interfaces as Floating-Menu and Interactive-Icon. Based on user\u2019s selection within the interface, it shows a detail information related to each organism group. Three study results: (d) Accuracy, (e) Ease of use and ease of learning, and (f) Grades on a scale of \u2018A\u2019 to \u2018F\u2019.","img_size":{"width":2103,"height":354},"subfigures":[{"x":702.5737614343842,"y":-0.11298589572368892,"width":360.8403922653523,"height":309.34957149249044,"type":"single","id":"single-0"}],"visualizations":[{"x":1070.866738894908,"y":3.325973910953098,"width":325.8169014084506,"height":300.7540628385699,"type":"bar_chart","id":"bar_chart-0"},{"x":1414.9111592632719,"y":3.325973910953098,"width":332.65222101841823,"height":303.03250270855904,"type":"bar_chart","id":"bar_chart-1"},{"x":1765.7908992416037,"y":4.977789815817999,"width":325.8169014084508,"height":291.6403033586132,"type":"bar_chart","id":"bar_chart-2"},{"x":389.6132177681473,"y":82.44474539544962,"width":227.8439869989166,"height":186.83206933911163,"type":"donut_chart","id":"donut_chart-3"},{"x":763.2773564463704,"y":57.38190682556883,"width":246.0715059588299,"height":209.61646803900325,"type":"donut_chart","id":"donut_chart-4"},{"x":43.29035752979415,"y":43.71126760563383,"width":262.020585048754,"height":227.84398699891653,"type":"donut_chart","id":"donut_chart-5"},{"x":361.250613647678,"y":14.94498068192382,"width":337.95993399919354,"height":288.2004873628661,"type":"proportional_area_chart","id":"proportional_area_chart-6"},{"x":718.0490211758313,"y":17.55372889040694,"width":333.1299569913641,"height":285.64295770688403,"type":"proportional_area_chart","id":"proportional_area_chart-7"},{"x":44.194525315518284,"y":53.36523122136619,"width":257.9861969073562,"height":211.3599862839811,"type":"proportional_area_chart","id":"proportional_area_chart-8"}],"relations":[{"vislist":[{"vislist":["donut_chart-3"],"relation":null,"id":"group-2"},{"vislist":["proportional_area_chart-6"],"relation":null,"id":"group-1"}],"relation":"nested","id":"relation-0"},{"vislist":[{"vislist":["donut_chart-4"],"relation":null,"id":"group-4"},{"vislist":["proportional_area_chart-7"],"relation":null,"id":"group-3"}],"relation":"nested","id":"relation-1"},{"vislist":[{"vislist":["donut_chart-5"],"relation":null,"id":"group-6"},{"vislist":["proportional_area_chart-8"],"relation":null,"id":"group-5"}],"relation":"nested","id":"relation-2"}]},"1864_0":{"comp":[["bar_chart","parallel_coordinate",["nested"]]],"visType":["bar_chart","parallel_coordinate"],"compType":["nested"],"compressed_tree":[{"composite_pattern":"nested","visualization_type":[["bar_chart"],["parallel_coordinate"]]}],"coOccurrence":[["bar_chart","parallel_coordinate",["coOccurrence"]]],"year":2009,"conference":["VAST"],"authors":["Youn ah Kang","Carsten G\xf6rg","John T. Stasko"],"title":"Evaluating visual analytics systems for investigative analysis: Deriving design principles from a case study","doi":"10.1109/VAST.2009.5333878","abstract":"Despite the growing number of systems providing visual analytic support for investigative analysis, few empirical studies of the potential benefits of such systems have been conducted, particularly controlled, comparative evaluations. Determining how such systems foster insight and sensemaking is important for their continued growth and study, however. Furthermore, studies that identify how people use such systems and why they benefit (or not) can help inform the design of new systems in this area. We conducted an evaluation of the visual analytics system Jigsaw employed in a small investigative sensemaking exercise, and we compared its use to three other more traditional methods of analysis. Sixteen participants performed a simulated intelligence analysis task under one of the four conditions. Experimental results suggest that Jigsaw assisted participants to analyze the data and identify an embedded threat. We describe different analysis strategies used by study participants and how computational support (or the lack thereof) influenced the strategies. We then illustrate several characteristics of the sensemaking process identified in the study and provide design implications for investigative analysis tools based thereon. We conclude with recommendations for metrics and techniques for evaluating other visual analytics investigative analysis tools.","keywords":"","caption":"Figure 1: Jigsaw\u2019s Document View, Graph View, and List View.","img_size":{"width":1014,"height":423},"subfigures":[{"x":4.1877703685367385,"y":6.138991702117333,"width":1005.069863513876,"height":412.94045106964967,"type":"interface","id":"interface-0"}],"visualizations":[{"x":434.5714285714285,"y":279.5006238303182,"width":131.07254189616788,"height":135.79756744521197,"type":"bar_chart","id":"bar_chart-0"},{"x":648.378041172801,"y":278.23549594510297,"width":141.85985874516447,"height":40.570488603601866,"type":"bar_chart","id":"bar_chart-1"},{"x":864.0823456019962,"y":278.86805988771056,"width":134.1128963996443,"height":140.58927822949306,"type":"bar_chart","id":"bar_chart-2"},{"x":433.9388646288209,"y":66.95913911416095,"width":570.5726762320649,"height":143.59201497192768,"type":"graph","id":"graph-3"},{"x":433.4983118232002,"y":275.1343570175399,"width":572.7418924827821,"height":144.9550561195964,"type":"parallel_coordinate","id":"parallel_coordinate-4"}],"relations":[{"vislist":[{"vislist":["bar_chart-0","bar_chart-1","bar_chart-2"],"relation":null,"id":"group-1"},{"vislist":["parallel_coordinate-4"],"relation":null,"id":"group-0"}],"relation":"nested","id":"relation-0"}]},"1866_3":{"comp":[["graph","matrix",["nested"]]],"visType":["graph","matrix"],"compType":["nested"],"compressed_tree":[{"composite_pattern":"nested","visualization_type":[["graph"],["matrix"]]}],"coOccurrence":[["graph","matrix",["coOccurrence"]]],"year":2009,"conference":["VAST"],"authors":["Tatiana von Landesberger","Melanie G\xf6rner","Tobias Schreck"],"title":"Visual analysis of graphs with multiple connected components","doi":"10.1109/VAST.2009.5333893","abstract":"In this paper, we present a system for the interactive visualization and exploration of graphs with many weakly connected components. The visualization of large graphs has recently received much research attention. However, specific systems for visual analysis of graph data sets consisting of many components are rare. In our approach, we rely on graph clustering using an extensive set of topology descriptors. Specifically, we use the self-organizing-map algorithm in conjunction with a user-adaptable combination of graph features for clustering of graphs. It offers insight into the overall structure of the data set. The clustering output is presented in a grid containing clusters of the connected components of the input graph. Interactive feature selection and task-tailored data views allow the exploration of the whole graph space. The system provides also tools for assessment and display of cluster quality. We demonstrate the usefulness of our system by application to a shareholder network analysis problem based on a large real-world data set. While so far our approach is applied to weighted directed graphs only, it can be used for various graph types.","keywords":"","caption":"Figure 4: Visualization of SOM clustering results (center). Each cell contains the nearest neighbor graph, while the background color indicates the frequency of the cluster elements at each cluster. Along the cluster map, several member views showing a set of nearest cluster members are shown. The member views allow interactive exploration of graph clusters.","img_size":{"width":2115,"height":1080},"subfigures":[{"x":1.6187441153484057,"y":2.6655350105870754,"width":2112.95375740677,"height":1077.0504064919737,"type":"single","id":"single-0"}],"visualizations":[{"x":6.098130841121473,"y":6.7289623367452185,"width":450.8411214953273,"height":306.16822429906546,"type":"graph","id":"graph-0"},{"x":1641.2383177570098,"y":13.457934299362043,"width":450.8411214953274,"height":319.6261682242992,"type":"graph","id":"graph-1"},{"x":1647.9672897196267,"y":363.36447635543686,"width":444.11214953271053,"height":312.8971962616822,"type":"graph","id":"graph-2"},{"x":1651.3317757009347,"y":709.9065324302031,"width":447.47663551401894,"height":356.63551401869154,"type":"graph","id":"graph-3"},{"x":3.344952364082645,"y":343.1775604675864,"width":460.9345794392524,"height":336.44859813084116,"type":"graph","id":"graph-4"},{"x":12.82710280373829,"y":719.9999903741284,"width":447.47663551401894,"height":339.8130841121497,"type":"graph","id":"graph-5"},{"x":490.584112149533,"y":215.32709317786674,"width":1130.4672897196263,"height":686.3551401869163,"type":"graph","id":"graph-6"},{"x":1644.6028037383178,"y":23.55139224328727,"width":447.47663551401894,"height":302.80373831775694,"type":"matrix","id":"matrix-10"},{"x":1647.9672897196267,"y":363.36447635543686,"width":440.7476635514021,"height":309.53271028037386,"type":"matrix","id":"matrix-11"},{"x":490.584112149533,"y":222.0560651404836,"width":1127.1028037383178,"height":672.8971962616822,"type":"matrix","id":"matrix-12"},{"x":1655.1811060947302,"y":714.3235292692847,"width":441.5624702898443,"height":353.17701827588365,"type":"matrix","id":"matrix-15"},{"x":3.344952364082645,"y":3.3449523640826446,"width":447.47663551401894,"height":309.53270065450226,"type":"matrix","id":"matrix-7"},{"x":3.344952364082645,"y":339.81307448627797,"width":460.30373831775717,"height":339.81308411214957,"type":"matrix","id":"matrix-8"},{"x":6.098130841121473,"y":713.2710184115117,"width":450.8411214953273,"height":346.54205607476644,"type":"matrix","id":"matrix-9"}],"relations":[{"vislist":[{"vislist":["graph-6"],"relation":null,"id":"group-16"},{"vislist":["matrix-12"],"relation":null,"id":"group-17"}],"relation":"nested","id":"relation-9"}]},"1870_3":{"comp":[["table","proportional_area_chart",["nested"]]],"visType":["table","proportional_area_chart"],"compType":["nested"],"compressed_tree":[{"composite_pattern":"nested","visualization_type":[["table"],["proportional_area_chart"]]}],"coOccurrence":[["table","proportional_area_chart",["coOccurrence"]]],"year":2009,"conference":["VAST"],"authors":["Daniela Oelke","Ming C. Hao","Christian Rohrdantz","Daniel A. Keim","Umeshwar Dayal","Lars-Erik Haug","Halld\xf3r Janetzko"],"title":"Visual opinion analysis of customer feedback data","doi":"10.1109/VAST.2009.5333919","abstract":"Today, online stores collect a lot of customer feedback in the form of surveys, reviews, and comments. This feedback is categorized and in some cases responded to, but in general it is underutilized - even though customer satisfaction is essential to the success of their business. In this paper, we introduce several new techniques to interactively analyze customer comments and ratings to determine the positive and negative opinions expressed by the customers. First, we introduce a new discrimination-based technique to automatically extract the terms that are the subject of the positive or negative opinion (such as price or customer service) and that are frequently commented on. Second, we derive a Reverse-Distance-Weighting method to map the attributes to the related positive and negative opinions in the text. Third, the resulting high-dimensional feature vectors are visualized in a new summary representation that provides a quick overview. We also cluster the reviews according to the similarity of the comments. Special thumbnails are used to provide insight into the composition of the clusters and their relationship. In addition, an interactive circular correlation map is provided to allow analysts to detect the relationships of the comments to other important attributes and the scores. We have applied these techniques to customer comments from real-world online stores and product reviews from web sites to identify the strength and problems of different products and services, and show the potential of our technique.","keywords":"Visual Opinion Analysis, Visual Sentiment Analysis, Visual Document Analysis, Attribute Extraction","caption":"Figure 4. Scatterplot of customer reviews on printers: Seven main opinion clusters have been identified and mapped in a 2D space, each represented by one thumbnail. The more reviews a cluster contains, the larger its thumbnail is displayed. Positive opinions are highlighted in shades blue, the negative ones accordingly in red. The color brightness is mapped to the percentage of reviews within a cluster that share a certain opinion.","img_size":{"width":2052,"height":864},"subfigures":[{"x":1.7725829595723468,"y":6.662555620089163,"width":2047.3325160561496,"height":855.1635804006304,"type":"single","id":"single-0"}],"visualizations":[{"x":6.281145340009552,"y":4.851786731188873,"width":2038.1401887122543,"height":854.296426537622,"type":"proportional_area_chart","id":"proportional_area_chart-7"},{"x":1374.5607476635512,"y":26.915880149770004,"width":656.7476635514017,"height":462.9532710280373,"type":"table","id":"table-0"},{"x":1417.626168224299,"y":516.7850390282747,"width":258.3925233644859,"height":185.7196261682243,"type":"table","id":"table-1"},{"x":873.9252336448596,"y":86.13083342079804,"width":258.392523364486,"height":185.71962616822427,"type":"table","id":"table-2"},{"x":596.6915887850466,"y":293.38316986939617,"width":204.5607476635513,"height":148.03738317757006,"type":"table","id":"table-3"},{"x":822.7850467289718,"y":546.3925156637887,"width":261.08411214953264,"height":185.7196261682243,"type":"table","id":"table-4"},{"x":1143.0841121495325,"y":662.130833420798,"width":220.71028037383167,"height":166.87850467289718,"type":"table","id":"table-5"},{"x":44.9158878504673,"y":516.7850390282747,"width":452.1869158878505,"height":325.68224299065406,"type":"table","id":"table-6"}],"relations":[{"vislist":[{"vislist":["table-0","table-1","table-2","table-3","table-4","table-6","table-5"],"relation":null,"id":"group-1"},{"vislist":["proportional_area_chart-7"],"relation":null,"id":"group-0"}],"relation":"nested","id":"relation-0"}]},"1681_0":{"comp":[["matrix","graph",["nested"]]],"visType":["matrix","graph"],"compType":["nested"],"compressed_tree":[{"composite_pattern":"nested","visualization_type":[["matrix"],["graph"]]}],"coOccurrence":[["matrix","graph",["coOccurrence"]]],"year":2008,"conference":["InfoVis"],"authors":["Nathalie Henry Riche","Anastasia Bezerianos","Jean-Daniel Fekete"],"title":"Improving the Readability of Clustered Social Networks using Node Duplication","doi":"10.1109/TVCG.2008.141","abstract":"Exploring communities is an important task in social network analysis. Such communities are currently identified using clustering methods to group actors. This approach often leads to actors belonging to one and only one cluster, whereas in real life a person can belong to several communities. As a solution we propose duplicating actors in social networks and discuss potential impact of such a move. Several visual duplication designs are discussed and a controlled experiment comparing network visualization with and without duplication is performed, using 6 tasks that are important for graph readability and visual interpretation of social networks. We show that in our experiment, duplications significantly improve community-related tasks but sometimes interfere with other graph readability tasks. Finally, we propose a set of guidelines for deciding when to duplicate actors and choosing candidates for duplication, and alternative ways to render them in social network representations.","keywords":"Clustering, Graph Visualization, Node Duplications, Social Networks","caption":"Fig. 1: Clustered graph representation of the same portion of a co-authorship network. Orange marks represent authors, blue co- authorship and grey duplication links. (a) Clustered node-link diagram with communities circled. (b) NodeTrix representation with communi- ties being adjacency matrices (authors are placed in rows and columns; blue squares indicate co-authorship). Missing intra-community links appear. (c) NodeTrix where actors shared among communities are du- plicated in each. Missing inter-community links appear.","img_size":{"width":1016,"height":467},"subfigures":[{"x":6.968025103685182,"y":5.240222494371285,"width":334.68070864565203,"height":455.9636620358602,"type":"single","id":"single-0"},{"x":342.828372691962,"y":5.2409169536919125,"width":329.7875649898091,"height":457.07405906801296,"type":"single","id":"single-1"}],"visualizations":[{"x":22.835219236209376,"y":15.852899575671854,"width":315.07637906647807,"height":443.22065063649217,"type":"graph","id":"graph-0"},{"x":356.4066478076379,"y":38.97171145685997,"width":311.7736916548797,"height":422.74398868458263,"type":"graph","id":"graph-1"},{"x":683.37270155587,"y":46.23762376237623,"width":314.41584158415833,"height":412.8359264497878,"type":"graph","id":"graph-2"},{"x":355.7461103253183,"y":38.97171145685997,"width":313.7553041018387,"height":422.74398868458263,"type":"matrix","id":"matrix-3"},{"x":682.7121640735503,"y":46.23762376237623,"width":316.3974540311174,"height":414.8175388967467,"type":"matrix","id":"matrix-4"}],"relations":[{"vislist":[{"vislist":["matrix-3"],"relation":null,"id":"group-0"},{"vislist":["graph-1"],"relation":null,"id":"group-1"}],"relation":"nested","id":"relation-0"}]},"1685_6":{"comp":[["bar_chart","map",["nested"]]],"visType":["bar_chart","map"],"compType":["nested"],"compressed_tree":[{"composite_pattern":"nested","visualization_type":[["bar_chart"],["map"]]}],"coOccurrence":[["bar_chart","map",["coOccurrence"]]],"year":2008,"conference":["InfoVis"],"authors":["Martin Luboschik","Heidrun Schumann","Hilko Cords"],"title":"Particle-based labeling: Fast point-feature labeling without obscuring other visual features","doi":"10.1109/TVCG.2008.152","abstract":"In many information visualization techniques, labels are an essential part to communicate the visualized data. To preserve the expressiveness of the visual representation, a placed label should neither occlude other labels nor visual representatives (e.g., icons, lines) that communicate crucial information. Optimal, non-overlapping labeling is an NP-hard problem. Thus, only a few approaches achieve a fast non-overlapping labeling in highly interactive scenarios like information visualization. These approaches generally target the point-feature label placement (PFLP) problem, solving only label-label conflicts. This paper presents a new, fast, solid and flexible 2D labeling approach for the PFLP problem that additionally respects other visual elements and the visual extent of labeled features. The results (number of placed labels, processing time) of our particle-based method compare favorably to those of existing techniques. Although the esthetic quality of non-real-time approaches may not be achieved with our method, it complies with practical demands and thus supports the interactive exploration of information spaces. In contrast to the known adjacent techniques, the flexibility of our technique enables labeling of dense point clouds by the use of non-occluding distant labels. Our approach is independent of the underlying visualization technique, which enables us to demonstrate the application of our labeling method within different information visualization scenarios.","keywords":"Interactive labeling, dynamic labeling, automatic label placement, occlusion-free, information visualization","caption":"Fig. 6. Labeling a 2D visualization showing 18 data items (health data set northern Germany 2000) with our method. This \ufb01gure simply demon- strates the usefulness of considering visual elements. Whereas the standard labeling would cover information presented by barchart icons (a), our approach regards those areas (b).","img_size":{"width":2077,"height":710},"subfigures":[{"x":88.45223341762434,"y":31.563964382412898,"width":946.7244759777323,"height":622.563162911324,"type":"single","id":"single-0"}],"visualizations":[{"x":126.08531583264971,"y":36.378999179655445,"width":884.301066447908,"height":616.7957342083674,"type":"bar_chart","id":"bar_chart-0"},{"x":1136.4716981132074,"y":41.490566037735846,"width":884.3010664479082,"height":611.684167350287,"type":"bar_chart","id":"bar_chart-1"},{"x":126.08531583264971,"y":34.675143560295304,"width":884.301066447908,"height":620.2034454470878,"type":"map","id":"map-2"},{"x":1138.1755537325676,"y":43.194421657096,"width":882.597210828548,"height":608.2764561115667,"type":"map","id":"map-3"}],"relations":[{"vislist":[{"vislist":["bar_chart-0"],"relation":null,"id":"group-0"},{"vislist":["map-2"],"relation":null,"id":"group-1"}],"relation":"nested","id":"relation-0"}]},"1686_0":{"comp":[["scatterplot","matrix",["nested"]]],"visType":["scatterplot","matrix"],"compType":["nested"],"compressed_tree":[{"composite_pattern":"nested","visualization_type":[["scatterplot"],["matrix"]]}],"coOccurrence":[["scatterplot","matrix",["coOccurrence"]]],"year":2008,"conference":["InfoVis"],"authors":["Niklas Elmqvist","Pierre Dragicevic","Jean-Daniel Fekete"],"title":"Rolling the Dice: Multidimensional Visual Exploration using Scatterplot Matrix Navigation","doi":"10.1109/TVCG.2008.153","abstract":"Scatterplots remain one of the most popular and widely-used visual representations for multidimensional data due to their simplicity, familiarity and visual clarity, even if they lack some of the flexibility and visual expressiveness of newer multidimensional visualization techniques. This paper presents new interactive methods to explore multidimensional data using scatterplots. This exploration is performed using a matrix of scatterplots that gives an overview of the possible configurations, thumbnails of the scatterplots, and support for interactive navigation in the multidimensional space. Transitions between scatterplots are performed as animated rotations in 3D space, somewhat akin to rolling dice. Users can iteratively build queries using bounding volumes in the dataset, sculpting the query from different viewpoints to become more and more refined. Furthermore, the dimensions in the navigation space can be reordered, manually or automatically, to highlight salient correlations and differences among them. An example scenario presents the interaction techniques supporting smooth and effortless visual exploration of multidimensional datasets.","keywords":"Visual exploration, visual queries, visual analytics, navigation, multivariate data, interaction","caption":"Fig. 1: Scatterplot matrix navigation for a digital camera dataset. The user is building queries for maximum camera resolution against price ranges and then studies them in relation to release year. The transition is performed using an animated 3D rotation.","img_size":{"width":2178,"height":992},"subfigures":[{"x":5.443448724685195,"y":1.943583853305695,"width":2168.3043348400097,"height":976.2010702122511,"type":"single","id":"single-0"}],"visualizations":[{"x":42.980198019801854,"y":255.36633663366337,"width":237.12588401697317,"height":256.7694483734088,"type":"matrix","id":"matrix-0"},{"x":40.17397454031105,"y":253.963224893918,"width":239.9321074964639,"height":258.1725601131542,"type":"scatterplot","id":"scatterplot-4"},{"x":308.168316831683,"y":230.1103253182461,"width":550.019801980198,"height":543.0042432814708,"type":"scatterplot","id":"scatterplot-5"},{"x":891.8628005657706,"y":22.44978783592645,"width":679.1060820367751,"height":963.937765205092,"type":"scatterplot","id":"scatterplot-6"},{"x":1599.0311173974537,"y":231.51343705799152,"width":551.4229137199435,"height":538.7949080622349,"type":"scatterplot","id":"scatterplot-7"}],"relations":[{"vislist":[{"vislist":["scatterplot-4"],"relation":null,"id":"group-0"},{"vislist":["matrix-0"],"relation":null,"id":"group-1"}],"relation":"nested","id":"relation-0"}]},"1718_3":{"comp":[["bar_chart","table",["nested"]],["bar_chart","matrix",["stacked"]],["matrix","scatterplot",["large_view"]],["matrix","bar_chart",["stacked"]]],"visType":["bar_chart","table","matrix","scatterplot"],"compType":["nested","stacked","large_view"],"compressed_tree":[{"composite_pattern":"large_view","visualization_type":[["matrix"],["scatterplot"]]},{"composite_pattern":"stacked","visualization_type":[["bar_chart","matrix"]]},{"composite_pattern":"nested","visualization_type":[["bar_chart"],["table"]]},{"composite_pattern":"nested","visualization_type":[["bar_chart"],["table"]]},{"composite_pattern":"nested","visualization_type":[["bar_chart"],["table"]]}],"coOccurrence":[["matrix","scatterplot",["coOccurrence"]],["matrix","bar_chart",["coOccurrence"]],["matrix","table",["coOccurrence"]],["scatterplot","bar_chart",["coOccurrence"]],["scatterplot","table",["coOccurrence"]],["bar_chart","table",["coOccurrence"]]],"year":2008,"conference":["VAST"],"authors":["Chris Weaver"],"title":"Multidimensional visual analysis using cross-filtered views","doi":"10.1109/VAST.2008.4677370","abstract":"Analysis of multidimensional data often requires careful examination of relationships across dimensions. Coordinated multiple view approaches have become commonplace in visual analysis tools because they directly support expression of complex multidimensional queries using simple interactions. However, generating such tools remains difficult because of the need to map domain-specific data structures and semantics into the idiosyncratic combinations of interdependent data and visual abstractions needed to reveal particular patterns and distributions in cross-dimensional relationships. This paper describes: (1) a method for interactively expressing sequences of multidimensional set queries by cross-filtering data values across pairs of views, and (2) design strategies for constructing coordinated multiple view interfaces for cross-filtered visual analysis of multidimensional data sets. Using examples of cross-filtered visualizations of data from several different domains, we describe how cross-filtering can be modularized and reused across designs, flexibly customized with respect to data types across multiple dimensions, and incorporated into more wide-ranging multiple view designs. The demonstrated analytic utility of these examples suggest that cross-filtering is a suitable design pattern for instantiation in a wide variety of visual analysis tools.","keywords":"","caption":"Figure 4: The Cinegraph visualization [24] of recent popular movies in the Internet Movie Database, with cross-filtering of seven dimensions (movies, ratings, release dates, genres, awards, people, and roles) spread across four data sets. Cross-filtering from awards to movies to people reveals winning collaborations between top actors and directors. Selected attribute values populate a graph that shows individual relationships.","img_size":{"width":2115,"height":1146},"subfigures":[{"x":12.304840473724793,"y":11.08104671326124,"width":2086.2679684346685,"height":1117.6536605318518,"type":"interface","id":"interface-0"}],"visualizations":[{"x":1086.5432721001991,"y":99.40378097803355,"width":441.09621680466813,"height":411.68980235102373,"type":"bar_chart","id":"bar_chart-0"},{"x":1727.6939127155597,"y":70.08910807513107,"width":55.05170961602366,"height":731.7886307922734,"type":"bar_chart","id":"bar_chart-15"},{"x":2022.160338673797,"y":66.18105729046637,"width":63.09833793362065,"height":182.21757070049745,"type":"bar_chart","id":"bar_chart-16"},{"x":2032.1663449164425,"y":320.5664563802643,"width":54.09577758630695,"height":803.1344647169863,"type":"bar_chart","id":"bar_chart-17"},{"x":436.9288437151421,"y":543.1733081875785,"width":858.1326399654456,"height":588.128289072891,"type":"graph","id":"graph-1"},{"x":1303.081414895218,"y":938.8232481093415,"width":232.57800522427942,"height":195.15165955600457,"type":"matrix","id":"matrix-2"},{"x":1308.4280357049715,"y":740.99827814846,"width":221.88476360477262,"height":200.4982803657582,"type":"matrix","id":"matrix-3"},{"x":701.5865737979431,"y":4.6632741255534205,"width":227.23138441452593,"height":232.57800522427956,"type":"matrix","id":"matrix-4"},{"x":1083.869961695322,"y":107.42371219266388,"width":443.76952720954495,"height":406.34318154127016,"type":"matrix","id":"matrix-5"},{"x":418.21567088100477,"y":4.6632741255534205,"width":505.2556665217109,"height":499.9090457119572,"type":"scatterplot","id":"scatterplot-6"},{"x":1532.9861097146206,"y":11.184537617099915,"width":264.657730082801,"height":801.9931214630332,"type":"table","id":"table-10"},{"x":1530.312799309744,"y":866.6438671776687,"width":267.3310404876777,"height":261.98441967792394,"type":"table","id":"table-11"},{"x":1305.7547253000946,"y":537.826687377825,"width":221.88476360477242,"height":200.4982803657582,"type":"table","id":"table-12"},{"x":4.66327412555342,"y":4.6632741255534205,"width":410.1957396663744,"height":852.7860191556919,"type":"table","id":"table-7"},{"x":1800.3171502022983,"y":257.1290948657634,"width":288.71752372669204,"height":874.1725023947062,"type":"table","id":"table-8"},{"x":1802.990460607175,"y":4.6632741255534205,"width":286.04421332181533,"height":253.96448846329386,"type":"table","id":"table-9"}],"relations":[{"vislist":[{"vislist":["matrix-4"],"relation":null,"id":"group-0"},{"vislist":["scatterplot-6"],"relation":null,"id":"group-1"}],"relation":"large_view","id":"relation-0"},{"vislist":[{"vislist":["bar_chart-0","matrix-5"],"relation":null,"id":"group-2"}],"relation":"stacked","id":"relation-1"},{"vislist":[{"vislist":["bar_chart-15"],"relation":null,"id":"group-3"},{"vislist":["table-10"],"relation":null,"id":"group-4"}],"relation":"nested","id":"relation-2"},{"vislist":[{"vislist":["bar_chart-16"],"relation":null,"id":"group-5"},{"vislist":["table-9"],"relation":null,"id":"group-6"}],"relation":"nested","id":"relation-3"},{"vislist":[{"vislist":["bar_chart-17"],"relation":null,"id":"group-7"},{"vislist":["table-8"],"relation":null,"id":"group-8"}],"relation":"nested","id":"relation-4"}]},"1737_1":{"comp":[["proportional_area_chart","chord_diagram",["nested"]]],"visType":["proportional_area_chart","chord_diagram"],"compType":["nested"],"compressed_tree":[{"composite_pattern":"nested","visualization_type":[["proportional_area_chart"],["chord_diagram"]]}],"coOccurrence":[["proportional_area_chart","chord_diagram",["coOccurrence"]]],"year":2008,"conference":["VAST"],"authors":["Carlos D. Correa","Tarik Crnovrsanin","Chris Muelder","Zeqian Shen","Ryan Armstrong","James Shearer","Kwan-Liu Ma"],"title":"Cell phone mini challenge award: Intuitive social network graphs visual analytics of cell phone data using mobivis and ontovis","doi":"10.1109/VAST.2008.4677391","abstract":"MobiVis is a visual analytics tools to aid in the process of processing and understanding complex relational data, such as social networks. At the core of these tools is the ability to filter complex networks structurally and semantically, which helps us discover clusters and patterns in the organization of social networks. Semantic filtering is obtained via an ontology graph, based on another visual analytics tool, called OntoVis. In this summary, we describe how these tools where used to analyze one of the mini-challenges of the 2008 VAST challenge.","keywords":"","caption":"Figure 4: A different layout for the call graph, where nodes are placedin a circular layout. Links indicate calls (where directionis encodedas a color gradient from red to green). Although an overview is diffi-cult to visualize, it provides detail information on periods of interest.Here, we show the calls among actors at two different stages.Similarpatterns where found on nodes that where believed to be linked.","img_size":{"width":987,"height":474},"subfigures":[{"x":0.45355953062038235,"y":3.8033757627198783,"width":480.9871552461239,"height":468.01207053181975,"type":"single","id":"single-0"}],"visualizations":[{"x":7.2413793103448825,"y":24.517241379310345,"width":464.919540229885,"height":442.2183908045977,"type":"chord_diagram","id":"chord_diagram-0"},{"x":498.4942528735632,"y":9.98850574712641,"width":482.1724137931034,"height":457.65517241379314,"type":"chord_diagram","id":"chord_diagram-1"},{"x":8.149425287356365,"y":24.51724137931032,"width":463.1034482758621,"height":443.1264367816092,"type":"proportional_area_chart","id":"proportional_area_chart-2"},{"x":498.4942528735632,"y":9.080459770114942,"width":482.1724137931034,"height":459.47126436781616,"type":"proportional_area_chart","id":"proportional_area_chart-3"}],"relations":[{"vislist":[{"vislist":["proportional_area_chart-2"],"relation":null,"id":"group-1"},{"vislist":["chord_diagram-0"],"relation":null,"id":"group-2"}],"relation":"nested","id":"relation-0"}]},"1542_6":{"comp":[["glyph_based","tree",["nested"]]],"visType":["glyph_based","tree"],"compType":["nested"],"compressed_tree":[{"composite_pattern":"nested","visualization_type":[["glyph_based"],["tree"]]}],"coOccurrence":[["glyph_based","tree",["coOccurrence"]]],"year":2007,"conference":["InfoVis"],"authors":["Nivedita R. Kadaba","Pourang Irani","Jason Leboe-McGowan"],"title":"Visualizing Causal Semantics Using Animations","doi":"10.1109/TVCG.2007.70528","abstract":"Michotte\'s theory of ampliation suggests that causal relationships are perceived by objects animated under appropriate spatiotemporal conditions. We extend the theory of ampliation and propose that the immediate perception of complex causal relations is also dependent on a set of structural and temporal rules. We designed animated representations, based on Michotte\'s rules, for showing complex causal relationships or causal semantics. In this paper we describe a set of animations for showing semantics such as causal amplification, causal strength, causal dampening, and causal multiplicity. In a two part study we compared the effectiveness of both the static and animated representations. The first study (N=44) asked participants to recall passages that were previously displayed using both types of representations. Participants were 8% more accurate in recalling causal semantics when they were presented using animations instead of static graphs. In the second study (N=112) we evaluated the intuitiveness of the representations. Our results showed that while users were as accurate with the static graphs as with the animations, they were 9% faster in matching the correct causal statements in the animated condition. Overall our results show that animated diagrams that are designed based on perceptual rules such as those proposed by Michotte have the potential to facilitate comprehension of complex causal relations.","keywords":"Causality, visualization, semantics, animated graphs, perception, visualizing cause and effect, graph semantics","caption":"Fig. 6. Representation of the flu graph using nodes, links, , , bars, and colors","img_size":{"width":825,"height":851},"subfigures":[{"x":14.986061391527326,"y":1.9932171251041104,"width":788.4549799422174,"height":824.4953822754649,"type":"single","id":"single-0"}],"visualizations":[{"x":374.1886973180077,"y":286.9272030651341,"width":88.0344827586207,"height":122.27011494252876,"type":"bar_chart","id":"bar_chart-0"},{"x":39.68720847398526,"y":142.17229331654033,"width":738.3824376052593,"height":591.108753179522,"type":"glyph_based","id":"glyph_based-2"},{"x":38.35344827586209,"y":140.20306513409963,"width":738.5114942528736,"height":595.0478927203065,"type":"tree","id":"tree-1"}],"relations":[{"vislist":[{"vislist":["glyph_based-2"],"relation":null,"id":"group-1"},{"vislist":["tree-1"],"relation":null,"id":"group-0"}],"relation":"nested","id":"relation-0"}]},"1546_0":{"comp":[["bar_chart","flow_diagram",["nested"]]],"visType":["bar_chart","flow_diagram"],"compType":["nested"],"compressed_tree":[{"composite_pattern":"nested","visualization_type":[["bar_chart"],["flow_diagram"]]}],"coOccurrence":[["bar_chart","flow_diagram",["coOccurrence"]]],"year":2007,"conference":["InfoVis"],"authors":["Jeffrey Heer","George G. Robertson"],"title":"Animated Transitions in Statistical Data Graphics","doi":"10.1109/TVCG.2007.70539","abstract":"In this paper we investigate the effectiveness of animated transitions between common statistical data graphics such as bar charts, pie charts, and scatter plots. We extend theoretical models of data graphics to include such transitions, introducing a taxonomy of transition types. We then propose design principles for creating effective transitions and illustrate the application of these principles in &lt;i&gt;DynaVis&lt;/i&gt;, a visualization system featuring animated data graphics. Two controlled experiments were conducted to assess the efficacy of various transition types, finding that animated transitions can significantly improve graphical perception.","keywords":"Statistical data graphics, animation, transitions, information visualization, design, experiment","caption":"Figure 2. Animating from stacked bars to grouped bars. The top path directly interpolates between the starting and ending states. The bottom path is staged: the first stage changes the widths and x-coordinates of bars, the second stage drops the bars down to the baseline.","img_size":{"width":2130,"height":567},"subfigures":[{"x":2.9892691093551558,"y":1.2697044395851866,"width":2118.1965656004377,"height":559.7994420031249,"type":"single","id":"single-0"}],"visualizations":[{"x":6.025459688826026,"y":146.42079207920796,"width":476.0113154172561,"height":241.01838755304098,"type":"bar_chart","id":"bar_chart-0"},{"x":1650.9759547383312,"y":146.42079207920796,"width":475.6553698311743,"height":247.04384724186704,"type":"bar_chart","id":"bar_chart-1"},{"x":548.3168316831685,"y":3.3686754304945787,"width":479.54496096423605,"height":239.77290230731612,"type":"bar_chart","id":"bar_chart-2"},{"x":1111.6973125884022,"y":3.3686754304945787,"width":480.1728974799817,"height":245.6942505217096,"type":"bar_chart","id":"bar_chart-3"},{"x":542.2913719943425,"y":315.13366336633663,"width":481.0485838109229,"height":242.77627839675063,"type":"bar_chart","id":"bar_chart-4"},{"x":1111.6973125884022,"y":321.15912305516275,"width":475.8870043497843,"height":235.93753643849126,"type":"bar_chart","id":"bar_chart-5"},{"x":3.3686754304945787,"y":3.3686754304945787,"width":2123.262649139011,"height":560.2626491390108,"type":"flow_diagram","id":"flow_diagram-6"}],"relations":[{"vislist":[{"vislist":["bar_chart-0","bar_chart-1","bar_chart-2","bar_chart-3","bar_chart-4","bar_chart-5"],"relation":null,"id":"group-1"},{"vislist":["flow_diagram-6"],"relation":null,"id":"group-0"}],"relation":"nested","id":"relation-0"}]},"1547_0":{"comp":[["treemap","treemap",["nested"]]],"visType":["treemap"],"compType":["nested"],"compressed_tree":[{"composite_pattern":"nested","visualization_type":[["treemap"],["treemap"]]}],"coOccurrence":[["treemap","treemap",["coOccurrence"]]],"year":2007,"conference":["InfoVis"],"authors":["Renaud Blanch","Eric Lecolinet"],"title":"Browsing Zoomable Treemaps: Structure-Aware Multi-Scale Navigation Techniques","doi":"10.1109/TVCG.2007.70540","abstract":"Treemaps provide an interesting solution for representing hierarchical data. However, most studies have mainly focused on layout algorithms and paid limited attention to the interaction with treemaps. This makes it difficult to explore large data sets and to get access to details, especially to those related to the leaves of the trees. We propose the notion of zoomable treemaps (ZTMs), an hybridization between treemaps and zoomable user interfaces that facilitates the navigation in large hierarchical data sets. By providing a consistent set of interaction techniques, ZTMs make it possible for users to browse through very large data sets (e.g., 700,000 nodes dispatched amongst 13 levels). These techniques use the structure of the displayed data to guide the interaction and provide a way to improve interactive navigation in treemaps.","keywords":"Information visualization, multi-scale interaction, structure-aware navigation, zoomable treemaps","caption":"Figure 2. Tree displayed with the HCIL Treemap 4 software. (left) global view, (right) detail of a node.","img_size":{"width":1056,"height":492},"subfigures":[{"x":3.3837968441366906,"y":4.296465932110097,"width":519.0330632557836,"height":485.71695514695625,"type":"single","id":"single-0"}],"visualizations":[{"x":540.5442764578834,"y":9.36933045356372,"width":504.0518358531317,"height":474.40172786177106,"type":"treemap","id":"treemap-0"},{"x":6.842332613390929,"y":7.08855291576674,"width":510.89416846652273,"height":476.682505399568,"type":"treemap","id":"treemap-1"},{"x":16.4845896645845,"y":56.705720830866376,"width":495.5241969932632,"height":419.36883630756427,"type":"treemap","id":"treemap-2"}],"relations":[{"vislist":[{"vislist":["treemap-2"],"relation":null,"id":"group-2"},{"vislist":["treemap-1"],"relation":null,"id":"group-1"}],"relation":"nested","id":"relation-1"}]},"1554_1":{"comp":[["bar_chart","matrix",["nested"]]],"visType":["bar_chart","matrix"],"compType":["nested"],"compressed_tree":[{"composite_pattern":"nested","visualization_type":[["bar_chart"],["matrix"]]}],"coOccurrence":[["bar_chart","matrix",["coOccurrence"]]],"year":2007,"conference":["InfoVis"],"authors":["Remco Chang","Ginette Wessel","Robert Kosara","Eric Sauda","William Ribarsky"],"title":"Legible Cities: Focus-Dependent Multi-Resolution Visualization of Urban Relationships","doi":"10.1109/TVCG.2007.70574","abstract":"Numerous systems have been developed to display large collections of data for urban contexts; however, most have focused on layering of single dimensions of data and manual calculations to understand relationships within the urban environment. Furthermore, these systems often limit the user\'s perspectives on the data, thereby diminishing the user\'s spatial understanding of the viewing region. In this paper, we introduce a highly interactive urban visualization tool that provides intuitive understanding of the urban data. Our system utilizes an aggregation method that combines buildings and city blocks into legible clusters, thus providing continuous levels of abstraction while preserving the user\'s mental model of the city. In conjunction with a 3D view of the urban model, a separate but integrated information visualization view displays multiple disparate dimensions of the urban data, allowing the user to understand the urban environment both spatially and cognitively in one glance. For our evaluation, expert users from various backgrounds viewed a real city model with census data and confirmed that our system allowed them to gain more intuitive and deeper understanding of the urban model from different perspectives and levels of abstraction than existing commercial urban visualization systems.","keywords":"Urban models, information visualization, multi-resolution","caption":"Fig. 2. UrbanVis overview. The data view on the left shows demographic data of the areas around the focus point (focus in the middle). The model view on the right shows the clustered building models. The color gradient indicates the distance from the focus point, and provides a visual link between the two different data views (matrix view and parallel coordinates) and the model view. The data shown is census data for the city of Charlotte in Mecklenburg county, North Carolina. The straight lines in the lower half of the model view are where the city and county border South Carolina.","img_size":{"width":2148,"height":1092},"subfigures":[{"x":6.368089724151371,"y":6.2781108505394165,"width":2138.8775029438953,"height":1083.0556843438626,"type":"interface","id":"interface-0"}],"visualizations":[{"x":8.38067349926797,"y":140.696925329429,"width":1068.0175695461203,"height":743.4553440702782,"type":"bar_chart","id":"bar_chart-0"},{"x":10.625158076942444,"y":80.3825378374791,"width":1060.5443727693998,"height":803.4397493643518,"type":"matrix","id":"matrix-2"},{"x":53.147877013177215,"y":884.1522693997072,"width":1013.6573938506589,"height":187.06295754026348,"type":"parallel_coordinate","id":"parallel_coordinate-1"}],"relations":[{"vislist":[{"vislist":["bar_chart-0"],"relation":null,"id":"group-2"},{"vislist":["matrix-2"],"relation":null,"id":"group-1"}],"relation":"nested","id":"relation-1"}]},"1557_0":{"comp":[["matrix","graph",["nested"]]],"visType":["matrix","graph"],"compType":["nested"],"compressed_tree":[{"composite_pattern":"nested","visualization_type":[["matrix"],["graph"]]}],"coOccurrence":[["matrix","graph",["coOccurrence"]]],"year":2007,"conference":["InfoVis"],"authors":["Nathalie Henry Riche","Jean-Daniel Fekete","Michael J. McGuffin"],"title":"NodeTrix: a Hybrid Visualization of Social Networks","doi":"10.1109/TVCG.2007.70582","abstract":"The need to visualize large social networks is growing as hardware capabilities make analyzing large networks feasible and many new data sets become available. Unfortunately, the visualizations in existing systems do not satisfactorily resolve the basic dilemma of being readable both for the global structure of the network and also for detailed analysis of local communities. To address this problem, we present NodeTrix, a hybrid representation for networks that combines the advantages of two traditional representations: node-link diagrams are used to show the global structure of a network, while arbitrary portions of the network can be shown as adjacency matrices to better support the analysis of communities. A key contribution is a set of interaction techniques. These allow analysts to create a NodeTrix visualization by dragging selections to and from node-link and matrix forms, and to flexibly manipulate the NodeTrix representation to explore the dataset and create meaningful summary visualizations of their findings. Finally, we present a case study applying NodeTrix to the analysis of the InfoVis 2004 coauthorship dataset to illustrate the capabilities of NodeTrix as both an exploration tool and an effective means of communicating results.","keywords":"Network visualization, Matrix visualization, Hybrid visualization, Aggregation, Interaction","caption":"Fig. 1: NodeTrix Representation of the largest component of the Info- Vis Co-authorship Network","img_size":{"width":1018,"height":420},"subfigures":[{"x":4.206729580518219,"y":4.002149688787263,"width":1010.1433243424483,"height":416.4464455387751,"type":"single","id":"single-0"}],"visualizations":[{"x":1.6100054404898971,"y":5.233644859813085,"width":1014.7799891190202,"height":413.15634969969705,"type":"graph","id":"graph-0"},{"x":71.33644859813081,"y":22.24299065420561,"width":31.40186915887853,"height":30.09345794392523,"type":"matrix","id":"matrix-1"},{"x":93.57943925233641,"y":109.90654205607478,"width":91.58878504672903,"height":95.5140186915888,"type":"matrix","id":"matrix-2"},{"x":54.327102803738285,"y":277.3831775700935,"width":74.57943925233647,"height":74.57943925233644,"type":"matrix","id":"matrix-3"},{"x":407.5981308411215,"y":128.22429906542058,"width":181.8691588785048,"height":185.7943925233645,"type":"matrix","id":"matrix-4"},{"x":271.5233644859814,"y":119.06542056074768,"width":30.093457943925163,"height":30.09345794392523,"type":"matrix","id":"matrix-5"},{"x":224.42056074766356,"y":249.9065420560748,"width":95.51401869158887,"height":96.82242990654207,"type":"matrix","id":"matrix-6"},{"x":388.85524189847445,"y":362.93299240437517,"width":20.167276505984834,"height":22.328056131626113,"type":"matrix","id":"matrix-7"},{"x":513.4602003104525,"y":378.77870965907755,"width":20.16727650598489,"height":20.88753638119863,"type":"matrix","id":"matrix-8"},{"x":658.9526951036293,"y":353.5696140265964,"width":29.530654883763646,"height":31.691434509404814,"type":"matrix","id":"matrix-9"},{"x":630.0280373831778,"y":124.29906542056077,"width":37.94392523364479,"height":39.25233644859813,"type":"matrix","id":"matrix-10"},{"x":738.6261682242991,"y":86.3551401869159,"width":65.42056074766357,"height":68.0373831775701,"type":"matrix","id":"matrix-11"},{"x":691.5233644859813,"y":219.81308411214957,"width":120.37383177570098,"height":121.68224299065425,"type":"matrix","id":"matrix-12"},{"x":851.1495327102806,"y":35.32710280373833,"width":146.5420560747663,"height":149.1588785046729,"type":"matrix","id":"matrix-13"},{"x":974.1401869158881,"y":239.43925233644862,"width":23.551401869158784,"height":22.24299065420561,"type":"matrix","id":"matrix-14"},{"x":877.3177570093459,"y":225.04672897196264,"width":23.551401869158898,"height":22.24299065420561,"type":"matrix","id":"matrix-15"},{"x":895.6355140186917,"y":365.04672897196264,"width":20.934579439252392,"height":22.24299065420564,"type":"matrix","id":"matrix-16"}],"relations":[{"vislist":[{"vislist":["matrix-1","matrix-2","matrix-3","matrix-4","matrix-5","matrix-6","matrix-7","matrix-8","matrix-9","matrix-10","matrix-11","matrix-12","matrix-13"],"relation":null,"id":"group-1"},{"vislist":["graph-0"],"relation":null,"id":"group-0"}],"relation":"nested","id":"relation-0"}]},"1572_8":{"comp":[["bar_chart","matrix",["nested"]]],"visType":["bar_chart","matrix"],"compType":["nested"],"compressed_tree":[{"composite_pattern":"nested","visualization_type":[["bar_chart"],["matrix"]]}],"coOccurrence":[["bar_chart","matrix",["coOccurrence"]]],"year":2007,"conference":["VAST"],"authors":["Gennady L. Andrienko","Natalia V. Andrienko","Ulrich Bartling"],"title":"Visual Analytics Approach to User-Controlled Evacuation Scheduling","doi":"10.1109/VAST.2007.4388995","abstract":"Application of the ideas of visual analytics is a promising approach to supporting decision making, in particular, where the problems have geographic (or spatial) and temporal aspects. Visual analytics may be especially helpful in time-critical applications, which pose hard challenges to decision support. We have designed a suite of tools to support transportation-planning tasks such as emergency evacuation of people from a disaster- affected area. The suite combines a tool for automated scheduling based on a genetic algorithm with visual analytics techniques allowing the user to evaluate tool results and direct its work. A transportation schedule, which is generated by the tool, is a complex construct involving geographical space, time, and heterogeneous objects (people and vehicles) with states and positions varying in time. We apply task-analytical approach to design techniques that could effectively support a human planner in the analysis of this complex information H. 1.2 [User/Machine Systems]: Human information processing - Visual Analytics; 1.6.9 [Visualization]: information visualization.","keywords":"Geovisualization, transportation planning, vehicle scheduling, task-centered design, coordinated multiple views","caption":"Figure 10.   The matrix shows how many people and how far have been transported from each source.","img_size":{"width":1020,"height":513},"subfigures":[{"x":6.931562986308733,"y":6.399249612813199,"width":1007.1309160203458,"height":503.18352431450114,"type":"single","id":"single-0"}],"visualizations":[{"x":302.1465517241381,"y":1.6131685160114881,"width":704.6379310344828,"height":194.5862068965517,"type":"bar_chart","id":"bar_chart-0"},{"x":12.232758620689767,"y":191.63793103448273,"width":292.8620689655172,"height":317.4310344827586,"type":"bar_chart","id":"bar_chart-1"},{"x":7.318965517241467,"y":1.96551724137931,"width":1001.4310344827587,"height":509.06896551724134,"type":"matrix","id":"matrix-2"}],"relations":[{"vislist":[{"vislist":["bar_chart-0","bar_chart-1"],"relation":null,"id":"group-1"},{"vislist":["matrix-2"],"relation":null,"id":"group-0"}],"relation":"nested","id":"relation-0"}]},"1580_5":{"comp":[["others","graph",["nested"]]],"visType":["others","graph"],"compType":["nested"],"compressed_tree":[{"composite_pattern":"nested","visualization_type":[["others"],["graph"]]}],"coOccurrence":[["others","graph",["coOccurrence"]]],"year":2007,"conference":["VAST"],"authors":["Hangzai Luo","Jianping Fa","Jing Yan","William Ribarsky","Shin\'ichi Satoh"],"title":"Analyzing Large-Scale News Video Databases to Support Knowledge Visualization and Intuitive Retrieval","doi":"10.1109/VAST.2007.4389003","abstract":"In this paper, we have developed a novel framework to enable more effective investigation of large-scale news video database via knowledge visualization. To relieve users from the burdensome exploration of well-known and uninteresting knowledge of news reports, a novel interestingness measurement for video news reports is presented to enable users to find news stories of interest at first glance and capture the relevant knowledge in large-scale video news databases efficiently. Our framework takes advantage of both automatic semantic video analysis and human intelligence by integrating with visualization techniques on semantic video retrieval systems. Our techniques on intelligent news video analysis and knowledge discovery have the capacity to enable more effective visualization and exploration of large-scale news video collections. In addition, news video visualization and exploration can provide valuable feedback to improve our techniques for intelligent news video analysis and knowledge discovery.","keywords":"Semantic Video Classification, Knowledge Discovery, Knowledge Visualization","caption":"Figure 6: Slimmed news topic relation network of Figure 3.","img_size":{"width":1512,"height":1161},"subfigures":[{"x":9.564395391391432,"y":4.0883300362412,"width":1490.3087403430966,"height":1145.143078172614,"type":"single","id":"single-0"}],"visualizations":[{"x":12.025862068965466,"y":13.344827586206897,"width":1496.8857805860112,"height":1140.9827586206893,"type":"graph","id":"graph-0"},{"x":9.17574201086446,"y":5.3833587167298695,"width":1496.119315451343,"height":1147.7620872388275,"type":"others","id":"others-1"}],"relations":[{"vislist":[{"vislist":["others-1"],"relation":null,"id":"group-1"},{"vislist":["graph-0"],"relation":null,"id":"group-0"}],"relation":"nested","id":"relation-0"}]},"1583_5":{"comp":[["bar_chart","parallel_coordinate",["nested"]]],"visType":["bar_chart","parallel_coordinate"],"compType":["nested"],"compressed_tree":[{"composite_pattern":"nested","visualization_type":[["bar_chart"],["parallel_coordinate"]]}],"coOccurrence":[["bar_chart","parallel_coordinate",["coOccurrence"]]],"year":2007,"conference":["VAST"],"authors":["John T. Stasko","Carsten G\xf6rg","Zhicheng Liu","Kanupriya Singhal"],"title":"Jigsaw: Supporting Investigative Analysis through Interactive Visualization","doi":"10.1109/VAST.2007.4389006","abstract":"Investigative analysts who work with collections of text documents connect embedded threads of evidence in order to formulate hypotheses about plans and activities of potential interest. As the number of documents and the corresponding number of concepts and entities within the documents grow larger, sense-making processes become more and more difficult for the analysts. We have developed a visual analytic system called Jigsaw that represents documents and their entities visually in order to help analysts examine reports more efficiently and develop theories about potential actions more quickly. Jigsaw provides multiple coordinated views of document entities with a special emphasis on visually illustrating connections between entities across the different documents.","keywords":"Visual analytics, investigative analysis, intelligence analysis, information visualization, multiple views","caption":"Figure 6: Views from the example scenario discussed in the text and the accompanying video.","img_size":{"width":2070,"height":2532},"subfigures":[{"x":7.688889074977428,"y":20.099487285952048,"width":2049.0365739353747,"height":2502.9675041897476,"type":"interface","id":"interface-0"}],"visualizations":[{"x":267.195544398339,"y":229.5804636041236,"width":221.4547120457385,"height":517.5712984383258,"type":"bar_chart","id":"bar_chart-0"},{"x":778.4395653496438,"y":230.84591910152784,"width":470.74944503436967,"height":517.5712984383258,"type":"bar_chart","id":"bar_chart-1"},{"x":1536.5847623571967,"y":224.70241262847512,"width":473.5015739520231,"height":524.2872317260573,"type":"bar_chart","id":"bar_chart-2"},{"x":50.33333333333348,"y":977.5141242937854,"width":715.2542372881352,"height":791.5480225988699,"type":"graph","id":"graph-3"},{"x":20.264165549086655,"y":209.88891240579403,"width":2005.234531218625,"height":560.0816307494559,"type":"parallel_coordinate","id":"parallel_coordinate-5"},{"x":888.5400337042479,"y":899.9034096889307,"width":1127.5108092569012,"height":869.5834999497666,"type":"scatterplot","id":"scatterplot-4"}],"relations":[{"vislist":[{"vislist":["bar_chart-0","bar_chart-1","bar_chart-2"],"relation":null,"id":"group-1"},{"vislist":["parallel_coordinate-5"],"relation":null,"id":"group-0"}],"relation":"nested","id":"relation-0"}]},"1589_5":{"comp":[["glyph_based","graph",["nested"]]],"visType":["glyph_based","graph"],"compType":["nested"],"compressed_tree":[{"composite_pattern":"nested","visualization_type":[["glyph_based"],["graph"]]}],"coOccurrence":[["glyph_based","graph",["coOccurrence"]]],"year":2007,"conference":["VAST"],"authors":["Ulrik Brandes","J\xfcrgen Lerner"],"title":"Visual Analysis of Controversy in User-generated Encyclopedias","doi":"10.1109/VAST.2007.4389012","abstract":"Wikipedia is a large and rapidly growing Web-based collaborative authoring environment, where anyone on the Internet can create, modify, and delete pages about encyclopedic topics. A remarkable property of some Wikipedia pages is that they are written by up to thousands of authors who may have contradicting opinions. In this paper we show that a visual analysis of the \\"who revises whom\\"- network gives deep insight into controversies. We propose a set of analysis and visualization techniques that reveal the dominant authors of a page, the roles they play, and the alters they confront. Thereby we provide tools to understand how Wikipedia authors collaborate in the presence of controversy.","keywords":"Wikipedia, social network analysis, controversy","caption":"Figure 6: Example visualization of a revision network (determined from Gun politics and related pages). Nodes represent the different authors. If two authors are on opposite sides they strongly revise each other. Other characteristics are represented as described in the legend on the righthand side (also see Sect. 4.2). The diagram at the bottom shows the total number of edits per month. For more on this particular network see Sect. 5.1.","img_size":{"width":1903,"height":1368},"subfigures":[{"x":-0.3705469472290603,"y":1.8559003004012873,"width":1902.2320037671893,"height":1361.2716624825428,"type":"interface","id":"interface-0"}],"visualizations":[{"x":29.15153733528541,"y":1127.648609077599,"width":1814.653001464129,"height":236.34553440702777,"type":"bar_chart","id":"bar_chart-0"},{"x":19.13689604685203,"y":3.638994701112979,"width":1472.1522693997072,"height":989.4465592972183,"type":"glyph_based","id":"glyph_based-1"},{"x":17.133967789165354,"y":3.638994701112979,"width":1470.1493411420208,"height":985.440702781845,"type":"graph","id":"graph-2"},{"x":1531.3477306002926,"y":560.8199121522695,"width":312.4568081991215,"height":266.38945827232806,"type":"graph","id":"graph-3"}],"relations":[{"vislist":[{"vislist":["glyph_based-1"],"relation":null,"id":"group-1"},{"vislist":["graph-2"],"relation":null,"id":"group-0"}],"relation":"nested","id":"relation-0"}]},"1590_4":{"comp":[["bar_chart","graph",["nested"]],["pie_chart","graph",["nested"]],["polar_plot","graph",["nested"]]],"visType":["bar_chart","graph","pie_chart","polar_plot"],"compType":["nested"],"compressed_tree":[{"composite_pattern":"nested","visualization_type":[["bar_chart","pie_chart","polar_plot"],["graph"]]}],"coOccurrence":[["bar_chart","pie_chart",["coOccurrence"]],["bar_chart","polar_plot",["coOccurrence"]],["bar_chart","graph",["coOccurrence"]],["pie_chart","polar_plot",["coOccurrence"]],["pie_chart","graph",["coOccurrence"]],["polar_plot","graph",["coOccurrence"]]],"year":2007,"conference":["VAST"],"authors":["Niklas Elmqvist","John T. Stasko","Philippas Tsigas"],"title":"DataMeadow: A Visual Canvas for Analysis of Large-Scale Multivariate Data","doi":"10.1109/VAST.2007.4389013","abstract":"Supporting visual analytics of multiple large-scale multidimensional datasets requires a high degree of interactivity and user control beyond the conventional challenges of visualizing such datasets. We present the DataMeadow, a visual canvas providing rich interaction for constructing visual queries using graphical set representations called DataRoses. A DataRose is essentially a starplot of selected columns in a dataset displayed as multivariate visualizations with dynamic query sliders integrated into each axis. The purpose of the DataMeadow is to allow users to create advanced visual queries by iteratively selecting and filtering into the multidimensional data. Furthermore, the canvas provides a clear history of the analysis that can be annotated to facilitate dissemination of analytical results to outsiders. Towards this end, the DataMeadow has a direct manipulation interface for selection, filtering, and creation of sets, subsets, and data dependencies using both simple and complex mouse gestures. We have evaluated our system using a qualitative expert review involving two researchers working in the area. Results from this review are favorable for our new method.","keywords":"Multivariate data, visual analytics, parallel coordinates, dynamic queries, iterative analysis, starplot, small multiples","caption":"Figure 5: The DataMeadow prototype implementation. The main panel shows the visualization canvas and the smaller panels to the right show the available and currently visualized dimensions in the data.","img_size":{"width":2115,"height":1314},"subfigures":[{"x":2.0855909789374074,"y":3.496138528921254,"width":2106.706467424247,"height":1302.8816925315673,"type":"interface","id":"interface-0"}],"visualizations":[{"x":114.28217821782188,"y":657.9292786421499,"width":187.71428571428567,"height":144.96746817538894,"type":"bar_chart","id":"bar_chart-0"},{"x":73.39391796322496,"y":157.97736916548808,"width":1427.371994342291,"height":1087.2560113154168,"type":"graph","id":"graph-1"},{"x":407.9342291371995,"y":511.1032531824611,"width":243.47100424328127,"height":243.47100424328144,"type":"pie_chart","id":"pie_chart-2"},{"x":909.7446958981612,"y":605.889674681754,"width":239.75388967468155,"height":250.9052333804808,"type":"pie_chart","id":"pie_chart-3"},{"x":88.26237623762381,"y":263.91513437058,"width":327.1060820367751,"height":330.8231966053748,"type":"polar_plot","id":"polar_plot-4"},{"x":627.2439886845827,"y":195.14851485148526,"width":319.6718528995756,"height":327.10608203677504,"type":"polar_plot","id":"polar_plot-5"},{"x":1143.9229137199434,"y":210.0169731258841,"width":334.5403111739747,"height":323.38896746817534,"type":"polar_plot","id":"polar_plot-6"},{"x":1097.4589816124471,"y":806.6138613861386,"width":328.9646393210746,"height":317.8132956152757,"type":"polar_plot","id":"polar_plot-7"},{"x":71.53536067892509,"y":862.3705799151344,"width":328.9646393210749,"height":317.81329561527554,"type":"polar_plot","id":"polar_plot-8"},{"x":526.8818953323904,"y":767.5841584158416,"width":462.7807637906647,"height":367.9943422913718,"type":"polar_plot","id":"polar_plot-9"}],"relations":[{"vislist":[{"vislist":["bar_chart-0","pie_chart-2","polar_plot-4","pie_chart-3","polar_plot-5","polar_plot-6","polar_plot-7","polar_plot-8","polar_plot-9"],"relation":null,"id":"group-1"},{"vislist":["graph-1"],"relation":null,"id":"group-0"}],"relation":"nested","id":"relation-0"}]},"1593_0":{"comp":[["bar_chart","parallel_coordinate",["nested"]]],"visType":["bar_chart","parallel_coordinate"],"compType":["nested"],"compressed_tree":[{"composite_pattern":"nested","visualization_type":[["bar_chart"],["parallel_coordinate"]]}],"coOccurrence":[["bar_chart","parallel_coordinate",["coOccurrence"]]],"year":2007,"conference":["VAST"],"authors":["Carsten G\xf6rg","Zhicheng Liu","Neel Parekh","Kanupriya Singhal","John T. Stasko"],"title":"Visual Analytics with Jigsaw","doi":"10.1109/VAST.2007.4389017","abstract":"This article briefly introduces the Jigsaw system and describes how we used it in analysis activities for the VAST \'07 Contest. Jigsaw is a visual analytic system that provides multiple coordinated views to show connections between entities that are extracted from a collection of documents.","keywords":"","caption":"Figure 1: The List View, Text View, Graph View, and Calendar View showing data from the VAST \u201907 dataset.","img_size":{"width":2070,"height":1674},"subfigures":[{"x":4.969963214216892,"y":5.935384424313578,"width":2056.3665416641184,"height":1660.2835868536808,"type":"interface","id":"interface-0"}],"visualizations":[{"x":10.396551724138021,"y":246.9310344827586,"width":468.20689655172407,"height":413.68965517241384,"type":"bar_chart","id":"bar_chart-0"},{"x":616.5000000000001,"y":240.51724137931035,"width":471.41379310344826,"height":615.7241379310344,"type":"bar_chart","id":"bar_chart-1"},{"x":16.81034482758628,"y":1042.2413793103447,"width":1199.3793103448277,"height":606.103448275862,"type":"graph","id":"graph-2"},{"x":1241.8448275862065,"y":974.896551724138,"width":772.8620689655172,"height":647.7931034482758,"type":"matrix","id":"matrix-3"},{"x":9.140162517538558,"y":241.10396424988988,"width":1079.2932696067026,"height":607.4405809842488,"type":"parallel_coordinate","id":"parallel_coordinate-4"}],"relations":[{"vislist":[{"vislist":["bar_chart-0","bar_chart-1"],"relation":null,"id":"group-4"},{"vislist":["parallel_coordinate-4"],"relation":null,"id":"group-5"}],"relation":"nested","id":"relation-1"}]},"2083_10":{"comp":[["scatterplot","matrix",["nested"]]],"visType":["scatterplot","matrix"],"compType":["nested"],"compressed_tree":[{"composite_pattern":"nested","visualization_type":[["scatterplot"],["matrix"]]}],"coOccurrence":[["scatterplot","matrix",["coOccurrence"]]],"year":2011,"conference":["InfoVis"],"authors":["Michael Bostock","Vadim Ogievetsky","Jeffrey Heer"],"title":"D\xb3 Data-Driven Documents","doi":"10.1109/TVCG.2011.185","abstract":"Data-Driven Documents (D3) is a novel representation-transparent approach to visualization for the web. Rather than hide the underlying scenegraph within a toolkit-specific abstraction, D3 enables direct inspection and manipulation of a native representation: the standard document object model (DOM). With D3, designers selectively bind input data to arbitrary document elements, applying dynamic transforms to both generate and modify content. We show how representational transparency improves expressiveness and better integrates with developer tools than prior approaches, while offering comparable notational efficiency and retaining powerful declarative components. Immediate evaluation of operators further simplifies debugging and allows iterative development. Additionally, we demonstrate how D3 transforms naturally enable animation and interaction with dramatic performance improvements over intermediate representations.","keywords":"Information visualization, user interfaces, toolkits, 2D graphics","caption":"Fig. 11. Visualizations used in our benchmarks. (a) Scatterplot matrix [40] L. W with brushing & linking. (b) Animated stacked graph.","img_size":{"width":1042,"height":1612},"subfigures":[{"x":14.432963162196247,"y":4.082156606026163,"width":1023.4169368591017,"height":1602.1201110479492,"type":"single","id":"single-0"}],"visualizations":[{"x":4.2880551594986285,"y":1068.4904214559388,"width":1031.4329501915709,"height":539.2215233845627,"type":"area_chart","id":"area_chart-0"},{"x":25.35632183908047,"y":9.264367816091953,"width":1000.5517241379306,"height":1009.8160919540229,"type":"scatterplot","id":"scatterplot-1"},{"x":24.704980842911937,"y":4.288055159498628,"width":998.1149425287355,"height":1015.9923371647509,"type":"matrix","id":"matrix-2"}],"relations":[{"vislist":[{"vislist":["scatterplot-1"],"relation":null,"id":"group-3"},{"vislist":["matrix-2"],"relation":null,"id":"group-4"}],"relation":"nested","id":"relation-2"}]},"2089_6":{"comp":[["heatmap","tree",["nested"]]],"visType":["heatmap","tree"],"compType":["nested"],"compressed_tree":[{"composite_pattern":"nested","visualization_type":[["heatmap"],["tree"]]}],"coOccurrence":[["heatmap","tree",["coOccurrence"]]],"year":2011,"conference":["InfoVis"],"authors":["Michelle Borkin","Krzysztof Z. Gajos","Amanda Randles","Dimitris Mitsouras","Simone Melchionna","Frank J. Rybicki","Charles L. Feldman","Hanspeter Pfister"],"title":"Evaluation of Artery Visualizations for Heart Disease Diagnosis","doi":"10.1109/TVCG.2011.192","abstract":"Heart disease is the number one killer in the United States, and finding indicators of the disease at an early stage is critical for treatment and prevention. In this paper we evaluate visualization techniques that enable the diagnosis of coronary artery disease. A key physical quantity of medical interest is endothelial shear stress (ESS). Low ESS has been associated with sites of lesion formation and rapid progression of disease in the coronary arteries. Having effective visualizations of a patient\'s ESS data is vital for the quick and thorough non-invasive evaluation by a cardiologist. We present a task taxonomy for hemodynamics based on a formative user study with domain experts. Based on the results of this study we developed HemoVis, an interactive visualization application for heart disease diagnosis that uses a novel 2D tree diagram representation of coronary artery trees. We present the results of a formal quantitative user study with domain experts that evaluates the effect of 2D versus 3D artery representations and of color maps on identifying regions of low ESS. We show statistically significant results demonstrating that our 2D visualizations are more accurate and efficient than 3D representations, and that a perceptually appropriate color map leads to fewer diagnostic mistakes than a rainbow color map.","keywords":"Quantitative evaluation, qualitative evaluation, biomedical and medical visualization","caption":"Fig. 5. HemoVis in the \u201ctree\u201d mode displaying a patient\u2019s left coronary artery tree with color mapped to ESS.","img_size":{"width":1083,"height":611},"subfigures":[{"x":14.824466354444478,"y":15.77182050674261,"width":1054.6514529081992,"height":590.5107542789158,"type":"interface","id":"interface-0"}],"visualizations":[{"x":17.49096621308098,"y":37.136260624240286,"width":1046.2648178486156,"height":563.9055446136745,"type":"heatmap","id":"heatmap-0"},{"x":90.9487244882731,"y":36.36692522588665,"width":831.9374941840257,"height":565.6769908609236,"type":"tree","id":"tree-1"}],"relations":[{"vislist":[{"vislist":["heatmap-0"],"relation":null,"id":"group-1"},{"vislist":["tree-1"],"relation":null,"id":"group-0"}],"relation":"nested","id":"relation-0"}]},"2111_6":{"comp":[["bar_chart","sankey_diagram",["nested"]],["heatmap","sankey_diagram",["nested"]],["parallel_coordinate","sankey_diagram",["nested"]]],"visType":["bar_chart","sankey_diagram","heatmap","parallel_coordinate"],"compType":["nested"],"compressed_tree":[{"composite_pattern":"nested","visualization_type":[["bar_chart","heatmap","parallel_coordinate"],["sankey_diagram"]]},{"composite_pattern":"nested","visualization_type":[["parallel_coordinate","heatmap"],["sankey_diagram"]]}],"coOccurrence":[["parallel_coordinate","heatmap",["coOccurrence"]],["parallel_coordinate","sankey_diagram",["coOccurrence"]],["heatmap","sankey_diagram",["coOccurrence"]]],"year":2011,"conference":["InfoVis"],"authors":["Alexander Lex","Hans-J\xf6rg Schulz","Marc Streit","Christian Partl","Dieter Schmalstieg"],"title":"VisBricks: Multiform Visualization of Large, Inhomogeneous Data","doi":"10.1109/TVCG.2011.250","abstract":"Large volumes of real-world data often exhibit inhomogeneities: vertically in the form of correlated or independent dimensions and horizontally in the form of clustered or scattered data items. In essence, these inhomogeneities form the patterns in the data that researchers are trying to find and understand. Sophisticated statistical methods are available to reveal these patterns, however, the visualization of their outcomes is mostly still performed in a one-view-fits-all manner, In contrast, our novel visualization approach, VisBricks, acknowledges the inhomogeneity of the data and the need for different visualizations that suit the individual characteristics of the different data subsets. The overall visualization of the entire data set is patched together from smaller visualizations, there is one VisBrick for each cluster in each group of interdependent dimensions. Whereas the total impression of all VisBricks together gives a comprehensive high-level overview of the different groups of data, each VisBrick independently shows the details of the group of data it represents, State-of-the-art brushing and visual linking between all VisBricks furthermore allows the comparison of the groupings and the distribution of data items among them. In this paper, we introduce the VisBricks visualization concept, discuss its design rationale and implementation, and demonstrate its usefulness by applying it to a use case from the field of biomedicine.","keywords":"Inhomogeneous data, multiple coordinated views, multiform visualization","caption":"Fig. 7. Steps in an analysis of gene expression in different genotypes of mice. (a) The overview with two dimension groups clustered. (b) All dimension groups clustered and two bricks brushed. Notice the connection from the top-left brick showing the parallel coordinates (orange brush) to the lower brick in the center (blue brush). The blue brick contains outliers of the orange brick, which indicates genes of interest. (c) Enlarged bricks of interest, showing only ribbons for the outliers of brushed bricks. (d) The bricks of interest in focus mode, which enables detailed analysis.","img_size":{"width":2124,"height":1347},"subfigures":[{"x":1071.3004362009187,"y":-0.7727056083203796,"width":1047.7935106759492,"height":614.5684712976367,"type":"interface","id":"interface-0"},{"x":1066.2854824802068,"y":671.0749815165217,"width":1049.2234634151366,"height":624.1430800236129,"type":"interface","id":"interface-1"}],"visualizations":[{"x":1072.3161925601748,"y":53.054704595185996,"width":1037.5142231947489,"height":551.17943107221,"type":"bar_chart","id":"bar_chart-1"},{"x":1075.2636761487968,"y":53.054704595185996,"width":1037.5142231947484,"height":551.17943107221,"type":"heatmap","id":"heatmap-4"},{"x":1075.2636761487968,"y":707.3960612691465,"width":1037.5142231947484,"height":577.706783369803,"type":"heatmap","id":"heatmap-6"},{"x":1075.2636761487968,"y":50.10722100656456,"width":1037.5142231947484,"height":551.17943107221,"type":"parallel_coordinate","id":"parallel_coordinate-7"},{"x":1078.2111597374178,"y":710.3435448577682,"width":1025.724288840263,"height":568.8643326039386,"type":"parallel_coordinate","id":"parallel_coordinate-9"},{"x":1078.2111597374178,"y":50.10722100656456,"width":1034.5667396061272,"height":554.1269146608313,"type":"sankey_diagram","id":"sankey_diagram-11"},{"x":1078.2111597374178,"y":707.3960612691465,"width":1028.6717724288842,"height":574.7592997811814,"type":"sankey_diagram","id":"sankey_diagram-13"}],"relations":[{"vislist":[{"vislist":["bar_chart-1","heatmap-4","parallel_coordinate-7"],"relation":null,"id":"group-9"},{"vislist":["sankey_diagram-11"],"relation":null,"id":"group-10"}],"relation":"nested","id":"relation-4"},{"vislist":[{"vislist":["parallel_coordinate-9","heatmap-6"],"relation":null,"id":"group-11"},{"vislist":["sankey_diagram-13"],"relation":null,"id":"group-12"}],"relation":"nested","id":"relation-5"}]},"2121_9":{"comp":[["glyph_based","graph",["nested"]],["bar_chart","matrix",["nested"]],["bar_chart","table",["nested"]],["bar_chart","comb",["stacked"]],["comb","bar_chart",["stacked"]]],"visType":["glyph_based","graph","bar_chart","matrix","table","comb"],"compType":["nested","stacked"],"compressed_tree":[{"composite_pattern":"nested","visualization_type":[["glyph_based"],["graph"]]},{"composite_pattern":"nested","visualization_type":[["bar_chart"],["matrix"]]},{"composite_pattern":"stacked","visualization_type":[["bar_chart",{"composite_pattern":"nested","visualization_type":[["bar_chart"],["table"]]}]]}],"coOccurrence":[["glyph_based","graph",["coOccurrence"]],["glyph_based","bar_chart",["coOccurrence"]],["glyph_based","matrix",["coOccurrence"]],["glyph_based","table",["coOccurrence"]],["graph","bar_chart",["coOccurrence"]],["graph","matrix",["coOccurrence"]],["graph","table",["coOccurrence"]],["bar_chart","matrix",["coOccurrence"]],["bar_chart","table",["coOccurrence"]],["matrix","table",["coOccurrence"]]],"year":2011,"conference":["VAST"],"authors":["Hossam Sharara","Awalin Sopan","Galileo Namata","Lise Getoor","Lisa Singh"],"title":"G-PARE: A visual analytic tool for comparative analysis of uncertain graphs","doi":"10.1109/VAST.2011.6102442","abstract":"There are a growing number of machine learning algorithms which operate on graphs. Example applications for these algorithms include predicting which customers will recommend products to their friends in a viral marketing campaign using a customer network, predicting the topics of publications in a citation network, or predicting the political affiliations of people in a social network. It is important for an analyst to have tools to help compare the output of these machine learning algorithms. In this work, we present G-PARE, a visual analytic tool for comparing two uncertain graphs, where each uncertain graph is produced by a machine learning algorithm which outputs probabilities over node labels. G-PARE provides several different views which allow users to obtain a global overview of the algorithms output, as well as focused views that show subsets of nodes of interest. By providing an adaptive exploration environment, G-PARE guides the users to places in the graph where two algorithms predictions agree and places where they disagree. This enables the user to follow cascades of misclassifications by comparing the algorithms outcome with the ground truth. After describing the features of G-PARE, we illustrate its utility through several use cases based on networks from different domains.","keywords":"Uncertain Graphs, Comparative Analysis, Model Comparison, Visualizing Uncertainty","caption":"Figure 9: Initial display for the communication network case study. The nodes represent email addresses, label indicates the title of the email address user, and edges indicate communication exchanged between email addresses.","img_size":{"width":1812,"height":999},"subfigures":[{"x":2.7170372887210563,"y":3.574247986383842,"width":1802.313189692489,"height":988.661937964718,"type":"interface","id":"interface-0"}],"visualizations":[{"x":1014.9507506524285,"y":205.77408637873762,"width":344.8977007036125,"height":82.97342192691025,"type":"bar_chart","id":"bar_chart-0"},{"x":1361.9567413831435,"y":205.77408637873754,"width":408.8493749238377,"height":82.97342192691022,"type":"bar_chart","id":"bar_chart-1"},{"x":1365.385466970764,"y":332.1238890768036,"width":401.81910136589323,"height":193.08263914232205,"type":"bar_chart","id":"bar_chart-13"},{"x":905.9999999999999,"y":644.2504951565447,"width":877.8588039867113,"height":318.73212972708734,"type":"bar_chart","id":"bar_chart-7"},{"x":21.50332225913607,"y":242.2823920265782,"width":587.4518272425252,"height":579.154485049834,"type":"glyph_based","id":"glyph_based-2"},{"x":21.50332225913607,"y":242.2823920265782,"width":587.4518272425252,"height":579.154485049834,"type":"glyph_based","id":"glyph_based-3"},{"x":21.50332225913607,"y":243.9418604651164,"width":589.1112956810632,"height":574.1760797342195,"type":"graph","id":"graph-4"},{"x":21.50332225913607,"y":243.9418604651164,"width":589.1112956810632,"height":574.1760797342195,"type":"graph","id":"graph-5"},{"x":906.0000000000002,"y":646.1984314716814,"width":877.858803986711,"height":311.8013558164885,"type":"matrix","id":"matrix-8"},{"x":909.3189368770763,"y":285.42857142857144,"width":861.2641196013292,"height":238.9634551495017,"type":"table","id":"table-10"},{"x":909.3189368770763,"y":285.42857142857144,"width":861.2641196013292,"height":238.9634551495017,"type":"table","id":"table-11"}],"relations":[{"vislist":[{"vislist":["glyph_based-3"],"relation":null,"id":"group-2"},{"vislist":["graph-5"],"relation":null,"id":"group-1"}],"relation":"nested","id":"relation-1"},{"vislist":[{"vislist":["bar_chart-7"],"relation":null,"id":"group-6"},{"vislist":["matrix-8"],"relation":null,"id":"group-7"}],"relation":"nested","id":"relation-3"},{"vislist":[{"vislist":["bar_chart-0","bar_chart-1",{"vislist":[{"vislist":["bar_chart-13"],"relation":null,"id":"group-8"},{"vislist":["table-11"],"relation":null,"id":"group-9"}],"relation":"nested","id":"relation-4"}],"relation":null,"id":"group-11"}],"relation":"stacked","id":"relation-5"}]},"2128_16":{"comp":[["bar_chart","scatterplot",["nested"]]],"visType":["bar_chart","scatterplot"],"compType":["nested"],"compressed_tree":[{"composite_pattern":"nested","visualization_type":[["bar_chart"],["scatterplot"]]}],"coOccurrence":[["bar_chart","scatterplot",["coOccurrence"]]],"year":2011,"conference":["VAST"],"authors":["Zhenyu Guo","Matthew O. Ward","Elke A. Rundensteiner","Carolina Ruiz"],"title":"Pointwise local pattern exploration for sensitivity analysis","doi":"10.1109/VAST.2011.6102450","abstract":"Sensitivity analysis is a powerful method for discovering the significant factors that contribute to targets and understanding the interaction between variables in multivariate datasets. A number of sensitivity analysis methods fall into the class of local analysis, in which the sensitivity is defined as the partial derivatives of a target variable with respect to a group of independent variables. Incorporating sensitivity analysis in visual analytic tools is essential for multivariate phenomena analysis. However, most current multivariate visualization techniques do not allow users to explore local patterns individually for understanding the sensitivity from a pointwise view. In this paper, we present a novel pointwise local pattern exploration system for visual sensitivity analysis. Using this system, analysts are able to explore local patterns and the sensitivity at individual data points, which reveals the relationships between a focal point and its neighbors. During exploration, users are able to interactively change the derivative coefficients to perform sensitivity analysis based on different requirements as well as their domain knowledge. Each local pattern is assigned an outlier factor, so that users can quickly identify anomalous local patterns that do not conform with the global pattern. Users can also compare the local pattern with the global pattern both visually and statistically. Finally, the local pattern is integrated into the original attribute space using color mapping and jittering, which reveals the distribution of the partial derivatives. Case studies with real datasets are used to investigate the effectiveness of the visualizations and interactions.","keywords":"Knowledge discovery, sensitivity analysis, local pattern visualizations","caption":"Figure 17: The local pattern view after de-creasing the coefficient of color and increas-ing the coefficient ofclarity.  The neighbor with higher clarity became a \u201cgood\u201d deal.","img_size":{"width":718,"height":691},"subfigures":[{"x":9.15147012809579,"y":12.723703420266459,"width":705.5818234344778,"height":675.1127773234831,"type":"interface","id":"interface-0"}],"visualizations":[{"x":81.22259136212614,"y":61.98338870431893,"width":580.8073089700995,"height":539.485049833887,"type":"bar_chart","id":"bar_chart-0"},{"x":81.24612673928482,"y":55.3981039358359,"width":586.6450019064522,"height":546.0370303342255,"type":"scatterplot","id":"scatterplot-2"}],"relations":[{"vislist":[{"vislist":["bar_chart-0"],"relation":null,"id":"group-2"},{"vislist":["scatterplot-2"],"relation":null,"id":"group-1"}],"relation":"nested","id":"relation-0"}]},"2168_1":{"comp":[["bar_chart","parallel_coordinate",["nested"]]],"visType":["bar_chart","parallel_coordinate"],"compType":["nested"],"compressed_tree":[{"composite_pattern":"nested","visualization_type":[["bar_chart"],["parallel_coordinate"]]}],"coOccurrence":[["bar_chart","parallel_coordinate",["coOccurrence"]]],"year":2011,"conference":["VAST"],"authors":["Elizabeth Braunstein","Carsten G\xf6rg","Zhicheng Liu","John T. Stasko"],"title":"Jigsaw to save vastopolis","doi":"10.1109/VAST.2011.6102496","abstract":"This article describes our analytic process and experience of using the Jigsaw system in working on the VAST 2011 Mini Challenge 3. We describe how we extracted and worked with entities from the documents, and how Jigsaw\'s computational analysis capabilities and visualizations scaffolded the investigation. Based on our experiences, we discuss desirable features that would enhance the analytic power of Jigsaw.","keywords":"","caption":"Figure 2: List View showing entities connected to Vastopolis.","img_size":{"width":975,"height":735},"subfigures":[{"x":0.8369179154527958,"y":4.2064107864946,"width":969.4148603544407,"height":730.4983079831464,"type":"interface","id":"interface-0"}],"visualizations":[{"x":16.339821955170912,"y":113.14147947054768,"width":215.60010732714815,"height":607.2775058735073,"type":"bar_chart","id":"bar_chart-2"},{"x":371.34134404354086,"y":115.47810765925246,"width":226.84148657240402,"height":604.9509272297789,"type":"bar_chart","id":"bar_chart-3"},{"x":739.1615676649068,"y":111.60025907949216,"width":219.4858096180425,"height":611.9243984780727,"type":"bar_chart","id":"bar_chart-4"},{"x":10.642972220962049,"y":90.90634931167438,"width":947.8670017569118,"height":637.2386178486742,"type":"parallel_coordinate","id":"parallel_coordinate-0"}],"relations":[{"vislist":[{"vislist":["bar_chart-2","bar_chart-3","bar_chart-4"],"relation":null,"id":"group-1"},{"vislist":["parallel_coordinate-0"],"relation":null,"id":"group-0"}],"relation":"nested","id":"relation-0"}]},"2985_2":{"comp":[["others","tree",["nested"]]],"visType":["others","tree"],"compType":["nested"],"compressed_tree":[{"composite_pattern":"nested","visualization_type":[["others"],["tree"]]}],"coOccurrence":[["others","tree",["coOccurrence"]]],"year":2018,"conference":["InfoVis"],"authors":["Alper Sarikaya","Michael Correll","Lyn Bartram","Melanie Tory","Danyel Fisher"],"title":"What Do We Talk About When We Talk About Dashboards?","doi":"10.1109/TVCG.2018.2864903","abstract":"Dashboards are one of the most common use cases for data visualization, and their design and contexts of use are considerably different from exploratory visualization tools. In this paper, we look at the broad scope of how dashboards are used in practice through an analysis of dashboard examples and documentation about their use. We systematically review the literature surrounding dashboard use, construct a design space for dashboards, and identify major dashboard types. We characterize dashboards by their design goals, levels of interaction, and the practices around them. Our framework and literature review suggest a number of fruitful research directions to better support dashboard design, implementation and use.","keywords":"Dashboards,literature review,survey,design space,open coding","caption":"Fig. 3: Hierarchical clustering of the sample of 83 dashboards using a Hamming distance. We identified 7 clusters that exemplified different functional and visual characteristics of dashboard design. An interactive version of this figure is available in the supplemental material.","img_size":{"width":967,"height":783},"subfigures":[{"x":2.9088149770189053,"y":12.266140737287374,"width":948.1825125971006,"height":760.2017321409967,"type":"single","id":"single-0"}],"visualizations":[{"x":0,"y":4.878504672897196,"width":957.9345794392523,"height":778.1214953271028,"type":"tree","id":"tree-0"},{"x":8.101429810270709,"y":20.041349228974386,"width":932.7971403794584,"height":745.9173015420508,"type":"others","id":"others-1"}],"relations":[{"vislist":[{"id":"group-0","relation":null,"vislist":["others-1"]},{"id":"group-1","relation":null,"vislist":["tree-0"]}],"relation":"nested","id":"relation-0"}]},"3000_5":{"comp":[["donut_chart","graph",["nested"]]],"visType":["donut_chart","graph"],"compType":["nested"],"compressed_tree":[{"composite_pattern":"nested","visualization_type":[["donut_chart"],["graph"]]},{"composite_pattern":"nested","visualization_type":[["donut_chart"],["graph"]]},{"composite_pattern":"nested","visualization_type":[["donut_chart"],["graph"]]},{"composite_pattern":"nested","visualization_type":[["donut_chart"],["graph"]]}],"coOccurrence":[["donut_chart","graph",["coOccurrence"]]],"year":2018,"conference":["InfoVis"],"authors":["Wei Che","Fangzhou Guo","Dongming Han","Jacheng Pan","Xiaotao Nie","Jiazhi Xia","Xiaolong Zhang"],"title":"Structure-Based Suggestive Exploration: A New Approach for Effective Exploration of Large Networks","doi":"10.1109/TVCG.2018.2865139","abstract":"When analyzing a visualized network, users need to explore different sections of the network to gain insight. However, effective exploration of large networks is often a challenge. While various tools are available for users to explore the global and local features of a network, these tools usually require significant interaction activities, such as repetitive navigation actions to follow network nodes and edges. In this paper, we propose a structure-based suggestive exploration approach to support effective exploration of large networks by suggesting appropriate structures upon user request. Encoding nodes with vectorized representations by transforming information of surrounding structures of nodes into a high dimensional space, our approach can identify similar structures within a large network, enable user interaction with multiple similar structures simultaneously, and guide the exploration of unexplored structures. We develop a web-based visual exploration system to incorporate this suggestive exploration approach and compare performances of our approach under different vectorizing methods and networks. We also present the usability and effectiveness of our approach through a controlled user study with two datasets.","keywords":"Large Network Exploration,Structure-Based Exploration,Suggestive Exploration","caption":"Figure 5. Encodings of nodes in the suggestion gallery and layout after node expansion. The layout of expanded nodes are firstly calculated by force-directed layout algorithm and then placed on the right of explored nodes. The color of the inner circle indicates if the node is selected. The outer ring encodes the ratio of explored neighbors (the grey part) and unexplored neighbors (the green part).","img_size":{"width":1021,"height":335},"subfigures":[{"x":291.8483747048101,"y":5.895944218157033,"width":404.11493134861564,"height":141.18303259450872,"type":"single","id":"single-0"}],"visualizations":[{"x":7.190140845070423,"y":17.973837129834674,"width":240.15070422535211,"height":140.9267605633803,"type":"donut_chart","id":"donut_chart-0"},{"x":279.7592386230652,"y":10.57342576672184,"width":414.511744107004,"height":143.8442895451618,"type":"donut_chart","id":"donut_chart-1"},{"x":11.504225352112677,"y":173.28087938335582,"width":192.69577464788733,"height":130.8605633802817,"type":"donut_chart","id":"donut_chart-3"},{"x":289.7873527327033,"y":157.9634707141489,"width":403.4052080368708,"height":129.9621702128946,"type":"donut_chart","id":"donut_chart-4"},{"x":6.385240775484677,"y":17.127579737335807,"width":240.72357723577235,"height":141.1138211382114,"type":"graph","id":"graph-6"},{"x":10.854909318323951,"y":172.92745465916192,"width":191.5572232645403,"height":130.89743589743586,"type":"graph","id":"graph-7"},{"x":287.33583489681047,"y":153.13320825515945,"width":406.10131332082545,"height":137.92120075046898,"type":"graph","id":"graph-8"},{"x":275.8424015009381,"y":9.465290806754197,"width":416.95622263914936,"height":130.8974358974359,"type":"graph","id":"graph-9"}],"relations":[{"vislist":[{"id":"group-0","relation":null,"vislist":["donut_chart-0"]},{"id":"group-1","relation":null,"vislist":["graph-6"]}],"relation":"nested","id":"relation-0"},{"vislist":[{"id":"group-2","relation":null,"vislist":["donut_chart-1"]},{"id":"group-3","relation":null,"vislist":["graph-9"]}],"relation":"nested","id":"relation-1"},{"vislist":[{"id":"group-4","relation":null,"vislist":["donut_chart-3"]},{"id":"group-5","relation":null,"vislist":["graph-7"]}],"relation":"nested","id":"relation-2"},{"vislist":[{"id":"group-6","relation":null,"vislist":["donut_chart-4"]},{"id":"group-7","relation":null,"vislist":["graph-8"]}],"relation":"nested","id":"relation-3"}]},"3000_8":{"comp":[["graph","tree",["nested"]]],"visType":["graph","tree"],"compType":["nested"],"compressed_tree":[{"composite_pattern":"nested","visualization_type":[["graph"],["tree"]]}],"coOccurrence":[["graph","tree",["coOccurrence"]]],"year":2018,"conference":["InfoVis"],"authors":["Wei Che","Fangzhou Guo","Dongming Han","Jacheng Pan","Xiaotao Nie","Jiazhi Xia","Xiaolong Zhang"],"title":"Structure-Based Suggestive Exploration: A New Approach for Effective Exploration of Large Networks","doi":"10.1109/TVCG.2018.2865139","abstract":"When analyzing a visualized network, users need to explore different sections of the network to gain insight. However, effective exploration of large networks is often a challenge. While various tools are available for users to explore the global and local features of a network, these tools usually require significant interaction activities, such as repetitive navigation actions to follow network nodes and edges. In this paper, we propose a structure-based suggestive exploration approach to support effective exploration of large networks by suggesting appropriate structures upon user request. Encoding nodes with vectorized representations by transforming information of surrounding structures of nodes into a high dimensional space, our approach can identify similar structures within a large network, enable user interaction with multiple similar structures simultaneously, and guide the exploration of unexplored structures. We develop a web-based visual exploration system to incorporate this suggestive exploration approach and compare performances of our approach under different vectorizing methods and networks. We also present the usability and effectiveness of our approach through a controlled user study with two datasets.","keywords":"Large Network Exploration,Structure-Based Exploration,Suggestive Exploration","caption":"Figure 6. Visual design used in the exploration history view: (a) the suggestion relation from an exemplar structure to a suggested struc- ture; and (b) the exploration relation from a suggested structure to an exemplar structure. The structures are encoded with the glyph described in Section 5.2.","img_size":{"width":1020,"height":384},"subfigures":[{"x":99.04913212876993,"y":13.27632871319234,"width":778.5441334180276,"height":363.8237350924756,"type":"single","id":"single-0"}],"visualizations":[{"x":108.22024517903145,"y":11.85140546082848,"width":833.9618713098939,"height":364.23391037182125,"type":"graph","id":"graph-0"},{"x":108.77768662838393,"y":12.935192780967988,"width":833.4044298605415,"height":362.31337161607877,"type":"tree","id":"tree-1"}],"relations":[{"vislist":[{"id":"group-0","relation":null,"vislist":["graph-0"]},{"id":"group-1","relation":null,"vislist":["tree-1"]}],"relation":"nested","id":"relation-0"}]},"3007_0":{"comp":[["bar_chart","table",["nested"]],["stripe_graph","table",["nested"]],["tree","comb",["stacked"]],["comb","tree",["stacked"]]],"visType":["bar_chart","table","stripe_graph","tree","comb"],"compType":["nested","stacked"],"compressed_tree":[{"composite_pattern":"stacked","visualization_type":[["tree",{"composite_pattern":"nested","visualization_type":[["bar_chart","stripe_graph"],["table"]]}]]}],"coOccurrence":[["bar_chart","stripe_graph",["coOccurrence"]],["bar_chart","table",["coOccurrence"]],["bar_chart","tree",["coOccurrence"]],["stripe_graph","table",["coOccurrence"]],["stripe_graph","tree",["coOccurrence"]],["table","tree",["coOccurrence"]]],"year":2018,"conference":["InfoVis"],"authors":["Carolina Nobre","Marc Streit","Alexander Lex"],"title":"Juniper: A Tree+Table Approach to Multivariate Graph Visualization","doi":"10.1109/TVCG.2018.2865149","abstract":"Analyzing large, multivariate graphs is an important problem in many domains, yet such graphs are challenging to visualize. In this paper, we introduce a novel, scalable, tree-table multivariate graph visualization technique, which makes many tasks related to multivariate graph analysis easier to achieve. The core principle we follow is to selectively query for nodes or subgraphs of interest and visualize these subgraphs as a spanning tree of the graph. The tree is laid out linearly, which enables us to juxtapose the nodes with a table visualization where diverse attributes can be shown. We also use this table as an adjacency matrix, so that the resulting technique is a hybrid node-link/adjacency matrix technique. We implement this concept in Juniper and complement it with a set of interaction techniques that enable analysts to dynamically grow, restructure, and aggregate the tree, as well as change the layout or show paths between nodes. We demonstrate the utility of our tool in usage scenarios for different multivariate networks: a bipartite network of scholars, papers, and citation metrics and a multitype network of story characters, places, books, etc.","keywords":"Multivariate graphs,networks,tree-based graph visualization,adjacency matrix,spanning trees,visualization","caption":"Fig. 1. Juniper visualizing a co-author network starting at the TreePlus paper as a spanning tree. The graph is extended for Catherine Plaisant to include all her papers and co-authors. The papers are shown in aggregate form and faceted by CHI and TVCG. Most of the tree use a conventional layout, but the descendants of Catherine Plaisant\u2019s node are shown in level layout, which groups nodes by distance to the branch root. Nodes in this branch are aggregated, with the exception of prolific authors, which are revealed using a degree-of-interest function. Ben Shneiderman is highlighted; two hidden edges originate at his node. The edge-count table shows a summary of the connectivity of each node. The adjacency matrix shows explicit connections to selected, highly connected nodes. The attribute table shows attributes about the authors and papers for individual as well as aggregated rows.","img_size":{"width":1953,"height":1100},"subfigures":[{"x":11.44705247585867,"y":11.708651963797026,"width":1928.8850559862938,"height":1082.6895341451766,"type":"interface","id":"interface-0"}],"visualizations":[{"x":1106.3892988929888,"y":150.18450184501845,"width":170.47970479704804,"height":48.70848708487085,"type":"bar_chart","id":"bar_chart-0"},{"x":1298.2842323651453,"y":76.07192254495162,"width":138.4508990318118,"height":152.1438450899032,"type":"bar_chart","id":"bar_chart-1"},{"x":1436.735131396957,"y":77.59336099585065,"width":136.9294605809132,"height":156.70816044260027,"type":"bar_chart","id":"bar_chart-2"},{"x":1579.750345781466,"y":80.63623789764871,"width":132.3651452282161,"height":144.53665283540803,"type":"bar_chart","id":"bar_chart-3"},{"x":1719.7226832641775,"y":76.07192254495162,"width":153.6652835408022,"height":150.62240663900417,"type":"bar_chart","id":"bar_chart-4"},{"x":1307.7668048195067,"y":259.17747503859,"width":584.2973345418618,"height":722.7083889598741,"type":"stripe_graph","id":"stripe_graph-5"},{"x":14.507380073800846,"y":255.71955719557198,"width":877.5527859013031,"height":801.6801661792555,"type":"tree","id":"tree-6"},{"x":937.7649960322672,"y":17.54987496188111,"width":957.6536194680882,"height":1069.347689429337,"type":"table","id":"table-7"}],"relations":[{"vislist":[{"id":"group-2","relation":null,"vislist":["tree-6",{"vislist":[{"vislist":["bar_chart-1","bar_chart-2","bar_chart-3","bar_chart-4","bar_chart-0","stripe_graph-5"],"relation":null,"id":"group-0"},{"id":"group-1","relation":null,"vislist":["table-7"]}],"relation":"nested","id":"relation-0"}]}],"relation":"stacked","id":"relation-1"}]},"3008_0":{"comp":[["matrix","graph",["nested"]],["bar_chart","comb",["large_view"]]],"visType":["matrix","graph","bar_chart","comb"],"compType":["nested","large_view"],"compressed_tree":[{"composite_pattern":"large_view","visualization_type":[["bar_chart"],[{"composite_pattern":"nested","visualization_type":[["matrix"],["graph"]]}]]}],"coOccurrence":[["matrix","graph",["coOccurrence"]],["matrix","bar_chart",["coOccurrence"]],["graph","bar_chart",["coOccurrence"]]],"year":2018,"conference":["InfoVis"],"authors":["Timothy Major","Rahul C. Basole"],"title":"Graphicle: Exploring Units, Networks, and Context in a Blended Visualization Approach","doi":"10.1109/TVCG.2018.2865151","abstract":"Many real-world datasets are large, multivariate, and relational in nature and relevant associated decisions frequently require a simultaneous consideration of both attributes and connections. Existing visualization systems and approaches, however, often make an explicit trade-off between either affording rich exploration of individual data units and their attributes or exploration of the underlying network structure. In doing so, important analysis opportunities and insights are potentially missed. In this study, we aim to address this gap by (1) considering visualizations and interaction techniques that blend the spectrum between unit and network visualizations, (2) discussing the nature of different forms of contexts and the challenges in implementing them, and (3) demonstrating the value of our approach for visual exploration of multivariate, relational data for a real-world use case. Specifically, we demonstrate through a system called Graphicle how network structure can be layered on top of unit visualization techniques to create new opportunities for visual exploration of physician characteristics and referral data. We report on the design, implementation, and evaluation of the system and effectiveness of our blended approach.","keywords":"Unit visualization,network visualization,context","caption":"Fig. 1. The interface for Graphicle. Units are drawn as circles on the main canvas (a). On the left, coordinated filters (b) are available. Scented widgets are used to show distributions for the data attributes and are updated as units are removed from the canvas. Controls for navigating between views, undo/redo/clear, and modifying the current view are shown in a toolbar (c). The grid view is shown. A searchbar (d) is available to find specific units. On the right, context bars (e) show information about filtered context. Units are arranged into a force-clustered layout that groups units by attribute and positions those groups as a network. One cluster has been expanded from a grid into a clustered network. The full network of a unit is selected and filtered structural context is shown in the context bar.","img_size":{"width":2151,"height":1123},"subfigures":[{"x":90.07521675852146,"y":28.34308079123501,"width":1938.5789081439093,"height":1079.7632197419434,"type":"interface","id":"interface-0"}],"visualizations":[{"x":1741.9532710280375,"y":171.42367601246107,"width":241.39252336448632,"height":125.94392523364486,"type":"bar_chart","id":"bar_chart-0"},{"x":561.3764654587897,"y":115.28056129087079,"width":1421.7399261915116,"height":976.9201586614662,"type":"graph","id":"graph-1"},{"x":1430.5919003115266,"y":279.87538940809964,"width":153.93146417445473,"height":146.9345794392523,"type":"matrix","id":"matrix-2"},{"x":1035.2679127725858,"y":167.92523364485982,"width":171.4236760124611,"height":160.9283489096573,"type":"matrix","id":"matrix-3"},{"x":765.8878504672898,"y":426.8099688473519,"width":251.88785046728978,"height":262.3831775700935,"type":"matrix","id":"matrix-4"},{"x":954.8037383177572,"y":776.6542056074767,"width":251.88785046728978,"height":237.89408099688464,"type":"matrix","id":"matrix-5"}],"relations":[{"vislist":[{"vislist":["bar_chart-0"],"relation":null,"id":"group-2"},{"vislist":[{"vislist":[{"vislist":["matrix-5","matrix-4","matrix-3","matrix-2"],"relation":null,"id":"group-0"},{"vislist":["graph-1"],"relation":null,"id":"group-0"}],"relation":"nested","id":"relation-0"}],"relation":null,"id":"group-3"}],"relation":"large_view","id":"relation-2"}]},"3016_0":{"comp":[["bar_chart","graph",["nested"]],["heatmap","matrix",["coordinated"]],["comb","tree",["stacked"]],["tree","comb",["stacked"]],["tree","parallel_coordinate",["stacked"]],["parallel_coordinate","tree",["stacked"]]],"visType":["bar_chart","graph","heatmap","matrix","comb","tree","parallel_coordinate"],"compType":["nested","coordinated","stacked"],"compressed_tree":[{"composite_pattern":"stacked","visualization_type":[[{"composite_pattern":"coordinated","visualization_type":[["heatmap"],["matrix"]]},"tree"]]},{"composite_pattern":"stacked","visualization_type":[[{"composite_pattern":"coordinated","visualization_type":[["heatmap"],["matrix"]]},"tree"]]},{"composite_pattern":"stacked","visualization_type":[["tree","parallel_coordinate"]]},{"composite_pattern":"stacked","visualization_type":[["tree","parallel_coordinate"]]},{"composite_pattern":"nested","visualization_type":[["bar_chart"],["graph"]]}],"coOccurrence":[["heatmap","matrix",["coOccurrence"]],["heatmap","tree",["coOccurrence"]],["heatmap","parallel_coordinate",["coOccurrence"]],["heatmap","bar_chart",["coOccurrence"]],["heatmap","graph",["coOccurrence"]],["matrix","tree",["coOccurrence"]],["matrix","parallel_coordinate",["coOccurrence"]],["matrix","bar_chart",["coOccurrence"]],["matrix","graph",["coOccurrence"]],["tree","parallel_coordinate",["coOccurrence"]],["tree","bar_chart",["coOccurrence"]],["tree","graph",["coOccurrence"]],["parallel_coordinate","bar_chart",["coOccurrence"]],["parallel_coordinate","graph",["coOccurrence"]],["bar_chart","graph",["coOccurrence"]]],"year":2018,"conference":["InfoVis"],"authors":["Shusen Liu","Zhimin Li","Tao Li","Vivek Srikumar","Valerio Pascucci","Peer-Timo Bremer"],"title":"NLIZE: A Perturbation-Driven Visual Interrogation Tool for Analyzing and Interpreting Natural Language Inference Models","doi":"10.1109/TVCG.2018.2865230","abstract":"With the recent advances in deep learning, neural network models have obtained state-of-the-art performances for many linguistic tasks in natural language processing. However, this rapid progress also brings enormous challenges. The opaque nature of a neural network model leads to hard-to-debug-systems and difficult-to-interpret mechanisms. Here, we introduce a visualization system that, through a tight yet flexible integration between visualization elements and the underlying model, allows a user to interrogate the model by perturbing the input, internal state, and prediction while observing changes in other parts of the pipeline. We use the natural language inference problem as an example to illustrate how a perturbation-driven paradigm can help domain experts assess the potential limitation of a model, probe its inner states, and interpret and form hypotheses about fundamental model mechanisms such as attention.","keywords":"Natural Language Processing,Interpretable Machine Learning,Natural Language Inference,Attention Visualization","caption":"Fig. 1. The interface of the proposed system. During exploration, we can filter through a large number of sentence pairs summarized in (a). the current selected pair is displayed in (b). The model internal information (attention) is displayed in (d) and (e). The predicted probability (one of three labels: neural, entailment, contradiction) is shown in the barycentric coordinate in (f). Finally, the high-level model structure and the updates to the model are summarized in (c).","img_size":{"width":2148,"height":1013},"subfigures":[{"x":92.69883300854858,"y":16.140159340588056,"width":1957.2313922416795,"height":988.7752336690331,"type":"interface","id":"interface-0"}],"visualizations":[{"x":101.78696925329444,"y":336.6778916544656,"width":339.6442166910688,"height":163.14787701317715,"type":"bar_chart","id":"bar_chart-0"},{"x":1439.5995607613472,"y":197.2606149341142,"width":158.69838945827223,"height":212.09224011713033,"type":"bar_chart","id":"bar_chart-1"},{"x":1420.3184480234263,"y":53.39385065885799,"width":130.51830161054158,"height":118.65300146412882,"type":"bar_chart","id":"bar_chart-2"},{"x":1644.2759882869693,"y":195.77745241581258,"width":157.21522693997076,"height":210.60907759882872,"type":"bar_chart","id":"bar_chart-3"},{"x":1851.918740849195,"y":194.294289897511,"width":160.18155197657416,"height":218.02489019033678,"type":"bar_chart","id":"bar_chart-4"},{"x":919.6314044466952,"y":668.3261077010357,"width":473.7808750236339,"height":329.6629613189849,"type":"heatmap","id":"heatmap-5"},{"x":920.9715473459364,"y":668.6045673898523,"width":470.954009710069,"height":332.368521812528,"type":"matrix","id":"matrix-6"},{"x":101.78696925329447,"y":687.1582644928776,"width":642.2093704245973,"height":209.39294399859176,"type":"parallel_coordinate","id":"parallel_coordinate-7"},{"x":432.5322108345536,"y":94.92240117130308,"width":317.39677891654463,"height":407.86969253294285,"type":"scatterplot","id":"scatterplot-8"},{"x":109.20278184480247,"y":96.40556368960468,"width":321.84626647144955,"height":232.85651537335286,"type":"treemap","id":"treemap-9"},{"x":1440.3613750326576,"y":190.47004895152185,"width":577.5898447753524,"height":219.3561983932514,"type":"graph","id":"graph-10"},{"x":150.914143948641,"y":897.1806210196669,"width":529.3401491285132,"height":63.621044595128076,"type":"tree","id":"tree-11"},{"x":157.34938184027305,"y":618.7366660891479,"width":483.87483267757193,"height":70.78109616308925,"type":"tree","id":"tree-12"},{"x":921.2261640628193,"y":566.7396338227902,"width":421.25935624461744,"height":101.36936359435587,"type":"tree","id":"tree-13"},{"x":797.2932126233666,"y":668.3507472396284,"width":121.5319359065277,"height":299.4321609152688,"type":"tree","id":"tree-14"}],"relations":[{"vislist":[{"id":"group-6","relation":null,"vislist":[{"vislist":[{"id":"group-4","relation":null,"vislist":["heatmap-5"]},{"id":"group-5","relation":null,"vislist":["matrix-6"]}],"relation":"coordinated","id":"relation-0"},"tree-13"]}],"relation":"stacked","id":"relation-1"},{"vislist":[{"id":"group-9","relation":null,"vislist":[{"vislist":[{"id":"group-7","relation":null,"vislist":["heatmap-5"]},{"id":"group-8","relation":null,"vislist":["matrix-6"]}],"relation":"coordinated","id":"relation-0"},"tree-14"]}],"relation":"stacked","id":"relation-2"},{"vislist":[{"id":"group-10","relation":null,"vislist":["tree-12","parallel_coordinate-7"]}],"relation":"stacked","id":"relation-3"},{"vislist":[{"id":"group-11","relation":null,"vislist":["tree-11","parallel_coordinate-7"]}],"relation":"stacked","id":"relation-4"},{"vislist":[{"vislist":["bar_chart-1","bar_chart-3","bar_chart-4"],"relation":null,"id":"group-2"},{"id":"group-12","relation":null,"vislist":["graph-10"]}],"relation":"nested","id":"relation-5"}]},"3018_6":{"comp":[["scatterplot","bar_chart",["nested"]],["comb","donut_chart",["nested"]],["comb","sankey_diagram",["nested"]]],"visType":["scatterplot","bar_chart","comb","donut_chart","sankey_diagram"],"compType":["nested"],"compressed_tree":[{"composite_pattern":"nested","visualization_type":[[{"composite_pattern":"nested","visualization_type":[[{"composite_pattern":"nested","visualization_type":[[{"composite_pattern":"nested","visualization_type":[["scatterplot"],["bar_chart"]]}],["donut_chart"]]}],["sankey_diagram"]]}],["donut_chart"]]},{"composite_pattern":"nested","visualization_type":[[{"composite_pattern":"nested","visualization_type":[[{"composite_pattern":"nested","visualization_type":[[{"composite_pattern":"nested","visualization_type":[["scatterplot"],["bar_chart"]]}],["donut_chart"]]}],["sankey_diagram"]]}],["donut_chart"]]}],"coOccurrence":[["scatterplot","bar_chart",["coOccurrence"]],["scatterplot","donut_chart",["coOccurrence"]],["scatterplot","sankey_diagram",["coOccurrence"]],["bar_chart","donut_chart",["coOccurrence"]],["bar_chart","sankey_diagram",["coOccurrence"]],["donut_chart","sankey_diagram",["coOccurrence"]]],"year":2018,"conference":["InfoVis"],"authors":["Qianwen Wang","Zhen Li","Siwei Fu","Weiwei Cui","Huamin Qu"],"title":"Narvis: Authoring Narrative Slideshows for Introducing Data Visualization Designs","doi":"10.1109/TVCG.2018.2865232","abstract":"Visual designs can be complex in modern data visualization systems, which poses special challenges for explaining them to the non-experts. However, few if any presentation tools are tailored for this purpose. In this study, we present Narvis, a slideshow authoring tool designed for introducing data visualizations to non-experts. Narvis targets two types of end users: teachers, experts in data visualization who produce tutorials for explaining a data visualization, and students, non-experts who try to understand visualization designs through tutorials. We present an analysis of requirements through close discussions with the two types of end users. The resulting considerations guide the design and implementation of Narvis. Additionally, to help teachers better organize their introduction slideshows, we specify a data visualization as a hierarchical combination of components, which are automatically detected and extracted by Narvis. The teachers craft an introduction slideshow through first organizing these components, and then explaining them sequentially. A series of templates are provided for adding annotations and animations to improve efficiency during the authoring process. We evaluate Narvis through a qualitative analysis of the authoring experience, and a preliminary evaluation of the generated slideshows.","keywords":"Education,Narrative Visualization,Authoring Tools","caption":"Fig. 6. Annotated screenshot of the interface of Narvis: a) Source Panelwhere Narvis process the input data, b) Units Panel where teachersdefine the relationships between units and obtain a narrative sequence,c) Channels Panel where teachers add annotations and animated transi-tions for the explanation of each unit, d) floating annotation window thatoffers options for adding annotations, e) Editing Panel where teachersmodify the added animations and annotations.","img_size":{"width":1081,"height":642},"subfigures":[{"x":16.206800909251918,"y":14.220371811973331,"width":1046.4553988961297,"height":601.4743109096656,"type":"interface","id":"interface-0"}],"visualizations":[{"x":687.838519472009,"y":203.98319862494625,"width":155.57224638769495,"height":135.44035702163688,"type":"bar_chart","id":"bar_chart-0"},{"x":191.97521958559471,"y":179.66828162465012,"width":94.23136045522033,"height":83.7787282471077,"type":"bar_chart","id":"bar_chart-1"},{"x":124.2357666962614,"y":117.16798991859567,"width":212.92871479874307,"height":217.3078907234693,"type":"donut_chart","id":"donut_chart-12"},{"x":574.1531258720627,"y":100.04785719738373,"width":361.0792720229739,"height":350.8287236752027,"type":"donut_chart","id":"donut_chart-14"},{"x":168.0445113492961,"y":161.53021084928685,"width":129.3407883502083,"height":130.46829568177847,"type":"donut_chart","id":"donut_chart-2"},{"x":647.514192187084,"y":164.77962406652148,"width":222.19260179398174,"height":221.52194320119048,"type":"donut_chart","id":"donut_chart-3"},{"x":137.73619646037773,"y":129.2466569902783,"width":180.18322181003137,"height":190.68905490631707,"type":"sankey_diagram","id":"sankey_diagram-11"},{"x":602.623414750423,"y":118.61292092099946,"width":309.8833277267292,"height":309.5960934383299,"type":"sankey_diagram","id":"sankey_diagram-13"},{"x":194.3730541116644,"y":187.51780991447245,"width":70.5753211764869,"height":57.15934154231576,"type":"scatterplot","id":"scatterplot-10"},{"x":698.0564777558952,"y":207.35105364698052,"width":117.78312064399059,"height":99.86765729058631,"type":"scatterplot","id":"scatterplot-9"}],"relations":[{"vislist":[{"vislist":[{"vislist":[{"vislist":[{"vislist":[{"vislist":[{"vislist":[{"vislist":["scatterplot-10"],"relation":null,"id":"group-0"},{"vislist":["bar_chart-1"],"relation":null,"id":"group-1"}],"relation":"nested","id":"relation-0"}],"relation":null,"id":"group-2"},{"vislist":["donut_chart-2"],"relation":null,"id":"group-3"}],"relation":"nested","id":"relation-1"}],"relation":null,"id":"group-4"},{"vislist":["sankey_diagram-11"],"relation":null,"id":"group-5"}],"relation":"nested","id":"relation-2"}],"relation":null,"id":"group-6"},{"vislist":["donut_chart-12"],"relation":null,"id":"group-7"}],"relation":"nested","id":"relation-3"},{"vislist":[{"vislist":[{"vislist":[{"vislist":[{"vislist":[{"vislist":[{"vislist":[{"vislist":["scatterplot-9"],"relation":null,"id":"group-8"},{"vislist":["bar_chart-0"],"relation":null,"id":"group-9"}],"relation":"nested","id":"relation-4"}],"relation":null,"id":"group-10"},{"vislist":["donut_chart-3"],"relation":null,"id":"group-11"}],"relation":"nested","id":"relation-5"}],"relation":null,"id":"group-12"},{"vislist":["sankey_diagram-13"],"relation":null,"id":"group-13"}],"relation":"nested","id":"relation-6"}],"relation":null,"id":"group-14"},{"vislist":["donut_chart-14"],"relation":null,"id":"group-15"}],"relation":"nested","id":"relation-7"}]},"3063_0":{"comp":[["scatterplot","flow_diagram",["nested"]],["scatterplot","heatmap",["coordinated"]],["surface_graph","flow_diagram",["nested"]],["surface_graph","heatmap",["coordinated"]],["vector_graph","flow_diagram",["nested"]],["heatmap","flow_diagram",["nested"]]],"visType":["scatterplot","flow_diagram","heatmap","surface_graph","vector_graph"],"compType":["nested","coordinated"],"compressed_tree":[{"composite_pattern":"nested","visualization_type":[["scatterplot","surface_graph","heatmap_matrix","vector_graph","heatmap"],["flow_diagram"]]},{"composite_pattern":"coordinated","visualization_type":[["scatterplot","surface_graph"],["heatmap_matrix","heatmap"]]}],"coOccurrence":[["scatterplot","surface_graph",["coOccurrence"]],["scatterplot","vector_graph",["coOccurrence"]],["scatterplot","heatmap",["coOccurrence"]],["surface_graph","vector_graph",["coOccurrence"]],["surface_graph","heatmap",["coOccurrence"]],["vector_graph","heatmap",["coOccurrence"]]],"year":2018,"conference":["VAST"],"authors":["Minsuk Kahng","Nikhil Thorat","Duen Horng Chau","Fernanda B. Vi\xe9gas","Martin Wattenberg"],"title":"GAN Lab: Understanding Complex Deep Generative Models using Interactive Visual Experimentation","doi":"10.1109/TVCG.2018.2864500","abstract":"Recent success in deep learning has generated immense interest among practitioners and students, inspiring many to learn about this new technology. While visual and interactive approaches have been successfully developed to help people more easily learn deep learning, most existing tools focus on simpler models. In this work, we present GAN Lab, the first interactive visualization tool designed for non-experts to learn and experiment with Generative Adversarial Networks (GANs), a popular class of complex deep learning models. With GAN Lab, users can interactively train generative models and visualize the dynamic training process\'s intermediate results. GAN Lab tightly integrates an model overview graph that summarizes GAN\'s structure, and a layered distributions view that helps users interpret the interplay between submodels. GAN Lab introduces new interactive experimentation features for learning complex deep learning models, such as step-by-step training at multiple levels of abstraction for understanding intricate training dynamics. Implemented using TensorFlow.js, GAN Lab is accessible to anyone via modern web browsers, without the need for installation or specialized hardware, overcoming a major practical challenge in deploying interactive tools for deep learning.","keywords":"Deep learning,information visualization,visual analytics,generative adversarial networks,machine learning,interactive experimentation,explorable explanations","caption":"Fig. 1. With GAN Lab, users can interactively train Generative Adversarial Networks (GANs), and visually examine the model training process. In this example, a user has successfully used GAN Lab to train a GAN that generates 2D data points whose challenging distribution resembles a ring. A. The model overview graph summarizes a GAN model\u2019s structure as a graph, with nodes representing the generator and discriminator submodels, and the data that flow through the graph (e.g., fake samples produced by the generator). B. The layered distributions view helps users interpret the interplay between submodels through user-selected layers, such as the discriminator\u2019s classification heatmap, real samples, and fake samples produced by the generator.","img_size":{"width":1989,"height":1048},"subfigures":[{"x":17.805001055684897,"y":14.941485267553908,"width":1939.7132248024673,"height":1028.069698509963,"type":"interface","id":"interface-0"}],"visualizations":[{"x":19.957943925233735,"y":156.7102803738318,"width":1305.9190031152648,"height":861.9065420560748,"type":"flow_diagram","id":"flow_diagram-0"},{"x":1389.8681364115253,"y":248.52472426545617,"width":550.857809119285,"height":537.3597733711041,"type":"heatmap","id":"heatmap-11"},{"x":698.5312053495362,"y":435.94126992994376,"width":261.4436591036577,"height":254.64195581734572,"type":"heatmap","id":"heatmap-8"},{"x":1517.2671377670365,"y":396.19909618593266,"width":312.4044757127386,"height":266.21475168803426,"type":"scatterplot","id":"scatterplot-1"},{"x":52.60591900311534,"y":581.1339563862928,"width":104.47352024922121,"height":130.5919003115265,"type":"scatterplot","id":"scatterplot-2"},{"x":539.0607476635514,"y":440.74766355140196,"width":94.67912772585669,"height":91.41433021806861,"type":"scatterplot","id":"scatterplot-3"},{"x":545.590342679128,"y":594.1931464174456,"width":81.61993769470405,"height":97.9439252336448,"type":"scatterplot","id":"scatterplot-4"},{"x":1032.0451713395637,"y":444.0124610591901,"width":84.88473520249227,"height":84.88473520249221,"type":"scatterplot","id":"scatterplot-5"},{"x":1032.0451713395637,"y":600.722741433022,"width":84.88473520249227,"height":81.61993769470405,"type":"scatterplot","id":"scatterplot-6"},{"x":1498.0564330729214,"y":387.86786869740564,"width":337.4994252046907,"height":273.7743490605198,"type":"surface_graph","id":"surface_graph-10"},{"x":214.22472052669085,"y":434.43014942016583,"width":261.21140871900076,"height":254.64402392623876,"type":"surface_graph","id":"surface_graph-7"},{"x":535.264785189194,"y":875.8562170467035,"width":100.53568000097489,"height":102.67373305356855,"type":"vector_graph","id":"vector_graph-9"}],"relations":[{"vislist":[{"vislist":["scatterplot-2","surface_graph-7","scatterplot-3","scatterplot-4","heatmap_matrix-8","scatterplot-5","scatterplot-6","vector_graph-9","heatmap-8"],"relation":null,"id":"group-3"},{"vislist":["flow_diagram-0"],"relation":null,"id":"group-1"}],"relation":"nested","id":"relation-0"},{"vislist":[{"vislist":["scatterplot-1","surface_graph-10"],"relation":null,"id":"group-1"},{"vislist":["heatmap_matrix-11","heatmap-11"],"relation":null,"id":"group-4"}],"relation":"coordinated","id":"relation-1"}]},"3064_0":{"comp":[["graph","bar_chart",["nested"]],["comb","map",["coordinated"]]],"visType":["graph","bar_chart","comb","map"],"compType":["nested","coordinated"],"compressed_tree":[{"composite_pattern":"coordinated","visualization_type":[[{"composite_pattern":"nested","visualization_type":[["graph"],["bar_chart"]]}],["map"]]}],"coOccurrence":[["graph","bar_chart",["coOccurrence"]],["graph","map",["coOccurrence"]],["bar_chart","map",["coOccurrence"]]],"year":2018,"conference":["VAST"],"authors":["Zhiguang Zhou","Linhao Meng","Cheng Tang","Ying Zha","Zhiyong Guo","Miaoxin Hu","Wei Chen"],"title":"Visual Abstraction of Large Scale Geospatial Origin-Destination Movement Data","doi":"10.1109/TVCG.2018.2864503","abstract":"A variety of human movement datasets are represented in an Origin-Destination(OD) form, such as taxi trips, mobile phone locations, etc. As a commonly-used method to visualize OD data, flow map always fails to discover patterns of human mobility, due to massive intersections and occlusions of lines on a 2D geographical map. A large number of techniques have been proposed to reduce visual clutter of flow maps, such as filtering, clustering and edge bundling, but the correlations of OD flows are often neglected, which makes the simplified OD flow map present little semantic information. In this paper, a characterization of OD flows is established based on an analogy between OD flows and natural language processing (NPL) terms. Then, an iterative multi-objective sampling scheme is designed to select OD flows in a vectorized representation space. To enhance the readability of sampled OD flows, a set of meaningful visual encodings are designed to present the interactions of OD flows. We design and implement a visual exploration system that supports visual inspection and quantitative evaluation from a variety of perspectives. Case studies based on real-world datasets and interviews with domain experts have demonstrated the effectiveness of our system in reducing the visual clutter and enhancing correlations of OD flows.","keywords":"Visual abstraction,human mobility,origin-destination,flow map,representation learning","caption":"Fig. 1. The visualization interface for a mobile phone location dataset. (a) A control view. (b) A map view supporting the presentation of OD flows and an interactive definition of flow wheels to focus on local areas of interest. (c) A word embedding view to characterize interactions of OD flows, in which each point corresponds to an OD flow. (d) A matrix view showing continuous trajectory segments, and allowing users to interactively highlight flows of interest. (e-g) present intermediate information in the course of sampling, guiding users to achieve a desired visual abstraction of large scale OD movements.","img_size":{"width":1774,"height":970},"subfigures":[{"x":12.61665793164181,"y":9.900880731244632,"width":1752.0935174638596,"height":952.4178942671545,"type":"interface","id":"interface-0"}],"visualizations":[{"x":15.714813048462513,"y":775.206741067076,"width":310.6131015712623,"height":176.53550377071733,"type":"bar_chart","id":"bar_chart-0"},{"x":551.6706774878897,"y":183.01684887074845,"width":449.91812909098803,"height":450.3829689251697,"type":"bar_chart","id":"bar_chart-9"},{"x":619.4735452451885,"y":340.6250577838352,"width":317.004351087771,"height":186.36099554344065,"type":"graph","id":"graph-8"},{"x":345.89310207460267,"y":776.1797389119962,"width":913.3611284269083,"height":176.58315149586892,"type":"heatmap","id":"heatmap-3"},{"x":34.7091394035397,"y":598.6712372963584,"width":119.55252470548582,"height":129.6083445405267,"type":"heatmap_matrix","id":"heatmap_matrix-4"},{"x":185.5464369291527,"y":598.6712372963584,"width":113.96595813046315,"height":128.49103122552222,"type":"heatmap_matrix","id":"heatmap_matrix-5"},{"x":323.45130544852134,"y":43.99105725840421,"width":951.5027422529673,"height":705.4058657531812,"type":"map","id":"map-2"},{"x":344.58566978193153,"y":776.6043613707167,"width":914.6685607195794,"height":180.21791183015705,"type":"matrix","id":"matrix-6"},{"x":1278.323987538941,"y":556.0124610591902,"width":495.5763239875391,"height":410.96573208722737,"type":"polar_plot","id":"polar_plot-7"}],"relations":[{"vislist":[{"vislist":[{"vislist":[{"vislist":["graph-8"],"relation":null,"id":"group-2"},{"vislist":["bar_chart-9"],"relation":null,"id":"group-3"}],"relation":"nested","id":"relation-1"}],"relation":null,"id":"group-7"},{"vislist":["map-2"],"relation":null,"id":"group-8"}],"relation":"coordinated","id":"relation-3"}]},"3067_4":{"comp":[["tree","line_chart",["nested"]]],"visType":["tree","line_chart"],"compType":["nested"],"compressed_tree":[{"composite_pattern":"nested","visualization_type":[["tree"],["line_chart"]]}],"coOccurrence":[["tree","line_chart",["coOccurrence"]]],"year":2018,"conference":["VAST"],"authors":["Mennatallah El-Assady","Fabian Sperrle","Oliver Deussen","Daniel A. Keim","Christopher Collins"],"title":"Visual Analytics for Topic Model Optimization based on User-Steerable Speculative Execution","doi":"10.1109/TVCG.2018.2864769","abstract":"To effectively assess the potential consequences of human interventions in model-driven analytics systems, we establish the concept of speculative execution as a visual analytics paradigm for creating user-steerable preview mechanisms. This paper presents an explainable, mixed-initiative topic modeling framework that integrates speculative execution into the algorithmic decision-making process. Our approach visualizes the model-space of our novel incremental hierarchical topic modeling algorithm, unveiling its inner-workings. We support the active incorporation of the user\'s domain knowledge in every step through explicit model manipulation interactions. In addition, users can initialize the model with expected topic seeds, the backbone priors. For a more targeted optimization, the modeling process automatically triggers a speculative execution of various optimization strategies, and requests feedback whenever the measured model quality deteriorates. Users compare the proposed optimizations to the current model state and preview their effect on the next model iterations, before applying one of them. This supervised human-in-the-Ioop process targets maximum improvement for minimum feedback and has proven to be effective in three independent studies that confirm topic model quality improvements.","keywords":"User-Steerable Topic Modeling,Speculative Execution,Mixed-Initiative Visual Analytics,Explainable Machine Learning","caption":"Fig. 3: The visual analytics workspace. New documents are added to the document-log on the right-hand side before they are shown in the topic-tree, the central component of our workspace. It shows both the model space and the algorithms decision making process, as well as topic hierarchies, keywords and uncertainties. The model quality timeline tracks the metric development over time and forecasts the effects of speculative executions (see Sect. 5). A control panel on the left hand side ranks optimizations based on their effectiveness for the current model and enables steering the speculative execution: Optimizations can be viewed , accepted and rejected . The control panel on top allows pausing the modeling process , setting its speed , and manually triggering a speculative execution . A color map shows which document group the nodes in the tree belong to. Unclustered nodes that have not yet been added to the model are listed and can be added via drag and drop.","img_size":{"width":2160,"height":1056},"subfigures":[{"x":7.284687224576816,"y":7.959517026180347,"width":2142.7301520496694,"height":1041.4316680925324,"type":"interface","id":"interface-0"}],"visualizations":[{"x":51.63224893917969,"y":939.4964639321073,"width":1242.7043847241866,"height":71.6944837340876,"type":"bar_chart","id":"bar_chart-0"},{"x":26.240452616690316,"y":767.7284299858555,"width":1747.5530410183871,"height":171.76803394625173,"type":"line_chart","id":"line_chart-1"},{"x":651.5961245630272,"y":29.801955197439504,"width":763.3388369511085,"height":732.3334433629595,"type":"line_chart","id":"line_chart-3"},{"x":840.3229379620208,"y":185.9221260900116,"width":407.18919827144873,"height":411.40655091215075,"type":"tree","id":"tree-2"}],"relations":[{"vislist":[{"vislist":["tree-2"],"relation":null,"id":"group-0"},{"vislist":["line_chart-3"],"relation":null,"id":"group-1"}],"relation":"nested","id":"relation-0"}]},"3069_0":{"comp":[["area_chart","sankey_diagram",["nested"]],["bar_chart","sankey_diagram",["nested"]],["bar_chart","comb",["stacked"]],["comb","bar_chart",["stacked"]]],"visType":["area_chart","sankey_diagram","bar_chart","comb"],"compType":["nested","stacked"],"compressed_tree":[{"composite_pattern":"stacked","visualization_type":[[{"composite_pattern":"nested","visualization_type":[["area_chart","bar_chart"],["sankey_diagram"]]},"bar_chart"]]}],"coOccurrence":[["area_chart","bar_chart",["coOccurrence"]],["area_chart","sankey_diagram",["coOccurrence"]],["bar_chart","sankey_diagram",["coOccurrence"]]],"year":2018,"conference":["VAST"],"authors":["Yao Ming","Huamin Qu","Enrico Bertini"],"title":"RuleMatrix: Visualizing and Understanding Classifiers with Rules","doi":"10.1109/TVCG.2018.2864812","abstract":"With the growing adoption of machine learning techniques, there is a surge of research interest towards making machine learning systems more transparent and interpretable. Various visualizations have been developed to help model developers understand, diagnose, and refine machine learning models. However, a large number of potential but neglected users are the domain experts with little knowledge of machine learning but are expected to work with machine learning systems. In this paper, we present an interactive visualization technique to help users with little expertise in machine learning to understand, explore and validate predictive models. By viewing the model as a black box, we extract a standardized rule-based knowledge representation from its input-output behavior. Then, we design RuleMatrix, a matrix-based visualization of rules to help users navigate and verify the rules and the black-box model. We evaluate the effectiveness of RuleMatrix via two use cases and a usability study.","keywords":"explainable machine learning,rule visualization,visual analytics","caption":"Fig. 1. Understanding the behavior of a trained neural network using the explanatory visual interface of RuleMatrix. The user uses the control panel (A) to specify the detail information to visualize (e.g., dataset, level of detail, rule filters). The rule-based representation is visualized as a matrix (B), where each row represents a rule, and each column is a feature used in the rules. The user can also filter the data or use a customized input in the data filter (C) and navigate the filtered dataset in the data table (D).","img_size":{"width":1928,"height":1028},"subfigures":[{"x":8.857810098412264,"y":16.324067293371524,"width":1893.4114212976815,"height":1006.204186993078,"type":"interface","id":"interface-0"}],"visualizations":[{"x":611.3974540311174,"y":231.19094766619523,"width":130.86280056577084,"height":43.62093352192363,"type":"area_chart","id":"area_chart-0"},{"x":746.6223479490806,"y":226.8288543140028,"width":126.50070721357858,"height":53.7991513437058,"type":"area_chart","id":"area_chart-1"},{"x":1123.2164073550211,"y":174.48373408769444,"width":348.967468175389,"height":676.124469589816,"type":"bar_chart","id":"bar_chart-2"},{"x":620.121640735502,"y":798.2630834512022,"width":69.79349363507788,"height":26.17256011315419,"type":"bar_chart","id":"bar_chart-3"},{"x":918.1980198019802,"y":795.3550212164074,"width":52.345120226308374,"height":27.62659123055164,"type":"bar_chart","id":"bar_chart-4"},{"x":1008.3479490806224,"y":750.2800565770863,"width":52.34512022630849,"height":24.71852899575674,"type":"bar_chart","id":"bar_chart-5"},{"x":1012.7100424328145,"y":667.4002828854315,"width":49.43705799151337,"height":27.626591230551526,"type":"bar_chart","id":"bar_chart-6"},{"x":745.168316831683,"y":747.3719943422914,"width":127.95473833097606,"height":27.62659123055164,"type":"bar_chart","id":"bar_chart-7"},{"x":615.7595473833097,"y":697.9349363507778,"width":63.977369165487964,"height":29.080622347949088,"type":"bar_chart","id":"bar_chart-8"},{"x":877.4851485148514,"y":697.9349363507778,"width":42.166902404526354,"height":27.62659123055164,"type":"bar_chart","id":"bar_chart-9"},{"x":746.6223479490806,"y":663.038189533239,"width":127.95473833097593,"height":31.988684582743986,"type":"bar_chart","id":"bar_chart-10"},{"x":743.7142857142856,"y":616.5091937765205,"width":132.31683168316837,"height":31.988684582743986,"type":"bar_chart","id":"bar_chart-11"},{"x":743.7142857142856,"y":565.6181046676096,"width":133.77086280056574,"height":30.534653465346537,"type":"bar_chart","id":"bar_chart-12"},{"x":973.4512022630834,"y":572.8882602545968,"width":45.074964639321024,"height":23.264497878359293,"type":"bar_chart","id":"bar_chart-13"},{"x":878.939179632249,"y":514.7270155586988,"width":91.60396039603961,"height":33.442715700141434,"type":"bar_chart","id":"bar_chart-14"},{"x":1069.4172560113152,"y":417.3069306930693,"width":45.07496463932148,"height":31.988684582743986,"type":"bar_chart","id":"bar_chart-15"},{"x":608.4893917963225,"y":468.19801980198025,"width":68.33946251768032,"height":30.534653465346537,"type":"bar_chart","id":"bar_chart-16"},{"x":743.7142857142856,"y":420.2149929278643,"width":129.4087694483735,"height":29.080622347949088,"type":"bar_chart","id":"bar_chart-17"},{"x":922.5601131541727,"y":367.8698727015559,"width":47.98302687411592,"height":29.080622347949088,"type":"bar_chart","id":"bar_chart-18"},{"x":926.9222065063648,"y":302.4384724186705,"width":45.074964639321024,"height":33.442715700141434,"type":"bar_chart","id":"bar_chart-19"},{"x":612.8514851485148,"y":334.42715700141446,"width":69.79349363507777,"height":36.350777934936325,"type":"bar_chart","id":"bar_chart-20"},{"x":745.168316831683,"y":303.8925035360679,"width":130.86280056577095,"height":29.080622347949035,"type":"bar_chart","id":"bar_chart-21"},{"x":967.6350777934937,"y":191.93210749646394,"width":53.79915134370572,"height":31.988684582743986,"type":"bar_chart","id":"bar_chart-22"},{"x":873.1230551626592,"y":337.33521923620935,"width":50.89108910891082,"height":27.62659123055164,"type":"bar_chart","id":"bar_chart-23"},{"x":745.168316831683,"y":194.84016973125884,"width":133.77086280056585,"height":33.442715700141434,"type":"bar_chart","id":"bar_chart-24"},{"x":404.92503536067886,"y":911.6775106082038,"width":1480.203677510608,"height":111.96039603960399,"type":"table","id":"table-25"},{"x":409.267433200451,"y":29.504277333165945,"width":710.114602491359,"height":821.0883114305337,"type":"sankey_diagram","id":"sankey_diagram-26"}],"relations":[{"vislist":[{"id":"group-2","relation":null,"vislist":[{"vislist":[{"vislist":["area_chart-0","area_chart-1","bar_chart-3","bar_chart-4","bar_chart-5","bar_chart-6","bar_chart-7","bar_chart-8","bar_chart-9","bar_chart-10","bar_chart-11","bar_chart-12","bar_chart-13","bar_chart-14","bar_chart-15","bar_chart-16","bar_chart-17","bar_chart-18","bar_chart-19","bar_chart-20","bar_chart-21","bar_chart-22","bar_chart-23","bar_chart-24"],"relation":null,"id":"group-0"},{"id":"group-1","relation":null,"vislist":["sankey_diagram-26"]}],"relation":"nested","id":"relation-0"},"bar_chart-2"]}],"relation":"stacked","id":"relation-1"}]},"3071_4":{"comp":[["glyph_based","matrix",["nested"]]],"visType":["glyph_based","matrix"],"compType":["nested"],"compressed_tree":[{"composite_pattern":"nested","visualization_type":[["glyph_based"],["matrix"]]}],"coOccurrence":[["glyph_based","matrix",["coOccurrence"]]],"year":2018,"conference":["VAST"],"authors":["Ke Xu","Meng Xia","Xing Mu","Yun Wang","Nan Cao"],"title":"EnsembleLens: Ensemble-based Visual Exploration of Anomaly Detection Algorithms with Multidimensional Data","doi":"10.1109/TVCG.2018.2864825","abstract":"The results of anomaly detection are sensitive to the choice of detection algorithms as they are specialized for different properties of data, especially for multidimensional data. Thus, it is vital to select the algorithm appropriately. To systematically select the algorithms, ensemble analysis techniques have been developed to support the assembly and comparison of heterogeneous algorithms. However, challenges remain due to the absence of the ground truth, interpretation, or evaluation of these anomaly detectors. In this paper, we present a visual analytics system named EnsembleLens that evaluates anomaly detection algorithms based on the ensemble analysis process. The system visualizes the ensemble processes and results by a set of novel visual designs and multiple coordinated contextual views to meet the requirements of correlation analysis, assessment and reasoning of anomaly detection algorithms. We also introduce an interactive analysis workflow that dynamically produces contextualized and interpretable data summaries that allow further refinements of exploration results based on user feedback. We demonstrate the effectiveness of EnsembleLens through a quantitative evaluation, three case studies with real-world data and interviews with two domain experts.","keywords":"Algorithm Evaluation,Ensemble Analysis,Anomaly Detection,Visual Analysis,Multidimensional Data","caption":"Fig. 5. Visual encoding of the correlation matrix view. (1) The glyph in thematrix is composed of two halves, with each representing an ensemblecomponent in a row or column. The top 20 detected anomaly data pointsfor each component are encoded around the semicircular arc. (2) A lineis drawn to link the same point in both components. (3) The backgroundcolor of the inner circle indicates the correlation of the two paired compo-nents. (4) The background color of ensemble component indicated theevaluated weight. (5) The bars perpendicular to the circular arc representthe top 20 detected outliers of the corresponding component, whosecolor and length are determined by the change of the rank comparedwith the opposite component.","img_size":{"width":1057,"height":644},"subfigures":[{"x":8.267668191562812,"y":7.276320205234615,"width":625.6565146990238,"height":633.7259219206762,"type":"single","id":"single-0"}],"visualizations":[{"x":334.2403027016349,"y":57.63712434465954,"width":100.17386018970156,"height":183.73746434142706,"type":"bar_chart","id":"bar_chart-0"},{"x":677.0065885797949,"y":432.79062957540265,"width":330.95754026354325,"height":145.20644216691068,"type":"bar_chart","id":"bar_chart-2"},{"x":444.9132776594073,"y":56.336295031498324,"width":100.17344468118512,"height":186.32740993700347,"type":"bar_chart","id":"bar_chart-5"},{"x":14.74042662614808,"y":20.963488744579497,"width":611.8676094124182,"height":615.8211923497871,"type":"glyph_based","id":"glyph_based-1"},{"x":16.0096827209978,"y":22.305883999269188,"width":609.9806345580048,"height":616.3882320014616,"type":"matrix","id":"matrix-6"}],"relations":[{"vislist":[{"vislist":["glyph_based-1"],"relation":null,"id":"group-1"},{"vislist":["matrix-6"],"relation":null,"id":"group-2"}],"relation":"nested","id":"relation-1"}]},"3074_0":{"comp":[["comb","donut_chart",["nested"]],["graph","scatterplot",["coordinated"]],["matrix","scatterplot",["large_view"]],["matrix","comb",["large_view"]]],"visType":["comb","donut_chart","graph","scatterplot","matrix"],"compType":["nested","coordinated","large_view"],"compressed_tree":[{"composite_pattern":"large_view","visualization_type":[["matrix"],["scatterplot"]]},{"composite_pattern":"coordinated","visualization_type":[["graph"],["scatterplot"]]},{"composite_pattern":"large_view","visualization_type":[["matrix"],[{"composite_pattern":"nested","visualization_type":[[{"composite_pattern":"coordinated","visualization_type":[["graph"],["scatterplot"]]}],["donut_chart"]]}]]}],"coOccurrence":[["matrix","scatterplot",["coOccurrence"]],["matrix","graph",["coOccurrence"]],["matrix","donut_chart",["coOccurrence"]],["scatterplot","graph",["coOccurrence"]],["scatterplot","donut_chart",["coOccurrence"]],["graph","donut_chart",["coOccurrence"]]],"year":2018,"conference":["VAST"],"authors":["Shixia Liu","Changjian Chen","Yafeng Lu","Fang-Xin Ou-Yang","Bin Wang"],"title":"An Interactive Method to Improve Crowdsourced Annotations","doi":"10.1109/TVCG.2018.2864843","abstract":"In order to effectively infer correct labels from noisy crowdsourced annotations, learning-from-crowds models have introduced expert validation. However, little research has been done on facilitating the validation procedure. In this paper, we propose an interactive method to assist experts in verifying uncertain instance labels and unreliable workers. Given the instance labels and worker reliability inferred from a learning-from-crowds model, candidate instances and workers are selected for expert validation. The influence of verified results is propagated to relevant instances and workers through the learning-from-crowds model. To facilitate the validation of annotations, we have developed a confusion visualization to indicate the confusing classes for further exploration, a constrained projection method to show the uncertain labels in context, and a scatter-plot-based visualization to illustrate worker reliability. The three visualizations are tightly integrated with the learning-from-crowds model to provide an iterative and progressive environment for data validation. Two case studies were conducted that demonstrate our approach offers an efficient method for validating and improving crowdsourced annotations.","keywords":"Crowdsourcing,learning-from-crowds,interactive visualization,focus + context","caption":"Fig. 1. LabelInspect: (a) the confusion visualization to reveal the confusion degree between different classes; (b) the instance visualization to illustrate the uncertain labels in context; (c) the worker visualization to demonstrate worker reliability; (d) the validation trail to display the number of validated and influenced instances at each validation step; (e) images.","img_size":{"width":1941,"height":1114},"subfigures":[{"x":16.154785848211525,"y":13.643223959496469,"width":1913.6210043256208,"height":1057.1090897400377,"type":"interface","id":"interface-0"}],"visualizations":[{"x":1117.6222043107716,"y":481.6526408499596,"width":209.9759677597749,"height":198.54870420822274,"type":"bar_chart","id":"bar_chart-0"},{"x":61.195461200585626,"y":70.14120775330407,"width":1001.4582723279651,"height":1004.707335591489,"type":"donut_chart","id":"donut_chart-1"},{"x":1428.693674828486,"y":473.63103561757987,"width":461.3795151834131,"height":97.46828866547104,"type":"graph","id":"graph-10"},{"x":598.2317806856812,"y":746.3392692256888,"width":293.63091922633043,"height":196.11209216040197,"type":"graph","id":"graph-13"},{"x":1154.7608108533168,"y":38.84617822730457,"width":307.1077079479703,"height":308.53611589191445,"type":"heatmap","id":"heatmap-3"},{"x":61.40108057229608,"y":67.69536863141315,"width":147.38802737670434,"height":130.13562051290367,"type":"matrix","id":"matrix-4"},{"x":1156.1892187972608,"y":38.84617822730457,"width":307.10770794797054,"height":304.2508920600823,"type":"matrix","id":"matrix-5"},{"x":1127.0930685008211,"y":692.1741646891119,"width":781.9105085149718,"height":383.6703737433714,"type":"matrix","id":"matrix-6"},{"x":128.78506991159514,"y":127.63828042133707,"width":881.8200479060433,"height":902.9381030505406,"type":"scatterplot","id":"scatterplot-12"},{"x":1121.9074281426037,"y":37.41777028336053,"width":815.408397294714,"height":419.9519355195502,"type":"scatterplot","id":"scatterplot-7"},{"x":1319.0277244068823,"y":445.9424422513584,"width":608.5017841201645,"height":241.4009425265442,"type":"scatterplot","id":"scatterplot-8"}],"relations":[{"vislist":[{"vislist":["matrix-5"],"relation":null,"id":"group-1"},{"vislist":["scatterplot-7"],"relation":null,"id":"group-2"}],"relation":"large_view","id":"relation-0"},{"vislist":[{"vislist":["graph-10"],"relation":null,"id":"group-3"},{"vislist":["scatterplot-8"],"relation":null,"id":"group-4"}],"relation":"coordinated","id":"relation-1"},{"vislist":[{"vislist":["matrix-4"],"relation":null,"id":"group-9"},{"vislist":[{"vislist":[{"vislist":[{"vislist":[{"vislist":["graph-13"],"relation":null,"id":"group-5"},{"vislist":["scatterplot-12"],"relation":null,"id":"group-6"}],"relation":"coordinated","id":"relation-2"}],"relation":null,"id":"group-7"},{"vislist":["donut_chart-1"],"relation":null,"id":"group-8"}],"relation":"nested","id":"relation-3"}],"relation":null,"id":"group-10"}],"relation":"large_view","id":"relation-4"}]},"3082_0":{"comp":[["scatterplot","matrix",["nested"]]],"visType":["scatterplot","matrix"],"compType":["nested"],"compressed_tree":[{"composite_pattern":"nested","visualization_type":[["scatterplot"],["matrix"]]}],"coOccurrence":[],"year":2018,"conference":["VAST"],"authors":["Ying Zha","Feng Luo","Minghui Chen","Yingchao Wang","Jiazhi Xia","Fangfang Zhou","Yunhai Wang","Yi Che","Wei Chen"],"title":"Evaluating Multi-Dimensional Visualizations for Understanding Fuzzy Clusters","doi":"10.1109/TVCG.2018.2865020","abstract":"Fuzzy clustering assigns a probability of membership for a datum to a cluster, which veritably reflects real-world clustering scenarios but significantly increases the complexity of understanding fuzzy clusters. Many studies have demonstrated that visualization techniques for multi-dimensional data are beneficial to understand fuzzy clusters. However, no empirical evidence exists on the effectiveness and efficiency of these visualization techniques in solving analytical tasks featured by fuzzy clusters. In this paper, we conduct a controlled experiment to evaluate the ability of fuzzy clusters analysis to use four multi-dimensional visualization techniques, namely, parallel coordinate plot, scatterplot matrix, principal component analysis, and Radviz. First, we define the analytical tasks and their representative questions specific to fuzzy clusters analysis. Then, we design objective questionnaires to compare the accuracy, time, and satisfaction in using the four techniques to solve the questions. We also design subjective questionnaires to collect the experience of the volunteers with the four techniques in terms of ease of use, informativeness, and helpfulness. With a complete experiment process and a detailed result analysis, we test against four hypotheses that are formulated on the basis of our experience, and provide instructive guidance for analysts in selecting appropriate and efficient visualization techniques to analyze fuzzy clusters.","keywords":"Evaluation,multi-dimensional visualization,fuzzy clustering,parallel coordinate plot,scatterplot matrix,principal component analysis,radviz","caption":"Figure 1. Four evaluated visualization techniques and three provided interactions: (a) PCP with range selecting interaction; (b) SPM with range selecting interaction; (c) PCA with hovering interaction; (d) Radviz with color encoding option.","img_size":{"width":2146,"height":1454},"subfigures":[{"x":12.395478259742198,"y":9.675496617695636,"width":1037.88136189721,"height":642.5303272338434,"type":"interface","id":"interface-0"},{"x":1098.897386576363,"y":12.875855203619876,"width":1028.3135096740154,"height":640.9596020103545,"type":"interface","id":"interface-1"},{"x":10.794629565917196,"y":746.8629972205273,"width":1039.47335990658,"height":644.5228649097061,"type":"interface","id":"interface-2"},{"x":1095.6877236660805,"y":740.426555094998,"width":1031.5134367380165,"height":647.7357652640457,"type":"interface","id":"interface-3"}],"visualizations":[{"x":207.23651452282158,"y":12.066390041493776,"width":848.9434340632965,"height":649.5222989045217,"type":"parallel_coordinate","id":"parallel_coordinate-0"},{"x":208.97874821775872,"y":743.8200514138819,"width":856.9825242580365,"height":653.8701283924804,"type":"scatterplot","id":"scatterplot-1"},{"x":1353.5435684647305,"y":760.1825726141077,"width":705.8838174273856,"height":619.4080221300139,"type":"scatterplot","id":"scatterplot-2"},{"x":1371.6431535269705,"y":14.077455048409403,"width":650.1271693564735,"height":645.5001688906904,"type":"matrix","id":"matrix-3"},{"x":1369.2885228566456,"y":11.806233151543186,"width":654.642984635723,"height":647.9660090332361,"type":"scatterplot","id":"scatterplot-4"}],"relations":[{"vislist":[{"id":"group-0","relation":null,"vislist":["scatterplot-4"]},{"id":"group-1","relation":null,"vislist":["matrix-3"]}],"relation":"nested","id":"relation-0"}]},"3086_5":{"comp":[["bar_chart","table",["nested"]]],"visType":["bar_chart","table"],"compType":["nested"],"compressed_tree":[{"composite_pattern":"nested","visualization_type":[["bar_chart"],["table"]]}],"coOccurrence":[["bar_chart","table",["coOccurrence"]]],"year":2018,"conference":["VAST"],"authors":["Holger Stitz","Samuel Gratzl","Harald Piringer","Thomas Zichner","Marc Streit"],"title":"KnowledgePearls: Provenance-Based Visualization Retrieval","doi":"10.1109/TVCG.2018.2865024","abstract":"Storing analytical provenance generates a knowledge base with a large potential for recalling previous results and guiding users in future analyses. However, without extensive manual creation of meta information and annotations by the users, search and retrieval of analysis states can become tedious. We present KnowledgePearls, a solution for efficient retrieval of analysis states that are structured as provenance graphs containing automatically recorded user interactions and visualizations. As a core component, we describe a visual interface for querying and exploring analysis states based on their similarity to a partial definition of a requested analysis state. Depending on the use case, this definition may be provided explicitly by the user by formulating a search query or inferred from given reference states. We explain our approach using the example of efficient retrieval of demographic analyses by Hans Rosling and discuss our implementation for a fast look-up of previous states. Our approach is independent of the underlying visualization framework. We discuss the applicability for visualizations which are based on the declarative grammar Vega and we use a Vega-based implementation of Gapminder as guiding example. We additionally present a biomedical case study to illustrate how KnowledgePearls facilitates the exploration process by recalling states from earlier analyses.","keywords":"Visualization provenance,interaction provenance,retrieval","caption":"Fig. 6. The user has entered three search terms to find similar state sequences and to recall a previously recorded analysis. The search query results in seven state sequences, with the first sequence matching all search terms. Jumping to this state shows a ranking of breast cancer cell lines with copy number information for the gene EGFR. The user continues the analysis for MDA-MB-468, the cell line with the highest copy number.","img_size":{"width":2157,"height":1037},"subfigures":[{"x":8.611732173674632,"y":12.941199070910216,"width":2135.7314513873494,"height":1011.117601858181,"type":"interface","id":"interface-0"}],"visualizations":[{"x":1676.9268774703557,"y":94.27272727272727,"width":477.51185770750976,"height":938.6284584980237,"type":"bar_chart","id":"bar_chart-0"},{"x":997.8075994516191,"y":112.90928774802303,"width":124.5541770609135,"height":924.0742966190718,"type":"bar_chart","id":"bar_chart-1"},{"x":12.808300395256936,"y":116.81620553359681,"width":174.19960474308297,"height":895.590909090909,"type":"table","id":"table-2"},{"x":416.5415019762845,"y":114.76679841897234,"width":702.9466403162056,"height":922.2332015810276,"type":"table","id":"table-3"},{"x":211.600790513834,"y":45.086956521739125,"width":209.03952569169962,"height":420.12845849802375,"type":"table","id":"table-4"},{"x":209.5513833992095,"y":467.26482213438726,"width":204.94071146245057,"height":268.4723320158103,"type":"table","id":"table-5"}],"relations":[{"vislist":[{"id":"group-0","relation":null,"vislist":["bar_chart-1"]},{"id":"group-1","relation":null,"vislist":["table-3"]}],"relation":"nested","id":"relation-0"}]},"3090_0":{"comp":[["treemap","bar_chart",["nested"]]],"visType":["treemap","bar_chart"],"compType":["nested"],"compressed_tree":[{"composite_pattern":"nested","visualization_type":[["treemap"],["bar_chart"]]}],"coOccurrence":[["treemap","bar_chart",["coOccurrence"]]],"year":2018,"conference":["VAST"],"authors":["Marco Angelini","Graziano Blasilli","Tiziana Catarci","Simone Lenti","Giuseppe Santucci"],"title":"Vulnus: Visual Vulnerability Analysis for Network Security","doi":"10.1109/TVCG.2018.2865028","abstract":"Vulnerabilities represent one of the main weaknesses of IT systems and the availability of consolidated official data, like CVE (Common Vulnerabilities and Exposures), allows for using them to compute the paths an attacker is likely to follow. However, even if patches are available, business constraints or lack of resources create obstacles to their straightforward application. As a consequence, the security manager of a network needs to deal with a large number of vulnerabilities, making decisions on how to cope with them. This paper presents VULNUS (VULNerabilities visUal aSsessment), a visual analytics solution for dynamically inspecting the vulnerabilities spread on networks, allowing for a quick understanding of the network status and visually classifying nodes according to their vulnerabilities. Moreover, VULNUS computes the approximated optimal sequence of patches able to eliminate all the attack paths and allows for exploring sub-optimal patching strategies, simulating the effect of removing one or more vulnerabilities. VULNUS has been evaluated by domain experts using a lab-test experiment, investigating the effectiveness and efficiency of the proposed solution.","keywords":"Visual Analytics,Network security,Vulnerability analysis,CVE,CVSS,Attack Graph,Vulnerability triage and management","caption":"Fig. 1: VULNUS dealing with a real network containing 122 nodes, 22 sub-networks and 846 vulnerabilities. Sub-networks are arranged horizontally, using a modified treemap bar chart representation. Each bar represents a sub-network (n1 , n2 , . . .), showing its nodes; both the node size and the bar length are proportional to the total number of vulnerabilities of the element. Bars are sorted by length and while the user is scrolling into the main pane (A), the pane (B) maintains the visual context. The leftmost part of each bar (a) contains nodes with zero vulnerabilities that are represented as squares of fixed dimension. Mouse-hovering a node (b) reveals its CVSS scores and the number of vulnerabilities. Nodes are selectable individually or by sub-network into the main pane and by uniform and statistical intervals of their scores in the selection pane (D). Selected nodes are listed in (C); their vulnerabilities are presented on a frequency plot (E) and filterable by scores (F). Further selections on the frequency plot are listed in (I), allowing for comparing vulnerability scores on a radar diagram (G) or inspecting numerical scores and accessing the CVE reference page (H). The approximated optimal fixing strategy (J) is automatically computed using the attack graph information and VULNUS allows the security manager to interactively simulate the vulnerabilities fixing in order to explore suboptimal variants of the fixing plan.","img_size":{"width":1967,"height":1066},"subfigures":[{"x":17.63658207729873,"y":13.56911406441966,"width":1928.0380640559501,"height":1042.5524369171037,"type":"interface","id":"interface-0"}],"visualizations":[{"x":653.0732087227415,"y":733.9127725856698,"width":478.20560747663524,"height":182.6479750778816,"type":"bar_chart","id":"bar_chart-0"},{"x":45.353582554517175,"y":743.8753894080996,"width":395.18380062305283,"height":66.41744548286601,"type":"bar_chart","id":"bar_chart-1"},{"x":1280.7180685358253,"y":740.5545171339563,"width":312.1619937694709,"height":312.1619937694704,"type":"polar_plot","id":"polar_plot-2"},{"x":22.16578155361889,"y":24.776086752707997,"width":1898.789832947391,"height":707.3974063265171,"type":"treemap","id":"treemap-3"},{"x":23.62198251284437,"y":29.06099045122817,"width":1891.4001927891813,"height":676.4326409462832,"type":"bar_chart","id":"bar_chart-4"}],"relations":[{"vislist":[{"id":"group-0","relation":null,"vislist":["treemap-3"]},{"id":"group-1","relation":null,"vislist":["bar_chart-4"]}],"relation":"nested","id":"relation-0"}]},"2463_0":{"comp":[["bar_chart","sankey_diagram",["stacked","nested"]],["bar_chart","table",["stacked"]],["bar_chart","matrix",["stacked"]],["bar_chart","parallel_coordinate",["stacked"]],["bar_chart","scatterplot",["stacked"]],["table","matrix",["stacked"]],["table","bar_chart",["stacked"]],["table","parallel_coordinate",["stacked"]],["table","scatterplot",["stacked"]],["table","sankey_diagram",["stacked"]],["matrix","table",["stacked"]],["matrix","bar_chart",["stacked"]],["matrix","parallel_coordinate",["stacked"]],["matrix","scatterplot",["stacked"]],["matrix","sankey_diagram",["stacked"]],["parallel_coordinate","table",["stacked"]],["parallel_coordinate","matrix",["stacked"]],["parallel_coordinate","bar_chart",["stacked"]],["parallel_coordinate","scatterplot",["stacked"]],["parallel_coordinate","sankey_diagram",["stacked"]],["scatterplot","table",["stacked"]],["scatterplot","matrix",["stacked"]],["scatterplot","bar_chart",["stacked"]],["scatterplot","parallel_coordinate",["stacked"]],["scatterplot","sankey_diagram",["stacked"]],["sankey_diagram","table",["stacked"]],["sankey_diagram","matrix",["stacked"]],["sankey_diagram","bar_chart",["stacked"]],["sankey_diagram","parallel_coordinate",["stacked"]],["sankey_diagram","scatterplot",["stacked"]]],"visType":["bar_chart","sankey_diagram","table","matrix","parallel_coordinate","scatterplot"],"compType":["stacked","nested"],"compressed_tree":[{"composite_pattern":"nested","visualization_type":[["bar_chart"],["sankey_diagram"]]},{"composite_pattern":"stacked","visualization_type":[["table","matrix","bar_chart","parallel_coordinate","scatterplot","sankey_diagram"]]}],"coOccurrence":[["bar_chart","sankey_diagram",["coOccurrence"]],["bar_chart","table",["coOccurrence"]],["bar_chart","matrix",["coOccurrence"]],["bar_chart","parallel_coordinate",["coOccurrence"]],["bar_chart","scatterplot",["coOccurrence"]],["sankey_diagram","table",["coOccurrence"]],["sankey_diagram","matrix",["coOccurrence"]],["sankey_diagram","parallel_coordinate",["coOccurrence"]],["sankey_diagram","scatterplot",["coOccurrence"]],["table","matrix",["coOccurrence"]],["table","parallel_coordinate",["coOccurrence"]],["table","scatterplot",["coOccurrence"]],["matrix","parallel_coordinate",["coOccurrence"]],["matrix","scatterplot",["coOccurrence"]],["parallel_coordinate","scatterplot",["coOccurrence"]]],"year":2014,"conference":["InfoVis"],"authors":["Samuel Gratzl","Nils Gehlenborg","Alexander Lex","Hanspeter Pfister","Marc Streit"],"title":"Domino: Extracting, Comparing, and Manipulating Subsets Across Multiple Tabular Datasets","doi":"10.1109/TVCG.2014.2346260","abstract":"Answering questions about complex issues often requires analysts to take into account information contained in multiple interconnected datasets. A common strategy in analyzing and visualizing large and heterogeneous data is dividing it into meaningful subsets. Interesting subsets can then be selected and the associated data and the relationships between the subsets visualized. However, neither the extraction and manipulation nor the comparison of subsets is well supported by state-of-the-art techniques. In this paper we present Domino, a novel multiform visualization technique for effectively representing subsets and the relationships between them. By providing comprehensive tools to arrange, combine, and extract subsets, Domino allows users to create both common visualization techniques and advanced visualizations tailored to specific use cases. In addition to the novel technique, we present an implementation that enables analysts to manage the wide range of options that our approach offers. Innovative interactive features such as placeholders and live previews support rapid creation of complex analysis setups. We introduce the technique and the implementation using a simple example and demonstrate scalability and effectiveness in a use case from the field of cancer genomics.","keywords":"Multiple coordinated views, visual linking, relationships, heterogeneous data, categorical data","caption":"Fig. 1: Domino showing relationships between subsets of a music charts dataset. The visualization illustrates that Whitney Houston is a female, inactive artist who has had many number-one hits in English speaking countries but produced fewer than 10 studio albums. The schematic illustration in the top-right corner shows the setup using a graphical notation.","img_size":{"width":1983,"height":723},"subfigures":[{"x":5.27865574241466,"y":4.245563646210516,"width":1968.1217647367037,"height":713.068720807634,"type":"interface","id":"interface-0"}],"visualizations":[{"x":326.89608723540726,"y":42.592914918327985,"width":288.7370109044258,"height":340.0226169388427,"type":"heatmap","id":"heatmap-0"},{"x":326.8960872354074,"y":43.410755586939494,"width":288.7370109044259,"height":337.9082994857758,"type":"matrix","id":"matrix-1"},{"x":619.0597400554316,"y":11.100485220601387,"width":528.7994222515905,"height":369.54620094667695,"type":"parallel_coordinate","id":"parallel_coordinate-2"},{"x":1531.4509300833868,"y":16.160359204618373,"width":429.92559332905694,"height":340.8877485567672,"type":"parallel_coordinate","id":"parallel_coordinate-3"},{"x":1148.5881975625396,"y":381.2155227710071,"width":581.2899294419498,"height":331.9839640795381,"type":"sankey_diagram","id":"sankey_diagram-4"},{"x":1144.2078849259306,"y":14.188696629091076,"width":302.12002164383955,"height":275.62655631525445,"type":"scatterplot","id":"scatterplot-5"},{"x":2.688936309234411,"y":39.31171764148443,"width":325.1221273815311,"height":343.2724484942687,"type":"table","id":"table-6"},{"x":1148.9448865868576,"y":295.6780825610505,"width":288.4038776199317,"height":84.37749105223246,"type":"parallel_coordinate","id":"parallel_coordinate-7"},{"x":323.9871411532939,"y":381.876268990638,"width":553.3669875346823,"height":193.82857582017724,"type":"bar_chart","id":"bar_chart-8"},{"x":317.3376049545241,"y":577.4334942359453,"width":561.4200281861866,"height":111.5270835976156,"type":"parallel_coordinate","id":"parallel_coordinate-9"},{"x":1606.7935616477025,"y":606.6195979966159,"width":96.65890845062383,"height":105.84191780821902,"type":"bar_chart","id":"bar_chart-10"}],"relations":[{"vislist":[{"vislist":["bar_chart-10"],"relation":null,"id":"group-0"},{"vislist":["sankey_diagram-4"],"relation":null,"id":"group-1"}],"relation":"nested","id":"relation-0"},{"vislist":[{"vislist":["table-6","matrix-1","bar_chart-8","parallel_coordinate-9","parallel_coordinate-2","scatterplot-5","parallel_coordinate-7","sankey_diagram-4"],"relation":null,"id":"group-2"}],"relation":"stacked","id":"relation-1"}]},"2539_10":{"comp":[["glyph_based","scatterplot",["nested"]]],"visType":["glyph_based","scatterplot"],"compType":["nested"],"compressed_tree":[{"composite_pattern":"nested","visualization_type":[["glyph_based"],["scatterplot"]]}],"coOccurrence":[["glyph_based","scatterplot",["coOccurrence"]]],"year":2014,"conference":["VAST"],"authors":["Josua Krause","Adam Perer","Enrico Bertini"],"title":"INFUSE: Interactive Feature Selection for Predictive Modeling of High Dimensional Data","doi":"10.1109/TVCG.2014.2346482","abstract":"Predictive modeling techniques are increasingly being used by data scientists to understand the probability of predicted outcomes. However, for data that is high-dimensional, a critical step in predictive modeling is determining which features should be included in the models. Feature selection algorithms are often used to remove non-informative features from models. However, there are many different classes of feature selection algorithms. Deciding which one to use is problematic as the algorithmic output is often not amenable to user interpretation. This limits the ability for users to utilize their domain expertise during the modeling process. To improve on this limitation, we developed INFUSE, a novel visual analytics system designed to help analysts understand how predictive features are being ranked across feature selection algorithms, cross-validation folds, and classifiers. We demonstrate how our system can lead to important insights in a case study involving clinical researchers predicting patient outcomes from electronic medical records.","keywords":"Predictive modeling, feature selection, classification, visual analytics, high-dimensional data","caption":"Fig. 10. The scatterplot view allows users to compare multiple types of rankings. In the case study, users became curious of the medication features that were chosen by only half of the models. When reviewing these medications with domain experts, it became clear that features picked by the upper-half algorithms were as clinically signi\ufb01cant as those picked by the bottom-half. This indicates that merging results from feature selection algorithms makes sense for this predictive model.","img_size":{"width":2145,"height":868},"subfigures":[{"x":27.195029168908757,"y":8.938969044182967,"width":970.4273392145966,"height":848.5646806330711,"type":"single","id":"single-0"}],"visualizations":[{"x":111.44644002565748,"y":23.29923027581784,"width":839.2880051314947,"height":835.1603592046184,"type":"glyph_based","id":"glyph_based-0"},{"x":1214.903784477229,"y":125.11449647209749,"width":814.5221295702376,"height":690.6927517639514,"type":"glyph_based","id":"glyph_based-1"},{"x":1214.903784477229,"y":125.11449647209749,"width":810.3944836433614,"height":689.316869788326,"type":"scatterplot","id":"scatterplot-2"},{"x":112.82232200128288,"y":23.29923027581784,"width":836.536241180244,"height":833.7844772289931,"type":"scatterplot","id":"scatterplot-3"}],"relations":[{"vislist":[{"vislist":["glyph_based-0"],"relation":null,"id":"group-0"},{"vislist":["scatterplot-3"],"relation":null,"id":"group-1"}],"relation":"nested","id":"relation-0"}]},"2541_0":{"comp":[["glyph_based","graph",["nested"]]],"visType":["glyph_based","graph"],"compType":["nested"],"compressed_tree":[{"composite_pattern":"nested","visualization_type":[["glyph_based"],["graph"]]}],"coOccurrence":[["glyph_based","graph",["coOccurrence"]]],"year":2014,"conference":["VAST"],"authors":["Narges Mahyar","Melanie Tory"],"title":"Supporting Communication and Coordination in Collaborative Sensemaking","doi":"10.1109/TVCG.2014.2346573","abstract":"When people work together to analyze a data set, they need to organize their findings, hypotheses, and evidence, share that information with their collaborators, and coordinate activities amongst team members. Sharing externalizations (recorded information such as notes) could increase awareness and assist with team communication and coordination. However, we currently know little about how to provide tool support for this sort of sharing. We explore how linked common work (LCW) can be employed within a `collaborative thinking space\', to facilitate synchronous collaborative sensemaking activities in Visual Analytics (VA). Collaborative thinking spaces provide an environment for analysts to record, organize, share and connect externalizations. Our tool, CLIP, extends earlier thinking spaces by integrating LCW features that reveal relationships between collaborators\' findings. We conducted a user study comparing CLIP to a baseline version without LCW. Results demonstrated that LCW significantly improved analytic outcomes at a collaborative intelligence task. Groups using CLIP were also able to more effectively coordinate their work, and held more discussion of their findings and hypotheses. LCW enabled them to maintain awareness of each other\'s activities and findings and link those findings to their own work, preventing disruptive oral awareness notifications.","keywords":"Sensemaking, Collaboration, Externalization, Linked common work, Collaborative thinking space","caption":"Fig. 1: Screenshot of CLIP. A) Graph pane, to create a network diagram of people, locations, and events, B) Timeline, to see the timeline of events, C) List of notes, easy review of all notes in one location, D) Tabs, to see collaborators\u2019 views, E) Merge option, to choose a collaborator\u2019s work to be merged with your own, F) Evidence cloud, to see the list of evidence and their frequencies, G, H) Filtering and sorting options.","img_size":{"width":1601,"height":973},"subfigures":[{"x":18.26066133936277,"y":15.773623070660447,"width":1554.8462439253349,"height":941.4527538586784,"type":"interface","id":"interface-0"}],"visualizations":[{"x":409.44802342606147,"y":115.39238653001463,"width":747.913616398243,"height":839.0878477306005,"type":"glyph_based","id":"glyph_based-0"},{"x":406.59882869692535,"y":116.81698389458273,"width":747.9136163982431,"height":834.814055636896,"type":"graph","id":"graph-1"}],"relations":[{"vislist":[{"vislist":["glyph_based-0"],"relation":null,"id":"group-0"},{"vislist":["graph-1"],"relation":null,"id":"group-1"}],"relation":"nested","id":"relation-0"}]},"2545_2":{"comp":[["others","bar_chart",["nested"]],["others","comb",["nested"]],["scivis","bar_chart",["nested"]],["bar_chart","proportional_area_chart",["coordinated"]]],"visType":["others","bar_chart","comb","scivis","proportional_area_chart"],"compType":["nested","coordinated"],"compressed_tree":[{"composite_pattern":"nested","visualization_type":[["others","scivis"],["bar_chart"]]},{"composite_pattern":"nested","visualization_type":[["others"],[{"composite_pattern":"coordinated","visualization_type":[["bar_chart"],["proportional_area_chart"]]}]]}],"coOccurrence":[["bar_chart","proportional_area_chart",["coOccurrence"]],["bar_chart","others",["coOccurrence"]],["proportional_area_chart","others",["coOccurrence"]]],"year":2014,"conference":["VAST"],"authors":["Paul Klemm","Steffen Oeltze-Jafra","Kai Lawonn","Katrin Hegenscheid","Henry V\xf6lzke","Bernhard Preim"],"title":"Interactive Visual Analysis of Image-Centric Cohort Study Data","doi":"10.1109/TVCG.2014.2346591","abstract":"Epidemiological population studies impose information about a set of subjects (a cohort) to characterize disease-specific risk factors. Cohort studies comprise heterogenous variables describing the medical condition as well as demographic and lifestyle factors and, more recently, medical image data. We propose an Interactive Visual Analysis (IVA) approach that enables epidemiologists to rapidly investigate the entire data pool for hypothesis validation and generation. We incorporate image data, which involves shape-based object detection and the derivation of attributes describing the object shape. The concurrent investigation of image-based and non-image data is realized in a web-based multiple coordinated view system, comprising standard views from information visualization and epidemiological data representations such as pivot tables. The views are equipped with brushing facilities and augmented by 3D shape renderings of the segmented objects, e.g., each bar in a histogram is overlaid with a mean shape of the associated subgroup of the cohort. We integrate an overview visualization, clustering of variables and object shape for data-driven subgroup definition and statistical key figures for measuring the association between variables. We demonstrate the IVA approach by validating and generating hypotheses related to lower back pain as part of a qualitative evaluation.","keywords":"Interactive Visual Analysis, Epidemiology, Spine","caption":"Fig. 3.  (Left) Screenshot from the front-end, which is divided as follows: (a) The sidebar containing all variables as well as the groups defined in the analysis process; (b) the canvas area where variables can be added via drag and drop and the visualization is chosen automatically according to the data type; (c) the interactive pivot table showing the exact numbers for each displayed variable combination; (d) buttons to open panes containing the contingency matrix, contingency pane and pivot table. The data displayed is used to analyze the lumbar spine. Variables can beadded freely on the canvas via drag and drop. Dropping thegenderparameter on the already plottedbody sizecontainer creates a mosaic plot combining both variables (right). In a prior step, the user selected all subjects with diagnosed thyroid disorder. These subjects are shown as shade in the visualizations, denoting their share. Subjects between 153.5-170 cm body size are more affected by thyroid disorder (box plot) and are mostly female (mosaic plot). Distance to the mean mesh of subjects with thyroid disorder is encoded as red for x axis, blue y axis and green z axis.","img_size":{"width":2136,"height":720},"subfigures":[{"x":15.254852885718051,"y":16.103858828646878,"width":968.2876536399737,"height":690.8941613645666,"type":"interface","id":"interface-0"},{"x":1507.6903992337943,"y":23.69782106366076,"width":613.1007025504496,"height":674.1552973836092,"type":"interface","id":"interface-1"}],"visualizations":[{"x":306.6447908121411,"y":105.92288761279738,"width":622.0508613617719,"height":234.80229696472523,"type":"bar_chart","id":"bar_chart-0"},{"x":1521.9503211341228,"y":72.29624486933967,"width":580.1416857740818,"height":307.76353120372914,"type":"bar_chart","id":"bar_chart-10"},{"x":14.018047579983593,"y":25.31911402789173,"width":2116.7251845775227,"height":685.1320754716982,"type":"flow_diagram","id":"flow_diagram-2"},{"x":300.88313141460344,"y":102.7596812374721,"width":629.5983824911389,"height":237.61090050775982,"type":"scivis","id":"scivis-8"},{"x":1524.619879840102,"y":71.8961036147365,"width":575.1780517794391,"height":302.9004985760748,"type":"scivis","id":"scivis-9"},{"x":1520.031592623841,"y":72.23804254691983,"width":585.8627406782408,"height":307.87993584856804,"type":"proportional_area_chart","id":"proportional_area_chart-11"},{"x":513.4109926168992,"y":458.1263330598852,"width":462.5955701394585,"height":199.7571780147661,"type":"table","id":"table-5"},{"x":1706.6972928630028,"y":501.93273174733383,"width":401.2666119770304,"height":164.7120590648072,"type":"table","id":"table-6"}],"relations":[{"vislist":[{"vislist":["others-8","scivis-8"],"relation":null,"id":"group-6"},{"vislist":["bar_chart-0"],"relation":null,"id":"group-1"}],"relation":"nested","id":"relation-0"},{"vislist":[{"vislist":["others-9"],"relation":null,"id":"group-4"},{"vislist":[{"vislist":[{"vislist":["bar_chart-10"],"relation":null,"id":"group-2"},{"vislist":["proportional_area_chart-11"],"relation":null,"id":"group-3"}],"relation":"coordinated","id":"relation-1"}],"relation":null,"id":"group-5"}],"relation":"nested","id":"relation-2"}]},"2547_0":{"comp":[["scivis","matrix",["nested"]],["scivis","tree",["nested"]],["scivis","proportional_area_chart",["nested"]],["comb","parallel_coordinate",["nested"]]],"visType":["scivis","matrix","tree","proportional_area_chart","comb","parallel_coordinate"],"compType":["nested"],"compressed_tree":[{"composite_pattern":"nested","visualization_type":[["scivis"],["matrix"]]},{"composite_pattern":"nested","visualization_type":[["scivis"],["tree"]]},{"composite_pattern":"nested","visualization_type":[[{"composite_pattern":"nested","visualization_type":[["scivis"],["proportional_area_chart"]]}],["parallel_coordinate"]]}],"coOccurrence":[["scivis","tree",["coOccurrence"]]],"year":2014,"conference":["VAST"],"authors":["Michael Beham","Wolfgang Herzner","M. Eduard Gr\xf6ller","Johannes Kehrer"],"title":"Cupid: Cluster-Based Exploration of Geometry Generators with Parallel Coordinates and Radial Trees","doi":"10.1109/TVCG.2014.2346626","abstract":"Geometry generators are commonly used in video games and evaluation systems for computer vision to create geometric shapes such as terrains, vegetation or airplanes. The parameters of the generator are often sampled automatically which can lead to many similar or unwanted geometric shapes. In this paper, we propose a novel visual exploration approach that combines the abstract parameter space of the geometry generator with the resulting 3D shapes in a composite visualization. Similar geometric shapes are first grouped using hierarchical clustering and then nested within an illustrative parallel coordinates visualization. This helps the user to study the sensitivity of the generator with respect to its parameter space and to identify invalid parameter settings. Starting from a compact overview representation, the user can iteratively drill-down into local shape differences by clicking on the respective clusters. Additionally, a linked radial tree gives an overview of the cluster hierarchy and enables the user to manually split or merge clusters. We evaluate our approach by exploring the parameter space of a cup generator and provide feedback from domain experts.","keywords":"Composite visualization, hierarchical clustering, illustrative parallel coordinates, radial trees, 3D shape analysis","caption":"Fig. 1. Overview ofCupid: (a) Composite parallel coordinates relate the parameter space of a cup generator and clusters of similar 3D cups. (b) Linked radial tree depicting the hierarchy of the clusters. (c) Members of a cluster can be compared in a detail window.","img_size":{"width":1867,"height":822},"subfigures":[{"x":58.52343223945154,"y":12.067267666761467,"width":967.510031021464,"height":784.3106790046046,"type":"single","id":"single-0"},{"x":1058.2467451889968,"y":10.813047267299119,"width":800.0922338554855,"height":797.6629483330261,"type":"single","id":"single-1"}],"visualizations":[{"x":55.8733528671176,"y":8.681302835900361,"width":976.5134353592391,"height":784.9093943281995,"type":"scivis","id":"scivis-4"},{"x":73.73036233080775,"y":410.79451662313966,"width":456.76237939482013,"height":344.0069667537214,"type":"matrix","id":"matrix-3"},{"x":57.943631039531475,"y":7.221083455344069,"width":974.8462664714493,"height":791.9121522693996,"type":"parallel_coordinate","id":"parallel_coordinate-1"},{"x":61.554172767203525,"y":9.628111273792097,"width":968.8286969253294,"height":788.3016105417275,"type":"proportional_area_chart","id":"proportional_area_chart-0"},{"x":1070.736550690486,"y":29.900785836831528,"width":764.3955053209681,"height":763.8424283263365,"type":"scivis","id":"scivis-5"},{"x":68.85323702122498,"y":406.8528119255909,"width":468.1630144937068,"height":351.8903761488188,"type":"scivis","id":"scivis-6"},{"x":1068.8953147877012,"y":30.087847730600295,"width":777.4699853587117,"height":769.0453879941433,"type":"tree","id":"tree-2"}],"relations":[{"vislist":[{"vislist":["scivis-6"],"relation":null,"id":"group-14"},{"vislist":["matrix-3"],"relation":null,"id":"group-15"}],"relation":"nested","id":"relation-4"},{"vislist":[{"vislist":["scivis-5"],"relation":null,"id":"group-16"},{"vislist":["tree-2"],"relation":null,"id":"group-17"}],"relation":"nested","id":"relation-5"},{"vislist":[{"vislist":[{"vislist":[{"vislist":["scivis-4"],"relation":null,"id":"group-18"},{"vislist":["proportional_area_chart-0"],"relation":null,"id":"group-19"}],"relation":"nested","id":"relation-6"}],"relation":null,"id":"group-20"},{"vislist":["parallel_coordinate-1"],"relation":null,"id":"group-21"}],"relation":"nested","id":"relation-7"}]},"2561_0":{"comp":[["glyph_based","tree",["nested"]]],"visType":["glyph_based","tree"],"compType":["nested"],"compressed_tree":[{"composite_pattern":"nested","visualization_type":[["glyph_based"],["tree"]]}],"coOccurrence":[["glyph_based","tree",["coOccurrence"]]],"year":2014,"conference":["VAST"],"authors":["Wei Zeng","Chi-Wing Fu","Stefan M\xfcller Arisona","Alexander Erath","Huamin Qu"],"title":"Visualizing Mobility of Public Transportation System","doi":"10.1109/TVCG.2014.2346893","abstract":"Public transportation systems (PTSs) play an important role in modern cities, providing shared/massive transportation services that are essential for the general public. However, due to their increasing complexity, designing effective methods to visualize and explore PTS is highly challenging. Most existing techniques employ network visualization methods and focus on showing the network topology across stops while ignoring various mobility-related factors such as riding time, transfer time, waiting time, and round-the-clock patterns. This work aims to visualize and explore passenger mobility in a PTS with a family of analytical tasks based on inputs from transportation researchers. After exploring different design alternatives, we come up with an integrated solution with three visualization modules: isochrone map view for geographical information, isotime flow map view for effective temporal information comparison and manipulation, and OD-pair journey view for detailed visual analysis of mobility factors along routes between specific origin-destination pairs. The isotime flow map linearizes a flow map into a parallel isoline representation, maximizing the visualization of mobility information along the horizontal time axis while presenting clear and smooth pathways from origin to destinations. Moreover, we devise several interactive visual query methods for users to easily explore the dynamics of PTS mobility over space and time. Lastly, we also construct a PTS mobility model from millions of real passenger trajectories, and evaluate our visualization techniques with assorted case studies with the transportation researchers.","keywords":"Mobility, public transportation, visual analytics","caption":"Fig. 1. Left: the isotime \ufb02ow map view overviews time-ef\ufb01cient routes from a source location in a parallel isotime fashion. Right: the OD-pair journey view enables us to explore temporal variations of mobility-related factors for speci\ufb01c time-ef\ufb01cient routes.","img_size":{"width":1980,"height":547},"subfigures":[{"x":3.882018929352078,"y":6.5596307937256775,"width":997.1845388489497,"height":531.0075479426981,"type":"single","id":"single-0"},{"x":1006.1709419870245,"y":12.221676131604852,"width":968.5958602906596,"height":523.9932429717143,"type":"single","id":"single-1"}],"visualizations":[{"x":1054.2095526894739,"y":21.59194710838334,"width":881.0477923147274,"height":484.62186448683593,"type":"glyph_based","id":"glyph_based-2"},{"x":49.40736119775421,"y":4.847473487211488,"width":952.3268870867124,"height":516.3069245165315,"type":"tree","id":"tree-0"},{"x":1042.6266416510316,"y":37.60881801125706,"width":923.7863340195858,"height":495.8974202919245,"type":"tree","id":"tree-1"}],"relations":[{"vislist":[{"vislist":["glyph_based-2"],"relation":null,"id":"group-0"},{"vislist":["tree-1"],"relation":null,"id":"group-1"}],"relation":"nested","id":"relation-0"}]},"2565_6":{"comp":[["matrix","matrix",["nested"]]],"visType":["matrix"],"compType":["nested"],"compressed_tree":[{"composite_pattern":"nested","visualization_type":[["matrix"],["matrix"]]}],"coOccurrence":[["matrix","matrix",["coOccurrence"]]],"year":2014,"conference":["VAST"],"authors":["Cong Xie","Wei Che","Xinxin Huang","Yueqi Hu","Scott Barlowe","Jing Yang"],"title":"VAET: A Visual Analytics Approach for E-Transactions Time-Series","doi":"10.1109/TVCG.2014.2346913","abstract":"Previous studies on E-transaction time-series have mainly focused on finding temporal trends of transaction behavior. Interesting transactions that are time-stamped and situation-relevant may easily be obscured in a large amount of information. This paper proposes a visual analytics system, Visual Analysis of E-transaction Time-Series (VAET), that allows the analysts to interactively explore large transaction datasets for insights about time-varying transactions. With a set of analyst-determined training samples, VAET automatically estimates the saliency of each transaction in a large time-series using a probabilistic decision tree learner. It provides an effective time-of-saliency (TOS) map where the analysts can explore a large number of transactions at different time granularities. Interesting transactions are further encoded with KnotLines, a compact visual representation that captures both the temporal variations and the contextual connection of transactions. The analysts can thus explore, select, and investigate knotlines of interest. A case study and user study with a real E-transactions dataset (26 million records) demonstrate the effectiveness of VAET.","keywords":"Time-Series, Visual Analytics, E-transaction","caption":"Fig. 7. (a) The visual layout of the three-level organization. (b) The compact layout derived from (a).","img_size":{"width":1033,"height":1164},"subfigures":[{"x":20.24381777848123,"y":3.9855969279045453,"width":1008.4208581850489,"height":582.0702254486487,"type":"single","id":"single-0"}],"visualizations":[{"x":13.895475892395844,"y":7.125476852903426,"width":1009.9815963378112,"height":577.3803785645649,"type":"matrix","id":"matrix-4"},{"x":95.84653465346527,"y":637.1541725601131,"width":834.7213578500711,"height":469.2220650636493,"type":"scatterplot","id":"scatterplot-0"},{"x":13.526874115982991,"y":8.231966053748232,"width":1015.4980418745097,"height":579.5304101838756,"type":"scatterplot","id":"scatterplot-1"},{"x":15.173267326732569,"y":4.9391796322489405,"width":1013.85164866376,"height":584.4695898161245,"type":"matrix","id":"matrix-2"},{"x":94.20014144271568,"y":637.1541725601131,"width":826.4893917963227,"height":467.5756718528996,"type":"small_multiple","id":"small_multiple-3"}],"relations":[{"vislist":[{"vislist":["matrix-2"],"relation":null,"id":"group-0"},{"vislist":["matrix-4"],"relation":null,"id":"group-1"}],"relation":"nested","id":"relation-0"}]},"2587_0":{"comp":[["others","graph",["nested"]]],"visType":["others","graph"],"compType":["nested"],"compressed_tree":[{"composite_pattern":"nested","visualization_type":[["others"],["graph"]]}],"coOccurrence":[["others","graph",["coOccurrence"]]],"year":2014,"conference":["VAST"],"authors":["Lauren Bradel","Chris North","Leanna House","Scotland Leman"],"title":"Multi-Model Semantic Interaction for Text Analytics","doi":"10.1109/VAST.2014.7042492","abstract":"Semantic interaction offers an intuitive communication mechanism between human users and complex statistical models. By shielding the users from manipulating model parameters, they focus instead on directly manipulating the spatialization, thus remaining in their cognitive zone. However, this technique is not inherently scalable past hundreds of text documents. To remedy this, we present the concept of multi-model semantic interaction, where semantic interactions can be used to steer multiple models at multiple levels of data scale, enabling users to tackle larger data problems. We also present an updated visualization pipeline model for generalized multi-model semantic interaction. To demonstrate multi-model semantic interaction, we introduce StarSPIRE, a visual text analytics prototype that transforms user interactions on documents into both small-scale display layout updates as well as large-scale relevancy-based document selection.","keywords":"Visual analytics, Semantic Interaction, Sensemaking, Text Analytics","caption":"Fig. 1. StarSPIRE spatial workspace showing clusters of open documents and numerous iconified documents selected and arranged through semantic interaction.","img_size":{"width":1597,"height":947},"subfigures":[{"x":30.83168747714636,"y":43.01627885331843,"width":1527.5719975755053,"height":889.4246989358769,"type":"interface","id":"interface-0"}],"visualizations":[{"x":19.963396778916547,"y":36.04978038067349,"width":1545.9809663250367,"height":907.427154143136,"type":"graph","id":"graph-0"},{"x":15.286839243190922,"y":46.86981002205342,"width":1545.3019828892784,"height":896.9463918606543,"type":"others","id":"others-1"}],"relations":[{"vislist":[{"vislist":["others-1"],"relation":null,"id":"group-0"},{"vislist":["graph-0"],"relation":null,"id":"group-1"}],"relation":"nested","id":"relation-0"}]},"2584_8":{"comp":[["map","heatmap",["nested"]],["comb","scatterplot",["nested"]]],"visType":["map","heatmap","comb","scatterplot"],"compType":["nested"],"compressed_tree":[{"composite_pattern":"nested","visualization_type":[[{"composite_pattern":"nested","visualization_type":[["map"],["heatmap"]]}],["scatterplot"]]}],"coOccurrence":[["map","heatmap",["coOccurrence"]],["map","scatterplot",["coOccurrence"]],["heatmap","scatterplot",["coOccurrence"]]],"year":2014,"conference":["VAST"],"authors":["Jie Li","Kang Zhang","Zhao-Peng Meng"],"title":"Vismate: Interactive Visual Analysis of Station-Based Observation Data on Climate Changes","doi":"10.1109/VAST.2014.7042489","abstract":"We present a new approach to visualizing the climate data of multi-dimensional, time-series, and geo-related characteristics. Our approach integrates three new highly interrelated visualization techniques, and uses the same input data types as in the traditional model-based analysis methods. As the main visualization view, Global Radial Map is used to identify the overall state of climate changes and provide users with a compact and intuitive view for analyzing spatial and temporal patterns at the same time. Other two visualization techniques, providing complementary views, are specialized in analysing time trend and detecting abnormal cases, which are two important analysis tasks in any climate change study. Case studies and expert reviews have been conducted, through which the effectiveness and scalability of the proposed approach has been confirmed.","keywords":"climate changes, spatiotemporal visualization, station-based observation data, radial layout, visual analytics","caption":"Fig. 9.\\r\\nThe winter climate change in china during the period of 2001\u20132012. (a) The parameter selection bar. (b) Most of the stations are in the selected cluster ring showing a slowly rising trend. (c) A reddish ring and a bluish ring in the time series disc represent a minima point and a maxima point respectively, and (d) The time series plot also proves this finding.","img_size":{"width":1056,"height":1573},"subfigures":[{"x":15.245405573269961,"y":16.021177853580635,"width":1023.358028892014,"height":1547.4033481469235,"type":"interface","id":"interface-0"}],"visualizations":[{"x":7.690992220672966,"y":1226.0871605766044,"width":316.3179469459363,"height":317.73280838451495,"type":"heatmap","id":"heatmap-2"},{"x":156.21339621505254,"y":246.8182617820498,"width":745.3153099441448,"height":737.9776081153002,"type":"heatmap","id":"heatmap-7"},{"x":383.3624457192976,"y":1183.595944674492,"width":641.3528654188751,"height":362.8310811407248,"type":"line_chart","id":"line_chart-3"},{"x":344.4075031205637,"y":450.76825860223585,"width":368.9963828231036,"height":312.60719323540906,"type":"map","id":"map-0"},{"x":17.336218750074334,"y":109.47434644128236,"width":1017.0252425769607,"height":1014.5775708022509,"type":"scatterplot","id":"scatterplot-4"}],"relations":[{"vislist":[{"vislist":[{"vislist":[{"vislist":["map-0"],"relation":null,"id":"group-6"},{"vislist":["heatmap-7"],"relation":null,"id":"group-7"}],"relation":"nested","id":"relation-3"}],"relation":null,"id":"group-8"},{"vislist":["scatterplot-4"],"relation":null,"id":"group-9"}],"relation":"nested","id":"relation-4"}]},"2583_0":{"comp":[["scatterplot","proportional_area_chart",["nested"]]],"visType":["scatterplot","proportional_area_chart"],"compType":["nested"],"compressed_tree":[{"composite_pattern":"nested","visualization_type":[["scatterplot"],["proportional_area_chart"]]}],"coOccurrence":[["scatterplot","proportional_area_chart",["coOccurrence"]]],"year":2014,"conference":["VAST"],"authors":["Pierre Accorsi","Nathalie Lalande","Micka\xebl Fabr\xe8gue","Agn\xe8s Braud","Pascal Poncelet","Arnaud Sallaberry","Sandra Bringay","Maguelonne Teisseire","Flavie Cernesson","Florence Le Ber"],"title":"HydroQual: Visual Analysis of River Water Quality","doi":"10.1109/VAST.2014.7042488","abstract":"Economic development based on industrialization, intensive agriculture expansion and population growth places greater pressure on water resources through increased water abstraction and water quality degradation [40], River pollution is now a visible issue, with emblematic ecological disasters following industrial accidents such as the pollution of the Rhine river in 1986 [31]. River water quality is a pivotal public health and environmental issue that has prompted governments to plan initiatives for preserving or restoring aquatic ecosystems and water resources [56], Water managers require operational tools to help interpret the complex range of information available on river water quality functioning. Tools based on statistical approaches often fail to resolve some tasks due to the sparse nature of the data. Here we describe HydroQual, a tool to facilitate visual analysis of river water quality. This tool combines spatiotemporal data mining and visualization techniques to perform tasks defined by water experts. We illustrate the approach with a case study that illustrates how the tool helps experts analyze water quality. We also perform a qualitative evaluation with these experts.","keywords":"Visual Analytics, Spatiotemporal Data Mining and Visualization, Water Quality","caption":"Figure 1: HydroQual is a tool that facilitates visual analysis of river water quality. The input dataset consists of sequences of biological indices and physicochemical values for several geolocalized sam- pling river stations. The clustering view (top left) shows stations grouped by their behavioral similarity. The geographical view (top right) shows the geolocation of the stations. By selecting a set of sta- tions from these two views, users can extract and visualize temporal patterns regarding biological indices and physicochemical parame- ters in the temporal patterns view (bottom).","img_size":{"width":1014,"height":567},"subfigures":[{"x":7.56912744218683,"y":9.588764021793159,"width":998.0873252482596,"height":547.8224719564128,"type":"interface","id":"interface-0"}],"visualizations":[{"x":383.27960526315786,"y":339.45394736842104,"width":613.0065789473683,"height":211.38157894736844,"type":"graph","id":"graph-1"},{"x":557.3585526315791,"y":42.27631578947368,"width":446.3881578947369,"height":290.9605263157895,"type":"map","id":"map-0"},{"x":142.48466659195216,"y":41.032894736841946,"width":415.75096738241746,"height":293.4473684210524,"type":"proportional_area_chart","id":"proportional_area_chart-2"},{"x":143.29934210526318,"y":41.0328947368421,"width":411.57236842105283,"height":290.9605263157895,"type":"scatterplot","id":"scatterplot-3"},{"x":559.8453947368421,"y":43.51973684210526,"width":442.6578947368422,"height":290.9605263157895,"type":"scatterplot","id":"scatterplot-4"},{"x":145.78618421052633,"y":336.96710526315786,"width":233.76315789473682,"height":215.11184210526312,"type":"table","id":"table-5"}],"relations":[{"vislist":[{"vislist":["scatterplot-3"],"relation":null,"id":"group-2"},{"vislist":["proportional_area_chart-2"],"relation":null,"id":"group-3"}],"relation":"nested","id":"relation-1"}]},"2368_2":{"comp":[["scatterplot","matrix",["nested"]],["heatmap","comb",["stacked"]],["comb","heatmap",["stacked"]]],"visType":["scatterplot","matrix","heatmap","comb"],"compType":["nested","stacked"],"compressed_tree":[{"composite_pattern":"stacked","visualization_type":[["heatmap",{"composite_pattern":"nested","visualization_type":[["scatterplot"],["matrix"]]}]]},{"composite_pattern":"stacked","visualization_type":[["heatmap",{"composite_pattern":"nested","visualization_type":[["scatterplot"],["matrix"]]}]]}],"coOccurrence":[["scatterplot","matrix",["coOccurrence"]],["scatterplot","heatmap",["coOccurrence"]],["matrix","heatmap",["coOccurrence"]]],"year":2013,"conference":["InfoVis"],"authors":["Xiaoru Yuan","Donghao Ren","Zuchao Wang","Cong Guo"],"title":"Dimension Projection Matrix/Tree: Interactive Subspace Visual Exploration and Analysis of High Dimensional Data","doi":"10.1109/TVCG.2013.150","abstract":"For high-dimensional data, this work proposes two novel visual exploration methods to gain insights into the data aspect and the dimension aspect of the data. The first is a Dimension Projection Matrix, as an extension of a scatterplot matrix. In the matrix, each row or column represents a group of dimensions, and each cell shows a dimension projection (such as MDS) of the data with the corresponding dimensions. The second is a Dimension Projection Tree, where every node is either a dimension projection plot or a Dimension Projection Matrix. Nodes are connected with links and each child node in the tree covers a subset of the parent node\'s dimensions or a subset of the parent node\'s data items. While the tree nodes visualize the subspaces of dimensions or subsets of the data items under exploration, the matrix nodes enable cross-comparison between different combinations of subspaces. Both Dimension Projection Matrix and Dimension Project Tree can be constructed algorithmically through automation, or manually through user interaction. Our implementation enables interactions such as drilling down to explore different levels of the data, merging or splitting the subspaces to adjust the matrix, and applying brushing to select data clusters. Our method enables simultaneously exploring data correlation and dimension correlation for data with high dimensions.","keywords":"High dimensional data, hierarchical visualization, sub-dimensional space, user interaction, subspace, tree, matrix","caption":"Fig. 3. Illustration of a Dimension Projection Matrix node. Each node represents a portion of the high-dimensional dataset defined by a set of dimensions and a set of data items. The data item plot is shown as an Dimension Projection Matrix of dimension groups. The upper right cells of the matrix show Dimension Projection of data items on the cor- responding dimensions, while the lower left cells of the matrix show Di- mension Projection of the corresponding dimensions. The dimensions for each cell are indicated by the dimension indicators. The dimension plot is an Dimension Projection of all dimensions in the node.","img_size":{"width":1088,"height":678},"subfigures":[{"x":17.624791493148376,"y":48.913787623750906,"width":1053.4717660031838,"height":584.501805714228,"type":"single","id":"single-0"}],"visualizations":[{"x":527.1261130427154,"y":99.4959105012049,"width":27.96594116248664,"height":498.838913063299,"type":"heatmap","id":"heatmap-5"},{"x":27.714507193592024,"y":602.5950804119476,"width":500.64237242129036,"height":22.28642891344831,"type":"heatmap","id":"heatmap-6"},{"x":24.592272553400676,"y":97.55694734623545,"width":502.07299612832145,"height":504.90734016839446,"type":"matrix","id":"matrix-4"},{"x":555.0282885431398,"y":96.65182270062861,"width":510.17821782178186,"height":525.9573705641807,"type":"scatterplot","id":"scatterplot-2"},{"x":22.678568004453396,"y":97.531508649616,"width":504.80841810876205,"height":505.0608441601928,"type":"scatterplot","id":"scatterplot-3"}],"relations":[{"vislist":[{"vislist":["heatmap-5",{"vislist":[{"vislist":["scatterplot-3"],"relation":null,"id":"group-1"},{"vislist":["matrix-4"],"relation":null,"id":"group-2"}],"relation":"nested","id":"relation-1"}],"relation":null,"id":"group-3"}],"relation":"stacked","id":"relation-2"},{"vislist":[{"vislist":["heatmap-6",{"vislist":[{"vislist":["scatterplot-3"],"relation":null,"id":"group-1"},{"vislist":["matrix-4"],"relation":null,"id":"group-2"}],"relation":"nested","id":"relation-1"}],"relation":null,"id":"group-4"}],"relation":"stacked","id":"relation-3"}]},"2373_8":{"comp":[["heatmap","matrix",["nested"]],["bar_chart","matrix",["nested"]],["scatterplot","matrix",["nested"]]],"visType":["heatmap","matrix","bar_chart","scatterplot"],"compType":["nested"],"compressed_tree":[{"composite_pattern":"nested","visualization_type":[["heatmap"],["matrix"]]},{"composite_pattern":"nested","visualization_type":[["bar_chart"],["matrix"]]},{"composite_pattern":"nested","visualization_type":[["scatterplot"],["matrix"]]}],"coOccurrence":[["heatmap","matrix",["coOccurrence"]],["heatmap","bar_chart",["coOccurrence"]],["heatmap","scatterplot",["coOccurrence"]],["matrix","bar_chart",["coOccurrence"]],["matrix","scatterplot",["coOccurrence"]],["bar_chart","scatterplot",["coOccurrence"]]],"year":2013,"conference":["InfoVis"],"authors":["Jean-Fran\xe7ois Im","Michael J. McGuffin","Rock Leung"],"title":"GPLOM: The Generalized Plot Matrix for Visualizing Multidimensional Multivariate Data","doi":"10.1109/TVCG.2013.160","abstract":"Scatterplot matrices (SPLOMs), parallel coordinates, and glyphs can all be used to visualize the multiple continuous variables (i.e., dependent variables or measures) in multidimensional multivariate data. However, these techniques are not well suited to visualizing many categorical variables (i.e., independent variables or dimensions). To visualize multiple categorical variables, \'hierarchical axes\' that \'stack dimensions\' have been used in systems like Polaris and Tableau. However, this approach does not scale well beyond a small number of categorical variables. Emerson et al. [8] extend the matrix paradigm of the SPLOM to simultaneously visualize several categorical and continuous variables, displaying many kinds of charts in the matrix depending on the kinds of variables involved. We propose a variant of their technique, called the Generalized Plot Matrix (GPLOM). The GPLOM restricts Emerson et al.\'s technique to only three kinds of charts (scatterplots for pairs of continuous variables, heatmaps for pairs of categorical variables, and barcharts for pairings of categorical and continuous variable), in an effort to make it easier to understand. At the same time, the GPLOM extends Emerson et al.\'s work by demonstrating interactive techniques suited to the matrix of charts. We discuss the visual design and interactive features of our GPLOM prototype, including a textual search feature allowing users to quickly locate values or variables by name. We also present a user study that compared performance with Tableau and our GPLOM prototype, that found that GPLOM is significantly faster in certain cases, and not significantly slower in other cases.","keywords":"Multidimensional data, tabular data, relational data, mdmv, high-dimensional data, database visualization, database overview, parallel coordinates, scatterplot matrix, user interfaces, business intelligence","caption":"Fig. 8. A GPLOM of 8 categorical variables, 8 continuous variables, and 144 million flights from the OnTime dataset. The menubar at the top displays the possible aggregation operators for barcharts and heatmaps: Average (currently selected), Sum, Count, Min, and Max. The menubar also shows that \u201cDeparture delay\u201d is the currently selected (dependent) continuous variable for heatmaps. Other interface elements: A: bendy highlight; B: textual search box; C: infobox. Note that heatmaps and barcharts are computed over the whole dataset, but scatterplots only show a random sample of 200 data points each.","img_size":{"width":2151,"height":1230},"subfigures":[{"x":9.470410109440257,"y":13.535679504784275,"width":2134.677449021026,"height":1212.0918588076624,"type":"interface","id":"interface-0"}],"visualizations":[{"x":6.678623718887365,"y":605.095168374817,"width":1188.5797950219624,"height":621.3030746705713,"type":"bar_chart","id":"bar_chart-0"},{"x":6.678623718887365,"y":84.64128843338214,"width":1046.310395314788,"height":507.84773060029295,"type":"heatmap","id":"heatmap-1"},{"x":1724.7166910688145,"y":93.64568081991216,"width":401.5959004392383,"height":288.1405563689605,"type":"line_chart","id":"line_chart-2"},{"x":6.678623718887365,"y":81.03953147877016,"width":1048.111273792094,"height":509.64860907759896,"type":"matrix","id":"matrix-3"},{"x":9.600222353483156,"y":615.4884590287194,"width":1186.515956408232,"height":603.2652070519888,"type":"matrix","id":"matrix-7"},{"x":1189.5614893872837,"y":678.6692952235079,"width":947.0209484721508,"height":544.9488190215812,"type":"matrix","id":"matrix-8"},{"x":1193.4575402635435,"y":666.3250366032212,"width":938.2576866764277,"height":560.2730756733076,"type":"scatterplot","id":"scatterplot-4"},{"x":3.401887723471286,"y":77.43777452415813,"width":2129.9143484626647,"height":1148.9604685212303,"type":"small_multiple","id":"small_multiple-5"}],"relations":[{"vislist":[{"vislist":["heatmap-1"],"relation":null,"id":"group-1"},{"vislist":["matrix-3"],"relation":null,"id":"group-0"}],"relation":"nested","id":"relation-0"},{"vislist":[{"vislist":["bar_chart-0"],"relation":null,"id":"group-3"},{"vislist":["matrix-7"],"relation":null,"id":"group-2"}],"relation":"nested","id":"relation-1"},{"vislist":[{"vislist":["scatterplot-4"],"relation":null,"id":"group-5"},{"vislist":["matrix-8"],"relation":null,"id":"group-4"}],"relation":"nested","id":"relation-2"}]},"2435_0":{"comp":[["glyph_based","tree",["nested"]],["glyph_based","graph",["nested"]],["glyph_based","bar_chart",["nested"]]],"visType":["glyph_based","tree","graph","bar_chart"],"compType":["nested"],"compressed_tree":[{"composite_pattern":"nested","visualization_type":[["glyph_based"],["tree"]]},{"composite_pattern":"nested","visualization_type":[["glyph_based"],["graph"]]},{"composite_pattern":"nested","visualization_type":[["glyph_based"],["bar_chart"]]}],"coOccurrence":[["glyph_based","tree",["coOccurrence"]],["glyph_based","graph",["coOccurrence"]],["glyph_based","bar_chart",["coOccurrence"]],["tree","graph",["coOccurrence"]],["tree","bar_chart",["coOccurrence"]],["graph","bar_chart",["coOccurrence"]]],"year":2013,"conference":["VAST"],"authors":["J\xfcrgen Bernard","Nils Wilhelm","Bj\xf6rn Kr\xfcger","Thorsten May","Tobias Schreck","J\xf6rn Kohlhammer"],"title":"MotionExplorer: Exploratory Search in Human Motion Capture Data Based on Hierarchical Aggregation","doi":"10.1109/TVCG.2013.178","abstract":"We present MotionExplorer, an exploratory search and analysis system for sequences of human motion in large motion capture data collections. This special type of multivariate time series data is relevant in many research fields including medicine, sports and animation. Key tasks in working with motion data include analysis of motion states and transitions, and synthesis of motion vectors by interpolation and combination. In the practice of research and application of human motion data, challenges exist in providing visual summaries and drill-down functionality for handling large motion data collections. We find that this domain can benefit from appropriate visual retrieval and analysis support to handle these tasks in presence of large motion data. To address this need, we developed MotionExplorer together with domain experts as an exploratory search system based on interactive aggregation and visualization of motion states as a basis for data navigation, exploration, and search. Based on an overview-first type visualization, users are able to search for interesting sub-sequences of motion based on a query-by-example metaphor, and explore search results by details on demand. We developed MotionExplorer in close collaboration with the targeted users who are researchers working on human motion synthesis and analysis, including a summative field study. Additionally, we conducted a laboratory design study to substantially improve MotionExplorer towards an intuitive, usable and robust design. MotionExplorer enables the search in human motion capture data with only a few mouse clicks. The researchers unanimously confirm that the system can efficiently support their work.","keywords":"Visual analytics, exploratory search, multivariate time series, motion capture data, data aggregation, cluster glyph","caption":"Fig. 1. MotionExplorer enables the exploratory search in human motion capture data. The pose hierarchy explorer (upper left) allows adjustment of the aggregation level of a hierarchical clustering and filtering of human poses. The motion explorer (upper right) shows human pose and movement aggregates. The search interface (below) allows for a visual query definition and an interactive search result exploration to identify style variations.","img_size":{"width":2157,"height":1043},"subfigures":[{"x":4.657559588982613,"y":11.640486208447623,"width":2144.3122450957917,"height":1028.7136574724577,"type":"interface","id":"interface-0"}],"visualizations":[{"x":561.1225296442689,"y":779.1581027667985,"width":1045.0612648221347,"height":257.65810276679855,"type":"bar_chart","id":"bar_chart-0"},{"x":12.826086956521777,"y":18.551383399209488,"width":1067.7351778656127,"height":748.2391304347827,"type":"glyph_based","id":"glyph_based-1"},{"x":291.0968379446641,"y":770.913043478261,"width":267.9644268774704,"height":268.6755795717031,"type":"glyph_based","id":"glyph_based-2"},{"x":6.642292490118621,"y":770.913043478261,"width":280.33201581027674,"height":268.6755795717031,"type":"glyph_based","id":"glyph_based-3"},{"x":1078.5,"y":12.367588932806326,"width":1069.7964426877475,"height":744.1166007905139,"type":"glyph_based","id":"glyph_based-4"},{"x":1872.0869565217397,"y":760.606719367589,"width":281.5016665282244,"height":278.981903682375,"type":"glyph_based","id":"glyph_based-5"},{"x":557.2865425859017,"y":781.4550882623039,"width":1053.306324110672,"height":253.53557312252977,"type":"glyph_based","id":"glyph_based-6"},{"x":1604.3755980042147,"y":787.8536834726976,"width":255.92163495597106,"height":247.83989911525606,"type":"glyph_based","id":"glyph_based-7"},{"x":1080.5612648221345,"y":22.673913043478265,"width":1063.6126482213444,"height":731.7490118577076,"type":"graph","id":"graph-8"},{"x":1867.9644268774705,"y":756.4841897233202,"width":285.62419617249344,"height":283.10443332664374,"type":"graph","id":"graph-9"},{"x":14.887351778656182,"y":18.551383399209488,"width":1067.7351778656127,"height":746.1778656126484,"type":"tree","id":"tree-10"}],"relations":[{"vislist":[{"vislist":["glyph_based-1"],"relation":null,"id":"group-1"},{"vislist":["tree-10"],"relation":null,"id":"group-0"}],"relation":"nested","id":"relation-0"},{"vislist":[{"vislist":["glyph_based-4"],"relation":null,"id":"group-3"},{"vislist":["graph-8"],"relation":null,"id":"group-2"}],"relation":"nested","id":"relation-1"},{"vislist":[{"vislist":["glyph_based-6"],"relation":null,"id":"group-5"},{"vislist":["bar_chart-0"],"relation":null,"id":"group-4"}],"relation":"nested","id":"relation-2"}]},"2359_4":{"comp":[["heatmap","table",["nested"]]],"visType":["heatmap","table"],"compType":["nested"],"compressed_tree":[{"composite_pattern":"nested","visualization_type":[["heatmap"],["table"]]}],"coOccurrence":[["heatmap","table",["coOccurrence"]]],"year":2013,"conference":["InfoVis"],"authors":["Hans-J\xf6rg Schulz","Thomas Nocke","Magnus Heitzler","Heidrun Schumann"],"title":"A Design Space of Visualization Tasks","doi":"10.1109/TVCG.2013.120","abstract":"Knowledge about visualization tasks plays an important role in choosing or building suitable visual representations to pursue them. Yet, tasks are a multi-faceted concept and it is thus not surprising that the many existing task taxonomies and models all describe different aspects of tasks, depending on what these task descriptions aim to capture. This results in a clear need to bring these different aspects together under the common hood of a general design space of visualization tasks, which we propose in this paper. Our design space consists of five design dimensions that characterize the main aspects of tasks and that have so far been distributed across different task descriptions. We exemplify its concrete use by applying our design space in the domain of climate impact research. To this end, we propose interfaces to our design space for different user roles (developers, authors, and end users) that allow users of different levels of expertise to work with it.","keywords":"Task taxonomy, design space, climate impact research, visualization recommendation","caption":"Fig. 3. Visualization recommendations given in the end user interface for the selection of 2D/2.5D visualization techniques based on the user- specified compound task \u201canalyze outliers\u201d. It orders the available visu- alizations according to their computed suitability score that is given in the middle column. The right-most column shows the four most influen- tial design requirements, ordered by the degree of their contribution to the final score. This column is usually hidden for end users, but it helps visualization authors and expert users to debug and further refine the set of compound tasks that form the domain-specific task subspace.","img_size":{"width":1080,"height":1151},"subfigures":[{"x":16.94075819284956,"y":4.14926415535378,"width":1057.1429172200483,"height":1146.376337092648,"type":"interface","id":"interface-0"}],"visualizations":[{"x":120.78854314002832,"y":179.0806223479491,"width":109.07637906647814,"height":113.960396039604,"type":"heatmap","id":"heatmap-0"},{"x":117.53253182461106,"y":299.5530410183876,"width":115.58840169731263,"height":109.07637906647807,"type":"heatmap","id":"heatmap-1"},{"x":119.1605374823197,"y":415.1414427157002,"width":113.96039603960402,"height":110.7043847241867,"type":"heatmap","id":"heatmap-2"},{"x":120.78854314002832,"y":533.98585572843,"width":109.07637906647814,"height":110.70438472418677,"type":"heatmap","id":"heatmap-3"},{"x":119.1605374823197,"y":647.9462517680339,"width":112.33239038189538,"height":109.07637906647813,"type":"heatmap","id":"heatmap-4"},{"x":119.1605374823197,"y":771.6746817538897,"width":107.4483734087695,"height":107.44837340876937,"type":"heatmap","id":"heatmap-5"},{"x":65.12022630834521,"y":135.1244695898161,"width":957.5834512022632,"height":748.882602545969,"type":"table","id":"table-6"}],"relations":[{"vislist":[{"vislist":["heatmap-0","heatmap-1","heatmap-2","heatmap-3","heatmap-4","heatmap-5"],"relation":null,"id":"group-1"},{"vislist":["table-6"],"relation":null,"id":"group-0"}],"relation":"nested","id":"relation-0"}]},"2371_6":{"comp":[["bar_chart","matrix",["nested"]],["bar_chart","bar_chart",["stacked"]],["graph","graph",["annotated"]]],"visType":["bar_chart","matrix","graph"],"compType":["nested","stacked","annotated"],"compressed_tree":[{"composite_pattern":"nested","visualization_type":[["bar_chart"],["matrix"]]},{"composite_pattern":"stacked","visualization_type":[["bar_chart"]]},{"composite_pattern":"annotated","visualization_type":[["graph"],["graph"]]}],"coOccurrence":[["bar_chart","matrix",["coOccurrence"]],["bar_chart","graph",["coOccurrence"]],["matrix","graph",["coOccurrence"]]],"year":2013,"conference":["InfoVis"],"authors":["Alexander Lex","Christian Partl","Denis Kalkofen","Marc Streit","Samuel Gratzl","Anne Mai Wassermann","Dieter Schmalstieg","Hanspeter Pfister"],"title":"Entourage: Visualizing Relationships between Biological Pathways using Contextual Subsets","doi":"10.1109/TVCG.2013.154","abstract":"Biological pathway maps are highly relevant tools for many tasks in molecular biology. They reduce the complexity of the overall biological network by partitioning it into smaller manageable parts. While this reduction of complexity is their biggest strength, it is, at the same time, their biggest weakness. By removing what is deemed not important for the primary function of the pathway, biologists lose the ability to follow and understand cross-talks between pathways. Considering these cross-talks is, however, critical in many analysis scenarios, such as judging effects of drugs. In this paper we introduce Entourage, a novel visualization technique that provides contextual information lost due to the artificial partitioning of the biological network, but at the same time limits the presented information to what is relevant to the analyst\'s task. We use one pathway map as the focus of an analysis and allow a larger set of contextual pathways. For these context pathways we only show the contextual subsets, i.e., the parts of the graph that are relevant to a selection. Entourage suggests related pathways based on similarities and highlights parts of a pathway that are interesting in terms of mapped experimental data. We visualize interdependencies between pathways using stubs of visual links, which we found effective yet not obtrusive. By combining this approach with visualization of experimental data, we can provide domain experts with a highly valuable tool. We demonstrate the utility of Entourage with case studies conducted with a biochemist who researches the effects of drugs on pathways. We show that the technique is well suited to investigate interdependencies between pathways and to analyze, understand, and predict the effect that drugs have on different cell types.","keywords":"Pathway visualization, biological networks, subsets, graphs, biomolecular data","caption":"Fig. 7. The ErbB signaling pathway (the focus pathway) is a target of the drugs Lapatinib and Erlotinib that are used for cancer treatment. As shown in the pathway list on the left that results from a query for similar pathways, the ErbB signaling pathway is related to many cancer pathways. A signaling cascade from ErbB2 to Ras is selected. The integrated enRoute view shows copy number and mRNA expression data for breast cancer cell lines. The sensitivity of the different cell lines to Lapatinib and Erlotinib is reported at the top. For the shown cell lines, increased copy numbers of ErB2 (high red bars in the ErbB2 row) result in over-expression of this gene (high blue bars). Furthermore, there is a strong relation between ErbB2 over-expression and sensitivity to Lapatinib (high blue bars for gene over-expression in the ErbB2 row coincide with low bars in the Lapatinib row). This means that Lapatinib is effective if ErbB2 is highly expressed. There are, however, two exceptions - the highlighted cell lines (gold and orange), for which an under-expression in Ras downstream in the pathway is observed, likely causing Lapatinib to be ineffective in these cases. While this observation was made for breast cancer tissue, exploring the related context pathways by setting the focus node to Ras reveals that the same signaling cascade (i.e., path) is also contained in the non-small cell lung cancer pathway. Thus, it would be interesting to explore the transferability of the observed resistance pattern to this tissue type.","img_size":{"width":2139,"height":927},"subfigures":[{"x":3.5169723870508984,"y":4.7410547416513085,"width":2131.9660552258956,"height":918.6331879362917,"type":"interface","id":"interface-0"}],"visualizations":[{"x":1567.2644092219018,"y":38.1657060518732,"width":550.160662824208,"height":741.2528818443805,"type":"bar_chart","id":"bar_chart-0"},{"x":10.787463976945068,"y":10.426512968299715,"width":232.70100864553308,"height":883.0309798270896,"type":"bar_chart","id":"bar_chart-1"},{"x":1567.2644092219018,"y":38.1657060518732,"width":550.160662824208,"height":741.2528818443805,"type":"bar_chart","id":"bar_chart-2"},{"x":10.787463976945068,"y":10.426512968299715,"width":232.70100864553308,"height":883.0309798270896,"type":"bar_chart","id":"bar_chart-3"},{"x":260.44020172910643,"y":102.89048991354473,"width":1015.5626801152738,"height":744.3350144092221,"type":"graph","id":"graph-14"},{"x":1291.4135446685877,"y":33.54250720461096,"width":109.41570605187329,"height":426.8753602305477,"type":"graph","id":"graph-15"},{"x":1422.4041786743517,"y":56.6585014409222,"width":101.71037463976928,"height":166.43515850144092,"type":"graph","id":"graph-16"},{"x":1291.4135446685877,"y":548.2586455331412,"width":104.79250720461117,"height":204.96181556195975,"type":"graph","id":"graph-17"},{"x":1419.32204610951,"y":545.1765129682998,"width":103.2514409221903,"height":345.1988472622479,"type":"graph","id":"graph-18"},{"x":260.44020172910643,"y":102.89048991354473,"width":1015.5626801152738,"height":744.3350144092221,"type":"graph","id":"graph-19"},{"x":1291.4135446685877,"y":33.54250720461096,"width":109.41570605187329,"height":426.8753602305477,"type":"graph","id":"graph-20"},{"x":1422.4041786743517,"y":56.6585014409222,"width":101.71037463976928,"height":166.43515850144092,"type":"graph","id":"graph-21"},{"x":1291.4135446685877,"y":548.2586455331412,"width":104.79250720461117,"height":204.96181556195975,"type":"graph","id":"graph-22"},{"x":1419.32204610951,"y":545.1765129682998,"width":103.2514409221903,"height":345.1988472622479,"type":"graph","id":"graph-23"},{"x":1571.887608069164,"y":35.08357348703171,"width":545.5374639769457,"height":745.876080691643,"type":"matrix","id":"matrix-24"}],"relations":[{"vislist":[{"vislist":["bar_chart-2"],"relation":null,"id":"group-3"},{"vislist":["matrix-24"],"relation":null,"id":"group-4"}],"relation":"nested","id":"relation-2"},{"vislist":[{"vislist":["bar_chart-3"],"relation":null,"id":"group-5"}],"relation":"stacked","id":"relation-3"},{"vislist":[{"vislist":["graph-20","graph-21","graph-22","graph-23"],"relation":null,"id":"group-6"},{"vislist":["graph-19"],"relation":null,"id":"group-7"}],"relation":"annotated","id":"relation-4"}]},"2386_0":{"comp":[["graph","donut_chart",["nested"]]],"visType":["graph","donut_chart"],"compType":["nested"],"compressed_tree":[{"composite_pattern":"nested","visualization_type":[["graph"],["donut_chart"]]}],"coOccurrence":[["graph","donut_chart",["coOccurrence"]]],"year":2013,"conference":["InfoVis"],"authors":["Rahul C. Basole","Trustin Clear","Mengdie Hu","Harshit Mehrotra","John T. Stasko"],"title":"Understanding Interfirm Relationships in Business Ecosystems with Interactive Visualization","doi":"10.1109/TVCG.2013.209","abstract":"Business ecosystems are characterized by large, complex, and global networks of firms, often from many different market segments, all collaborating, partnering, and competing to create and deliver new products and services. Given the rapidly increasing scale, complexity, and rate of change of business ecosystems, as well as economic and competitive pressures, analysts are faced with the formidable task of quickly understanding the fundamental characteristics of these interfirm networks. Existing tools, however, are predominantly query- or list-centric with limited interactive, exploratory capabilities. Guided by a field study of corporate analysts, we have designed and implemented dotlink360, an interactive visualization system that provides capabilities to gain systemic insight into the compositional, temporal, and connective characteristics of business ecosystems. dotlink360 consists of novel, multiple connected views enabling the analyst to explore, discover, and understand interfirm networks for a focal firm, specific market segments or countries, and the entire business ecosystem. System evaluation by a small group of prototypical users shows supporting evidence of the benefits of our approach. This design study contributes to the relatively unexplored, but promising area of exploratory information visualization in market research and business strategy.","keywords":"Business ecosystems, market research, strategic analysis, design study, interaction, network visualization","caption":"Fig. 1. The dotlink360 user interface including the navigator panel (left), the central visualization window, and the details panel (right). This image shows the Segment view with Apple selected so it and its market segments are colored yellow, while its partners are colored orange. The mouse cursor is over Nokia so it and its segments are colored light blue, with its partners dark blue. Company positions are determined by their segment memberships.","img_size":{"width":1907,"height":946},"subfigures":[{"x":0.9673375099668162,"y":11.399270160721962,"width":1882.9152512473468,"height":928.2353760868606,"type":"interface","id":"interface-0"}],"visualizations":[{"x":444.37270155586987,"y":112.39603960396039,"width":984.803394625177,"height":776.0678925035361,"type":"donut_chart","id":"donut_chart-0"},{"x":441.6966053748232,"y":113.73408769448373,"width":984.8033946251768,"height":774.7298444130129,"type":"graph","id":"graph-1"}],"relations":[{"vislist":[{"vislist":["graph-1"],"relation":null,"id":"group-1"},{"vislist":["donut_chart-0"],"relation":null,"id":"group-2"}],"relation":"nested","id":"relation-1"}]},"2437_3":{"comp":[["glyph_based","flow_diagram",["nested"]]],"visType":["glyph_based","flow_diagram"],"compType":["nested"],"compressed_tree":[{"composite_pattern":"nested","visualization_type":[["glyph_based"],["flow_diagram"]]}],"coOccurrence":[["glyph_based","flow_diagram",["coOccurrence"]]],"year":2013,"conference":["VAST"],"authors":["Harald Bosch","Dennis Thom","Florian Heimerl","Edwin Puttmann","Steffen Koch","Robert Kr\xfcger","Michael W\xf6rne","Thomas Ertl"],"title":"ScatterBlogs2: Real-Time Monitoring of Microblog Messages through User-Guided filtering","doi":"10.1109/TVCG.2013.186","abstract":"The number of microblog posts published daily has reached a level that hampers the effective retrieval of relevant messages, and the amount of information conveyed through services such as Twitter is still increasing. Analysts require new methods for monitoring their topic of interest, dealing with the data volume and its dynamic nature. It is of particular importance to provide situational awareness for decision making in time-critical tasks. Current tools for monitoring microblogs typically filter messages based on user-defined keyword queries and metadata restrictions. Used on their own, such methods can have drawbacks with respect to filter accuracy and adaptability to changes in trends and topic structure. We suggest ScatterBlogs2, a new approach to let analysts build task-tailored message filters in an interactive and visual manner based on recorded messages of well-understood previous events. These message filters include supervised classification and query creation backed by the statistical distribution of terms and their co-occurrences. The created filter methods can be orchestrated and adapted afterwards for interactive, visual real-time monitoring and analysis of microblog feeds. We demonstrate the feasibility of our approach for analyzing the Twitter stream in emergency management scenarios.","keywords":"Microblog analysis, Twitter, text analytics, social media monitoring, live monitoring, visual analytics, information visualization, filter construction, query construction, text classification","caption":"Fig. 3. User Interface of the monitoring environment showing (a) the Map View with aggregated filter detection symbols with the respective number of aggregated messages, (b) the LDA topic view, (c) the table of selected message contents, (d) the filter orchestration view, (e) the class panel view, (f) the smooth scroll time slider, and (g) the control panel allowing to perform textual and geographic search, summon Contentlenses, and starting simulation mode.","img_size":{"width":2166,"height":972},"subfigures":[{"x":2.4130037576768992,"y":14.05744629516624,"width":2151.013868725197,"height":950.6652253676791,"type":"interface","id":"interface-0"}],"visualizations":[{"x":394.8462390486483,"y":633.8205689277897,"width":655.1865837084632,"height":32.40011804215794,"type":"bar_chart","id":"bar_chart-0"},{"x":1413.7352297592997,"y":168.0262582056892,"width":338.17943107221004,"height":438.144420131291,"type":"flow_diagram","id":"flow_diagram-1"},{"x":1411.522429638322,"y":172.87285471032214,"width":337.2884331079845,"height":438.623437372445,"type":"glyph_based","id":"glyph_based-7"},{"x":397.3024231015507,"y":149.8462987409796,"width":948.1871822447658,"height":465.50259350896454,"type":"map","id":"map-5"},{"x":394.94310722100664,"y":153.13785557986867,"width":954.9846827133479,"height":465.7943107221006,"type":"scatterplot","id":"scatterplot-2"},{"x":3.59080962800877,"y":759.3085339168489,"width":2118.407002188184,"height":185.04157549234125,"type":"table","id":"table-3"},{"x":58.89059080962802,"y":168.0262582056892,"width":242.46827133479215,"height":512.5864332603936,"type":"word_cloud","id":"word_cloud-4"}],"relations":[{"vislist":[{"vislist":["glyph_based-7"],"relation":null,"id":"group-3"},{"vislist":["flow_diagram-1"],"relation":null,"id":"group-2"}],"relation":"nested","id":"relation-1"}]},"1434_2":{"comp":[["scatterplot","matrix",["nested"]]],"visType":["scatterplot","matrix"],"compType":["nested"],"compressed_tree":[{"composite_pattern":"nested","visualization_type":[["scatterplot"],["matrix"]]}],"coOccurrence":[["scatterplot","matrix",["coOccurrence"]]],"year":2006,"conference":["InfoVis"],"authors":["Qingguang Cui","Matthew O. Ward","Elke A. Rundensteiner","Jing Yan"],"title":"Measuring Data Abstraction Quality in Multiresolution Visualizations","doi":"10.1109/TVCG.2006.161","abstract":"Data abstraction techniques are widely used in multiresolution visualization systems to reduce visual clutter and facilitate analysis from overview to detail. However, analysts are usually unaware of how well the abstracted data represent the original dataset, which can impact the reliability of results gleaned from the abstractions. In this paper, we define two data abstraction quality measures for computing the degree to which the abstraction conveys the original dataset: the histogram difference measure and the nearest neighbor measure. They have been integrated within XmdvTool, a public-domain multiresolution visualization system for multivariate data analysis that supports sampling as well as clustering to simplify data. Several interactive operations are provided, including adjusting the data abstraction level, changing selected regions, and setting the acceptable data abstraction quality level. Conducting these operations, analysts can select an optimal data abstraction level. Also, analysts can compare different abstraction methods using the measures to see how well relative data density and outliers are maintained, and then select an abstraction method that meets the requirement of their analytic tasks","keywords":"Metrics, Clustering, Sampling, Multiresolution Visualization","caption":"Fig. 4. Scatterplots of original dataset (DAL=1.00)","img_size":{"width":936,"height":696},"subfigures":[{"x":7.11127920102586,"y":12.447087346331962,"width":918.6966128652566,"height":676.5005343335623,"type":"single","id":"single-0"}],"visualizations":[{"x":8.192771084337323,"y":9.317269076305221,"width":917.7510040160643,"height":672.7068273092368,"type":"scatterplot","id":"scatterplot-0"},{"x":9.124497991967871,"y":10.248995983935743,"width":914.9558232931729,"height":670.843373493976,"type":"matrix","id":"matrix-1"}],"relations":[{"vislist":[{"vislist":["scatterplot-0"],"relation":null,"id":"group-0"},{"vislist":["matrix-1"],"relation":null,"id":"group-1"}],"relation":"nested","id":"relation-0"}]},"1447_17":{"comp":[["bar_chart","donut_chart",["nested"]],["tree","donut_chart",["nested"]]],"visType":["bar_chart","donut_chart","tree"],"compType":["nested"],"compressed_tree":[{"composite_pattern":"nested","visualization_type":[["bar_chart","tree"],["donut_chart"]]}],"coOccurrence":[["bar_chart","tree",["coOccurrence"]],["bar_chart","donut_chart",["coOccurrence"]],["tree","donut_chart",["coOccurrence"]]],"year":2006,"conference":["InfoVis"],"authors":["Roel Vliegen","Jarke J. van Wijk","Erik-Jan van der Linden"],"title":"Visualizing Business Data with Generalized Treemaps","doi":"10.1109/TVCG.2006.200","abstract":"Business data is often presented using simple business graphics. These familiar visualizations are effective for providing overviews, but fall short for the presentation of large amounts of detailed information. Treemaps can provide such detail, but are often not easy to understand. We present how standard treemap algorithms can be adapted such that the results mimic familiar business graphics. Specifically, we present the use of different layout algorithms per level, a number of variations of the squarified algorithm, the use of variable borders, and the use of non-rectangular shapes. The combined use of these leads to histograms, pie charts and a variety of other styles","keywords":"Information visualization, treemap, business graphics, hierarchical data","caption":"Fig. 17: Careers of students.","img_size":{"width":1125,"height":1074},"subfigures":[{"x":11.561018022935583,"y":6.262186270515682,"width":1101.8779639541292,"height":1055.8391470256468,"type":"single","id":"single-0"}],"visualizations":[{"x":30.057284299858562,"y":4.557284299858557,"width":1045.137199434229,"height":1040.5799151343704,"type":"bar_chart","id":"bar_chart-0"},{"x":26.206585411594254,"y":9.33652063414385,"width":1046.1729401827665,"height":1031.8552539153084,"type":"donut_chart","id":"donut_chart-2"},{"x":28.206060606060642,"y":4.339393939393972,"width":1045.2575757575755,"height":1041.4545454545455,"type":"tree","id":"tree-1"}],"relations":[{"vislist":[{"vislist":["bar_chart-0","tree-1"],"relation":null,"id":"group-0"},{"vislist":["donut_chart-2"],"relation":null,"id":"group-1"}],"relation":"nested","id":"relation-0"}]},"1447_13":{"comp":[["others","pie_chart",["nested"]],["comb","proportional_area_chart",["nested"]]],"visType":["others","pie_chart","comb","proportional_area_chart"],"compType":["nested"],"compressed_tree":[{"composite_pattern":"nested","visualization_type":[[{"composite_pattern":"nested","visualization_type":[["others"],["pie_chart"]]}],["proportional_area_chart"]]}],"coOccurrence":[["others","pie_chart",["coOccurrence"]],["others","proportional_area_chart",["coOccurrence"]],["pie_chart","proportional_area_chart",["coOccurrence"]]],"year":2006,"conference":["InfoVis"],"authors":["Roel Vliegen","Jarke J. van Wijk","Erik-Jan van der Linden"],"title":"Visualizing Business Data with Generalized Treemaps","doi":"10.1109/TVCG.2006.200","abstract":"Business data is often presented using simple business graphics. These familiar visualizations are effective for providing overviews, but fall short for the presentation of large amounts of detailed information. Treemaps can provide such detail, but are often not easy to understand. We present how standard treemap algorithms can be adapted such that the results mimic familiar business graphics. Specifically, we present the use of different layout algorithms per level, a number of variations of the squarified algorithm, the use of variable borders, and the use of non-rectangular shapes. The combined use of these leads to histograms, pie charts and a variety of other styles","keywords":"Information visualization, treemap, business graphics, hierarchical data","caption":"Fig. 13: Distribution of cases over employees.","img_size":{"width":1078,"height":401},"subfigures":[{"x":12.305477734541412,"y":22.751086641776975,"width":1037.2162087849863,"height":358.86827879474566,"type":"single","id":"single-0"}],"visualizations":[{"x":15.928953239835664,"y":25.0956543642242,"width":1035.6826037499134,"height":355.56486921072553,"type":"others","id":"others-2"},{"x":13.137908915971778,"y":21.063822963438117,"width":1039.9692110327135,"height":360.25529185375245,"type":"pie_chart","id":"pie_chart-0"},{"x":15.9377089608015,"y":21.323035010978874,"width":1036.6159550143852,"height":358.35392997804234,"type":"proportional_area_chart","id":"proportional_area_chart-1"}],"relations":[{"vislist":[{"vislist":[{"vislist":[{"vislist":["others-2"],"relation":null,"id":"group-0"},{"vislist":["pie_chart-0"],"relation":null,"id":"group-1"}],"relation":"nested","id":"relation-0"}],"relation":null,"id":"group-2"},{"vislist":["proportional_area_chart-1"],"relation":null,"id":"group-3"}],"relation":"nested","id":"relation-1"}]},"1447_9":{"comp":[["treemap","bar_chart",["nested"]],["tree","comb",["stacked"]],["comb","tree",["stacked"]]],"visType":["treemap","bar_chart","tree","comb"],"compType":["nested","stacked"],"compressed_tree":[{"composite_pattern":"stacked","visualization_type":[["tree",{"composite_pattern":"nested","visualization_type":[["treemap"],["bar_chart"]]}]]}],"coOccurrence":[["treemap","bar_chart",["coOccurrence"]],["treemap","tree",["coOccurrence"]],["bar_chart","tree",["coOccurrence"]]],"year":2006,"conference":["InfoVis"],"authors":["Roel Vliegen","Jarke J. van Wijk","Erik-Jan van der Linden"],"title":"Visualizing Business Data with Generalized Treemaps","doi":"10.1109/TVCG.2006.200","abstract":"Business data is often presented using simple business graphics. These familiar visualizations are effective for providing overviews, but fall short for the presentation of large amounts of detailed information. Treemaps can provide such detail, but are often not easy to understand. We present how standard treemap algorithms can be adapted such that the results mimic familiar business graphics. Specifically, we present the use of different layout algorithms per level, a number of variations of the squarified algorithm, the use of variable borders, and the use of non-rectangular shapes. The combined use of these leads to histograms, pie charts and a variety of other styles","keywords":"Information visualization, treemap, business graphics, hierarchical data","caption":"Fig. 9: Addition of empty nodes to obtain a matrix structure.","img_size":{"width":1055,"height":835},"subfigures":[{"x":531.2909595673959,"y":456.7092194840145,"width":513.8014331100784,"height":365.3827469333944,"type":"single","id":"single-0"}],"visualizations":[{"x":529.2715700141441,"y":11.81046676096181,"width":514.936350777935,"height":420.45261669024035,"type":"bar_chart","id":"bar_chart-0"},{"x":211.57001414427148,"y":453.5219236209335,"width":309.4342291371994,"height":362.5813295615276,"type":"bar_chart","id":"bar_chart-1"},{"x":743.0410183875529,"y":455.8840169731258,"width":297.62376237623766,"height":359.03818953323906,"type":"bar_chart","id":"bar_chart-2"},{"x":528.7235195330886,"y":457.0139491192803,"width":251.22808491670096,"height":360.28094894238313,"type":"tree","id":"tree-3"},{"x":6.067892503536029,"y":17.715700141442717,"width":512.5742574257424,"height":412.1852899575672,"type":"treemap","id":"treemap-4"},{"x":530.4526166902403,"y":14.172560113154171,"width":512.5742574257425,"height":419.2715700141443,"type":"treemap","id":"treemap-5"},{"x":740.6789250353605,"y":458.2461103253183,"width":302.3479490806223,"height":356.67609618104666,"type":"treemap","id":"treemap-6"},{"x":212.7510608203677,"y":455.8840169731258,"width":304.71004243281476,"height":360.21923620933524,"type":"treemap","id":"treemap-7"},{"x":6.067892503536029,"y":18.896746817538897,"width":511.3932107496464,"height":411.00424328147096,"type":"unit_visualization","id":"unit_visualization-8"},{"x":2.851542223315029,"y":459.42715700141446,"width":518.4794908062232,"height":357.8571428571429,"type":"unit_visualization","id":"unit_visualization-9"},{"x":532.8147100424328,"y":455.8840169731258,"width":505.48797736916543,"height":357.8571428571429,"type":"unit_visualization","id":"unit_visualization-10"},{"x":530.4526166902403,"y":12.991513437057993,"width":514.9363507779349,"height":420.45261669024035,"type":"unit_visualization","id":"unit_visualization-11"}],"relations":[{"vislist":[{"vislist":["tree-3",{"vislist":[{"vislist":["treemap-6"],"relation":null,"id":"group-0"},{"vislist":["bar_chart-2"],"relation":null,"id":"group-1"}],"relation":"nested","id":"relation-0"}],"relation":null,"id":"group-2"}],"relation":"stacked","id":"relation-1"}]},"1447_11":{"comp":[["others","others",["nested"]]],"visType":["others"],"compType":["nested"],"compressed_tree":[{"composite_pattern":"nested","visualization_type":[["others"],["others"]]}],"coOccurrence":[["others","others",["coOccurrence"]]],"year":2006,"conference":["InfoVis"],"authors":["Roel Vliegen","Jarke J. van Wijk","Erik-Jan van der Linden"],"title":"Visualizing Business Data with Generalized Treemaps","doi":"10.1109/TVCG.2006.200","abstract":"Business data is often presented using simple business graphics. These familiar visualizations are effective for providing overviews, but fall short for the presentation of large amounts of detailed information. Treemaps can provide such detail, but are often not easy to understand. We present how standard treemap algorithms can be adapted such that the results mimic familiar business graphics. Specifically, we present the use of different layout algorithms per level, a number of variations of the squarified algorithm, the use of variable borders, and the use of non-rectangular shapes. The combined use of these leads to histograms, pie charts and a variety of other styles","keywords":"Information visualization, treemap, business graphics, hierarchical data","caption":"Fig. 11: Composite transformation.","img_size":{"width":1073,"height":1079},"subfigures":[{"x":18.95059687121105,"y":23.98644901198561,"width":1035.0988062575777,"height":1029.8323378054006,"type":"single","id":"single-0"}],"visualizations":[{"x":26.926110179772653,"y":29.864298421864337,"width":1017.673828686363,"height":1013.3761588599712,"type":"others","id":"others-0"},{"x":37.136006854281185,"y":38.600536930995474,"width":1000.2019372455272,"height":995.9036818417092,"type":"others","id":"others-1"}],"relations":[{"vislist":[{"vislist":["others-1"],"relation":null,"id":"group-2"},{"vislist":["others-0"],"relation":null,"id":"group-3"}],"relation":"nested","id":"relation-0"}]},"1456_6":{"comp":[["others","matrix",["nested"]]],"visType":["others","matrix"],"compType":["nested"],"compressed_tree":[{"composite_pattern":"nested","visualization_type":[["others"],["matrix"]]}],"coOccurrence":[["others","matrix",["coOccurrence"]]],"year":2006,"conference":["VAST"],"authors":["J\xf6rn Schneidewind","Mike Sips","Daniel A. Keim"],"title":"Pixnostics: Towards Measuring the Value of Visualization","doi":"10.1109/VAST.2006.261423","abstract":"During the last two decades a wide variety of advanced methods for the visual exploration of large data sets have been proposed. For most of these techniques user interaction has become a crucial element, since there are many situations in which a user or an analyst has to select the right parameter settings from among many or select a subset of the available attribute space for the visualization process, in order to construct valuable visualizations that provide insight, into the data and reveal interesting patterns. The right choice of input parameters is often essential, since suboptimal parameter settings or the investigation of irrelevant data dimensions make the exploration process more time consuming and may result in wrong conclusions. In this paper we propose a novel method for automatically determining meaningful parameter- and attribute settings based on the information content of the resulting visualizations. Our technique called Pixnostics, in analogy to Scagnostics (Wilkinson et al., 2005), automatically analyses pixel images resulting from diverse parameter mappings and ranks them according to the potential value for the user. This allows a more effective and more efficient visual data analysis process, since the attribute/parameter space is reduced to meaningful selections and thus the analyst obtains faster insight into the data. Real world applications are provided to show the benefit of the proposed approach","keywords":"Visual Data Exploration, Visualization technique,Visual Analytics","caption":"Figure 7: Pixel Bar Chart showing top 25 results after image analysis using entropy measure. It is easy to see that the bar in the middle (\u201dreject\u201dparts) show significant differences in comparison to the 2 other bars.","img_size":{"width":2127,"height":872},"subfigures":[{"x":1070.9369372434937,"y":12.842954722373722,"width":1038.1809112251262,"height":731.8756566422156,"type":"interface","id":"interface-1"},{"x":9.725188899605152,"y":20.79660222368836,"width":1013.282128276812,"height":725.2915678491678,"type":"interface","id":"interface-2"}],"visualizations":[{"x":17.4487284659557,"y":46.89335520918787,"width":996.3223954060705,"height":689.2247744052501,"type":"heatmap","id":"heatmap-0"},{"x":1090.5455291222313,"y":55.617719442165715,"width":1001.5570139458572,"height":680.5004101722723,"type":"heatmap","id":"heatmap-1"},{"x":26.047677045785058,"y":53.788164648960674,"width":977.3594592094736,"height":678.1016563006409,"type":"others","id":"others-4"},{"x":1089.603642426542,"y":53.77958835592084,"width":1007.8149894800977,"height":672.4891122953225,"type":"others","id":"others-5"},{"x":17.448728465955714,"y":46.89335520918786,"width":998.067268252666,"height":689.2247744052502,"type":"matrix","id":"matrix-2"}],"relations":[{"vislist":[{"vislist":["others-4"],"relation":null,"id":"group-0"},{"vislist":["matrix-2"],"relation":null,"id":"group-1"}],"relation":"nested","id":"relation-0"}]},"1457_5":{"comp":[["scatterplot","matrix",["nested"]]],"visType":["scatterplot","matrix"],"compType":["nested"],"compressed_tree":[{"composite_pattern":"nested","visualization_type":[["scatterplot"],["matrix"]]}],"coOccurrence":[["scatterplot","matrix",["coOccurrence"]]],"year":2006,"conference":["VAST"],"authors":["Zaixian Xie","Shiping Huang","Matthew O. Ward","Elke A. Rundensteiner"],"title":"Exploratory Visualization of Multivariate Data with Variable Quality","doi":"10.1109/VAST.2006.261424","abstract":"Real-world data is known to be imperfect, suffering from various forms of defects such as sensor variability, estimation errors, uncertainty, human errors in data entry, and gaps in data gathering. Analysis conducted on variable quality data can lead to inaccurate or incorrect results. An effective visualization system must make users aware of the quality of their data by explicitly conveying not only the actual data content, but also its quality attributes. While some research has been conducted on visualizing uncertainty in spatio-temporal data and univariate data, little work has been reported on extending this capability into multivariate data visualization. In this paper we describe our approach to the problem of visually exploring multivariate data with variable quality. As a foundation, we propose a general approach to defining quality measures for tabular data, in which data may experience quality problems at three granularities: individual data values, complete records, and specific dimensions. We then present two approaches to visual mapping of quality information into display space. In particular, one solution embeds the quality measures as explicit values into the original dataset by regarding value quality and record quality as new data dimensions. The other solution is to superimpose the quality information within the data visualizations using additional visual variables. We also report on user studies conducted to assess alternate mappings of quality attributes to visual variables for the second method. In addition, we describe case studies that expose some of the advantages and disadvantages of these two approaches","keywords":"Uncertainty visualization, multivariate visualization,data quality","caption":"Figure 7: Interactive quality brushing (dataset:an adaptation of hipel- mcleod, red point: selected data point)","img_size":{"width":907,"height":720},"subfigures":[{"x":8.773042956450462,"y":8.110140541091951,"width":884.6738104255849,"height":702.9824712784716,"type":"single","id":"single-0"}],"visualizations":[{"x":4.534482758620584,"y":2.4588148512417023,"width":897.9310344827585,"height":707.5862068965517,"type":"scatterplot","id":"scatterplot-0"},{"x":5.913793103448199,"y":2.7586141125909216,"width":895.1724137931033,"height":707.5862068965516,"type":"matrix","id":"matrix-1"}],"relations":[{"vislist":[{"vislist":["scatterplot-0"],"relation":null,"id":"group-0"},{"vislist":["matrix-1"],"relation":null,"id":"group-1"}],"relation":"nested","id":"relation-0"}]},"1463_5":{"comp":[["map","graph",["nested"]]],"visType":["map","graph"],"compType":["nested"],"compressed_tree":[{"composite_pattern":"nested","visualization_type":[["map"],["graph"]]}],"coOccurrence":[["map","graph",["coOccurrence"]]],"year":2006,"conference":["VAST"],"authors":["David Gotz","Michelle X. Zhou","Vikram Aggarwal"],"title":"Interactive Visual Synthesis of Analytic Knowledge","doi":"10.1109/VAST.2006.261430","abstract":"A visual investigation involves both the examination of existing information and the synthesis of new analytic knowledge. This is a progressive process in which newly synthesized knowledge becomes the foundation for future discovery. In this paper, we present a novel system supporting interactive, progressive synthesis of analytic knowledge. Here we use the term \\"analytic knowledge\\" to refer to concepts that a user derives from existing data along with the evidence supporting such concepts. Unlike existing visual analytic-tools, which typically support only exploration of existing information, our system offers two unique features. First, we support user-system cooperative visual synthesis of analytic knowledge from existing data. Specifically, users can visually define new concepts by annotating existing information, and refine partially formed concepts by linking additional evidence or manipulating related concepts. In response to user actions, our system can automatically manage the evolving corpus of synthesized knowledge and its corresponding evidence. Second, we support progressive visual analysis of synthesized knowledge. This feature allows analysts to visually explore both existing knowledge and synthesized knowledge, dynamically incorporating earlier analytic conclusions into the ensuing discovery process. We have applied our system to two complex but very different analytic applications. Our preliminary evaluation shows the promise of our work","keywords":"Visual Analytics, Intelligence analysis, Problem solving environments, Visual Knowledge Discovery","caption":"Figure 6: HARVEST\u2019s discovery space supports multi-metaphor vi- sual composition as shown by this combination of timeline and map metaphors.","img_size":{"width":1006,"height":606},"subfigures":[{"x":4.246883565746178,"y":5.673589450162391,"width":998.564985290019,"height":598.8933017236265,"type":"single","id":"single-0"}],"visualizations":[{"x":270.4807238138143,"y":4.419709223556671,"width":730.3574734384589,"height":267.1159770706025,"type":"graph","id":"graph-2"},{"x":277.4018691588784,"y":2.21808688903392,"width":473.85046728971986,"height":269.96261142124644,"type":"map","id":"map-0"},{"x":804.1121495327104,"y":71.73831235582584,"width":198.22429906542064,"height":105.71962616822432,"type":"map","id":"map-1"},{"x":10.516725940435343,"y":272.90019576554386,"width":988.5159651233593,"height":184.4099434891266,"type":"others","id":"others-4"},{"x":11.368219476932271,"y":460.6132231475404,"width":979.7141440419059,"height":143.46457660099605,"type":"others","id":"others-5"}],"relations":[{"vislist":[{"vislist":["map-0","map-1"],"relation":null,"id":"group-0"},{"vislist":["graph-2"],"relation":null,"id":"group-1"}],"relation":"nested","id":"relation-0"}]},"1469_5":{"comp":[["scatterplot","scatterplot",["nested"]]],"visType":["scatterplot"],"compType":["nested"],"compressed_tree":[{"composite_pattern":"nested","visualization_type":[["scatterplot"],["scatterplot"]]}],"coOccurrence":[["scatterplot","scatterplot",["coOccurrence"]]],"year":2006,"conference":["VAST"],"authors":["Ling Xiao","John Gerth","Pat Hanrahan"],"title":"Enhancing Visual Analysis of Network Traffic Using a Knowledge Representation","doi":"10.1109/VAST.2006.261436","abstract":"This paper presents a network traffic analysis system that couples visual analysis with a declarative knowledge representation. The system supports multiple iterations of the sense-making loop of analytic reasoning by allowing users to save discoveries as they are found and to reuse them in future iterations. We show how the knowledge representation can be used to improve both the visual representations and the basic analytical tasks of filtering and changing level of detail. We describe how the system can be used to produce models of network patterns, and show results from classifying one day of network traffic in our laboratory","keywords":"network traffic visualization, visual analysis","caption":null,"img_size":{"width":1003,"height":370},"subfigures":[{"x":5.701118540423381,"y":6.993276221441206,"width":989.7167989243577,"height":349.4173780722385,"type":"single","id":"single-0"}],"visualizations":[{"x":17.56347717323327,"y":16.578799249530967,"width":964.1504447282947,"height":298.6919987131175,"type":"scatterplot","id":"scatterplot-0"},{"x":216.40712945590997,"y":43.55128205128205,"width":315.5153220762976,"height":153.68042526579114,"type":"scatterplot","id":"scatterplot-1"},{"x":541.331457160725,"y":45.06750299168127,"width":143.6441525953719,"height":218.61184320364896,"type":"scatterplot","id":"scatterplot-2"},{"x":917.6916823014384,"y":42.92401500938087,"width":65.23577235772348,"height":156.18949343339582,"type":"scatterplot","id":"scatterplot-3"},{"x":720.7298311444653,"y":44.17854909318325,"width":80.29018136335208,"height":31.36335209505941,"type":"scatterplot","id":"scatterplot-4"},{"x":800.3927454659163,"y":42.92401500938087,"width":57.70856785490935,"height":31.36335209505941,"type":"scatterplot","id":"scatterplot-5"},{"x":867.5103189493433,"y":47.942151344590364,"width":38.890556597873676,"height":26.972482801751102,"type":"scatterplot","id":"scatterplot-6"}],"relations":[{"vislist":[{"vislist":["scatterplot-1","scatterplot-2","scatterplot-3","scatterplot-4","scatterplot-5","scatterplot-6"],"relation":null,"id":"group-0"},{"vislist":["scatterplot-0"],"relation":null,"id":"group-1"}],"relation":"nested","id":"relation-0"}]},"1725_0":{"comp":[["bar_chart","table",["nested"]]],"visType":["bar_chart","table"],"compType":["nested"],"compressed_tree":[{"composite_pattern":"nested","visualization_type":[["bar_chart"],["table"]]}],"coOccurrence":[["bar_chart","table",["coOccurrence"]]],"year":2008,"conference":["VAST"],"authors":["Yedendra Babu Shrinivasan","Jarke J. van Wijk"],"title":"Supporting exploration awareness for visual analytics","doi":"10.1109/VAST.2008.4677378","abstract":"While exploring data using information visualization, analysts try to make sense of the data, build cases, and present them to others. However, if the exploration is long or done in multiple sessions, it can be hard for analysts to remember all interesting visualizations and the relationships among them they have seen. Often, they will see the same or similar visualizations, and are unable to recall when, why and how they have seen something similar. Recalling and retrieving interesting visualizations are important tasks for the analysis processes such as problem solving, reasoning, and conceptualization. In this paper, we argue that offering support for thinking based on past analysis processes is important, and present a solution for this.","keywords":"","caption":"Figure 1: The exploration of a weblog data using the Aruvi prototype. (a) associative search results; (c) detailed view of the similar visualizations that can be accessed via the \u2018similar visualization\u2019 button (b); (d) dynamic query interface for defining the similarity criteria; (e) analysis searcher interface for the direct search on the archived cues.","img_size":{"width":1944,"height":795},"subfigures":[{"x":6.982045334943635,"y":2.5141365685915855,"width":1934.288903950046,"height":784.6552752355557,"type":"interface","id":"interface-0"}],"visualizations":[{"x":616.9809160305342,"y":455.1526717557251,"width":671.6030534351144,"height":281.1832061068702,"type":"bar_chart","id":"bar_chart-0"},{"x":889.6769220959146,"y":111.43164715375644,"width":393.0846524944852,"height":187.5200261125982,"type":"flow_diagram","id":"flow_diagram-1"},{"x":243.93852908475708,"y":118.6012761194185,"width":579.975893781877,"height":612.8297401738969,"type":"scatterplot","id":"scatterplot-2"},{"x":1478.736641221374,"y":133.51145038167937,"width":440.99236641221364,"height":190.15267175572518,"type":"table","id":"table-3"},{"x":615.9956109737274,"y":453.61158742423385,"width":671.3896636587363,"height":280.6759639048397,"type":"table","id":"table-4"}],"relations":[{"vislist":[{"vislist":["bar_chart-0"],"relation":null,"id":"group-0"},{"vislist":["table-4"],"relation":null,"id":"group-1"}],"relation":"nested","id":"relation-0"}]},"3032_8":{"comp":[["scivis","matrix",["nested"]]],"visType":["scivis","matrix"],"compType":["nested"],"compressed_tree":[{"composite_pattern":"nested","visualization_type":[["scivis"],["matrix"]]}],"coOccurrence":[["scivis","matrix",["coOccurrence"]]],"year":2018,"conference":["SciVis"],"authors":["Hui Zhan","Steffen Frey","Holger Steeb","David Uribe","Thomas Ertl","Wenping Wang"],"title":"Visualization of Bubble Formation in Porous Media","doi":"10.1109/TVCG.2018.2864506","abstract":"We present a visualization approach for the analysis of CO<sub>2</sub>bubble-induced attenuation in porous rock formations. As a basis for this, we introduce customized techniques to extract CO<sub>2</sub>bubbles and their surrounding porous structure from X-ray computed tomography data (XCT) measurements. To understand how the structure of porous media influences the occurrence and the shape of formed bubbles, we automatically classify and relate them in terms of morphology and geometric features, and further directly support searching for promising porous structures. To allow for the meaningful direct visual comparison of bubbles and their structures, we propose a customized registration technique considering the bubble shape as well as its points of contact with the porous media surface. With our quantitative extraction of geometric bubble features, we further support the analysis as well as the creation of a physical model. We demonstrate that our approach was successfully used to answer several research questions in the domain, and discuss its high practical relevance to identify critical seismic characteristics of fluid-saturated rock that govern its capability to store CO<sub>2</sub>.","keywords":"3D volume rendering,bubble visualization,porous media","caption":"Fig. 8: Comparing bubbles to gain insights regarding underlying properties. (a) For each bubble, we automatically determine the most similar bubbles of the same morphology class. (b) We render and compare the registered results of the most similar bubble pair (e.g. 1 and 9) from different views. (c) Registration results for selected bubble pairs (gray boxes in (a)) using a standard method (dotted black box, top) and our approach (dotted red box, bottom). Dotted boxes indicate inadequate parts of the registration with the standard method. The similarity in the pore space geometry surrounding similar bubbles reinforces the idea of identifying a prototypical bubble per cluster (RQ3). The difference found between the bubbles can then be attributed to a scaling difference (RQ2). ","img_size":{"width":2114,"height":1534},"subfigures":[{"x":1071.0290159941949,"y":6.771479712478435,"width":1031.1298837120087,"height":1056.8088615525744,"type":"interface","id":"interface-1"},{"x":0.4996364635966651,"y":1108.932706721603,"width":2103.2085429523104,"height":382.1988855063461,"type":"interface","id":"interface-2"},{"x":6.221396464881494,"y":13.673720699844608,"width":1063.5856902975843,"height":1051.1671996310542,"type":"single","id":"single-0"}],"visualizations":[{"x":16.6266420888424,"y":18.05365662890509,"width":1036.2470763026638,"height":1029.3468156877952,"type":"matrix","id":"matrix-0"},{"x":16.765772730319423,"y":18.037011135867,"width":1047.3930298269552,"height":1026.1149786525839,"type":"scivis","id":"scivis-1"}],"relations":[{"vislist":[{"vislist":["scivis-1"],"relation":null,"id":"group-1"},{"vislist":["matrix-0"],"relation":null,"id":"group-0"}],"relation":"nested","id":"relation-0"}]},"3034_0":{"comp":[["scivis","matrix",["nested"]]],"visType":["scivis","matrix"],"compType":["nested"],"compressed_tree":[{"composite_pattern":"nested","visualization_type":[["scivis"],["matrix"]]}],"coOccurrence":[["scivis","matrix",["coOccurrence"]]],"year":2018,"conference":["SciVis"],"authors":["Antoni Sagrist\xe0","Stefan Jordan","Thomas M\xfclle","Filip Sadlo"],"title":"Gaia Sky: Navigating the Gaia Catalog","doi":"10.1109/TVCG.2018.2864508","abstract":"In this paper, we present Gaia Sky, a free and open-source multiplatform 3D Universe system, developed since 2014 in the Data Processing and Analysis Consortium framework of ESA\'s Gaia mission. Gaia\'s data release 2 represents the largest catalog of the stars of our Galaxy, comprising 1.3 billion star positions, with parallaxes, proper motions, magnitudes, and colors. In this mission, Gaia Sky is the central tool for off-the-shelf visualization of these data, and for aiding production of outreach material. With its capabilities to effectively handle these data, to enable seamless navigation along the high dynamic range of distances, and at the same time to provide advanced visualization techniques including relativistic aberration and gravitational wave effects, currently no actively maintained cross-platform, modern, and open alternative exists.","keywords":"Astronomy visualization,3D Universe software,star catalog rendering,Gaia mission","caption":"Fig. 1: Screenshot of Gaia Sky with Saturn and some of its moons, the Milky Way Star Clusters catalog indicated by yellowish spherical meshes, semi-transparent isosurfaces of OB star densities, and stars from Gaia showing parts of the Milky Way galaxy. ","img_size":{"width":1954,"height":532},"subfigures":[{"x":8.286833053277071,"y":7.217404654480781,"width":1939.4631536149946,"height":517.5651906910382,"type":"interface","id":"interface-0"}],"visualizations":[{"x":8.96094108541552,"y":110.77942900372918,"width":105.90459548890442,"height":78.94577634807818,"type":"bar_chart","id":"bar_chart-1"},{"x":6.269229484423236,"y":235.37549318504298,"width":116.5493918682918,"height":100.86319384714832,"type":"matrix","id":"matrix-2"},{"x":12.099755438623287,"y":15.748110689907227,"width":1919.9160631286409,"height":506.6934942791286,"type":"scivis","id":"scivis-0"},{"x":6.241012372106791,"y":230.50374446362034,"width":105.48584684954807,"height":104.41697563105123,"type":"scivis","id":"scivis-3"}],"relations":[{"vislist":[{"vislist":["scivis-3"],"relation":null,"id":"group-1"},{"vislist":["matrix-2"],"relation":null,"id":"group-0"}],"relation":"nested","id":"relation-0"}]},"3042_0":{"comp":[["heatmap","matrix",["nested"]]],"visType":["heatmap","matrix"],"compType":["nested"],"compressed_tree":[{"composite_pattern":"nested","visualization_type":[["heatmap"],["matrix"]]}],"coOccurrence":[["heatmap","matrix",["coOccurrence"]]],"year":2018,"conference":["SciVis"],"authors":["Jun Tao","Martin Imre","Chaoli Wang","Nitesh V. Chawla","Hanqi Guo","Gokhan Sever","Seung Hyun Kim"],"title":"Exploring Time-Varying Multivariate Volume Data Using Matrix of Isosurface Similarity Maps","doi":"10.1109/TVCG.2018.2864808","abstract":"We present a novel visual representation and interface named the matrix of isosurface similarity maps (MISM) for effective exploration of large time-varying multivariate volumetric data sets. MISM synthesizes three types of similarity maps (i.e., self, temporal, and variable similarity maps) to capture the essential relationships among isosurfaces of different variables and time steps. Additionally, it serves as the main visual mapping and navigation tool for examining the vast number of isosurfaces and exploring the underlying time-varying multivariate data set. We present temporal clustering, variable grouping, and interactive filtering to reduce the huge exploration space of MISM. In conjunction with the isovalue and isosurface views, MISM allows users to identify important isosurfaces or isosurface pairs and compare them over space, time, and value range. More importantly, we introduce path recommendation that suggests, animates, and compares traversal paths for effectively exploring MISM under varied criteria and at different levels-of-detail. A silhouette-based method is applied to render multiple surfaces of interest in a visually succinct manner. We demonstrate the effectiveness of our approach with case studies of several time-varying multivariate data sets and an ensemble data set, and evaluate our work with two domain experts.","keywords":"Time-varying multivariate data visualization,isosurface,similarity map,visual interface,path recommendation","caption":"Fig. 1. MISM interface. The cells in the similarity maps are colored purple/white/green for high/medium/low values. A path is specified to reveal the connections between the isosurfaces of variable U corresponding to four different wind directions using the atmospheric ensemble data set. (a) shows the parameter panel. (b) shows the matrix view with a user-specified path. A summarized view of the matrix is displayed on the left and the representative SSMs and VSMs related to the path are displayed on the right. (c) shows the isovalue view. The blue, orange, green, and red paths correspond to the isovalues of U under the west, east, south, and north wind directions, respectively. (d) and (e) show the isosurface view with surface silhouettes and original surfaces, respectively.","img_size":{"width":1749,"height":640},"subfigures":[{"x":5.604734038113546,"y":6.3693246846796505,"width":1740.5252282080567,"height":628.1726684678368,"type":"interface","id":"interface-0"}],"visualizations":[{"x":328.65654364442423,"y":34.0549337990461,"width":146.11876983342665,"height":580.7352755508679,"type":"heatmap","id":"heatmap-4"},{"x":480.3894873578458,"y":37.38630203907605,"width":321.5195559341322,"height":582.9176822197674,"type":"line_chart","id":"line_chart-3"},{"x":335.6734406713551,"y":42.86191704549895,"width":148.67389056689484,"height":575.2833808877817,"type":"matrix","id":"matrix-0"},{"x":804.6747774347915,"y":39.65414158875639,"width":622.9408292679208,"height":590.5440749502277,"type":"scivis","id":"scivis-1"},{"x":1407.4298512681485,"y":299.29564526812817,"width":338.6684161241829,"height":323.34764733684364,"type":"scivis","id":"scivis-2"}],"relations":[{"vislist":[{"vislist":["heatmap-4"],"relation":null,"id":"group-1"},{"vislist":["matrix-0"],"relation":null,"id":"group-0"}],"relation":"nested","id":"relation-0"}]},"2033_13":{"comp":[["scivis","matrix",["nested"]]],"visType":["scivis","matrix"],"compType":["nested"],"compressed_tree":[{"composite_pattern":"nested","visualization_type":[["scivis"],["matrix"]]}],"coOccurrence":[["scivis","matrix",["coOccurrence"]]],"year":2010,"conference":["Vis"],"authors":["Zahid Hossai","Torsten M\xf6ller"],"title":"Edge Aware Anisotropic Diffusion for 3D Scalar Data","doi":"10.1109/TVCG.2010.147","abstract":"In this paper we present a novel anisotropic diffusion model targeted for 3D scalar field data. Our model preserves material boundaries as well as fine tubular structures while noise is smoothed out. One of the major novelties is the use of the directional second derivative to define material boundaries instead of the gradient magnitude for thresholding. This results in a diffusion model that has much lower sensitivity to the diffusion parameter and smoothes material boundaries consistently compared to gradient magnitude based techniques. We empirically analyze the stability and convergence of the proposed diffusion and demonstrate its de-noising capabilities for both analytic and real data. We also discuss applications in the context of volume rendering.","keywords":"Anisotropic diffusion, PDE, De-noising, Scale-Space, Principal Curvatures","caption":"Fig. 12: Comparison of x = 90 slice of the synthetic MRI data for each type of noise after diffusing with three different methods. The image in the first row is taken from the original volume. After that, each row, going from top to bottom, corresponds to a particular noise type: Gaussian,Rician, Poisson, Speckle and Salt and Pepper respectively. Images in the first column are taken from the noisy volumes, while those in the second, third and fourth columns are taken from the volumes diffused with our, SRNRAD, and ORNRAD filters respectively.","img_size":{"width":2072,"height":2411},"subfigures":[{"x":15.612444905514083,"y":11.502256696160646,"width":2037.4823186668903,"height":2391.2886826221297,"type":"single","id":"single-0"}],"visualizations":[{"x":28.60299498517116,"y":430.44125280615,"width":2011.5012185075786,"height":1951.887408150893,"type":"matrix","id":"matrix-0"},{"x":58.04295768866695,"y":479.250890548335,"width":1985.549208321376,"height":1857.561328680972,"type":"scivis","id":"scivis-1"},{"x":830.6459958293784,"y":13.433443341473655,"width":443.6359235620303,"height":365.40395645773833,"type":"scivis","id":"scivis-2"}],"relations":[{"vislist":[{"vislist":["scivis-1"],"relation":null,"id":"group-0"},{"vislist":["matrix-0"],"relation":null,"id":"group-1"}],"relation":"nested","id":"relation-0"}]},"2795_3":{"comp":[["stripe_graph","graph",["nested"]]],"visType":["stripe_graph","graph"],"compType":["nested"],"compressed_tree":[{"composite_pattern":"nested","visualization_type":[["stripe_graph"],["graph"]]}],"coOccurrence":[["stripe_graph","graph",["coOccurrence"]]],"year":2016,"conference":["SciVis"],"authors":["Chris Bryan","Gregory Guterman","Kwan-Liu Ma","Harris Lewin","Denis Larkin","Jaebum Kim","Jian M","Marta Farre"],"title":"Synteny Explorer: An Interactive Visualization Application for Teaching Genome Evolution","doi":"10.1109/TVCG.2016.2598789","abstract":"Rapid advances in biology demand new tools for more active research dissemination and engaged teaching. This paper presents Synteny Explorer, an interactive visualization application designed to let college students explore genome evolution of mammalian species. The tool visualizes synteny blocks: segments of homologous DNA shared between various extant species that can be traced back or reconstructed in extinct, ancestral species. We take a karyogram-based approach to create an interactive synteny visualization, leading to a more appealing and engaging design for undergraduate-level genome evolution education. For validation, we conduct three user studies: two focused studies on color and animation design choices and a larger study that performs overall system usability testing while comparing our karyogram-based designs with two more common genome mapping representations in an educational context. While existing views communicate the same information, study participants found the interactive, karyogram-based views much easier and likable to use. We additionally discuss feedback from biology and genomics faculty, who judge Synteny Explorer\'s fitness for use in classrooms.","keywords":"Bioinformatic visualization;education;learning;genome evolution;chromosome;user study","caption":"Fig.2: The Genome View shows the chromosomes and synteny map- pings of selected species. In this example, the Static mapping is used with the Faded color palette.","img_size":{"width":953,"height":556},"subfigures":[{"x":6.121310797582504,"y":7.113772326727039,"width":936.1995174797627,"height":534.9374686786402,"type":"interface","id":"interface-0"}],"visualizations":[{"x":16.06720796331956,"y":13.724506143952782,"width":766.194269330447,"height":468.0825932922579,"type":"graph","id":"graph-0"},{"x":19.407137307057837,"y":12.880950285399416,"width":761.1956205858274,"height":467.2501885752048,"type":"stripe_graph","id":"stripe_graph-1"}],"relations":[{"vislist":[{"vislist":["stripe_graph-1"],"relation":null,"id":"group-0"},{"vislist":["graph-0"],"relation":null,"id":"group-1"}],"relation":"nested","id":"relation-0"}]},"2207_2":{"comp":[["others","map",["coordinated"]]],"visType":["others","map"],"compType":["coordinated"],"compressed_tree":[{"composite_pattern":"coordinated","visualization_type":[["others"],["map"]]}],"coOccurrence":[["others","map",["coOccurrence"]]],"year":2011,"conference":["Vis"],"authors":["Lyn Bartram","Billy Cheung","Maureen C. Stone"],"title":"The Effect of Colour and Transparency on the Perception of Overlaid Grids","doi":"10.1109/TVCG.2011.242","abstract":"Overlaid reference elements need to be sufficiently visible to effectively relate to the underlying information, but not so obtrusive that they clutter the presentation. We seek to create guidelines for presenting such structures through experimental studies to define boundary conditions for visual intrusiveness. We base our work on the practice of designers, who use transparency to integrate overlaid grids with their underlying imagery. Previous work discovered a useful range of alpha values for black or white grids overlayed on scatterplot images rendered in shades of gray over gray backgrounds of different lightness values. This work compares black grids to blue and red ones on different image types of scatterplots and maps. We expected that the coloured grids over grayscale images would be more visually salient than black ones, resulting in lower alpha values. Instead, we found that there was no significant difference between the boundaries set for red and black grids, but that the boundaries for blue grids were set consistently higher (more opaque). As in our previous study, alpha values are affected by image density rather than image type, and are consistently lower than many default settings. These results have implications for the design of subtle reference structures.","keywords":"Information visualization, automated presentation, applied perception, visual design, computational aesthetics","caption":"Fig. 2. One of the training images with a faint blue grid, showing the experimental setup. ","img_size":{"width":1024,"height":942},"subfigures":[{"x":13.953351112844135,"y":11.230613420377523,"width":993.0881415787771,"height":896.480668951566,"type":"interface","id":"interface-0"}],"visualizations":[{"x":17.907891765336153,"y":39.59718591951195,"width":981.1721853464109,"height":743.505002042982,"type":"map","id":"map-0"},{"x":259.7937897062848,"y":41.52314718906741,"width":645.6547617775796,"height":726.6202379951835,"type":"others","id":"others-1"}],"relations":[{"vislist":[{"vislist":["others-1"],"relation":null,"id":"group-1"},{"vislist":["map-0"],"relation":null,"id":"group-0"}],"relation":"coordinated","id":"relation-0"}]},"2411_7":{"comp":[["others","scivis",["coordinated"]],["scivis","others",["coordinated"]]],"visType":["others","scivis"],"compType":["coordinated"],"compressed_tree":[{"composite_pattern":"coordinated","visualization_type":[["others"],["scivis"]]},{"composite_pattern":"coordinated","visualization_type":[["scivis"],["others"]]}],"coOccurrence":[["others","scivis",["coOccurrence"]]],"year":2013,"conference":["SciVis"],"authors":["Dane M. Coffey","Chi-Lun Lin","Arthur G. Erdman","Daniel F. Keefe"],"title":"Design by Dragging: An Interface for Creative Forward and Inverse Design with Simulation Ensembles","doi":"10.1109/TVCG.2013.147","abstract":"We present an interface for exploring large design spaces as encountered in simulation-based engineering, design of visual effects, and other tasks that require tuning parameters of computationally-intensive simulations and visually evaluating results. The goal is to enable a style of design with simulations that feels as-direct-as-possible so users can concentrate on creative design tasks. The approach integrates forward design via direct manipulation of simulation inputs (e.g., geometric properties, applied forces) in the same visual space with inverse design via \'tugging\' and reshaping simulation outputs (e.g., scalar fields from finite element analysis (FEA) or computational fluid dynamics (CFD)). The interface includes algorithms for interpreting the intent of users\' drag operations relative to parameterized models, morphing arbitrary scalar fields output from FEA and CFD simulations, and in-place interactive ensemble visualization. The inverse design strategy can be extended to use multi-touch input in combination with an as-rigid-as-possible shape manipulation to support rich visual queries. The potential of this new design approach is confirmed via two applications: medical device engineering of a vacuum-assisted biopsy device and visual effects design using a physically based flame simulation.","keywords":"Design, simulation, direct manipulation, multi-touch","caption":"Fig. 7. Left: In multi-touch inverse design, a control mesh is generated interactively when the user selects an iso-contour of the simulation data. Right: The mesh is reshaped based on simultaneous input from multiple fingers to create a detailed inverse query into the result space. This example comes from the flame simulation described in Section9.","img_size":{"width":1051,"height":740},"subfigures":[{"x":6.571612250421925,"y":6.562568811735536,"width":1039.4306087391285,"height":727.6624095524589,"type":"interface","id":"interface-0"}],"visualizations":[{"x":531.4148079238622,"y":13.585062292159684,"width":511.469936443018,"height":713.6174225916101,"type":"others","id":"others-0"},{"x":19.105663533147773,"y":25.53142088467818,"width":478.4722879631576,"height":392.819420081251,"type":"others","id":"others-2"},{"x":15.90067389845985,"y":13.10581088087528,"width":500.6205996322536,"height":423.97101749629053,"type":"scivis","id":"scivis-1"},{"x":532.2079762720062,"y":11.200169335505477,"width":512.2443496066865,"height":708.1490952178383,"type":"scivis","id":"scivis-3"}],"relations":[{"vislist":[{"vislist":["others-2"],"relation":null,"id":"group-1"},{"vislist":["scivis-1"],"relation":null,"id":"group-0"}],"relation":"coordinated","id":"relation-0"},{"vislist":[{"vislist":["scivis-3"],"relation":null,"id":"group-3"},{"vislist":["others-0"],"relation":null,"id":"group-2"}],"relation":"coordinated","id":"relation-1"}]},"1934_8":{"comp":[["heatmap","scivis",["coordinated"]]],"visType":["heatmap","scivis"],"compType":["coordinated"],"compressed_tree":[{"composite_pattern":"coordinated","visualization_type":[["heatmap"],["scivis"]]}],"coOccurrence":[["heatmap","scivis",["coOccurrence"]]],"year":2009,"conference":["Vis"],"authors":["Emanuele Santos","Lauro Didier Lins","James P. Ahrens","Juliana Freire","Cl\xe1udio T. Silva"],"title":"VisMashup: Streamlining the Creation of Custom Visualization Applications","doi":"10.1109/TVCG.2009.195","abstract":"Visualization is essential for understanding the increasing volumes of digital data. However, the process required to create insightful visualizations is involved and time consuming. Although several visualization tools are available, including tools with sophisticated visual interfaces, they are out of reach for users who have little or no knowledge of visualization techniques and/or who do not have programming expertise. In this paper, we propose VisMashup, a new framework for streamlining the creation of customized visualization applications. Because these applications can be customized for very specific tasks, they can hide much of the complexity in a visualization specification and make it easier for users to explore visualizations by manipulating a small set of parameters. We describe the framework and how it supports the various tasks a designer needs to carry out to develop an application, from mining and exploring a set of visualization specifications (pipelines), to the creation of simplified views of the pipelines, and the automatic generation of the application and its interface. We also describe the implementation of the system and demonstrate its use in two real application scenarios.","keywords":"Scientific Visualization, Dataflow, Visualization Systems","caption":"Fig. 9:  Neuroscience VISMASHUP.  This mashup combines two pipelines\u2014one that produces a plot of a single EEG sensor\u2019s raw data and its S-Transformed representation, and another that creates a vol- ume rendered visualization. To ensure that the plots and the visualiza- tion are derived for the same patient, the variables in the pipeline views corresponding to the patient (i.e., the input data set) are synchronized.","img_size":{"width":1013,"height":328},"subfigures":[{"x":7.450352242403777,"y":7.123272876805778,"width":999.6831990806452,"height":315.33900802344033,"type":"interface","id":"interface-0"}],"visualizations":[{"x":382.06037717818685,"y":141.12744061559096,"width":359.0521504229278,"height":116.26238659379197,"type":"heatmap","id":"heatmap-1"},{"x":11.671206682247327,"y":30.15276461558336,"width":356.16338415452316,"height":228.58944042952933,"type":"heatmap","id":"heatmap-3"},{"x":385.2720933169931,"y":25.923747212500306,"width":360.31519987410337,"height":111.39852529301446,"type":"line_chart","id":"line_chart-0"},{"x":11.047054685555132,"y":27.594302294042286,"width":361.8954691563664,"height":228.57783650352224,"type":"scivis","id":"scivis-2"}],"relations":[{"vislist":[{"vislist":["heatmap-3"],"relation":null,"id":"group-1"},{"vislist":["scivis-2"],"relation":null,"id":"group-0"}],"relation":"coordinated","id":"relation-0"}]},"1935_13":{"comp":[["heatmap","scivis",["coordinated"]]],"visType":["heatmap","scivis"],"compType":["coordinated"],"compressed_tree":[{"composite_pattern":"coordinated","visualization_type":[["heatmap"],["scivis"]]}],"coOccurrence":[["heatmap","scivis",["coOccurrence"]]],"year":2009,"conference":["Vis"],"authors":["Heike Leitte","Michael B\xf6ttinger","Uwe Mikolajewicz","Gerik Scheuermann"],"title":"Visual Exploration of Climate Variability Changes Using Wavelet Analysis","doi":"10.1109/TVCG.2009.197","abstract":"Due to its nonlinear nature, the climate system shows quite high natural variability on different time scales, including multiyear oscillations such as the El Nino southern oscillation phenomenon. Beside a shift of the mean states and of extreme values of climate variables, climate change may also change the frequency or the spatial patterns of these natural climate variations. Wavelet analysis is a well established tool to investigate variability in the frequency domain. However, due to the size and complexity of the analysis results, only few time series are commonly analyzed concurrently. In this paper we will explore different techniques to visually assist the user in the analysis of variability and variability changes to allow for a holistic analysis of a global climate model data set consisting of several variables and extending over 250 years. Our new framework and data from the IPCC AR4 simulations with the coupled climate model ECHAM5/MPI-OM are used to explore the temporal evolution of El Nino due to climate change.","keywords":"Wavelet analysis, multivariate data, time-dependent data, climate variability change visualization, El Nino","caption":"Fig. 14. Visualization of global changes for U10M (DJF): height encodes the mean U10M of the years 1961 \u2013 1990, color encodes the projected change for the U10M wind for 2071 \u2013 2100 relative to the same period.","img_size":{"width":1056,"height":749},"subfigures":[{"x":3.7770308659466902,"y":6.656008564588005,"width":1050.0398305525723,"height":739.6736101327904,"type":"interface","id":"interface-0"}],"visualizations":[{"x":12.450641484574337,"y":22.377397564375222,"width":1022.3323094662983,"height":691.4911976329577,"type":"heatmap","id":"heatmap-1"},{"x":6.905828122703046,"y":16.15757787127704,"width":1032.6249900478085,"height":726.2503496861648,"type":"scivis","id":"scivis-0"}],"relations":[{"vislist":[{"vislist":["heatmap-1"],"relation":null,"id":"group-1"},{"vislist":["scivis-0"],"relation":null,"id":"group-0"}],"relation":"coordinated","id":"relation-0"}]},"2267_6":{"comp":[["bar_chart","map",["coordinated"]],["scatterplot","map",["coordinated"]]],"visType":["bar_chart","map","scatterplot"],"compType":["coordinated"],"compressed_tree":[{"composite_pattern":"coordinated","visualization_type":[["bar_chart"],["map"]]},{"composite_pattern":"coordinated","visualization_type":[["scatterplot"],["map"]]}],"coOccurrence":[["bar_chart","map",["coOccurrence"]]],"year":2012,"conference":["SciVis"],"authors":["Andrea Unger","Sven Schulte","Volker Klemann","Doris Dransch"],"title":"A Visual Analysis Concept for the Validation of Geoscientific Simulation Models","doi":"10.1109/TVCG.2012.190","abstract":"Geoscientific modeling and simulation helps to improve our understanding of the complex Earth system. During the modeling process, validation of the geoscientific model is an essential step. In validation, it is determined whether the model output shows sufficient agreement with observation data. Measures for this agreement are called goodness of fit. In the geosciences, analyzing the goodness of fit is challenging due to its manifold dependencies: 1) The goodness of fit depends on the model parameterization, whose precise values are not known. 2) The goodness of fit varies in space and time due to the spatio-temporal dimension of geoscientific models. 3) The significance of the goodness of fit is affected by resolution and preciseness of available observational data. 4) The correlation between goodness of fit and underlying modeled and observed values is ambiguous. In this paper, we introduce a visual analysis concept that targets these challenges in the validation of geoscientific models - specifically focusing on applications where observation data is sparse, unevenly distributed in space and time, and imprecise, which hinders a rigorous analytical approach. Our concept, developed in close cooperation with Earth system modelers, addresses the four challenges by four tailored visualization components. The tight linking of these components supports a twofold interactive drill-down in model parameter space and in the set of data samples, which facilitates the exploration of the numerous dependencies of the goodness of fit. We exemplify our visualization concept for geoscientific modeling of glacial isostatic adjustments in the last 100,000 years, validated against sea levels indicators - a prominent example for sparse and imprecise observation data. An initial use case and feedback from Earth system modelers indicate that our visualization concept is a valuable complement to the range of validation methods.","keywords":"Earth science visualization, model validation, coordinated multiple views, spatio-temporal visualization, sea level indicators","caption":"Fig. 7.  Exploration of spatio-temporal variations of goodness of fit for one model parameterization. Left: Individual samples are shown in the region of interest (here:  Hudson Bay).   The color corresponds to the goodness of fit of each sample, the color of the bounding box to the av- erage goodness of fit of the region.  Right:  Average goodness of fit for geologically meaningful spatial regions are shown. The symbol commu- nicates temporal variations in goodness of fit within the region.","img_size":{"width":1044,"height":383},"subfigures":[{"x":3.5157864122876825,"y":5.840222051097823,"width":510.7178252665555,"height":373.5936679933239,"type":"single","id":"single-0"},{"x":526.7314597765842,"y":4.316706378038462,"width":514.5128238460069,"height":373.6085498787499,"type":"single","id":"single-1"}],"visualizations":[{"x":633.366906667612,"y":81.50957332007452,"width":203.6302016170576,"height":91.06314101906943,"type":"bar_chart","id":"bar_chart-3"},{"x":8.121694764643383,"y":11.12825613390334,"width":502.85922705213926,"height":347.8517164981154,"type":"map","id":"map-0"},{"x":531.1526225304984,"y":12.056649779013036,"width":502.90864794762285,"height":348.75745161519825,"type":"map","id":"map-2"},{"x":67.2387732796693,"y":21.001130436753854,"width":354.23627413996013,"height":324.4226046826777,"type":"scatterplot","id":"scatterplot-1"}],"relations":[{"vislist":[{"vislist":["bar_chart-3"],"relation":null,"id":"group-0"},{"vislist":["map-2"],"relation":null,"id":"group-1"}],"relation":"coordinated","id":"relation-0"},{"vislist":[{"vislist":["scatterplot-1"],"relation":null,"id":"group-2"},{"vislist":["map-0"],"relation":null,"id":"group-3"}],"relation":"coordinated","id":"relation-1"}]},"2267_7":{"comp":[["scatterplot","map",["coordinated"]]],"visType":["scatterplot","map"],"compType":["coordinated"],"compressed_tree":[{"composite_pattern":"coordinated","visualization_type":[["scatterplot"],["map"]]}],"coOccurrence":[["scatterplot","map",["coOccurrence"]]],"year":2012,"conference":["SciVis"],"authors":["Andrea Unger","Sven Schulte","Volker Klemann","Doris Dransch"],"title":"A Visual Analysis Concept for the Validation of Geoscientific Simulation Models","doi":"10.1109/TVCG.2012.190","abstract":"Geoscientific modeling and simulation helps to improve our understanding of the complex Earth system. During the modeling process, validation of the geoscientific model is an essential step. In validation, it is determined whether the model output shows sufficient agreement with observation data. Measures for this agreement are called goodness of fit. In the geosciences, analyzing the goodness of fit is challenging due to its manifold dependencies: 1) The goodness of fit depends on the model parameterization, whose precise values are not known. 2) The goodness of fit varies in space and time due to the spatio-temporal dimension of geoscientific models. 3) The significance of the goodness of fit is affected by resolution and preciseness of available observational data. 4) The correlation between goodness of fit and underlying modeled and observed values is ambiguous. In this paper, we introduce a visual analysis concept that targets these challenges in the validation of geoscientific models - specifically focusing on applications where observation data is sparse, unevenly distributed in space and time, and imprecise, which hinders a rigorous analytical approach. Our concept, developed in close cooperation with Earth system modelers, addresses the four challenges by four tailored visualization components. The tight linking of these components supports a twofold interactive drill-down in model parameter space and in the set of data samples, which facilitates the exploration of the numerous dependencies of the goodness of fit. We exemplify our visualization concept for geoscientific modeling of glacial isostatic adjustments in the last 100,000 years, validated against sea levels indicators - a prominent example for sparse and imprecise observation data. An initial use case and feedback from Earth system modelers indicate that our visualization concept is a valuable complement to the range of validation methods.","keywords":"Earth science visualization, model validation, coordinated multiple views, spatio-temporal visualization, sea level indicators","caption":"Fig. 8. Multiple linked views concept to analyze unevenly distributed and imprecise observation data. Each view offers a different perspective on the data. A - Data view: A time value plot shows observed value ranges along with imprecise age ranges of samples. B - Temporal View: A temporal histogram communicates temporal distribution of samples. C - Geospatial View: A map (or globe) shows the uneven coverage of data samples in geospatial context. D - Attribute View: Additional attributes provided in a table convey important geological information. E - Hierar- chy View: An explicit visualization of the spatial hierarchy supports fast overview and selection of observations. Color used throughout views in- dicates the categorization of observation samples by their type of value range. ","img_size":{"width":1052,"height":583},"subfigures":[{"x":8.506338101709959,"y":9.885781488060498,"width":1038.9693213757273,"height":568.0063713492843,"type":"interface","id":"interface-0"}],"visualizations":[{"x":8.403398181290921,"y":149.8719108163641,"width":309.55264937134086,"height":143.23827385022554,"type":"bar_chart","id":"bar_chart-1"},{"x":8.400100234363851,"y":312.7584887169196,"width":308.631316167667,"height":252.35516585371568,"type":"map","id":"map-4"},{"x":9.327803659379766,"y":11.593035779339349,"width":309.55969661021555,"height":136.9784022176577,"type":"others","id":"others-0"},{"x":6.544725901148647,"y":316.4653386593408,"width":306.7744902489356,"height":250.5050913139213,"type":"scatterplot","id":"scatterplot-5"},{"x":321.3278950154353,"y":30.87368514373389,"width":497.4974742341909,"height":532.3798804026283,"type":"table","id":"table-3"},{"x":834.8215004629051,"y":13.409816942231869,"width":208.213895873182,"height":553.3985534430126,"type":"tree","id":"tree-2"}],"relations":[{"vislist":[{"vislist":["scatterplot-5"],"relation":null,"id":"group-0"},{"vislist":["map-4"],"relation":null,"id":"group-1"}],"relation":"coordinated","id":"relation-0"}]},"2298_0":{"comp":[["scatterplot","map",["coordinated"]]],"visType":["scatterplot","map"],"compType":["coordinated"],"compressed_tree":[{"composite_pattern":"coordinated","visualization_type":[["scatterplot"],["map"]]}],"coOccurrence":[["scatterplot","map",["coOccurrence"]]],"year":2012,"conference":["SciVis"],"authors":["Joerg Meyer","E. Wes Bethel","Jennifer L. Horsman","Susan S. Hubbard","Harinarayan Krishnan","Alexandru Romosan","Elizabeth H. Keating","Laura Monroe","Richard Strelitz","Phil Moore","Glenn Taylor","Ben Torkian","Timothy C. Johnson","Ian Gorton"],"title":"Visual Data Analysis as an Integral Part of Environmental Management","doi":"10.1109/TVCG.2012.278","abstract":"The U.S. Department of Energy\'s (DOE) Office of Environmental Management (DOE/EM) currently supports an effort to understand and predict the fate of nuclear contaminants and their transport in natural and engineered systems. Geologists, hydrologists, physicists and computer scientists are working together to create models of existing nuclear waste sites, to simulate their behavior and to extrapolate it into the future. We use visualization as an integral part in each step of this process. In the first step, visualization is used to verify model setup and to estimate critical parameters. High-performance computing simulations of contaminant transport produces massive amounts of data, which is then analyzed using visualization software specifically designed for parallel processing of large amounts of structured and unstructured data. Finally, simulation results are validated by comparing simulation results to measured current and historical field data. We describe in this article how visual analysis is used as an integral part of the decision-making process in the planning of ongoing and future treatment options for the contaminated nuclear waste sites. Lessons learned from visually analyzing our large-scale simulation runs will also have an impact on deciding on treatment measures for other contaminated sites.","keywords":"Visual analytics, high-performance computing, data management, parallel rendering, environmental management","caption":"Fig. 1. Plan view map of the oil and groundwater U-238 contamination at Savannah River Site (SRS F-area, upper aquifer zone) in (a) 1994, (b) 2001 and (c) 2008, displayed in a web browser as a Google Maps bitmap overlay created in VisIt [1].","img_size":{"width":1961,"height":585},"subfigures":[{"x":9.890371268803445,"y":9.94049815832833,"width":626.563852890555,"height":565.1190036833431,"type":"interface","id":"interface-0"}],"visualizations":[{"x":26.05924834933141,"y":69.60797138469998,"width":592.5620368084464,"height":492.58575898278525,"type":"heatmap","id":"heatmap-2"},{"x":19.184769932421016,"y":66.30280890572644,"width":597.6623769110388,"height":504.39627302430915,"type":"map","id":"map-0"},{"x":17.5046059107833,"y":67.92025778524928,"width":609.671321685541,"height":495.9611861816864,"type":"scatterplot","id":"scatterplot-1"}],"relations":[{"vislist":[{"vislist":["scatterplot-1"],"relation":null,"id":"group-0"},{"vislist":["map-0"],"relation":null,"id":"group-1"}],"relation":"coordinated","id":"relation-0"}]},"1620_8":{"comp":[["error_bar","contour_graph",["coordinated"]],["graph","contour_graph",["coordinated"]]],"visType":["error_bar","contour_graph","graph"],"compType":["coordinated"],"compressed_tree":[{"composite_pattern":"coordinated","visualization_type":[["error_bar"],["contour_graph"]]},{"composite_pattern":"coordinated","visualization_type":[["graph"],["contour_graph"]]}],"coOccurrence":[["graph","contour_graph",["coOccurrence"]]],"year":2007,"conference":["Vis"],"authors":["Hongwei Li","Chi-Wing Fu","Yinggang Li","Andrew J. Hanson"],"title":"Visualizing Large-Scale Uncertainty in Astrophysical Data","doi":"10.1109/TVCG.2007.70530","abstract":"Visualization of uncertainty or error in astrophysical data is seldom available in simulations of astronomical phenomena, and yet almost all rendered attributes possess some degree of uncertainty due to observational error. Uncertainties associated with spatial location typically vary significantly with scale and thus introduce further complexity in the interpretation of a given visualization. This paper introduces effective techniques for visualizing uncertainty in large-scale virtual astrophysical environments. Building upon our previous transparently scalable visualization architecture, we develop tools that enhance the perception and comprehension of uncertainty across wide scale ranges. Our methods include a unified color-coding scheme for representing log-scale distances and percentage errors, an ellipsoid model to represent positional uncertainty, an ellipsoid envelope model to expose trajectory uncertainty, and a magic-glass design supporting the selection of ranges of log-scale distance and uncertainty parameters, as well as an overview mode and a scalable WIM tool for exposing the magnitudes of spatial context and uncertainty.","keywords":"Uncertainty visualization, large spatial scale, interstellar data, astronomy","caption":"Fig. 9. The log-sky visualization mode; Left: positional uncertainty (error bars) of stars; Right: positional uncertainty of constellation lines plotted in 3D; Middle: two zoomed views. ","img_size":{"width":2134,"height":860},"subfigures":[{"x":6.382934740404253,"y":5.387255834080982,"width":846.6248711757856,"height":850.3372051341937,"type":"single","id":"single-0"},{"x":1276.5661695518452,"y":7.59168978407126,"width":854.3646957551191,"height":847.0400540365697,"type":"single","id":"single-1"}],"visualizations":[{"x":14.02189830245242,"y":19.73311000275001,"width":829.4513826698593,"height":831.3332562885655,"type":"contour_graph","id":"contour_graph-0"},{"x":1279.7859462578647,"y":11.691767944675659,"width":845.535444823771,"height":839.3163331841648,"type":"contour_graph","id":"contour_graph-3"},{"x":30.06079604667704,"y":45.00230078664052,"width":785.2292495635209,"height":776.7450711105112,"type":"error_bar","id":"error_bar-1"},{"x":1321.2512770192814,"y":48.81425888823868,"width":753.159187375907,"height":742.1224641721486,"type":"graph","id":"graph-4"}],"relations":[{"vislist":[{"vislist":["error_bar-1"],"relation":null,"id":"group-1"},{"vislist":["contour_graph-0"],"relation":null,"id":"group-0"}],"relation":"coordinated","id":"relation-0"},{"vislist":[{"vislist":["graph-4"],"relation":null,"id":"group-3"},{"vislist":["contour_graph-3"],"relation":null,"id":"group-2"}],"relation":"coordinated","id":"relation-1"}]},"1627_13":{"comp":[["others","map",["coordinated"]]],"visType":["others","map"],"compType":["coordinated"],"compressed_tree":[{"composite_pattern":"coordinated","visualization_type":[["others"],["map"]]}],"coOccurrence":[["others","map",["coOccurrence"]]],"year":2007,"conference":["Vis"],"authors":["Yi Wang","David M. Krum","Enylton Machado Coelho","Doug A. Bowman"],"title":"Contextualized Videos: Combining Videos with Environment Models to Support Situational Understanding","doi":"10.1109/TVCG.2007.70544","abstract":"Multiple spatially-related videos are increasingly used in security, communication, and other applications. Since it can be difficult to understand the spatial relationships between multiple videos in complex environments (e.g. to predict a person\'s path through a building), some visualization techniques, such as video texture projection, have been used to aid spatial understanding. In this paper, we identify and begin to characterize an overall class of visualization techniques that combine video with 3D spatial context. This set of techniques, which we call contextualized videos, forms a design palette which must be well understood so that designers can select and use appropriate techniques that address the requirements of particular spatial video tasks. In this paper, we first identify user tasks in video surveillance that are likely to benefit from contextualized videos and discuss the video, model, and navigation related dimensions of the contextualized video design space. We then describe our contextualized video testbed which allows us to explore this design space and compose various video visualizations for evaluation. Finally, we describe the results of our process to identify promising design patterns through user selection of visualization features from the design space, followed by user interviews.","keywords":"situational awareness, videos, virtual environment models, design space, testbed design and evaluation","caption":"Fig. 14: Usage Patterns: (a) Pattern 2, 2D billboard + landmark view + explosion. (b) Pattern 2, Billboard + semi transparency. (c) Pattern 3, associated video + fixed plane video + landmark. (d) A view behind the camera used in Pattern 5.  (e) Pattern 6, video projection + walls.","img_size":{"width":1032,"height":1791},"subfigures":[{"x":4.018102332196302,"y":6.786164003146933,"width":546.1118334118705,"height":530.8533033094099,"type":"interface","id":"interface-0"}],"visualizations":[{"x":5.2141407259985115,"y":57.76526118607414,"width":538.0083785933049,"height":474.6409573356444,"type":"map","id":"map-0"},{"x":-1.6196667060255587,"y":17.8428819524729,"width":551.6759934573541,"height":455.36971095332683,"type":"others","id":"others-1"}],"relations":[{"vislist":[{"vislist":["others-1"],"relation":null,"id":"group-1"},{"vislist":["map-0"],"relation":null,"id":"group-0"}],"relation":"coordinated","id":"relation-0"}]},"3260_7":{"comp":[["graph","glyph_based",["coordinated"]]],"visType":["graph","glyph_based"],"compType":["coordinated"],"compressed_tree":[{"composite_pattern":"coordinated","visualization_type":[["graph"],["glyph_based"]]}],"coOccurrence":[["graph","glyph_based",["coOccurrence"]]],"year":2020,"conference":["InfoVis"],"authors":["Wouter Meulemans","Max Sondag","Bettina Speckmann"],"title":"A Simple Pipeline for Coherent Grid Maps","doi":"10.1109/TVCG.2020.3028953","abstract":"Grid maps are spatial arrangements of simple tiles (often squares or hexagons), each of which represents a spatial element. They are an established, effective way to show complex data per spatial element, using visual encodings within each tile ranging from simple coloring to nested small-multiples visualizations. An effective grid map is coherent with the underlying geographic space: the tiles maintain the contiguity, neighborhoods and identifiability of the corresponding spatial elements, while the grid map as a whole maintains the global shape of the input. Of particular importance are salient local features of the global shape which need to be represented by tiles assigned to the appropriate spatial elements. State-of-the-art techniques can adequately deal only with simple cases, such as close-to-uniform spatial distributions or global shapes that have few characteristic features. We introduce a simple fully-automated 3-step pipeline for computing coherent grid maps. Each step is a well-studied problem: shape decomposition based on salient features, tile-based Mosaic Cartograms, and point-set matching. Our pipeline is a seamless composition of existing techniques for these problems and results in high-quality grid maps. We provide an implementation, demonstrate the efficacy of our approach on various complex datasets, and compare it to the state-of-the-art.","keywords":"Grid maps, algorithms, tile maps, small multiples, geovisualization","caption":"Fig. 8. Output of [23]: municipalities of Denmark; the \ufb01ve brown contigu- ous regions of N\xf8rrejyske \xd8 (inset) map to discontiguous tiles.2 ","img_size":{"width":822,"height":522},"subfigures":[{"x":4.687624812176572,"y":3.884005047442023,"width":809.0587817259845,"height":512.0929832860222,"type":"single","id":"single-0"}],"visualizations":[{"x":8.320430050035084,"y":162.53774146907102,"width":529.8382911323248,"height":349.15672043579474,"type":"graph","id":"graph-1"},{"x":7.601124842854579,"y":160.38400166096574,"width":532.0019564118642,"height":352.7392847978451,"type":"glyph_based","id":"glyph_based-0"}],"relations":[{"vislist":[{"vislist":["graph-1"],"relation":null,"id":"group-0"},{"vislist":["glyph_based-0"],"relation":null,"id":"group-1"}],"relation":"coordinated","id":"relation-0"}]},"3262_0":{"comp":[["graph","proportional_area_chart",["coordinated"]]],"visType":["graph","proportional_area_chart"],"compType":["coordinated"],"compressed_tree":[{"composite_pattern":"coordinated","visualization_type":[["graph"],["proportional_area_chart"]]}],"coOccurrence":[["graph","proportional_area_chart",["coOccurrence"]]],"year":2020,"conference":["InfoVis"],"authors":["Arpit Narechania","Ahsan Qamar","Alex Endert"],"title":"SafetyLens: Visual Data Analysis of Functional Safety of Vehicles","doi":"10.1109/TVCG.2020.3030382","abstract":"Modern automobiles have evolved from just being mechanical machines to having full-fledged electronics systems that enhance vehicle dynamics and driver experience. However, these complex hardware and software systems, if not properly designed, can experience failures that can compromise the safety of the vehicle, its occupants, and the surrounding environment. For example, a system to activate the brakes to avoid a collision saves lives when it functions properly, but could lead to tragic outcomes if the brakes were applied in a way that\'s inconsistent with the design. Broadly speaking, the analysis performed to minimize such risks falls into a systems engineering domain called Functional Safety. In this paper, we present SafetyLens, a visual data analysis tool to assist engineers and analysts in analyzing automotive Functional Safety datasets. SafetyLens combines techniques including network exploration and visual comparison to help analysts perform domain-specific tasks. This paper presents the design study with domain experts that resulted in the design guidelines, the tool, and user feedback.","keywords":"Visual data analysis, Design study, Network visualization, Functional safety, Automotive engineering.","caption":"Fig. 1. The SafetyLens Compare view: (A) Project Panel comprising the visualization canvas and three tabs: (1) Nodes, (2) Links, and (3) Trace, (B) Shared Nodes Panel with three nodes (Hazards) selected and highlighted across all three projects (ellipses), (C) Detail View Panel showing details of a node (System Behavior) hovered in Project-B ( ), and (D) opens into a Control Panel comprising search and \ufb01lter controls. ","img_size":{"width":1822,"height":995},"subfigures":[{"x":11.82279701334856,"y":10.119280727904503,"width":1798.3544059733015,"height":976.1205136310325,"type":"interface","id":"interface-0"}],"visualizations":[{"x":353.6347279545764,"y":70.69023316179992,"width":1445.7965935518614,"height":510.9044885344334,"type":"graph","id":"graph-0"},{"x":358.4100248481298,"y":75.4517728501332,"width":1434.6388830197982,"height":504.599390802294,"type":"proportional_area_chart","id":"proportional_area_chart-1"}],"relations":[{"vislist":[{"vislist":["graph-0"],"relation":null,"id":"group-0"},{"vislist":["proportional_area_chart-1"],"relation":null,"id":"group-1"}],"relation":"coordinated","id":"relation-0"}]},"3304_10":{"comp":[["scatterplot","map",["coordinated"]]],"visType":["scatterplot","map"],"compType":["coordinated"],"compressed_tree":[{"composite_pattern":"coordinated","visualization_type":[["scatterplot"],["map"]]}],"coOccurrence":[["scatterplot","map",["coOccurrence"]]],"year":2020,"conference":["VAST"],"authors":["Shayan Monadjemi","Roman Garnett","Alvitta Ottley"],"title":"Competing Models: Inferring Exploration Patterns and Information Relevance via Bayesian Model Selection","doi":"10.1109/TVCG.2020.3030430","abstract":"Analyzing interaction data provides an opportunity to learn about users, uncover their underlying goals, and create intelligent visualization systems. The first step for intelligent response in visualizations is to enable computers to infer user goals and strategies through observing their interactions with a system. Researchers have proposed multiple techniques to model users, however, their frameworks often depend on the visualization design, interaction space, and dataset. Due to these dependencies, many techniques do not provide a general algorithmic solution to user exploration modeling. In this paper, we construct a series of models based on the dataset and pose user exploration modeling as a Bayesian model selection problem where we maintain a belief over numerous competing models that could explain user interactions. Each of these competing models represent an exploration strategy the user could adopt during a session. The goal of our technique is to make high-level and in-depth inferences about the user by observing their low-level interactions. Although our proposed idea is applicable to various probabilistic model spaces, we demonstrate a specific instance of encoding exploration patterns as competing models to infer information relevance. We validate our technique\'s ability to infer exploration bias, predict future interactions, and summarize an analytic session using user study datasets. Our results indicate that depending on the application, our method outperforms established baselines for bias detection and future interaction prediction. Finally, we discuss future research directions based on our proposed modeling paradigm and suggest how practitioners can use this method to build intelligent visualization systems that understand users\' goals and adapt to improve the exploration process.","keywords":"User Interaction Modeling, Bayesian Machine Learning","caption":"Fig. 8. The experiment interface from Kern et al. [25]. Crime cases were visualized on an interactive map, where the colors indicate the type of crimes. Users were able to zoom, pan, hover, and click. While hovering on dots, a tooltip with more details opens. When a dot is clicked, the crime case is added to the sidebar as shown above. ","img_size":{"width":984,"height":564},"subfigures":[{"x":6.7725387897166485,"y":10.324878169537177,"width":969.6846194610905,"height":547.9724648608038,"type":"interface","id":"interface-0"}],"visualizations":[{"x":11.144506580941437,"y":41.6752408431314,"width":722.1570932803604,"height":448.53424558709,"type":"map","id":"map-0"},{"x":13.731885395364966,"y":41.6952509913736,"width":719.5861823206191,"height":449.3622056345684,"type":"scatterplot","id":"scatterplot-1"}],"relations":[{"vislist":[{"vislist":["scatterplot-1"],"relation":null,"id":"group-0"},{"vislist":["map-0"],"relation":null,"id":"group-1"}],"relation":"coordinated","id":"relation-0"}]},"3323_0":{"comp":[["others","map",["coordinated"]]],"visType":["others","map"],"compType":["coordinated"],"compressed_tree":[{"composite_pattern":"coordinated","visualization_type":[["others"],["map"]]}],"coOccurrence":[["others","map",["coOccurrence"]]],"year":2020,"conference":["VAST"],"authors":["Thomas Ortner","Andreas Walch","Rebecca Nowak","Robert Barnes","Thomas H\xf6llt","M. Eduard Gr\xf6ller"],"title":"InCorr: Interactive Data-Driven Correlation Panels for Digital Outcrop Analysis","doi":"10.1109/TVCG.2020.3030409","abstract":"Geological analysis of 3D Digital Outcrop Models (DOMs) for reconstruction of ancient habitable environments is a key aspect of the upcoming ESA ExoMars 2022 Rosalind Franklin Rover and the NASA 2020 Rover Perseverance missions in seeking signs of past life on Mars. Geologists measure and interpret 3D DOMs, create sedimentary logs and combine them in `correlation panels\' to map the extents of key geological horizons, and build a stratigraphic model to understand their position in the ancient landscape. Currently, the creation of correlation panels is completely manual and therefore time-consuming, and inflexible. With InCorr we present a visualization solution that encompasses a 3D logging tool and an interactive data-driven correlation panel that evolves with the stratigraphic analysis. For the creation of InCorr we closely cooperated with leading planetary geologists in the form of a design study. We verify our results by recreating an existing correlation analysis with InCorr and validate our correlation panel against a manually created illustration. Further, we conducted a user-study with a wider circle of geologists. Our evaluation shows that InCorr efficiently supports the domain experts in tackling their research questions and that it has the potential to significantly impact how geologists work with digital outcrop representations in general.","keywords":"Geographic / geospatial visualization, remote sensing geology, digital outcrop analysis, integration of spatial andnon-spatial data visualization","caption":"Fig. 1. System overview of InCorr: (a) Outcrop View, showing digital outcrop model annotated in 3D by a geologist and vertical 3D logging tool indicating layer thicknesses. (b) InCorrPanel, showing logs for two outcrops created directly from annotation data mimicking manual illustrations. (c) GUI to assign rock types to rock layers. ","img_size":{"width":1794,"height":673},"subfigures":[{"x":12.582596318672154,"y":9.951094857582046,"width":1777.9560312338945,"height":654.3994058619448,"type":"interface","id":"interface-0"}],"visualizations":[{"x":1030.7186608784164,"y":11.912002917277773,"width":485.794128108717,"height":649.1759941654432,"type":"bar_chart","id":"bar_chart-2"},{"x":8.884428636179024,"y":5.549306012072581,"width":1011.922759775834,"height":647.6396811429822,"type":"map","id":"map-0"},{"x":16.735971581089576,"y":5.549306012072487,"width":999.3845119106588,"height":647.6396811429812,"type":"others","id":"others-1"}],"relations":[{"vislist":[{"vislist":["others-1"],"relation":null,"id":"group-0"},{"vislist":["map-0"],"relation":null,"id":"group-1"}],"relation":"coordinated","id":"relation-0"}]},"3335_3":{"comp":[["graph","map",["coordinated"]],["matrix","comb",["large_view"]]],"visType":["graph","map","matrix","comb"],"compType":["coordinated","large_view"],"compressed_tree":[{"composite_pattern":"large_view","visualization_type":[["matrix"],[{"composite_pattern":"coordinated","visualization_type":[["graph"],["map"]]}]]}],"coOccurrence":[["graph","map",["coOccurrence"]],["graph","matrix",["coOccurrence"]],["map","matrix",["coOccurrence"]]],"year":2020,"conference":["VAST"],"authors":["Karen B. Schloss","Zachary Leggon","Laurent Lessard"],"title":"Semantic Discriminability for Visual Communication","doi":"10.1109/TVCG.2020.3030434","abstract":"To interpret information visualizations, observers must determine how visual features map onto concepts. First and foremost, this ability depends on perceptual discriminability; observers must be able to see the difference between different colors for those colors to communicate different meanings. However, the ability to interpret visualizations also depends on semantic discriminability, the degree to which observers can infer a unique mapping between visual features and concepts, based on the visual features and concepts alone (i.e., without help from verbal cues such as legends or labels). Previous evidence suggested that observers were better at interpreting encoding systems that maximized semantic discriminability (maximizing association strength between assigned colors and concepts while minimizing association strength between unassigned colors and concepts), compared to a system that only maximized color-concept association strength. However, increasing semantic discriminability also resulted in increased perceptual distance, so it is unclear which factor was responsible for improved performance. In the present study, we conducted two experiments that tested for independent effects of semantic distance and perceptual distance on semantic discriminability of bar graph data visualizations. Perceptual distance was large enough to ensure colors were more than just noticeably different. We found that increasing semantic distance improved performance, independent of variation in perceptual distance, and when these two factors were uncorrelated, responses were dominated by semantic distance. These results have implications for navigating trade-offs in color palette design optimization for visual communication.","keywords":" Multi-Robot Systems, Human-Subjects QualitativeStudies, Debugging","caption":"Figure 2: The operator is using the Main View to evaluate the system\u2019s performance. (a) Summary overview shows state of the science objective and the worldview synchronization (b) Scatterplot abstracts the \u201cbehavior\u201d of agents with the x- and y-axis encoding average CPU load and battery level, respectively. (c) Graph depicts the agents\u2019 location and communication links (d) Task Abstraction provides a task-centric perspective of each agent\u2019s task. Squares represent navigation tasks. Triangles represent science tasks (e) Timeline shows agents\u2019 activities. Agent 5\u2019s science chain of task is highlighted in pink. (Note: other agents\u2019 timelines are highlighted in different colors for illustrative purposes for the case study in Sect. 6.3) ","img_size":{"width":2040,"height":1005},"subfigures":[{"x":15.767407732999347,"y":7.539015554927593,"width":2014.3920189653836,"height":988.4410775751633,"type":"interface","id":"interface-0"}],"visualizations":[{"x":806.9544262294152,"y":55.410946958800764,"width":697.80148898813,"height":437.6676903776042,"type":"graph","id":"graph-1"},{"x":406.8119764844159,"y":9.475346139769334,"width":1616.8471999715039,"height":507.97147080126825,"type":"map","id":"map-0"},{"x":1767.6305639143832,"y":260.7781419379847,"width":250.16291987688166,"height":237.21565725963382,"type":"matrix","id":"matrix-2"},{"x":103.78287447811077,"y":574.4387550573463,"width":1917.0063440769386,"height":389.9161649416997,"type":"others","id":"others-3"}],"relations":[{"vislist":[{"vislist":["matrix-2"],"relation":null,"id":"group-2"},{"vislist":[{"vislist":[{"vislist":["graph-1"],"relation":null,"id":"group-0"},{"vislist":["map-0"],"relation":null,"id":"group-1"}],"relation":"coordinated","id":"relation-0"}],"relation":null,"id":"group-3"}],"relation":"large_view","id":"relation-1"}]},"1512_0":{"comp":[["vector_graph","map",["coordinated"]]],"visType":["vector_graph","map"],"compType":["coordinated"],"compressed_tree":[{"composite_pattern":"coordinated","visualization_type":[["vector_graph"],["map"]]}],"coOccurrence":[["vector_graph","map",["coOccurrence"]]],"year":2006,"conference":["Vis"],"authors":["Lingxiao Zhao","Charl P. Botha","Javier Bescos","Roel Truyen","Frans Vos","Frits H. Post"],"title":"Lines of Curvature for Polyp Detection in Virtual Colonoscopy","doi":"10.1109/TVCG.2006.158","abstract":"Computer-aided diagnosis (CAD) is a helpful addition to laborious visual inspection for preselection of suspected colonic polyps in virtual colonoscopy. Most of the previous work on automatic polyp detection makes use of indicators based on the scalar curvature of the colon wall and can result in many false-positive detections. Our work tries to reduce the number of false-positive detections in the preselection of polyp candidates. Polyp surface shape can be characterized and visualized using lines of curvature. In this paper, we describe techniques for generating and rendering lines of curvature on surfaces and we show that these lines can be used as part of a polyp detection approach. We have adapted existing approaches on explicit triangular surface meshes, and developed a new algorithm on implicit surfaces embedded in 3D volume data. The visualization of shaded colonic surfaces can be enhanced by rendering the derived lines of curvature on these surfaces. Features strongly correlated with true-positive detections were calculated on lines of curvature and used for the polyp candidate selection. We studied the performance of these features on 5 data sets that included 331 pre-detected candidates, of which 50 sites were true polyps. The winding angle had a significant discriminating power for true-positive detections, which was demonstrated by a Wilcoxon rank sum test with p&amp;lt;0.001. The median winding angle and inter-quartile range (IQR) for true polyps were 7.817 and 6.770-9.288 compared to 2.954 and 1.995-3.749 for false-positive detections","keywords":"Medical visualization, virtual colonoscopy, polyp detection, line of curvature, implicit surface","caption":"Fig.  1.   Distinctive  patterns  on  polyp  surfaces.   Left:  Circular  pattern in maximum curvature directions.  Right:  Focusing pattern in minimum curvature directions.","img_size":{"width":880,"height":446},"subfigures":[{"x":8.057150214902398,"y":11.958016750260422,"width":427.9728377639805,"height":424.6410445734454,"type":"single","id":"single-0"}],"visualizations":[{"x":9.93341581498096,"y":14.002388793779035,"width":421.5720017441804,"height":418.77045072361915,"type":"map","id":"map-0"},{"x":10.69906355665628,"y":17.84736400289765,"width":419.2644918066254,"height":414.95664186126663,"type":"vector_graph","id":"vector_graph-1"}],"relations":[{"vislist":[{"vislist":["vector_graph-1"],"relation":null,"id":"group-0"},{"vislist":["map-0"],"relation":null,"id":"group-1"}],"relation":"coordinated","id":"relation-0"}]},"2691_2":{"comp":[["graph","contour_graph",["coordinated"]]],"visType":["graph","contour_graph"],"compType":["coordinated"],"compressed_tree":[{"composite_pattern":"coordinated","visualization_type":[["graph"],["contour_graph"]]}],"coOccurrence":[["graph","contour_graph",["coOccurrence"]]],"year":2015,"conference":["VAST"],"authors":["Mengchen Liu","Shixia Liu","Xizhou Zhu","Qinying Liao","Furu Wei","Shimei Pan"],"title":"An Uncertainty-Aware Approach for Exploratory Microblog Retrieval","doi":"10.1109/TVCG.2015.2467554","abstract":"Although there has been a great deal of interest in analyzing customer opinions and breaking news in microblogs, progress has been hampered by the lack of an effective mechanism to discover and retrieve data of interest from microblogs. To address this problem, we have developed an uncertainty-aware visual analytics approach to retrieve salient posts, users, and hashtags. We extend an existing ranking technique to compute a multifaceted retrieval result: the mutual reinforcement rank of a graph node, the uncertainty of each rank, and the propagation of uncertainty among different graph nodes. To illustrate the three facets, we have also designed a composite visualization with three visual components: a graph visualization, an uncertainty glyph, and a flow map. The graph visualization with glyphs, the flow map, and the uncertainty analysis together enable analysts to effectively find the most uncertain results and interactively refine them. We have applied our approach to several Twitter datasets. Qualitative evaluation and two real-world case studies demonstrate the promise of our approach for retrieving high-quality microblog data.","keywords":"microblog data, mutual reinforcement model, uncertainty modeling, uncertainty visualization, uncertainty propagation","caption":"Fig. 3.  User interface:  (a) MutualRanker visualization; (b) control panel; (c) information panel","img_size":{"width":988,"height":644},"subfigures":[{"x":15.096213530361844,"y":12.629337616023099,"width":956.9279398320126,"height":618.7413247679546,"type":"interface","id":"interface-0"}],"visualizations":[{"x":18.252716473009553,"y":33.7425135100006,"width":635.8100683910326,"height":562.4930629482175,"type":"contour_graph","id":"contour_graph-3"},{"x":17.36456808199115,"y":31.115666178623734,"width":633.6281112737922,"height":561.0248901903367,"type":"graph","id":"graph-0"},{"x":17.36456808199115,"y":30.172767203513924,"width":635.5139092240117,"height":563.8535871156662,"type":"heatmap","id":"heatmap-1"},{"x":674.5651537335287,"y":119.74816983894588,"width":292.29868228404104,"height":505.3938506588582,"type":"table","id":"table-2"}],"relations":[{"vislist":[{"vislist":["graph-0"],"relation":null,"id":"group-1"},{"vislist":["contour_graph-3"],"relation":null,"id":"group-0"}],"relation":"coordinated","id":"relation-0"}]},"2715_3":{"comp":[["graph","map",["coordinated"]]],"visType":["graph","map"],"compType":["coordinated"],"compressed_tree":[{"composite_pattern":"coordinated","visualization_type":[["graph"],["map"]]}],"coOccurrence":[["graph","map",["coOccurrence"]]],"year":2015,"conference":["VAST"],"authors":["Tatiana von Landesberger","Felix Brodkorb","Philipp Roskosch","Natalia V. Andrienko","Gennady L. Andrienko","Andreas Kerren"],"title":"MobilityGraphs: Visual Analysis of Mass Mobility Dynamics via Spatio-Temporal Graphs and Clustering","doi":"10.1109/TVCG.2015.2468111","abstract":"Learning more about people mobility is an important task for official decision makers and urban planners. Mobility data sets characterize the variation of the presence of people in different places over time as well as movements (or flows) of people between the places. The analysis of mobility data is challenging due to the need to analyze and compare spatial situations (i.e., presence and flows of people at certain time moments) and to gain an understanding of the spatio-temporal changes (variations of situations over time). Traditional flow visualizations usually fail due to massive clutter. Modern approaches offer limited support for investigating the complex variation of the movements over longer time periods. We propose a visual analytics methodology that solves these issues by combined spatial and temporal simplifications. We have developed a graph-based method, called MobilityGraphs, which reveals movement patterns that were occluded in flow maps. Our method enables the visual representation of the spatio-temporal variation of movements for long time series of spatial situations originally containing a large number of intersecting flows. The interactive system supports data exploration from various perspectives and at various levels of detail by interactive setting of clustering parameters. The feasibility our approach was tested on aggregated mobility data derived from a set of geolocated Twitter posts within the Greater London city area and mobile phone call data records in Abidjan, Ivory Coast. We could show that MobilityGraphs support the identification of regular daily and weekly movement patterns of resident population.","keywords":"Visual analytics, movement data, networks, graphs, temporal aggregation, spatial aggregation, flows, clustering","caption":"Fig. 5. The difference graph view displays differences between two spa- tial situations. Blue indicates decrease, white no change, and red an increase. A user-selected spatial aggregate is shown on a map.","img_size":{"width":857,"height":561},"subfigures":[{"x":6.221769265421468,"y":7.972905534443044,"width":427.78649995961325,"height":545.0541889311141,"type":"single","id":"single-0"}],"visualizations":[{"x":4.978260869565219,"y":4.434782608695651,"width":432.3913043478261,"height":419.0869565217392,"type":"graph","id":"graph-2"},{"x":7.195652173913062,"y":2.2173913043478257,"width":430.1739130434783,"height":420.1956521739129,"type":"map","id":"map-0"},{"x":495.0217391304348,"y":77.60869565217388,"width":348.13043478260863,"height":260.54347826086956,"type":"map","id":"map-1"},{"x":10.52173913043478,"y":420.1956521739129,"width":427.9565217391305,"height":136.3695652173913,"type":"matrix","id":"matrix-3"}],"relations":[{"vislist":[{"vislist":["graph-2"],"relation":null,"id":"group-1"},{"vislist":["map-0"],"relation":null,"id":"group-0"}],"relation":"coordinated","id":"relation-0"}]},"2729_3":{"comp":[["matrix","map",["coordinated"]],["glyph_based","map",["coordinated"]]],"visType":["matrix","map","glyph_based"],"compType":["coordinated"],"compressed_tree":[{"composite_pattern":"coordinated","visualization_type":[["matrix"],["map"]]},{"composite_pattern":"coordinated","visualization_type":[["glyph_based"],["map"]]}],"coOccurrence":[["matrix","map",["coOccurrence"]],["matrix","glyph_based",["coOccurrence"]],["map","glyph_based",["coOccurrence"]]],"year":2015,"conference":["VAST"],"authors":["Mihaela Jarema","Ismail Demir","Johannes Kehrer","R\xfcdiger Westermann"],"title":"Comparative visual analysis of vector field ensembles","doi":"10.1109/VAST.2015.7347634","abstract":"We present a new visual analysis approach to support the comparative exploration of 2D vector-valued ensemble fields. Our approach enables the user to quickly identify the most similar groups of ensemble members, as well as the locations where the variation among the members is high. We further provide means to visualize the main features of the potentially multimodal directional distributions at user-selected locations. For this purpose, directional data is modelled using mixtures of probability density functions (pdfs), which allows us to characterize and classify complex distributions with relatively few parameters. The resulting mixture models are used to determine the degree of similarity between ensemble members, and to construct glyphs showing the direction, spread, and strength of the principal modes of the directional distributions. We also propose several similarity measures, based on which we compute pairwise member similarities in the spatial domain and form clusters of similar members. The hierarchical clustering is shown using dendrograms and similarity matrices, which can be used to select particular members and visualize their variations. A user interface providing multiple linked views enables the simultaneous visualization of aggregated global and detailed local variations, as well as the selection of members for a detailed comparison.","keywords":"Uncertainty Visualization, Vector Field Data, Coordinated and Multiple Views, Glyph-based Techniques","caption":"Figure 4: Multiple linked views of a wind ensemble. View (A) color codes geolocated scalar measures over the entire domain (here the modality of the distributions), while (B) shows a detail view over the region selected by the user (marked in A by a rectangle), where directional distributions are displayed using glyphs. The isocontours show the geopotential height. The hierarchical clustering of the ensemble members is shown using a dendrogram in (C), and the pairwise dissimilarities between ensemble members are shown in the global dissimilarity matrix in (D).","img_size":{"width":1695,"height":969},"subfigures":[{"x":12.514913146227599,"y":12.448906286635891,"width":1669.970173707544,"height":941.4550642927559,"type":"interface","id":"interface-0"}],"visualizations":[{"x":25.864332603938745,"y":544.9299781181618,"width":994.4442013129103,"height":419.8293216630197,"type":"glyph_based","id":"glyph_based-0"},{"x":8.90153172866519,"y":42.40700218818381,"width":1036.851203501094,"height":432.55142231947474,"type":"heatmap","id":"heatmap-1"},{"x":1071.1969365426696,"y":523.72647702407,"width":432.55142231947474,"height":434.6717724288839,"type":"heatmap","id":"heatmap-2"},{"x":27.984682713347922,"y":544.9299781181618,"width":992.3238512035011,"height":417.70897155361047,"type":"matrix","id":"matrix-3"},{"x":1069.0765864332604,"y":521.6061269146609,"width":436.79212253829314,"height":436.7921225382931,"type":"matrix","id":"matrix-4"},{"x":8.90153172866519,"y":44.52735229759299,"width":1041.0919037199124,"height":434.67177242888397,"type":"matrix","id":"matrix-5"},{"x":27.984682713347922,"y":549.1706783369802,"width":994.4442013129103,"height":411.34792122538295,"type":"small_multiple","id":"small_multiple-6"},{"x":8.90153172866519,"y":42.40700218818381,"width":1038.9715536105032,"height":434.67177242888397,"type":"map","id":"map-7"},{"x":1075.437636761488,"y":55.12910284463894,"width":419.82932166301975,"height":415.58862144420124,"type":"tree","id":"tree-8"},{"x":26.035049378191616,"y":549.764543288536,"width":994.7130146077299,"height":411.85742866464,"type":"map","id":"map-10"}],"relations":[{"vislist":[{"vislist":["matrix-5"],"relation":null,"id":"group-1"},{"vislist":["map-7"],"relation":null,"id":"group-0"}],"relation":"coordinated","id":"relation-0"},{"vislist":[{"vislist":["glyph_based-0"],"relation":null,"id":"group-3"},{"vislist":["map-10"],"relation":null,"id":"group-2"}],"relation":"coordinated","id":"relation-1"}]},"2619_0":{"comp":[["proportional_area_chart","map",["coordinated"]]],"visType":["proportional_area_chart","map"],"compType":["coordinated"],"compressed_tree":[{"composite_pattern":"coordinated","visualization_type":[["proportional_area_chart"],["map"]]}],"coOccurrence":[["proportional_area_chart","map",["coOccurrence"]]],"year":2015,"conference":["InfoVis"],"authors":["P. Samuel Quinan","Miriah D. Meyer"],"title":"Visually Comparing Weather Features in Forecasts","doi":"10.1109/TVCG.2015.2467754","abstract":"Meteorologists process and analyze weather forecasts using visualization in order to examine the behaviors of and relationships among weather features. In this design study conducted with meteorologists in decision support roles, we identified and attempted to address two significant common challenges in weather visualization: the employment of inconsistent and often ineffective visual encoding practices across a wide range of visualizations, and a lack of support for directly visualizing how different weather features relate across an ensemble of possible forecast outcomes. In this work, we present a characterization of the problems and data associated with meteorological forecasting, we propose a set of informed default encoding choices that integrate existing meteorological conventions with effective visualization practice, and we extend a set of techniques as an initial step toward directly visualizing the interactions of multiple features over an ensemble forecast. We discuss the integration of these contributions into a functional prototype tool, and also reflect on the many practical challenges that arise when working with weather data.","keywords":"Design study, weather, geographic/geospatial visualization, ensemble data","caption":"Fig. 1: An overview of the interface for WeaVER, an open-source tool developed for supporting metorological analysis, shown here visually relating multiple isocontour features across an ensemble using contour boxplots.","img_size":{"width":1463,"height":939},"subfigures":[{"x":50.713487502778456,"y":17.061859917131855,"width":1387.2138517194985,"height":889.485267021461,"type":"interface","id":"interface-0"}],"visualizations":[{"x":97.4243772241993,"y":110.27402135231314,"width":1074.3362989323841,"height":750.197508896797,"type":"map","id":"map-0"},{"x":100.24119134499573,"y":116.19388524037406,"width":1070.6487488527034,"height":747.6564897105351,"type":"proportional_area_chart","id":"proportional_area_chart-1"}],"relations":[{"vislist":[{"vislist":["proportional_area_chart-1"],"relation":null,"id":"group-1"},{"vislist":["map-0"],"relation":null,"id":"group-0"}],"relation":"coordinated","id":"relation-0"}]},"2761_1":{"comp":[["word_cloud","graph",["coordinated"]]],"visType":["word_cloud","graph"],"compType":["coordinated"],"compressed_tree":[{"composite_pattern":"coordinated","visualization_type":[["word_cloud"],["graph"]]}],"coOccurrence":[],"year":2016,"conference":["InfoVis"],"authors":["Mengdie Hu","Krist Wongsuphasawat","John T. Stasko"],"title":"Visualizing Social Media Content with SentenTree","doi":"10.1109/TVCG.2016.2598590","abstract":"We introduce SentenTree, a novel technique for visualizing the content of unstructured social media text. SentenTree displays frequent sentence patterns abstracted from a corpus of social media posts. The technique employs design ideas from word clouds and the Word Tree, but overcomes a number of limitations of both those visualizations. SentenTree displays a node-link diagram where nodes are words and links indicate word co-occurrence within the same sentence. The spatial arrangement of nodes gives cues to the syntactic ordering of words while the size of nodes gives cues to their frequency of occurrence. SentenTree can help people gain a rapid understanding of key concepts and opinions in a large social media text collection. It is implemented as a lightweight application that runs in the browser.","keywords":"text visualization;social media;natural language processing;word cloud;Twitter","caption":"Fig. 2: Interacting with the World Cup visualization.","img_size":{"width":2151,"height":307},"subfigures":[{"x":16.551171866990483,"y":16.456606436389716,"width":1041.4516055488434,"height":224.22695436599014,"type":"interface","id":"interface-0"}],"visualizations":[{"x":16.733491799566952,"y":4.464132900813598,"width":1036.0634074608718,"height":119.5491591347982,"type":"graph","id":"graph-2"},{"x":1084.9447937927341,"y":8.37479465517599,"width":1056.888076044317,"height":126.92124626978163,"type":"graph","id":"graph-3"},{"x":16.091813829601676,"y":1.4161330484321737,"width":1037.1928362234037,"height":123.5239634444991,"type":"word_cloud","id":"word_cloud-0"},{"x":1086.9343339587235,"y":1.523496343638494,"width":1057.3395872420258,"height":129.22878491007543,"type":"word_cloud","id":"word_cloud-1"}],"relations":[{"vislist":[{"vislist":["word_cloud-0"],"relation":null,"id":"group-0"},{"vislist":["graph-2"],"relation":null,"id":"group-1"}],"relation":"coordinated","id":"relation-0"}]},"2966_0":{"comp":[["graph","map",["coordinated"]]],"visType":["graph","map"],"compType":["coordinated"],"compressed_tree":[{"composite_pattern":"coordinated","visualization_type":[["graph"],["map"]]}],"coOccurrence":[["graph","map",["coOccurrence"]]],"year":2017,"conference":["VAST"],"authors":["Haeyong Chung","Sai Prashanth Dasari","Santhosh Nandhakumar","Christopher Andrews"],"title":"CRICTO: Supporting Sensemaking through Crowdsourced Information Schematization","doi":"10.1109/VAST.2017.8585484","abstract":"We present CRICTO, a new crowdsourcing visual analytics environment for making sense of and analyzing text data, whereby multiple crowdworkers are able to parallelize the simple information schematization tasks of relating and connecting entities across documents. The diverse links from these schematization tasks are then automatically combined and the system visualizes them based on the semantic types of the linkages. CRICTO also includes several tools that allow analysts to interactively explore and refine crowdworkers\' results to better support their own sensemaking processes. We evaluated CRICTO\'s techniques and analysis workflow with deployments of CRICTO using Amazon Mechanical Turk and a user study that assess the effect of crowdsourced schematization in sensemaking tasks. The results of our evaluation show that CRICTO\'s crowdsourcing approaches and workflow help analysts explore diverse aspects of datasets, and uncover more accurate hidden stories embedded in the text datasets.","keywords":"Visual text analytics,sensemaking,crowdsourcing","caption":"Fig. 1. CRICTO (CRowdsourcing Information sChematization TOol): a crowdsourcing visual analytics environment for sensemaking of text data. (a) Document view. (b) Graph view. (c) Map view. (d) Timeline view. (e) Scratch pad. (f) Bar chart.","img_size":{"width":2106,"height":1086},"subfigures":[{"x":11.704032832768567,"y":10.599757899968823,"width":2084.121580573741,"height":1066.3299770631318,"type":"interface","id":"interface-0"}],"visualizations":[{"x":142.99209486166,"y":8.584980237154149,"width":806.98814229249,"height":111.60474308300397,"type":"bar_chart","id":"bar_chart-0"},{"x":945.687747035573,"y":543,"width":1160.312252964427,"height":257.5494071146245,"type":"map","id":"map-1"},{"x":941.395256916996,"y":4.292490118577074,"width":1158.9723320158105,"height":527.9762845849802,"type":"graph","id":"graph-3"},{"x":941.395256916996,"y":543,"width":1164.604743083004,"height":257.5494071146245,"type":"graph","id":"graph-4"}],"relations":[{"vislist":[{"id":"group-0","relation":null,"vislist":["graph-4"]},{"id":"group-1","relation":null,"vislist":["map-1"]}],"relation":"coordinated","id":"relation-0"}]},"2975_0":{"comp":[["donut_chart","map",["coordinated"]]],"visType":["donut_chart","map"],"compType":["coordinated"],"compressed_tree":[{"composite_pattern":"coordinated","visualization_type":[["donut_chart"],["map"]]}],"coOccurrence":[["donut_chart","map",["coOccurrence"]]],"year":2017,"conference":["VAST"],"authors":["Isaac Cho","Ryan Wesslen","Svitlana Volkova","William Ribarsky","Wenwen Dou"],"title":"CrystalBall: A Visual Analytic System for Future Event Discovery and Analysis from Social Media Data","doi":"10.1109/VAST.2017.8585658","abstract":"Social media data bear valuable insights regarding events that occur around the world. Events are inherently temporal and spatial. Existing visual text analysis systems have focused on detecting and analyzing past and ongoing events. Few have leveraged social media information to look for events that may occur in the future. In this paper, we present an interactive visual analytic system, CrystalBall, that automatically identifies and ranks future events from Twitter streams. CrystalBall integrates new methods to discover events with interactive visualizations that permit sensemaking of the identified future events. Our computational methods integrate seven different measures to identify and characterize future events, leveraging information regarding time, location, social networks, and the informativeness of the messages. A visual interface is tightly coupled with the computational methods to present a concise summary of the possible future events. A novel connection graph and glyphs are designed to visualize the characteristics of the future events. To demonstrate the efficacy of CrystalBall in identifying future events and supporting interactive analysis, we present multiple case studies and validation studies on analyzing events derived from Twitter data.","keywords":"Social media analysis,Event detection and analysis,visual analytics","caption":"Figure 1: CrystalBall interface. The interface is comprised of four main views: A) Event Calendar View, B) Map View, C) Word Cloud View, and D) Social Network view. The E) Tweet panel is shown on demand.","img_size":{"width":1851,"height":1125},"subfigures":[{"x":5.677938284943867,"y":43.51861431708984,"width":1831.9633399415225,"height":1073.3055531468058,"type":"interface","id":"interface-0"}],"visualizations":[{"x":587.5553359683796,"y":42.243072402335905,"width":878.2114624505928,"height":655.8794466403161,"type":"donut_chart","id":"donut_chart-0"},{"x":2.822134387351753,"y":46.689712718541436,"width":575.8399209486166,"height":1078.3102872814586,"type":"graph","id":"graph-1"},{"x":1018.3228668289652,"y":698.2013190591823,"width":442.0830811767821,"height":423.15597678389224,"type":"graph","id":"graph-2"},{"x":585.3320158102766,"y":42.243072402335905,"width":871.5415019762846,"height":653.6561264822134,"type":"map","id":"map-3"},{"x":587.5553359683796,"y":689.229238410241,"width":431.32411067193675,"height":435.770761589759,"type":"word_cloud","id":"word_cloud-4"}],"relations":[{"vislist":[{"id":"group-0","relation":null,"vislist":["donut_chart-0"]},{"id":"group-1","relation":null,"vislist":["map-3"]}],"relation":"coordinated","id":"relation-0"}]},"1942_1":{"comp":[["word_cloud","area_chart",["coordinated"]]],"visType":["word_cloud","area_chart"],"compType":["coordinated"],"compressed_tree":[{"composite_pattern":"coordinated","visualization_type":[["word_cloud"],["area_chart"]]}],"coOccurrence":[["word_cloud","area_chart",["coOccurrence"]]],"year":2010,"conference":["InfoVis"],"authors":["Marian D\xf6rk","Dan Gruen","Carey L. Williamson","Sheelagh Carpendale"],"title":"A Visual Backchannel for Large-Scale Events","doi":"10.1109/TVCG.2010.129","abstract":"We introduce the concept of a Visual Backchannel as a novel way of following and exploring online conversations about large-scale events. Microblogging communities, such as Twitter, are increasingly used as digital backchannels for timely exchange of brief comments and impressions during political speeches, sport competitions, natural disasters, and other large events. Currently, shared updates are typically displayed in the form of a simple list, making it difficult to get an overview of the fast-paced discussions as it happens in the moment and how it evolves over time. In contrast, our Visual Backchannel design provides an evolving, interactive, and multi-faceted visual overview of large-scale ongoing conversations on Twitter. To visualize a continuously updating information stream, we include visual saliency for what is happening now and what has just happened, set in the context of the evolving conversation. As part of a fully web-based coordinated-view system we introduce Topic Streams, a temporally adjustable stacked graph visualizing topics over time, a People Spiral representing participants and their activity, and an Image Cloud encoding the popularity of event photos by size. Together with a post listing, these mutually linked views support cross-filtering along topics, participants, and time ranges. We discuss our design considerations, in particular with respect to evolving visualizations of dynamically changing data. Initial feedback indicates significant interest and suggests several unanticipated uses.","keywords":"Backchannel, information visualization, events, multiple views, microblogging, information retrieval, World Wide Web","caption":"Fig. 2. The Visual Backchannel interface representing Twitter posts about the earthquake in Chile on the evening of February 27, 2010.","img_size":{"width":2169,"height":1380},"subfigures":[{"x":8.473022917896289,"y":4.93739962083054,"width":2141.776389944944,"height":1365.7191935848969,"type":"interface","id":"interface-0"}],"visualizations":[{"x":18.68740849194728,"y":14.143484626647147,"width":2123.5431918008785,"height":674.8462664714497,"type":"area_chart","id":"area_chart-0"},{"x":156.1784861187032,"y":122.27180572535222,"width":1701.8590529082137,"height":544.2642420478369,"type":"word_cloud","id":"word_cloud-9"}],"relations":[{"vislist":[{"vislist":["word_cloud-9"],"relation":null,"id":"group-2"},{"vislist":["area_chart-0"],"relation":null,"id":"group-3"}],"relation":"coordinated","id":"relation-1"}]},"1949_2":{"comp":[["graph","contour_graph",["coordinated"]]],"visType":["graph","contour_graph"],"compType":["coordinated"],"compressed_tree":[{"composite_pattern":"coordinated","visualization_type":[["graph"],["contour_graph"]]}],"coOccurrence":[["graph","contour_graph",["coOccurrence"]]],"year":2010,"conference":["InfoVis"],"authors":["Nan Cao","Jimeng Sun","Yu-Ru Lin","David Gotz","Shixia Liu","Huamin Qu"],"title":"FacetAtlas: Multifaceted Visualization for Rich Text Corpora","doi":"10.1109/TVCG.2010.154","abstract":"Documents in rich text corpora usually contain multiple facets of information. For example, an article about a specific disease often consists of different facets such as symptom, treatment, cause, diagnosis, prognosis, and prevention. Thus, documents may have different relations based on different facets. Powerful search tools have been developed to help users locate lists of individual documents that are most related to specific keywords. However, there is a lack of effective analysis tools that reveal the multifaceted relations of documents within or cross the document clusters. In this paper, we present FacetAtlas, a multifaceted visualization technique for visually analyzing rich text corpora. FacetAtlas combines search technology with advanced visual analytical tools to convey both global and local patterns simultaneously. We describe several unique aspects of FacetAtlas, including (1) node cliques and multifaceted edges, (2) an optimized density map, and (3) automated opacity pattern enhancement for highlighting visual patterns, (4) interactive context switch between facets. In addition, we demonstrate the power of FacetAtlas through a case study that targets patient education in the health care domain. Our evaluation shows the benefits of this work, especially in support of complex multifaceted data analysis.","keywords":"Multi-facet visualization, Text visualization, Multi-relational Graph, Search UI","caption":"Fig. 3. FacetAtlas applied to Google Health data. This \ufb01gure shows a disease diagram for the search term \u201cHIV.\u201d FacetAtlas contains four main components: (1) an interactive facet legend, (2) a query box, (3) a canvas for rendering multifaceted relational diagrams, and (4) a dynamic query \ufb01lter to control that amount of information being displayed.","img_size":{"width":954,"height":807},"subfigures":[{"x":4.471295396071684,"y":8.873365711518,"width":943.3400783234091,"height":793.5475291916592,"type":"interface","id":"interface-0"}],"visualizations":[{"x":17.967057101024864,"y":134.69692532942898,"width":909.7950219619324,"height":642.7642752562225,"type":"graph","id":"graph-0"},{"x":14.422401171303022,"y":137.06002928257686,"width":912.1581259150804,"height":642.7642752562224,"type":"contour_graph","id":"contour_graph-1"}],"relations":[{"vislist":[{"vislist":["graph-0"],"relation":null,"id":"group-0"},{"vislist":["contour_graph-1"],"relation":null,"id":"group-1"}],"relation":"coordinated","id":"relation-0"}]},"1960_13":{"comp":[["glyph_based","map",["coordinated"]]],"visType":["glyph_based","map"],"compType":["coordinated"],"compressed_tree":[{"composite_pattern":"coordinated","visualization_type":[["glyph_based"],["map"]]}],"coOccurrence":[["glyph_based","map",["coOccurrence"]]],"year":2010,"conference":["InfoVis"],"authors":["Bettina Speckmann","Kevin Verbeek"],"title":"Necklace Maps","doi":"10.1109/TVCG.2010.180","abstract":"Statistical data associated with geographic regions is nowadays globally available in large amounts and hence automated methods to visually display these data are in high demand. There are several well-established thematic map types for quantitative data on the ratio-scale associated with regions: choropleth maps, cartograms, and proportional symbol maps. However, all these maps suffer from limitations, especially if large data values are associated with small regions. To overcome these limitations, we propose a novel type of quantitative thematic map, the necklace map. In a necklace map, the regions of the underlying two-dimensional map are projected onto intervals on a one-dimensional curve (the necklace) that surrounds the map regions. Symbols are scaled such that their area corresponds to the data of their region and placed without overlap inside the corresponding interval on the necklace. Necklace maps appear clear and uncluttered and allow for comparatively large symbol sizes. They visualize data sets well which are not proportional to region sizes. The linear ordering of the symbols along the necklace facilitates an easy comparison of symbol sizes. One map can contain several nested or disjoint necklaces to visualize clustered data. The advantages of necklace maps come at a price: the association between a symbol and its region is weaker than with other types of maps. Interactivity can help to strengthen this association if necessary. We present an automated approach to generate necklace maps which allows the user to interactively control the final symbol placement. We validate our approach with experiments using various data sets and maps.","keywords":"Geographic Visualization, Automated Cartography, Proportional Symbol Maps, Necklace Maps","caption":"Fig. 14. FIFA World Cup 2010.","img_size":{"width":1876,"height":1029},"subfigures":[{"x":10.555890262006757,"y":12.40881624724096,"width":1846.126091284643,"height":1011.8481814355414,"type":"single","id":"single-0"}],"visualizations":[{"x":22.707877461706747,"y":33.774617067833695,"width":1821.577680525164,"height":970.4573304157549,"type":"map","id":"map-0"},{"x":34.35112466888478,"y":44.07234391932036,"width":1803.9882544893026,"height":952.4382823682239,"type":"glyph_based","id":"glyph_based-1"}],"relations":[{"vislist":[{"vislist":["glyph_based-1"],"relation":null,"id":"group-2"},{"vislist":["map-0"],"relation":null,"id":"group-3"}],"relation":"coordinated","id":"relation-1"}]},"1986_1":{"comp":[["graph","map",["coordinated"]]],"visType":["graph","map"],"compType":["coordinated"],"compressed_tree":[{"composite_pattern":"coordinated","visualization_type":[["graph"],["map"]]}],"coOccurrence":[["graph","map",["coOccurrence"]]],"year":2010,"conference":["VAST"],"authors":["Stephanie Dudzic","J. Alex Godwin","Ryan M. Kilgore"],"title":"Visualization of temporal relationships within coordinated views","doi":"10.1109/VAST.2010.5651617","abstract":"In command and control (C2) environments, decision makers must rapidly understand and address key temporal relationships that exist between critical tasks as conditions fluctuate. However, traditional temporal displays, such as mission timelines, fail to support user understanding of and reasoning about critical relationships. We have developed visualization methods to compactly and effectively convey key temporal constraints. In this paper, we present examples of our visualization approach and describe how we are exploring interaction methods within an integrated visualization workspace to support user awareness of temporal constraints.","keywords":"temporal relationships, temporal visualization","caption":"Figure 3.  Integrated temporal component with visualization cues within integrated visualization workspace","img_size":{"width":831,"height":657},"subfigures":[{"x":5.281055070208508,"y":5.823509105580209,"width":820.4378898595818,"height":645.3529817888393,"type":"interface","id":"interface-0"}],"visualizations":[{"x":8.620185858444131,"y":54.26712122335292,"width":809.7914163515007,"height":368.0035935470116,"type":"map","id":"map-0"},{"x":8.055196392469213,"y":53.72853601031372,"width":809.981949990376,"height":370.0157468809858,"type":"graph","id":"graph-1"},{"x":6.538674033149221,"y":480.66877902028887,"width":247.97773697171624,"height":152.58143592296835,"type":"table","id":"table-2"}],"relations":[{"vislist":[{"vislist":["graph-1"],"relation":null,"id":"group-0"},{"vislist":["map-0"],"relation":null,"id":"group-1"}],"relation":"coordinated","id":"relation-0"}]},"2010_3":{"comp":[["word_cloud","area_chart",["coordinated"]]],"visType":["word_cloud","area_chart"],"compType":["coordinated"],"compressed_tree":[{"composite_pattern":"coordinated","visualization_type":[["word_cloud"],["area_chart"]]}],"coOccurrence":[["word_cloud","area_chart",["coOccurrence"]]],"year":2010,"conference":["VAST"],"authors":["Lei Shi","Furu Wei","Shixia Liu","Li Tan","Xiaoxiao Lian","Michelle X. Zhou"],"title":"Understanding text corpora with multiple facets","doi":"10.1109/VAST.2010.5652931","abstract":"Text visualization becomes an increasingly more important research topic as the need to understand massive-scale textual information is proven to be imperative for many people and businesses. However, it is still very challenging to design effective visual metaphors to represent large corpora of text due to the unstructured and high-dimensional nature of text. In this paper, we propose a data model that can be used to represent most of the text corpora. Such a data model contains four basic types of facets: time, category, content (unstructured), and structured facet. To understand the corpus with such a data model, we develop a hybrid visualization by combining the trend graph with tag-clouds. We encode the four types of data facets with four separate visual dimensions. To help people discover evolutionary and correlation patterns, we also develop several visual interaction methods that allow people to interactively analyze text by one or more facets. Finally, we present two case studies to demonstrate the effectiveness of our solution in support of multi-faceted visual analysis of text corpora.","keywords":"text visualization, multi-facet data visualization","caption":"Figure 2: Data navigation interactions.","img_size":{"width":1424,"height":726},"subfigures":[{"x":4.9497311413542,"y":2.5647162737337954,"width":1411.7835596122193,"height":710.8261482006134,"type":"interface","id":"interface-0"}],"visualizations":[{"x":3.1397174254317113,"y":5.167259786476868,"width":1417.7205651491365,"height":712.7329012898507,"type":"area_chart","id":"area_chart-0"},{"x":5.596401028277655,"y":6.830752335967625,"width":1410.9408740359897,"height":707.3367609254499,"type":"word_cloud","id":"word_cloud-1"}],"relations":[{"vislist":[{"vislist":["word_cloud-1"],"relation":null,"id":"group-0"},{"vislist":["area_chart-0"],"relation":null,"id":"group-1"}],"relation":"coordinated","id":"relation-0"}]},"1799_9":{"comp":[["others","map",["coordinated"]]],"visType":["others","map"],"compType":["coordinated"],"compressed_tree":[{"composite_pattern":"coordinated","visualization_type":[["others"],["map"]]}],"coOccurrence":[["others","map",["coOccurrence"]]],"year":2009,"conference":["InfoVis"],"authors":["Christopher Collins","Gerald Penn","Sheelagh Carpendale"],"title":"Bubble Sets: Revealing Set Relations with Isocontours over Existing Visualizations","doi":"10.1109/TVCG.2009.122","abstract":"While many data sets contain multiple relationships, depicting more than one data relationship within a single visualization is challenging. We introduce Bubble Sets as a visualization technique for data that has both a primary data relation with a semantically significant spatial organization and a significant set membership relation in which members of the same set are not necessarily adjacent in the primary layout. In order to maintain the spatial rights of the primary data relation, we avoid layout adjustment techniques that improve set cluster continuity and density. Instead, we use a continuous, possibly concave, isocontour to delineate set membership, without disrupting the primary layout. Optimizations minimize cluster overlap and provide for calculation of the isocontours at interactive speeds. Case studies show how this technique can be used to indicate multiple sets on a variety of common visualizations.","keywords":"clustering, spatial layout, graph visualization, tree visualization","caption":"Fig. 9: Sets of geographically-de\ufb01ned items in lower Manhattan, showing ho- tels (orange), subway stations (brown), and medical clinics (purple). Medical clinics are noticably absent on the West side, and there is a cluster of clinics and hotels near transit in the Northeast corner.","img_size":{"width":1087,"height":1278},"subfigures":[{"x":24.950843822446764,"y":8.841306909625391,"width":1059.4451688564852,"height":1266.7048955133178,"type":"single","id":"single-0"}],"visualizations":[{"x":30.58620689655163,"y":17.137931034482758,"width":1047.8620689655172,"height":1257.46248181053,"type":"map","id":"map-0"},{"x":41.43031662436629,"y":54.68258430209382,"width":854.6230226328829,"height":1221.679326453468,"type":"others","id":"others-1"}],"relations":[{"vislist":[{"vislist":["others-1"],"relation":null,"id":"group-1"},{"vislist":["map-0"],"relation":null,"id":"group-0"}],"relation":"coordinated","id":"relation-0"}]},"1807_6":{"comp":[["graph","map",["coordinated"]]],"visType":["graph","map"],"compType":["coordinated"],"compressed_tree":[{"composite_pattern":"coordinated","visualization_type":[["graph"],["map"]]}],"coOccurrence":[["graph","map",["coOccurrence"]]],"year":2009,"conference":["InfoVis"],"authors":["Diansheng Guo"],"title":"Flow Mapping and Multivariate Visualization of Large Spatial Interaction Data","doi":"10.1109/TVCG.2009.143","abstract":"Spatial interactions (or flows), such as population migration and disease spread, naturally form a weighted location-to-location network (graph). Such geographically embedded networks (graphs) are usually very large. For example, the county-to-county migration data in the U.S. has thousands of counties and about a million migration paths. Moreover, many variables are associated with each flow, such as the number of migrants for different age groups, income levels, and occupations. It is a challenging task to visualize such data and discover network structures, multivariate relations, and their geographic patterns simultaneously. This paper addresses these challenges by developing an integrated interactive visualization framework that consists three coupled components: (1) a spatially constrained graph partitioning method that can construct a hierarchy of geographical regions (communities), where there are more flows or connections within regions than across regions; (2) a multivariate clustering and visualization method to detect and present multivariate patterns in the aggregated region-to-region flows; and (3) a highly interactive flow mapping component to map both flow and multivariate patterns in the geographic space, at different hierarchical levels. The proposed approach can process relatively large data sets and effectively discover and visualize major flow structures and multivariate relations at the same time. User interactions are supported to facilitate the understanding of both an overview and detailed patterns.","keywords":"hierarchical clustering, graph partitioning, flow mapping, spatial interaction, contiguity constraints, multidimensional visualization, coordinated views, data mining","caption":"Fig. 6: Multivariate flow mapping at the regional level. A self-organizing map (bottom left), parallel coordinate plot (bottom right), and a flow map (top right) are coordinated to present flow structure, multivariate information, and spatial patterns at the same time.","img_size":{"width":2133,"height":1473},"subfigures":[{"x":10.671125737024477,"y":5.208428773677659,"width":2124.6604681556537,"height":1457.7110384194946,"type":"interface","id":"interface-0"}],"visualizations":[{"x":641.558232931727,"y":80.84738955823282,"width":1453.281124497992,"height":942.5622489959841,"type":"map","id":"map-0"},{"x":636.098101265823,"y":1087.6582278481012,"width":1479.2151898734178,"height":369.80379746835433,"type":"parallel_coordinate","id":"parallel_coordinate-1"},{"x":665.1491933138076,"y":82.66377173213162,"width":1434.372760443705,"height":907.9230883105206,"type":"graph","id":"graph-2"}],"relations":[{"vislist":[{"vislist":["graph-2"],"relation":null,"id":"group-5"},{"vislist":["map-0"],"relation":null,"id":"group-6"}],"relation":"coordinated","id":"relation-1"}]},"1832_0":{"comp":[["graph","map",["coordinated"]]],"visType":["graph","map"],"compType":["coordinated"],"compressed_tree":[{"composite_pattern":"coordinated","visualization_type":[["graph"],["map"]]}],"coOccurrence":[["graph","map",["coOccurrence"]]],"year":2009,"conference":["VAST"],"authors":["Gennady L. Andrienko","Natalia V. Andrienko","Salvatore Rinzivillo","Mirco Nanni","Dino Pedreschi","Fosca Giannotti"],"title":"Interactive visual clustering of large collections of trajectories","doi":"10.1109/VAST.2009.5332584","abstract":"One of the most common operations in exploration and analysis of various kinds of data is clustering, i.e. discovery and interpretation of groups of objects having similar properties and/or behaviors. In clustering, objects are often treated as points in multi-dimensional space of properties. However, structurally complex objects, such as trajectories of moving entities and other kinds of spatio-temporal data, cannot be adequately represented in this manner. Such data require sophisticated and computationally intensive clustering algorithms, which are very hard to scale effectively to large datasets not fitting in the computer main memory. We propose an approach to extracting meaningful clusters from large databases by combining clustering and classification, which are driven by a human analyst through an interactive visual interface.","keywords":"Spatio-temporal data, movement data, trajectories, clustering, classification, scalable visualization, geovisualization","caption":"Figure 2. Examples of density-based clusters of trajectories according to the distance function \u201croute similarity\u201d [5].","img_size":{"width":890,"height":514},"subfigures":[{"x":1.9827469362824446,"y":0.13847228520227625,"width":445.3872833032414,"height":513.1563522222993,"type":"single","id":"single-0"}],"visualizations":[{"x":452.8957355263914,"y":7.0838157607356855,"width":429.9182394595901,"height":498.7062133134387,"type":"graph","id":"graph-2"},{"x":11.69320613033783,"y":7.654011753943148,"width":435.5357616629629,"height":500.381209239748,"type":"graph","id":"graph-3"},{"x":10.26168224299056,"y":3.202492211838006,"width":433.93769470404976,"height":505.9937694704049,"type":"map","id":"map-0"},{"x":453.8068535825545,"y":6.404984423676012,"width":429.1339563862928,"height":499.58878504672884,"type":"map","id":"map-1"}],"relations":[{"vislist":[{"vislist":["graph-3"],"relation":null,"id":"group-1"},{"vislist":["map-0"],"relation":null,"id":"group-0"}],"relation":"coordinated","id":"relation-0"}]},"1836_3":{"comp":[["heatmap","map",["coordinated"]]],"visType":["heatmap","map"],"compType":["coordinated"],"compressed_tree":[{"composite_pattern":"coordinated","visualization_type":[["heatmap"],["map"]]}],"coOccurrence":[["heatmap","map",["coOccurrence"]]],"year":2009,"conference":["VAST"],"authors":["Yi Han","Erich P. Stuntebeck","John T. Stasko","Gregory D. Abowd"],"title":"A visual analytics system for radio frequency fingerprinting-based localization","doi":"10.1109/VAST.2009.5332596","abstract":"Radio frequency (RF) fingerprinting-based techniques for localization are a promising approach for ubiquitous positioning systems, particularly indoors. By finding unique fingerprints of RF signals received at different locations within a predefined area beforehand, whenever a similar fingerprint is subsequently seen again, the localization system will be able to infer a user\'s current location. However, developers of these systems face the problem of finding reliable RF fingerprints that are unique enough and adequately stable over time. We present a visual analytics system that enables developers of these localization systems to visually gain insight on whether their collected datasets and chosen fingerprint features have the necessary properties to enable a reliable RF fingerprinting-based localization system. The system was evaluated by testing and debugging an existing localization system.","keywords":"","caption":"Figure 3: Standard deviation view of a selected feature in the Data Variance Perspective that shows several temporally unstable blocks. One is in the kitchen area and two are in the rooms at the back of the house.","img_size":{"width":1005,"height":1107},"subfigures":[{"x":7.548333318109905,"y":5.139294929770563,"width":992.3457734293066,"height":1096.7214101404586,"type":"interface","id":"interface-0"}],"visualizations":[{"x":216.4424409001115,"y":287.6682169545749,"width":464.15844375412894,"height":691.2658167300323,"type":"heatmap","id":"heatmap-0"},{"x":216.8844473842829,"y":290.5803976475408,"width":466.42619842573333,"height":687.2427413998533,"type":"map","id":"map-1"}],"relations":[{"vislist":[{"vislist":["heatmap-0"],"relation":null,"id":"group-1"},{"vislist":["map-1"],"relation":null,"id":"group-0"}],"relation":"coordinated","id":"relation-0"}]},"1837_9":{"comp":[["heatmap","map",["coordinated"]],["graph","map",["coordinated"]]],"visType":["heatmap","map","graph"],"compType":["coordinated"],"compressed_tree":[{"composite_pattern":"coordinated","visualization_type":[["heatmap","graph"],["map"]]},{"composite_pattern":"coordinated","visualization_type":[["heatmap","graph"],["map"]]},{"composite_pattern":"coordinated","visualization_type":[["graph"],["map"]]},{"composite_pattern":"coordinated","visualization_type":[["graph"],["map"]]}],"coOccurrence":[["heatmap","graph",["coOccurrence"]],["heatmap","map",["coOccurrence"]],["graph","map",["coOccurrence"]]],"year":2009,"conference":["VAST"],"authors":["Ho Van Quan","Tobias \xc5str\xf6m","Mikael Jern"],"title":"Geovisual analytics for self-organizing network data","doi":"10.1109/VAST.2009.5332610","abstract":"Cellular radio networks are continually growing in both node count and complexity. It therefore becomes more difficult to manage the networks and necessary to use time and cost effective automatic algorithms to organize the networks neighbor cell relations. There have been a number of attempts to develop such automatic algorithms. Network operators, however, may not trust them because they need to have an understanding of their behavior and of their reliability and performance, which is not easily perceived. This paper presents a novel Web-enabled geovisual analytics approach to exploration and understanding of self-organizing network data related to cells and neighbor cell relations. A demonstrator and case study are presented in this paper, developed in close collaboration with the Swedish telecom company Ericsson and based on large multivariate, time-varying and geospatial data provided by the company. It allows the operators to follow, interact with and analyze the evolution of a self-organizing network and enhance their understanding of how an automatic algorithm configures locally-unique physical cell identities and organizes neighbor cell relations of the network. The geovisual analytics tool is tested with a self-organizing network that is operated by the automatic neighbor relations (ANR) algorithm. The demonstrator has been tested with positive results by a group of domain experts from Ericsson and will be tested in production.","keywords":"Geovisual analytics, visualization, self-organizing network, multi-layer, multi-dimensional, time-varying, geospatial data sets","caption":"Figure 11. Changes occurring in time interval 20 for cases 2 and 3","img_size":{"width":894,"height":652},"subfigures":[{"x":53.468315999952644,"y":6.645271287458381,"width":712.9779765926054,"height":331.7591855886992,"type":"interface","id":"interface-0"}],"visualizations":[{"x":49.56182921631473,"y":26.97194446539781,"width":369.6588700289588,"height":307.17208787753196,"type":"graph","id":"graph-0"},{"x":416.72261495408594,"y":29.37774881802546,"width":344.73563218390814,"height":304.76628352490434,"type":"graph","id":"graph-1"},{"x":415.47357280849207,"y":334.14403234292973,"width":351.0582466736892,"height":309.3675893235975,"type":"graph","id":"graph-2"},{"x":50.610214961950824,"y":331.9537622177836,"width":367.98158489288255,"height":310.0835373316786,"type":"graph","id":"graph-3"},{"x":51.2826168461618,"y":29.553125910168415,"width":366.6763351719396,"height":303.81479187782423,"type":"heatmap","id":"heatmap-4"},{"x":49.19525828284935,"y":333.3687188968851,"width":368.00418770053005,"height":309.60081018898745,"type":"heatmap","id":"heatmap-5"},{"x":419.07001637861487,"y":27.353407350745908,"width":343.48659003831426,"height":308.5134099616858,"type":"map","id":"map-6"},{"x":420.57239413311,"y":336.2193820288857,"width":343.3565138384557,"height":306.6003335058795,"type":"map","id":"map-7"},{"x":48.7014354013912,"y":27.832338280321366,"width":368.0890429906156,"height":307.6070659315861,"type":"map","id":"map-8"},{"x":47.780301603747894,"y":327.7088921804792,"width":369.0101767882589,"height":312.27147543574006,"type":"map","id":"map-9"}],"relations":[{"vislist":[{"vislist":["heatmap-4","graph-0"],"relation":null,"id":"group-7"},{"vislist":["map-8"],"relation":null,"id":"group-1"}],"relation":"coordinated","id":"relation-0"},{"vislist":[{"vislist":["heatmap-5","graph-3"],"relation":null,"id":"group-8"},{"vislist":["map-9"],"relation":null,"id":"group-3"}],"relation":"coordinated","id":"relation-1"},{"vislist":[{"vislist":["graph-1"],"relation":null,"id":"group-6"},{"vislist":["map-6"],"relation":null,"id":"group-5"}],"relation":"coordinated","id":"relation-2"},{"vislist":[{"vislist":["graph-2"],"relation":null,"id":"group-11"},{"vislist":["map-7"],"relation":null,"id":"group-9"}],"relation":"coordinated","id":"relation-3"}]},"1875_4":{"comp":[["graph","matrix",["coordinated"]]],"visType":["graph","matrix"],"compType":["coordinated"],"compressed_tree":[{"composite_pattern":"coordinated","visualization_type":[["graph"],["matrix"]]}],"coOccurrence":[],"year":2009,"conference":["VAST"],"authors":["Jo Wood","Aidan Slingsby","Naz Khalili-Shavarini","Jason Dykes","David M. Mountain"],"title":"Visualization of uncertainty and analysis of geographical data","doi":"10.1109/VAST.2009.5333965","abstract":"A team of five worked on this challenge to identify a possible criminal structure within the Flitter social network. Initially we worked on the problem individually, deliberately not sharing any data, results or conclusions. This maximised the chances of spotting any blunders, unjustified assumptions or inferences and allowed us to triangulate any common conclusions. After an agreed period we shared our results demonstrating the visualization applications we had built and the reasoning behind our conclusions. This sharing of assumptions encouraged us to incorporate uncertainty in our visualization approaches as it became clear that there was a number of possible interpretations of the rules and assumptions governing the challenge. This summary of the work emphasises one of those applications detailing the geographic analysis and uncertainty handling of the network data.","keywords":"","caption":"Figure 2: Left: Flow map of inter-city Flitter contacts. Number indicates number of Flitter members in each city. Right: Origin-Destination map showing numbers of contacts between all combinations of cities.","img_size":{"width":1695,"height":780},"subfigures":[{"x":0.8746249431091745,"y":7.140468348782849,"width":768.9709914785124,"height":770.3562580202025,"type":"single","id":"single-0"},{"x":776.2829442495843,"y":10.812204524822452,"width":914.6758757367171,"height":763.0127856681241,"type":"single","id":"single-1"}],"visualizations":[{"x":8.950381679389253,"y":9.923664122137403,"width":756.1832061068701,"height":754.1984732824425,"type":"graph","id":"graph-0"},{"x":779.0267175572517,"y":5.9541984732824424,"width":913.2925759381997,"height":771.365095022169,"type":"heatmap","id":"heatmap-1"},{"x":777.2917471584063,"y":4.582741102112052,"width":915.027546337045,"height":772.7365523933395,"type":"matrix","id":"matrix-2"},{"x":12.919847328244215,"y":9.923664122137403,"width":752.2137404580151,"height":760.1526717557249,"type":"matrix","id":"matrix-3"}],"relations":[{"vislist":[{"vislist":["graph-0"],"relation":null,"id":"group-1"},{"vislist":["matrix-3"],"relation":null,"id":"group-2"}],"relation":"coordinated","id":"relation-1"}]},"1704_4":{"comp":[["glyph_based","map",["coordinated"]]],"visType":["glyph_based","map"],"compType":["coordinated"],"compressed_tree":[{"composite_pattern":"coordinated","visualization_type":[["glyph_based"],["map"]]}],"coOccurrence":[["glyph_based","map",["coOccurrence"]]],"year":2008,"conference":["VAST"],"authors":["Gennady L. Andrienko","Natalia V. Andrienko"],"title":"Spatio-temporal aggregation for visual analysis of movements","doi":"10.1109/VAST.2008.4677356","abstract":"Data about movements of various objects are collected in growing amounts by means of current tracking technologies. Traditional approaches to visualization and interactive exploration of movement data cannot cope with data of such sizes. In this research paper we investigate the ways of using aggregation for visual analysis of movement data. We define aggregation methods suitable for movement data and find visualization and interaction techniques to represent results of aggregations and enable comprehensive exploration of the data. We consider two possible views of movement, traffic-oriented and trajectory-oriented. Each view requires different methods of analysis and of data aggregation. We illustrate our argument with example data resulting from tracking multiple cars in Milan and example analysis tasks from the domain of city traffic management.","keywords":"Movement data, spatio-temporal data, aggregation, scalable visualization, geovisualization","caption":"Figure 5. The directional bar diagrams show movement data aggregated by compass directions. The lengths of the bars are proportional to the numbers of the cars that moved in the respective directions during a selected time interval. The radii of the circles are proportional to the numbers of the cars with the speeds below a selected threshold (here 5km/h). On the right, only dominant directions are shown, specifically, where values are at least 25% higher than the next highest value (25% is a selected threshold). ","img_size":{"width":2010,"height":1164},"subfigures":[{"x":0.7972009365467982,"y":5.43783169165872,"width":1001.491654039749,"height":1160.8244440091933,"type":"single","id":"single-0"}],"visualizations":[{"x":4.816124469589739,"y":6.5855728429985865,"width":991.1287128712872,"height":1147.5360678925038,"type":"glyph_based","id":"glyph_based-0"},{"x":1010.7623762376239,"y":8.231966053748232,"width":994.8058596997935,"height":1145.889674681754,"type":"glyph_based","id":"glyph_based-1"},{"x":6.462517680339374,"y":11.524752475247528,"width":987.8359264497881,"height":1140.950495049505,"type":"map","id":"map-2"},{"x":1015.701555869873,"y":9.878359264497881,"width":969.7256011315416,"height":1145.889674681754,"type":"map","id":"map-3"}],"relations":[{"vislist":[{"vislist":["glyph_based-0"],"relation":null,"id":"group-0"},{"vislist":["map-2"],"relation":null,"id":"group-1"}],"relation":"coordinated","id":"relation-0"}]},"1551_0":{"comp":[["heatmap","map",["coordinated"]]],"visType":["heatmap","map"],"compType":["coordinated"],"compressed_tree":[{"composite_pattern":"coordinated","visualization_type":[["heatmap"],["map"]]}],"coOccurrence":[["heatmap","map",["coOccurrence"]]],"year":2007,"conference":["InfoVis"],"authors":["Danyel Fisher"],"title":"Hotmap: Looking at Geographic Attention","doi":"10.1109/TVCG.2007.70561","abstract":"Understanding how people use online maps allows data acquisition teams to concentrate their efforts on the portions of the map that are most seen by users. Online maps represent vast databases, and so it is insufficient to simply look at a list of the most-accessed URLs. Hotmap takes advantage of the design of a mapping system\'s imagery pyramid to superpose a heatmap of the log files over the original maps. Users\' behavior within the system can be observed and interpreted. This paper discusses the imagery acquisition task that motivated Hotmap, and presents several examples of information that Hotmap makes visible. We discuss the design choices behind Hotmap, including logarithmic color schemes; low-saturation background images; and tuning images to explore both infrequently-viewed and frequently-viewed spaces.","keywords":"Geographical visualization, GIS, heatmap, server log analysis, online mapping systems, social navigation","caption":"Figure  1.  Hotmap  showing  southwestern  Europe.A  red  markshows that a tile was downloaded at least one time. Interest followsmajor cities, but also note the strong interest in coastlines. Imagerydepicted is at level 13 (approximately 20 meters per pixel).","img_size":{"width":855,"height":768},"subfigures":[{"x":4.915026655480019,"y":1.0419089405761661,"width":846.8640608964657,"height":764.2226877094973,"type":"single","id":"single-0"}],"visualizations":[{"x":10.004672897196313,"y":9.570093457943926,"width":834.9906542056076,"height":753.6448598130842,"type":"heatmap","id":"heatmap-0"},{"x":14.789719626168333,"y":9.570093457943926,"width":830.2056074766356,"height":751.2523364485982,"type":"map","id":"map-1"}],"relations":[{"vislist":[{"vislist":["heatmap-0"],"relation":null,"id":"group-1"},{"vislist":["map-1"],"relation":null,"id":"group-0"}],"relation":"coordinated","id":"relation-0"}]},"1553_1":{"comp":[["graph","map",["coordinated"]]],"visType":["graph","map"],"compType":["coordinated"],"compressed_tree":[{"composite_pattern":"coordinated","visualization_type":[["graph"],["map"]]}],"coOccurrence":[["graph","map",["coOccurrence"]]],"year":2007,"conference":["InfoVis"],"authors":["Jo Wood","Jason Dykes","Aidan Slingsby","Keith Clarke"],"title":"Interactive Visual Exploration of a Large Spatio-temporal Dataset: Reflections on a Geovisualization Mashup.","doi":"10.1109/TVCG.2007.70570","abstract":"Exploratory visual analysis is useful for the preliminary investigation of large structured, multifaceted spatio-temporal datasets. This process requires the selection and aggregation of records by time, space and attribute, the ability to transform data and the flexibility to apply appropriate visual encodings and interactions. We propose an approach inspired by geographical \'mashups\' in which freely-available functionality and data are loosely but flexibly combined using de facto exchange standards. Our case study combines MySQL, PHP and the LandSerf GIS to allow Google Earth to be used for visual synthesis and interaction with encodings described in KML. This approach is applied to the exploration of a log of 1.42 million requests made of a mobile directory service. Novel combinations of interaction and visual encoding are developed including spatial \'tag clouds\', \'tag maps\', \'data dials\' and multi-scale density surfaces. Four aspects of the approach are informally evaluated: the visual encodings employed, their success in the visual exploration of the dataset, the specific tools used and the \'mashup\' approach. Preliminary findings will be beneficial to others considering using mashups for visualization. The specific techniques developed may be more widely applied to offer insights into the structure of multifarious spatio-temporal data of the type explored here.","keywords":"Large dataset visualization, text and document visualization, multiresolution visualization, geographic visualization, applications of infovis","caption":"Fig. 3. Three plotting techniques: overplotting with user initiated \u2018explosion\u2019 (left), proportionally sized (middle) and dithering (right), using identical data and extents. The latter two techniques must have the positional and size adjustments explicitly specified in KML. Photographic imagery copyright 2007 Sanborn.","img_size":{"width":1068,"height":554},"subfigures":[{"x":4.15443186610447,"y":4.902642497260206,"width":347.3219527838967,"height":524.0381624066928,"type":"single","id":"single-0"}],"visualizations":[{"x":5.467612658350863,"y":42.36311786970741,"width":335.8254249450917,"height":457.1117215193856,"type":"graph","id":"graph-3"},{"x":4.73938506588577,"y":5.677891654465593,"width":340.6734992679356,"height":522.3660322108345,"type":"map","id":"map-0"},{"x":353.524158125915,"y":9.733528550512444,"width":343.9180087847731,"height":517.4992679355784,"type":"map","id":"map-1"},{"x":702.3089311859445,"y":10.544655929721815,"width":345.5402635431919,"height":519.1215226939971,"type":"map","id":"map-2"}],"relations":[{"vislist":[{"vislist":["graph-3"],"relation":null,"id":"group-1"},{"vislist":["map-0"],"relation":null,"id":"group-0"}],"relation":"coordinated","id":"relation-0"}]},"1553_4":{"comp":[["word_cloud","map",["coordinated"]]],"visType":["word_cloud","map"],"compType":["coordinated"],"compressed_tree":[{"composite_pattern":"coordinated","visualization_type":[["word_cloud"],["map"]]}],"coOccurrence":[["word_cloud","map",["coOccurrence"]]],"year":2007,"conference":["InfoVis"],"authors":["Jo Wood","Jason Dykes","Aidan Slingsby","Keith Clarke"],"title":"Interactive Visual Exploration of a Large Spatio-temporal Dataset: Reflections on a Geovisualization Mashup.","doi":"10.1109/TVCG.2007.70570","abstract":"Exploratory visual analysis is useful for the preliminary investigation of large structured, multifaceted spatio-temporal datasets. This process requires the selection and aggregation of records by time, space and attribute, the ability to transform data and the flexibility to apply appropriate visual encodings and interactions. We propose an approach inspired by geographical \'mashups\' in which freely-available functionality and data are loosely but flexibly combined using de facto exchange standards. Our case study combines MySQL, PHP and the LandSerf GIS to allow Google Earth to be used for visual synthesis and interaction with encodings described in KML. This approach is applied to the exploration of a log of 1.42 million requests made of a mobile directory service. Novel combinations of interaction and visual encoding are developed including spatial \'tag clouds\', \'tag maps\', \'data dials\' and multi-scale density surfaces. Four aspects of the approach are informally evaluated: the visual encodings employed, their success in the visual exploration of the dataset, the specific tools used and the \'mashup\' approach. Preliminary findings will be beneficial to others considering using mashups for visualization. The specific techniques developed may be more widely applied to offer insights into the structure of multifarious spatio-temporal data of the type explored here.","keywords":"Large dataset visualization, text and document visualization, multiresolution visualization, geographic visualization, applications of infovis","caption":"Fig. 5. Tag map (left) and tag cloud (right) of the 50 most popular business names in the selected geographic area. The smaller bounding box is \u2018bank of america\u2019; the larger is \u2018starbucks\u2019 (which is more spatially diluted). Aerial imagery copyright 2007 NASA.","img_size":{"width":1059,"height":651},"subfigures":[{"x":0.9704328105593412,"y":3.742719930129289,"width":640.4248642792606,"height":645.6678118203802,"type":"single","id":"single-0"}],"visualizations":[{"x":4.792093704246014,"y":2.8594436310395306,"width":637.6559297218155,"height":646.4088417853168,"type":"map","id":"map-0"},{"x":1.7317145836436765,"y":1.7317145836436765,"width":639.5622254758418,"height":647.5365708327126,"type":"word_cloud","id":"word_cloud-1"},{"x":647.2137628111273,"y":1.906295754026354,"width":406.9941434846268,"height":647.187408491947,"type":"word_cloud","id":"word_cloud-2"}],"relations":[{"vislist":[{"vislist":["word_cloud-1"],"relation":null,"id":"group-1"},{"vislist":["map-0"],"relation":null,"id":"group-0"}],"relation":"coordinated","id":"relation-0"}]},"1553_7":{"comp":[["graph","map",["coordinated"]]],"visType":["graph","map"],"compType":["coordinated"],"compressed_tree":[{"composite_pattern":"coordinated","visualization_type":[["graph"],["map"]]},{"composite_pattern":"coordinated","visualization_type":[["graph"],["map"]]},{"composite_pattern":"coordinated","visualization_type":[["graph"],["map"]]}],"coOccurrence":[["graph","map",["coOccurrence"]]],"year":2007,"conference":["InfoVis"],"authors":["Jo Wood","Jason Dykes","Aidan Slingsby","Keith Clarke"],"title":"Interactive Visual Exploration of a Large Spatio-temporal Dataset: Reflections on a Geovisualization Mashup.","doi":"10.1109/TVCG.2007.70570","abstract":"Exploratory visual analysis is useful for the preliminary investigation of large structured, multifaceted spatio-temporal datasets. This process requires the selection and aggregation of records by time, space and attribute, the ability to transform data and the flexibility to apply appropriate visual encodings and interactions. We propose an approach inspired by geographical \'mashups\' in which freely-available functionality and data are loosely but flexibly combined using de facto exchange standards. Our case study combines MySQL, PHP and the LandSerf GIS to allow Google Earth to be used for visual synthesis and interaction with encodings described in KML. This approach is applied to the exploration of a log of 1.42 million requests made of a mobile directory service. Novel combinations of interaction and visual encoding are developed including spatial \'tag clouds\', \'tag maps\', \'data dials\' and multi-scale density surfaces. Four aspects of the approach are informally evaluated: the visual encodings employed, their success in the visual exploration of the dataset, the specific tools used and the \'mashup\' approach. Preliminary findings will be beneficial to others considering using mashups for visualization. The specific techniques developed may be more widely applied to offer insights into the structure of multifarious spatio-temporal data of the type explored here.","keywords":"Large dataset visualization, text and document visualization, multiresolution visualization, geographic visualization, applications of infovis","caption":"Fig. 8. Population density surface generated in LandSerf displayed in Google Earth using geo-mipmapping. The surfaces displayed at any viewpoint relate to resolutions appropriate for the distance of view. Aerial imagery copyright 2007 NASA, Europa Technologies and TerraMetrics Inc.","img_size":{"width":1055,"height":577},"subfigures":[{"x":4.278416037498069,"y":7.100762157785558,"width":403.9477647864017,"height":565.3431274401444,"type":"single","id":"single-0"}],"visualizations":[{"x":3.3001464128844016,"y":11.827232796486092,"width":402.9707174231333,"height":554.190336749634,"type":"map","id":"map-0"},{"x":417.2532942898976,"y":10.982430453879942,"width":326.09370424597375,"height":557.5695461200586,"type":"map","id":"map-1"},{"x":750.9502196193266,"y":6.758418740849194,"width":299.06002928257675,"height":560.9487554904832,"type":"map","id":"map-2"},{"x":7.524158125915136,"y":11.827232796486092,"width":401.2811127379209,"height":554.190336749634,"type":"graph","id":"graph-3"},{"x":415.56368960468535,"y":10.982430453879942,"width":332.0073206442167,"height":555.8799414348463,"type":"graph","id":"graph-4"},{"x":752.6398243045389,"y":9.292825768667642,"width":294.83601756954613,"height":558.4143484626647,"type":"graph","id":"graph-5"}],"relations":[{"vislist":[{"vislist":["graph-3"],"relation":null,"id":"group-1"},{"vislist":["map-0"],"relation":null,"id":"group-0"}],"relation":"coordinated","id":"relation-0"},{"vislist":[{"vislist":["graph-4"],"relation":null,"id":"group-3"},{"vislist":["map-1"],"relation":null,"id":"group-2"}],"relation":"coordinated","id":"relation-1"},{"vislist":[{"vislist":["graph-5"],"relation":null,"id":"group-5"},{"vislist":["map-2"],"relation":null,"id":"group-4"}],"relation":"coordinated","id":"relation-2"}]},"1563_2":{"comp":[["glyph_based","map",["coordinated"]]],"visType":["glyph_based","map"],"compType":["coordinated"],"compressed_tree":[{"composite_pattern":"coordinated","visualization_type":[["glyph_based"],["map"]]}],"coOccurrence":[["glyph_based","map",["coOccurrence"]]],"year":2007,"conference":["InfoVis"],"authors":["Mike Cammarano","Xin Don","Bryan Chan","Jeff Klingner","Justin Talbot","Alon Y. Halevy","Pat Hanrahan"],"title":"Visualization of Heterogeneous Data","doi":"10.1109/TVCG.2007.70617","abstract":"Both the resource description framework (RDF), used in the semantic web, and Maya Viz u-forms represent data as a graph of objects connected by labeled edges. Existing systems for flexible visualization of this kind of data require manual specification of the possible visualization roles for each data attribute. When the schema is large and unfamiliar, this requirement inhibits exploratory visualization by requiring a costly up-front data integration step. To eliminate this step, we propose an automatic technique for mapping data attributes to visualization attributes. We formulate this as a schema matching problem, finding appropriate paths in the data model for each required visualization attribute in a visualization template.","keywords":"Data integration, RDF, attribute inference","caption":"Fig. 2. A map marking states with their senators, based on data auto-matically extracted from dbpedia.","img_size":{"width":1056,"height":690},"subfigures":[{"x":4.099425549164088,"y":5.477348431005894,"width":1048.5621369334865,"height":682.0883009047892,"type":"single","id":"single-0"}],"visualizations":[{"x":10.167544427115068,"y":10.49719900634736,"width":1038.6030092906826,"height":672.6772746318406,"type":"glyph_based","id":"glyph_based-1"},{"x":7.328147100424246,"y":11.711456859971712,"width":1038.4158415841584,"height":672.4328147100425,"type":"map","id":"map-0"}],"relations":[{"vislist":[{"vislist":["glyph_based-1"],"relation":null,"id":"group-1"},{"vislist":["map-0"],"relation":null,"id":"group-0"}],"relation":"coordinated","id":"relation-0"}]},"1568_7":{"comp":[["glyph_based","map",["coordinated"]]],"visType":["glyph_based","map"],"compType":["coordinated"],"compressed_tree":[{"composite_pattern":"coordinated","visualization_type":[["glyph_based"],["map"]]}],"coOccurrence":[["glyph_based","map",["coOccurrence"]]],"year":2007,"conference":["VAST"],"authors":["Chi-Chun Pan","Prasenjit Mitra"],"title":"FemaRepViz: Automatic Extraction and Geo-Temporal Visualization of FEMA National Situation Updates","doi":"10.1109/VAST.2007.4388991","abstract":"An architecture for visualizing information extracted from text documents is proposed. In conformance with this architecture, a toolkit, FemaRepViz, has been implemented to extract and visualize temporal, geospatial, and summarized information from FEMA national update reports. Preliminary tests have shown satisfactory accuracy for FEMARepViz. A central component of the architecture is an entity extractor that extracts named entities like person names, location names, temporal references, etc. FEMARepViz is based on FactXtractor, an entity-extractor that works on text documents. The information extracted using FactXtractor is processed using GeoTagger, a geographical name disambiguation tool based on a novel clustering-based disambiguation algorithm. To extract relationships among entities, we propose a machine-learning based algorithm that uses a novel stripped dependency tree kernel. We illustrate and evaluate the usefulness of our system on the FEMA National Situation Updates. Daily reports are fetched by FEMARepViz from the FEMA website, segmented into coherent sections and each section is classified into one of several known incident types. We use concept Vista, Google maps and Google earth to visualize the events extracted from the text reports and allow the user to interactively filter the topics, locations, and time-periods of interest to create a visual analytics toolkit that is useful for rapid analysis of events reported in a large set of text documents.","keywords":"visual analytics, geo-temporal visualization, text processing, knowledge discovery, geospatial analytics","caption":"Figure4: Processed FEMA National Situation Updates from Feb 3, 2007 to Feb 6, 2007.","img_size":{"width":1600,"height":1069},"subfigures":[{"x":6.587901345547198,"y":6.114690312124182,"width":1579.747468253162,"height":1053.2347882749805,"type":"interface","id":"interface-0"}],"visualizations":[{"x":401.3463791018504,"y":218.63786596686174,"width":1115.648021827662,"height":582.8037531528453,"type":"glyph_based","id":"glyph_based-1"},{"x":289.05076628352475,"y":77.81992337164749,"width":1286.0766283524902,"height":982.9885057471262,"type":"map","id":"map-0"}],"relations":[{"vislist":[{"vislist":["glyph_based-1"],"relation":null,"id":"group-1"},{"vislist":["map-0"],"relation":null,"id":"group-0"}],"relation":"coordinated","id":"relation-0"}]},"1569_0":{"comp":[["line_chart","map",["coordinated"]]],"visType":["line_chart","map"],"compType":["coordinated"],"compressed_tree":[{"composite_pattern":"coordinated","visualization_type":[["line_chart"],["map"]]}],"coOccurrence":[["line_chart","map",["coOccurrence"]]],"year":2007,"conference":["VAST"],"authors":["Ryan Eccles","Thomas Kapler","Robert Harpe","William Wright"],"title":"Stories in GeoTime","doi":"10.1109/VAST.2007.4388992","abstract":"A story is a powerful abstraction used by intelligence analysts to conceptualize threats and understand patterns as part of the analytical process. This paper demonstrates a system that detects geo-temporal patterns and integrates story narration to increase analytic sense-making cohesion in GeoTime. The GeoTime geo-temporal event visualization tool was augmented with a story system that uses narratives, hypertext linked visualizations, visual annotations, and pattern detection to create an environment for analytic exploration and communication, thereby assisting the analyst in identifying, extracting, arranging and presenting stories within the data The story system lets analysts operate at the story level with higher-level abstractions of data, such as behaviors and events, while staying connected to the evidence. The story system was developed and evaluated in collaboration with analysts.","keywords":"human information interaction, visual analytics, sense-making, narrative, pattern detection, story making, story telling","caption":"Figure 1. GeoTime for analysis of events in time and space.","img_size":{"width":1032,"height":735},"subfigures":[{"x":5.014630861510853,"y":5.103807971681275,"width":1021.9707382769788,"height":724.7923840566381,"type":"interface","id":"interface-0"}],"visualizations":[{"x":802.5834684707775,"y":337.46574312034653,"width":198.98315250272023,"height":125.77549030237569,"type":"bar_chart","id":"bar_chart-3"},{"x":12.62356321839087,"y":78.85057471264372,"width":791.3218390804597,"height":616.7241379310345,"type":"line_chart","id":"line_chart-1"},{"x":12.623563218390812,"y":80.25862068965517,"width":789.9137931034483,"height":615.316091954023,"type":"map","id":"map-0"}],"relations":[{"vislist":[{"vislist":["line_chart-1"],"relation":null,"id":"group-1"},{"vislist":["map-0"],"relation":null,"id":"group-0"}],"relation":"coordinated","id":"relation-0"}]},"1571_10":{"comp":[["heatmap","map",["coordinated"]]],"visType":["heatmap","map"],"compType":["coordinated"],"compressed_tree":[{"composite_pattern":"coordinated","visualization_type":[["heatmap"],["map"]]},{"composite_pattern":"coordinated","visualization_type":[["heatmap"],["map"]]}],"coOccurrence":[["heatmap","map",["coOccurrence"]]],"year":2007,"conference":["VAST"],"authors":["SungYe Kim","Yun Jang","Angela Mellema","David S. Ebert","Timothy W. Collins"],"title":"Visual Analytics on Mobile Devices for Emergency Response","doi":"10.1109/VAST.2007.4388994","abstract":"Using mobile devices for visualization provides a ubiquitous environment for accessing information and effective decision making. These visualizations are critical in satisfying the knowledge needs of operators in areas as diverse as education, business, law enforcement, protective services, medical services, scientific discovery, and homeland security. In this paper, we present an efficient and interactive mobile visual analytic system for increased situational awareness and decision making in emergency response and training situations. Our system provides visual analytics with locational scene data within a simple interface tailored to mobile device capabilities. In particular, we focus on processing and displaying sensor network data for first responders. To verify our system, we have used simulated data of The Station nightclub fire evacuation.","keywords":"mobile visualization, visual analytics, emergency response","caption":"Figure 6: Visualization of the temperature spread at different time steps.","img_size":{"width":1014,"height":672},"subfigures":[{"x":3.94117803373267,"y":6.3205921530665865,"width":502.1383534998672,"height":656.394037937463,"type":"single","id":"single-0"}],"visualizations":[{"x":3.7379209370425315,"y":4.919472913616398,"width":503.75402635431925,"height":660.1932650073207,"type":"heatmap","id":"heatmap-0"},{"x":507.4919472913618,"y":3.935578330893119,"width":498.83455344070285,"height":663.1449487554905,"type":"heatmap","id":"heatmap-1"},{"x":2.858754104612051,"y":5.950353907515261,"width":499.2233448565126,"height":658.668936233011,"type":"map","id":"map-2"},{"x":506.90521669071825,"y":5.941185867076077,"width":497.8091821610438,"height":656.5417383859532,"type":"map","id":"map-3"}],"relations":[{"vislist":[{"vislist":["heatmap-0"],"relation":null,"id":"group-1"},{"vislist":["map-2"],"relation":null,"id":"group-0"}],"relation":"coordinated","id":"relation-0"},{"vislist":[{"vislist":["heatmap-1"],"relation":null,"id":"group-3"},{"vislist":["map-3"],"relation":null,"id":"group-2"}],"relation":"coordinated","id":"relation-1"}]},"1570_1":{"comp":[["glyph_based","map",["coordinated"]]],"visType":["glyph_based","map"],"compType":["coordinated"],"compressed_tree":[{"composite_pattern":"coordinated","visualization_type":[["glyph_based"],["map"]]},{"composite_pattern":"coordinated","visualization_type":[["glyph_based"],["map"]]}],"coOccurrence":[["glyph_based","map",["coOccurrence"]]],"year":2007,"conference":["VAST"],"authors":["Ross Maciejewski","Benjamin Tyner","Yun Jang","Cheng Zheng","Rimma V. Nehme","David S. Ebert","William S. Cleveland","Mourad Ouzzani","Shaun J. Grannis","Lawrence T. Glickman"],"title":"LAHVA: Linked Animal-Human Health Visual Analytics","doi":"10.1109/VAST.2007.4388993","abstract":"Coordinated animal-human health monitoring can provide an early warning system with fewer false alarms for naturally occurring disease outbreaks, as well as biological, chemical and environmental incidents. This monitoring requires the integration and analysis of multi-field, multi-scale and multi-source data sets. In order to better understand these data sets, models and measurements at different resolutions must be analyzed. To facilitate these investigations, we have created an application to provide a visual analytics framework for analyzing both human emergency room data and veterinary hospital data. Our integrated visual analytic tool links temporally varying geospatial visualization of animal and human patient health information with advanced statistical analysis of these multi-source data. Various statistical analysis techniques have been applied in conjunction with a spatio-temporal viewing window. Such an application provides researchers with the ability to visually search the data for clusters in both a statistical model view and a spatio-temporal view. Our interface provides a factor specification/filtering component to allow exploration of causal factors and spread patterns. In this paper, we will discuss the application of our linked animal-human visual analytics (LAHVA) tool to two specific case studies. The first case study is the effect of seasonal influenza and its correlation with different companion animals (e.g., cats, dogs) syndromes. Here we use data from the Indiana Network for Patient Care (INPC) and Banfield Pet Hospitals in an attempt to determine if there are correlations between respiratory syndromes representing the onset of seasonal influenza in humans and general respiratory syndromes in cats and dogs. Our second case study examines the effect of the release of industrial wastewater in a community through companion animal surveillance.","keywords":"","caption":"Figure 2: LAHVA screen shots. (Left) Geospatial temporal view. (Right) Statistical view.","img_size":{"width":1986,"height":738},"subfigures":[{"x":-2.3620910364239167,"y":5.921406701958941,"width":959.9741818493109,"height":727.2423596046909,"type":"interface","id":"interface-0"}],"visualizations":[{"x":306.55755160544396,"y":80.31913406581647,"width":464.9505424151988,"height":523.2824809125632,"type":"glyph_based","id":"glyph_based-3"},{"x":1040.5400625249022,"y":478.0982440142788,"width":230.1688345391906,"height":218.21049061479243,"type":"glyph_based","id":"glyph_based-4"},{"x":1337.57670221493,"y":171.86628383921249,"width":625.6144380639867,"height":373.08777686628383,"type":"line_chart","id":"line_chart-2"},{"x":1039.2099447513813,"y":464.8176795580111,"width":275.9005524861877,"height":244.64088397790053,"type":"map","id":"map-0"},{"x":298.49171270718233,"y":73.39226519337016,"width":648.0759657177562,"height":564.4264386622492,"type":"map","id":"map-1"}],"relations":[{"vislist":[{"vislist":["glyph_based-3"],"relation":null,"id":"group-1"},{"vislist":["map-1"],"relation":null,"id":"group-0"}],"relation":"coordinated","id":"relation-0"},{"vislist":[{"vislist":["glyph_based-4"],"relation":null,"id":"group-3"},{"vislist":["map-0"],"relation":null,"id":"group-2"}],"relation":"coordinated","id":"relation-1"}]},"1572_10":{"comp":[["graph","map",["coordinated"]]],"visType":["graph","map"],"compType":["coordinated"],"compressed_tree":[{"composite_pattern":"coordinated","visualization_type":[["graph"],["map"]]}],"coOccurrence":[["graph","map",["coOccurrence"]]],"year":2007,"conference":["VAST"],"authors":["Gennady L. Andrienko","Natalia V. Andrienko","Ulrich Bartling"],"title":"Visual Analytics Approach to User-Controlled Evacuation Scheduling","doi":"10.1109/VAST.2007.4388995","abstract":"Application of the ideas of visual analytics is a promising approach to supporting decision making, in particular, where the problems have geographic (or spatial) and temporal aspects. Visual analytics may be especially helpful in time-critical applications, which pose hard challenges to decision support. We have designed a suite of tools to support transportation-planning tasks such as emergency evacuation of people from a disaster- affected area. The suite combines a tool for automated scheduling based on a genetic algorithm with visual analytics techniques allowing the user to evaluate tool results and direct its work. A transportation schedule, which is generated by the tool, is a complex construct involving geographical space, time, and heterogeneous objects (people and vehicles) with states and positions varying in time. We apply task-analytical approach to design techniques that could effectively support a human planner in the analysis of this complex information H. 1.2 [User/Machine Systems]: Human information processing - Visual Analytics; 1.6.9 [Visualization]: information visualization.","keywords":"Geovisualization, transportation planning, vehicle scheduling, task-centered design, coordinated multiple views","caption":"Figure 11.   The map display portrays the geographic information corresponding to the second row of the matrix in Figure 10.","img_size":{"width":1021,"height":449},"subfigures":[{"x":2.548110871299432,"y":3.111620565712253,"width":1014.7869296187815,"height":447.2423269141599,"type":"single","id":"single-0"}],"visualizations":[{"x":7.740421455938685,"y":6.881226053639846,"width":1001.2183908045977,"height":439.5383141762451,"type":"map","id":"map-0"},{"x":5.65766634773151,"y":10.447824031268766,"width":996.7726932257382,"height":434.5620749991661,"type":"graph","id":"graph-1"}],"relations":[{"vislist":[{"vislist":["graph-1"],"relation":null,"id":"group-2"},{"vislist":["map-0"],"relation":null,"id":"group-3"}],"relation":"coordinated","id":"relation-1"}]},"1603_2":{"comp":[["graph","donut_chart",["coordinated"]]],"visType":["graph","donut_chart"],"compType":["coordinated"],"compressed_tree":[{"composite_pattern":"coordinated","visualization_type":[["graph"],["donut_chart"]]}],"coOccurrence":[["graph","donut_chart",["coOccurrence"]]],"year":2007,"conference":["VAST"],"authors":["Adel Ahmed","Xiaoyan Fu","Seok-Hee Hong","Quan Hoang Nguyen","Kai X"],"title":"Visual Analysis of Dynamic Networks with Geological Clustering","doi":"10.1109/VAST.2007.4389027","abstract":"Many dynamic networks have associated geological information. Here we present two complementing visual analysis methods for such networks. The first one provides an overview with summerized information while the second one presents a more detailed view. The geological information is encoded in the network layout, which is designed to help maintain user\'s mental map. We also combined visualization with social network analysis to facilitate knowledge discovery, especially to understand network changes in the context overall evolution. Both methods are applied to the \\"History of the FIFA World Cup Competition\\" data set.","keywords":"","caption":"Figure 3: World Cup 2002.","img_size":{"width":616,"height":763},"subfigures":[{"x":11.201134104416052,"y":105.50581900149984,"width":599.4908452433483,"height":621.8108277845835,"type":"single","id":"single-0"}],"visualizations":[{"x":2.029643974378072,"y":123.601246105919,"width":601.3676012461059,"height":603.7445482866043,"type":"donut_chart","id":"donut_chart-0"},{"x":4.9392523364485905,"y":125.97819314641742,"width":596.613707165109,"height":603.7445482866044,"type":"graph","id":"graph-1"}],"relations":[{"vislist":[{"vislist":["graph-1"],"relation":null,"id":"group-1"},{"vislist":["donut_chart-0"],"relation":null,"id":"group-0"}],"relation":"coordinated","id":"relation-0"}]},"2099_4":{"comp":[["graph","map",["coordinated"]],["graph","comb",["annotated"]]],"visType":["graph","map","comb"],"compType":["coordinated","annotated"],"compressed_tree":[{"composite_pattern":"annotated","visualization_type":[["graph"],[{"composite_pattern":"coordinated","visualization_type":[["graph"],["map"]]}]]}],"coOccurrence":[["graph","map",["coOccurrence"]]],"year":2011,"conference":["InfoVis"],"authors":["Steffen Hadlak","Hans-J\xf6rg Schulz","Heidrun Schumann"],"title":"In Situ Exploration of Large Dynamic Networks","doi":"10.1109/TVCG.2011.213","abstract":"The analysis of large dynamic networks poses a challenge in many fields, ranging from large bot-nets to social networks. As dynamic networks exhibit different characteristics, e.g., being of sparse or dense structure, or having a continuous or discrete time line, a variety of visualization techniques have been specifically designed to handle these different aspects of network structure and time. This wide range of existing techniques is well justified, as rarely a single visualization is suitable to cover the entire visual analysis. Instead, visual representations are often switched in the course of the exploration of dynamic graphs as the focus of analysis shifts between the temporal and the structural aspects of the data. To support such a switching in a seamless and intuitive manner, we introduce the concept of in situ visualization- a novel strategy that tightly integrates existing visualization techniques for dynamic networks. It does so by allowing the user to interactively select in a base visualization a region for which a different visualization technique is then applied and embedded in the selection made. This permits to change the way a locally selected group of data items, such as nodes or time points, are shown - right in the place where they are positioned, thus supporting the user\'s overall mental map. Using this approach, a user can switch seamlessly between different visual representations to adapt a region of a base visualization to the specifics of the data within it or to the current analysis focus. This paper presents and discusses the in situ visualization strategy and its implications for dynamic graph visualization. Furthermore, it illustrates its usefulness by employing it for the visual exploration of dynamic networks from two different fields: model versioning and wireless mesh networks.","keywords":"Dynamic graph data, multiform visualization, multi-focus+context","caption":"Fig. 4. Visualization of the Opennet mesh network on 01/16/11. Thebase visualization shows the network overview on top of a map. Node-link and matrix visualizations are embedded to better reflect the struc-ture of spatially clustered subgraphs in the villages around Rostock. Theoverlay capability of the in situ strategy is used to maintain the connec-tions across different representations. Individual nodes of interest areshown in even more detail in further embedded in situ views.","img_size":{"width":961,"height":1435},"subfigures":[{"x":10.410708676648104,"y":17.25238362551706,"width":934.0747295722039,"height":1398.9680297794282,"type":"interface","id":"interface-0"}],"visualizations":[{"x":28.28256704980845,"y":96.21647509578544,"width":901.6858237547892,"height":1305.795019157088,"type":"map","id":"map-0"},{"x":534.1063218390804,"y":335.3831417624521,"width":376.61877394636025,"height":373.86973180076626,"type":"graph","id":"graph-1"},{"x":47.52586206896558,"y":722.9980842911878,"width":514.0708812260536,"height":670.7662835249041,"type":"graph","id":"graph-2"},{"x":20.03544061302682,"y":96.21647509578544,"width":920.9291187739462,"height":1305.795019157088,"type":"graph","id":"graph-3"},{"x":600.0833333333333,"y":1036.388888888889,"width":327.1360153256703,"height":365.6226053639846,"type":"matrix","id":"matrix-4"}],"relations":[{"vislist":[{"vislist":["graph-1","graph-2"],"relation":null,"id":"group-3"},{"vislist":[{"vislist":[{"vislist":["graph-3"],"relation":null,"id":"group-1"},{"vislist":["map-0"],"relation":null,"id":"group-0"}],"relation":"coordinated","id":"relation-0"}],"relation":null,"id":"group-2"}],"relation":"annotated","id":"relation-1"}]},"2133_2":{"comp":[["heatmap","map",["coordinated"]]],"visType":["heatmap","map"],"compType":["coordinated"],"compressed_tree":[{"composite_pattern":"coordinated","visualization_type":[["heatmap"],["map"]]}],"coOccurrence":[["heatmap","map",["coOccurrence"]]],"year":2011,"conference":["VAST"],"authors":["Alan M. MacEachren","Anuj R. Jaiswal","Anthony C. Robinson","Scott Pezanowski","Alexander Savelyev","Prasenjit Mitra","Xiao Zhang","Justine I. Blanford"],"title":"SensePlace2: GeoTwitter analytics support for situational awareness","doi":"10.1109/VAST.2011.6102456","abstract":"Geographically-grounded situational awareness (SA) is critical to crisis management and is essential in many other decision making domains that range from infectious disease monitoring, through regional planning, to political campaigning. Social media are becoming an important information input to support situational assessment (to produce awareness) in all domains. Here, we present a geovisual analytics approach to supporting SA for crisis events using one source of social media, Twitter. Specifically, we focus on leveraging explicit and implicit geographic information for tweets, on developing place-time-theme indexing schemes that support overview+detail methods and that scale analytical capabilities to relatively large tweet volumes, and on providing visual interface methods to enable understanding of place, time, and theme components of evolving situations. Our approach is user-centered, using scenario-based design methods that include formal scenarios to guide design and validate implementation as well as a systematic claims analysis to justify design choices and provide a framework for future testing. The work is informed by a structured survey of practitioners and the end product of Phase-I development is demonstrated / validated through implementation in SensePlace2, a map-based, web application initially focused on tweets but extensible to other media.","keywords":"social media analytics, scenario-based design, geovisualization, situational awareness, text analytics, crisis management, spatio-temporal analysis ","caption":"Fig. 3. SensePlace 2 mockup used in survey.","img_size":{"width":1005,"height":783},"subfigures":[{"x":3.4183663842359326,"y":-3.000434367760834,"width":996.4973790419164,"height":782.3343883165742,"type":"interface","id":"interface-0"}],"visualizations":[{"x":394.17984189723313,"y":40.233201581027664,"width":608.1403162055337,"height":459.586956521739,"type":"heatmap","id":"heatmap-0"},{"x":395.72727272727275,"y":37.13833992094862,"width":607.1898816214324,"height":461.13438735177857,"type":"map","id":"map-1"},{"x":8.869565217391312,"y":540.0533596837945,"width":383.7628458498023,"height":236.75691699604738,"type":"word_cloud","id":"word_cloud-2"}],"relations":[{"vislist":[{"vislist":["heatmap-0"],"relation":null,"id":"group-1"},{"vislist":["map-1"],"relation":null,"id":"group-0"}],"relation":"coordinated","id":"relation-0"}]},"2137_0":{"comp":[["heatmap","map",["coordinated"]],["bar_chart","matrix",["stacked"]],["matrix","bar_chart",["stacked"]]],"visType":["heatmap","map","bar_chart","matrix"],"compType":["coordinated","stacked"],"compressed_tree":[{"composite_pattern":"coordinated","visualization_type":[["heatmap"],["map"]]},{"composite_pattern":"stacked","visualization_type":[["bar_chart","matrix"]]},{"composite_pattern":"stacked","visualization_type":[["bar_chart","matrix"]]}],"coOccurrence":[["heatmap","map",["coOccurrence"]],["heatmap","bar_chart",["coOccurrence"]],["heatmap","matrix",["coOccurrence"]],["map","bar_chart",["coOccurrence"]],["map","matrix",["coOccurrence"]],["bar_chart","matrix",["coOccurrence"]]],"year":2011,"conference":["VAST"],"authors":["Abish Malik","Ross Maciejewski","Ben Maule","David S. Ebert"],"title":"A visual analytics process for maritime resource allocation and risk assessment","doi":"10.1109/VAST.2011.6102460","abstract":"In this paper, we present our collaborative work with the U.S. Coast Guard\'s Ninth District and Atlantic Area Commands where we developed a visual analytics system to analyze historic response operations and assess the potential risks in the maritime environment associated with the hypothetical allocation of Coast Guard resources. The system includes linked views and interactive displays that enable the analysis of trends, patterns and anomalies among the U.S. Coast Guard search and rescue (SAR) operations and their associated sorties. Our system allows users to determine the potential change in risks associated with closing certain stations in terms of response time, potential lives and property lost and provides optimal direction as to the nearest available station. We provide maritime risk assessment tools that allow analysts to explore Coast Guard coverage for SAR operations and identify regions of high risk. The system also enables a thorough assessment of all SAR operations conducted by each Coast Guard station in the Great Lakes region. Our system demonstrates the effectiveness of visual analytics in analyzing risk within the maritime domain and is currently being used by analysts at the Coast Guard Atlantic Area.","keywords":"Visual analytics, risk assessment, Coast Guard","caption":"Figure 1: A screenshot of our risk assessment visual analytics system. Here, the user is visualizing all search and rescue (SAR) operations conducted by the U.S. Coast Guard in the Great Lakes region in July 2008. The main viewing area (a) shows the map view with the circles showing the locations of SAR incidents in the Great Lakes. The right-most window (b) shows an interactive menu showing all distress types with SAR cases selected in blue. The top window (c) shows the time-series and the left window (d) shows the calendar views of the SAR incident report data. The bottom-left window (e) shows the time slider with radio buttons that allow different temporal aggregation levels. A legend for all District Nine maritime zones is shown in the upper right (f).","img_size":{"width":2112,"height":1323},"subfigures":[{"x":7.911196801118714,"y":8.972662180376163,"width":2097.585041350718,"height":1313.5027154804998,"type":"interface","id":"interface-0"}],"visualizations":[{"x":96.19546120058571,"y":1140.9180087847728,"width":211.13762811127376,"height":147.21522693997076,"type":"bar_chart","id":"bar_chart-0"},{"x":279.22173417927024,"y":135.18977644531023,"width":90.67289719626181,"height":1022.1308411214952,"type":"bar_chart","id":"bar_chart-1"},{"x":502.9743777452416,"y":488.134699853587,"width":1596.1229868228397,"height":817.4319180087847,"type":"map","id":"map-2"},{"x":501.0373352855051,"y":484.2606149341141,"width":1605.8081991215226,"height":825.1800878477304,"type":"heatmap","id":"heatmap-3"},{"x":543.6522693997072,"y":54.23718887262078,"width":1160.2884333821376,"height":298.3045387994143,"type":"line_chart","id":"line_chart-4"},{"x":2.4154057067072716,"y":99.8478470177983,"width":276.12908351224104,"height":1041.6812540102871,"type":"matrix","id":"matrix-5"},{"x":3.519290928050052,"y":100.72620790629571,"width":371.25549048316253,"height":1191.2811127379207,"type":"unit_visualization","id":"unit_visualization-6"}],"relations":[{"vislist":[{"vislist":["heatmap-3"],"relation":null,"id":"group-1"},{"vislist":["map-2"],"relation":null,"id":"group-0"}],"relation":"coordinated","id":"relation-0"},{"vislist":[{"vislist":["bar_chart-1","matrix-5"],"relation":null,"id":"group-2"}],"relation":"stacked","id":"relation-1"},{"vislist":[{"vislist":["bar_chart-0","matrix-5"],"relation":null,"id":"group-3"}],"relation":"stacked","id":"relation-2"}]},"2152_0":{"comp":[["graph","matrix",["coordinated"]]],"visType":["graph","matrix"],"compType":["coordinated"],"compressed_tree":[{"composite_pattern":"coordinated","visualization_type":[["graph"],["matrix"]]}],"coOccurrence":[["graph","matrix",["coOccurrence"]]],"year":2011,"conference":["VAST"],"authors":["Dong Hyun Jeong","Soo-Yeon Ji","William Ribarsky","Remco Chang"],"title":"A state transition approach to understanding users\' interactions","doi":"10.1109/VAST.2011.6102476","abstract":"Understanding users\' interactions is considered as one of the important research topics in visual analytics. Although numerous empirical user studies have been performed to understand a user\'s interaction, a limited study has been successful in connecting the user\'s interaction to his/her reasoning. In this paper, we present an approach of understanding experts\' interactive analysis by connecting their interactions to conclusions (i.e. findings) through a state transition approach.","keywords":"","caption":"Figure 1: Overview of InteractionViz. It consists of two windows as a Relation Window (a) and a Transition Window (b). The Relation Window consists of multiple coordinated views to show the relationships among keywords, accounts, and transactions. Experts\u2019 findings on transactions are represented in the Relation Window and their overall semantic-level interactions (i.e. keywords, accounts, and transactions) are displayed in the Transition Window by following a state transition approach.","img_size":{"width":1650,"height":726},"subfigures":[{"x":4.958606122395786,"y":6.920783551103616,"width":665.7397405564728,"height":664.8236195583911,"type":"single","id":"single-0"},{"x":687.5325677668458,"y":5.246404526870448,"width":959.4689029219054,"height":674.1968083955086,"type":"single","id":"single-1"}],"visualizations":[{"x":696.4079538165493,"y":2.624759461193092,"width":943.0083386786406,"height":655.131494547787,"type":"graph","id":"graph-0"},{"x":695.3495830660682,"y":4.741500962155246,"width":945.1250801796026,"height":653.014753046825,"type":"matrix","id":"matrix-1"},{"x":10.583707504810778,"y":436.556767158435,"width":651.9563822963438,"height":228.60808210391286,"type":"parallel_coordinate","id":"parallel_coordinate-2"},{"x":12.700449005772933,"y":11.09172546504171,"width":645.6061577934574,"height":423.3483001924311,"type":"scatterplot","id":"scatterplot-3"}],"relations":[{"vislist":[{"vislist":["graph-0"],"relation":null,"id":"group-1"},{"vislist":["matrix-1"],"relation":null,"id":"group-0"}],"relation":"coordinated","id":"relation-0"}]},"2163_1":{"comp":[["graph","map",["coordinated"]]],"visType":["graph","map"],"compType":["coordinated"],"compressed_tree":[{"composite_pattern":"coordinated","visualization_type":[["graph"],["map"]]}],"coOccurrence":[["graph","map",["coOccurrence"]]],"year":2011,"conference":["VAST"],"authors":["Victor Y. Chen","Cheryl Z. Qian","Li Zhang"],"title":"MobileAnalymator: Animating data changes on mobile devices","doi":"10.1109/VAST.2011.6102490","abstract":"MobileAnalymator (Mobile Analysis Animator) is a visual analytic system designed to analyze geospatial-temporal data on mobile devices. The system is an Internet based application that allows analysts to work in flexile enviornments at anytime. Its client side is developed by Adobe Flash to animate and interact with data. The server side uses Java and MySQL to query, compute, and serve data. The analyst can run the analytical task from a tablet (or computer) with Internet connection. MobileAnalymator adopted spatial and temporal autocorrelations in the interface design and integrated tangible interaction in the navigation to support analysis process.","keywords":"","caption":"Figure 3: Trace sick bloggers who blogged at night May 18th in Villa and Eastside (the blogger moved from the dark shade end to the bright yellow end).","img_size":{"width":1014,"height":585},"subfigures":[{"x":2.7825086771376557,"y":3.337362849211539,"width":1004.6979751026275,"height":578.9478622717372,"type":"interface","id":"interface-0"}],"visualizations":[{"x":9.294908062234809,"y":33.097595473833096,"width":922.5954738330977,"height":471.6407355021216,"type":"map","id":"map-0"},{"x":8.467468175388973,"y":33.097595473833096,"width":925.0777934936352,"height":473.2956152758133,"type":"graph","id":"graph-1"}],"relations":[{"vislist":[{"vislist":["graph-1"],"relation":null,"id":"group-3"},{"vislist":["map-0"],"relation":null,"id":"group-4"}],"relation":"coordinated","id":"relation-1"}]},"2985_0":{"comp":[["vector_graph","map",["coordinated"]],["bar_chart","vector_graph",["large_view"]],["bar_chart","map",["large_view"]],["bar_chart","bar_chart",["mirrored"]],["line_chart","vector_graph",["large_view"]],["line_chart","map",["large_view"]]],"visType":["vector_graph","map","bar_chart","line_chart"],"compType":["coordinated","large_view","mirrored"],"compressed_tree":[{"composite_pattern":"large_view","visualization_type":[["bar_chart","line_chart"],["vector_graph","map"]]},{"composite_pattern":"coordinated","visualization_type":[["vector_graph"],["map"]]},{"composite_pattern":"mirrored","visualization_type":[["bar_chart"]]}],"coOccurrence":[["bar_chart","line_chart",["coOccurrence"]],["bar_chart","vector_graph",["coOccurrence"]],["bar_chart","map",["coOccurrence"]],["line_chart","vector_graph",["coOccurrence"]],["line_chart","map",["coOccurrence"]],["vector_graph","map",["coOccurrence"]]],"year":2018,"conference":["InfoVis"],"authors":["Alper Sarikaya","Michael Correll","Lyn Bartram","Melanie Tory","Danyel Fisher"],"title":"What Do We Talk About When We Talk About Dashboards?","doi":"10.1109/TVCG.2018.2864903","abstract":"Dashboards are one of the most common use cases for data visualization, and their design and contexts of use are considerably different from exploratory visualization tools. In this paper, we look at the broad scope of how dashboards are used in practice through an analysis of dashboard examples and documentation about their use. We systematically review the literature surrounding dashboard use, construct a design space for dashboards, and identify major dashboard types. We characterize dashboards by their design goals, levels of interaction, and the practices around them. Our framework and literature review suggest a number of fruitful research directions to better support dashboard design, implementation and use.","keywords":"Dashboards,literature review,survey,design space,open coding","caption":"Fig. 1: Klipfolio\u2019s Social Media Manager Dashboard (DB065 from our example corpus, left) is a traditional dashboard, with large numbers representing key metrics, and tiled graphs of real-time data. The UNCHR Refugees/Migrants Emergency Response dashboard (DB117, right) also is a juxtaposition of key metrics and simple visualizations, but includes annotations and guided narrative elements. Are both dashboards? Do design principles meant for one transfer to the other?","img_size":{"width":1934,"height":644},"subfigures":[{"x":15.501215447168176,"y":10.175567362874022,"width":830.64829332329,"height":626.0693194317399,"type":"interface","id":"interface-0"},{"x":945.8846437527674,"y":13.664378141407395,"width":968.2955887619929,"height":608.1996541659794,"type":"interface","id":"interface-1"}],"visualizations":[{"x":531.0549062590608,"y":422.19168892525863,"width":302.23979662238685,"height":45.716944026915655,"type":"area_chart","id":"area_chart-0"},{"x":521.7399783315277,"y":186.85048754062842,"width":316.0796134765679,"height":133.36218186599683,"type":"bar_chart","id":"bar_chart-1"},{"x":23.048754062838572,"y":140.75297941495126,"width":324.7778981581799,"height":127.81581798483212,"type":"bar_chart","id":"bar_chart-2"},{"x":272.78010051521727,"y":287.40345723285157,"width":237.276707919275,"height":127.61894649044666,"type":"bar_chart","id":"bar_chart-3"},{"x":28.97383654473247,"y":414.5020515803374,"width":75.62604236470918,"height":97.36852954456305,"type":"bar_chart","id":"bar_chart-4"},{"x":968.662065215928,"y":205.6129255727661,"width":216.9388613526448,"height":215.5188052515859,"type":"bar_chart","id":"bar_chart-5"},{"x":961.3847377723542,"y":439.89691314148035,"width":425.6239896535089,"height":161.48335650810623,"type":"bar_chart","id":"bar_chart-6"},{"x":1402.0284208943292,"y":460.21234443194624,"width":251.79459428678274,"height":145.65348838743114,"type":"line_chart","id":"line_chart-10"},{"x":519.6446370530876,"y":44.36728060671724,"width":331.06392199349955,"height":136.19718309859158,"type":"line_chart","id":"line_chart-8"},{"x":521.455822195055,"y":487.70722865031297,"width":316.04599773729376,"height":125.72632756702569,"type":"line_chart","id":"line_chart-9"},{"x":962.8781132791445,"y":92.72474122455951,"width":927.4054858643262,"height":514.4815513849891,"type":"map","id":"map-7"},{"x":114.02656287670833,"y":420.0286875020354,"width":144.63480602250627,"height":93.58722742632756,"type":"table","id":"table-11"},{"x":1224.5712019029731,"y":231.20210605260772,"width":495.8788405036079,"height":200.70994314592474,"type":"vector_graph","id":"vector_graph-12"}],"relations":[{"vislist":[{"vislist":["bar_chart-6","bar_chart-5","line_chart-10"],"relation":null,"id":"group-0"},{"vislist":["vector_graph-12","map-7"],"relation":null,"id":"group-1"}],"relation":"large_view","id":"relation-0"},{"vislist":[{"vislist":["vector_graph-12"],"relation":null,"id":"group-1"},{"vislist":["map-7"],"relation":null,"id":"group-2"}],"relation":"coordinated","id":"relation-1"},{"vislist":[{"vislist":["bar_chart-2"],"relation":null,"id":"group-3"}],"relation":"mirrored","id":"relation-2"}]},"2985_1":{"comp":[["bar_chart","line_chart",["coordinated"]],["bar_chart","bar_chart",["mirrored"]],["comb","comb",["large_view"]]],"visType":["bar_chart","line_chart","comb"],"compType":["coordinated","mirrored","large_view"],"compressed_tree":[{"composite_pattern":"large_view","visualization_type":[[{"composite_pattern":"mirrored","visualization_type":[["bar_chart"]]}],[{"composite_pattern":"coordinated","visualization_type":[["bar_chart"],["line_chart"]]}]]},{"composite_pattern":"coordinated","visualization_type":[["bar_chart"],["line_chart"]]}],"coOccurrence":[],"year":2018,"conference":["InfoVis"],"authors":["Alper Sarikaya","Michael Correll","Lyn Bartram","Melanie Tory","Danyel Fisher"],"title":"What Do We Talk About When We Talk About Dashboards?","doi":"10.1109/TVCG.2018.2864903","abstract":"Dashboards are one of the most common use cases for data visualization, and their design and contexts of use are considerably different from exploratory visualization tools. In this paper, we look at the broad scope of how dashboards are used in practice through an analysis of dashboard examples and documentation about their use. We systematically review the literature surrounding dashboard use, construct a design space for dashboards, and identify major dashboard types. We characterize dashboards by their design goals, levels of interaction, and the practices around them. Our framework and literature review suggest a number of fruitful research directions to better support dashboard design, implementation and use.","keywords":"Dashboards,literature review,survey,design space,open coding","caption":"Fig. 2: Four dashboard exemplars demonstrating different attributes of dashboard design. A representative strategic dashboard (Fig. 2a) emphasizes the trends of paying subscribers along with monthly breakdowns for increases and decreases. Fig. 2b is a tactical dashboard that uses multiple metrics to summarize a student\u2019s performance in a class. The operational dashboard (Fig. 2c) shows performance metrics that may be actionable, but with no collective summarization. The social dashboard (Fig. 2d) uses social and personal data to situate the context of the personal workout data. We demonstrate common factors of designs in the survey and highlight relevant challenges through our literature review.","img_size":{"width":1566,"height":1219},"subfigures":[{"x":19.93137348469584,"y":5.566187651117852,"width":685.4732782271903,"height":570.7693194838674,"type":"interface","id":"interface-0"},{"x":880.2029137113842,"y":121.98314338300827,"width":670.5469941646961,"height":449.9675252504952,"type":"interface","id":"interface-1"},{"x":43.597315261151806,"y":730.7404017694143,"width":697.5141312575057,"height":413.5144853042943,"type":"interface","id":"interface-2"},{"x":896.3836941654068,"y":726.8066713841706,"width":661.1248996638078,"height":437.57936061411897,"type":"interface","id":"interface-3"}],"visualizations":[{"x":28.462546999892307,"y":64.95125036266563,"width":360.8611002727498,"height":263.97621342909326,"type":"bar_chart","id":"bar_chart-0"},{"x":33.25036992918785,"y":362.45619733171964,"width":170.09416711423208,"height":88.597339152463,"type":"bar_chart","id":"bar_chart-1"},{"x":48.967958535693484,"y":84.76778244715551,"width":156.33115424879477,"height":68.55037260568811,"type":"bar_chart","id":"bar_chart-13"},{"x":1259.587227414331,"y":1036.7196261682243,"width":300.00311526479754,"height":121.5202492211838,"type":"bar_chart","id":"bar_chart-2"},{"x":887.4314641744548,"y":178.48286604361385,"width":440.5109034267914,"height":383.5482866043613,"type":"bar_chart","id":"bar_chart-3"},{"x":44.38473520249238,"y":729.1214953271028,"width":694.9439252336448,"height":413.9283489096573,"type":"donut_chart","id":"donut_chart-4"},{"x":906.419003115265,"y":786.0841121495329,"width":148.1028037383178,"height":167.09034267912776,"type":"donut_chart","id":"donut_chart-5"},{"x":1233.004672897196,"y":774.6915887850466,"width":322.7881619937698,"height":235.4454828660436,"type":"donut_chart","id":"donut_chart-6"},{"x":1077.3068535825544,"y":778.4890965732087,"width":129.11526479750796,"height":170.88785046728972,"type":"donut_chart","id":"donut_chart-7"},{"x":513.1907544134253,"y":100.32314964670336,"width":196.2391285024354,"height":472.796781063732,"type":"heatmap","id":"heatmap-12"},{"x":28.462546999892307,"y":66.35537915750125,"width":360.8611002727498,"height":265.38034222392895,"type":"line_chart","id":"line_chart-8"},{"x":31.75752081487775,"y":364.7023391323907,"width":378.6322173914107,"height":195.31254652769596,"type":"line_chart","id":"line_chart-9"},{"x":428.50523763837015,"y":89.93888775602979,"width":290.36585542947466,"height":489.7175289669108,"type":"table","id":"table-10"},{"x":879.8364485981309,"y":129.1152647975079,"width":668.3613707165107,"height":432.9158878504673,"type":"table","id":"table-11"}],"relations":[{"vislist":[{"vislist":[{"vislist":[{"vislist":["bar_chart-13"],"relation":null,"id":"group-6"}],"relation":"mirrored","id":"relation-4"}],"relation":null,"id":"group-7"},{"vislist":[{"vislist":[{"vislist":["bar_chart-0"],"relation":null,"id":"group-4"},{"vislist":["line_chart-8"],"relation":null,"id":"group-5"}],"relation":"coordinated","id":"relation-3"}],"relation":null,"id":"group-8"}],"relation":"large_view","id":"relation-5"},{"vislist":[{"vislist":["bar_chart-1"],"relation":null,"id":"group-9"},{"vislist":["line_chart-9"],"relation":null,"id":"group-10"}],"relation":"coordinated","id":"relation-6"}]},"3008_3":{"comp":[["graph","matrix",["coordinated"]]],"visType":["graph","matrix"],"compType":["coordinated"],"compressed_tree":[{"composite_pattern":"coordinated","visualization_type":[["graph"],["matrix"]]},{"composite_pattern":"coordinated","visualization_type":[["graph"],["matrix"]]},{"composite_pattern":"coordinated","visualization_type":[["graph"],["matrix"]]}],"coOccurrence":[["graph","matrix",["coOccurrence"]]],"year":2018,"conference":["InfoVis"],"authors":["Timothy Major","Rahul C. Basole"],"title":"Graphicle: Exploring Units, Networks, and Context in a Blended Visualization Approach","doi":"10.1109/TVCG.2018.2865151","abstract":"Many real-world datasets are large, multivariate, and relational in nature and relevant associated decisions frequently require a simultaneous consideration of both attributes and connections. Existing visualization systems and approaches, however, often make an explicit trade-off between either affording rich exploration of individual data units and their attributes or exploration of the underlying network structure. In doing so, important analysis opportunities and insights are potentially missed. In this study, we aim to address this gap by (1) considering visualizations and interaction techniques that blend the spectrum between unit and network visualizations, (2) discussing the nature of different forms of contexts and the challenges in implementing them, and (3) demonstrating the value of our approach for visual exploration of multivariate, relational data for a real-world use case. Specifically, we demonstrate through a system called Graphicle how network structure can be layered on top of unit visualization techniques to create new opportunities for visual exploration of physician characteristics and referral data. We report on the design, implementation, and evaluation of the system and effectiveness of our blended approach.","keywords":"Unit visualization,network visualization,context","caption":"Fig. 4. Users can utilize long press on a node (or a cluster label (not shown)) to open up a context menu where they can select the target\u2019s (i.e., node or cluster) (a) 1-step , (b) 2-step, or (c) full network. The selected structure is highlighted and enclosed by a blue selection frame.","img_size":{"width":2148,"height":693},"subfigures":[{"x":1541.4220041962665,"y":39.09620102570677,"width":464.28631519715674,"height":473.7844200616178,"type":"single","id":"single-0"}],"visualizations":[{"x":837.7898158179847,"y":56.76435536294689,"width":456.13001083423603,"height":449.14842903575277,"type":"graph","id":"graph-0"},{"x":1547.583965330444,"y":56.76435536294689,"width":451.47562296858064,"height":451.47562296858064,"type":"graph","id":"graph-1"},{"x":141.95882990249183,"y":66.07313109425783,"width":449.1484290357529,"height":446.82123510292513,"type":"graph","id":"graph-2"},{"x":1550.7089550304775,"y":54.24317808587959,"width":451.41972271598155,"height":463.8501144164751,"type":"matrix","id":"matrix-3"},{"x":836.7820591763727,"y":58.94869599023142,"width":461.39794538018225,"height":447.91672566659537,"type":"matrix","id":"matrix-4"},{"x":137.75626145521812,"y":65.39710921018977,"width":452.9821660121746,"height":443.1728404031503,"type":"matrix","id":"matrix-5"}],"relations":[{"vislist":[{"id":"group-0","relation":null,"vislist":["graph-0"]},{"id":"group-1","relation":null,"vislist":["matrix-4"]}],"relation":"coordinated","id":"relation-0"},{"vislist":[{"id":"group-2","relation":null,"vislist":["graph-1"]},{"id":"group-3","relation":null,"vislist":["matrix-3"]}],"relation":"coordinated","id":"relation-1"},{"vislist":[{"id":"group-4","relation":null,"vislist":["graph-2"]},{"id":"group-5","relation":null,"vislist":["matrix-5"]}],"relation":"coordinated","id":"relation-2"}]},"3013_6":{"comp":[["graph","map",["coordinated"]]],"visType":["graph","map"],"compType":["coordinated"],"compressed_tree":[{"composite_pattern":"coordinated","visualization_type":[["graph"],["map"]]},{"composite_pattern":"coordinated","visualization_type":[["graph"],["map"]]}],"coOccurrence":[["graph","map",["coOccurrence"]]],"year":2018,"conference":["InfoVis"],"authors":["Yalong Yang","Tim Dwyer","Bernhard Jenny","Kim Marriott","Maxime Cordeil","Haohui Chen"],"title":"Origin-Destination Flow Maps in Immersive Environments","doi":"10.1109/TVCG.2018.2865192","abstract":"Immersive virtual- and augmented-reality headsets can overlay a flat image against any surface or hang virtual objects in the space around the user. The technology is rapidly improving and may, in the long term, replace traditional flat panel displays in many situations. When displays are no longer intrinsically flat, how should we use the space around the user for abstract data visualisation? In this paper, we ask this question with respect to origin-destination flow data in a global geographic context. We report on the findings of three studies exploring different spatial encodings for flow maps. The first experiment focuses on different 2D and 3D encodings for flows on flat maps. We find that participants are significantly more accurate with raised flow paths whose height is proportional to flow distance but fastest with traditional straight line 2D flows. In our second and third experiment we compared flat maps, 3D globes and a novel interactive design we call<i>MapsLink</i>, involving a pair of linked flat maps. We find that participants took significantly more time with MapsLink than other flow maps while the 3D globe with raised flows was the fastest, most accurate, and most preferred method. Our work suggests that<i>careful</i>use of the third spatial dimension can resolve visual clutter in complex flow maps.","keywords":"Origin-destination,Flow Map,Virtual Reality,Cartographic Information Visualisation,Immersive Analytics","caption":"Fig. 5.  Study 2:  (a) 3D globe flow map, (b, c, d) MapsLink:  flow tubeslinking a pair of flat maps","img_size":{"width":1062,"height":657},"subfigures":[{"x":556.3324279146184,"y":15.159967523898164,"width":429.38575258048434,"height":272.39317962327715,"type":"single","id":"single-1"},{"x":79.85082067675278,"y":17.53764258008919,"width":409.88281032318883,"height":474.24455524685993,"type":"single","id":"single-0"}],"visualizations":[{"x":74.37136929460581,"y":10.904564315352747,"width":410.7385892116182,"height":475.2572614107883,"type":"graph","id":"graph-4"},{"x":710.4780238342598,"y":40.535703367969646,"width":247.33470860755182,"height":223.4991310821648,"type":"graph","id":"graph-6"},{"x":73.46265560165978,"y":10.904564315352747,"width":410.73858921161815,"height":473.4398340248963,"type":"map","id":"map-0"},{"x":555.9896265560164,"y":15.44813278008304,"width":418.00829875518656,"height":269.8879668049792,"type":"map","id":"map-1"}],"relations":[{"vislist":[{"vislist":["graph-4"],"relation":null,"id":"group-0"},{"vislist":["map-0"],"relation":null,"id":"group-1"}],"relation":"coordinated","id":"relation-0"},{"vislist":[{"vislist":["graph-6"],"relation":null,"id":"group-6"},{"vislist":["map-1"],"relation":null,"id":"group-7"}],"relation":"coordinated","id":"relation-5"}]},"3064_6":{"comp":[["graph","map",["coordinated"]],["bar_chart","comb",["large_view"]],["heatmap","comb",["large_view"]]],"visType":["graph","map","bar_chart","comb","heatmap"],"compType":["coordinated","large_view"],"compressed_tree":[{"composite_pattern":"large_view","visualization_type":[["bar_chart"],[{"composite_pattern":"coordinated","visualization_type":[["graph"],["map"]]}]]},{"composite_pattern":"large_view","visualization_type":[["heatmap"],[{"composite_pattern":"coordinated","visualization_type":[["graph"],["map"]]}]]}],"coOccurrence":[["graph","map",["coOccurrence"]],["graph","heatmap",["coOccurrence"]],["map","heatmap",["coOccurrence"]]],"year":2018,"conference":["VAST"],"authors":["Zhiguang Zhou","Linhao Meng","Cheng Tang","Ying Zha","Zhiyong Guo","Miaoxin Hu","Wei Chen"],"title":"Visual Abstraction of Large Scale Geospatial Origin-Destination Movement Data","doi":"10.1109/TVCG.2018.2864503","abstract":"A variety of human movement datasets are represented in an Origin-Destination(OD) form, such as taxi trips, mobile phone locations, etc. As a commonly-used method to visualize OD data, flow map always fails to discover patterns of human mobility, due to massive intersections and occlusions of lines on a 2D geographical map. A large number of techniques have been proposed to reduce visual clutter of flow maps, such as filtering, clustering and edge bundling, but the correlations of OD flows are often neglected, which makes the simplified OD flow map present little semantic information. In this paper, a characterization of OD flows is established based on an analogy between OD flows and natural language processing (NPL) terms. Then, an iterative multi-objective sampling scheme is designed to select OD flows in a vectorized representation space. To enhance the readability of sampled OD flows, a set of meaningful visual encodings are designed to present the interactions of OD flows. We design and implement a visual exploration system that supports visual inspection and quantitative evaluation from a variety of perspectives. Case studies based on real-world datasets and interviews with domain experts have demonstrated the effectiveness of our system in reducing the visual clutter and enhancing correlations of OD flows.","keywords":"Visual abstraction,human mobility,origin-destination,flow map,representation learning","caption":"Fig. 6. The comparison for sampled flow maps based on different multi-objective sampling strategies. (a-c) present the sampling results by means of adaptive blue noise sampling without considering any constraint. (d-f) present the different sampling results by means of multi-objective sampling schemes with a variety of constraints taken into consideration. The statistics are also presented in a variety of visualization views at the upper right corner for an insightful comparison.","img_size":{"width":2151,"height":1101},"subfigures":[{"x":35.79631274624624,"y":20.0864502659932,"width":683.7014013436168,"height":532.0341828510695,"type":"single","id":"single-0"},{"x":729.7702468952443,"y":20.08645026599321,"width":690.1148954453832,"height":532.0341828510674,"type":"single","id":"single-1"}],"visualizations":[{"x":452.97196261682217,"y":34.299065420560744,"width":270.9626168224299,"height":168.06542056074767,"type":"bar_chart","id":"bar_chart-0"},{"x":449.5420560747662,"y":576.2242990654206,"width":274.3925233644861,"height":168.06542056074773,"type":"bar_chart","id":"bar_chart-1"},{"x":1423.6355140186915,"y":13.7196261682243,"width":692.8411214953271,"height":531.6355140186915,"type":"graph","id":"graph-10"},{"x":1427.0654205607473,"y":559.0747663551402,"width":689.4112149532713,"height":531.6355140186915,"type":"graph","id":"graph-11"},{"x":730.7943925233644,"y":555.6448598130842,"width":692.8411214953271,"height":535.0654205607476,"type":"graph","id":"graph-12"},{"x":27.663551401868972,"y":562.5046728971963,"width":703.1308411214955,"height":538.4953271028038,"type":"graph","id":"graph-13"},{"x":31.09345794392505,"y":6.85981308411215,"width":685.981308411215,"height":548.7850467289719,"type":"graph","id":"graph-8"},{"x":723.9345794392522,"y":20.579439252336456,"width":692.8411214953271,"height":535.0654205607476,"type":"graph","id":"graph-9"},{"x":1238.420560747663,"y":41.15887850467291,"width":178.35514018691583,"height":171.49532710280374,"type":"heatmap","id":"heatmap-14"},{"x":1234.9906542056071,"y":583.0841121495326,"width":181.78504672897176,"height":168.06542056074784,"type":"heatmap","id":"heatmap-15"},{"x":1931.2616822429902,"y":37.72897196261682,"width":185.21495327102818,"height":181.78504672897196,"type":"heatmap","id":"heatmap-16"},{"x":1931.2616822429902,"y":583.0841121495326,"width":185.21495327102818,"height":188.64485981308417,"type":"heatmap","id":"heatmap-17"},{"x":34.52336448598112,"y":0,"width":675.6915887850469,"height":548.7850467289719,"type":"map","id":"map-2"},{"x":723.9345794392522,"y":41.15887850467291,"width":689.4112149532712,"height":504.1962616822429,"type":"map","id":"map-3"},{"x":1430.4953271028037,"y":20.579439252336456,"width":679.1214953271028,"height":517.9158878504672,"type":"map","id":"map-4"},{"x":1433.9252336448594,"y":552.214953271028,"width":689.4112149532713,"height":535.0654205607477,"type":"map","id":"map-5"},{"x":734.2242990654202,"y":555.6448598130842,"width":682.5514018691588,"height":528.2056074766355,"type":"map","id":"map-6"},{"x":37.95327102803719,"y":562.5046728971963,"width":685.981308411215,"height":538.4953271028038,"type":"map","id":"map-7"}],"relations":[{"vislist":[{"vislist":["bar_chart-0"],"relation":null,"id":"group-28"},{"vislist":[{"vislist":[{"vislist":["graph-8"],"relation":null,"id":"group-0"},{"vislist":["map-2"],"relation":null,"id":"group-1"}],"relation":"coordinated","id":"relation-0"}],"relation":null,"id":"group-29"}],"relation":"large_view","id":"relation-12"},{"vislist":[{"vislist":["heatmap-14"],"relation":null,"id":"group-30"},{"vislist":[{"vislist":[{"vislist":["graph-9"],"relation":null,"id":"group-2"},{"vislist":["map-3"],"relation":null,"id":"group-3"}],"relation":"coordinated","id":"relation-1"}],"relation":null,"id":"group-31"}],"relation":"large_view","id":"relation-13"}]},"3068_9":{"comp":[["graph","map",["coordinated"]]],"visType":["graph","map"],"compType":["coordinated"],"compressed_tree":[{"composite_pattern":"coordinated","visualization_type":[["graph"],["map"]]}],"coOccurrence":[["graph","map",["coOccurrence"]]],"year":2018,"conference":["VAST"],"authors":["Natalia V. Andrienko","Gennady L. Andrienko","Jose Manuel Cordero Garcia","David Scarlatti"],"title":"Analysis of Flight Variability: a Systematic Approach","doi":"10.1109/TVCG.2018.2864811","abstract":"In movement data analysis, there exists a problem of comparing multiple trajectories of moving objects to common or distinct reference trajectories. We introduce a general conceptual framework for comparative analysis of trajectories and an analytical procedure, which consists of (1) finding corresponding points in pairs of trajectories, (2) computation of pairwise difference measures, and (3) interactive visual analysis of the distributions of the differences with respect to space, time, set of moving objects, trajectory structures, and spatio-temporal context. We propose a combination of visualisation, interaction, and data transformation techniques supporting the analysis and demonstrate the use of our approach for solving a challenging problem from the aviation domain.","keywords":"Visual analytics,movement data,flight trajectories","caption":"Fig. 12. Flow maps obtained by aggregation of the flight plan seg- ments such that the corresponding actual segments take longer (left) and shorter (right) time by at least 5 minutes.","img_size":{"width":1056,"height":401},"subfigures":[{"x":8.81396345088526,"y":8.09052887584965,"width":516.2205190153472,"height":386.798664390058,"type":"single","id":"single-0"}],"visualizations":[{"x":22.133849988874026,"y":24.135170137172324,"width":496.25032873475743,"height":359.14165014774477,"type":"graph","id":"graph-2"},{"x":7.26454033771107,"y":7.329268292682934,"width":515.7823639774859,"height":389.64352720450296,"type":"map","id":"map-0"},{"x":531.6322701688556,"y":7.329268292682934,"width":521.7260787992496,"height":388.98311444652916,"type":"map","id":"map-1"}],"relations":[{"vislist":[{"vislist":["graph-2"],"relation":null,"id":"group-0"},{"vislist":["map-0"],"relation":null,"id":"group-1"}],"relation":"coordinated","id":"relation-0"}]},"3068_8":{"comp":[["graph","map",["coordinated"]]],"visType":["graph","map"],"compType":["coordinated"],"compressed_tree":[{"composite_pattern":"coordinated","visualization_type":[["graph"],["map"]]}],"coOccurrence":[["graph","map",["coOccurrence"]]],"year":2018,"conference":["VAST"],"authors":["Natalia V. Andrienko","Gennady L. Andrienko","Jose Manuel Cordero Garcia","David Scarlatti"],"title":"Analysis of Flight Variability: a Systematic Approach","doi":"10.1109/TVCG.2018.2864811","abstract":"In movement data analysis, there exists a problem of comparing multiple trajectories of moving objects to common or distinct reference trajectories. We introduce a general conceptual framework for comparative analysis of trajectories and an analytical procedure, which consists of (1) finding corresponding points in pairs of trajectories, (2) computation of pairwise difference measures, and (3) interactive visual analysis of the distributions of the differences with respect to space, time, set of moving objects, trajectory structures, and spatio-temporal context. We propose a combination of visualisation, interaction, and data transformation techniques supporting the analysis and demonstrate the use of our approach for solving a challenging problem from the aviation domain.","keywords":"Visual analytics,movement data,flight trajectories","caption":"Fig. 8. Left: The cruise parts of the flight plans have been aggregated in a density map (top) and in a flow map (bottom). Right: The density and flow maps represent the planned path segments such that the corresponding actual paths were shorter by 2.5 km or more.","img_size":{"width":1071,"height":824},"subfigures":[{"x":11.02903896501678,"y":8.433875000425514,"width":518.3716134169351,"height":413.88542273923116,"type":"single","id":"single-0"}],"visualizations":[{"x":12.778642149929285,"y":10.48939179632249,"width":516.3111739745405,"height":411.41725601131543,"type":"map","id":"map-2"},{"x":13.944130127298479,"y":11.654879773691656,"width":516.3111739745405,"height":410.25176803394623,"type":"graph","id":"graph-6"}],"relations":[{"vislist":[{"vislist":["graph-6"],"relation":null,"id":"group-0"},{"vislist":["map-2"],"relation":null,"id":"group-1"}],"relation":"coordinated","id":"relation-0"}]},"3079_0":{"comp":[["scivis","map",["coordinated"]]],"visType":["scivis","map"],"compType":["coordinated"],"compressed_tree":[{"composite_pattern":"coordinated","visualization_type":[["scivis"],["map"]]}],"coOccurrence":[["scivis","map",["coOccurrence"]]],"year":2018,"conference":["VAST"],"authors":["Alexander Kumpf","Marc Rautenhaus","Michael Riemer","R\xfcdiger Westermann"],"title":"Visual Analysis of the Temporal Evolution of Ensemble Forecast Sensitivities","doi":"10.1109/TVCG.2018.2864901","abstract":"Ensemble sensitivity analysis (ESA) has been established in the atmospheric sciences as a correlation-based approach to determine the sensitivity of a scalar forecast quantity computed by a numerical weather prediction model to changes in another model variable at a different model state. Its applications include determining the origin of forecast errors and placing targeted observations to improve future forecasts. We - a team of visualization scientists and meteorologists - present a visual analysis framework to improve upon current practice of ESA. We support the user in selecting regions to compute a meaningful target forecast quantity by embedding correlation-based grid-point clustering to obtain statistically coherent regions. The evolution of sensitivity features computed via ESA are then traced through time, by integrating a quantitative measure of feature matching into optical-flow-based feature assignment, and displayed by means of a swipe-path showing the geo-spatial evolution of the sensitivities. Visualization of the internal correlation structure of computed features guides the user towards those features robustly predicting a certain weather event. We demonstrate the use of our method by application to real-world 2D and 3D cases that occurred during the 2016 NAWDEX field campaign, showing the interactive generation of hypothesis chains to explore how atmospheric processes sensitive to each other are interrelated.","keywords":"Correlation,clustering,tracking,ensemble visualization","caption":"Fig. 1: Analysis of the ensemble sensitivity of forecast variable precipitation (top left) to moisture flux (bottom left) over Norway. (a) A high precipitation event is picked and a stochastically coherent clique is computed. (b) Sensitivity regions are extracted. Color shows sub-regions with high mutual correlations. (c) For a time sequence, sensitivity regions are matched between time steps and tracked over time. A \u201cswipe-path\u201d colors (time in h) all locations covered by a selected sensitivity region over time according to the first time of coverage. Stippling covers statistically insignificant regions. (c1) The proposed workflow operates on 2D and 3D data.","img_size":{"width":1999,"height":758},"subfigures":[{"x":758.193037811664,"y":8.885401994036396,"width":1193.6329694960634,"height":737.7313138559467,"type":"single","id":"single-0"}],"visualizations":[{"x":8.751094434021262,"y":0.8277048155096977,"width":730.0913070669167,"height":376.2970606629143,"type":"heatmap","id":"heatmap-0"},{"x":11.25140712945591,"y":382.1253908692934,"width":735.0919324577861,"height":371.29643527204496,"type":"heatmap","id":"heatmap-1"},{"x":751.3439649781109,"y":3.328017510944343,"width":1208.9011882426516,"height":748.8436522826765,"type":"heatmap","id":"heatmap-2"},{"x":8.751094434021262,"y":0,"width":730.0913070669167,"height":374.62445278298935,"type":"map","id":"map-3"},{"x":11.25140712945591,"y":384.6257035647279,"width":732.5916197623515,"height":366.2958098811757,"type":"map","id":"map-4"},{"x":750.0938086303939,"y":2.07786116322702,"width":1213.9018136335205,"height":755.922138836773,"type":"map","id":"map-5"},{"x":1383.3547015429463,"y":474.3487371671409,"width":583.6631310567511,"height":276.23052566571727,"type":"map","id":"map-8"},{"x":1384.7990854525162,"y":502.52669788935515,"width":571.6742114925358,"height":224.4226042212885,"type":"scivis","id":"scivis-7"},{"x":746.8093816533752,"y":9.696562304577402,"width":1219.7431486811083,"height":740.1228753908454,"type":"vector_graph","id":"vector_graph-6"}],"relations":[{"vislist":[{"vislist":["scivis-7"],"relation":null,"id":"group-5"},{"vislist":["map-8"],"relation":null,"id":"group-6"}],"relation":"coordinated","id":"relation-3"}]},"3079_7":{"comp":[["contour_graph","map",["coordinated"]]],"visType":["contour_graph","map"],"compType":["coordinated"],"compressed_tree":[{"composite_pattern":"coordinated","visualization_type":[["contour_graph"],["map"]]}],"coOccurrence":[["contour_graph","map",["coOccurrence"]]],"year":2018,"conference":["VAST"],"authors":["Alexander Kumpf","Marc Rautenhaus","Michael Riemer","R\xfcdiger Westermann"],"title":"Visual Analysis of the Temporal Evolution of Ensemble Forecast Sensitivities","doi":"10.1109/TVCG.2018.2864901","abstract":"Ensemble sensitivity analysis (ESA) has been established in the atmospheric sciences as a correlation-based approach to determine the sensitivity of a scalar forecast quantity computed by a numerical weather prediction model to changes in another model variable at a different model state. Its applications include determining the origin of forecast errors and placing targeted observations to improve future forecasts. We - a team of visualization scientists and meteorologists - present a visual analysis framework to improve upon current practice of ESA. We support the user in selecting regions to compute a meaningful target forecast quantity by embedding correlation-based grid-point clustering to obtain statistically coherent regions. The evolution of sensitivity features computed via ESA are then traced through time, by integrating a quantitative measure of feature matching into optical-flow-based feature assignment, and displayed by means of a swipe-path showing the geo-spatial evolution of the sensitivities. Visualization of the internal correlation structure of computed features guides the user towards those features robustly predicting a certain weather event. We demonstrate the use of our method by application to real-world 2D and 3D cases that occurred during the 2016 NAWDEX field campaign, showing the interactive generation of hypothesis chains to explore how atmospheric processes sensitive to each other are interrelated.","keywords":"Correlation,clustering,tracking,ensemble visualization","caption":"Fig. 9: (a) Geopotential height error (m) of control forecast, and (b) geopotential height mean absolute error (m), at 300 hPa with a lead time of 144h. Contours show geopotential height of control run (a) and analysis (b).","img_size":{"width":1007,"height":253},"subfigures":[{"x":5.877982261749004,"y":4.208410122644614,"width":486.6198532837689,"height":239.54381449857564,"type":"single","id":"single-0"}],"visualizations":[{"x":5.895513025190226,"y":6.838420798276142,"width":486.0630289421778,"height":237.7936314111282,"type":"contour_graph","id":"contour_graph-4"},{"x":3.1488430268918077,"y":1.9113672254616134,"width":497.51719824890563,"height":246.4709193245779,"type":"map","id":"map-2"}],"relations":[{"vislist":[{"vislist":["contour_graph-4"],"relation":null,"id":"group-0"},{"vislist":["map-2"],"relation":null,"id":"group-1"}],"relation":"coordinated","id":"relation-0"}]},"3094_3":{"comp":[["graph","others",["coordinated"]],["matrix","bar_chart",["stacked"]],["bar_chart","matrix",["stacked"]],["bar_chart","bar_chart",["mirrored"]],["sankey_diagram","comb",["stacked"]],["comb","sankey_diagram",["stacked"]]],"visType":["graph","others","matrix","bar_chart","sankey_diagram","comb"],"compType":["coordinated","stacked","mirrored"],"compressed_tree":[{"composite_pattern":"coordinated","visualization_type":[["graph"],["others"]]},{"composite_pattern":"stacked","visualization_type":[["matrix","bar_chart"]]},{"composite_pattern":"stacked","visualization_type":[["sankey_diagram",{"composite_pattern":"mirrored","visualization_type":[["bar_chart"]]}]]},{"composite_pattern":"stacked","visualization_type":[["sankey_diagram",{"composite_pattern":"mirrored","visualization_type":[["bar_chart"]]}]]}],"coOccurrence":[["graph","others",["coOccurrence"]],["graph","matrix",["coOccurrence"]],["graph","bar_chart",["coOccurrence"]],["graph","sankey_diagram",["coOccurrence"]],["others","matrix",["coOccurrence"]],["others","bar_chart",["coOccurrence"]],["others","sankey_diagram",["coOccurrence"]],["matrix","bar_chart",["coOccurrence"]],["matrix","sankey_diagram",["coOccurrence"]],["bar_chart","sankey_diagram",["coOccurrence"]]],"year":2018,"conference":["VAST"],"authors":["Yingcai Wu","Xiao Xie","Jiachen Wang","Dazhen Deng","Hongye Liang","Hui Zhang","Shoubin Cheng","Wei Che"],"title":"ForVizor: Visualizing Spatio-Temporal Team Formations in Soccer","doi":"10.1109/TVCG.2018.2865041","abstract":"Regarded as a high-level tactic in soccer, a team formation assigns players different tasks and indicates their active regions on the pitch, thereby influencing the team performance significantly. Analysis of formations in soccer has become particularly indispensable for soccer analysts. However, formations of a team are intrinsically time-varying and contain inherent spatial information. The spatio-temporal nature of formations and other characteristics of soccer data, such as multivariate features, make analysis of formations in soccer a challenging problem. In this study, we closely worked with domain experts to characterize domain problems of formation analysis in soccer and formulated several design goals. We design a novel spatio-temporal visual representation of changes in team formation, allowing analysts to visually analyze the evolution of formations and track the spatial flow of players within formations over time. Based on the new design, we further design and develop ForVizor, a visual analytics system, which empowers users to track the spatio-temporal changes in formation and understand how and why such changes occur. With ForVizor, domain experts conduct formation analysis of two games. Analysis results with insights and useful feedback are summarized in two case studies.","keywords":"Soccer data,formation analysis,spatio-temporal visualization","caption":"Fig. 4. System interface. The system comprises two views, namely, a formation view (A) and a display view (G). Formation view contains a confrontation matrix (B), a narrative timeline (E), and two formation flows (F). Display view contains a pitch (H) and a statistical dashborad (I).","img_size":{"width":2154,"height":1212},"subfigures":[{"x":42.13779887653392,"y":24.66201302989698,"width":2085.8822353622995,"height":1172.1044770843532,"type":"interface","id":"interface-0"}],"visualizations":[{"x":493.28571428571416,"y":119.99999999999997,"width":78.85714285714295,"height":402.8571428571428,"type":"bar_chart","id":"bar_chart-0"},{"x":903.6795670656986,"y":293.1627013712924,"width":1136.0050540324871,"height":60.40889085226576,"type":"bar_chart","id":"bar_chart-11"},{"x":632.3017547660232,"y":358.14765447484376,"width":217.7014980552063,"height":183.29983275071731,"type":"glyph_based","id":"glyph_based-13"},{"x":805.0661860151748,"y":779.5289386424864,"width":519.892340737914,"height":323.41522855655427,"type":"graph","id":"graph-5"},{"x":1357.2857142857142,"y":637.7142857142854,"width":735.4285714285714,"height":186.8571428571429,"type":"line_chart","id":"line_chart-7"},{"x":51,"y":137.1428571428571,"width":380.5714285714285,"height":370.2857142857142,"type":"matrix","id":"matrix-8"},{"x":451.05686561576005,"y":638.6439464123117,"width":874.3642657335805,"height":539.8942934101938,"type":"others","id":"others-14"},{"x":1569.8571428571427,"y":870.8571428571427,"width":298.28571428571433,"height":301.7142857142858,"type":"polar_plot","id":"polar_plot-9"},{"x":915.0911145770008,"y":93.17308722068874,"width":1126.2563140933414,"height":189.84815754242837,"type":"sankey_diagram","id":"sankey_diagram-10"},{"x":909.8232867025346,"y":358.45387994143454,"width":1132.6315066532272,"height":189.87408491947286,"type":"sankey_diagram","id":"sankey_diagram-6"}],"relations":[{"vislist":[{"vislist":["graph-5"],"relation":null,"id":"group-0"},{"vislist":["others-14"],"relation":null,"id":"group-1"}],"relation":"coordinated","id":"relation-0"},{"vislist":[{"vislist":["matrix-8","bar_chart-0"],"relation":null,"id":"group-6"}],"relation":"stacked","id":"relation-5"},{"vislist":[{"vislist":["sankey_diagram-10",{"vislist":[{"vislist":["bar_chart-11"],"relation":null,"id":"group-7"}],"relation":"mirrored","id":"relation-6"}],"relation":null,"id":"group-8"}],"relation":"stacked","id":"relation-7"},{"vislist":[{"vislist":["sankey_diagram-6",{"vislist":[{"vislist":["bar_chart-11"],"relation":null,"id":"group-7"}],"relation":"mirrored","id":"relation-6"}],"relation":null,"id":"group-9"}],"relation":"stacked","id":"relation-8"}]},"2462_4":{"comp":[["polar_plot","scatterplot",["coordinated"]]],"visType":["polar_plot","scatterplot"],"compType":["coordinated"],"compressed_tree":[{"composite_pattern":"coordinated","visualization_type":[["polar_plot"],["scatterplot"]]},{"composite_pattern":"coordinated","visualization_type":[["polar_plot"],["scatterplot"]]},{"composite_pattern":"coordinated","visualization_type":[["polar_plot"],["scatterplot"]]},{"composite_pattern":"coordinated","visualization_type":[["polar_plot"],["scatterplot"]]}],"coOccurrence":[["polar_plot","scatterplot",["coOccurrence"]]],"year":2014,"conference":["InfoVis"],"authors":["Manuel Rubio-S\xe1nchez","Alberto S\xe1nche"],"title":"Axis Calibration for Improving Data Attribute Estimation in Star Coordinates Plots","doi":"10.1109/TVCG.2014.2346258","abstract":"Star coordinates is a well-known multivariate visualization method that produces linear dimensionality reduction mappings through a set of radial axes defined by vectors in an observable space. One of its main drawbacks concerns the difficulty to recover attributes of data samples accurately, which typically lie in the [0], [1] interval, given the locations of the low-dimensional embeddings and the vectors. In this paper we show that centering the data can considerably increase attribute estimation accuracy, where data values can be read off approximately by projecting embedded points onto calibrated (i.e., labeled) axes, similarly to classical statistical biplots. In addition, this idea can be coupled with a recently developed orthonormalization process on the axis vectors that prevents unnecessary distortions. We demonstrate that the combination of both approaches not only enhances the estimates, but also provides more faithful representations of the data.","keywords":"Star Coordinates, RadViz, Biplots, Axis calibration, Attribute value estimation, Data centering, Orthographic projection","caption":"Fig. 5. Comparison of methods. The graphics show SC plots of a breakfast cereal data set containing \ufb01ve variables, where the axis associated with protein content has been labeled with original values that lie in the interval [1,6], shown as a gray area. The points have been colored according to protein content, where the color bar indicates the particular coding. Note that lighter points, with higher values, are located towards the right, in the direction of the axis vector. Additionally, since the estimates for protein are the (orthogonal) projections of the points onto its labeled axis, ideally they should be located inside the gray area. In (a) the plot uses data in [0,1] (not centered) and a con\ufb01guration of axis vectors that does not generate orthographic projections, where the estimates are highly inaccurate. In (b) the columns of V form an orthonormal set, which has a positive effect on the accuracy. In (c) the vectors do not produce orthographic projections but the [0,1] data has been centered, which allows to reduce the squared estimation errors considerably. Finally, in (d) both approaches are combined to reduce the attribute estimation error even further, where almost every point lies in the [1,6] interval.","img_size":{"width":1977,"height":1419},"subfigures":[{"x":7.738004371769882,"y":4.11881414905772,"width":767.4094007655185,"height":575.3901372419417,"type":"single","id":"single-0"}],"visualizations":[{"x":24.95961187786169,"y":5.71615136901899,"width":745.0649032284045,"height":572.0635989013066,"type":"polar_plot","id":"polar_plot-4"},{"x":1174.279120905092,"y":15.572290828431322,"width":789.5369962850527,"height":563.9824675234667,"type":"polar_plot","id":"polar_plot-5"},{"x":18.266513312929938,"y":718.8778155898833,"width":753.2209416281082,"height":582.1869917710525,"type":"polar_plot","id":"polar_plot-6"},{"x":1177.801323855272,"y":724.6780692836373,"width":792.9529078450116,"height":578.3405827441997,"type":"polar_plot","id":"polar_plot-7"},{"x":1174.1541725601137,"y":4.846311475409836,"width":786.772277227723,"height":578.0367751060822,"type":"scatterplot","id":"scatterplot-0"},{"x":28.11598302687423,"y":8.028288543140027,"width":740.6096181046677,"height":570.0084865629423,"type":"scatterplot","id":"scatterplot-1"},{"x":1176.1612446958986,"y":728.5671852899575,"width":790.7864214992932,"height":570.0084865629422,"type":"scatterplot","id":"scatterplot-2"},{"x":22.09476661951931,"y":722.5459688826026,"width":742.6166902404527,"height":578.036775106082,"type":"scatterplot","id":"scatterplot-3"}],"relations":[{"vislist":[{"vislist":["polar_plot-4"],"relation":null,"id":"group-0"},{"vislist":["scatterplot-1"],"relation":null,"id":"group-1"}],"relation":"coordinated","id":"relation-0"},{"vislist":[{"vislist":["polar_plot-5"],"relation":null,"id":"group-2"},{"vislist":["scatterplot-0"],"relation":null,"id":"group-3"}],"relation":"coordinated","id":"relation-1"},{"vislist":[{"vislist":["polar_plot-6"],"relation":null,"id":"group-4"},{"vislist":["scatterplot-3"],"relation":null,"id":"group-5"}],"relation":"coordinated","id":"relation-2"},{"vislist":[{"vislist":["polar_plot-7"],"relation":null,"id":"group-6"},{"vislist":["scatterplot-2"],"relation":null,"id":"group-7"}],"relation":"coordinated","id":"relation-3"}]},"2470_1":{"comp":[["area_chart","map",["coordinated"]],["line_chart","map",["coordinated"]]],"visType":["area_chart","map","line_chart"],"compType":["coordinated"],"compressed_tree":[{"composite_pattern":"coordinated","visualization_type":[["area_chart","line_chart"],["map"]]}],"coOccurrence":[["area_chart","line_chart",["coOccurrence"]],["area_chart","map",["coOccurrence"]],["line_chart","map",["coOccurrence"]]],"year":2014,"conference":["InfoVis"],"authors":["Donghao Ren","Tobias H\xf6llerer","Xiaoru Yuan"],"title":"iVisDesigner: Expressive Interactive Design of Information Visualizations","doi":"10.1109/TVCG.2014.2346291","abstract":"We present the design, implementation and evaluation of iVisDesigner, a web-based system that enables users to design information visualizations for complex datasets interactively, without the need for textual programming. Our system achieves high interactive expressiveness through conceptual modularity, covering a broad information visualization design space. iVisDesigner supports the interactive design of interactive visualizations, such as provisioning for responsive graph layouts and different types of brushing and linking interactions. We present the system design and implementation, exemplify it through a variety of illustrative visualization designs and discuss its limitations. A performance analysis and an informal user study are presented to evaluate the system.","keywords":"Visualization design, Interactive Design, Interaction, Expressiveness, Web-based visualization","caption":"Fig. 2. The interface of iVisDesigner. (1) Menu Bar: Commands for loading or saving visualization designs, view settings, login and logout. (2) Tools Panel: Tools for moving objects around, creating new objects and changing the view. Grouped into different categories. (3) Schema Panel: Shows the structure of the dataset. Allows selection. (4) Objects Panel: Shows the objects currently in the visualization design. Allows selection. (5) Style Panel: Adjust graphical styles for currently selected objects. (6) Property Panel: Adjust properties of currently selected objects. (7) The canvas to draw the visualization. In this example, a visualization of Beijing Air Pollution data is presented. There are two linked views, the left view shows the timeline plots of PM2.5 indexes for each measurement station on top of a map, the right plots shows the trends of the PM2.5 indexes, wind strength, temperature and humidity. This visualization is designed solely through user interaction with iVisDesigner, without textual programming.","img_size":{"width":2134,"height":807},"subfigures":[{"x":7.243360935529228,"y":16.22640276101393,"width":2122.6132449614347,"height":783.8520501377849,"type":"interface","id":"interface-0"}],"visualizations":[{"x":295.3354767114706,"y":141.08055566135758,"width":786.6363858952581,"height":658.223226134618,"type":"area_chart","id":"area_chart-6"},{"x":1110.523412028989,"y":674.2541902765072,"width":696.5650168562681,"height":110.3913483352942,"type":"line_chart","id":"line_chart-1"},{"x":1110.523412028989,"y":532.0798158475641,"width":688.5174107565169,"height":130.55005450707984,"type":"line_chart","id":"line_chart-2"},{"x":1120.4030114311,"y":382.2892946943637,"width":681.0237628793466,"height":120.48096554687088,"type":"line_chart","id":"line_chart-3"},{"x":1107.129684718309,"y":139.28531333711555,"width":691.234014196878,"height":239.9409059619887,"type":"line_chart","id":"line_chart-4"},{"x":297.2128727007768,"y":137.35663451078244,"width":786.6462340195391,"height":661.9137631552802,"type":"line_chart","id":"line_chart-5"},{"x":299.3552091878589,"y":137.4064807219032,"width":779.0237899917965,"height":661.7325676784249,"type":"map","id":"map-0"}],"relations":[{"vislist":[{"vislist":["area_chart-6","line_chart-5"],"relation":null,"id":"group-0"},{"vislist":["map-0"],"relation":null,"id":"group-1"}],"relation":"coordinated","id":"relation-0"}]},"2470_11":{"comp":[["graph","map",["coordinated"]]],"visType":["graph","map"],"compType":["coordinated"],"compressed_tree":[{"composite_pattern":"coordinated","visualization_type":[["graph"],["map"]]}],"coOccurrence":[["graph","map",["coOccurrence"]]],"year":2014,"conference":["InfoVis"],"authors":["Donghao Ren","Tobias H\xf6llerer","Xiaoru Yuan"],"title":"iVisDesigner: Expressive Interactive Design of Information Visualizations","doi":"10.1109/TVCG.2014.2346291","abstract":"We present the design, implementation and evaluation of iVisDesigner, a web-based system that enables users to design information visualizations for complex datasets interactively, without the need for textual programming. Our system achieves high interactive expressiveness through conceptual modularity, covering a broad information visualization design space. iVisDesigner supports the interactive design of interactive visualizations, such as provisioning for responsive graph layouts and different types of brushing and linking interactions. We present the system design and implementation, exemplify it through a variety of illustrative visualization designs and discuss its limitations. A performance analysis and an informal user study are presented to evaluate the system.","keywords":"Visualization design, Interactive Design, Interaction, Expressiveness, Web-based visualization","caption":"Fig. 12. A visualization design by the participant from the supervised study. Each circle shows a cluster of tweets, dots between circles show the time-dependent movement pattern between clusters.","img_size":{"width":1067,"height":567},"subfigures":[{"x":13.624096261689317,"y":4.8325796471677736,"width":1038.2018240603743,"height":553.4584296551145,"type":"single","id":"single-0"}],"visualizations":[{"x":14.882512420136939,"y":3.687162693009611,"width":1039.117295211174,"height":553.975049717787,"type":"map","id":"map-1"},{"x":14.067114093959786,"y":2.3525832113312046,"width":1044.1932885906037,"height":557.8671140939597,"type":"graph","id":"graph-0"}],"relations":[{"vislist":[{"vislist":["graph-0"],"relation":null,"id":"group-0"},{"vislist":["map-1"],"relation":null,"id":"group-1"}],"relation":"coordinated","id":"relation-0"}]},"2489_0":{"comp":[["word_cloud","pie_chart",["coordinated"]]],"visType":["word_cloud","pie_chart"],"compType":["coordinated"],"compressed_tree":[{"composite_pattern":"coordinated","visualization_type":[["word_cloud"],["pie_chart"]]}],"coOccurrence":[["word_cloud","pie_chart",["coOccurrence"]]],"year":2014,"conference":["InfoVis"],"authors":["Weiwei Cui","Shixia Liu","Zhuofeng W","Hao Wei"],"title":"How Hierarchical Topics Evolve in Large Text Corpora","doi":"10.1109/TVCG.2014.2346433","abstract":"Using a sequence of topic trees to organize documents is a popular way to represent hierarchical and evolving topics in text corpora. However, following evolving topics in the context of topic trees remains difficult for users. To address this issue, we present an interactive visual text analysis approach to allow users to progressively explore and analyze the complex evolutionary patterns of hierarchical topics. The key idea behind our approach is to exploit a tree cut to approximate each tree and allow users to interactively modify the tree cuts based on their interests. In particular, we propose an incremental evolutionary tree cut algorithm with the goal of balancing 1) the fitness of each tree cut and the smoothness between adjacent tree cuts; 2) the historical and new information related to user interests. A time-based visualization is designed to illustrate the evolving topics over time. To preserve the mental map, we develop a stable layout algorithm. As a result, our approach can quickly guide users to progressively gain profound insights into evolving hierarchical topics. We evaluate the effectiveness of the proposed method on Amazon\'s Mechanical Turk and real-world news data. The results show that users are able to successfully analyze evolving topics in text data.","keywords":"Hierarchical topic visualization, evolutionary tree clustering, data transformation","caption":"Figure 1. RoseRiver, a visual analytics system for exploring evolutionary hierarchical topics. (a) Overview of the Prism scandal (Jun. 5 to Aug. 16, 2013). Four colors represent the four major topics. Topics are displayed as vertical bars. The color stripes represent the evolving relationships between topics. (b) Comparison of the prominent keywords in tweets and news articles of the topic. The arc lengths encode the news article and tweet numbers (in log scale). (c) The new layout generated by splitting the gray topic.","img_size":{"width":1907,"height":705},"subfigures":[{"x":10.598096207070132,"y":10.576864142890265,"width":1887.1889146030949,"height":685.2312292118883,"type":"interface","id":"interface-0"}],"visualizations":[{"x":5.453765490943755,"y":0.7321258341277428,"width":1899.728312678741,"height":701.7178265014298,"type":"area_chart","id":"area_chart-0"},{"x":1450.7016205910388,"y":398.8570066730219,"width":441.75500476644424,"height":299.9571020019065,"type":"area_chart","id":"area_chart-1"},{"x":423.89354333808467,"y":407.2788616343709,"width":428.4373220577726,"height":289.8276777934918,"type":"pie_chart","id":"pie_chart-2"},{"x":421.7578646329838,"y":409.76453765490936,"width":429.02955195424204,"height":279.9599618684461,"type":"word_cloud","id":"word_cloud-3"}],"relations":[{"vislist":[{"vislist":["word_cloud-3"],"relation":null,"id":"group-0"},{"vislist":["pie_chart-2"],"relation":null,"id":"group-1"}],"relation":"coordinated","id":"relation-0"}]},"2554_8":{"comp":[["graph","map",["coordinated"]]],"visType":["graph","map"],"compType":["coordinated"],"compressed_tree":[{"composite_pattern":"coordinated","visualization_type":[["graph"],["map"]]}],"coOccurrence":[["graph","map",["coOccurrence"]]],"year":2014,"conference":["VAST"],"authors":["Zuchao Wang","Tangzhi Ye","Min Lu","Xiaoru Yuan","Huamin Qu","Jacky Yuan","Qianliang Wu"],"title":"Visual Exploration of Sparse Traffic Trajectory Data","doi":"10.1109/TVCG.2014.2346746","abstract":"In this paper, we present a visual analysis system to explore sparse traffic trajectory data recorded by transportation cells. Such data contains the movements of nearly all moving vehicles on the major roads of a city. Therefore it is very suitable for macro-traffic analysis. However, the vehicle movements are recorded only when they pass through the cells. The exact tracks between two consecutive cells are unknown. To deal with such uncertainties, we first design a local animation, showing the vehicle movements only in the vicinity of cells. Besides, we ignore the micro-behaviors of individual vehicles, and focus on the macro-traffic patterns. We apply existing trajectory aggregation techniques to the dataset, studying cell status pattern and inter-cell flow pattern. Beyond that, we propose to study the correlation between these two patterns with dynamic graph visualization techniques. It allows us to check how traffic congestion on one cell is correlated with traffic flows on neighbouring links, and with route selection in its neighbourhood. Case studies show the effectiveness of our system.","keywords":"Sparse Traffic Trajectory, Traffic Visualization, Dynamic Graph Visualization, Traffic Congestion","caption":"Fig. 7. Map view: overview of city traffic network, visualizing cells as nodes, and inter-cell links as edges. To avoid visual clutter, only links with 10-minutes flow volumes above 100 are shown.","img_size":{"width":1075,"height":754},"subfigures":[{"x":12.59711243934012,"y":22.8880257050026,"width":1043.6242270710725,"height":702.0445961348372,"type":"single","id":"single-0"}],"visualizations":[{"x":15.458981612446905,"y":19.196605374823196,"width":1041.949080622348,"height":711.3408769448372,"type":"map","id":"map-0"},{"x":197.02985062009108,"y":103.85964876887552,"width":618.7352041138181,"height":495.26064526276775,"type":"graph","id":"graph-4"}],"relations":[{"vislist":[{"vislist":["graph-4"],"relation":null,"id":"group-4"},{"vislist":["map-0"],"relation":null,"id":"group-5"}],"relation":"coordinated","id":"relation-2"}]},"2567_0":{"comp":[["word_cloud","sankey_diagram",["coordinated"]]],"visType":["word_cloud","sankey_diagram"],"compType":["coordinated"],"compressed_tree":[{"composite_pattern":"coordinated","visualization_type":[["word_cloud"],["sankey_diagram"]]}],"coOccurrence":[["word_cloud","sankey_diagram",["coOccurrence"]]],"year":2014,"conference":["VAST"],"authors":["Yingcai Wu","Shixia Liu","Kai Yan","Mengchen Liu","Fangzhao Wu"],"title":"OpinionFlow: Visual Analysis of Opinion Diffusion on Social Media","doi":"10.1109/TVCG.2014.2346920","abstract":"It is important for many different applications such as government and business intelligence to analyze and explore the diffusion of public opinions on social media. However, the rapid propagation and great diversity of public opinions on social media pose great challenges to effective analysis of opinion diffusion. In this paper, we introduce a visual analysis system called OpinionFlow to empower analysts to detect opinion propagation patterns and glean insights. Inspired by the information diffusion model and the theory of selective exposure, we develop an opinion diffusion model to approximate opinion propagation among Twitter users. Accordingly, we design an opinion flow visualization that combines a Sankey graph with a tailored density map in one view to visually convey diffusion of opinions among many users. A stacked tree is used to allow analysts to select topics of interest at different levels. The stacked tree is synchronized with the opinion flow visualization to help users examine and compare diffusion patterns across topics. Experiments and case studies on Twitter data demonstrate the effectiveness and usability of OpinionFlow.","keywords":"Opinion visualization, opinion diffusion, opinion flow, influence estimation, kernel density estimation, level-of-detail","caption":"Fig. 1. Three major parts of the system: (a) data preprocessing, (b) diffusion modeling, and (c) interactive visualization.","img_size":{"width":1071,"height":846},"subfigures":[{"x":36.798588551236,"y":439.45047272309796,"width":999.7147323499966,"height":390.03229434267945,"type":"interface","id":"interface-0"}],"visualizations":[{"x":145.9436310395315,"y":540.0527086383603,"width":698.6002928257686,"height":245.25329428989755,"type":"sankey_diagram","id":"sankey_diagram-3"},{"x":149.6595900439239,"y":542.5300146412884,"width":693.6456808199118,"height":245.25329428989755,"type":"word_cloud","id":"word_cloud-4"}],"relations":[{"vislist":[{"vislist":["word_cloud-4"],"relation":null,"id":"group-4"},{"vislist":["sankey_diagram-3"],"relation":null,"id":"group-5"}],"relation":"coordinated","id":"relation-1"}]},"2567_8":{"comp":[["graph","area_chart",["coordinated"]],["word_cloud","area_chart",["coordinated"]]],"visType":["graph","area_chart","word_cloud"],"compType":["coordinated"],"compressed_tree":[{"composite_pattern":"coordinated","visualization_type":[["graph"],["area_chart"]]},{"composite_pattern":"coordinated","visualization_type":[["word_cloud"],["area_chart"]]}],"coOccurrence":[["graph","area_chart",["coOccurrence"]],["graph","word_cloud",["coOccurrence"]],["area_chart","word_cloud",["coOccurrence"]]],"year":2014,"conference":["VAST"],"authors":["Yingcai Wu","Shixia Liu","Kai Yan","Mengchen Liu","Fangzhao Wu"],"title":"OpinionFlow: Visual Analysis of Opinion Diffusion on Social Media","doi":"10.1109/TVCG.2014.2346920","abstract":"It is important for many different applications such as government and business intelligence to analyze and explore the diffusion of public opinions on social media. However, the rapid propagation and great diversity of public opinions on social media pose great challenges to effective analysis of opinion diffusion. In this paper, we introduce a visual analysis system called OpinionFlow to empower analysts to detect opinion propagation patterns and glean insights. Inspired by the information diffusion model and the theory of selective exposure, we develop an opinion diffusion model to approximate opinion propagation among Twitter users. Accordingly, we design an opinion flow visualization that combines a Sankey graph with a tailored density map in one view to visually convey diffusion of opinions among many users. A stacked tree is used to allow analysts to select topics of interest at different levels. The stacked tree is synchronized with the opinion flow visualization to help users examine and compare diffusion patterns across topics. Experiments and case studies on Twitter data demonstrate the effectiveness and usability of OpinionFlow.","keywords":"Opinion visualization, opinion diffusion, opinion flow, influence estimation, kernel density estimation, level-of-detail","caption":"Fig. 10. Opinion diffusion triggered by World War II veterans who crossed memorial barricades despite the shutdown.","img_size":{"width":1059,"height":586},"subfigures":[{"x":9.721956966979466,"y":6.719904813510023,"width":1039.5560860660414,"height":567.7576697645953,"type":"single","id":"single-0"}],"visualizations":[{"x":3.1295754026353677,"y":9.437774524158126,"width":1047.592972181552,"height":569.6983894582723,"type":"area_chart","id":"area_chart-0"},{"x":324.6370052592651,"y":144.34270412546297,"width":707.7050157701146,"height":262.72528736774086,"type":"graph","id":"graph-1"},{"x":128.69374517941657,"y":146.66283395503996,"width":664.9392756131613,"height":312.77974650504717,"type":"word_cloud","id":"word_cloud-3"}],"relations":[{"vislist":[{"vislist":["graph-1"],"relation":null,"id":"group-2"},{"vislist":["area_chart-0"],"relation":null,"id":"group-3"}],"relation":"coordinated","id":"relation-1"},{"vislist":[{"vislist":["word_cloud-3"],"relation":null,"id":"group-4"},{"vislist":["area_chart-0"],"relation":null,"id":"group-5"}],"relation":"coordinated","id":"relation-2"}]},"2588_0":{"comp":[["proportional_area_chart","matrix",["coordinated"]]],"visType":["proportional_area_chart","matrix"],"compType":["coordinated"],"compressed_tree":[{"composite_pattern":"coordinated","visualization_type":[["proportional_area_chart"],["matrix"]]}],"coOccurrence":[],"year":2014,"conference":["VAST"],"authors":["Eric C. Alexander","Joe Kohlmann","Robin Valenza","Michael Witmore","Michael Gleicher"],"title":"Serendip: Topic Model-Driven Visual Exploration of Text Corpora","doi":"10.1109/VAST.2014.7042493","abstract":"Exploration and discovery in a large text corpus requires investigation at multiple levels of abstraction, from a zoomed-out view of the entire corpus down to close-ups of individual passages and words. At each of these levels, there is a wealth of information that can inform inquiry - from statistical models, to metadata, to the researcher\'s own knowledge and expertise. Joining all this information together can be a challenge, and there are issues of scale to be combatted along the way. In this paper, we describe an approach to text analysis that addresses these challenges of scale and multiple information sources, using probabilistic topic models to structure exploration through multiple levels of inquiry in a way that fosters serendipitous discovery. In implementing this approach into a tool called Serendip, we incorporate topic model data and metadata into a highly reorderable matrix to expose corpus level trends; extend encodings of tagged text to illustrate probabilistic information at a passage level; and introduce a technique for visualizing individual word rankings, along with interaction techniques and new statistical methods to create links between different levels and information types. We describe example uses from both the humanities and visualization research that illustrate the benefits of our approach.","keywords":"Text visualization, topic modeling","caption":"Fig. 1. The three main views of Serendip: CorpusViewer, TextViewer, and RankViewer.","img_size":{"width":2151,"height":1052},"subfigures":[{"x":4.176469475348643,"y":23.422633466809256,"width":1069.325672308086,"height":617.3843026839588,"type":"interface","id":"interface-0"},{"x":1117.9754511731785,"y":29.615085037903313,"width":1024.3040991183664,"height":611.2537613221316,"type":"interface","id":"interface-1"},{"x":412.00647306055635,"y":678.0080657641375,"width":1267.6184763357035,"height":358.94621719006074,"type":"single","id":"single-2"}],"visualizations":[{"x":424.75691699604755,"y":717.2727272727273,"width":1091.501976284585,"height":329.988533988534,"type":"bar_chart","id":"bar_chart-0"},{"x":1541.207509881423,"y":715.193675889328,"width":124.74308300395249,"height":245.32806324110675,"type":"bar_chart","id":"bar_chart-1"},{"x":817.6976284584979,"y":68.6086956521739,"width":145.5335968379447,"height":228.69565217391303,"type":"bar_chart","id":"bar_chart-2"},{"x":1125.221735680228,"y":29.308123014129393,"width":158.52478260779856,"height":604.8071773951646,"type":"bar_chart","id":"bar_chart-5"},{"x":1836.4328063241107,"y":27.027667984189726,"width":307.6996047430828,"height":609.1620553359684,"type":"line_chart","id":"line_chart-3"},{"x":225.2292535237258,"y":60.82803529823867,"width":582.0731180177761,"height":573.2826366385202,"type":"matrix","id":"matrix-4"},{"x":223.0870455600011,"y":63.01423556793062,"width":576.2147977688861,"height":571.5138712064797,"type":"proportional_area_chart","id":"proportional_area_chart-6"}],"relations":[{"vislist":[{"vislist":["proportional_area_chart-6"],"relation":null,"id":"group-0"},{"vislist":["matrix-4"],"relation":null,"id":"group-1"}],"relation":"coordinated","id":"relation-0"}]},"2577_1":{"comp":[["graph","map",["coordinated"]],["graph","scatterplot",["coordinated"]]],"visType":["graph","map","scatterplot"],"compType":["coordinated"],"compressed_tree":[{"composite_pattern":"coordinated","visualization_type":[["graph"],["map"]]},{"composite_pattern":"coordinated","visualization_type":[["graph"],["scatterplot"]]}],"coOccurrence":[["graph","scatterplot",["coOccurrence"]]],"year":2014,"conference":["VAST"],"authors":["Steven R. Gomez","Hua Guo","Caroline Ziemkiewicz","David H. Laidlaw"],"title":"An Insight- and Task-based Methodology for Evaluating Spatiotemporal Visual Analytics","doi":"10.1109/VAST.2014.7042482","abstract":"We present a method for evaluating visualizations using both tasks and exploration, and demonstrate this method in a study of spatiotemporal network designs for a visual analytics system. The method is well suited for studying visual analytics applications in which users perform both targeted data searches and analyses of broader patterns. In such applications, an effective visualization design is one that helps users complete tasks accurately and efficiently, and supports hypothesis generation during open-ended exploration. To evaluate both of these aims in a single study, we developed an approach called layered insight- and task-based evaluation (LITE) that interposes several prompts for observations about the data model between sequences of predefined search tasks. We demonstrate the evaluation method in a user study of four network visualizations for spatiotemporal data in a visual analytics application. Results include findings that might have been difficult to obtain in a single experiment using a different methodology. For example, with one dataset we studied, we found that on average participants were faster on search tasks using a force-directed layout than using our other designs; at the same time, participants found this design least helpful in understanding the data. Our contributions include a novel evaluation method that combines well-defined tasks with exploration and observation, an evaluation of network visualization designs for spatiotemporal visual analytics, and guidelines for using this evaluation method.","keywords":"Evaluation methodology, insight-based evaluation, visual analytics, network visualization, information visualization","caption":"Fig. 2: Four visualization designs were evaluated using a layered insight- and task-based evaluation: force-directed (F), time-situated (TS), space-situated (SS), and time- and space-situated (TSS). These visualizations depict microblog messages and their authors, and the designs differ in how attributes of the nodes, like timestamp and location, are used to lay out the diagram.","img_size":{"width":2049,"height":1593},"subfigures":[{"x":1028.6396282134726,"y":14.738982326866072,"width":1013.8009772866877,"height":684.464073748111,"type":"interface","id":"interface-1"},{"x":27.013648482777032,"y":837.9847198755058,"width":692.3640647483513,"height":693.8218777998345,"type":"interface","id":"interface-2"},{"x":1050.022682137238,"y":827.2559557606771,"width":957.9870366683411,"height":713.1035199859286,"type":"single","id":"single-0"}],"visualizations":[{"x":4.517195767195767,"y":5.440573770491803,"width":680.3980263157896,"height":768.5526315789473,"type":"graph","id":"graph-0"},{"x":1033.2335526315792,"y":24.453947368421055,"width":1011.2492516012251,"height":747.5921052631579,"type":"graph","id":"graph-1"},{"x":29.26394438634771,"y":842.7657926496427,"width":698.4698242415557,"height":744.7936335798655,"type":"graph","id":"graph-2"},{"x":1076.9686807486814,"y":836.8465568509854,"width":926.3604024898596,"height":750.7128693785228,"type":"graph","id":"graph-3"},{"x":22.269098481228546,"y":840.7699896612465,"width":707.1231786989161,"height":744.9559223168494,"type":"map","id":"map-4"},{"x":1072.8642710991126,"y":843.3033074390373,"width":931.3852144155304,"height":742.0655162694653,"type":"scatterplot","id":"scatterplot-5"}],"relations":[{"vislist":[{"vislist":["graph-2"],"relation":null,"id":"group-0"},{"vislist":["map-4"],"relation":null,"id":"group-1"}],"relation":"coordinated","id":"relation-0"},{"vislist":[{"vislist":["graph-3"],"relation":null,"id":"group-2"},{"vislist":["scatterplot-5"],"relation":null,"id":"group-3"}],"relation":"coordinated","id":"relation-1"}]},"2457_3":{"comp":[["proportional_area_chart","map",["coordinated"]]],"visType":["proportional_area_chart","map"],"compType":["coordinated"],"compressed_tree":[{"composite_pattern":"coordinated","visualization_type":[["proportional_area_chart"],["map"]]}],"coOccurrence":[["proportional_area_chart","map",["coOccurrence"]]],"year":2013,"conference":["VAST"],"authors":["Nivan Ferreira","Jorge Poco","Huy T. Vo","Juliana Freire","Cl\xe1udio T. Silva"],"title":"Visual Exploration of Big Spatio-Temporal Urban Data: A Study of New York City Taxi Trips","doi":"10.1109/TVCG.2013.226","abstract":"As increasing volumes of urban data are captured and become available, new opportunities arise for data-driven analysis that can lead to improvements in the lives of citizens through evidence-based decision making and policies. In this paper, we focus on a particularly important urban data set: taxi trips. Taxis are valuable sensors and information associated with taxi trips can provide unprecedented insight into many different aspects of city life, from economic activity and human behavior to mobility patterns. But analyzing these data presents many challenges. The data are complex, containing geographical and temporal components in addition to multiple variables associated with each trip. Consequently, it is hard to specify exploratory queries and to perform comparative analyses (e.g., compare different regions over time). This problem is compounded due to the size of the data-there are on average 500,000 taxi trips each day in NYC. We propose a new model that allows users to visually query taxi trips. Besides standard analytics queries, the model supports origin-destination queries that enable the study of mobility across the city. We show that this model is able to express a wide range of spatio-temporal queries, and it is also flexible in that not only can queries be composed but also different aggregations and visual representations can be applied, allowing users to explore and compare results. We have built a scalable system that implements this model which supports interactive response times; makes use of an adaptive level-of-detail rendering strategy to generate clutter-free visualization for large results; and shows hidden details to the users in a summary through the use of overlay heat maps. We present a series of case studies motivated by traffic engineers and economists that show how our model and system enable domain experts to perform tasks that were previously unattainable for them.","keywords":"Spatio-temporal queries, urban data, taxi movement data, visual exploration","caption":"Fig. 4. TaxiVis user interface components. (A) Time selection widget, (B) Map, (C) Tool bar, and (D) Data summary. We can also see an ex- ample of three distinct queries specified by colors. The orange query (orange border polygon) represents an atomic query with a spatial sin- gle region start constraint. The red query (red border polygon) repre- sents an atomic query with a spatial single region end constraint. The blue query is a complex query which is the union of two atomic queries: the polygon with blue border (atomic single region start constraint) and a directional query (blue arrow).","img_size":{"width":981,"height":1190},"subfigures":[{"x":32.77405990890654,"y":5.404817141945383,"width":924.3181403387207,"height":1150.0617627361298,"type":"interface","id":"interface-0"}],"visualizations":[{"x":55.420948616600754,"y":761.97628458498,"width":867.8063241106721,"height":338.65612648221344,"type":"line_chart","id":"line_chart-2"},{"x":46.013833992094874,"y":195.197628458498,"width":844.2885375494072,"height":522.0948616600791,"type":"map","id":"map-0"},{"x":250.78153847878443,"y":212.10963793290696,"width":388.2411042895256,"height":487.1593043257075,"type":"proportional_area_chart","id":"proportional_area_chart-3"}],"relations":[{"vislist":[{"vislist":["proportional_area_chart-3"],"relation":null,"id":"group-1"},{"vislist":["map-0"],"relation":null,"id":"group-0"}],"relation":"coordinated","id":"relation-0"}]},"1431_16":{"comp":[["graph","treemap",["coordinated"]]],"visType":["graph","treemap"],"compType":["coordinated"],"compressed_tree":[{"composite_pattern":"coordinated","visualization_type":[["hierarchical_edge_bundling","graph"],["treemap"]]}],"coOccurrence":[],"year":2006,"conference":["InfoVis"],"authors":["Danny Holten"],"title":"Hierarchical Edge Bundles: Visualization of Adjacency Relations in Hierarchical Data","doi":"10.1109/TVCG.2006.147","abstract":"A compound graph is a frequently encountered type of data set. Relations are given between items, and a hierarchy is defined on the items as well. We present a new method for visualizing such compound graphs. Our approach is based on visually bundling the adjacency edges, i.e., non-hierarchical edges, together. We realize this as follows. We assume that the hierarchy is shown via a standard tree visualization method. Next, we bend each adjacency edge, modeled as a B-spline curve, toward the polyline defined by the path via the inclusion edges from one node to another. This hierarchical bundling reduces visual clutter and also visualizes implicit adjacency edges between parent nodes that are the result of explicit adjacency edges between their respective child nodes. Furthermore, hierarchical edge bundling is a generic method which can be used in conjunction with existing tree visualization techniques. We illustrate our technique by providing example visualizations and discuss the results based on an informal evaluation provided by potential users of such visualizations","keywords":"Network visualization, edge bundling, edge aggregation, edge concentration, curves, graph visualization, tree visualization, node-link diagrams, hierarchies, treemaps","caption":"Fig. 15. The software system from \ufb01gure 13 and its associated call tween a low-level and a high-level view of the adjacency relations. We graph (caller = green, callee = red) visualized using a squari\ufb01ed treemap have also illustrated how the use of more advanced blending modes layout (node labels disabled) for comparison with \ufb01gure 11b. The encir- than standard alpha blending can provide a valuable addition to the cled regions highlight the same parts of the system as in \ufb01gure 13.","img_size":{"width":1078,"height":993},"subfigures":[{"x":14.840695211656483,"y":12.706847643504437,"width":1051.7925796736977,"height":972.797687460001,"type":"single","id":"single-0"}],"visualizations":[{"x":31.00245652865258,"y":26.121150867791844,"width":1013.2812463477611,"height":931.2632953210485,"type":"graph","id":"graph-2"},{"x":31.279661016949145,"y":22.44067796610169,"width":1024.7909604519775,"height":953.728813559322,"type":"treemap","id":"treemap-1"}],"relations":[{"vislist":[{"vislist":["hierarchical_edge_bundling-0","graph-2"],"relation":null,"id":"group-0"},{"vislist":["treemap-1"],"relation":null,"id":"group-1"}],"relation":"coordinated","id":"relation-0"}]},"1431_14":{"comp":[["graph","treemap",["coordinated"]],["arc_diagram","tree",["stacked"]],["tree","arc_diagram",["stacked"]]],"visType":["graph","treemap","arc_diagram","tree"],"compType":["coordinated","stacked"],"compressed_tree":[{"composite_pattern":"stacked","visualization_type":[["arc_diagram","tree"]]},{"composite_pattern":"coordinated","visualization_type":[["graph","hierarchical_edge_bundling"],["treemap"]]}],"coOccurrence":[["graph","treemap",["coOccurrence"]]],"year":2006,"conference":["InfoVis"],"authors":["Danny Holten"],"title":"Hierarchical Edge Bundles: Visualization of Adjacency Relations in Hierarchical Data","doi":"10.1109/TVCG.2006.147","abstract":"A compound graph is a frequently encountered type of data set. Relations are given between items, and a hierarchy is defined on the items as well. We present a new method for visualizing such compound graphs. Our approach is based on visually bundling the adjacency edges, i.e., non-hierarchical edges, together. We realize this as follows. We assume that the hierarchy is shown via a standard tree visualization method. Next, we bend each adjacency edge, modeled as a B-spline curve, toward the polyline defined by the path via the inclusion edges from one node to another. This hierarchical bundling reduces visual clutter and also visualizes implicit adjacency edges between parent nodes that are the result of explicit adjacency edges between their respective child nodes. Furthermore, hierarchical edge bundling is a generic method which can be used in conjunction with existing tree visualization techniques. We illustrate our technique by providing example visualizations and discuss the results based on an informal evaluation provided by potential users of such visualizations","keywords":"Network visualization, edge bundling, edge aggregation, edge concentration, curves, graph visualization, tree visualization, node-link diagrams, hierarchies, treemaps","caption":"Fig. 17. Collinearity problems. The rooted tree layout (a) and the slice- and-dice treemap layout (b) were found to be less pleasing. This is probably due to the large number of collinear nodes within these layouts, which causes bundles to overlap along the collinearity axes, as is visible within the encircled regions.","img_size":{"width":1048,"height":551},"subfigures":[{"x":5.381299491854492,"y":11.877050549541078,"width":473.8386146413773,"height":476.78321642938596,"type":"single","id":"single-0"},{"x":483.8319155295692,"y":8.614041603979102,"width":559.2251373595404,"height":478.7217177321882,"type":"single","id":"single-1"}],"visualizations":[{"x":3.0466786453814843,"y":326.36840117268093,"width":460.45850805430393,"height":155.15215149412495,"type":"arc_diagram","id":"arc_diagram-4"},{"x":489.9032908396799,"y":13.805667908854684,"width":546.1086577746939,"height":468.8690660652765,"type":"graph","id":"graph-6"},{"x":3.6111111111111005,"y":12.451977401129943,"width":468.26788697243,"height":473.2170150762944,"type":"hierarchical_edge_bundling","id":"hierarchical_edge_bundling-0"},{"x":489.23822975517885,"y":14.527306967984934,"width":546.8493408662898,"height":467.98681732580036,"type":"hierarchical_edge_bundling","id":"hierarchical_edge_bundling-1"},{"x":4.576536925787629,"y":11.423163368454714,"width":466.67148752102537,"height":310.42646148851276,"type":"tree","id":"tree-2"},{"x":489.1454522489517,"y":14.495892411418286,"width":549.0174479393721,"height":470.09356144922197,"type":"treemap","id":"treemap-3"}],"relations":[{"vislist":[{"vislist":["arc_diagram-4","tree-2"],"relation":null,"id":"group-0"}],"relation":"stacked","id":"relation-0"},{"vislist":[{"vislist":["graph-6","hierarchical_edge_bundling-1"],"relation":null,"id":"group-1"},{"vislist":["treemap-3"],"relation":null,"id":"group-2"}],"relation":"coordinated","id":"relation-1"}]},"1441_1":{"comp":[["graph","contour_graph",["coordinated"]]],"visType":["graph","contour_graph"],"compType":["coordinated"],"compressed_tree":[{"composite_pattern":"coordinated","visualization_type":[["graph"],["contour_graph"]]}],"coOccurrence":[],"year":2006,"conference":["InfoVis"],"authors":["Pier Francesco Cortese","Giuseppe Di Battista","Antonello Moneta","Maurizio Patrignani","Maurizio Pizzonia"],"title":"Topographic Visualization of Prefix Propagation in the Internet","doi":"10.1109/TVCG.2006.185","abstract":"We propose a new metaphor for the visualization of prefixes propagation in the Internet. Such a metaphor is based on the concept of topographic map and allows to put in evidence the relative importance of the Internet Service Providers (ISPs) involved in the routing of the prefix. Based on the new metaphor we propose an algorithm for computing layouts and experiment with such algorithm on a test suite taken from the real Internet. The paper extends the visualization approach of the BGPlay service, which is an Internet routing monitoring tool widely used by ISP operators","keywords":"Interdomain Routing, Internet Visualization, Graph Drawing, Spring Embedder","caption":"Fig. 2. (a) A screenshot of the BGPlay system enhanced by the topographic map approach described in this paper. The AS that originates the pre\ufb01x is 137, highlighted in red an indicated by an arrow. Our approach clearly shows the importance of the ASes traversed by paths ending into 137. (b), (c) An example of a real topographic map (courtesy of the U.S. GS).","img_size":{"width":2148,"height":1256},"subfigures":[{"x":58.41793347240404,"y":20.49240014622482,"width":1407.4275773511933,"height":1177.909161532827,"type":"interface","id":"interface-0"},{"x":1513.550524363811,"y":24.718822075787884,"width":626.0872406560799,"height":497.27770604548857,"type":"single","id":"single-1"}],"visualizations":[{"x":64.04809052333798,"y":26.647807637906645,"width":1389.239038189533,"height":1170.7270155586987,"type":"graph","id":"graph-0"},{"x":1517.241867043847,"y":19.541725601131542,"width":620.0056577086282,"height":500.97878359264496,"type":"graph","id":"graph-1"},{"x":1513.6888260254595,"y":573.8161244695898,"width":620.0056577086284,"height":625.3352192362094,"type":"graph","id":"graph-2"},{"x":1513.6888260254595,"y":19.541725601131542,"width":625.3352192362095,"height":499.2022630834512,"type":"map","id":"map-3"},{"x":1515.4653465346535,"y":572.0396039603961,"width":623.5586987270156,"height":628.8882602545968,"type":"map","id":"map-4"},{"x":60.49504950495043,"y":24.87128712871287,"width":1396.3451202263082,"height":1174.2800565770865,"type":"contour_graph","id":"contour_graph-5"}],"relations":[{"vislist":[{"vislist":["graph-0"],"relation":null,"id":"group-2"},{"vislist":["contour_graph-5"],"relation":null,"id":"group-3"}],"relation":"coordinated","id":"relation-0"}]},"1740_2":{"comp":[["graph","map",["coordinated"]]],"visType":["graph","map"],"compType":["coordinated"],"compressed_tree":[{"composite_pattern":"coordinated","visualization_type":[["graph"],["map"]]}],"coOccurrence":[["graph","map",["coOccurrence"]]],"year":2008,"conference":["VAST"],"authors":["Benjamin Holland","Lisa Kuchy","Jason Dalton"],"title":"Migrant boat mini challenge award: Analysis summary a geo-temporal analysis of the migrant boat dataset","doi":"10.1109/VAST.2008.4677394","abstract":"The SPADAC team used various visual analytics tools and methods to find geo-temporal patterns of migration from a Caribbean island from 2005-2007. In this paper, we describe the tools and methods used in the analysis. These methods included generating temporal variograms, dendrograms, and proportionally weighted migration maps, using tools such as the R statistical software package and Signature Analysttrade. We found that there is a significant positive space-time correlation with the boat encounters (especially the landings), with a migratory shift further away from the point of departure over time.","keywords":"","caption":"Figure 3: Geographic Patterns of Migration (Landings) from Isla del Sue\xf1o, 2006","img_size":{"width":974,"height":648},"subfigures":[{"x":2.8245017163900576,"y":4.72844124945942,"width":961.7065080299361,"height":634.7440326207385,"type":"single","id":"single-0"}],"visualizations":[{"x":243.49999999999983,"y":185.48272702539793,"width":486.99999999999943,"height":401.2315801952236,"type":"graph","id":"graph-1"},{"x":5.506588579794994,"y":1.848730563654033,"width":962.9868228404101,"height":641.358711566618,"type":"map","id":"map-0"}],"relations":[{"vislist":[{"vislist":["graph-1"],"relation":null,"id":"group-0"},{"vislist":["map-0"],"relation":null,"id":"group-1"}],"relation":"coordinated","id":"relation-0"}]},"2639_0":{"comp":[["glyph_based","map",["coordinated"]]],"visType":["glyph_based","map"],"compType":["coordinated"],"compressed_tree":[{"composite_pattern":"coordinated","visualization_type":[["glyph_based"],["map"]]}],"coOccurrence":[["glyph_based","map",["coOccurrence"]]],"year":2015,"conference":["SciVis"],"authors":["Najmeh Abedzadeh"],"title":"Correlation analysis in multidimensional multivariate time-varying datasets","doi":"10.1109/SciVis.2015.7429502","abstract":"One of the most vital challenges for weather forecasters is the correlation between two geographical phenomena that are distributed continuously in multidimensional multivariate time-varying datasets. In this research, we have visualized the correlation between Pressure and Temperature in the climate datasets. Pearson correlation is used in this study to measure the major linear relationship between two variables in the dataset. Using glyphs in the spatial location, we highlighted the significant association between variables. Based on the positive or negative slope of correlation lines, we can conclude how much they are correlated. The principal of this research is visualizing the local trend of variables versus each other in multidimensional multivariate time-varying datasets, which needs to be visualized with their spatial locations in meteorological datasets. Using glyphs, not only can we visualize the correlation between two variables in the coordinate system, but we can also discern whether any of these variables is separately increasing or decreasing. Moreover, we can visualize the background color as another variable and see the correlation lines around of a particular zone such as storm area.","keywords":"","caption":"Figure 1: These images visualize the correlation between Pressure and Temperature within 6 hours (60-66) as the local trend of 72 time steps. Figure a visualizes the correlation between Pressure and Temperature within 6 hours (42-48) as the local trend of 72 time steps. Figure b visualizes the speci\ufb01c humidity at 850mb as the background color and the numbers are in kg. The shading color is Pressure and the numbers are in millibars. The violet circles are representing that Pressure is rising. ","img_size":{"width":2133,"height":896},"subfigures":[{"x":5.690351462560852,"y":6.449876184532944,"width":2119.3958904904007,"height":849.75300754457,"type":"single","id":"single-0"}],"visualizations":[{"x":47.27841604716508,"y":12.194237237048721,"width":883.9229892659083,"height":794.6989907735548,"type":"glyph_based","id":"glyph_based-1"},{"x":32.598519021269404,"y":12.259768215910174,"width":897.0979210003168,"height":805.3626705354598,"type":"map","id":"map-0"}],"relations":[{"vislist":[{"vislist":["glyph_based-1"],"relation":null,"id":"group-1"},{"vislist":["map-0"],"relation":null,"id":"group-0"}],"relation":"coordinated","id":"relation-0"}]},"2646_2":{"comp":[["scatterplot","map",["coordinated"]]],"visType":["scatterplot","map"],"compType":["coordinated"],"compressed_tree":[{"composite_pattern":"coordinated","visualization_type":[["scatterplot"],["map"]]}],"coOccurrence":[["scatterplot","map",["coOccurrence"]]],"year":2015,"conference":["SciVis"],"authors":["Jonathan Leidig","Santhosh Dharmapuri"],"title":"Automated visualization workflow for simulation experiments","doi":"10.1109/SciVis.2015.7429509","abstract":"Modeling and simulation is often used to predict future events and plan accordingly. Experiments in this domain often produce thousands of results from individual simulations, based on slightly varying input parameters. Geo-spatial visualizations can be a powerful tool to help health researchers and decision-makers to take measures during catastrophic and epidemic events such as Ebola outbreaks. The work produced a web-based geo-visualization tool to visualize and compare the spread of Ebola in the West African countries Ivory Coast and Senegal based on multiple simulation results. The visualization is not Ebola specific and may visualize any time-varying frequencies for given geo-locations.","keywords":"","caption":"Figure 3: For  a  selected  simulation  run,  the  tool  automatically  extracts the daily predictions and visualizes the Ebola affected locations  in  Senegal  in  an  animation,  using  Heatmap  data  layers  on  Google  maps,  where  green  colors  represent  low  Ebola  prevalence,  red  for  high  Ebola  prevalence,  and  marker  sizes  are  aligned  with  aggregated  infected  counts  for  a  given  day and location.","img_size":{"width":970,"height":702},"subfigures":[{"x":6.1676851360134535,"y":6.972199335726259,"width":959.9044383084114,"height":690.2969180211244,"type":"single","id":"single-0"}],"visualizations":[{"x":12.844919218586675,"y":12.903617875164272,"width":947.2965730034134,"height":680.6753976348257,"type":"map","id":"map-0"},{"x":297.3259716110874,"y":80.54773127477117,"width":544.8269060310345,"height":460.2171365176858,"type":"scatterplot","id":"scatterplot-1"}],"relations":[{"vislist":[{"vislist":["scatterplot-1"],"relation":null,"id":"group-1"},{"vislist":["map-0"],"relation":null,"id":"group-0"}],"relation":"coordinated","id":"relation-0"}]},"2533_0":{"comp":[["line_chart","map",["coordinated"]]],"visType":["line_chart","map"],"compType":["coordinated"],"compressed_tree":[{"composite_pattern":"coordinated","visualization_type":[["line_chart"],["map"]]}],"coOccurrence":[["line_chart","map",["coOccurrence"]]],"year":2014,"conference":["SciVis"],"authors":["Mahsa Mirzargar","Ross T. Whitaker","Robert Michael Kirby"],"title":"Curve Boxplot: Generalization of Boxplot for Ensembles of Curves","doi":"10.1109/TVCG.2014.2346455","abstract":"In simulation science, computational scientists often study the behavior of their simulations by repeated solutions with variations in parameters and/or boundary values or initial conditions. Through such simulation ensembles, one can try to understand or quantify the variability or uncertainty in a solution as a function of the various inputs or model assumptions. In response to a growing interest in simulation ensembles, the visualization community has developed a suite of methods for allowing users to observe and understand the properties of these ensembles in an efficient and effective manner. An important aspect of visualizing simulations is the analysis of derived features, often represented as points, surfaces, or curves. In this paper, we present a novel, nonparametric method for summarizing ensembles of 2D and 3D curves. We propose an extension of a method from descriptive statistics, data depth, to curves. We also demonstrate a set of rendering and visualization strategies for showing rank statistics of an ensemble of curves, which is a generalization of traditional whisker plots or boxplots to multidimensional curves. Results are presented for applications in neuroimaging, hurricane forecasting and fluid dynamics.","keywords":"Uncertainty visualization, boxplots, ensemble visualization, order statistics, data depth, nonparametric statistic, functional data, parametric curves","caption":"Fig. 1. Visualization of the order statistics of 27 historic hurricane tracks originating in the Gulf of Mexico between 1920 \u2212 2012 (left) and a curve boxplot visualization of an ensemble of 50 simulated hurricane tracks (right). ","img_size":{"width":1895,"height":528},"subfigures":[{"x":91.0849104457358,"y":7.105105535371554,"width":786.5189794090666,"height":508.2794868306745,"type":"single","id":"single-0"}],"visualizations":[{"x":276.03408338652076,"y":30.138145743606255,"width":582.3960289349634,"height":476.082323902447,"type":"line_chart","id":"line_chart-1"},{"x":269.4238521342078,"y":17.035906749621336,"width":597.287998701769,"height":495.5999095786884,"type":"map","id":"map-0"}],"relations":[{"vislist":[{"vislist":["line_chart-1"],"relation":null,"id":"group-0"},{"vislist":["map-0"],"relation":null,"id":"group-1"}],"relation":"coordinated","id":"relation-0"}]},"2049_8":{"comp":[["others","map",["coordinated"]]],"visType":["others","map"],"compType":["coordinated"],"compressed_tree":[{"composite_pattern":"coordinated","visualization_type":[["others"],["map"]]}],"coOccurrence":[["others","map",["coOccurrence"]]],"year":2010,"conference":["Vis"],"authors":["Jibonananda Sanyal","Song Zhan","Jamie Dyer","Andrew Merce","Philip Amburn","Robert J. Moorhead II"],"title":"Noodles: A Tool for Visualization of Numerical Weather Model Ensemble Uncertainty","doi":"10.1109/TVCG.2010.181","abstract":"Numerical weather prediction ensembles are routinely used for operational weather forecasting. The members of these ensembles are individual simulations with either slightly perturbed initial conditions or different model parameterizations, or occasionally both. Multi-member ensemble output is usually large, multivariate, and challenging to interpret interactively. Forecast meteorologists are interested in understanding the uncertainties associated with numerical weather prediction; specifically variability between the ensemble members. Currently, visualization of ensemble members is mostly accomplished through spaghetti plots of a single midtroposphere pressure surface height contour. In order to explore new uncertainty visualization methods, the Weather Research and Forecasting (WRF) model was used to create a 48-hour, 18 member parameterization ensemble of the 13 March 1993 \\"Superstorm\\". A tool was designed to interactively explore the ensemble uncertainty of three important weather variables: water-vapor mixing ratio, perturbation potential temperature, and perturbation pressure. Uncertainty was quantified using individual ensemble member standard deviation, inter-quartile range, and the width of the 95% confidence interval. Bootstrapping was employed to overcome the dependence on normality in the uncertainty metrics. A coordinated view of ribbon and glyph-based uncertainty visualization, spaghetti plots, iso-pressure colormaps, and data transect plots was provided to two meteorologists for expert evaluation. They found it useful in assessing uncertainty in the data, especially in finding outliers in the ensemble run and therefore avoiding the WRF parameterizations that lead to these outliers. Additionally, the meteorologists could identify spatial regions where the uncertainty was significantly high, allowing for identification of poorly simulated storm environments and physical interpretation of these model issues.","keywords":"Uncertainty visualization, weather ensemble, geographic/geospatial visualization, glyph-based techniques, time-varying data, qualitative evaluation","caption":"Fig. 9. The user interface of Noodles. The main display area is boxed in red, the second data control area is in blue, the third uncertainty visual- ization control area is in green, and the fourth data-transect plot area is in pink. ","img_size":{"width":849,"height":753},"subfigures":[{"x":9.888266180676029,"y":99.24330231700166,"width":832.3115648856366,"height":582.2836019897338,"type":"interface","id":"interface-0"}],"visualizations":[{"x":531.6184872521999,"y":247.0451257008544,"width":295.29907124870425,"height":179.71323341207574,"type":"line_chart","id":"line_chart-0"},{"x":23.864173140041167,"y":126.91164424210025,"width":496.579392017051,"height":418.9516701583348,"type":"map","id":"map-1"},{"x":23.85246724389011,"y":126.93908049692013,"width":487.3385120683882,"height":423.010902333693,"type":"others","id":"others-2"}],"relations":[{"vislist":[{"vislist":["others-2"],"relation":null,"id":"group-0"},{"vislist":["map-1"],"relation":null,"id":"group-1"}],"relation":"coordinated","id":"relation-0"}]},"3154_12":{"comp":[["scivis","scivis",["large_view"]]],"visType":["scivis"],"compType":["large_view"],"compressed_tree":[{"composite_pattern":"large_view","visualization_type":[["scivis"],["scivis"]]}],"coOccurrence":[["scivis","scivis",["coOccurrence"]]],"year":2019,"conference":["InfoVis"],"authors":["Wenbin He","Junpeng Wang","Hanqi Guo","Ko-Chih Wang","Han-Wei Shen","Mukund Raj","Youssef S. G. Nashed","Tom Peterka"],"title":"InSituNet: Deep Image Synthesis for Parameter Space Exploration of Ensemble Simulations (J) (Best Paper Aw","doi":"10.1109/TVCG.2019.2934312","abstract":"We propose InSituNet, a deep learning based surrogate model to support parameter space exploration for ensemble simulations that are visualized in situ. In situ visualization, generating visualizations at simulation time, is becoming prevalent in handling large-scale simulations because of the I/O and storage constraints. However, in situ visualization approaches limit the flexibility of post-hoc exploration because the raw simulation data are no longer available. Although multiple image-based approaches have been proposed to mitigate this limitation, those approaches lack the ability to explore the simulation parameters. Our approach allows flexible exploration of parameter space for large-scale ensemble simulations by taking advantage of the recent advances in deep learning. Specifically, we design InSituNet as a convolutional regression model to learn the mapping from the simulation and visualization parameters to the visualization results. With the trained model, users can generate new images for different simulation parameters under various visualization settings, which enables in-depth analysis of the underlying ensemble simulations. We demonstrate the effectiveness of InSituNet in combustion, cosmology, and ocean simulations through quantitative and qualitative evaluations.","keywords":"In situ visualization, ensemble visualization, parameter space exploration, deep learning, image synthesis","caption":"Fig. 7. Visual interface for parameter space exploration. (a) The three groups of parameters: simulation, visual mapping, and view parameters. (b) The predicted visualization image and the sensitivity analysis result.","img_size":{"width":1044,"height":504},"subfigures":[{"x":3.8872086015059097,"y":3.84946974332139,"width":1037.8579572514143,"height":493.5816212456715,"type":"interface","id":"interface-0"}],"visualizations":[{"x":47.960238135343786,"y":56.592766985111986,"width":505.1241990684194,"height":116.1054322270108,"type":"line_chart","id":"line_chart-0"},{"x":583.2833619396484,"y":44.093366004461245,"width":453.0771555607883,"height":444.20867292742025,"type":"scivis","id":"scivis-1"},{"x":826.894979203962,"y":292.19236139211995,"width":206.8057742381623,"height":196.96574403585961,"type":"scivis","id":"scivis-2"}],"relations":[{"vislist":[{"vislist":["scivis-2"],"relation":null,"id":"group-1"},{"vislist":["scivis-1"],"relation":null,"id":"group-0"}],"relation":"large_view","id":"relation-0"}]},"3188_1":{"comp":[["line_chart","heatmap",["large_view"]]],"visType":["line_chart","heatmap"],"compType":["large_view"],"compressed_tree":[{"composite_pattern":"large_view","visualization_type":[["line_chart"],["heatmap"]]}],"coOccurrence":[["line_chart","heatmap",["coOccurrence"]]],"year":2019,"conference":["VAST"],"authors":["Shusen Liu","Di Wang","Dan Maljovec","Rushil Anirudh","Jayaraman J. Thiagarajan","Sam Ade Jacobs","Brian C. Van Essen"],"title":"Scalable Topological Data Analysis and Visualization for Interpreting Data-Driven Models in Scientific Applications","doi":"10.1109/TVCG.2019.2934594","abstract":"With the rapid adoption of machine learning techniques for large-scale applications in science and engineering comes the convergence of two grand challenges in visualization. First, the utilization of black box models (e.g., deep neural networks) calls for advanced techniques in exploring and interpreting model behaviors. Second, the rapid growth in computing has produced enormous datasets that require techniques that can handle millions or more samples. Although some solutions to these interpretability challenges have been proposed, they typically do not scale beyond thousands of samples, nor do they provide the high-level intuition scientists are looking for. Here, we present the first scalable solution to explore and analyze high-dimensional functions often encountered in the scientific data analysis pipeline. By combining a new streaming neighborhood graph construction, the corresponding topology computation, and a novel data aggregation scheme, namely topology aware datacubes, we enable interactive exploration of both the topological and the geometric aspect of high-dimensional data. Following two use cases from high-energy-density (HED) physics and computational biology, we demonstrate how these capabilities have led to crucial new insights in both applications.","keywords":"Model Evaluation, Deep Learning, High-Dimensional Space, Topological Data Analysis, Inertial Con\ufb01nement Fusion","caption":"Fig. 2. The proposed visualization interface consists of three views: topological spine (a), density scatterplot (b), density parallel coordinates plot (c). These views provide complementary information, and the linked selection enables a joint analysis of both geometric and topological features. In (a1), we show the persistence plot, which controls the number of extrema displayed in the topological spine. ","img_size":{"width":1044,"height":741},"subfigures":[{"x":5.921164336998578,"y":5.0389460544284415,"width":1032.9460569396385,"height":738.808222179839,"type":"interface","id":"interface-0"}],"visualizations":[{"x":70.10873705825,"y":540.530102499832,"width":422.8673015674641,"height":186.88057651580388,"type":"heatmap","id":"heatmap-2"},{"x":9.562060965582182,"y":388.63052243755396,"width":165.53555920903585,"height":85.97372659969245,"type":"line_chart","id":"line_chart-1"},{"x":20.639869716095884,"y":55.042270574926114,"width":964.0893654997997,"height":315.4708873022762,"type":"parallel_coordinate","id":"parallel_coordinate-0"},{"x":525.7705823535791,"y":402.8122298763932,"width":496.1481391995231,"height":300.6509788443971,"type":"scatterplot","id":"scatterplot-3"}],"relations":[{"vislist":[{"vislist":["line_chart-1"],"relation":null,"id":"group-1"},{"vislist":["heatmap-2"],"relation":null,"id":"group-0"}],"relation":"large_view","id":"relation-0"}]},"2270_0":{"comp":[["scivis","scivis",["large_view"]]],"visType":["scivis"],"compType":["large_view"],"compressed_tree":[{"composite_pattern":"large_view","visualization_type":[["scivis"],["scivis"]]}],"coOccurrence":[["scivis","scivis",["coOccurrence"]]],"year":2012,"conference":["SciVis"],"authors":["Daniela Ushizima","Dmitriy Morozov","Gunther H. Weber","Andrea Gomes Campos Bianchi","James A. Sethian","E. Wes Bethel"],"title":"Augmented Topological Descriptors of Pore Networks for Material Science","doi":"10.1109/TVCG.2012.200","abstract":"One potential solution to reduce the concentration of carbon dioxide in the atmosphere is the geologic storage of captured CO&lt;sub&gt;2&lt;/sub&gt; in underground rock formations, also known as carbon sequestration. There is ongoing research to guarantee that this process is both efficient and safe. We describe tools that provide measurements of media porosity, and permeability estimates, including visualization of pore structures. Existing standard algorithms make limited use of geometric information in calculating permeability of complex microstructures. This quantity is important for the analysis of biomineralization, a subsurface process that can affect physical properties of porous media. This paper introduces geometric and topological descriptors that enhance the estimation of material permeability. Our analysis framework includes the processing of experimental data, segmentation, and feature extraction and making novel use of multiscale topological analysis to quantify maximum flow through porous networks. We illustrate our results using synchrotron-based X-ray computed microtomography of glass beads during biomineralization. We also benchmark the proposed algorithms using simulated data sets modeling jammed packed bead beds of a monodispersive material.","keywords":"Reeb graph, persistent homology, topological data analysis, geometric algorithms, segmentation, microscopy","caption":"Fig. 1. MicroCT of porous media: (A) cross-section of glass bead column, inoculated with S. pausterii that promote calcite precipitation; cross-section is input to our software Quant-CT, which outputs seg- mented slices as in (B); rendering of the segmentation result for the whole stack in (D) using VisIt; SEM image in (C) emphasizes the result of biomineralization, which clogs the void space, cementing the pore channels. ","img_size":{"width":1049,"height":781},"subfigures":[{"x":7.8184165845428,"y":6.87114703411878,"width":1036.562865106715,"height":765.1241629311085,"type":"single","id":"single-0"}],"visualizations":[{"x":13.095618457673531,"y":11.081892673137519,"width":1023.8753291765861,"height":755.6359001527444,"type":"scivis","id":"scivis-0"},{"x":785.2827141181373,"y":12.54966292052819,"width":251.69498841576103,"height":257.71838350644333,"type":"scivis","id":"scivis-1"},{"x":15.045034162936824,"y":16.620296229418145,"width":223.2516270914801,"height":227.17491538180687,"type":"scivis","id":"scivis-2"},{"x":798.0288192019295,"y":493.75838817353497,"width":239.0015713513833,"height":274.5971703002045,"type":"scivis","id":"scivis-3"}],"relations":[{"vislist":[{"vislist":["scivis-1","scivis-2","scivis-3"],"relation":null,"id":"group-0"},{"vislist":["scivis-0"],"relation":null,"id":"group-1"}],"relation":"large_view","id":"relation-0"}]},"1638_10":{"comp":[["scivis","scatterplot",["large_view"]]],"visType":["scivis","scatterplot"],"compType":["large_view"],"compressed_tree":[{"composite_pattern":"large_view","visualization_type":[["scivis"],["scatterplot"]]}],"coOccurrence":[["scivis","scatterplot",["coOccurrence"]]],"year":2007,"conference":["Vis"],"authors":["Carlos D. Correa","Deborah Silver","Mi Chen"],"title":"Illustrative Deformation for Data Exploration","doi":"10.1109/TVCG.2007.70565","abstract":"Much of the visualization research has focused on improving the rendering quality and speed, and enhancing the perceptibility of features in the data. Recently, significant emphasis has been placed on focus+context (F+C) techniques (e.g., fisheye views and magnification lens) for data exploration in addition to viewing transformation and hierarchical navigation. However, most of the existing data exploration techniques rely on the manipulation of viewing attributes of the rendering system or optical attributes of the data objects, with users being passive viewers. In this paper, we propose a more active approach to data exploration, which attempts to mimic how we would explore data if we were able to hold it and interact with it in our hands. This involves allowing the users to physically or actively manipulate the geometry of a data object. While this approach has been traditionally used in applications, such as surgical simulation, where the original geometry of the data objects is well understood by the users, there are several challenges when this approach is generalized for applications, such as flow and information visualization, where there is no common perception as to the normal or natural geometry of a data object. We introduce a taxonomy and a set of transformations especially for illustrative deformation of general data exploration. We present combined geometric or optical illustration operators for focus+context visualization, and examine the best means for preventing the deformed context from being misperceived. We demonstrated the feasibility of this generalization with examples of flow, information and video visualization.","keywords":"Volume deformation, focus+context visualization, interaction techniques","caption":"Fig. 10. Scatter Plot Visualization with Interaction Widget (inset). (a)-(c) Sequence for splitting while preserving FoA (de\ufb01ned along the center of the split). (d) Rotation can be used to select the region of interest along a different dimension. (e) Scaling of the FoA helps to get a better view. ","img_size":{"width":2174,"height":471},"subfigures":[{"x":1735.812720848446,"y":8.518167384816662,"width":434.8419196493648,"height":463.0120762301082,"type":"interface","id":"interface-0"}],"visualizations":[{"x":1743.8907642297006,"y":20.501466114201836,"width":416.92000160708005,"height":438.23760533121197,"type":"scatterplot","id":"scatterplot-0"},{"x":2012.6887366361734,"y":17.00783620042422,"width":157.00611324641903,"height":156.80605057219304,"type":"scivis","id":"scivis-1"}],"relations":[{"vislist":[{"vislist":["scivis-1"],"relation":null,"id":"group-1"},{"vislist":["scatterplot-0"],"relation":null,"id":"group-0"}],"relation":"large_view","id":"relation-0"}]},"3371_0":{"comp":[["area_chart","scatterplot",["large_view"]],["others","scatterplot",["large_view"]],["parallel_coordinate","scatterplot",["large_view"]]],"visType":["area_chart","scatterplot","others","parallel_coordinate"],"compType":["large_view"],"compressed_tree":[{"composite_pattern":"large_view","visualization_type":[["area_chart","others","parallel_coordinate"],["scatterplot"]]}],"coOccurrence":[["area_chart","others",["coOccurrence"]],["area_chart","parallel_coordinate",["coOccurrence"]],["area_chart","scatterplot",["coOccurrence"]],["others","parallel_coordinate",["coOccurrence"]],["others","scatterplot",["coOccurrence"]],["parallel_coordinate","scatterplot",["coOccurrence"]]],"year":2020,"conference":["SciVis"],"authors":["Tobias Rapp","Christoph Peters","Carsten Dachsbacher"],"title":"Visual Analysis of Large Multivariate Scattered Data using Clustering and Probabilistic Summaries","doi":"10.1109/TVCG.2020.3030379","abstract":"Rapidly growing data sizes of scientific simulations pose significant challenges for interactive visualization and analysis techniques. In this work, we propose a compact probabilistic representation to interactively visualize large scattered datasets. In contrast to previous approaches that represent blocks of volumetric data using probability distributions, we model clusters of arbitrarily structured multivariate data. In detail, we discuss how to efficiently represent and store a high-dimensional distribution for each cluster. We observe that it suffices to consider low-dimensional marginal distributions for two or three data dimensions at a time to employ common visual analysis techniques. Based on this observation, we represent high-dimensional distributions by combinations of low-dimensional Gaussian mixture models. We discuss the application of common interactive visual analysis techniques to this representation. In particular, we investigate several frequency-based views, such as density plots in 1D and 2D, density-based parallel coordinates, and a time histogram. We visualize the uncertainty introduced by the representation, discuss a level-of-detail mechanism, and explicitly visualize outliers. Furthermore, we propose a spatial visualization by splatting anisotropic 3D Gaussians for which we derive a closed-form solution. Lastly, we describe the application of brushing and linking to this clustered representation. Our evaluation on several large, real-world datasets demonstrates the scaling of our approach.","keywords":"interactive visual analysis, probabilistic data summaries, multivariate data, scattered data, Gaussian mixture models,Gaussian rendering","caption":"Fig. 1: Our probabilistic summary of a cosmological dataset represents 2.6 billion particles partitioned into 5.3 million clusters. We model each cluster using combinations of low-dimensional Gaussian mixture models. This allows us to interactively visualize the position of particles by splatting 3D Gaussians (a) and to create density-based 1D and 2D plots, depicted in (b) and (c). A density-based parallel coordinate plot is shown in (d). All of those views support interactive navigation and exploration by brushing (red) and linking. We render this massive dataset in 28 ms on an NVIDIA GTX 1080 Ti at a resolution of 1920 \xd7 1080. ","img_size":{"width":1831,"height":919},"subfigures":[{"x":14.144256035596323,"y":12.219007560997694,"width":1805.3713001454414,"height":898.5509803820826,"type":"interface","id":"interface-0"}],"visualizations":[{"x":1356.1974593505045,"y":12.681080566220285,"width":426.79987581724356,"height":262.344128463021,"type":"area_chart","id":"area_chart-0"},{"x":1357.6276906736873,"y":307.8348533698063,"width":417.4791919633789,"height":250.04974992701128,"type":"others","id":"others-2"},{"x":1055.4699744907994,"y":592.5397844505795,"width":753.6954442180082,"height":303.860788574038,"type":"parallel_coordinate","id":"parallel_coordinate-1"},{"x":25.560130708404483,"y":21.95285087245444,"width":1789.570070394439,"height":876.7088601742837,"type":"scatterplot","id":"scatterplot-3"}],"relations":[{"vislist":[{"vislist":["area_chart-0","others-2","parallel_coordinate-1"],"relation":null,"id":"group-0"},{"vislist":["scatterplot-3"],"relation":null,"id":"group-1"}],"relation":"large_view","id":"relation-0"}]},"1526_1":{"comp":[["scatterplot","others",["large_view"]]],"visType":["scatterplot","others"],"compType":["large_view"],"compressed_tree":[{"composite_pattern":"large_view","visualization_type":[["scatterplot"],["others"]]}],"coOccurrence":[["scatterplot","others",["coOccurrence"]]],"year":2006,"conference":["Vis"],"authors":["Yinggang Li","Chi-Wing Fu","Andrew J. Hanson"],"title":"Scalable WIM: Effective Exploration in Large-scale Astrophysical Environments","doi":"10.1109/TVCG.2006.176","abstract":"Navigating through large-scale virtual environments such as simulations of the astrophysical Universe is difficult. The huge spatial range of astronomical models and the dominance of empty space make it hard for users to travel across cosmological scales effectively, and the problem of wayfinding further impedes the user\'s ability to acquire reliable spatial knowledge of astronomical contexts. We introduce a new technique called the scalable world-in-miniature (WIM) map as a unifying interface to facilitate travel and wayfinding in a virtual environment spanning gigantic spatial scales: power-law spatial seating enables rapid and accurate transitions among widely separated regions; logarithmically mapped miniature spaces offer a global overview mode when the full context is too large; 3D landmarks represented in the WIM are enhanced by scale, positional, and directional cues to augment spatial context awareness; a series of navigation models are incorporated into the scalable WIM to improve the performance of travel tasks posed by the unique characteristics of virtual cosmic exploration. The scalable WIM user interface supports an improved physical navigation experience and assists pragmatic cognitive understanding of a visualization context that incorporates the features of large-scale astronomy","keywords":"Astrophysical visualization, large-scale exploration, interaction techniques, world-in-miniature (WIM)","caption":"Fig. 2. (a) First person view from our star exploration application. The lack of context cues limits knowledge acquisition in the first person view. (b) Scalable WIM interface enriched with landmarks and cues for scale, position, and orientation. Comparison of the two views reveals the common local context: the brightest star near the right edge is Sirius, and the dark bulge at the center is the Galactic Center (which the camera icon points to). ","img_size":{"width":2131,"height":933},"subfigures":[{"x":4.281406364317937,"y":13.729861287457034,"width":1108.625283656626,"height":866.8375896077366,"type":"interface","id":"interface-0"},{"x":1123.0468277452405,"y":13.69880579992497,"width":1005.5167540012338,"height":862.2553780447181,"type":"single","id":"single-1"}],"visualizations":[{"x":1137.2579984929644,"y":23.182112668210475,"width":984.2883224988263,"height":852.8345954622112,"type":"others","id":"others-1"},{"x":1154.2399878744839,"y":813.6035243928918,"width":961.6023869306406,"height":54.24809446955357,"type":"scatterplot","id":"scatterplot-0"}],"relations":[{"vislist":[{"vislist":["scatterplot-0"],"relation":null,"id":"group-0"},{"vislist":["others-1"],"relation":null,"id":"group-1"}],"relation":"large_view","id":"relation-0"}]},"2597_8":{"comp":[["bar_chart","scatterplot",["large_view"]]],"visType":["bar_chart","scatterplot"],"compType":["large_view"],"compressed_tree":[{"composite_pattern":"large_view","visualization_type":[["bar_chart"],["scatterplot"]]}],"coOccurrence":[["bar_chart","scatterplot",["coOccurrence"]]],"year":2015,"conference":["InfoVis"],"authors":["Roeland Scheepens","Christophe Hurter","Huub van de Wetering","Jarke J. van Wijk"],"title":"Visualization, Selection, and Analysis of Traffic Flows","doi":"10.1109/TVCG.2015.2467112","abstract":"Visualization of the trajectories of moving objects leads to dense and cluttered images, which hinders exploration and understanding. It also hinders adding additional visual information, such as direction, and makes it difficult to interactively extract traffic flows, i.e., subsets of trajectories. In this paper we present our approach to visualize traffic flows and provide interaction tools to support their exploration. We show an overview of the traffic using a density map. The directions of traffic flows are visualized using a particle system on top of the density map. The user can extract traffic flows using a novel selection widget that allows for the intuitive selection of an area, and filtering on a range of directions and any additional attributes. Using simple, visual set expressions, the user can construct more complicated selections. The dynamic behaviors of selected flows may then be shown in annotation windows in which they can be interactively explored and compared. We validate our approach through use cases where we explore and analyze the temporal behavior of aircraft and vessel trajectories, e.g., landing and takeoff sequences, or the evolution of flight route density. The aircraft use cases have been developed and validated in collaboration with domain experts.","keywords":"Moving Object Visualization, traffic flows, interaction","caption":"Fig. 10. (a) An overview of traffic flows over the Paris area. Outgoing traffic flows have been marked with the green arrows, while incoming traffic flows have been marked with a red arrow. (b) The traffic flows have been bundled, selected, and the dynamics of these traffic flows are displayed using the movable windows.","img_size":{"width":2130,"height":1038},"subfigures":[{"x":21.117978030856776,"y":13.988698407858376,"width":1060.5041820518468,"height":988.3648097760929,"type":"interface","id":"interface-0"},{"x":1093.373184953378,"y":20.095656103320703,"width":1026.2083037687087,"height":976.1508943851672,"type":"interface","id":"interface-1"}],"visualizations":[{"x":1297.8118161925604,"y":168.0787746170678,"width":115.83807439824933,"height":81.76805251641133,"type":"bar_chart","id":"bar_chart-0"},{"x":1604.4420131291033,"y":111.29540481400433,"width":109.0240700218817,"height":79.49671772428883,"type":"bar_chart","id":"bar_chart-1"},{"x":1929.2428884026262,"y":104.48140043763672,"width":104.48140043763674,"height":74.95404814004377,"type":"bar_chart","id":"bar_chart-2"},{"x":1241.028446389497,"y":524.678336980306,"width":111.29540481400433,"height":72.68271334792121,"type":"bar_chart","id":"bar_chart-3"},{"x":2015.5536105032825,"y":399.7549234135667,"width":113.56673960612697,"height":74.95404814004377,"type":"bar_chart","id":"bar_chart-4"},{"x":1363.6805251641138,"y":826.7658643326039,"width":109.0240700218817,"height":74.95404814004382,"type":"bar_chart","id":"bar_chart-5"},{"x":1606.7133479212252,"y":860.8358862144421,"width":113.56673960612697,"height":74.95404814004371,"type":"bar_chart","id":"bar_chart-6"},{"x":1954.2275711159737,"y":792.6958424507656,"width":95.39606126914691,"height":72.68271334792132,"type":"bar_chart","id":"bar_chart-7"},{"x":3.1509846827133434,"y":6.814004376367613,"width":1081.1553610503283,"height":997.1159737417939,"type":"scatterplot","id":"scatterplot-8"},{"x":1084.3063457330418,"y":6.814004376367613,"width":1040.2713347921228,"height":983.4879649890588,"type":"scatterplot","id":"scatterplot-9"}],"relations":[{"vislist":[{"vislist":["bar_chart-0","bar_chart-1","bar_chart-2","bar_chart-3","bar_chart-4","bar_chart-5","bar_chart-6","bar_chart-7"],"relation":null,"id":"group-1"},{"vislist":["scatterplot-9"],"relation":null,"id":"group-0"}],"relation":"large_view","id":"relation-0"}]},"2597_9":{"comp":[["bar_chart","scatterplot",["large_view"]]],"visType":["bar_chart","scatterplot"],"compType":["large_view"],"compressed_tree":[{"composite_pattern":"large_view","visualization_type":[["bar_chart"],["scatterplot"]]}],"coOccurrence":[],"year":2015,"conference":["InfoVis"],"authors":["Roeland Scheepens","Christophe Hurter","Huub van de Wetering","Jarke J. van Wijk"],"title":"Visualization, Selection, and Analysis of Traffic Flows","doi":"10.1109/TVCG.2015.2467112","abstract":"Visualization of the trajectories of moving objects leads to dense and cluttered images, which hinders exploration and understanding. It also hinders adding additional visual information, such as direction, and makes it difficult to interactively extract traffic flows, i.e., subsets of trajectories. In this paper we present our approach to visualize traffic flows and provide interaction tools to support their exploration. We show an overview of the traffic using a density map. The directions of traffic flows are visualized using a particle system on top of the density map. The user can extract traffic flows using a novel selection widget that allows for the intuitive selection of an area, and filtering on a range of directions and any additional attributes. Using simple, visual set expressions, the user can construct more complicated selections. The dynamic behaviors of selected flows may then be shown in annotation windows in which they can be interactively explored and compared. We validate our approach through use cases where we explore and analyze the temporal behavior of aircraft and vessel trajectories, e.g., landing and takeoff sequences, or the evolution of flight route density. The aircraft use cases have been developed and validated in collaboration with domain experts.","keywords":"Moving Object Visualization, traffic flows, interaction","caption":"Fig. 9. (a) Aircraft traffic flows over the airport of Roissy Charles de Gaulle, France. Takeoff (blue) and landing (green) sequences have been selected and their dynamics can be compared using the windows. According to our experts we can see postal aircraft taking off (1), several large departure (2) and landing (3) sequences, and a peak in both landing and take-off at the same time. (b) The view has been rotated to aircraft altitude where we can see aircraft flying east and aircraft flying west fly at alternating flight levels.","img_size":{"width":2154,"height":1240},"subfigures":[{"x":1096.562563524781,"y":14.275414202606033,"width":1036.7634126559813,"height":1211.4491715947881,"type":"interface","id":"interface-0"}],"visualizations":[{"x":541.730859997761,"y":24.888459655728404,"width":495.76700214268374,"height":424.3910714991742,"type":"bar_chart","id":"bar_chart-1"},{"x":26.85583427045083,"y":27.583543201184366,"width":494.46999828598075,"height":420.3635948160717,"type":"bar_chart","id":"bar_chart-2"},{"x":49.92430547163194,"y":748.8311604950272,"width":487.8315560210395,"height":485.00395126654007,"type":"bar_chart","id":"bar_chart-3"},{"x":10.599492627660592,"y":14.853129606073665,"width":1041.8252006041632,"height":1214.3818120112826,"type":"scatterplot","id":"scatterplot-0"}],"relations":[{"vislist":[{"vislist":["bar_chart-1","bar_chart-2","bar_chart-3"],"relation":null,"id":"group-1"},{"vislist":["scatterplot-0"],"relation":null,"id":"group-0"}],"relation":"large_view","id":"relation-0"}]},"2717_1":{"comp":[["heatmap","matrix",["large_view"]]],"visType":["heatmap","matrix"],"compType":["large_view"],"compressed_tree":[{"composite_pattern":"large_view","visualization_type":[["heatmap"],["matrix"]]}],"coOccurrence":[["heatmap","matrix",["coOccurrence"]]],"year":2015,"conference":["VAST"],"authors":["Paul Klemm","Kai Lawonn","Sylvia Gla\xdfer","Uli Niemann","Katrin Hegenscheid","Henry V\xf6lzke","Bernhard Preim"],"title":"3D Regression Heat Map Analysis of Population Study Data","doi":"10.1109/TVCG.2015.2468291","abstract":"Epidemiological studies comprise heterogeneous data about a subject group to define disease-specific risk factors. These data contain information (features) about a subject\'s lifestyle, medical status as well as medical image data. Statistical regression analysis is used to evaluate these features and to identify feature combinations indicating a disease (the target feature). We propose an analysis approach of epidemiological data sets by incorporating all features in an exhaustive regression-based analysis. This approach combines all independent features w.r.t. a target feature. It provides a visualization that reveals insights into the data by highlighting relationships. The 3D Regression Heat Map, a novel 3D visual encoding, acts as an overview of the whole data set. It shows all combinations of two to three independent features with a specific target disease. Slicing through the 3D Regression Heat Map allows for the detailed analysis of the underlying relationships. Expert knowledge about disease-specific hypotheses can be included into the analysis by adjusting the regression model formulas. Furthermore, the influences of features can be assessed using a difference view comparing different calculation results. We applied our 3D Regression Heat Map method to a hepatic steatosis data set to reproduce results from a data mining-driven analysis. A qualitative analysis was conducted on a breast density data set. We were able to derive new hypotheses about relations between breast density and breast lesions with breast cancer. With the 3D Regression Heat Map, we present a visual overview of epidemiological data that allows for the first time an interactive regression-based analysis of large feature sets with respect to a disease.","keywords":"Interactive Visual Analysis, Regression Analysis, Heat Map, Epidemiology, Breast Cancer, Hepatic Steatosis","caption":"Fig. 2. Breast density data set loaded into our prototype. (a) Using the formula input, the user specifies the dependent feature and calculation rules. (b) 3D heat map showing values above the matrix diagonal as overview. The values of the currently selected slice are mirrored and represented as orange data points on the slicing plane. (c) 2D heat map of the selected slice for feature Pain/Discomfort.","img_size":{"width":1046,"height":852},"subfigures":[{"x":7.033107594144179,"y":5.151298496122667,"width":1027.27706195307,"height":831.2236464590934,"type":"interface","id":"interface-0"}],"visualizations":[{"x":28.802631578947285,"y":106.49999999999996,"width":814.6315789473686,"height":743.6315789473686,"type":"heatmap","id":"heatmap-0"},{"x":652.8552631578948,"y":112.10526315789471,"width":334.4473684210527,"height":392.3684210526316,"type":"heatmap","id":"heatmap-1"},{"x":30.671052631578846,"y":106.49999999999996,"width":810.8947368421053,"height":745.5,"type":"matrix","id":"matrix-2"}],"relations":[{"vislist":[{"vislist":["heatmap-1"],"relation":null,"id":"group-1"},{"vislist":["matrix-2"],"relation":null,"id":"group-0"}],"relation":"large_view","id":"relation-0"}]},"2731_0":{"comp":[["parallel_coordinate","map",["large_view"]],["parallel_coordinate","table",["stacked"]],["table","parallel_coordinate",["stacked"]]],"visType":["parallel_coordinate","map","table"],"compType":["large_view","stacked"],"compressed_tree":[{"composite_pattern":"large_view","visualization_type":[["parallel_coordinate"],["map"]]},{"composite_pattern":"stacked","visualization_type":[["table","parallel_coordinate"]]}],"coOccurrence":[["parallel_coordinate","map",["coOccurrence"]],["parallel_coordinate","table",["coOccurrence"]],["map","table",["coOccurrence"]]],"year":2015,"conference":["VAST"],"authors":["Nivan Ferreira","Marcos Lage","Harish Doraiswamy","Huy T. Vo","Luc Wilson","Heidi Werner","Muchan Park","Cl\xe1udio T. Silva"],"title":"Urbane: A 3D framework to support data driven decision making in urban development","doi":"10.1109/VAST.2015.7347636","abstract":"Architects working with developers and city planners typically rely on experience, precedent and data analyzed in isolation when making decisions that impact the character of a city. These decisions are critical in enabling vibrant, sustainable environments but must also negotiate a range of complex political and social forces. This requires those shaping the built environment to balance maximizing the value of a new development with its impact on the character of a neighborhood. As a result architects are focused on two issues throughout the decision making process: a) what defines the character of a neighborhood? and b) how will a new development change its neighborhood? In the first, character can be influenced by a variety of factors and understanding the interplay between diverse data sets is crucial; including safety, transportation access, school quality and access to entertainment. In the second, the impact of a new development is measured, for example, by how it impacts the view from the buildings that surround it. In this paper, we work in collaboration with architects to design Urbane, a 3-dimensional multi-resolution framework that enables a data-driven approach for decision making in the design of new urban development. This is accomplished by integrating multiple data layers and impact analysis techniques facilitating architects to explore and assess the effect of these attributes on the character and value of a neighborhood. Several of these data layers, as well as impact analysis, involve working in 3-dimensions and operating in real time. Efficient computation and visualization is accomplished through the use of techniques from computer graphics. We demonstrate the effectiveness of Urbane through a case study of development in Manhattan depicting how a data-driven understanding of the value and impact of speculative buildings can benefit the design-development process between architects, planners and developers.","keywords":"","caption":"Figure 1: Urbane provides architects, developers, and planners with a new, data and analysis rich way of reading the city with the goal of improving decision making in urban development. Users can explore properties of neighborhoods and buildings using the data exploration view to identify underdeveloped sites for potential development. Then, using the visual interface together with the map view, they can simulate the impact of such development. For example, the views of the freedom tower (highlighted in green) from the buildings highlighted in red would be adversely impacted (positively impacted buildings are highlighted in blue) if the new constructions (colored yellow) are built. The supplemental video shows the different features and visualizations supported by Urbane.","img_size":{"width":1556,"height":841},"subfigures":[{"x":882.1779948711253,"y":361.4166535615306,"width":651.3173784537138,"height":458.18952284530013,"type":"interface","id":"interface-1"},{"x":23.701687022420614,"y":15.637907900904636,"width":1428.145909680134,"height":655.7949300908911,"type":"single","id":"single-0"}],"visualizations":[{"x":15.1166007905139,"y":8.310276679841943,"width":1392.802371541502,"height":666.4841897233202,"type":"map","id":"map-0"},{"x":884.371541501976,"y":407.2170984866825,"width":616.6225296442681,"height":217.04130187596786,"type":"parallel_coordinate","id":"parallel_coordinate-1"},{"x":887.6956521739123,"y":626.9944495930565,"width":641.5533596837944,"height":187.01307709847242,"type":"table","id":"table-2"}],"relations":[{"vislist":[{"vislist":["parallel_coordinate-1"],"relation":null,"id":"group-1"},{"vislist":["map-0"],"relation":null,"id":"group-0"}],"relation":"large_view","id":"relation-0"},{"vislist":[{"vislist":["table-2","parallel_coordinate-1"],"relation":null,"id":"group-3"}],"relation":"stacked","id":"relation-1"}]},"2853_0":{"comp":[["bar_chart","scatterplot",["large_view"]]],"visType":["bar_chart","scatterplot"],"compType":["large_view"],"compressed_tree":[{"composite_pattern":"large_view","visualization_type":[["bar_chart"],["scatterplot"]]}],"coOccurrence":[["bar_chart","scatterplot",["coOccurrence"]]],"year":2016,"conference":["VAST"],"authors":["Florian Heimerl","Markus John","Qi Han","Steffen Koch","Thomas Ertl"],"title":"DocuCompass: Effective exploration of document landscapes","doi":"10.1109/VAST.2016.7883507","abstract":"The creation of interactive visualization to analyze text documents has gained an impressive momentum in recent years. This is not surprising in the light of massive and still increasing amounts of available digitized texts. Websites, social media, news wire, and digital libraries are just few examples of the diverse text sources whose visual analysis and exploration offers new opportunities to effectively mine and manage the information and knowledge hidden within them. A popular visualization method for large text collections is to represent each document by a glyph in 2D space. These landscapes can be the result of optimizing pairwise distances in 2D to represent document similarities, or they are provided directly as meta data, such as geo-locations. For well-defined information needs, suitable interaction methods are available for these spatializations. However, free exploration and navigation on a level of abstraction between a labeled document spatialization and reading single documents is largely unsupported. As a result, vital foraging steps for task-tailored actions, such as selecting subgroups of documents for detailed inspection, or subsequent sense-making steps are hampered. To fill in this gap, we propose DocuCompass, a focus+context approach based on the lens metaphor. It comprises multiple methods to characterize local groups of documents, and to efficiently guide exploration based on users\' requirements. DocuCompass thus allows for effective interactive exploration of document landscapes without disrupting the mental map of users by changing the layout itself. We discuss the suitability of multiple navigation and characterization methods for different spatializations and texts. Finally, we provide insights generated through user feedback and discuss the effectiveness of our approach.","keywords":"","caption":"Figure 1: DocuCompass comprises lenses with different features: (A) a lens showing terms as text labels for characterizing focused docu- ments, (B) a lens depicting previews of term distributions over the display, (C) a lens with the term \u2018scalar\u2019 selected, (D) a lens using a bar chart to depict the distribution of publication years.","img_size":{"width":2118,"height":812},"subfigures":[{"x":14.819143131837604,"y":15.85568953737462,"width":2086.8233515640595,"height":787.9816325426169,"type":"single","id":"single-0"}],"visualizations":[{"x":1674.266416510319,"y":605.3489681050655,"width":219.87992495309575,"height":174.84427767354603,"type":"bar_chart","id":"bar_chart-0"},{"x":5.298311444652907,"y":4.669888698781155,"width":2108.031799856566,"height":802.6602226024377,"type":"scatterplot","id":"scatterplot-1"}],"relations":[{"vislist":[{"vislist":["bar_chart-0"],"relation":null,"id":"group-0"},{"vislist":["scatterplot-1"],"relation":null,"id":"group-1"}],"relation":"large_view","id":"relation-0"}]},"2891_0":{"comp":[["table","scivis",["large_view"]]],"visType":["table","scivis"],"compType":["large_view"],"compressed_tree":[{"composite_pattern":"large_view","visualization_type":[["table"],["scivis"]]}],"coOccurrence":[["table","scivis",["coOccurrence"]]],"year":2017,"conference":["InfoVis"],"authors":["Paulo Ivson","Daniel Nascimento","Waldemar Celes Filho","Simone D. J. Barbosa"],"title":"CasCADe: A Novel 4D Visualization System for Virtual Construction Planning","doi":"10.1109/TVCG.2017.2745105","abstract":"Building Information Modeling (BIM) provides an integrated 3D environment to manage large-scale engineering projects. The Architecture, Engineering and Construction (AEC) industry explores 4D visualizations over these datasets for virtual construction planning. However, existing solutions lack adequate visual mechanisms to inspect the underlying schedule and make inconsistencies readily apparent. The goal of this paper is to apply best practices of information visualization to improve 4D analysis of construction plans. We first present a review of previous work that identifies common use cases and limitations. We then consulted with AEC professionals to specify the main design requirements for such applications. These guided the development of CasCADe, a novel 4D visualization system where task sequencing and spatio-temporal simultaneity are immediately apparent. This unique framework enables the combination of diverse analytical features to create an information-rich analysis environment. We also describe how engineering collaborators used CasCADe to review the real-world construction plans of an Oil &amp;amp; Gas process plant. The system made evident schedule uncertainties, identified work-space conflicts and helped analyze other constructability issues. The results and contributions of this paper suggest new avenues for future research in information visualization for the AEC industry.","keywords":"Visualization in physical sciences and engineering,design studies,integrating spatial and non-spatial data visualization,task and requirements analysis","caption":"Fig. 1: CasCADe\u2019s unique 4D visualization combines the intuitive task sequencing from PERT/Gantt charts with the spatial awareness conveyed by 3D CAD models to bring forth problems and inconsistencies in engineering construction schedules.","img_size":{"width":1927,"height":997},"subfigures":[{"x":10.70924561668806,"y":7.865034245800398,"width":1906.9811423388392,"height":981.2699315083994,"type":"interface","id":"interface-0"}],"visualizations":[{"x":69.41142020497801,"y":81.74524158125917,"width":205.8228404099561,"height":458.3572474377745,"type":"table","id":"table-0"},{"x":69.41142020497801,"y":569.2972181551977,"width":216.04099560761347,"height":380.9912152269399,"type":"table","id":"table-1"},{"x":10.146542860189452,"y":8.620737164913196,"width":1900.8586593479092,"height":973.9110183387969,"type":"scivis","id":"scivis-2"}],"relations":[{"vislist":[{"vislist":["table-1","table-0"],"relation":null,"id":"group-0"},{"id":"group-0","relation":null,"vislist":["scivis-2"]}],"relation":"large_view","id":"relation-0"}]},"1886_0":{"comp":[["others","others",["large_view"]]],"visType":["others"],"compType":["large_view"],"compressed_tree":[{"composite_pattern":"large_view","visualization_type":[["others"],["others"]]}],"coOccurrence":[["others","others",["coOccurrence"]]],"year":2009,"conference":["VAST"],"authors":["Claudia M\xfcller-Birn","Lukas Birn"],"title":"Combining iterative analytical reasoning and software development using the visualization language Processing","doi":"10.1109/VAST.2009.5334463","abstract":"Processing is a very powerful visualization language which combines software concepts with principles of visual form and interaction. Artists, designers and architects use it but it is also a very effective programming language in the area of visual analytics. In the following contribution Processing is utilized in order to visually analyze data provided by IEEE VAST 2009 Mini Challenge Badge and Network Traffic. The applied process is iterative and each stage of the analytical reasoning process is accompanied by customized software development. The visual model, the process and the technical solution will be briefly introduced.","keywords":"","caption":"Figure 1: Basic visual model of all employees with all proximity data logs and the traffic logs (monthly overview)","img_size":{"width":1013,"height":668},"subfigures":[{"x":5.93115081927866,"y":10.435350222797238,"width":1004.0860073084864,"height":655.9672235032009,"type":"single","id":"single-0"}],"visualizations":[{"x":11.010910570755705,"y":28.582133265883158,"width":986.7111007946096,"height":638.5616510727049,"type":"others","id":"others-0"},{"x":453.4488423027449,"y":245.364934431008,"width":530.676582750423,"height":343.625636764808,"type":"others","id":"others-1"}],"relations":[{"vislist":[{"vislist":["others-1"],"relation":null,"id":"group-1"},{"vislist":["others-0"],"relation":null,"id":"group-0"}],"relation":"large_view","id":"relation-0"}]},"1677_5":{"comp":[["graph","graph",["large_view"]]],"visType":["graph"],"compType":["large_view"],"compressed_tree":[{"composite_pattern":"large_view","visualization_type":[["graph"],["graph"]]}],"coOccurrence":[["graph","graph",["coOccurrence"]]],"year":2008,"conference":["InfoVis"],"authors":["Tim Dwyer","Kim Marriott","Falk Schreiber","Peter J. Stuckey","Michael Woodward","Michael Wybrow"],"title":"Exploration of Networks using overview+detail with Constraint-based cooperative layout","doi":"10.1109/TVCG.2008.130","abstract":"A standard approach to large network visualization is to provide an overview of the network and a detailed view of a small component of the graph centred around a focal node. The user explores the network by changing the focal node in the detailed view or by changing the level of detail of a node or cluster. For scalability, fast force-based layout algorithms are used for the overview and the detailed view. However, using the same layout algorithm in both views is problematic since layout for the detailed view has different requirements to that in the overview. Here we present a model in which constrained graph layout algorithms are used for layout in the detailed view. This means the detailed view has high-quality layout including sophisticated edge routing and is customisable by the user who can add placement constraints on the layout. Scalability is still ensured since the slower layout techniques are only applied to the small subgraph shown in the detailed view. The main technical innovations are techniques to ensure that the overview and detailed view remain synchronized, and modifying constrained graph layout algorithms to support smooth, stable layout. The key innovation supporting stability are new dynamic graph layout algorithms that preserve the topology or structure of the network when the user changes the focus node or the level of detail by in situ semantic zooming. We have built a prototype tool and demonstrate its use in two application domains, UML class diagrams and biological networks.","keywords":"Graph drawing, constraints, stress majorization, force directed algorithms, multidimensional scaling","caption":"Fig. 5. Navigation of a metabolic pathway network with 432 nodes and 481 edges; and \ufb01nal precise layout with placement of a detailed sub- graph.","img_size":{"width":1038,"height":2679},"subfigures":[{"x":9.796133365928805,"y":-6.125838770539223,"width":1027.2680661031627,"height":862.5619197606068,"type":"single","id":"single-0"}],"visualizations":[{"x":613.3444167794066,"y":418.36247565141235,"width":409.8870847030171,"height":409.88708470301725,"type":"graph","id":"graph-0"},{"x":607.6515406029758,"y":1327.3250384881956,"width":413.6823354873044,"height":411.78471009516056,"type":"graph","id":"graph-1"},{"x":33.32218307386635,"y":17.21392958456072,"width":986.0124148024083,"height":818.6021743289032,"type":"graph","id":"graph-2"}],"relations":[{"vislist":[{"vislist":["graph-0"],"relation":null,"id":"group-0"},{"vislist":["graph-2"],"relation":null,"id":"group-1"}],"relation":"large_view","id":"relation-0"}]},"2143_1":{"comp":[["line_chart","scatterplot",["large_view"]],["parallel_coordinate","scatterplot",["large_view"]],["scatterplot","scatterplot",["large_view"]]],"visType":["line_chart","scatterplot","parallel_coordinate"],"compType":["large_view"],"compressed_tree":[{"composite_pattern":"large_view","visualization_type":[["line_chart","parallel_coordinate","scatterplot"],["scatterplot"]]}],"coOccurrence":[["line_chart","parallel_coordinate",["coOccurrence"]],["line_chart","scatterplot",["coOccurrence"]],["parallel_coordinate","scatterplot",["coOccurrence"]]],"year":2011,"conference":["VAST"],"authors":["Ian Bowman","Shantanu H. Joshi","John D. Van Horn"],"title":"Query-based coordinated multiple views with Feature Similarity Space for visual analysis of MRI repositories","doi":"10.1109/VAST.2011.6102467","abstract":"It is a laborious process to quantify relationship patterns within a feature-rich archive. For example, understanding the degree of neuroanatomical similarity between the scanned subjects of a Magnetic Resonance Imaging (MRI) repository is a nontrivial task. In this work we present a Coordinated Multiple View (CMV) system for visually analyzing collections of feature-rich datasets. A query-based user interface operates on a feature-respective data scheme, and is geared towards domain experts that are non-specialists in informatics and analytics. We employ multi-dimensional scaling (MDS) to project feature surface representations into three-dimensions, where proximity in location is proportional to the feature similarity. Through query feedback and environment navigation, the user groups clusters that exhibit probable trends across feature and attribute. The system provides supervised classification methods for determining attribute classes within the user selected groups. Finally, using visual or analytical feature-wise exploration the user determines intra-group feature commonality.","keywords":"","caption":"Figure 1: (a) Within Feature Similarity Space, MRI surface data is viewable at multiple zoom levels. The right half image demonstrates the zoom-determined multi-resolution approach employed to maintain interactive frame rates. (b) Interactive grouping allows the user to label and color data members by feature similarity or subject metadata values. (c) Exploratory clustering and classification quantifies the feature and attribute distributions of the user-selected groups.","img_size":{"width":1890,"height":582},"subfigures":[{"x":1210.215203933984,"y":3.633701011903541,"width":674.290083885468,"height":475.39688074947315,"type":"interface","id":"interface-0"}],"visualizations":[{"x":1669.8726016321202,"y":319.39149250465107,"width":212.61771218225138,"height":127.44054940070502,"type":"line_chart","id":"line_chart-1"},{"x":1486.456558376279,"y":29.363303141826467,"width":219.72928284246674,"height":102.19102935061686,"type":"parallel_coordinate","id":"parallel_coordinate-0"},{"x":1251.9280955749325,"y":260.3188198698312,"width":111.56026440442768,"height":127.15647969248317,"type":"scatterplot","id":"scatterplot-2"},{"x":1215.6773034282626,"y":12.24841885907428,"width":660.9006720357611,"height":458.21385477515895,"type":"scatterplot","id":"scatterplot-3"}],"relations":[{"vislist":[{"vislist":["line_chart-1","parallel_coordinate-0","scatterplot-2"],"relation":null,"id":"group-1"},{"vislist":["scatterplot-3"],"relation":null,"id":"group-0"}],"relation":"large_view","id":"relation-0"}]},"2584_7":{"comp":[["map","scatterplot",["large_view"]]],"visType":["map","scatterplot"],"compType":["large_view"],"compressed_tree":[{"composite_pattern":"large_view","visualization_type":[["map"],["scatterplot"]]}],"coOccurrence":[["map","scatterplot",["coOccurrence"]]],"year":2014,"conference":["VAST"],"authors":["Jie Li","Kang Zhang","Zhao-Peng Meng"],"title":"Vismate: Interactive Visual Analysis of Station-Based Observation Data on Climate Changes","doi":"10.1109/VAST.2014.7042489","abstract":"We present a new approach to visualizing the climate data of multi-dimensional, time-series, and geo-related characteristics. Our approach integrates three new highly interrelated visualization techniques, and uses the same input data types as in the traditional model-based analysis methods. As the main visualization view, Global Radial Map is used to identify the overall state of climate changes and provide users with a compact and intuitive view for analyzing spatial and temporal patterns at the same time. Other two visualization techniques, providing complementary views, are specialized in analysing time trend and detecting abnormal cases, which are two important analysis tasks in any climate change study. Case studies and expert reviews have been conducted, through which the effectiveness and scalability of the proposed approach has been confirmed.","keywords":"climate changes, spatiotemporal visualization, station-based observation data, radial layout, visual analytics","caption":"Fig. 8.\\r\\nAnomaly detection scatterplot based on PCA. A hypotenuse slice is selected as the 9-dimensional vector of each station for mapping.","img_size":{"width":1029,"height":673},"subfigures":[{"x":12.21607530870524,"y":178.63234899437467,"width":1003.6487653551451,"height":477.5239712438749,"type":"interface","id":"interface-0"}],"visualizations":[{"x":42.957236842105324,"y":296.6513157894737,"width":382.2521929824563,"height":308.4583333333333,"type":"map","id":"map-3"},{"x":17.664239695691723,"y":181.26358490070473,"width":989.6695426448472,"height":467.40561846050974,"type":"scatterplot","id":"scatterplot-2"}],"relations":[{"vislist":[{"vislist":["map-3"],"relation":null,"id":"group-2"},{"vislist":["scatterplot-2"],"relation":null,"id":"group-3"}],"relation":"large_view","id":"relation-1"}]},"2429_0":{"comp":[["bar_chart","map",["large_view"]]],"visType":["bar_chart","map"],"compType":["large_view"],"compressed_tree":[{"composite_pattern":"large_view","visualization_type":[["bar_chart"],["map"]]}],"coOccurrence":[["bar_chart","map",["coOccurrence"]]],"year":2013,"conference":["VAST"],"authors":["Bertjan Broeksema","Thomas Baudel","Arthur G. Telea","Paolo Crisafulli"],"title":"Decision Exploration Lab: A Visual Analytics Solution for Decision Management","doi":"10.1109/TVCG.2013.146","abstract":"We present a visual analytics solution designed to address prevalent issues in the area of Operational Decision Management (ODM). In ODM, which has its roots in Artificial Intelligence (Expert Systems) and Management Science, it is increasingly important to align business decisions with business goals. In our work, we consider decision models (executable models of the business domain) as ontologies that describe the business domain, and production rules that describe the business logic of decisions to be made over this ontology. Executing a decision model produces an accumulation of decisions made over time for individual cases. We are interested, first, to get insight in the decision logic and the accumulated facts by themselves. Secondly and more importantly, we want to see how the accumulated facts reveal potential divergences between the reality as captured by the decision model, and the reality as captured by the executed decisions. We illustrate the motivation, added value for visual analytics, and our proposed solution and tooling through a business case from the car insurance industry.","keywords":"Decision support systems, model validation and analysis, multivariate Statistics, program analysis","caption":"Fig. 1. Decision Exploration Lab in visual querying mode, with the DataSpace tree (A), the Decision Map (B) and the Rule Triggering view (C).","img_size":{"width":1862,"height":823},"subfigures":[{"x":7.866155814870828,"y":4.357052638546477,"width":1835.5926265645264,"height":809.4346841711566,"type":"interface","id":"interface-0"}],"visualizations":[{"x":98.09518599562372,"y":181.88840262582056,"width":201.69803063457323,"height":122.45951859956237,"type":"bar_chart","id":"bar_chart-0"},{"x":598.738512035011,"y":144.07002188183807,"width":147.67177242888397,"height":55.82713347921225,"type":"bar_chart","id":"bar_chart-1"},{"x":1070.5678336980304,"y":142.26914660831508,"width":151.27352297593006,"height":57.62800875273522,"type":"bar_chart","id":"bar_chart-2"},{"x":1070.5678336980304,"y":704.1422319474835,"width":142.26914660831517,"height":57.62800875273525,"type":"bar_chart","id":"bar_chart-3"},{"x":589.0911646305299,"y":140.3898934508191,"width":637.8998581212087,"height":632.8323381252573,"type":"map","id":"map-5"},{"x":1239.8501094091898,"y":201.69803063457329,"width":558.2713347921226,"height":203.49890590809628,"type":"table","id":"table-4"}],"relations":[{"vislist":[{"vislist":["bar_chart-1","bar_chart-2","bar_chart-3"],"relation":null,"id":"group-1"},{"vislist":["map-5"],"relation":null,"id":"group-0"}],"relation":"large_view","id":"relation-0"}]},"1433_0":{"comp":[["proportional_area_chart","comb",["large_view"]],["matrix","comb",["large_view"]],["matrix","bar_chart",["stacked"]],["graph","graph",["large_view"]],["bar_chart","matrix",["stacked"]]],"visType":["proportional_area_chart","comb","matrix","bar_chart","graph"],"compType":["large_view","stacked"],"compressed_tree":[{"composite_pattern":"large_view","visualization_type":[["proportional_area_chart","matrix"],[{"composite_pattern":"stacked","visualization_type":[["matrix","bar_chart"]]}]]},{"composite_pattern":"large_view","visualization_type":[["graph"],["graph"]]}],"coOccurrence":[["graph","graph",["coOccurrence"]]],"year":2006,"conference":["InfoVis"],"authors":["Nathalie Henry Riche","Jean-Daniel Fekete"],"title":"MatrixExplorer: a Dual-Representation System to Explore Social Networks","doi":"10.1109/TVCG.2006.160","abstract":"MatrixExplorer is a network visualization system that uses two representations: node-link diagrams and matrices. Its design comes from a list of requirements formalized after several interviews and a participatory design session conducted with social science researchers. Although matrices are commonly used in social networks analysis, very few systems support the matrix-based representations to visualize and analyze networks. MatrixExplorer provides several novel features to support the exploration of social networks with a matrix-based representation, in addition to the standard interactive filtering and clustering functions. It provides tools to reorder (layout) matrices, to annotate and compare findings across different layouts and find consensus among several clusterings. MatrixExplorer also supports node-link diagram views which are familiar to most users and remain a convenient way to publish or communicate exploration results. Matrix and node-link representations are kept synchronized at all stages of the exploration process","keywords":"social networks visualization, node-link diagrams, matrix-based representations, exploratory process, matrix ordering, interactive clustering, consensus","caption":"Fig. 1. MatrixExplorer showing two synchronized representations of the same network: matrix on the left and node-link on the right.","img_size":{"width":2145,"height":849},"subfigures":[{"x":6.860053310199536,"y":9.92961718061004,"width":992.1636652981844,"height":835.1757687769893,"type":"interface","id":"interface-0"},{"x":1000.859875490286,"y":12.478713412575646,"width":1136.225872138088,"height":832.4022669497534,"type":"interface","id":"interface-1"}],"visualizations":[{"x":105.65937822733753,"y":70.56892075405008,"width":664.7951880114958,"height":89.05803142560708,"type":"bar_chart","id":"bar_chart-0"},{"x":14.157888148999405,"y":159.25621068493217,"width":92.42724167044469,"height":333.9306795835423,"type":"bar_chart","id":"bar_chart-1"},{"x":1001.2071621374583,"y":72.5827728213722,"width":841.1074651353566,"height":751.3658736669398,"type":"graph","id":"graph-2"},{"x":1514.3500792341829,"y":344.42432852492936,"width":234.48527621740664,"height":269.9282168485602,"type":"graph","id":"graph-8"},{"x":101.36415639002428,"y":160.8343144676694,"width":671.6313386136878,"height":663.6391377416363,"type":"matrix","id":"matrix-3"},{"x":531.8413456314277,"y":170.62145207977292,"width":239.3671929415977,"height":267.38359609736506,"type":"matrix","id":"matrix-6"},{"x":10.81772334293948,"y":518.7687319884726,"width":347.7125360230548,"height":321.4409221902019,"type":"proportional_area_chart","id":"proportional_area_chart-4"}],"relations":[{"vislist":[{"vislist":["proportional_area_chart-4","matrix-6"],"relation":null,"id":"group-1"},{"vislist":[{"vislist":[{"vislist":["matrix-3","bar_chart-0","bar_chart-1"],"relation":null,"id":"group-0"}],"relation":"stacked","id":"relation-0"}],"relation":null,"id":"group-2"}],"relation":"large_view","id":"relation-1"},{"vislist":[{"vislist":["graph-8"],"relation":null,"id":"group-3"},{"vislist":["graph-2"],"relation":null,"id":"group-4"}],"relation":"large_view","id":"relation-2"}]},"1800_3":{"comp":[["bar_chart","scatterplot",["large_view"]]],"visType":["bar_chart","scatterplot"],"compType":["large_view"],"compressed_tree":[{"composite_pattern":"large_view","visualization_type":[["bar_chart"],["scatterplot"]]}],"coOccurrence":[["bar_chart","scatterplot",["coOccurrence"]]],"year":2009,"conference":["InfoVis"],"authors":["Michael Ogawa","Kwan-Liu Ma"],"title":"code_swarm: A Design Study in Organic Software Visualization","doi":"10.1109/TVCG.2009.123","abstract":"In May of 2008, we published online a series of software visualization videos using a method called code_swarm. Shortly thereafter, we made the code open source and its popularity took off. This paper is a study of our code swarm application, comprising its design, results and public response. We share our design methodology, including why we chose the organic information visualization technique, how we designed for both developers and a casual audience, and what lessons we learned from our experiment. We validate the results produced by code_swarm through a qualitative analysis and by gathering online user comments. Furthermore, we successfully released the code as open source, and the software community used it to visualize their own projects and shared their results as well. In the end, we believe code_swarm has positive implications for the future of organic information design and open source information visualization practice.","keywords":"Software visualization, organic information visualization, software development history and evolution","caption":"Fig. 3. Frame from the Eclipse code swarm video. January, 2001. There are many developers working on many \ufb01les. Red \ufb01les are source code, teal \ufb01les are images. The histogram shows periodic weekend breaks and a longer break a few weeks earlier. http://www.vimeo.com/1130828","img_size":{"width":1047,"height":786},"subfigures":[{"x":12.181827584730934,"y":4.149187854581249,"width":1025.6974094382826,"height":772.6014168628562,"type":"single","id":"single-0"}],"visualizations":[{"x":6.589411764705915,"y":3.698823529411764,"width":1038.235857171502,"height":780.126445406796,"type":"bar_chart","id":"bar_chart-0"},{"x":7.391566265060192,"y":5.261044176706827,"width":1031.1646586345382,"height":774.425702811245,"type":"scatterplot","id":"scatterplot-1"}],"relations":[{"vislist":[{"vislist":["bar_chart-0"],"relation":null,"id":"group-0"},{"vislist":["scatterplot-1"],"relation":null,"id":"group-1"}],"relation":"large_view","id":"relation-0"}]},"2922_5":{"comp":[["scatterplot","scivis",["large_view"]]],"visType":["scatterplot","scivis"],"compType":["large_view"],"compressed_tree":[{"composite_pattern":"large_view","visualization_type":[["scatterplot"],["scivis"]]}],"coOccurrence":[["scatterplot","scivis",["coOccurrence"]]],"year":2017,"conference":["SciVis"],"authors":["Haneen Mohammed","Ali K. Al-Awami","Johanna Beyer","Corrado Cal\xec","Pierre J. Magistretti","Hanspeter Pfister","Markus Hadwiger"],"title":"Abstractocyte: A Visual Tool for Exploring Nanoscale Astroglial Cells","doi":"10.1109/TVCG.2017.2744278","abstract":"This paper presents Abstractocyte, a system for the visual analysis of astrocytes and their relation to neurons, in nanoscale volumes of brain tissue. Astrocytes are glial cells, i.e., non-neuronal cells that support neurons and the nervous system. The study of astrocytes has immense potential for understanding brain function. However, their complex and widely-branching structure requires high-resolution electron microscopy imaging and makes visualization and analysis challenging. Furthermore, the structure and function of astrocytes is very different from neurons, and therefore requires the development of new visualization and analysis tools. With Abstractocyte, biologists can explore the morphology of astrocytes using various visual abstraction levels, while simultaneously analyzing neighboring neurons and their connectivity. We define a novel, conceptual 2D abstraction space for jointly visualizing astrocytes and neurons. Neuroscientists can choose a specific joint visualization as a point in this space. Interactively moving this point allows them to smoothly transition between different abstraction levels in an intuitive manner. In contrast to simply switching between different visualizations, this preserves the visual context and correlations throughout the transition. Users can smoothly navigate from concrete, highly-detailed 3D views to simplified and abstracted 2D views. In addition to investigating astrocytes, neurons, and their relationships, we enable the interactive analysis of the distribution of glycogen, which is of high importance to neuroscientists. We describe the design of Abstractocyte, and present three case studies in which neuroscientists have successfully used our system to assess astrocytic coverage of synapses, glycogen distribution in relation to synapses, and astrocytic-mitochondria coverage.","keywords":"Connectomics,Neuroscience,Data Abstraction,Interactive 3D Visualization","caption":"Fig. 6. Abstractocyte user interface. The filtering and analysis panel is displayed on the left. It allows users to interactively filter, select, and sort the data. The abstraction space panel is shown at the bottom right. ","img_size":{"width":1044,"height":766},"subfigures":[{"x":4.813056826955484,"y":3.5518111774462344,"width":1034.3738863460896,"height":757.2659421403467,"type":"interface","id":"interface-0"}],"visualizations":[{"x":789.0649428709416,"y":463.81629455831956,"width":240.4453403494588,"height":273.8470426457742,"type":"scatterplot","id":"scatterplot-1"},{"x":383.9098279141012,"y":41.2702651435594,"width":641.0696199750793,"height":629.6550980557491,"type":"scivis","id":"scivis-0"}],"relations":[{"vislist":[{"vislist":["scatterplot-1"],"relation":null,"id":"group-2"},{"vislist":["scivis-0"],"relation":null,"id":"group-1"}],"relation":"large_view","id":"relation-0"}]},"1755_1":{"comp":[["others","map",["large_view"]]],"visType":["others","map"],"compType":["large_view"],"compressed_tree":[{"composite_pattern":"large_view","visualization_type":[["others"],["map"]]}],"coOccurrence":[["others","map",["coOccurrence"]]],"year":2008,"conference":["Vis"],"authors":["Yi Wang","Doug A. Bowman","David M. Krum","Enylton Machado Coelho","Tonya L. Smith-Jackson","David Bailey","Sarah Peck","Swethan Anand","Trevor Kennedy","Yernar Abdrazakov"],"title":"Effects of Video Placement and Spatial Context Presentation on Path Reconstruction Tasks with Contextualized Videos","doi":"10.1109/TVCG.2008.126","abstract":"Many interesting and promising prototypes for visualizing video data have been proposed, including those that combine videos with their spatial context (contextualized videos). However, relatively little work has investigated the fundamental design factors behind these prototypes in order to provide general design guidance. Focusing on real-time video data visualization, we evaluated two important design factors - video placement method and spatial context presentation method - through a user study. In addition, we evaluated the effect of spatial knowledge of the environment. Participantspsila performance was measured through path reconstruction tasks, where the participants followed a target through simulated surveillance videos and marked the target paths on the environment model. We found that embedding videos inside the model enabled realtime strategies and led to faster performance. With the help of contextualized videos, participants not familiar with the real environment achieved similar task performance to participants that worked in that environment. We discuss design implications and provide general design recommendations for traffic and security surveillance system interfaces.","keywords":"contextualized videos, design factors, user study, video placement, spatial context, tracking, path reconstruction","caption":"Fig. 1. Testbed Interface using the 2D associated design. In the 2D associated design, the camera glyphs indicated the camera\u2019s location in the building model and the short line on the camera glyph indicated where the camera was facing. The testbed provided a \u201cReplay\u201d button allowing the user to replay the video multiple times, and a \u201cConfirm\u201d button allowing the user to confirm the path of the target actor and end the session. The elapsed time since the start of the task was shown in the lower-right corner.","img_size":{"width":2104,"height":1408},"subfigures":[{"x":11.382757922687585,"y":8.607338609060358,"width":2081.234484154623,"height":1390.7853227818807,"type":"interface","id":"interface-0"}],"visualizations":[{"x":17.107550947022688,"y":18.061487881390523,"width":2069.7848981059556,"height":1364.184249474297,"type":"map","id":"map-0"},{"x":16.410598924323818,"y":25.26390870757575,"width":328.5224680078413,"height":1276.6980475742055,"type":"others","id":"others-1"},{"x":358.9835978674063,"y":27.10631169956994,"width":689.7396553027713,"height":242.18142335917435,"type":"others","id":"others-2"}],"relations":[{"vislist":[{"vislist":["others-1","others-2"],"relation":null,"id":"group-0"},{"vislist":["map-0"],"relation":null,"id":"group-1"}],"relation":"large_view","id":"relation-0"}]},"2672_0":{"comp":[["scivis","others",["large_view"]]],"visType":["scivis","others"],"compType":["large_view"],"compressed_tree":[{"composite_pattern":"large_view","visualization_type":[["scivis"],["others"]]}],"coOccurrence":[["scivis","others",["coOccurrence"]]],"year":2015,"conference":["SciVis"],"authors":["Daisuke Sakurai","Osamu Saeki","Hamish A. Carr","Hsiang-Yun Wu","Takahiro Yamamoto","David J. Duke","Shigeo Takahashi"],"title":"Interactive Visualization for Singular Fibers of Functions f : R3 -> R2","doi":"10.1109/TVCG.2015.2467433","abstract":"Scalar topology in the form of Morse theory has provided computational tools that analyze and visualize data from scientific and engineering tasks. Contracting isocontours to single points encapsulates variations in isocontour connectivity in the Reeb graph. For multivariate data, isocontours generalize to fibers-inverse images of points in the range, and this area is therefore known as fiber topology. However, fiber topology is less fully developed than Morse theory, and current efforts rely on manual visualizations. This paper presents how to accelerate and semi-automate this task through an interface for visualizing fiber singularities of multivariate functions R<sup>3</sup>\u2192R<sup>2</sup>. This interface exploits existing conventions of fiber topology, but also introduces a 3D view based on the extension of Reeb graphs to Reeb spaces. Using the Joint Contour Net, a quantized approximation of the Reeb space, this accelerates topological visualization and permits online perturbation to reduce or remove degeneracies in functions under study. Validation of the interface is performed by assessing whether the interface supports the mathematical workflow both of experts and of less experienced mathematicians.","keywords":"Singular fibers, fiber topology, mathematical visualization, design study","caption":"Fig. 1. Singular fibers of the tangle cube function f (x, y, z) = (\u2212x4 \u2212 y4 \u2212 z4 + 5(x2 + y2 + z2 ) \u2212 10, z) after interactive perturbation. The domain view on the left visualizes isosurfaces of individual axis function in yellow and green with their intersection along the current fiber in red. In the center, the range view shows a cross mark at the function value defining the current fiber. Critical function values are shown in different colors according to the topological types of their fibers. Arranged around this view are thumbnails of the domain space that pop up when a value is selected. The Reeb space view shows the connectivity of connected components in the fiber, constructed by using a 3D layout of the Joint Contour Net. ","img_size":{"width":1516,"height":918},"subfigures":[{"x":6.335133857828002,"y":5.228778092998788,"width":1505.2832586795232,"height":906.5654596146743,"type":"interface","id":"interface-0"}],"visualizations":[{"x":1005.8571235356519,"y":35.60396507765814,"width":497.6539248780353,"height":495.077758086448,"type":"others","id":"others-0"},{"x":514.6267990886971,"y":40.47046530310704,"width":495.53727060092007,"height":494.13761542950687,"type":"others","id":"others-1"},{"x":901.5461206762044,"y":684.8883340572273,"width":588.0875836885042,"height":170.74604900892538,"type":"others","id":"others-3"},{"x":18.569579073265533,"y":36.56939341527963,"width":492.3300122872626,"height":493.1469014112061,"type":"scivis","id":"scivis-2"},{"x":509.03449335225685,"y":37.659197898977474,"width":92.57428629550988,"height":88.44980232049727,"type":"scivis","id":"scivis-4"},{"x":913.2345346667041,"y":444.14847253364576,"width":95.86442086415785,"height":90.27607529107166,"type":"scivis","id":"scivis-5"},{"x":507.0840618011242,"y":441.26847030616784,"width":92.56809660741445,"height":94.08211134736949,"type":"scivis","id":"scivis-6"}],"relations":[{"vislist":[{"vislist":["scivis-4","scivis-5","scivis-6"],"relation":null,"id":"group-1"},{"vislist":["others-1"],"relation":null,"id":"group-0"}],"relation":"large_view","id":"relation-0"}]},"2513_0":{"comp":[["scivis","scivis",["large_view"]]],"visType":["scivis"],"compType":["large_view"],"compressed_tree":[{"composite_pattern":"large_view","visualization_type":[["scivis"],["scivis"]]}],"coOccurrence":[["scivis","scivis",["coOccurrence"]]],"year":2014,"conference":["SciVis"],"authors":["Daniel Haehn","Seymour Knowles-Barley","Mike Roberts","Johanna Beyer","Narayanan Kasthuri","Jeff Lichtman","Hanspeter Pfister"],"title":"Design and Evaluation of Interactive Proofreading Tools for Connectomics","doi":"10.1109/TVCG.2014.2346371","abstract":"Proofreading refers to the manual correction of automatic segmentations of image data. In connectomics, electron microscopy data is acquired at nanometer-scale resolution and results in very large image volumes of brain tissue that require fully automatic segmentation algorithms to identify cell boundaries. However, these algorithms require hundreds of corrections per cubic micron of tissue. Even though this task is time consuming, it is fairly easy for humans to perform corrections through splitting, merging, and adjusting segments during proofreading. In this paper we present the design and implementation of Mojo, a fully-featured single-user desktop application for proofreading, and Dojo, a multi-user web-based application for collaborative proofreading. We evaluate the accuracy and speed of Mojo, Dojo, and Raveler, a proofreading tool from Janelia Farm, through a quantitative user study. We designed a between-subjects experiment and asked non-experts to proofread neurons in a publicly available connectomics dataset. Our results show a significant improvement of corrections using web-based Dojo, when given the same amount of time. In addition, all participants using Dojo reported better usability. We discuss our findings and provide an analysis of requirements for designing visual proofreading software.","keywords":"Proofreading, Segmentation, Connectomics, Quantitative Evaluation","caption":"Fig. 1: Proofreading with Dojo. We present a web-based application for interactive proofreading of automatic segmentations of connectome data acquired via electron microscopy.  Split, merge and adjust functionality enables multiple users to correct the labeling of neurons in a collaborative fashion. Color-coded structures can be explored in 2D and 3D.","img_size":{"width":1948,"height":546},"subfigures":[{"x":12.244320854696829,"y":8.351101583475932,"width":1929.1709041103777,"height":526.6750629205821,"type":"interface","id":"interface-0"}],"visualizations":[{"x":1230.7776051664152,"y":56.451928852831955,"width":694.3791385585215,"height":419.343532625601,"type":"scivis","id":"scivis-0"},{"x":8.388066918006256,"y":52.20479239757383,"width":1927.787353080372,"height":481.12916800246467,"type":"scivis","id":"scivis-1"}],"relations":[{"vislist":[{"vislist":["scivis-0"],"relation":null,"id":"group-0"},{"vislist":["scivis-1"],"relation":null,"id":"group-1"}],"relation":"large_view","id":"relation-0"}]},"2513_3":{"comp":[["scivis","scivis",["large_view"]]],"visType":["scivis"],"compType":["large_view"],"compressed_tree":[{"composite_pattern":"large_view","visualization_type":[["scivis"],["scivis"]]}],"coOccurrence":[["scivis","scivis",["coOccurrence"]]],"year":2014,"conference":["SciVis"],"authors":["Daniel Haehn","Seymour Knowles-Barley","Mike Roberts","Johanna Beyer","Narayanan Kasthuri","Jeff Lichtman","Hanspeter Pfister"],"title":"Design and Evaluation of Interactive Proofreading Tools for Connectomics","doi":"10.1109/TVCG.2014.2346371","abstract":"Proofreading refers to the manual correction of automatic segmentations of image data. In connectomics, electron microscopy data is acquired at nanometer-scale resolution and results in very large image volumes of brain tissue that require fully automatic segmentation algorithms to identify cell boundaries. However, these algorithms require hundreds of corrections per cubic micron of tissue. Even though this task is time consuming, it is fairly easy for humans to perform corrections through splitting, merging, and adjusting segments during proofreading. In this paper we present the design and implementation of Mojo, a fully-featured single-user desktop application for proofreading, and Dojo, a multi-user web-based application for collaborative proofreading. We evaluate the accuracy and speed of Mojo, Dojo, and Raveler, a proofreading tool from Janelia Farm, through a quantitative user study. We designed a between-subjects experiment and asked non-experts to proofread neurons in a publicly available connectomics dataset. Our results show a significant improvement of corrections using web-based Dojo, when given the same amount of time. In addition, all participants using Dojo reported better usability. We discuss our findings and provide an analysis of requirements for designing visual proofreading software.","keywords":"Proofreading, Segmentation, Connectomics, Quantitative Evaluation","caption":"Fig. 3: User interface of Raveler by Janelia Farm. The interface con- sists of the 2D slice view (center), the toolbox (right), additional tex- tual information (bottom) and a simple 3D renderer showing bounding boxes of segments (bottom left).","img_size":{"width":1033,"height":739},"subfigures":[{"x":3.7178054496512867,"y":27.551581472442408,"width":594.6392568416411,"height":525.4204865014818,"type":"interface","id":"interface-0"}],"visualizations":[{"x":4.678824138503341,"y":53.53003155342604,"width":328.30882449467975,"height":490.62344595360264,"type":"scivis","id":"scivis-0"},{"x":6.2885551287544486,"y":323.7197411002672,"width":227.19770483472013,"height":215.71714912492374,"type":"scivis","id":"scivis-1"}],"relations":[{"vislist":[{"vislist":["scivis-1"],"relation":null,"id":"group-0"},{"vislist":["scivis-0"],"relation":null,"id":"group-1"}],"relation":"large_view","id":"relation-0"}]},"2045_5":{"comp":[["heatmap","vector_graph",["large_view"]],["vector_graph","vector_graph",["large_view"]]],"visType":["heatmap","vector_graph"],"compType":["large_view"],"compressed_tree":[{"composite_pattern":"large_view","visualization_type":[["heatmap","vector_graph"],["vector_graph"]]}],"coOccurrence":[["heatmap","vector_graph",["coOccurrence"]]],"year":2010,"conference":["Vis"],"authors":["Joel Daniels II","Erik W. Anderson","Luis Gustavo Nonato","Cl\xe1udio T. Silva"],"title":"Interactive Vector field Feature Identification","doi":"10.1109/TVCG.2010.170","abstract":"We introduce a flexible technique for interactive exploration of vector field data through classification derived from user-specified feature templates. Our method is founded on the observation that, while similar features within the vector field may be spatially disparate, they share similar neighborhood characteristics. Users generate feature-based visualizations by interactively highlighting well-accepted and domain specific representative feature points. Feature exploration begins with the computation of attributes that describe the neighborhood of each sample within the input vector field. Compilation of these attributes forms a representation of the vector field samples in the attribute space. We project the attribute points onto the canonical 2D plane to enable interactive exploration of the vector field using a painting interface. The projection encodes the similarities between vector field points within the distances computed between their associated attribute points. The proposed method is performed at interactive rates for enhanced user experience and is completely flexible as showcased by the simultaneous identification of diverse feature types.","keywords":"Vector field, data clustering, feature classification, high-dimensional data, user interaction","caption":"Fig. 5. The user interface is composed of multiple windows (labeled above) that manage a set of linked views of the dataset. The main window contains the vector field visualization with the user-designed texture as well as vector glyphs. The projection window provides the 2D canvas on which the user designs the highlighting texture, manipulates the location of control points, and views the projection of the attribute points. The control point window visualizes the selected control points, and, lastly, the brush dialog allows the user to affect their painting style.","img_size":{"width":2134,"height":869},"subfigures":[{"x":527.8202454643995,"y":13.11253995559747,"width":1592.9540032650152,"height":842.7749200888045,"type":"interface","id":"interface-0"}],"visualizations":[{"x":595.8471146660349,"y":85.73233049317899,"width":435.9616768286136,"height":398.75484117296736,"type":"heatmap","id":"heatmap-2"},{"x":542.6175318529971,"y":46.53036689859834,"width":1364.9947049371488,"height":800.3678603658778,"type":"vector_graph","id":"vector_graph-0"},{"x":1586.567726493992,"y":484.1621178866261,"width":532.6017899704797,"height":361.06080806929634,"type":"vector_graph","id":"vector_graph-1"}],"relations":[{"vislist":[{"vislist":["heatmap-2","vector_graph-1"],"relation":null,"id":"group-0"},{"vislist":["vector_graph-0"],"relation":null,"id":"group-1"}],"relation":"large_view","id":"relation-0"}]},"2070_8":{"comp":[["comb","others",["large_view"]],["bar_chart","stripe_graph",["stacked"]],["stripe_graph","bar_chart",["stacked"]]],"visType":["comb","others","bar_chart","stripe_graph"],"compType":["large_view","stacked"],"compressed_tree":[{"composite_pattern":"large_view","visualization_type":[[{"composite_pattern":"stacked","visualization_type":[["bar_chart","stripe_graph"]]}],["others"]]}],"coOccurrence":[["bar_chart","stripe_graph",["coOccurrence"]],["bar_chart","others",["coOccurrence"]],["stripe_graph","others",["coOccurrence"]]],"year":2010,"conference":["Vis"],"authors":["J\xfcrgen Waser","Raphael Fuchs","Hrvoje Ribicic","Benjamin Schindler","G\xfcnter Bl\xf6schl","M. Eduard Gr\xf6ller"],"title":"World Lines","doi":"10.1109/TVCG.2010.223","abstract":"In this paper we present World Lines as a novel interactive visualization that provides complete control over multiple heterogeneous simulation runs. In many application areas, decisions can only be made by exploring alternative scenarios. The goal of the suggested approach is to support users in this decision making process. In this setting, the data domain is extended to a set of alternative worlds where only one outcome will actually happen. World Lines integrate simulation, visualization and computational steering into a single unified system that is capable of dealing with the extended solution space. World Lines represent simulation runs as causally connected tracks that share a common time axis. This setup enables users to interfere and add new information quickly. A World Line is introduced as a visual combination of user events and their effects in order to present a possible future. To quickly find the most attractive outcome, we suggest World Lines as the governing component in a system of multiple linked views and a simulation component. World Lines employ linking and brushing to enable comparative visual analysis of multiple simulations in linked views. Analysis results can be mapped to various visual variables that World Lines provide in order to highlight the most compelling solutions. To demonstrate this technique we present a flooding scenario and show the usefulness of the integrated approach to support informed decision making.","keywords":"Problem solving environment, decision making, simulation steering, parallel worlds, CFD, smoothed particle hydrodynamics","caption":"Fig. 9. Final structure of World Lines as a result of an exploration process that involved 59 simulation runs. We have identi\ufb01ed 7 stages that led to the \ufb01nal solution. The lower right corner shows a screenshot of the same World Lines in the visualization mode (embedded in the \ufb01gure only). This image analyzes the percentage of \ufb02ooded buildings using a combined current time step and frame-wise visualization of all tracks that were investigated during the re\ufb01nement stage. ","img_size":{"width":2151,"height":865},"subfigures":[{"x":15.05003629678135,"y":10.571940379000596,"width":2119.337596418457,"height":848.5453202888833,"type":"interface","id":"interface-0"}],"visualizations":[{"x":1070.6234103186464,"y":467.0970888201482,"width":199.4846897030572,"height":386.1417225985072,"type":"bar_chart","id":"bar_chart-2"},{"x":14.885421788449875,"y":85.44862114041193,"width":2111.7425809060815,"height":771.8893073433048,"type":"others","id":"others-0"},{"x":1266.3477366975103,"y":470.8887626399671,"width":851.5593438172541,"height":384.2500737118562,"type":"stripe_graph","id":"stripe_graph-1"}],"relations":[{"vislist":[{"vislist":[{"vislist":[{"vislist":["bar_chart-2","stripe_graph-1"],"relation":null,"id":"group-0"}],"relation":"stacked","id":"relation-0"}],"relation":null,"id":"group-1"},{"vislist":["others-0"],"relation":null,"id":"group-2"}],"relation":"large_view","id":"relation-1"}]},"2068_6":{"comp":[["line_chart","scivis",["large_view"]]],"visType":["line_chart","scivis"],"compType":["large_view"],"compressed_tree":[{"composite_pattern":"large_view","visualization_type":[["line_chart"],["scivis"]]}],"coOccurrence":[["line_chart","scivis",["coOccurrence"]]],"year":2010,"conference":["Vis"],"authors":["Chad Jones","Kwan-Liu Ma"],"title":"Visualizing Flow Trajectories Using Locality-based Rendering and Warped Curve Plots","doi":"10.1109/TVCG.2010.218","abstract":"In flow simulations the behavior and properties of particle trajectories often depend on the physical geometry contained in the simulated environment. Understanding the flow in and around the geometry itself is an important part of analyzing the data. Previous work has often utilized focus+context rendering techniques, with an emphasis on showing trajectories while simplifying or illustratively rendering the physical areas. Our research instead emphasizes the local relationship between particle paths and geometry by using a projected multi-field visualization technique. The correlation between a particle path and its surrounding area is calculated on-the-fly and displayed in a non-intrusive manner. In addition, we support visual exploration and comparative analysis through the use of linked information visualization, such as manipulatable curve plots and one-on-one similarity plots. Our technique is demonstrated on particle trajectories from a groundwater simulation and a computer room airflow simulation, where the flow of particles is highly influenced by the dense geometry.","keywords":"Flow visualization, Multi-field visualization, Focus+context visualization, Coordinated linked views","caption":"Fig. 7. The curve plot and spatial view shown above reveal how the air conditioners pull in warm air near the ceiling so that it can cool and recirculate it back into the room through the \ufb02oor. ","img_size":{"width":965,"height":524},"subfigures":[{"x":6.7864394134598225,"y":4.567000401274671,"width":942.8386350284865,"height":505.5614569948583,"type":"single","id":"single-0"}],"visualizations":[{"x":7.49365058102486,"y":6.421316471097882,"width":223.9478728076976,"height":294.0206121909813,"type":"line_chart","id":"line_chart-1"},{"x":12.577810339872428,"y":6.942493704157194,"width":931.332482180393,"height":500.74832904841116,"type":"scivis","id":"scivis-0"}],"relations":[{"vislist":[{"vislist":["line_chart-1"],"relation":null,"id":"group-0"},{"vislist":["scivis-0"],"relation":null,"id":"group-1"}],"relation":"large_view","id":"relation-0"}]},"2065_7":{"comp":[["surface_graph","line_chart",["large_view"]]],"visType":["surface_graph","line_chart"],"compType":["large_view"],"compressed_tree":[{"composite_pattern":"large_view","visualization_type":[["surface_graph"],["line_chart"]]}],"coOccurrence":[["surface_graph","line_chart",["coOccurrence"]]],"year":2010,"conference":["Vis"],"authors":["Samuel Gerber","Peer-Timo Bremer","Valerio Pascucci","Ross T. Whitaker"],"title":"Visual Exploration of High Dimensional Scalar Functions","doi":"10.1109/TVCG.2010.213","abstract":"An important goal of scientific data analysis is to understand the behavior of a system or process based on a sample of the system. In many instances it is possible to observe both input parameters and system outputs, and characterize the system as a high-dimensional function. Such data sets arise, for instance, in large numerical simulations, as energy landscapes in optimization problems, or in the analysis of image data relating to biological or medical parameters. This paper proposes an approach to analyze and visualizing such data sets. The proposed method combines topological and geometric techniques to provide interactive visualizations of discretely sampled high-dimensional scalar fields. The method relies on a segmentation of the parameter space using an approximate Morse-Smale complex on the cloud of point samples. For each crystal of the Morse-Smale complex, a regression of the system parameters with respect to the output yields a curve in the parameter space. The result is a simplified geometric representation of the Morse-Smale complex in the high dimensional input domain. Finally, the geometric representation is embedded in 2D, using dimension reduction, to provide a visualization platform. The geometric properties of the regression curves enable the visualization of additional information about each crystal such as local and global shape, width, length, and sampling densities. The method is illustrated on several synthetic examples of two dimensional functions. Two use cases, using data sets from the UCI machine learning repository, demonstrate the utility of the proposed approach on real data. Finally, in collaboration with domain experts the proposed method is applied to two scientific challenges. The analysis of parameters of climate simulations and their relationship to predicted global energy flux and the concentrations of chemical species in a combustion simulation and their integration with temperature.","keywords":"Morse theory, High-dimensional visualization, Morse-Smale complex","caption":"Fig. 7. Average persistence graphs showing the number of maxima vs. persistence for the sensitivity study for different number of features and different dimensions. Each curves shows the mean and standard error of 50 random instantiations. Among our experiments we manually picked the curve with lowest number of samples that showed a distinct plateau at the correct count and thus could differentiate all (positive) features. ","img_size":{"width":2169,"height":551},"subfigures":[{"x":89.45028535011915,"y":26.225765045380506,"width":685.6641824833134,"height":520.6163708738502,"type":"single","id":"single-0"}],"visualizations":[{"x":105.1351054803145,"y":49.81834499963151,"width":673.06461905442,"height":489.6183127321409,"type":"line_chart","id":"line_chart-0"},{"x":210.55581084832806,"y":97.47508005460865,"width":341.69209863230486,"height":264.23783333541337,"type":"surface_graph","id":"surface_graph-1"}],"relations":[{"vislist":[{"vislist":["surface_graph-1"],"relation":null,"id":"group-0"},{"vislist":["line_chart-0"],"relation":null,"id":"group-1"}],"relation":"large_view","id":"relation-0"}]},"2795_2":{"comp":[["tree","tree",["large_view"]]],"visType":["tree"],"compType":["large_view"],"compressed_tree":[{"composite_pattern":"large_view","visualization_type":[["tree"],["tree"]]}],"coOccurrence":[["tree","tree",["coOccurrence"]]],"year":2016,"conference":["SciVis"],"authors":["Chris Bryan","Gregory Guterman","Kwan-Liu Ma","Harris Lewin","Denis Larkin","Jaebum Kim","Jian M","Marta Farre"],"title":"Synteny Explorer: An Interactive Visualization Application for Teaching Genome Evolution","doi":"10.1109/TVCG.2016.2598789","abstract":"Rapid advances in biology demand new tools for more active research dissemination and engaged teaching. This paper presents Synteny Explorer, an interactive visualization application designed to let college students explore genome evolution of mammalian species. The tool visualizes synteny blocks: segments of homologous DNA shared between various extant species that can be traced back or reconstructed in extinct, ancestral species. We take a karyogram-based approach to create an interactive synteny visualization, leading to a more appealing and engaging design for undergraduate-level genome evolution education. For validation, we conduct three user studies: two focused studies on color and animation design choices and a larger study that performs overall system usability testing while comparing our karyogram-based designs with two more common genome mapping representations in an educational context. While existing views communicate the same information, study participants found the interactive, karyogram-based views much easier and likable to use. We additionally discuss feedback from biology and genomics faculty, who judge Synteny Explorer\'s fitness for use in classrooms.","keywords":"Bioinformatic visualization;education;learning;genome evolution;chromosome;user study","caption":"Fig.1: The Phylo View lets users explore a subset of the mammalian tree of life. Species selection is done by dragging icons into the blue sidebar. In this example, marmoset and mouse are selected.","img_size":{"width":951,"height":563},"subfigures":[{"x":6.709152674927527,"y":7.21179754078142,"width":938.3504031308812,"height":543.193374850847,"type":"interface","id":"interface-0"}],"visualizations":[{"x":8.196462913484444,"y":51.85548581910486,"width":214.04278602507736,"height":373.77064635193216,"type":"tree","id":"tree-0"},{"x":1.0506150660238445,"y":12.395174426936432,"width":802.9404623734897,"height":483.7126430025894,"type":"tree","id":"tree-1"}],"relations":[{"vislist":[{"vislist":["tree-0"],"relation":null,"id":"group-0"},{"vislist":["tree-1"],"relation":null,"id":"group-1"}],"relation":"large_view","id":"relation-0"}]},"2800_2":{"comp":[["glyph_based","scivis",["large_view"]]],"visType":["glyph_based","scivis"],"compType":["large_view"],"compressed_tree":[{"composite_pattern":"large_view","visualization_type":[["glyph_based"],["scivis"]]}],"coOccurrence":[["glyph_based","scivis",["coOccurrence"]]],"year":2016,"conference":["SciVis"],"authors":["Pedro Hermosilla","Jorge Estrada","Victor Guallar","Timo Ropinski","Alvar Vinacua","Pere-Pau V\xe1zquez"],"title":"Physics-Based Visual Characterization of Molecular Interaction Forces","doi":"10.1109/TVCG.2016.2598825","abstract":"Molecular simulations are used in many areas of biotechnology, such as drug design and enzyme engineering. Despite the development of automatic computational protocols, analysis of molecular interactions is still a major aspect where human comprehension and intuition are key to accelerate, analyze, and propose modifications to the molecule of interest. Most visualization algorithms help the users by providing an accurate depiction of the spatial arrangement: the atoms involved in inter-molecular contacts. There are few tools that provide visual information on the forces governing molecular docking. However, these tools, commonly restricted to close interaction between atoms, do not consider whole simulation paths, long-range distances and, importantly, do not provide visual cues for a quick and intuitive comprehension of the energy functions (modeling intermolecular interactions) involved. In this paper, we propose visualizations designed to enable the characterization of interaction forces by taking into account several relevant variables such as molecule-ligand distance and the energy function, which is essential to understand binding affinities. We put emphasis on mapping molecular docking paths obtained from Molecular Dynamics or Monte Carlo simulations, and provide time-dependent visualizations for different energy components and particle resolutions: atoms, groups or residues. The presented visualizations have the potential to support domain experts in a more efficient drug or enzyme design process.","keywords":"Molecular visualization;binding analysis","caption":"Fig. 3. The snapshot corresponds to the docking position of an artificial substrate, ABTS, to the manganase peroxidase 4. In Figure 4 the docking path is illustrated. This zoomed view shows the main idioms used to communicate energy: cones for direction of forces, their thickness and color to encode energy and intensity, and colored highlights of residues as described in Section 5. ","img_size":{"width":955,"height":810},"subfigures":[{"x":9.097455195163972,"y":4.951664966860011,"width":937.9114316478477,"height":800.0966700662791,"type":"single","id":"single-0"}],"visualizations":[{"x":685.1277938103945,"y":551.7136251011722,"width":254.08134547532262,"height":246.4875239962211,"type":"glyph_based","id":"glyph_based-1"},{"x":14.573670516149912,"y":13.722719621143547,"width":926.9590010058748,"height":786.9800916937666,"type":"scivis","id":"scivis-0"}],"relations":[{"vislist":[{"vislist":["glyph_based-1"],"relation":null,"id":"group-0"},{"vislist":["scivis-0"],"relation":null,"id":"group-1"}],"relation":"large_view","id":"relation-0"}]},"1908_2":{"comp":[["line_chart","parallel_coordinate",["stacked"]],["parallel_coordinate","line_chart",["stacked"]]],"visType":["line_chart","parallel_coordinate"],"compType":["stacked"],"compressed_tree":[{"composite_pattern":"stacked","visualization_type":[["line_chart","parallel_coordinate"]]}],"coOccurrence":[["line_chart","parallel_coordinate",["coOccurrence"]]],"year":2009,"conference":["Vis"],"authors":["Daniel F. Keefe","Marcus Ewert","William Ribarsky","Remco Chang"],"title":"Interactive Coordinated Multiple-View Visualization of Biomechanical Motion Data","doi":"10.1109/TVCG.2009.152","abstract":"We present an interactive framework for exploring space-time and form-function relationships in experimentally collected high-resolution biomechanical data sets. These data describe complex 3D motions (e.g. chewing, walking, flying) performed by animals and humans and captured via high-speed imaging technologies, such as biplane fluoroscopy. In analyzing these 3D biomechanical motions, interactive 3D visualizations are important, in particular, for supporting spatial analysis. However, as researchers in information visualization have pointed out, 2D visualizations can also be effective tools for multi-dimensional data analysis, especially for identifying trends over time. Our approach, therefore, combines techniques from both 3D and 2D visualizations. Specifically, it utilizes a multi-view visualization strategy including a small multiples view of motion sequences, a parallel coordinates view, and detailed 3D inspection views. The resulting framework follows an overview first, zoom and filter, then details-on-demand style of analysis, and it explicitly targets a limitation of current tools, namely, supporting analysis and comparison at the level of a collection of motions rather than sequential analysis of a single or small number of motions. Scientific motion collections appropriate for this style of analysis exist in clinical work in orthopedics and physical rehabilitation, in the study of functional morphology within evolutionary biology, and in other contexts. An application is described based on a collaboration with evolutionary biologists studying the mechanics of chewing motions in pigs. Interactive exploration of data describing a collection of more than one hundred experimentally captured pig chewing cycles is described.","keywords":"Scientific visualization, information visualization, coordinated multiple views, biomechanics","caption":"Fig. 3. A coordinated multiple view window created by zooming in on a portion of the larger data set. ","img_size":{"width":1056,"height":1088},"subfigures":[{"x":29.1978457215384,"y":10.786096574660935,"width":967.5104945587482,"height":1065.2698996514732,"type":"interface","id":"interface-0"}],"visualizations":[{"x":54.45440945324468,"y":794.0203596161082,"width":928.5719109407876,"height":203.96685788385594,"type":"line_chart","id":"line_chart-2"},{"x":56.699129778741074,"y":561.5554288164612,"width":914.8228352134333,"height":226.5761693871967,"type":"parallel_coordinate","id":"parallel_coordinate-1"},{"x":59.06207087513472,"y":68.18844740203845,"width":923.9864056351878,"height":465.30208153021533,"type":"scivis","id":"scivis-0"}],"relations":[{"vislist":[{"vislist":["line_chart-2","parallel_coordinate-1"],"relation":null,"id":"group-0"}],"relation":"stacked","id":"relation-0"}]},"3218_4":{"comp":[["tree","stripe_graph",["stacked"]],["stripe_graph","tree",["stacked"]],["table","map",["annotated"]]],"visType":["tree","stripe_graph","table","map"],"compType":["stacked","annotated"],"compressed_tree":[{"composite_pattern":"annotated","visualization_type":[["table"],["map"]]},{"composite_pattern":"stacked","visualization_type":[["tree","stripe_graph"]]}],"coOccurrence":[["table","map",["coOccurrence"]],["table","tree",["coOccurrence"]],["table","stripe_graph",["coOccurrence"]],["map","tree",["coOccurrence"]],["map","stripe_graph",["coOccurrence"]],["tree","stripe_graph",["coOccurrence"]]],"year":2019,"conference":["VAST"],"authors":["Shuai Chen","Sihang Li","Siming Chen","Xiaoru Yuan"],"title":"R-Map: A Map Metaphor for Visualizing Information Reposting Process in Social Media","doi":"10.1109/TVCG.2019.2934263","abstract":"We propose R-Map (Reposting Map), a visual analytical approach with a map metaphor to support interactive exploration and analysis of the information reposting process in social media. A single original social media post can cause large cascades of repostings (i.e., retweets) on online networks, involving thousands, even millions of people with different opinions. Such reposting behaviors form the reposting tree, in which a node represents a message and a link represents the reposting relation. In R-Map, the reposting tree structure can be spatialized with highlighted key players and tiled nodes. The important reposting behaviors, the following relations and the semantics relations are represented as rivers, routes and bridges, respectively, in a virtual geographical space. R-Map supports a scalable overview of a large number of information repostings with semantics. Additional interactions on the map are provided to support the investigation of temporal patterns and user behaviors in the information diffusion process. We evaluate the usability and effectiveness of our system with two use cases and a formal user study.","keywords":"Social Media, Information Diffusion, Map-like Visual Metaphor","caption":"Fig. 5. R-Map System Interface. (a) Weibo Table View, for selecting different weibos; (b) R-Map View, summarizing the diffusion process of an original weibo; (c) User Information Panel, showing features of users; (d) Timeline View, revealing the temporal patterns of repostings induced by different key players; (e) Word Cloud View, showing hot keywords of the selected weibos; (f) R-Map Legend, showing visual mappings in the map. For the convenience of non-Chinese readers, keywords and some important weibos are translated from Chinese to English.","img_size":{"width":2148,"height":1178},"subfigures":[{"x":6.031871119533884,"y":2.972489878124786,"width":2130.921635308984,"height":1168.293950352219,"type":"interface","id":"interface-0"}],"visualizations":[{"x":547.2717892883072,"y":68.08578839695534,"width":1273.4886002697897,"height":1101.556933935206,"type":"map","id":"map-2"},{"x":1823.61896917506,"y":194.97386896240414,"width":318.41571964884326,"height":938.7310050509157,"type":"stripe_graph","id":"stripe_graph-3"},{"x":2.494791969970032,"y":125.01965069628723,"width":528.0828811935451,"height":579.0918973032725,"type":"table","id":"table-0"},{"x":833.3237749175319,"y":100.4057818397721,"width":299.3505244524775,"height":272.6635029474778,"type":"table","id":"table-5"},{"x":1827.4238578963623,"y":98.13582798536018,"width":305.0222013745774,"height":96.66041231601795,"type":"tree","id":"tree-4"},{"x":21.39894435718909,"y":801.6917802761658,"width":506.5732563336549,"height":357.8744096908444,"type":"word_cloud","id":"word_cloud-1"}],"relations":[{"vislist":[{"vislist":["table-5"],"relation":null,"id":"group-1"},{"vislist":["map-2"],"relation":null,"id":"group-0"}],"relation":"annotated","id":"relation-0"},{"vislist":[{"vislist":["tree-4","stripe_graph-3"],"relation":null,"id":"group-2"}],"relation":"stacked","id":"relation-1"}]},"3222_3":{"comp":[["others","area_chart",["stacked"]],["area_chart","others",["stacked"]]],"visType":["others","area_chart"],"compType":["stacked"],"compressed_tree":[{"composite_pattern":"stacked","visualization_type":[["others","area_chart"]]}],"coOccurrence":[["others","area_chart",["coOccurrence"]]],"year":2019,"conference":["VAST"],"authors":["Fabian Sperrle","Rita Sevastjanova","Rebecca Kehlbeck","Mennatallah El-Assady"],"title":"VIANA: Visual Interactive Annotation of Argumentation","doi":"10.1109/VAST47406.2019.8986917","abstract":"Argumentation Mining addresses the challenging tasks of identifying boundaries of argumentative text fragments and extracting their relationships. Fully automated solutions do not reach satisfactory accuracy due to their insufficient incorporation of semantics and domain knowledge. Therefore, experts currently rely on time-consuming manual annotations. In this paper, we present a visual analytics system that augments the manual annotation process by automatically suggesting which text fragments to annotate next. The accuracy of those suggestions is improved over time by incorporating linguistic knowledge and language modeling to learn a measure of argument similarity from user interactions. Based on a long-term collaboration with domain experts, we identify and model five high-level analysis tasks. We enable close reading and note-taking, annotation of arguments, argument reconstruction, extraction of argument relations, and exploration of argument graphs. To avoid context switches, we transition between all views through seamless morphing, visually anchoring all text- and graph-based layers. We evaluate our system with a two-stage expert user study based on a corpus of presidential debates. The results show that experts prefer our system over existing solutions due to the speedup provided by the automatic suggestions and the tight integration between text and graph views.","keywords":" Argumentation annotation, machine learning, userinteraction, layered interfaces, semantic transitions","caption":"Figure 4: VIANA system overview. The top bar shows the currently active annotation layer. Here, a graph view is shown next to a text view. An interaction log is displayed at the bottom of the screen.","img_size":{"width":1025,"height":591},"subfigures":[{"x":6.249074859726348,"y":7.7420162584674435,"width":1013.1307038032103,"height":578.0318614342773,"type":"interface","id":"interface-0"}],"visualizations":[{"x":963.770415183804,"y":62.51005235813528,"width":52.151689883136115,"height":477.65908814823206,"type":"area_chart","id":"area_chart-1"},{"x":50.573186925466544,"y":77.64279117610052,"width":350.26036041796783,"height":394.83724262204197,"type":"graph","id":"graph-0"},{"x":431.830738897522,"y":97.32927428138285,"width":328.55554204520786,"height":435.9209383669359,"type":"others","id":"others-2"}],"relations":[{"vislist":[{"vislist":["others-2","area_chart-1"],"relation":null,"id":"group-0"}],"relation":"stacked","id":"relation-0"}]},"3300_0":{"comp":[["bar_chart","matrix",["stacked"]],["matrix","bar_chart",["stacked"]]],"visType":["bar_chart","matrix"],"compType":["stacked"],"compressed_tree":[{"composite_pattern":"stacked","visualization_type":[["bar_chart","matrix"]]}],"coOccurrence":[["bar_chart","matrix",["coOccurrence"]]],"year":2020,"conference":["VAST"],"authors":["Jorge Piazentin Ono","Sonia Castelo","Roque Lopez","Enrico Bertini","Juliana Freire","Claudio Silva"],"title":"PipelineProfiler: A Visual Analytics Tool for the Exploration of AutoML Pipelines","doi":"10.1109/TVCG.2020.3030361","abstract":"In recent years, a wide variety of automated machine learning (AutoML) methods have been proposed to generate end-to-end ML pipelines. While these techniques facilitate the creation of models, given their black-box nature, the complexity of the underlying algorithms, and the large number of pipelines they derive, they are difficult for developers to debug. It is also challenging for machine learning experts to select an AutoML system that is well suited for a given problem. In this paper, we present the Pipeline Profiler, an interactive visualization tool that allows the exploration and comparison of the solution space of machine learning (ML) pipelines produced by AutoML systems. PipelineProfiler is integrated with Jupyter Notebook and can be combined with common data science tools to enable a rich set of analyses of the ML pipelines, providing users a better understanding of the algorithms that generated them as well as insights into how they can be improved. We demonstrate the utility of our tool through use cases where PipelineProfiler is used to better understand and improve a real-world AutoML system. Furthermore, we validate our approach by presenting a detailed analysis of a think-aloud experiment with six data scientists who develop and evaluate AutoML tools.","keywords":"Automatic Machine Learning, Pipeline Visualization, Model Evaluation","caption":"Fig. 1. PipelinePro\ufb01ler applied to the analysis of binary classi\ufb01cation pipelines generated by \ufb01ve different AutoML systems for the Statlog (Heart) Data Set. A) The system is integrated with Jupyter Notebook and can be invoked with one line of code. B) PipelinePro\ufb01ler menu, with options to subset, export, sort, and perform automated analysis on pipelines. C) Pipeline Matrix: C1) Primitives (columns) used by the pipelines (rows). C2) Tooltip showing the metadata and hyperparameters for a primitive. C3) One-hot-encoded hyperparameters (columns) for the primitive Xgboost Gbtree across pipelines (rows). C4) Pipeline scores: users can select different metrics to rank pipelines. C5) Primitive Contribution View, showing correlations between primitive usage and pipeline scores (here, Deep Feature Synthesis has the highest correlation with F1 scores). D) Pipeline Comparison View: visual comparison of the top-3 scoring pipelines. ","img_size":{"width":1628,"height":945},"subfigures":[{"x":79.32879495961824,"y":71.14178050261005,"width":1493.8661159714738,"height":858.2199728177878,"type":"interface","id":"interface-0"}],"visualizations":[{"x":193.010415962473,"y":117.68082738136388,"width":755.1762731203521,"height":326.3759370533425,"type":"bar_chart","id":"bar_chart-1"},{"x":1271.216450962821,"y":440.8623573243139,"width":260.2124316228712,"height":251.31789011577087,"type":"bar_chart","id":"bar_chart-3"},{"x":78.32930915419954,"y":696.106789553403,"width":1487.1373458346732,"height":230.31397393744257,"type":"flow_diagram","id":"flow_diagram-0"},{"x":121.48714725151403,"y":440.82486149369146,"width":1149.5222400911591,"height":248.5220023149638,"type":"matrix","id":"matrix-2"}],"relations":[{"vislist":[{"vislist":["bar_chart-3","bar_chart-1","matrix-2"],"relation":null,"id":"group-0"}],"relation":"stacked","id":"relation-0"}]},"3344_0":{"comp":[["others","matrix",["stacked"]],["matrix","others",["stacked"]]],"visType":["others","matrix"],"compType":["stacked"],"compressed_tree":[{"composite_pattern":"stacked","visualization_type":[["others","matrix"]]}],"coOccurrence":[["others","matrix",["coOccurrence"]]],"year":2020,"conference":["VAST"],"authors":["David Borland","Jonathan Zhang","Smiti Kaul","David Gotz"],"title":"Selection-Bias-Corrected Visualization via Dynamic Reweighting","doi":"10.1109/TVCG.2020.3030455","abstract":"The collection and visual analysis of large-scale data from complex systems, such as electronic health records or clickstream data, has become increasingly common across a wide range of industries. This type of retrospective visual analysis, however, is prone to a variety of selection bias effects, especially for high-dimensional data where only a subset of dimensions is visualized at any given time. The risk of selection bias is even higher when analysts dynamically apply filters or perform grouping operations during ad hoc analyses. These bias effects threaten the validity and generalizability of insights discovered during visual analysis as the basis for decision making. Past work has focused on bias transparency, helping users understand when selection bias may have occurred. However, countering the effects of selection bias via bias mitigation is typically left for the user to accomplish as a separate process. Dynamic reweighting (DR) is a novel computational approach to selection bias mitigation that helps users craft bias-corrected visualizations. This paper describes the DR workflow, introduces key DR visualization designs, and presents statistical methods that support the DR process. Use cases from the medical domain, as well as findings from domain expert user interviews, are also reported.","keywords":"Selection bias, bias mitigation, bias correction, high-dimensional visualization, cohort selection, medical informatics","caption":"Fig. 1.  Coordinated visualization panels supporting the dynamic reweighting workflow. The visual designs help users discover dimensions with high selection bias, select dimensions for correction, and assess both the quality and impact of a reweighting solution.","img_size":{"width":1809,"height":908},"subfigures":[{"x":7.430647503676817,"y":6.5417915240872295,"width":1791.5108511969688,"height":890.9698850339693,"type":"interface","id":"interface-0"}],"visualizations":[{"x":905.1051442888379,"y":163.12420240849158,"width":515.7802921505652,"height":433.4051114728963,"type":"glyph_based","id":"glyph_based-4"},{"x":9.076910275366105,"y":42.161880300669274,"width":362.7394826845293,"height":830.0567333216771,"type":"graph","id":"graph-0"},{"x":1489.3602207404579,"y":552.2318710477082,"width":121.16036039916543,"height":337.9026239571671,"type":"matrix","id":"matrix-1"},{"x":1608.5845832606813,"y":558.478352107345,"width":153.9721252469934,"height":325.40966183789203,"type":"others","id":"others-2"},{"x":1491.1928427107812,"y":269.638381996803,"width":302.5905095587524,"height":276.20607412266327,"type":"others","id":"others-3"},{"x":359.46188706641937,"y":93.10170960555733,"width":514.0465973397086,"height":809.5283722303548,"type":"others","id":"others-5"}],"relations":[{"vislist":[{"vislist":["others-3","others-2","matrix-1"],"relation":null,"id":"group-0"}],"relation":"stacked","id":"relation-0"}]},"2690_0":{"comp":[["scatterplot","stripe_graph",["stacked"]],["stripe_graph","scatterplot",["stacked"]]],"visType":["scatterplot","stripe_graph"],"compType":["stacked"],"compressed_tree":[{"composite_pattern":"stacked","visualization_type":[["scatterplot","stripe_graph"]]}],"coOccurrence":[["scatterplot","stripe_graph",["coOccurrence"]]],"year":2015,"conference":["VAST"],"authors":["Dominik J\xe4ckle","Fabian Fische","Tobias Schreck","Daniel A. Keim"],"title":"Temporal MDS Plots for Analysis of Multivariate Data","doi":"10.1109/TVCG.2015.2467553","abstract":"Multivariate time series data can be found in many application domains. Examples include data from computer networks, healthcare, social networks, or financial markets. Often, patterns in such data evolve over time among multiple dimensions and are hard to detect. Dimensionality reduction methods such as PCA and MDS allow analysis and visualization of multivariate data, but per se do not provide means to explore multivariate patterns over time. We propose Temporal Multidimensional Scaling (TMDS), a novel visualization technique that computes temporal one-dimensional MDS plots for multivariate data which evolve over time. Using a sliding window approach, MDS is computed for each data window separately, and the results are plotted sequentially along the time axis, taking care of plot alignment. Our TMDS plots enable visual identification of patterns based on multidimensional similarity of the data evolving over time. We demonstrate the usefulness of our approach in the field of network security and show in two case studies how users can iteratively explore the data to identify previously unknown, temporally evolving patterns.","keywords":"Multivariate Data, Time Series, Data Reduction, Multidimensional Scaling","caption":"Fig. 1. Temporal MDS plots (top) applied to network traffic data, which was collected from a /16 computer network over a period of 24 hours. For each temporal MDS plot the sequentially aligned matrix (bottom) provides an overview of correlations among dimensions. The visualization reveals a distributed brute-force attack (A, D) and various different port scans (B, C).","img_size":{"width":2154,"height":917},"subfigures":[{"x":36.85888842022265,"y":12.45958120740505,"width":2086.5402630444555,"height":892.0808375851906,"type":"interface","id":"interface-0"}],"visualizations":[{"x":45.80112570356473,"y":98.1529080675422,"width":1625.9399624765479,"height":665.4634146341461,"type":"scatterplot","id":"scatterplot-0"},{"x":57.924953095684806,"y":774.3930581613508,"width":1598.998123827392,"height":111.80863039399627,"type":"stripe_graph","id":"stripe_graph-1"}],"relations":[{"vislist":[{"vislist":["scatterplot-0","stripe_graph-1"],"relation":null,"id":"group-0"}],"relation":"stacked","id":"relation-0"}]},"2724_3":{"comp":[["stripe_graph","stripe_graph",["stacked"]]],"visType":["stripe_graph"],"compType":["stacked"],"compressed_tree":[{"composite_pattern":"stacked","visualization_type":[["stripe_graph"]]},{"composite_pattern":"stacked","visualization_type":[["stripe_graph"]]},{"composite_pattern":"stacked","visualization_type":[["stripe_graph"]]},{"composite_pattern":"stacked","visualization_type":[["stripe_graph"]]}],"coOccurrence":[["stripe_graph","stripe_graph",["coOccurrence"]]],"year":2015,"conference":["VAST"],"authors":["Martin R\xf6hlig","Martin Luboschik","Frank Kr\xfcge","Thomas Kirste","Heidrun Schumann","Markus B\xf6gl","Bilal Alsallakh","Silvia Miksch"],"title":"Supporting activity recognition by visual analytics","doi":"10.1109/VAST.2015.7347629","abstract":"Recognizing activities has become increasingly relevant in many application domains, such as security or ambient assisted living. To handle different scenarios, the underlying automated algorithms are configured using multiple input parameters. However, the influence and interplay of these parameters is often not clear, making exhaustive evaluations necessary. On this account, we propose a visual analytics approach to supporting users in understanding the complex relationships among parameters, recognized activities, and associated accuracies. First, representative parameter settings are determined. Then, the respective output is computed and statistically analyzed to assess parameters\' influence in general. Finally, visualizing the parameter settings along with the activities provides overview and allows to investigate the computed results in detail. Coordinated interaction helps to explore dependencies, compare different settings, and examine individual activities. By integrating automated, visual, and interactive means users can select parameter values that meet desired quality criteria. We demonstrate the application of our solution in a use case with realistic complexity, involving a study of human protagonists in daily living with respect to hundreds of parameter settings.","keywords":"","caption":"Figure 3: Schematic illustration of the visual analysis tool. For each parameter setting (a) three different modes are shown: activities as color- coded stripes (b), deviations from the ground truth (c) for all activities (d), and for one selected activity (e). Two additional views represent three types of aggregated information per column (f) or per row (g): the dominant activity (h), the percentage of the dominant activity (i), and the percentages of all activities as stacked bars (j). A visual cue (k) denotes the presence (red) or absence (green) of over-plotting in rows and columns. Selecting and highlighting different parts of the data is enabled through a dedicated toolbar (m).","img_size":{"width":2118,"height":789},"subfigures":[{"x":8.69542606756901,"y":5.623583400603964,"width":2095.994061348074,"height":779.2913211256234,"type":"interface","id":"interface-0"}],"visualizations":[{"x":3.5959252971137516,"y":6.1400593383607704,"width":158.22071307300504,"height":528.6010186757215,"type":"stripe_graph","id":"stripe_graph-0"},{"x":160.01867572156195,"y":2.5441340412470552,"width":1957.9813242784378,"height":786.4558659587528,"type":"stripe_graph","id":"stripe_graph-1"},{"x":160.01867572156195,"y":2.5441340412470552,"width":566.3582342954159,"height":782.1137521222408,"type":"stripe_graph","id":"stripe_graph-2"},{"x":706.5993208828523,"y":99.63411706331836,"width":550.1765704584041,"height":689.3658829366816,"type":"stripe_graph","id":"stripe_graph-3"},{"x":1262.1697792869265,"y":101.43207971187525,"width":704.8013582342953,"height":681.4278438030559,"type":"stripe_graph","id":"stripe_graph-4"}],"relations":[{"vislist":[{"vislist":["stripe_graph-0","stripe_graph-1","stripe_graph-2","stripe_graph-3","stripe_graph-4"],"relation":null,"id":"group-0"}],"relation":"stacked","id":"relation-0"},{"vislist":[{"vislist":["stripe_graph-2"],"relation":null,"id":"group-1"}],"relation":"stacked","id":"relation-1"},{"vislist":[{"vislist":["stripe_graph-3"],"relation":null,"id":"group-2"}],"relation":"stacked","id":"relation-2"},{"vislist":[{"vislist":["stripe_graph-4"],"relation":null,"id":"group-3"}],"relation":"stacked","id":"relation-3"}]},"2750_0":{"comp":[["bar_chart","heatmap",["stacked"]],["heatmap","bar_chart",["stacked"]]],"visType":["bar_chart","heatmap"],"compType":["stacked"],"compressed_tree":[{"composite_pattern":"stacked","visualization_type":[["bar_chart","heatmap"]]}],"coOccurrence":[["heatmap","heatmap",["coOccurrence"]]],"year":2015,"conference":["VAST"],"authors":["Yi-Chih Tsai","Liang-Chi Hsieh","Wen-Feng Cheng","Yin-Hsi Kuo","Winston H. Hsu","Wen-Chin Chen"],"title":"Trending pool: Visual analytics for trending event compositions for time-series categorical log data","doi":"10.1109/VAST.2015.7347688","abstract":"Although many visualization tools provide us plenty of ways to view the data, users can not easily find the trending events and their explanation from the data. In this work, we address the issue by leveraging the real music streaming log data as an example to better understand a million-scale dataset. Trending event explanation turns out to be challenging when it comes to categorical log data. Therefore, we propose to use a learning-based method with an interface design to uncover the trending event compositions for time-series categorical log data, which can be extend to other datasets, e.g., the hashtags in social media. First, we perform \u201ctrending pool\u201d operation to save the memory and time cost. Second, we apply sparse coding to learn important trending candidate combination sets instead of traditional brute-force way or manual investigation for generating combinations. Besides the contributions above, we also observe some interesting user behaviors by exploring detected trending candidate combinations visually through our interface.","keywords":"","caption":"Figure 1: Trending Pool for Trending Event Composition \u2013 Visualization Layout: Widget (b) is for visualizing the trending event compositions using sparse codewords by trending candidate bases, i.e., columns in the heatmap, while the importance of trending candidate-bases is shown in widget (a). Also, we draw the trending and volume bubbles, detailed in (e), to show the volume change for each trending candidate in \u201ctrending pool\u201d shown in widget (c). In each bubble, we encode the current time traffic of the candidate as the outer radius, its mean traffic in the scoring window as the inner radius, and the buzz score is embedded in colors. Besides, user can explore the trending events in different timestamps with the time selection widget (d). This visualization shows a trending event formed by song genre 2, which indicates English pop songs. Another event is composed by users born in the year ranging from 1985 to 1989 listening to song genre 23, Korean songs, at 10 a.m. April 7th, 2014.","img_size":{"width":1848,"height":470},"subfigures":[{"x":777.3490217645601,"y":160.40409108664048,"width":600.6780492019784,"height":299.434589054871,"type":"single","id":"single-0"},{"x":1399.4444385171396,"y":18.60037068630829,"width":438.34368181587615,"height":444.8723384582161,"type":"single","id":"single-1"},{"x":47.886826392184496,"y":12.199227386787662,"width":510.6416931708035,"height":135.72582956836004,"type":"single","id":"single-2"},{"x":26.159878220114383,"y":164.52570578577192,"width":723.2195532010502,"height":293.8742662856828,"type":"single","id":"single-3"}],"visualizations":[{"x":48.540337711069434,"y":11.367729831144484,"width":518.9193245778611,"height":138.68667917448406,"type":"bar_chart","id":"bar_chart-0"},{"x":781.2682926829268,"y":153.52157598499065,"width":595.1969981238274,"height":307.4221388367729,"type":"glyph_based","id":"glyph_based-1"},{"x":1403.6986049032917,"y":27.68696411562711,"width":380.470308994034,"height":436.84000380336084,"type":"glyph_based","id":"glyph_based-5"},{"x":12.712945590994375,"y":155.8330206378987,"width":553.5909943714821,"height":309.733583489681,"type":"heatmap","id":"heatmap-2"},{"x":43.91744840525328,"y":156.98874296435272,"width":520.0750469043152,"height":308.5778611632268,"type":"matrix","id":"matrix-3"}],"relations":[{"vislist":[{"vislist":["bar_chart-0","heatmap-2"],"relation":null,"id":"group-0"}],"relation":"stacked","id":"relation-0"}]},"2832_0":{"comp":[["bar_chart","matrix",["stacked"]],["matrix","bar_chart",["stacked"]]],"visType":["bar_chart","matrix"],"compType":["stacked"],"compressed_tree":[{"composite_pattern":"stacked","visualization_type":[["bar_chart","matrix"]]}],"coOccurrence":[["bar_chart","matrix",["coOccurrence"]]],"year":2016,"conference":["VAST"],"authors":["Michael Glueck","Alina Gvozdik","Fanny Chevalier","Azam Khan","Michael Brudno","Daniel J. Wigdor"],"title":"PhenoStacks: Cross-Sectional Cohort Phenotype Comparison Visualizations","doi":"10.1109/TVCG.2016.2598469","abstract":"Cross-sectional phenotype studies are used by genetics researchers to better understand how phenotypes vary across patients with genetic diseases, both within and between cohorts. Analyses within cohorts identify patterns between phenotypes and patients (e.g., co-occurrence) and isolate special cases (e.g., potential outliers). Comparing the variation of phenotypes between two cohorts can help distinguish how different factors affect disease manifestation (e.g., causal genes, age of onset, etc.). PhenoStacks is a novel visual analytics tool that supports the exploration of phenotype variation within and between cross-sectional patient cohorts. By leveraging the semantic hierarchy of the Human Phenotype Ontology, phenotypes are presented in context, can be grouped and clustered, and are summarized via overviews to support the exploration of phenotype distributions. The design of PhenoStacks was motivated by formative interviews with genetics researchers: we distil high-level tasks, present an algorithm for simplifying ontology topologies for visualization, and report the results of a deployment evaluation with four expert genetics researchers. The results suggest that PhenoStacks can help identify phenotype patterns, investigate data quality issues, and inform data collection design.","keywords":"Cross-sectional cohort analysis;Phenotypes;Human Phenotype Ontology (HPO)","caption":"Fig. 1. PhenoStacks employs an observations plot (D) to reveal the distribution of phenotypes (rows) across patients (columns) in a cohort, which can be sorted by patient or phenotype attributes. Similar phenotypes can be grouped based on the Human Phenotype Ontology (B,C). Radial hierarchies (A) summarize global patterns. Views are linked, e.g., search results (E) are highlighted (A,C,D).","img_size":{"width":1967,"height":732},"subfigures":[{"x":33.68573304812382,"y":10.76105954014635,"width":1912.4867140433057,"height":704.7679324913435,"type":"interface","id":"interface-0"}],"visualizations":[{"x":1512.8200339558573,"y":254.12478777589138,"width":101.85653650254676,"height":469.2079796264856,"type":"bar_chart","id":"bar_chart-0"},{"x":1324.134974533107,"y":247.44567062818334,"width":195.36417657045828,"height":475.88709677419354,"type":"matrix","id":"matrix-1"},{"x":56.77249575551784,"y":302.54838709677426,"width":293.8811544991512,"height":297.2207130730051,"type":"sunburst_icicle","id":"sunburst_icicle-2"}],"relations":[{"vislist":[{"vislist":["bar_chart-0","matrix-1"],"relation":null,"id":"group-0"}],"relation":"stacked","id":"relation-0"}]},"2876_1":{"comp":[["bar_chart","storyline",["stacked"]],["storyline","bar_chart",["stacked"]]],"visType":["bar_chart","storyline"],"compType":["stacked"],"compressed_tree":[{"composite_pattern":"stacked","visualization_type":[["bar_chart","storyline"]]}],"coOccurrence":[["bar_chart","storyline",["coOccurrence"]]],"year":2017,"conference":["InfoVis"],"authors":["Nam Wook Kim","Benjamin Bach","Hyejin Im","Sasha Schriber","Markus H. Gross","Hanspeter Pfister"],"title":"Visualizing Nonlinear Narratives with Story Curves","doi":"10.1109/TVCG.2017.2744118","abstract":"In this paper, we present story curves, a visualization technique for exploring and communicating nonlinear narratives in movies. A nonlinear narrative is a storytelling device that portrays events of a story out of chronological order, e.g., in reverse order or going back and forth between past and future events. Many acclaimed movies employ unique narrative patterns which in turn have inspired other movies and contributed to the broader analysis of narrative patterns in movies. However, understanding and communicating nonlinear narratives is a difficult task due to complex temporal disruptions in the order of events as well as no explicit records specifying the actual temporal order of the underlying story. Story curves visualize the nonlinear narrative of a movie by showing the order in which events are told in the movie and comparing them to their actual chronological order, resulting in possibly meandering visual patterns in the curve. We also present Story Explorer, an interactive tool that visualizes a story curve together with complementary information such as characters and settings. Story Explorer further provides a script curation interface that allows users to specify the chronological order of events in movies. We used Story Explorer to analyze 10 popular nonlinear movies and describe the spectrum of narrative patterns that we discovered, including some novel patterns not previously described in the literature. Feedback from experts highlights potential use cases in screenplay writing and analysis, education and film production. A controlled user study shows that users with no expertise are able to understand visual patterns of nonlinear narratives using story curves.","keywords":"Nonlinear narrative,storytelling,visualization","caption":"Fig. 2. Overview of Story Explorer with three embedded views: (a) story curve view, (b) script view, and (c) metadata view. The story curve succinctly summarizes the nonlinear narrative of Pulp Fiction with additional metadata displayed along the story curve.","img_size":{"width":2151,"height":1472},"subfigures":[{"x":10.170077404135261,"y":12.950484550861463,"width":2120.6129424873934,"height":1442.0778077267485,"type":"interface","id":"interface-0"}],"visualizations":[{"x":7.239190474864849,"y":796.5025211717984,"width":1461.6244227787824,"height":656.018800510518,"type":"bar_chart","id":"bar_chart-1"},{"x":8.456152758133046,"y":233.18811881188117,"width":1442.8514851485147,"height":568.3960396039605,"type":"storyline","id":"storyline-0"}],"relations":[{"vislist":[{"vislist":["bar_chart-1","storyline-0"],"relation":null,"id":"group-0"}],"relation":"stacked","id":"relation-0"}]},"2939_0":{"comp":[["matrix","sunburst_icicle",["stacked"]],["sunburst_icicle","matrix",["stacked"]]],"visType":["matrix","sunburst_icicle"],"compType":["stacked"],"compressed_tree":[{"composite_pattern":"stacked","visualization_type":[["matrix","sunburst_icicle"]]}],"coOccurrence":[["matrix","sunburst_icicle",["coOccurrence"]]],"year":2017,"conference":["VAST"],"authors":["Bilal Alsallakh","Amin Jourabloo","Mao Ye","Xiaoming Li","Liu Ren"],"title":"Do Convolutional Neural Networks Learn Class Hierarchy?","doi":"10.1109/TVCG.2017.2744683","abstract":"Convolutional Neural Networks (CNNs) currently achieve state-of-the-art accuracy in image classification. With a growing number of classes, the accuracy usually drops as the possibilities of confusion increase. Interestingly, the class confusion patterns follow a hierarchical structure over the classes. We present visual-analytics methods to reveal and analyze this hierarchy of similar classes in relation with CNN-internal data. We found that this hierarchy not only dictates the confusion patterns between the classes, it furthermore dictates the learning behavior of CNNs. In particular, the early layers in these networks develop feature detectors that can separate high-level groups of classes quite well, even after a few training epochs. In contrast, the latter layers require substantially more epochs to develop specialized feature detectors that can separate individual classes. We demonstrate how these insights are key to significant improvement in accuracy by designing hierarchy-aware CNNs that accelerate model convergence and alleviate overfitting. We further demonstrate how our methods help in identifying various quality issues in the training data.","keywords":"Convolutional Neural Networks,deep learning,image classification,large-scale classification,confusion matrix","caption":"Fig. 1. The user interface of our system, showing classification results of the ImageNet ILSVRC dataset [56] using GoogLeNet [64]. (a) The class hierarchy with all classes under bird group selected. (b) The confusion matrix showing misclassified samples only. The bands indicate the selected classes in both dimensions. (c) The sample viewer shows selected samples grouped by actual class.","img_size":{"width":1889,"height":1040},"subfigures":[{"x":16.720374143543484,"y":6.342199225112956,"width":1859.8222660101244,"height":1024.4745199611957,"type":"interface","id":"interface-0"}],"visualizations":[{"x":422.2242888402626,"y":45.51422319474836,"width":928.4901531728664,"height":960.3501094091903,"type":"matrix","id":"matrix-0"},{"x":196.9288840262582,"y":70.54704595185996,"width":218.4682713347921,"height":930.7658643326038,"type":"sunburst_icicle","id":"sunburst_icicle-1"}],"relations":[{"vislist":[{"id":"group-0","relation":null,"vislist":["matrix-0","sunburst_icicle-1"]}],"relation":"stacked","id":"relation-0"}]},"1950_4":{"comp":[["matrix","matrix",["stacked"]]],"visType":["matrix"],"compType":["stacked"],"compressed_tree":[{"composite_pattern":"stacked","visualization_type":[["matrix"]]}],"coOccurrence":[["matrix","matrix",["coOccurrence"]]],"year":2010,"conference":["InfoVis"],"authors":["Anastasia Bezerianos","Pierre Dragicevic","Jean-Daniel Fekete","Juhee Bae","Benjamin Watson"],"title":"GeneaQuilts: A System for Exploring Large Genealogies","doi":"10.1109/TVCG.2010.159","abstract":"GeneaQuilts is a new visualization technique for representing large genealogies of up to several thousand individuals. The visualization takes the form of a diagonally-filled matrix, where rows are individuals and columns are nuclear families. After identifying the major tasks performed in genealogical research and the limits of current software, we present an interactive genealogy exploration system based on GeneaQuilts. The system includes an overview, a timeline, search and filtering components, and a new interaction technique called Bring &amp; Slide that allows fluid navigation in very large genealogies. We report on preliminary feedback from domain experts and show how our system supports a number of their tasks.","keywords":"Genealogy visualization, interaction","caption":"Fig. 4. The GeneaQuilts System showing part of the European Royal families. It consists of (a) the main visualization, (b) an overview, (c) a timeline and (d) a query and details panel.","img_size":{"width":1062,"height":1079},"subfigures":[{"x":23.560660243010002,"y":21.030777321219237,"width":1004.5459889087086,"height":1057.6083659668818,"type":"interface","id":"interface-0"}],"visualizations":[{"x":30.64876843624244,"y":111.37031563764407,"width":592.032110576752,"height":535.5521435935839,"type":"matrix","id":"matrix-0"},{"x":798.9792122538295,"y":125.13566739606128,"width":221.93873085339166,"height":318.74179431072207,"type":"matrix","id":"matrix-1"},{"x":278.64076767609066,"y":632.4565424797008,"width":515.0428854862462,"height":437.5089993742017,"type":"matrix","id":"matrix-3"},{"x":796.6181619256018,"y":502.9037199124727,"width":221.93873085339166,"height":207.77242888402625,"type":"table","id":"table-2"}],"relations":[{"vislist":[{"vislist":["matrix-0","matrix-3"],"relation":null,"id":"group-0"}],"relation":"stacked","id":"relation-0"}]},"1970_0":{"comp":[["others","scatterplot",["stacked"]],["scatterplot","others",["stacked"]]],"visType":["others","scatterplot"],"compType":["stacked"],"compressed_tree":[{"composite_pattern":"stacked","visualization_type":[["others","scatterplot"]]}],"coOccurrence":[["others","scatterplot",["coOccurrence"]]],"year":2010,"conference":["InfoVis"],"authors":["Dominikus Baur","Frederik Seiffert","Michael Sedlmair","Sebastian Boring"],"title":"The Streams of Our Lives: Visualizing Listening Histories in Context","doi":"10.1109/TVCG.2010.206","abstract":"The choices we take when listening to music are expressions of our personal taste and character. Storing and accessing our listening histories is trivial due to services like Last.fm, but learning from them and understanding them is not. Existing solutions operate at a very abstract level and only produce statistics. By applying techniques from information visualization to this problem, we were able to provide average people with a detailed and powerful tool for accessing their own musical past. LastHistory is an interactive visualization for displaying music listening histories, along with contextual information from personal photos and calendar entries. Its two main user tasks are (1) analysis, with an emphasis on temporal patterns and hypotheses related to musical genre and sequences, and (2) reminiscing, where listening histories and context represent part of one\'s past. In this design study paper we give an overview of the field of music listening histories and explain their unique characteristics as a type of personal data. We then describe the design rationale, data and view transformations of LastHistory and present the results from both a laband a large-scale online study. We also put listening histories in contrast to other lifelogging data. The resonant and enthusiastic feedback that we received from average users shows a need for making their personal data accessible. We hope to stimulate such developments through this research.","keywords":"Information visualization, lifelogging, design study, music, listening history, timelines, photos, calendars","caption":"Fig. 1. LastHistory: Visualizing personal music listening histories, photo and calendar streams for analysis and reminiscing.","img_size":{"width":1466,"height":871},"subfigures":[{"x":36.82532790844267,"y":15.853584832864042,"width":1405.3256049771853,"height":808.7030080670634,"type":"interface","id":"interface-0"}],"visualizations":[{"x":37.09444546184255,"y":636.0439677324974,"width":1385.3455954975377,"height":118.937258587191,"type":"others","id":"others-1"},{"x":38.19465648854963,"y":14.545875084810975,"width":1416.2061068702287,"height":620.3417432838238,"type":"scatterplot","id":"scatterplot-0"}],"relations":[{"vislist":[{"vislist":["others-1","scatterplot-0"],"relation":null,"id":"group-0"}],"relation":"stacked","id":"relation-0"}]},"1998_4":{"comp":[["bar_chart","matrix",["stacked"]],["bar_chart","others",["stacked"]],["matrix","bar_chart",["stacked"]],["others","bar_chart",["stacked"]]],"visType":["bar_chart","matrix","others"],"compType":["stacked"],"compressed_tree":[{"composite_pattern":"stacked","visualization_type":[["bar_chart","matrix"]]},{"composite_pattern":"stacked","visualization_type":[["bar_chart","others"]]}],"coOccurrence":[["bar_chart","matrix",["coOccurrence"]],["bar_chart","others",["coOccurrence"]],["matrix","others",["coOccurrence"]]],"year":2010,"conference":["VAST"],"authors":["Chris Weaver"],"title":"Multidimensional data dissection using attribute relationship graphs","doi":"10.1109/VAST.2010.5652520","abstract":"Visual exploration and analysis is a process of discovering and dissecting the abundant and complex attribute relationships that pervade multidimensional data. Recent research has identified and characterized patterns of multiple coordinated views, such as cross-filtered views, in which rapid sequences of simple interactions can be used to express queries on subsets of attribute values. In visualizations designed around these patterns, for the most part, distinct views serve to visually isolate each attribute from the others. Although the brush-and-click simplicity of visual isolation facilitates discovery of many-to-many relationships between attributes, dissecting these relationships into more fine-grained one-to-many relationships is interactively tedious and, worse, visually fragmented over prolonged sequences of queries. This paper describes: (1) a method for interactively dissecting multidimensional data by iteratively slicing and manipulating a multigraph representation of data values and value co-occurrences; and (2) design strategies for extending the construction of coordinated multiple view interfaces for dissection as well as discovery of attribute relationships in multidimensional data sets. Using examples from different domains, we describe how attribute relationship graphs can be combined with cross-filtered views, modularized for reuse across designs, and integrated into broader visual analysis tools. The exploratory and analytic utility of these examples suggests that an attribute relationship graph would be a useful addition to a wide variety of visual analysis tools.","keywords":"","caption":"Figure 5: Visualization of wiki edits from the VAST 2008 Wiki Editors Mini Challenge. The attribute relationship graph shows connections between prominent authors, frequent words, and revision types during early morning and afternoon activity at the end of two multi-day editing periods. Times (hours of the day) and dates are both treated as nominal data values; the corresponding nodes in the graph have been laid out by hand.","img_size":{"width":2112,"height":975},"subfigures":[{"x":5.668769279396642,"y":6.4357228535251645,"width":2102.863977946793,"height":959.9267893155592,"type":"interface","id":"interface-0"}],"visualizations":[{"x":817.8534482758615,"y":683.6645261176784,"width":672.4137931034478,"height":188.72116894158367,"type":"bar_chart","id":"bar_chart-0"},{"x":15.299234598411049,"y":875.4472047489546,"width":700.9817454449037,"height":89.32187887920722,"type":"bar_chart","id":"bar_chart-5"},{"x":819.721264367816,"y":61.63793103448276,"width":720.9770114942528,"height":592.0977011494252,"type":"graph","id":"graph-1"},{"x":5.353448275861974,"y":514.4374325647594,"width":805.0287356321834,"height":364.6659786015838,"type":"matrix","id":"matrix-2"},{"x":881.235142903246,"y":874.6287505135641,"width":604.7490267361317,"height":45.852176617552026,"type":"others","id":"others-4"},{"x":5.353448275861979,"y":59.770114942528735,"width":784.4827586206897,"height":332.47126436781605,"type":"table","id":"table-3"}],"relations":[{"vislist":[{"vislist":["bar_chart-5","matrix-2"],"relation":null,"id":"group-0"}],"relation":"stacked","id":"relation-0"},{"vislist":[{"vislist":["bar_chart-0","others-4"],"relation":null,"id":"group-1"}],"relation":"stacked","id":"relation-1"}]},"2323_0":{"comp":[["bar_chart","table",["stacked"]],["table","bar_chart",["stacked"]]],"visType":["bar_chart","table"],"compType":["stacked"],"compressed_tree":[{"composite_pattern":"stacked","visualization_type":[["bar_chart","table"]]}],"coOccurrence":[["bar_chart","table",["coOccurrence"]]],"year":2012,"conference":["VAST"],"authors":["Abish Malik","Ross Maciejewski","Niklas Elmqvist","Yun Jang","David S. Ebert","Whitney Huang"],"title":"A correlative analysis process in a visual analytics environment","doi":"10.1109/VAST.2012.6400491","abstract":"Finding patterns and trends in spatial and temporal datasets has been a long studied problem in statistics and different domains of science. This paper presents a visual analytics approach for the interactive exploration and analysis of spatiotemporal correlations among multivariate datasets. Our approach enables users to discover correlations and explore potentially causal or predictive links at different spatiotemporal aggregation levels among the datasets, and allows them to understand the underlying statistical foundations that precede the analysis. Our technique utilizes the Pearson\'s product-moment correlation coefficient and factors in the lead or lag between different datasets to detect trends and periodic patterns amongst them.","keywords":"Visual analytics, correlative analysis","caption":"Figure 1: A screenshot of our correlative visual analytics system. Here, the user is visualizing all crimes related to noise complaints and drunkenness/public intoxication in Tippecanoe County, IN. The main viewing area (a) shows the map view with the points showing the locations of the selected offenses on the map for the week of 1/3/2011 to 1/9/2011. The top-right window (b) shows an interactive menu that allows users to filter through the variables of the datasets. The middle window (c) shows the weekly time-series view of the selected incident reports, where the user is performing a correlative analysis of the system, the results of which are displayed in the correlation vs. lead/lag graph (d). The region of overlap between the time series in (c) is colored by the corresponding correlation value based on a divergent color scale (e). The left window (f) shows the calendar view for the year 2011, and the right window (g) shows a clock view of the selected incident report data for the week of 1/3/2011 to 1/9/2011. Finally, the bottom-left window (h) shows the time slider with radio buttons that allow different temporal aggregation levels.","img_size":{"width":2110,"height":1287},"subfigures":[{"x":10.42896433525812,"y":1.919372953818499,"width":2091.881249293904,"height":1285.9006411610687,"type":"interface","id":"interface-0"}],"visualizations":[{"x":213.01328136255427,"y":146.13160182595237,"width":68.49474569821051,"height":782.4706566139802,"type":"bar_chart","id":"bar_chart-1"},{"x":14.17438468680935,"y":927.5889495991248,"width":261.44597675311695,"height":115.17011205104869,"type":"bar_chart","id":"bar_chart-2"},{"x":335.53506958869815,"y":73.96993040555125,"width":1377.511892133632,"height":235.99805347796746,"type":"bar_chart","id":"bar_chart-4"},{"x":343.09907617641977,"y":309.0274507302416,"width":1403.329191417503,"height":244.41281907128635,"type":"line_chart","id":"line_chart-5"},{"x":300.5487875322987,"y":605.0457739804192,"width":1458.651359644421,"height":665.2952955126742,"type":"map","id":"map-7"},{"x":1770.89948812769,"y":499.31898960492595,"width":328.84945949524035,"height":340.4975638827368,"type":"pie_chart","id":"pie_chart-6"},{"x":16.73321977331341,"y":105.48825644660803,"width":202.08106525631322,"height":828.3796574169808,"type":"table","id":"table-0"}],"relations":[{"vislist":[{"vislist":["bar_chart-1","bar_chart-2","table-0"],"relation":null,"id":"group-0"}],"relation":"stacked","id":"relation-0"}]},"2333_0":{"comp":[["map","bar_chart",["stacked"]],["bar_chart","map",["stacked"]]],"visType":["map","bar_chart"],"compType":["stacked"],"compressed_tree":[{"composite_pattern":"stacked","visualization_type":[["map","bar_chart"]]}],"coOccurrence":[["map","bar_chart",["coOccurrence"]]],"year":2012,"conference":["VAST"],"authors":["Fred Olislagers","Marcel Worring"],"title":"The spatiotemporal multivariate hypercube for discovery of patterns in event data","doi":"10.1109/VAST.2012.6400536","abstract":"Event data can hold valuable decision making information, yet detecting interesting patterns in this type of data is not an easy task because the data is usually rich and contains spatial, temporal as well as multivariate dimensions. Research into visual analytics tools to support the discovery of patterns in event data often focuses on the spatiotemporal or spatiomultivariate dimension of the data only. Few research efforts focus on all three dimensions in one framework. An integral view on all three dimensions is, however, required to unlock the full potential of event datasets. In this poster, we present an event visualization, transition, and interaction framework that enables an integral view on all dimensions of spatiotemporal multivariate event data. The framework is built around the notion that the event data space can be considered a spatiotemporal multivariate hypercube. Results of a case study we performed suggest that a visual analytics tool based on the proposed framework is indeed capable to support users in the discovery of multidimensional spatiotemporal multivariate patterns in event data.","keywords":"","caption":"Figure 1 \u2013 The spatiotemporal multivariate hypercube: a metaphor for considering spatiotemporal multivariate event data in one integrated visualization, transition, and interaction framework to support the detection of multidimensional patterns.","img_size":{"width":627,"height":544},"subfigures":[{"x":9.842587031105808,"y":1.3677883959941068,"width":610.7903765848567,"height":538.369655210002,"type":"interface","id":"interface-0"}],"visualizations":[{"x":22.263790664780743,"y":107.72277227722773,"width":37.70297029702971,"height":337.01838755304107,"type":"bar_chart","id":"bar_chart-0"},{"x":252.32885431400283,"y":279.30975954738324,"width":322.3988684582744,"height":84.6393210749647,"type":"bar_chart","id":"bar_chart-1"},{"x":236.1704384724186,"y":366.25742574257424,"width":337.01838755304107,"height":53.09193776520504,"type":"bar_chart","id":"bar_chart-2"},{"x":111.519801980198,"y":429.3521923620934,"width":434.7383309759547,"height":101.56718528995754,"type":"bar_chart","id":"bar_chart-3"},{"x":283.10678925035353,"y":41.55021216407356,"width":292.39038189533244,"height":229.29561527581333,"type":"map","id":"map-4"},{"x":74.58628005657704,"y":48.47524752475247,"width":115.41725601131543,"height":377.02970297029697,"type":"map","id":"map-5"},{"x":196.9285714285714,"y":37.7029702970297,"width":53.09193776520504,"height":339.3267326732673,"type":"map","id":"map-6"}],"relations":[{"vislist":[{"vislist":["map-5","bar_chart-0","bar_chart-3"],"relation":null,"id":"group-1"}],"relation":"stacked","id":"relation-1"}]},"1833_0":{"comp":[["heatmap","parallel_coordinate",["stacked"]],["heatmap","scatterplot",["stacked"]],["parallel_coordinate","heatmap",["stacked"]],["parallel_coordinate","scatterplot",["stacked"]],["scatterplot","heatmap",["stacked"]],["scatterplot","parallel_coordinate",["stacked"]]],"visType":["heatmap","parallel_coordinate","scatterplot"],"compType":["stacked"],"compressed_tree":[{"composite_pattern":"stacked","visualization_type":[["heatmap","parallel_coordinate","scatterplot"]]}],"coOccurrence":[["heatmap","parallel_coordinate",["coOccurrence"]],["heatmap","scatterplot",["coOccurrence"]],["parallel_coordinate","scatterplot",["coOccurrence"]]],"year":2009,"conference":["VAST"],"authors":["Chad A. Steed","J. Edward Swan","T. J. Jankun-Kelly","Patrick J. Fitzpatrick"],"title":"Guided analysis of hurricane trends using statistical processes integrated with interactive parallel coordinates","doi":"10.1109/VAST.2009.5332586","abstract":"This paper demonstrates the promise of augmenting interactive multivariate representations with information from statistical processes in the domain of weather data analysis. Statistical regression, correlation analysis, and descriptive statistical calculations are integrated via graphical indicators into an enhanced parallel coordinates system, called the Multidimensional Data eXplorer (MDX). These statistical indicators, which highlight significant associations in the data, are complemented with interactive visual analysis capabilities. The resulting system allows a smooth, interactive, and highly visual workflow. The system\'s utility is demonstrated with an extensive hurricane climate study that was conducted by a hurricane expert. In the study, the expert used a new data set of environmental weather data, composed of 28 independent variables, to predict annual hurricane activity. MDX shows the Atlantic Meridional Mode increases the explained variance of hurricane seasonal activity by 7-15% and removes less significant variables used in earlier studies. The findings and feedback from the expert (1) validate the utility of the data set for hurricane prediction, and (2) indicate that the integration of statistical processes with interactive parallel coordinates, as implemented in MDX, addresses both deficiencies in traditional weather data analysis and exhibits some of the expected benefits of visual data analysis.","keywords":"Climate study, multivariate data, correlation, regression, interaction, statistical analysis, visual analytics","caption":"Figure 1: The MDX system developed in this research is composed of a settings panel (upper left), parallel coordinates panel (upper right), and a table view panel (lower). In this example, the mouse is used to highlight the AMM-June axis to examine its correlation with the other AMM variables. The correlation appears to be stronger for the months that are closer in time. This pattern is observed for all the AMM variables.","img_size":{"width":2115,"height":843},"subfigures":[{"x":8.744982721239566,"y":6.46979317876116,"width":2100.98036002865,"height":824.2765626150236,"type":"interface","id":"interface-0"}],"visualizations":[{"x":733.1682242990654,"y":508.0117751879849,"width":1319.4468455061296,"height":25.100374344725424,"type":"heatmap","id":"heatmap-0"},{"x":751.5514018691589,"y":149.69158878504672,"width":1281.570093457944,"height":359.785046728972,"type":"parallel_coordinate","id":"parallel_coordinate-1"},{"x":1397.588785046729,"y":525.2336448598131,"width":640.785046728972,"height":99.79439252336444,"type":"scatterplot","id":"scatterplot-2"},{"x":743.6728971962618,"y":522.607476635514,"width":533.1121495327104,"height":107.67289719626173,"type":"scatterplot","id":"scatterplot-3"},{"x":8.345794392523375,"y":688.0560747663551,"width":2072.046728971963,"height":141.81308411214957,"type":"table","id":"table-4"}],"relations":[{"vislist":[{"vislist":["heatmap-0","parallel_coordinate-1","scatterplot-2","scatterplot-3"],"relation":null,"id":"group-0"}],"relation":"stacked","id":"relation-0"}]},"1696_3":{"comp":[["line_chart","others",["stacked"]],["others","line_chart",["stacked"]]],"visType":["line_chart","others"],"compType":["stacked"],"compressed_tree":[{"composite_pattern":"stacked","visualization_type":[["line_chart","others"]]}],"coOccurrence":[["line_chart","others",["coOccurrence"]]],"year":2008,"conference":["InfoVis"],"authors":["Mario Romero","Jay Summet","John T. Stasko","Gregory D. Abowd"],"title":"Viz-A-Vis: Toward Visualizing Video through Computer Vision","doi":"10.1109/TVCG.2008.185","abstract":"In the established procedural model of information visualization, the first operation is to transform raw data into data tables. The transforms typically include abstractions that aggregate and segment relevant data and are usually defined by a human, user or programmer. The theme of this paper is that for video, data transforms should be supported by low level computer vision. High level reasoning still resides in the human analyst, while part of the low level perception is handled by the computer. To illustrate this approach, we present Viz-A-Vis, an overhead video capture and access system for activity analysis in natural settings over variable periods of time. Overhead video provides rich opportunities for long-term behavioral and occupancy analysis, but it poses considerable challenges. We present initial steps addressing two challenges. First, overhead video generates overwhelmingly large volumes of video impractical to analyze manually. Second, automatic video analysis remains an open problem for computer vision.","keywords":"Spatiotemporal visualization, time series data, video visualization, sensor analytics, image/video analytics","caption":"Fig. 4. Model of visualization and navigation for the activity cube. (a) Activity cube showing 5 aggregate 2D isocontour slices of motion across 80 minutes, (b) aggregation of motion across entire 80 minutes, (c) aggregation of motion across X (Y vs. T), (d) aggreagation of motion across Y (X vs. T), (e-f) aggregation of motion across X and Y, (g) aggregation of motion across Y and T, (h) aggregation of motion across X and T, (i) sub-space result of the query (X0<X<X1)&(Y0<Y>Y1)&T0<T<T1). The dynamic query is performed through double sided sliders on X (blue), Y (red), and T  (green). The fourth querying dimension is aggregate motion M (yellow).","img_size":{"width":1086,"height":901},"subfigures":[{"x":8.468153959657338,"y":8.158248998494438,"width":1075.0293350968116,"height":893.623961746122,"type":"single","id":"single-0"}],"visualizations":[{"x":139.96647509578543,"y":764.6417542216423,"width":683.833949263251,"height":130.5650274315154,"type":"line_chart","id":"line_chart-0"},{"x":46.759578544061355,"y":624.831409394056,"width":95.65293389217004,"height":138.31316840912345,"type":"line_chart","id":"line_chart-1"},{"x":723.0340699815838,"y":114.49171270718234,"width":86.28360957642735,"height":511.06445672191535,"type":"line_chart","id":"line_chart-2"},{"x":773.4281609195402,"y":15.534474528155563,"width":208.852490421456,"height":105.28927203065133,"type":"line_chart","id":"line_chart-3"},{"x":824.9309494519904,"y":125.49829834417902,"width":188.4186674062472,"height":506.23732560926396,"type":"others","id":"others-4"},{"x":148.31792263206694,"y":629.505961179428,"width":823.6064068698487,"height":135.13579304221412,"type":"others","id":"others-5"},{"x":36.04397428860776,"y":24.769131071847085,"width":657.9609966396271,"height":600.4030069395047,"type":"others","id":"others-6"}],"relations":[{"vislist":[{"vislist":["line_chart-0","line_chart-1","others-5","others-4","line_chart-2","line_chart-3"],"relation":null,"id":"group-0"}],"relation":"stacked","id":"relation-0"}]},"1718_0":{"comp":[["bar_chart","matrix",["stacked"]],["matrix","bar_chart",["stacked"]]],"visType":["bar_chart","matrix"],"compType":["stacked"],"compressed_tree":[{"composite_pattern":"stacked","visualization_type":[["bar_chart","matrix"]]}],"coOccurrence":[["bar_chart","matrix",["coOccurrence"]]],"year":2008,"conference":["VAST"],"authors":["Chris Weaver"],"title":"Multidimensional visual analysis using cross-filtered views","doi":"10.1109/VAST.2008.4677370","abstract":"Analysis of multidimensional data often requires careful examination of relationships across dimensions. Coordinated multiple view approaches have become commonplace in visual analysis tools because they directly support expression of complex multidimensional queries using simple interactions. However, generating such tools remains difficult because of the need to map domain-specific data structures and semantics into the idiosyncratic combinations of interdependent data and visual abstractions needed to reveal particular patterns and distributions in cross-dimensional relationships. This paper describes: (1) a method for interactively expressing sequences of multidimensional set queries by cross-filtering data values across pairs of views, and (2) design strategies for constructing coordinated multiple view interfaces for cross-filtered visual analysis of multidimensional data sets. Using examples of cross-filtered visualizations of data from several different domains, we describe how cross-filtering can be modularized and reused across designs, flexibly customized with respect to data types across multiple dimensions, and incorporated into more wide-ranging multiple view designs. The demonstrated analytic utility of these examples suggest that cross-filtering is a suitable design pattern for instantiation in a wide variety of visual analysis tools.","keywords":"","caption":"Figure 1: Cross-filtered visualization of geographic and temporal patterns in 150,000+ citations of political activity in international events reported by Agence France-Presse from May 1991 to January 2007. Cross-filtering on event source actor Iraq reveals a spike in conflictual events in early 2003. Further cross-filtering with military engagement as the chosen event type reveals the United States military as a frequent target actor.","img_size":{"width":2099,"height":1182},"subfigures":[{"x":3.7172352511522333,"y":1.6092775256403686,"width":2083.740861422517,"height":1177.478248079021,"type":"interface","id":"interface-0"}],"visualizations":[{"x":1473.5508474576268,"y":1048.4406779661015,"width":494.16949152542367,"height":55.649717514124404,"type":"bar_chart","id":"bar_chart-0"},{"x":1967.7203389830506,"y":153.59322033898303,"width":60.10169491525449,"height":892.6214689265536,"type":"bar_chart","id":"bar_chart-1"},{"x":68.95197740112992,"y":304.9604519774011,"width":69.00564971751406,"height":173.62711864406776,"type":"heatmap","id":"heatmap-2"},{"x":507.4230324738829,"y":257.2963293615368,"width":740.1215723116326,"height":149.09466797985712,"type":"heatmap","id":"heatmap-3"},{"x":509.69774011299427,"y":6.6779661016949134,"width":736.8022598870056,"height":142.46327683615817,"type":"heatmap","id":"heatmap-4"},{"x":140.15194041424314,"y":624.4824155496501,"width":265.2975033902174,"height":28.424732506094642,"type":"heatmap","id":"heatmap-5"},{"x":142.85905779577598,"y":754.424049863226,"width":265.2975033902174,"height":27.07117381532828,"type":"heatmap","id":"heatmap-6"},{"x":141.50549910500956,"y":721.9386412848321,"width":263.94394469945087,"height":27.07117381532828,"type":"heatmap","id":"heatmap-7"},{"x":1270.9858757062145,"y":124.65536723163841,"width":816.9378531073446,"height":1043.9887005649714,"type":"matrix","id":"matrix-8"},{"x":512.3805803750072,"y":424.1557293162208,"width":732.2752517046304,"height":430.43166366372,"type":"map","id":"map-9"},{"x":507.47175141242934,"y":908.2033898305083,"width":714.5423728813557,"height":264.89265536723144,"type":"table","id":"table-10"}],"relations":[{"vislist":[{"vislist":["bar_chart-1","bar_chart-0","matrix-8"],"relation":null,"id":"group-0"}],"relation":"stacked","id":"relation-0"}]},"1722_0":{"comp":[["comb","comb",["stacked"]],["bar_chart","bar_chart",["mirrored"]]],"visType":["comb","bar_chart"],"compType":["stacked","mirrored"],"compressed_tree":[{"composite_pattern":"stacked","visualization_type":[[{"composite_pattern":"mirrored","visualization_type":[["bar_chart"]]}]]}],"coOccurrence":[["bar_chart","bar_chart",["coOccurrence"]]],"year":2008,"conference":["VAST"],"authors":["Jaime Montemayor","Christopher P. Diehl","Michael Pekala","David Patrone"],"title":"Interactive poster - SocialRank: An ego- and time-centric workflow for relationship identification","doi":"10.1109/VAST.2008.4677375","abstract":"From instant messaging and email to wikis and blogs, millions of individuals are generating content that reflects their relationships with others in the world, both online and offline. Since communication artifacts are recordings of life events, we can gain insights into the social attributes and structures of the people within this communication history. In this paper, we describe SocialRank, an ego- and time-centric workflow for identifying social relationships in an email corpus. This workflow includes four high-level tasks: discovery, validation, annotation and dissemination. SocialRank combines relationship ranking algorithms with timeline, social network diagram, and multidimensional scaling visualization techniques to support these tasks.","keywords":"","caption":"Figure 1: The timeline viewer displays an ego\u2019s pairwise communi- cation relationships on a timeline. A supervisor ranking algorithm highlights (light shading and triangles) the time intervals that contain messages that are likely to express this relationship. After reading a message, if an analyst is satisfied that the content suggests a social relationship exists between the ego and alter, s/he can immediately create an annotated relationship (through a contextual menu) and assign the message as the validating evidence.","img_size":{"width":855,"height":537},"subfigures":[{"x":6.136413957603097,"y":2.498260469902403,"width":846.8730179982043,"height":533.187602104232,"type":"single","id":"single-0"}],"visualizations":[{"x":41.488549618320576,"y":84.7175572519084,"width":370.29770992366406,"height":355.2671755725192,"type":"bar_chart","id":"bar_chart-0"}],"relations":[{"vislist":[{"vislist":[{"vislist":[{"vislist":["bar_chart-0"],"relation":null,"id":"group-2"}],"relation":"mirrored","id":"relation-2"}],"relation":null,"id":"group-3"}],"relation":"stacked","id":"relation-3"}]},"1734_0":{"comp":[["bar_chart","line_chart",["stacked"]],["line_chart","bar_chart",["stacked"]]],"visType":["bar_chart","line_chart"],"compType":["stacked"],"compressed_tree":[{"composite_pattern":"stacked","visualization_type":[["bar_chart","line_chart"]]}],"coOccurrence":[["bar_chart","line_chart",["coOccurrence"]]],"year":2008,"conference":["VAST"],"authors":["Natalia V. Andrienko","Gennady L. Andrienko"],"title":"Evacuation trace Mini Challenge award: Tool integration analysis of movements with Geospatial Visual Analytics Toolkit","doi":"10.1109/VAST.2008.4677388","abstract":"The Geospatial Visual Analytics Toolkit intended for exploratory analysis of spatial and spatio-temporal data has been recently enriched with specific visual and computational techniques supporting analysis of data about movement. We applied these and other techniques to the data and tasks of Mini Challenge 4, where it was necessary to analyze tracks of moving people.CR Categories and Subject Descriptors: H.1.2 [User/Machine Systems]: Human information processing - Visual Analytics; 1.6.9 [Visualization]: information visualization.","keywords":"","caption":"Figure 1. The time graph and time histogram visualize path lengths by 1-unit time intervals from [365,366] to [380,381]. ","img_size":{"width":935,"height":752},"subfigures":[{"x":6.0092476971255575,"y":5.951179090776471,"width":923.8110030961585,"height":739.2685351805354,"type":"interface","id":"interface-0"}],"visualizations":[{"x":7.578774617067778,"y":353.78555798687086,"width":875.413566739606,"height":278.09190371991247,"type":"bar_chart","id":"bar_chart-0"},{"x":20.74288840262579,"y":80.63019693654267,"width":881.9956236323851,"height":255.054704595186,"type":"line_chart","id":"line_chart-1"}],"relations":[{"vislist":[{"vislist":["bar_chart-0","line_chart-1"],"relation":null,"id":"group-0"}],"relation":"stacked","id":"relation-0"}]},"1576_0":{"comp":[["bar_chart","heatmap",["stacked"]],["heatmap","bar_chart",["stacked"]]],"visType":["bar_chart","heatmap"],"compType":["stacked"],"compressed_tree":[{"composite_pattern":"stacked","visualization_type":[["bar_chart","heatmap"]]},{"composite_pattern":"stacked","visualization_type":[["bar_chart","heatmap"]]}],"coOccurrence":[["bar_chart","heatmap",["coOccurrence"]]],"year":2007,"conference":["VAST"],"authors":["Eun Ju Nam","Yiping Han","Klaus Mueller","Alla Zelenyuk","Dan Imre"],"title":"ClusterSculptor: A Visual Analytics Tool for High-Dimensional Data","doi":"10.1109/VAST.2007.4388999","abstract":"Cluster analysis (CA) is a powerful strategy for the exploration of high-dimensional data in the absence of a-priori hypotheses or data classification models, and the results of CA can then be used to form such models. But even though formal models and classification rules may not exist in these data exploration scenarios, domain scientists and experts generally have a vast amount of non-compiled knowledge and intuition that they can bring to bear in this effort. In CA, there are various popular mechanisms to generate the clusters, however, the results from their non- supervised deployment rarely fully agree with this expert knowledge and intuition. To this end, our paper describes a comprehensive and intuitive framework to aid scientists in the derivation of classification hierarchies in CA, using k-means as the overall clustering engine, but allowing them to tune its parameters interactively based on a non-distorted compact visual presentation of the inherent characteristics of the data in high- dimensional space. These include cluster geometry, composition, spatial relations to neighbors, and others. In essence, we provide all the tools necessary for a high-dimensional activity we call cluster sculpting, and the evolving hierarchy can then be viewed in a space-efficient radial dendrogram. We demonstrate our system in the context of the mining and classification of a large collection of millions of data items of aerosol mass spectra, but our framework readily applies to any high-dimensional CA scenario.","keywords":"Visual Analytics, High-Dimensional Data, Visual Data Mining, Visualization in Earth/Space/ and Environmental Sciences","caption":"Figure 1. The ClusterSculptor interface","img_size":{"width":2007,"height":1152},"subfigures":[{"x":6.801226263294678,"y":7.869902730893918,"width":1987.044588017468,"height":1137.5303153452235,"type":"interface","id":"interface-0"}],"visualizations":[{"x":1422.6390922401172,"y":271.5549048316252,"width":59.033674963396834,"height":509.37628111273796,"type":"bar_chart","id":"bar_chart-0"},{"x":548.9407027818448,"y":775.8711566617862,"width":877.0717423133236,"height":107.94729136163984,"type":"bar_chart","id":"bar_chart-1"},{"x":439.3067349926793,"y":266.49487554904834,"width":113.00732064421675,"height":512.7496339677891,"type":"bar_chart","id":"bar_chart-2"},{"x":545.5673499267937,"y":158.5475841874085,"width":883.8184480234261,"height":116.38067349926796,"type":"bar_chart","id":"bar_chart-3"},{"x":540.5073206442167,"y":266.49487554904834,"width":939.0620637904821,"height":516.1992616560519,"type":"heatmap","id":"heatmap-4"},{"x":547.2540263543192,"y":893.9385065885797,"width":885.5051244509518,"height":109.63396778916548,"type":"heatmap","id":"heatmap-5"}],"relations":[{"vislist":[{"vislist":["bar_chart-0","heatmap-4","bar_chart-2"],"relation":null,"id":"group-0"}],"relation":"stacked","id":"relation-0"},{"vislist":[{"vislist":["bar_chart-3","heatmap-4","bar_chart-1","heatmap-5"],"relation":null,"id":"group-1"}],"relation":"stacked","id":"relation-1"}]},"2092_5":{"comp":[["line_chart","scatterplot",["stacked"]],["scatterplot","line_chart",["stacked"]]],"visType":["line_chart","scatterplot"],"compType":["stacked"],"compressed_tree":[{"composite_pattern":"stacked","visualization_type":[["line_chart","scatterplot"]]}],"coOccurrence":[["line_chart","scatterplot",["coOccurrence"]]],"year":2011,"conference":["InfoVis"],"authors":["Johnny Rodgers","Lyn Bartram"],"title":"Exploring Ambient and Artistic Visualization for Residential Energy Use Feedback","doi":"10.1109/TVCG.2011.196","abstract":"Providing effective feedback on resource consumption in the home is a key challenge of environmental conservation efforts. One promising approach for providing feedback about residential energy consumption is the use of ambient and artistic visualizations. Pervasive computing technologies enable the integration of such feedback into the home in the form of distributed point-of-consumption feedback devices to support decision-making in everyday activities. However, introducing these devices into the home requires sensitivity to the domestic context. In this paper we describe three abstract visualizations and suggest four design requirements that this type of device must meet to be effective: pragmatic, aesthetic, ambient, and ecological. We report on the findings from a mixed methods user study that explores the viability of using ambient and artistic feedback in the home based on these requirements. Our findings suggest that this approach is a viable way to provide resource use feedback and that both the aesthetics of the representation and the context of use are important elements that must be considered in this design space.","keywords":"Ambient visualization, informative art, casual infovis, sustainability, distributed visualization","caption":"Fig. 6. One participant\u02bcs power use mapped to their attention events.","img_size":{"width":1059,"height":776},"subfigures":[{"x":8.178668995807303,"y":3.6192348037098045,"width":1026.949122414882,"height":772.0649715197221,"type":"single","id":"single-0"}],"visualizations":[{"x":17.103053435114475,"y":2.064225064374029,"width":1014.9211195928754,"height":771.871549871252,"type":"line_chart","id":"line_chart-0"},{"x":18.042425190950322,"y":628.6308778023794,"width":1014.6553919373072,"height":150.52135996095927,"type":"scatterplot","id":"scatterplot-1"}],"relations":[{"vislist":[{"vislist":["line_chart-0","scatterplot-1"],"relation":null,"id":"group-0"}],"relation":"stacked","id":"relation-0"}]},"3080_1":{"comp":[["comb","bar_chart",["stacked"]],["bar_chart","comb",["stacked"]],["area_chart","area_chart",["stacked"]]],"visType":["comb","bar_chart","area_chart"],"compType":["stacked"],"compressed_tree":[{"composite_pattern":"stacked","visualization_type":[[{"composite_pattern":"stacked","visualization_type":[["area_chart"]]},"bar_chart"]]}],"coOccurrence":[["area_chart","bar_chart",["coOccurrence"]]],"year":2018,"conference":["VAST"],"authors":["Nicole Sultanum","Devin Singh","Michael Brudno","Fanny Chevalier"],"title":"Doccurate: A Curation-Based Approach for Clinical Text Visualization","doi":"10.1109/TVCG.2018.2864905","abstract":"Before seeing a patient, physicians seek to obtain an overview of the patient\'s medical history. Text plays a major role in this activity since it represents the bulk of the clinical documentation, but reviewing it quickly becomes onerous when patient charts grow too large. Text visualization methods have been widely explored to manage this large scale through visual summaries that rely on information retrieval algorithms to structure text and make it amenable to visualization. However, the integration with such automated approaches comes with a number of limitations, including significant error rates and the need for healthcare providers to fine-tune algorithms without expert knowledge of their inner mechanics. In addition, several of these approaches obscure or substitute the original clinical text and therefore fail to leverage qualitative and rhetorical flavours of the clinical notes. These drawbacks have limited the adoption of text visualization and other summarization technologies in clinical practice. In this work we present Doccurate, a novel system embodying a curation-based approach for the visualization of large clinical text datasets. Our approach offers automation auditing and customizability to physicians while also preserving and extensively linking to the original text. We discuss findings of a formal qualitative evaluation conducted with 6 domain experts, shedding light onto physicians\' information needs, perceived strengths and limitations of automated tools, and the importance of customization while balancing efficiency. We also present use case scenarios to showcase Doccurate\'s envisioned usage in practice.","keywords":"Visual Curation,Clinical Text,Text Visualization,Medical Narrative","caption":"Fig. 2. Doccurate\u2019s interface: (A) Control Panel with Demographics (A.1), options to adjust the Timeline\u2019s binning interval and the visible documents types in the Text Panel (A.2), and the complete list of FCs sorted by frequency (A.3); (B) Timeline with breadcrumbs indicating level of detail (B.1), scrollable list of items encompassed by the current level (B.3); items tracks with frequency streams and representative labels (B.5), a dark line marker indicating time of current visible document (B.2) and time axis, featuring a document histogram (B.4); (C) Text Panel, with the double text overview bar and respectivedocument counts at the bottom (C.1), and all visible chart documents (C.2); (D) Curation Panel for a selected FC, with subpanels for the list of codes (D.1), hierarchy adjustment for a selected code (D.2), list of keywords (D.3) and colour/title editing (D.4).","img_size":{"width":2157,"height":1381},"subfigures":[{"x":17.107766441113245,"y":18.543651116154578,"width":2075.413022811689,"height":1333.2085409211104,"type":"interface","id":"interface-0"}],"visualizations":[{"x":284.0449679106982,"y":83.1499740268755,"width":603.6945861816379,"height":911.6336225275072,"type":"area_chart","id":"area_chart-5"},{"x":888.0509193776521,"y":193.37906647807625,"width":54.693069306930724,"height":791.0961810466762,"type":"bar_chart","id":"bar_chart-0"},{"x":1081.4299858557283,"y":72.27298444130118,"width":50.786421499292835,"height":951.2687411598304,"type":"bar_chart","id":"bar_chart-1"},{"x":943.3419080952295,"y":105.47949080622341,"width":138.1771664393471,"height":921.9688826025457,"type":"bar_chart","id":"bar_chart-2"},{"x":298.20515212613867,"y":1087.2671692138908,"width":462.45084901023813,"height":235.2533246801652,"type":"proportional_area_chart","id":"proportional_area_chart-4"},{"x":1118.5431400282885,"y":78.13295615275801,"width":46.87977369165491,"height":916.1089108910891,"type":"stripe_graph","id":"stripe_graph-3"}],"relations":[{"vislist":[{"vislist":[{"vislist":[{"vislist":["area_chart-5"],"relation":null,"id":"group-1"}],"relation":"stacked","id":"relation-0"},"bar_chart-0"],"relation":null,"id":"group-2"}],"relation":"stacked","id":"relation-1"}]},"2459_0":{"comp":[["bar_chart","matrix",["stacked"]],["bar_chart","box_plot",["stacked"]],["matrix","bar_chart",["stacked"]],["matrix","box_plot",["stacked"]],["box_plot","bar_chart",["stacked"]],["box_plot","matrix",["stacked"]]],"visType":["bar_chart","matrix","box_plot"],"compType":["stacked"],"compressed_tree":[{"composite_pattern":"stacked","visualization_type":[["bar_chart","matrix","box_plot"]]}],"coOccurrence":[["bar_chart","matrix",["coOccurrence"]],["bar_chart","box_plot",["coOccurrence"]],["matrix","box_plot",["coOccurrence"]]],"year":2014,"conference":["InfoVis"],"authors":["Alexander Lex","Nils Gehlenborg","Hendrik Strobelt","Romain Vuillemot","Hanspeter Pfister"],"title":"UpSet: Visualization of Intersecting Sets","doi":"10.1109/TVCG.2014.2346248","abstract":"Understanding relationships between sets is an important analysis task that has received widespread attention in the visualization community. The major challenge in this context is the combinatorial explosion of the number of set intersections if the number of sets exceeds a trivial threshold. In this paper we introduce UpSet, a novel visualization technique for the quantitative analysis of sets, their intersections, and aggregates of intersections. UpSet is focused on creating task-driven aggregates, communicating the size and properties of aggregates and intersections, and a duality between the visualization of the elements in a dataset and their set membership. UpSet visualizes set intersections in a matrix layout and introduces aggregates based on groupings and queries. The matrix layout enables the effective representation of associated data, such as the number of elements in the aggregates and intersections, as well as additional summary statistics derived from subset or element attributes. Sorting according to various measures enables a task-driven analysis of relevant intersections and aggregates. The elements represented in the sets and their associated attributes are visualized in a separate view. Queries based on containment in specific intersections, aggregates or driven by attribute filters are propagated between both views. We also introduce several advanced visual encodings and interaction methods to overcome the problems of varying scales and to address scalability. UpSet is web-based and open source. We demonstrate its general utility in multiple use cases from various domains.","keywords":"Sets, set visualization, sets intersections, set attributes, set relationships, multidimensional data","caption":"Fig. 1. UpSet showing relationships of movie genres. The set view visualizes intersections and their aggregates, the number of elements, and attribute statistics. The element view shows \ufb01ltered elements and a scatterplot comparing two sets of \ufb01ltered elements.","img_size":{"width":1956,"height":936},"subfigures":[{"x":9.433842169743311,"y":6.751038589092045,"width":1930.028830275841,"height":835.8259522270768,"type":"interface","id":"interface-0"}],"visualizations":[{"x":14.859971711456895,"y":1.2100874696726276,"width":418.35360678925036,"height":85.9296426465251,"type":"bar_chart","id":"bar_chart-0"},{"x":393.75224465663325,"y":125.77086280056577,"width":469.38576161658887,"height":709.6124469589818,"type":"bar_chart","id":"bar_chart-1"},{"x":880.6930693069309,"y":121.79915134370582,"width":460.7185289957566,"height":710.9363507779348,"type":"box_plot","id":"box_plot-2"},{"x":17.507779349363513,"y":124.23006725686899,"width":357.4540311173968,"height":707.969997482067,"type":"matrix","id":"matrix-3"},{"x":1357.2984441301276,"y":47.6605374823196,"width":369.36916548797745,"height":234.33097595473853,"type":"scatterplot","id":"scatterplot-4"},{"x":1361.2701555869876,"y":644.7411598302687,"width":571.9264497878362,"height":197.2616690240452,"type":"table","id":"table-5"}],"relations":[{"vislist":[{"vislist":["bar_chart-0","matrix-3","bar_chart-1","box_plot-2"],"relation":null,"id":"group-0"}],"relation":"stacked","id":"relation-0"}]},"2459_12":{"comp":[["bar_chart","matrix",["stacked"]],["matrix","bar_chart",["stacked"]]],"visType":["bar_chart","matrix"],"compType":["stacked"],"compressed_tree":[{"composite_pattern":"stacked","visualization_type":[["bar_chart","matrix"]]}],"coOccurrence":[["bar_chart","matrix",["coOccurrence"]]],"year":2014,"conference":["InfoVis"],"authors":["Alexander Lex","Nils Gehlenborg","Hendrik Strobelt","Romain Vuillemot","Hanspeter Pfister"],"title":"UpSet: Visualization of Intersecting Sets","doi":"10.1109/TVCG.2014.2346248","abstract":"Understanding relationships between sets is an important analysis task that has received widespread attention in the visualization community. The major challenge in this context is the combinatorial explosion of the number of set intersections if the number of sets exceeds a trivial threshold. In this paper we introduce UpSet, a novel visualization technique for the quantitative analysis of sets, their intersections, and aggregates of intersections. UpSet is focused on creating task-driven aggregates, communicating the size and properties of aggregates and intersections, and a duality between the visualization of the elements in a dataset and their set membership. UpSet visualizes set intersections in a matrix layout and introduces aggregates based on groupings and queries. The matrix layout enables the effective representation of associated data, such as the number of elements in the aggregates and intersections, as well as additional summary statistics derived from subset or element attributes. Sorting according to various measures enables a task-driven analysis of relevant intersections and aggregates. The elements represented in the sets and their associated attributes are visualized in a separate view. Queries based on containment in specific intersections, aggregates or driven by attribute filters are propagated between both views. We also introduce several advanced visual encodings and interaction methods to overcome the problems of varying scales and to address scalability. UpSet is web-based and open source. We demonstrate its general utility in multiple use cases from various domains.","keywords":"Sets, set visualization, sets intersections, set attributes, set relationships, multidimensional data","caption":"Fig. 13. Genomic variant case study. The set view shows an aggre-gation by degree. The element view shows two queries corresponding to the variants reported by all active tool combinations (degree 4) and those only identified byM/S.Q20. The variant frequency plot with nu-cleotide change matrix (blue query on the left, green query on the right) and transition/transversion ratios indicate that the green query contains mostly variant calls of low quality.","img_size":{"width":1064,"height":708},"subfigures":[{"x":7.270272481718793,"y":8.172048777340688,"width":1049.4594550365625,"height":695.5241443005359,"type":"interface","id":"interface-0"}],"visualizations":[{"x":145.95473833097589,"y":56.079207920792065,"width":296.41867043847236,"height":142.2008486562942,"type":"bar_chart","id":"bar_chart-0"},{"x":150.96181046676088,"y":203.28712871287127,"width":340.4809052333805,"height":494.69872701555863,"type":"bar_chart","id":"bar_chart-1"},{"x":575.5615275813295,"y":131.18528995756714,"width":111.15700141442721,"height":114.16124469589816,"type":"matrix","id":"matrix-2"},{"x":732.7835926449786,"y":133.18811881188117,"width":109.15417256011324,"height":112.15841584158417,"type":"matrix","id":"matrix-3"},{"x":235.08062234794903,"y":274.38755304101835,"width":81.11456859971712,"height":92.13012729844417,"type":"matrix","id":"matrix-4"},{"x":234.07920792079207,"y":390.5516265912305,"width":84.1188118811881,"height":142.20084865629417,"type":"matrix","id":"matrix-5"},{"x":234.07920792079207,"y":554.7835926449786,"width":80.11315417256003,"height":95.13437057991517,"type":"matrix","id":"matrix-6"},{"x":569.5530410183874,"y":537.7595473833096,"width":481.68033946251785,"height":163.23055162659122,"type":"table","id":"table-7"}],"relations":[{"vislist":[{"vislist":["bar_chart-0","matrix-5","matrix-4","matrix-6","bar_chart-1"],"relation":null,"id":"group-0"}],"relation":"stacked","id":"relation-0"}]},"2476_0":{"comp":[["heatmap","tree",["stacked"]],["heatmap","stripe_graph",["stacked"]],["heatmap","others",["stacked"]],["tree","heatmap",["stacked"]],["tree","stripe_graph",["stacked"]],["tree","others",["stacked"]],["stripe_graph","heatmap",["stacked"]],["stripe_graph","tree",["stacked"]],["stripe_graph","others",["stacked"]],["others","heatmap",["stacked"]],["others","tree",["stacked"]],["others","stripe_graph",["stacked"]]],"visType":["heatmap","tree","stripe_graph","others"],"compType":["stacked"],"compressed_tree":[{"composite_pattern":"stacked","visualization_type":[["heatmap","tree","stripe_graph","others"]]}],"coOccurrence":[["heatmap","tree",["coOccurrence"]]],"year":2014,"conference":["InfoVis"],"authors":["Ali K. Al-Awami","Johanna Beyer","Hendrik Strobelt","Narayanan Kasthuri","Jeff Lichtman","Hanspeter Pfister","Markus Hadwiger"],"title":"NeuroLines: A Subway Map Metaphor for Visualizing Nanoscale Neuronal Connectivity","doi":"10.1109/TVCG.2014.2346312","abstract":"We present NeuroLines, a novel visualization technique designed for scalable detailed analysis of neuronal connectivity at the nanoscale level. The topology of 3D brain tissue data is abstracted into a multi-scale, relative distance-preserving subway map visualization that allows domain scientists to conduct an interactive analysis of neurons and their connectivity. Nanoscale connectomics aims at reverse-engineering the wiring of the brain. Reconstructing and analyzing the detailed connectivity of neurons and neurites (axons, dendrites) will be crucial for understanding the brain and its development and diseases. However, the enormous scale and complexity of nanoscale neuronal connectivity pose big challenges to existing visualization techniques in terms of scalability. NeuroLines offers a scalable visualization framework that can interactively render thousands of neurites, and that supports the detailed analysis of neuronal structures and their connectivity. We describe and analyze the design of NeuroLines based on two real-world use-cases of our collaborators in developmental neuroscience, and investigate its scalability to large-scale neuronal connectivity data.","keywords":"Connectomics, Neuroscience, Data Abstraction, Multi-Trees, Focus+Context","caption":"Fig. 1: NeuroLines neurite visualization. We abstract the original 3D structure and topology of neurites segmented in nanoscale brain tissue data into a 2D subway map visualization that preserves topology and relative distances. Left: Volume rendering of a dendrite (red) and connected axons (blue). Right: NeuroLines abstraction of the same data, represented as subway lines to more clearly show branches, clusters of adjacent synapses, individual synapses, and the actual connections (shown on demand).","img_size":{"width":1789,"height":510},"subfigures":[{"x":799.6599063046096,"y":26.00276245072581,"width":979.715595850127,"height":450.1890471969999,"type":"single","id":"single-0"}],"visualizations":[{"x":907.1281396369254,"y":34.8834346759206,"width":867.4269976523542,"height":430.26324751430997,"type":"others","id":"others-1"},{"x":6.44729353551131,"y":17.04360938064298,"width":531.0565463221851,"height":471.1680026642364,"type":"scivis","id":"scivis-2"},{"x":813.4918970448045,"y":29.030028598665385,"width":57.98474737845572,"height":434.8856053384176,"type":"stripe_graph","id":"stripe_graph-0"}],"relations":[{"vislist":[{"vislist":["heatmap-0","tree-2","stripe_graph-0","others-1"],"relation":null,"id":"group-1"}],"relation":"stacked","id":"relation-0"}]},"2566_0":{"comp":[["others","line_chart",["stacked"]],["line_chart","others",["stacked"]]],"visType":["others","line_chart"],"compType":["stacked"],"compressed_tree":[{"composite_pattern":"stacked","visualization_type":[["others","line_chart"]]}],"coOccurrence":[],"year":2014,"conference":["VAST"],"authors":["Guodao Sun","Yingcai Wu","Shixia Liu","Tai-Quan Peng","Jonathan J. H. Zhu","Ronghua Liang"],"title":"EvoRiver: Visual Analysis of Topic Coopetition on Social Media","doi":"10.1109/TVCG.2014.2346919","abstract":"Cooperation and competition (jointly called \u201ccoopetition\u201d) are two modes of interactions among a set of concurrent topics on social media. How do topics cooperate or compete with each other to gain public attention? Which topics tend to cooperate or compete with one another? Who plays the key role in coopetition-related interactions? We answer these intricate questions by proposing a visual analytics system that facilitates the in-depth analysis of topic coopetition on social media. We model the complex interactions among topics as a combination of carry-over, coopetition recruitment, and coopetition distraction effects. This model provides a close functional approximation of the coopetition process by depicting how different groups of influential users (i.e., \u201ctopic leaders\u201d) affect coopetition. We also design EvoRiver, a time-based visualization, that allows users to explore coopetition-related interactions and to detect dynamically evolving patterns, as well as their major causes. We test our model and demonstrate the usefulness of our system based on two Twitter data sets (social topics data and business topics data).","keywords":"Topic coopetition, information diffusion, information propagation, time-based visualization","caption":"Fig. 1. (a) Topic coopetition dynamics during the 2012 U.S. presidential election with EvoRiver, showing most of the topics were transiting from competition to cooperation during that time; (b) playfair-style chart of spending and job to unfold their coopetition power; (c) pairwise similarity between international issues and other topics with connected arcs; (d) word cloud of international issues.","img_size":{"width":1961,"height":746},"subfigures":[{"x":1574.4041292435193,"y":76.36687348135357,"width":363.2857128875327,"height":614.6379564315747,"type":"interface","id":"interface-2"},{"x":18.605838749779778,"y":4.369814760164237,"width":1174.591418053219,"height":685.9682823333926,"type":"single","id":"single-0"},{"x":1222.33027470041,"y":82.05309544825029,"width":355.2690641341891,"height":613.2389740817795,"type":"single","id":"single-1"}],"visualizations":[{"x":5.946854045617227,"y":545.737787996218,"width":1202.0586728611436,"height":157.03831289645498,"type":"line_chart","id":"line_chart-3"},{"x":13.99723756906088,"y":64.58912804233296,"width":1193.8747697974209,"height":474.7142393112825,"type":"others","id":"others-0"},{"x":1216.389847074327,"y":74.37367104440276,"width":349.4840768590171,"height":611.9693558474036,"type":"others","id":"others-1"},{"x":1579.96066298281,"y":73.8450007959439,"width":359.15715727953085,"height":622.4859243340364,"type":"others","id":"others-5"},{"x":1317.6938677875592,"y":142.87962334026753,"width":159.12372826967928,"height":468.87501257872424,"type":"others","id":"others-7"},{"x":1654.3729281767953,"y":413.5285451197053,"width":247.29281767955806,"height":262.4051565377532,"type":"word_cloud","id":"word_cloud-2"}],"relations":[{"vislist":[{"vislist":["others-0","line_chart-3"],"relation":null,"id":"group-0"}],"relation":"stacked","id":"relation-0"}]},"2564_0":{"comp":[["bar_chart","others",["stacked"]],["others","bar_chart",["stacked"]]],"visType":["bar_chart","others"],"compType":["stacked"],"compressed_tree":[{"composite_pattern":"stacked","visualization_type":[["bar_chart","others"]]}],"coOccurrence":[["bar_chart","others",["coOccurrence"]]],"year":2014,"conference":["VAST"],"authors":["Conglei Shi","Yingcai Wu","Shixia Liu","Hong Zhou","Huamin Qu"],"title":"LoyalTracker: Visualizing Loyalty Dynamics in Search Engines","doi":"10.1109/TVCG.2014.2346912","abstract":"The huge amount of user log data collected by search engine providers creates new opportunities to understand user loyalty and defection behavior at an unprecedented scale. However, this also poses a great challenge to analyze the behavior and glean insights into the complex, large data. In this paper, we introduce LoyalTracker, a visual analytics system to track user loyalty and switching behavior towards multiple search engines from the vast amount of user log data. We propose a new interactive visualization technique (flow view) based on a flow metaphor, which conveys a proper visual summary of the dynamics of user loyalty of thousands of users over time. Two other visualization techniques, a density map and a word cloud, are integrated to enable analysts to gain further insights into the patterns identified by the flow view. Case studies and the interview with domain experts are conducted to demonstrate the usefulness of our technique in understanding user loyalty and switching behavior in search engines.","keywords":"Time-series visualization, stacked graphs, log data visualization, text visualization","caption":"Fig. 1: LoyalTracker illustrates loyalty dynamics of the users using search engine A. Top and bottom show the same flow view that highlights two different flowing patterns of the users (in orange) selected from a layer flow (top) and a branch flow (bottom) across multiple loyalty categories (layers) over time. The switching histogram on the top shows a visual summary of switching behavior.","img_size":{"width":1809,"height":429},"subfigures":[{"x":7.438282684560041,"y":9.26804748023991,"width":1794.123434630881,"height":409.15220768295507,"type":"single","id":"single-0"}],"visualizations":[{"x":12.564324695634996,"y":0.795718281586961,"width":1787.0626504897682,"height":93.8248435878418,"type":"bar_chart","id":"bar_chart-2"},{"x":125.31879409878125,"y":274.2584990378447,"width":921.3252084669662,"height":142.72418216805647,"type":"others","id":"others-0"},{"x":3.988587656324413,"y":103.09177212231717,"width":1801.0228246873507,"height":191.65762135199802,"type":"others","id":"others-1"}],"relations":[{"vislist":[{"vislist":["bar_chart-2","others-1"],"relation":null,"id":"group-0"}],"relation":"stacked","id":"relation-0"}]},"2371_7":{"comp":[["bar_chart","bar_chart",["stacked"]]],"visType":["bar_chart"],"compType":["stacked"],"compressed_tree":[{"composite_pattern":"stacked","visualization_type":[["bar_chart"]]}],"coOccurrence":[["bar_chart","bar_chart",["coOccurrence"]]],"year":2013,"conference":["InfoVis"],"authors":["Alexander Lex","Christian Partl","Denis Kalkofen","Marc Streit","Samuel Gratzl","Anne Mai Wassermann","Dieter Schmalstieg","Hanspeter Pfister"],"title":"Entourage: Visualizing Relationships between Biological Pathways using Contextual Subsets","doi":"10.1109/TVCG.2013.154","abstract":"Biological pathway maps are highly relevant tools for many tasks in molecular biology. They reduce the complexity of the overall biological network by partitioning it into smaller manageable parts. While this reduction of complexity is their biggest strength, it is, at the same time, their biggest weakness. By removing what is deemed not important for the primary function of the pathway, biologists lose the ability to follow and understand cross-talks between pathways. Considering these cross-talks is, however, critical in many analysis scenarios, such as judging effects of drugs. In this paper we introduce Entourage, a novel visualization technique that provides contextual information lost due to the artificial partitioning of the biological network, but at the same time limits the presented information to what is relevant to the analyst\'s task. We use one pathway map as the focus of an analysis and allow a larger set of contextual pathways. For these context pathways we only show the contextual subsets, i.e., the parts of the graph that are relevant to a selection. Entourage suggests related pathways based on similarities and highlights parts of a pathway that are interesting in terms of mapped experimental data. We visualize interdependencies between pathways using stubs of visual links, which we found effective yet not obtrusive. By combining this approach with visualization of experimental data, we can provide domain experts with a highly valuable tool. We demonstrate the utility of Entourage with case studies conducted with a biochemist who researches the effects of drugs on pathways. We show that the technique is well suited to investigate interdependencies between pathways and to analyze, understand, and predict the effect that drugs have on different cell types.","keywords":"Pathway visualization, biological networks, subsets, graphs, biomolecular data","caption":"Fig. 8. TNF-alpha (the focus node) was originally explored as a target for the Graft-Versus-Host Disease (GVHD, top-right pathway). However, when tested in clinical trials, TNF-alpha inhibiting compounds were not effective against GVHD but could later be repositioned for the treatment of Rheumatoid Arthritis (focus pathway). Entourage shows Rheumatoid Athritis as closely related to the GVHD pathway (see pathway list on the left). Entourage also reveals seemingly contradictory roles of TNF-alpha. It is involved in cell death (Apoptosis) and also in cancer (i.e., uncontrolled cell growth) through the MAPK signaling pathway.","img_size":{"width":1917,"height":920},"subfigures":[{"x":-3.8297750872014613,"y":7.829192216789976,"width":1916.666544225145,"height":899.3511224212839,"type":"interface","id":"interface-0"}],"visualizations":[{"x":3.350498338870367,"y":100.63628132721048,"width":215.48172757475086,"height":787.7025099286874,"type":"bar_chart","id":"bar_chart-0"},{"x":3.3504983388703633,"y":36.244658261206354,"width":215.48172757475078,"height":63.719579280848684,"type":"bar_chart","id":"bar_chart-1"},{"x":240.22757475083048,"y":93.22259136212624,"width":1412.0930232558142,"height":783.986710963455,"type":"graph","id":"graph-13"},{"x":1663.0182724252493,"y":61.129568106312306,"width":242.99003322259134,"height":108.5049833887043,"type":"graph","id":"graph-14"},{"x":1656.9053156146174,"y":288.8372093023256,"width":235.34883720930225,"height":181.86046511627913,"type":"graph","id":"graph-15"},{"x":1664.3052665283094,"y":687.3027189171526,"width":109.2065872295063,"height":207.52529669612113,"type":"graph","id":"graph-16"},{"x":1674.1753545633235,"y":486.75443502042367,"width":98.88296104057936,"height":124.02948075632231,"type":"graph","id":"graph-17"}],"relations":[{"vislist":[{"vislist":["bar_chart-0","bar_chart-1"],"relation":null,"id":"group-3"}],"relation":"stacked","id":"relation-2"}]},"1433_10":{"comp":[["bar_chart","matrix",["stacked"]],["matrix","bar_chart",["stacked"]]],"visType":["bar_chart","matrix"],"compType":["stacked"],"compressed_tree":[{"composite_pattern":"stacked","visualization_type":[["bar_chart","matrix"]]}],"coOccurrence":[["bar_chart","matrix",["coOccurrence"]]],"year":2006,"conference":["InfoVis"],"authors":["Nathalie Henry Riche","Jean-Daniel Fekete"],"title":"MatrixExplorer: a Dual-Representation System to Explore Social Networks","doi":"10.1109/TVCG.2006.160","abstract":"MatrixExplorer is a network visualization system that uses two representations: node-link diagrams and matrices. Its design comes from a list of requirements formalized after several interviews and a participatory design session conducted with social science researchers. Although matrices are commonly used in social networks analysis, very few systems support the matrix-based representations to visualize and analyze networks. MatrixExplorer provides several novel features to support the exploration of social networks with a matrix-based representation, in addition to the standard interactive filtering and clustering functions. It provides tools to reorder (layout) matrices, to annotate and compare findings across different layouts and find consensus among several clusterings. MatrixExplorer also supports node-link diagram views which are familiar to most users and remain a convenient way to publish or communicate exploration results. Matrix and node-link representations are kept synchronized at all stages of the exploration process","keywords":"social networks visualization, node-link diagrams, matrix-based representations, exploratory process, matrix ordering, interactive clustering, consensus","caption":"Fig. 11. Consensus between TSP (left) and HCS (right).  We observed that a consensus exists for A, B and C. However, B is slightly different and lost some of its elements with HCS.","img_size":{"width":1073,"height":694},"subfigures":[{"x":14.03694307797941,"y":12.5109956193861,"width":1046.1389041792445,"height":678.6905287381995,"type":"single","id":"single-0"}],"visualizations":[{"x":106.37164156015784,"y":19.475486505541372,"width":426.693338151297,"height":93.14653930750626,"type":"bar_chart","id":"bar_chart-0"},{"x":19.3892114715307,"y":110.56732274008792,"width":85.29186801595228,"height":568.5386446230868,"type":"bar_chart","id":"bar_chart-1"},{"x":534.0709278619806,"y":223.4601364040014,"width":204.51989848750603,"height":459.563854451516,"type":"bar_chart","id":"bar_chart-2"},{"x":740.443161394207,"y":21.74037989035125,"width":311.19228751301944,"height":203.75685491923895,"type":"bar_chart","id":"bar_chart-3"},{"x":740.4263721552878,"y":21.36813922356086,"width":310.30254350736266,"height":200.67469879518075,"type":"heatmap","id":"heatmap-4"},{"x":535.1064257028113,"y":225.75903614457832,"width":202.532797858099,"height":452.4471218206159,"type":"heatmap","id":"heatmap-5"},{"x":737.6392235609103,"y":223.90093708165995,"width":315.8768406961179,"height":455.23427041499343,"type":"matrix","id":"matrix-6"},{"x":535.1064257028113,"y":19.51004016064252,"width":140.28647925033465,"height":203.46184738955824,"type":"matrix","id":"matrix-7"},{"x":105.88554216867462,"y":109.62784471218202,"width":426.4337349397591,"height":571.3654618473897,"type":"matrix","id":"matrix-8"},{"x":17.625836680053453,"y":21.36813922356086,"width":66.89156626506022,"height":88.25970548862117,"type":"matrix","id":"matrix-9"}],"relations":[{"vislist":[{"vislist":["bar_chart-0","bar_chart-1","matrix-8"],"relation":null,"id":"group-0"}],"relation":"stacked","id":"relation-0"}]},"1463_8":{"comp":[["bar_chart","others",["stacked"]],["others","bar_chart",["stacked"]]],"visType":["bar_chart","others"],"compType":["stacked"],"compressed_tree":[{"composite_pattern":"stacked","visualization_type":[["bar_chart","others"]]}],"coOccurrence":[["bar_chart","others",["coOccurrence"]]],"year":2006,"conference":["VAST"],"authors":["David Gotz","Michelle X. Zhou","Vikram Aggarwal"],"title":"Interactive Visual Synthesis of Analytic Knowledge","doi":"10.1109/VAST.2006.261430","abstract":"A visual investigation involves both the examination of existing information and the synthesis of new analytic knowledge. This is a progressive process in which newly synthesized knowledge becomes the foundation for future discovery. In this paper, we present a novel system supporting interactive, progressive synthesis of analytic knowledge. Here we use the term \\"analytic knowledge\\" to refer to concepts that a user derives from existing data along with the evidence supporting such concepts. Unlike existing visual analytic-tools, which typically support only exploration of existing information, our system offers two unique features. First, we support user-system cooperative visual synthesis of analytic knowledge from existing data. Specifically, users can visually define new concepts by annotating existing information, and refine partially formed concepts by linking additional evidence or manipulating related concepts. In response to user actions, our system can automatically manage the evolving corpus of synthesized knowledge and its corresponding evidence. Second, we support progressive visual analysis of synthesized knowledge. This feature allows analysts to visually explore both existing knowledge and synthesized knowledge, dynamically incorporating earlier analytic conclusions into the ensuing discovery process. We have applied our system to two complex but very different analytic applications. Our preliminary evaluation shows the promise of our work","keywords":"Visual Analytics, Intelligence analysis, Problem solving environments, Visual Knowledge Discovery","caption":"Figure 10: A screen shot from the HARVEST prototype for analyzing organizational communications data in our \ufb01rst case study.","img_size":{"width":991,"height":681},"subfigures":[{"x":6.870608604344801,"y":7.677563660707654,"width":975.7512507328748,"height":666.3989360707965,"type":"interface","id":"interface-0"}],"visualizations":[{"x":258.9532710280374,"y":564.3177570093458,"width":717.0654205607478,"height":65.76635514018687,"type":"bar_chart","id":"bar_chart-0"},{"x":264.81025117062364,"y":58.895509423837034,"width":712.4786769258915,"height":498.0963083987193,"type":"others","id":"others-1"}],"relations":[{"vislist":[{"vislist":["bar_chart-0","others-1"],"relation":null,"id":"group-0"}],"relation":"stacked","id":"relation-0"}]},"1935_6":{"comp":[["others","map",["annotated"]]],"visType":["others","map"],"compType":["annotated"],"compressed_tree":[{"composite_pattern":"annotated","visualization_type":[["others"],["map"]]}],"coOccurrence":[["others","map",["coOccurrence"]]],"year":2009,"conference":["Vis"],"authors":["Heike Leitte","Michael B\xf6ttinger","Uwe Mikolajewicz","Gerik Scheuermann"],"title":"Visual Exploration of Climate Variability Changes Using Wavelet Analysis","doi":"10.1109/TVCG.2009.197","abstract":"Due to its nonlinear nature, the climate system shows quite high natural variability on different time scales, including multiyear oscillations such as the El Nino southern oscillation phenomenon. Beside a shift of the mean states and of extreme values of climate variables, climate change may also change the frequency or the spatial patterns of these natural climate variations. Wavelet analysis is a well established tool to investigate variability in the frequency domain. However, due to the size and complexity of the analysis results, only few time series are commonly analyzed concurrently. In this paper we will explore different techniques to visually assist the user in the analysis of variability and variability changes to allow for a holistic analysis of a global climate model data set consisting of several variables and extending over 250 years. Our new framework and data from the IPCC AR4 simulations with the coupled climate model ECHAM5/MPI-OM are used to explore the temporal evolution of El Nino due to climate change.","keywords":"Wavelet analysis, multivariate data, time-dependent data, climate variability change visualization, El Nino","caption":"Fig. 7. Main window of the wavelet analysis application.","img_size":{"width":1052,"height":712},"subfigures":[{"x":3.6204692273243775,"y":6.327207073413432,"width":1046.2735838448705,"height":703.1343263211572,"type":"interface","id":"interface-0"}],"visualizations":[{"x":112.94497555431509,"y":104.70893864349553,"width":898.8071192683041,"height":523.7990693337188,"type":"map","id":"map-0"},{"x":447.5703413944518,"y":270.3422099354436,"width":317.39868096015766,"height":320.5919545676779,"type":"others","id":"others-1"}],"relations":[{"vislist":[{"vislist":["others-1"],"relation":null,"id":"group-1"},{"vislist":["map-0"],"relation":null,"id":"group-0"}],"relation":"annotated","id":"relation-0"}]},"1683_4":{"comp":[["parallel_coordinate","map",["annotated"]]],"visType":["parallel_coordinate","map"],"compType":["annotated"],"compressed_tree":[{"composite_pattern":"annotated","visualization_type":[["parallel_coordinate"],["map"]]}],"coOccurrence":[["parallel_coordinate","map",["coOccurrence"]]],"year":2008,"conference":["InfoVis"],"authors":["Thomas Butkiewicz","Wenwen Dou","Zachary Wartell","William Ribarsky","Remco Chang"],"title":"Multi-Focused Geospatial Analysis Using Probes","doi":"10.1109/TVCG.2008.149","abstract":"Traditional geospatial information visualizations often present views that restrict the user to a single perspective. When zoomed out, local trends and anomalies become suppressed and lost; when zoomed in for local inspection, spatial awareness and comparison between regions become limited. In our model, coordinated visualizations are integrated within individual probe interfaces, which depict the local data in user-defined regions-of-interest. Our probe concept can be incorporated into a variety of geospatial visualizations to empower users with the ability to observe, coordinate, and compare data across multiple local regions. It is especially useful when dealing with complex simulations or analyses where behavior in various localities differs from other localities and from the system as a whole. We illustrate the effectiveness of our technique over traditional interfaces by incorporating it within three existing geospatial visualization systems: an agent-based social simulation, a census data exploration tool, and an 3D GIS environment for analyzing urban change over time. In each case, the probe-based interaction enhances spatial awareness, improves inspection and comparison capabilities, expands the range of scopes, and facilitates collaboration among multiple users.","keywords":"Multiple-view techniques, geospatial visualization, geospatial analysis, focus + context, probes","caption":"Fig. 5. Shown here, the coordinated visualizations for each probe have been limited to solely the parallel coordinates view and resized to the point where each shows only the most general view of the associated data. Here the probes begin to resemble flags stuck in the map, giving a simple representation, allowing for quick visual comparison (Assuming the user knows how to interpret them.)","img_size":{"width":1064,"height":648},"subfigures":[{"x":1.7449269154548595,"y":2.9800496462826622,"width":1055.5044245200124,"height":635.6099141219328,"type":"single","id":"single-0"}],"visualizations":[{"x":27.379310344827555,"y":336.41379310344814,"width":146.48275862068965,"height":73.24137931034483,"type":"parallel_coordinate","id":"parallel_coordinate-0"},{"x":629.4482758620688,"y":23.586206896551722,"width":125.37931034482756,"height":48.413793103448256,"type":"parallel_coordinate","id":"parallel_coordinate-1"},{"x":629.4482758620688,"y":265.6551724137931,"width":119.17241379310337,"height":54.62068965517238,"type":"parallel_coordinate","id":"parallel_coordinate-2"},{"x":789.5862068965515,"y":551.1724137931033,"width":132.8275862068965,"height":64.55172413793105,"type":"parallel_coordinate","id":"parallel_coordinate-3"},{"x":8.758620689655148,"y":6.206896551724138,"width":1039.0344827586207,"height":628.1379310344826,"type":"map","id":"map-4"}],"relations":[{"vislist":[{"vislist":["parallel_coordinate-3","parallel_coordinate-2","parallel_coordinate-1","parallel_coordinate-0"],"relation":null,"id":"group-0"},{"vislist":["map-4"],"relation":null,"id":"group-1"}],"relation":"annotated","id":"relation-0"}]},"1683_6":{"comp":[["line_chart","map",["annotated"]],["parallel_coordinate","map",["annotated"]]],"visType":["line_chart","map","parallel_coordinate"],"compType":["annotated"],"compressed_tree":[{"composite_pattern":"annotated","visualization_type":[["line_chart","parallel_coordinate"],["map"]]}],"coOccurrence":[["line_chart","parallel_coordinate",["coOccurrence"]],["line_chart","map",["coOccurrence"]],["parallel_coordinate","map",["coOccurrence"]]],"year":2008,"conference":["InfoVis"],"authors":["Thomas Butkiewicz","Wenwen Dou","Zachary Wartell","William Ribarsky","Remco Chang"],"title":"Multi-Focused Geospatial Analysis Using Probes","doi":"10.1109/TVCG.2008.149","abstract":"Traditional geospatial information visualizations often present views that restrict the user to a single perspective. When zoomed out, local trends and anomalies become suppressed and lost; when zoomed in for local inspection, spatial awareness and comparison between regions become limited. In our model, coordinated visualizations are integrated within individual probe interfaces, which depict the local data in user-defined regions-of-interest. Our probe concept can be incorporated into a variety of geospatial visualizations to empower users with the ability to observe, coordinate, and compare data across multiple local regions. It is especially useful when dealing with complex simulations or analyses where behavior in various localities differs from other localities and from the system as a whole. We illustrate the effectiveness of our technique over traditional interfaces by incorporating it within three existing geospatial visualization systems: an agent-based social simulation, a census data exploration tool, and an 3D GIS environment for analyzing urban change over time. In each case, the probe-based interaction enhances spatial awareness, improves inspection and comparison capabilities, expands the range of scopes, and facilitates collaboration among multiple users.","keywords":"Multiple-view techniques, geospatial visualization, geospatial analysis, focus + context, probes","caption":"Fig. 7. An example workspace in our new, probe-based interface. Notice that the user can add any number of different overview maps. Probes can then be Inserted into these maps, spawning linked coordinated visualization/interaction panes. This extends observation and interaction across all levels, from global to individual cells.","img_size":{"width":1064,"height":857},"subfigures":[{"x":-0.01743943851614351,"y":6.98277228509679,"width":1053.3316904850399,"height":846.2469527877932,"type":"interface","id":"interface-0"}],"visualizations":[{"x":6.352715565675866,"y":11.077188086851919,"width":1042.5306379253284,"height":838.867508003644,"type":"map","id":"map-3"},{"x":460.58333333333326,"y":512.2298850574713,"width":315.2183908045976,"height":169.10153256704984,"type":"line_chart","id":"line_chart-4"},{"x":22.232758620689594,"y":90.2969348659004,"width":313.5766283524904,"height":172.38505747126442,"type":"parallel_coordinate","id":"parallel_coordinate-5"},{"x":693.713601532567,"y":129.69923371647508,"width":318.50191570881225,"height":172.3850574712644,"type":"parallel_coordinate","id":"parallel_coordinate-6"}],"relations":[{"vislist":[{"vislist":["line_chart-4","parallel_coordinate-5","parallel_coordinate-6"],"relation":null,"id":"group-0"},{"vislist":["map-3"],"relation":null,"id":"group-1"}],"relation":"annotated","id":"relation-0"}]},"1573_4":{"comp":[["table","map",["annotated"]]],"visType":["table","map"],"compType":["annotated"],"compressed_tree":[{"composite_pattern":"annotated","visualization_type":[["table"],["map"]]}],"coOccurrence":[["table","map",["coOccurrence"]]],"year":2007,"conference":["VAST"],"authors":["Stephen G. Eick","M. Andrew Eick","Jesse Fugitt","Brian Horst","Maxim Khailo","Russell A. Lankenau"],"title":"Thin Client Visualization","doi":"10.1109/VAST.2007.4388996","abstract":"We have developed a Web 2.0 thin client visualization framework called GeoBoosttrade. Our framework focuses on geospatial visualization and using scalable vector graphics (SVG), AJAX, RSS and GeoRSS we have built a complete thin client component set. Our component set provides a rich user experience that is completely browser based. It includes maps, standard business charts, graphs, and time-oriented components. The components are live, interactive, linked, and support real time collaboration.","keywords":"web 20, JavaScript, scalable vector graphics, visualization components, linked view visual analytics","caption":"Figure 2. Linked GeoBoost Maps with Standard Business Charts.","img_size":{"width":989,"height":804},"subfigures":[{"x":4.6659551032038795,"y":0.21659867179500158,"width":982.3286810710974,"height":802.6803641765158,"type":"interface","id":"interface-0"}],"visualizations":[{"x":31.528730227281553,"y":545.0591828664535,"width":267.39562354096245,"height":234.07035295128753,"type":"bar_chart","id":"bar_chart-0"},{"x":8.743687215456989,"y":122.18711892448087,"width":694.247962145807,"height":383.6051637971258,"type":"map","id":"map-1"},{"x":721.0444479041253,"y":136.4278887311549,"width":232.4834353041602,"height":193.60395294953955,"type":"map","id":"map-2"},{"x":10.31496470632794,"y":122.14562990700861,"width":693.2733890793962,"height":384.82752942838795,"type":"map","id":"map-3"},{"x":721.0444479041254,"y":137.22134755471868,"width":230.89651765703272,"height":194.3974117731032,"type":"map","id":"map-4"},{"x":352.2304458982086,"y":163.99392013260413,"width":176.75466255039598,"height":216.7473724071255,"type":"table","id":"table-7"},{"x":367.161812594721,"y":569.6564063969279,"width":249.14607059899754,"height":165.83289412481054,"type":"pie_chart","id":"pie_chart-5"},{"x":8.810344514408811,"y":124.82554357690802,"width":689.0867152128358,"height":384.07269938675904,"type":"scatterplot","id":"scatterplot-6"}],"relations":[{"vislist":[{"vislist":["table-7"],"relation":null,"id":"group-5"},{"vislist":["map-3"],"relation":null,"id":"group-6"}],"relation":"annotated","id":"relation-2"}]},"3099_0":{"comp":[["vector_graph","heatmap",["annotated"]]],"visType":["vector_graph","heatmap"],"compType":["annotated"],"compressed_tree":[{"composite_pattern":"annotated","visualization_type":[["vector_graph"],["heatmap"]]}],"coOccurrence":[["vector_graph","heatmap",["coOccurrence"]]],"year":2018,"conference":["VAST"],"authors":["Juri Buchm\xfcller","Dominik J\xe4ckle","Eren Cakmak","Ulrik Brandes","Daniel A. Keim"],"title":"MotionRugs: Visualizing Collective Trends in Space and Time","doi":"10.1109/TVCG.2018.2865049","abstract":"Understanding the movement patterns of collectives, such as flocks of birds or fish swarms, is an interesting open research question. The collectives are driven by mutual objectives or react to individual direction changes and external influence factors and stimuli. The challenge in visualizing collective movement data is to show space and time of hundreds of movements at the same time to enable the detection of spatiotemporal patterns. In this paper, we propose MotionRugs, a novel space efficient technique for visualizing moving groups of entities. Building upon established space-partitioning strategies, our approach reduces the spatial dimensions in each time step to a one-dimensional ordered representation of the individual entities. By design, MotionRugs provides an overlap-free, compact overview of the development of group movements over time and thus, enables analysts to visually identify and explore group-specific temporal patterns. We demonstrate the usefulness of our approach in the field of fish swarm analysis and report on initial feedback of domain experts from the field of collective behavior.","keywords":"Spatio-Temporal Visualization,Spatial Abstraction,Spatial Index Structures,Collective Movement","caption":"Fig. 1. Example of a MotionRug applied to swarm data comprising 151 golden shiner fish swimming through a water tank. Each frame of the data is represented as one vertical slice, and all slices are aligned sequentially on a time axis. The color encodes the speed of the fish, leading to this visual representation. We selected six frames that indicate the overall states and movement of the fish, as shown above the MotionRug. Below the MotionRug, we highlight key areas of the visualization: Overall, there is a strong spatial dynamic at the beginning. First, the fish are slow as they approach the right wall of the tank. Then, the fish speed up slowly and slow down when hitting the next wall. The fish repeat this behavior when approaching the wall on the left. Arrived, the fish show a spatial stagnation, meaning as a whole, the group remains in one place. Trends are typically indicated by tapered feature values. ","img_size":{"width":2104,"height":619},"subfigures":[{"x":28.032970756643486,"y":31.13210281181623,"width":2047.9340584867164,"height":567.2704884293227,"type":"interface","id":"interface-0"}],"visualizations":[{"x":29.633802816901408,"y":285.5650054171181,"width":2033.3347778981583,"height":168.6847237269772,"type":"heatmap","id":"heatmap-0"},{"x":184.64138678223182,"y":34.81744312026001,"width":303.1765980498375,"height":189.20043336944744,"type":"vector_graph","id":"vector_graph-1"},{"x":508.3336944745396,"y":30.25839653304441,"width":307.7356446370531,"height":189.20043336944747,"type":"vector_graph","id":"vector_graph-2"},{"x":832.0260021668472,"y":30.25839653304441,"width":314.5742145178764,"height":191.47995666305525,"type":"vector_graph","id":"vector_graph-3"},{"x":1167.1159263271938,"y":34.81744312026001,"width":303.17659804983737,"height":186.9209100758396,"type":"vector_graph","id":"vector_graph-4"},{"x":1522.7215601300106,"y":34.81744312026001,"width":207.43661971830988,"height":182.36186348862404,"type":"vector_graph","id":"vector_graph-5"},{"x":1730.1581798483205,"y":30.25839653304441,"width":305.4561213434454,"height":191.47995666305525,"type":"vector_graph","id":"vector_graph-6"}],"relations":[{"vislist":[{"vislist":["vector_graph-1","vector_graph-2","vector_graph-3","vector_graph-4","vector_graph-5","vector_graph-6"],"relation":null,"id":"group-2"},{"vislist":["heatmap-0"],"relation":null,"id":"group-1"}],"relation":"annotated","id":"relation-1"}]},"3100_0":{"comp":[["line_chart","scatterplot",["annotated"]]],"visType":["line_chart","scatterplot"],"compType":["annotated"],"compressed_tree":[{"composite_pattern":"annotated","visualization_type":[["line_chart"],["scatterplot"]]},{"composite_pattern":"annotated","visualization_type":[["line_chart"],["scatterplot"]]}],"coOccurrence":[["line_chart","scatterplot",["coOccurrence"]]],"year":2018,"conference":["VAST"],"authors":["Daniel Orban","Daniel F. Keefe","Ayan Biswas","James P. Ahrens","David H. Rogers"],"title":"Drag and Track: A Direct Manipulation Interface for Contextualizing Data Instances within a Continuous Parameter Space","doi":"10.1109/TVCG.2018.2865051","abstract":"We present a direct manipulation technique that allows material scientists to interactively highlight relevant parameterized simulation instances located in dimensionally reduced spaces, enabling a user-defined understanding of a continuous parameter space. Our goals are two-fold: first, to build a user-directed intuition of dimensionally reduced data, and second, to provide a mechanism for creatively exploring parameter relationships in parameterized simulation sets, called ensembles. We start by visualizing ensemble data instances in dimensionally reduced scatter plots. To understand these abstract views, we employ user-defined virtual data instances that, through direct manipulation, search an ensemble for similar instances. Users can create multiple of these direct manipulation queries to visually annotate the spaces with sets of highlighted ensemble data instances. User-defined goals are therefore translated into custom illustrations that are projected onto the dimensionally reduced spaces. Combined forward and inverse searches of the parameter space follow naturally allowing for continuous parameter space prediction and visual query comparison in the context of an ensemble. The potential for this visualization technique is confirmed via expert user feedback for a shock physics application and synthetic model analysis.","keywords":"Visual Parameter Space Analysis,Ensemble Visualization,Semantic Interaction,Direct Manipulation,Shock Physics","caption":"Fig. 1. Our parameter space exploration tool allows users to query linked dimensionally reduced spaces by interactive clicking and dragging virtual data instances. These are visualized via interactive callouts that can be directly manipulated to search and display the nearest ensemble instances. The linked parallel coordinate plot allows for filtering the ensemble and displays trends of selected parameters based on the user-defined annotation.","img_size":{"width":1628,"height":715},"subfigures":[{"x":17.56872958262012,"y":19.38315602009324,"width":1567.4205798398868,"height":690.4761460766629,"type":"interface","id":"interface-0"}],"visualizations":[{"x":49.080179602309165,"y":169.01122514432333,"width":706.9634381013472,"height":516.9082745349584,"type":"heatmap","id":"heatmap-0"},{"x":829.1417575368827,"y":167.96696600384863,"width":712.1847338037204,"height":520.0410519563823,"type":"heatmap","id":"heatmap-1"},{"x":523.1738293778063,"y":634.7508017960232,"width":98.16035920461832,"height":72.05388069275172,"type":"line_chart","id":"line_chart-10"},{"x":78.31943553559974,"y":573.139512508018,"width":99.20461834509298,"height":69.96536241180252,"type":"line_chart","id":"line_chart-11"},{"x":91.89480436177043,"y":170.055484284798,"width":99.20461834509297,"height":73.09813983322641,"type":"line_chart","id":"line_chart-2"},{"x":648.4849262347659,"y":165.87844772289927,"width":100.2488774855676,"height":73.09813983322644,"type":"line_chart","id":"line_chart-3"},{"x":894.9300833867865,"y":219.13566388710717,"width":101.29313662604225,"height":72.05388069275172,"type":"line_chart","id":"line_chart-4"},{"x":1300.102629890956,"y":162.74567030147531,"width":99.20461834509297,"height":75.18665811417578,"type":"line_chart","id":"line_chart-5"},{"x":1408.7055805003208,"y":244.19788325849908,"width":97.11610006414367,"height":73.09813983322644,"type":"line_chart","id":"line_chart-6"},{"x":1466.1398332264275,"y":588.8033996151378,"width":96.07184092366901,"height":71.00962155227705,"type":"line_chart","id":"line_chart-7"},{"x":886.5760102629891,"y":583.5821039127646,"width":99.20461834509297,"height":73.09813983322647,"type":"line_chart","id":"line_chart-8"},{"x":659.9717767799872,"y":554.342847979474,"width":96.07184092366901,"height":69.96536241180252,"type":"line_chart","id":"line_chart-9"},{"x":253.75497113534317,"y":22.814945477870427,"width":1060.967286722258,"height":98.16035920461837,"type":"parallel_coordinate","id":"parallel_coordinate-12"},{"x":51.1686978832585,"y":166.92270686337397,"width":701.7421423989738,"height":516.9082745349584,"type":"scatterplot","id":"scatterplot-13"},{"x":829.1417575368827,"y":169.01122514432333,"width":711.1404746632459,"height":521.0853110968569,"type":"scatterplot","id":"scatterplot-14"}],"relations":[{"vislist":[{"vislist":["line_chart-2","line_chart-3","line_chart-11","line_chart-10","line_chart-9"],"relation":null,"id":"group-7"},{"vislist":["scatterplot-13"],"relation":null,"id":"group-8"}],"relation":"annotated","id":"relation-4"},{"vislist":[{"vislist":["line_chart-4","line_chart-5","line_chart-6","line_chart-8","line_chart-7"],"relation":null,"id":"group-9"},{"vislist":["scatterplot-14"],"relation":null,"id":"group-10"}],"relation":"annotated","id":"relation-5"}]},"2574_2":{"comp":[["line_chart","scatterplot",["annotated"]],["stripe_graph","scatterplot",["annotated"]]],"visType":["line_chart","scatterplot","stripe_graph"],"compType":["annotated"],"compressed_tree":[{"composite_pattern":"annotated","visualization_type":[["line_chart","stripe_graph"],["scatterplot"]]}],"coOccurrence":[["line_chart","stripe_graph",["coOccurrence"]],["line_chart","scatterplot",["coOccurrence"]],["stripe_graph","scatterplot",["coOccurrence"]]],"year":2014,"conference":["VAST"],"authors":["Tarik Crnovrsanin","Chris Muelder","Kwan-Liu Ma"],"title":"A System for Visual Analysis of Radio Signal Data","doi":"10.1109/VAST.2014.7042479","abstract":"Analysis of radio transmissions is vital for military defense as it provides valuable information about enemy communication and infrastructure. One challenge to the data analysis task is that there are far too many signals for analysts to go through by hand. Even typical signal meta data (such as frequency band, duration, and geographic location) can be overwhelming. In this paper, we present a system for exploring and analyzing such radio signal meta-data. Our system incorporates several visual representations for signal data, designed for readability and ease of comparison, as well as novel algorithms for extracting and classifying consistent signal patterns. We demonstrate the effectiveness of our system using data collected from real missions with an airborne sensor platform.","keywords":"Intelligence Analysis, Coordinated and Multiple Views, Time-varying data, Geographic/Geospatial Visualization","caption":"Fig. 3. The system has three primary views (A-C) and several interface tools (D-G). The map view (A) shows the locations of selected signals\u2019 sources geospatially. The main view (B) shows the results of the analytic algorithms, and allows the user to inspect or select them. The timeline view directly plots a parameter of the signals over time as lines for the signals\u2019 durations (frequency bands shown here), and allows the user to filter by that property or by time. The menu control (D) provides additional user controls for the three different views. The color editor (E) is used to create or modify a color gradient and provide histogram of each data property . The algorithm workflow (F) allows the user to visually select the algorithmic methods by directing the flow of data from source to view. The search window (G) gives the user the ability to draw a specific signal pattern and search for it in the results. Previously drawn patterns can also be loaded.","img_size":{"width":2023,"height":1097},"subfigures":[{"x":8.926886542175607,"y":11.107339875729291,"width":2002.1492048136358,"height":1067.293333463277,"type":"interface","id":"interface-0"}],"visualizations":[{"x":4.459876543209877,"y":764.5270863836018,"width":1375.2928257686676,"height":309.98682284040984,"type":"heatmap","id":"heatmap-4"},{"x":721.5900439238653,"y":27.304538799414352,"width":163.827232796486,"height":81.91361639824305,"type":"line_chart","id":"line_chart-6"},{"x":676.6178623718887,"y":558.9399707174232,"width":162.221083455344,"height":89.94436310395315,"type":"line_chart","id":"line_chart-7"},{"x":1410.6281112737922,"y":583.0322108345536,"width":286.5660855300209,"height":157.7904516741229,"type":"area_chart","id":"area_chart-8"},{"x":4.459876543209877,"y":4.459349593495934,"width":658.9502196193263,"height":732.4040995607614,"type":"map","id":"map-2"},{"x":4.459876543209877,"y":6.424597364568083,"width":655.3089311859442,"height":732.4040995607614,"type":"glyph_based","id":"glyph_based-3"},{"x":686.2547584187408,"y":30.516837481698392,"width":692.250366032211,"height":690.6442166910689,"type":"scatterplot","id":"scatterplot-9"},{"x":1148.8257686676427,"y":43.36603221083456,"width":165.4333821376283,"height":40.15373352855053,"type":"stripe_graph","id":"stripe_graph-10"},{"x":686.2547584187408,"y":295.5314787701318,"width":171.85797950219614,"height":46.57833089311862,"type":"stripe_graph","id":"stripe_graph-11"},{"x":1744.7071742313324,"y":130.09809663250363,"width":255.37774524158138,"height":210.4055636896047,"type":"tree","id":"tree-12"}],"relations":[{"vislist":[{"vislist":["line_chart-6","stripe_graph-10","stripe_graph-11","line_chart-7"],"relation":null,"id":"group-0"},{"vislist":["scatterplot-9"],"relation":null,"id":"group-1"}],"relation":"annotated","id":"relation-0"}]},"1748_3":{"comp":[["box_plot","scatterplot",["annotated"]]],"visType":["box_plot","scatterplot"],"compType":["annotated"],"compressed_tree":[{"composite_pattern":"annotated","visualization_type":[["box_plot"],["scatterplot"]]}],"coOccurrence":[["box_plot","scatterplot",["coOccurrence"]]],"year":2008,"conference":["Vis"],"authors":["Heike Leitte","Michael B\xf6ttinger","Gerik Scheuermann"],"title":"Brushing of Attribute Clouds for the Visualization of Multivariate Data","doi":"10.1109/TVCG.2008.116","abstract":"The visualization and exploration of multivariate data is still a challenging task. Methods either try to visualize all variables simultaneously at each position using glyph-based approaches or use linked views for the interaction between attribute space and physical domain such as brushing of scatterplots. Most visualizations of the attribute space are either difficult to understand or suffer from visual clutter. We propose a transformation of the high-dimensional data in attribute space to 2D that results in a point cloud, called attribute cloud, such that points with similar multivariate attributes are located close to each other. The transformation is based on ideas from multivariate density estimation and manifold learning. The resulting attribute cloud is an easy to understand visualization of multivariate data in two dimensions. We explain several techniques to incorporate additional information into the attribute cloud, that help the user get a better understanding of multivariate data. Using different examples from fluid dynamics and climate simulation, we show how brushing can be used to explore the attribute cloud and find interesting structures in physical space.","keywords":"Multivariate data, brushing, data transformation, manifold learning, linked views","caption":"Fig. 4. The brushing window consists of two parts: The brushing area on the left and a column for information on the points (right).","img_size":{"width":1059,"height":806},"subfigures":[{"x":8.638081612354645,"y":9.260877601929776,"width":1039.5214817288445,"height":784.1754874494187,"type":"interface","id":"interface-0"}],"visualizations":[{"x":597.0620119943421,"y":480.1746487052925,"width":162.19390728165325,"height":229.87147392469942,"type":"box_plot","id":"box_plot-1"},{"x":262.504338619703,"y":528.8354893288587,"width":169.50156257362582,"height":226.1279175013465,"type":"box_plot","id":"box_plot-2"},{"x":53.1489122188443,"y":102.48297945540978,"width":163.15789141108337,"height":223.41878444733857,"type":"box_plot","id":"box_plot-3"},{"x":13.076416497348836,"y":55.182487749898016,"width":790.5881118961382,"height":729.7635170829926,"type":"scatterplot","id":"scatterplot-0"},{"x":836.5172360399954,"y":57.74536577620773,"width":211.84867033761108,"height":611.2430921262654,"type":"table","id":"table-4"}],"relations":[{"vislist":[{"vislist":["box_plot-3","box_plot-2","box_plot-1"],"relation":null,"id":"group-0"},{"vislist":["scatterplot-0"],"relation":null,"id":"group-1"}],"relation":"annotated","id":"relation-0"}]},"2698_0":{"comp":[["bar_chart","bar_chart",["mirrored"]]],"visType":["bar_chart"],"compType":["mirrored"],"compressed_tree":[{"composite_pattern":"mirrored","visualization_type":[["bar_chart"]]}],"coOccurrence":[["bar_chart","bar_chart",["coOccurrence"]]],"year":2015,"conference":["VAST"],"authors":["Hannah Kim","Jaegul Choo","Haesun Park","Alex Endert"],"title":"InterAxis: Steering Scatterplot Axes via Observation-Level Interaction","doi":"10.1109/TVCG.2015.2467615","abstract":"Scatterplots are effective visualization techniques for multidimensional data that use two (or three) axes to visualize data items as a point at its corresponding x and y Cartesian coordinates. Typically, each axis is bound to a single data attribute. Interactive exploration occurs by changing the data attributes bound to each of these axes. In the case of using scatterplots to visualize the outputs of dimension reduction techniques, the x and y axes are combinations of the true, high-dimensional data. For these spatializations, the axes present usability challenges in terms of interpretability and interactivity. That is, understanding the axes and interacting with them to make adjustments can be challenging. In this paper, we present InterAxis, a visual analytics technique to properly interpret, define, and change an axis in a user-driven manner. Users are given the ability to define and modify axes by dragging data items to either side of the x or y axes, from which the system computes a linear combination of data attributes and binds it to the axis. Further, users can directly tune the positive and negative contribution to these complex axes by using the visualization of data attributes that correspond to each axis. We describe the details of our technique and demonstrate the intended usage through two scenarios.","keywords":"Scatterplots, user interaction, model steering","caption":"Fig. 1. An overview of the proposed visual analytics system, InterAxis, showing a car dataset, which includes 387 data items with 18 attributes. The proposed system contains three panels: (A) the scatterplot view to provide a two-dimensional overview of data, (B-D) the axis interaction panel to support the proposed interaction capabilities, and (E) the data detail view to show the original high-dimensional information of the data items of interest. The axis interaction panel (B-D) consists of (B) two drop zones (the high-end and the low-end of each axis), which a user drags data points into in order to steer the axis, (C) an interactive bar chart, and a sub-panel containing buttons to save the current axis for future use (D, middle) or to clear the data points currently assigned to the axis (D, right) and a combo box to change the axis back to one among the original features or the previously created axes via our interaction (D, left).","img_size":{"width":1954,"height":996},"subfigures":[{"x":10.859297319672303,"y":6.894057598661412,"width":1933.7006497820898,"height":982.2118848026794,"type":"interface","id":"interface-0"}],"visualizations":[{"x":583.9956076134699,"y":711.636896046852,"width":815.1742313323574,"height":265.4055636896046,"type":"bar_chart","id":"bar_chart-0"},{"x":12.352855051244491,"y":157.493411420205,"width":425.81551976573934,"height":351.44363103953157,"type":"bar_chart","id":"bar_chart-1"},{"x":414.83601756954613,"y":10.207906295754025,"width":1108.2869692532943,"height":654.7642752562224,"type":"scatterplot","id":"scatterplot-2"},{"x":40.06002928257686,"y":683.92972181552,"width":399.5666178623718,"height":116.66178623718884,"type":"table","id":"table-3"},{"x":1578.5373352855056,"y":13.124450951683752,"width":360.19326500732063,"height":559.9765739385065,"type":"table","id":"table-4"}],"relations":[{"vislist":[{"vislist":["bar_chart-1"],"relation":null,"id":"group-1"}],"relation":"mirrored","id":"relation-1"}]},"2705_0":{"comp":[["heatmap","heatmap",["mirrored"]]],"visType":["heatmap"],"compType":["mirrored"],"compressed_tree":[{"composite_pattern":"mirrored","visualization_type":[["heatmap"]]},{"composite_pattern":"mirrored","visualization_type":[["heatmap"]]}],"coOccurrence":[["heatmap","heatmap",["coOccurrence"]]],"year":2015,"conference":["VAST"],"authors":["Fabian Bec","Sebastian Koch","Daniel Weiskopf"],"title":"Visual Analysis and Dissemination of Scientific Literature Collections with SurVis","doi":"10.1109/TVCG.2015.2467757","abstract":"Bibliographic data such as collections of scientific articles and citation networks have been studied extensively in information visualization and visual analytics research. Powerful systems have been built to support various types of bibliographic analysis, but they require some training and cannot be used to disseminate the insights gained. In contrast, we focused on developing a more accessible visual analytics system, called SurVis, that is ready to disseminate a carefully surveyed literature collection. The authors of a survey may use our Web-based system to structure and analyze their literature database. Later, readers of the survey can obtain an overview, quickly retrieve specific publications, and reproduce or extend the original bibliographic analysis. Our system employs a set of selectors that enable users to filter and browse the literature collection as well as to control interactive visualizations. The versatile selector concept includes selectors for textual search, filtering by keywords and meta-information, selection and clustering of similar publications, and following citation links. Agreement to the selector is represented by word-sized sparkline visualizations seamlessly integrated into the user interface. Based on an analysis of the analytical reasoning process, we derived requirements for the system. We developed the system in a formative way involving other researchers writing literature surveys. A questionnaire study with 14 visual analytics experts confirms that SurVis meets the initially formulated requirements.","keywords":"Visual analytics of documents, bibliographic data, dissemination, literature browser","caption":"Fig. 1. User interface of SurVis, a Web-based visual analytics system to analyze and disseminate literature collections, consisting of a literature overview and a list of publications; versatile interactive selectors allow the user to query the literature collection; the system visualizes the selector agreement in a timeline and using word-sized sparkline visualizations embedded in word clouds.","img_size":{"width":1974,"height":624},"subfigures":[{"x":16.375319221782473,"y":9.904999848308147,"width":1035.106104461903,"height":592.7009946042351,"type":"interface","id":"interface-0"},{"x":1094.569393383478,"y":12.773920089342237,"width":865.9245294502568,"height":591.2715312593481,"type":"single","id":"single-1"}],"visualizations":[{"x":18.81792183031459,"y":139.81601525262158,"width":434.69399428026696,"height":195.7063870352717,"type":"bar_chart","id":"bar_chart-0"},{"x":1176.1201143946616,"y":384.44899904671126,"width":771.5347950428979,"height":223.9332697807435,"type":"bar_chart","id":"bar_chart-1"},{"x":1178.001906577693,"y":92.7712106768351,"width":771.5347950428979,"height":242.75119161105818,"type":"bar_chart","id":"bar_chart-2"},{"x":18.81792183031459,"y":141.69780743565303,"width":430.9304099142041,"height":193.82459485224024,"type":"heatmap","id":"heatmap-3"},{"x":1178.001906577693,"y":89.00762631077221,"width":765.8894184938039,"height":246.51477597712108,"type":"heatmap","id":"heatmap-4"},{"x":16.936129647283128,"y":371.27645376549106,"width":397.05815061963784,"height":163.7159199237369,"type":"word_cloud","id":"word_cloud-5"}],"relations":[{"vislist":[{"vislist":["heatmap-4"],"relation":null,"id":"group-0"}],"relation":"mirrored","id":"relation-0"},{"vislist":[{"vislist":["heatmap-3"],"relation":null,"id":"group-1"}],"relation":"mirrored","id":"relation-1"}]},"2721_2":{"comp":[["bar_chart","bar_chart",["mirrored"]]],"visType":["bar_chart"],"compType":["mirrored"],"compressed_tree":[{"composite_pattern":"mirrored","visualization_type":[["bar_chart"]]}],"coOccurrence":[["bar_chart","bar_chart",["coOccurrence"]]],"year":2015,"conference":["VAST"],"authors":["Chris Bryan","Xue Wu","Susan M. Mniszewski","Kwan-Liu Ma"],"title":"Integrating predictive analytics into a spatiotemporal epidemic simulation","doi":"10.1109/VAST.2015.7347626","abstract":"The Epidemic Simulation System (EpiSimS) is a scalable, complex modeling tool for analyzing disease within the United States. Due to its high input dimensionality, time requirements, and resource constraints, simulating over the entire parameter space is unfeasible. One solution is to take a granular sampling of the input space and use simpler predictive models (emulators) in between. The quality of the implemented emulator depends on many factors: robustness, sophistication, configuration, and suitability to the input data. Visual analytics can be leveraged to provide guidance and understanding of these things to the user. In this paper, we have implemented a novel interface and workflow for emulator building and use. We introduce a workflow to build emulators, make predictions, and then analyze the results. Our prediction process first predicts temporal time series, and uses these to derive predicted spatial densities. Integrated into the EpiSimS framework, we target users who are non-experts at statistical modeling. This approach allows for a high level of analysis into the state of the built emulators and their resultant predictions. We present our workflow, models, the associated system, and evaluate the overall utility with feedback from EpiSimS scientists.","keywords":"Predictive Modeling, Visual Analytics, Epidemic Visualization, Spatial-Temporal Systems","caption":"Figure 4: The emulator panel includes (A) a radar plot for important numeric values, (B) error residuals, (C) parameter metrics chart, and (D) run influences to the model.","img_size":{"width":747,"height":516},"subfigures":[{"x":9.354896475706127,"y":7.267315648020493,"width":726.1751829835015,"height":489.4836534659762,"type":"interface","id":"interface-0"}],"visualizations":[{"x":34.59210526315788,"y":299.86842105263156,"width":678.9473684210526,"height":114.28947368421053,"type":"bar_chart","id":"bar_chart-0"},{"x":35.72368421052627,"y":411.8947368421053,"width":675.5526315789475,"height":73.55263157894734,"type":"bar_chart","id":"bar_chart-1"},{"x":23.27631578947367,"y":127.86842105263158,"width":200.2894736842105,"height":174.26315789473685,"type":"polar_plot","id":"polar_plot-2"},{"x":234.88157894736838,"y":140.31578947368422,"width":484.31578947368405,"height":159.55263157894734,"type":"scatterplot","id":"scatterplot-3"}],"relations":[{"vislist":[{"vislist":["bar_chart-0"],"relation":null,"id":"group-0"}],"relation":"mirrored","id":"relation-0"}]},"2953_4":{"comp":[["bar_chart","bar_chart",["mirrored"]]],"visType":["bar_chart"],"compType":["mirrored"],"compressed_tree":[{"composite_pattern":"mirrored","visualization_type":[["bar_chart"]]}],"coOccurrence":[["bar_chart","bar_chart",["coOccurrence"]]],"year":2017,"conference":["VAST"],"authors":["Mennatallah El-Assady","Rita Sevastjanova","Fabian Sperrle","Daniel A. Keim","Christopher Collins"],"title":"Progressive Learning of Topic Modeling Parameters: A Visual Analytics Framework","doi":"10.1109/TVCG.2017.2745080","abstract":"Topic modeling algorithms are widely used to analyze the thematic composition of text corpora but remain difficult to interpret and adjust. Addressing these limitations, we present a modular visual analytics framework, tackling the understandability and adaptability of topic models through a user-driven reinforcement learning process which does not require a deep understanding of the underlying topic modeling algorithms. Given a document corpus, our approach initializes two algorithm configurations based on a parameter space analysis that enhances document separability. We abstract the model complexity in an interactive visual workspace for exploring the automatic matching results of two models, investigating topic summaries, analyzing parameter distributions, and reviewing documents. The main contribution of our work is an iterative decision-making technique in which users provide a document-based relevance feedback that allows the framework to converge to a user-endorsed topic distribution. We also report feedback from a two-stage study which shows that our technique results in topic model quality improvements on two independent measures.","keywords":"Topic Model Configuration,Reinforcement Learning,Feature Detection and Tracking,Iterative Optimization","caption":"Fig. 4. Topic Summarization View. The topic descriptors of the two compared topics are shown in the top cards on the left and right A . Descriptors appearing in both topics are colored blue, those appearing in only one topic orange or purple, respectively. All keywords are associated a small glyph above them, showing their relevance score for the topic. The mirrored bar chart in the middle B shows all documents in the corpus, where the length of the bars is mapped to the length of the document. Documents belonging to the respective topic of both models are colored green, documents appearing in only one of both are orange or purple. To the left and the right of the bar chart, the top 10 most representative sentences for the topics are shown C . The pie charts D show the percentage of matching documents of the topics.","img_size":{"width":2157,"height":420},"subfigures":[{"x":16.67171494121549,"y":13.035914799047836,"width":2129.9233259354555,"height":398.6261537022989,"type":"single","id":"single-0"}],"visualizations":[{"x":973.3027989821882,"y":106.63231552162847,"width":109.7709923664121,"height":305.5292620865139,"type":"bar_chart","id":"bar_chart-0"},{"x":1084.903307888041,"y":106.63231552162847,"width":104.2824427480914,"height":305.5292620865139,"type":"bar_chart","id":"bar_chart-1"}],"relations":[{"vislist":[{"id":"group-0","relation":null,"vislist":["bar_chart-0","bar_chart-1"]}],"relation":"mirrored","id":"relation-0"}]},"2953_6":{"comp":[["bar_chart","bar_chart",["mirrored"]]],"visType":["bar_chart"],"compType":["mirrored"],"compressed_tree":[{"composite_pattern":"mirrored","visualization_type":[["bar_chart"]]}],"coOccurrence":[["bar_chart","bar_chart",["coOccurrence"]]],"year":2017,"conference":["VAST"],"authors":["Mennatallah El-Assady","Rita Sevastjanova","Fabian Sperrle","Daniel A. Keim","Christopher Collins"],"title":"Progressive Learning of Topic Modeling Parameters: A Visual Analytics Framework","doi":"10.1109/TVCG.2017.2745080","abstract":"Topic modeling algorithms are widely used to analyze the thematic composition of text corpora but remain difficult to interpret and adjust. Addressing these limitations, we present a modular visual analytics framework, tackling the understandability and adaptability of topic models through a user-driven reinforcement learning process which does not require a deep understanding of the underlying topic modeling algorithms. Given a document corpus, our approach initializes two algorithm configurations based on a parameter space analysis that enhances document separability. We abstract the model complexity in an interactive visual workspace for exploring the automatic matching results of two models, investigating topic summaries, analyzing parameter distributions, and reviewing documents. The main contribution of our work is an iterative decision-making technique in which users provide a document-based relevance feedback that allows the framework to converge to a user-endorsed topic distribution. We also report feedback from a two-stage study which shows that our technique results in topic model quality improvements on two independent measures.","keywords":"Topic Model Configuration,Reinforcement Learning,Feature Detection and Tracking,Iterative Optimization","caption":"ig. 5. TheDocument Relevance Feedback View. A The document in review; B the topic descriptors of the associated topics; Cthe decision slider; D the navigation arrows.  The bar chart E shows the documents sorted and color coded by their topic coherence, from bad (red) to good (green).  Users rate topics for the current document by selecting a slider position, and can navigate between documents with the arrow buttons D.","img_size":{"width":2149,"height":573},"subfigures":[{"x":11.933916404853745,"y":6.541029626153949,"width":2123.571288857815,"height":556.7974987388505,"type":"single","id":"single-0"}],"visualizations":[{"x":153.37407711238717,"y":458.3847415914683,"width":1819.3338802296962,"height":111.21653376058197,"type":"bar_chart","id":"bar_chart-0"}],"relations":[{"vislist":[{"vislist":["bar_chart-0"],"relation":null,"id":"group-0"}],"relation":"mirrored","id":"relation-0"}]},"2977_4":{"comp":[["bar_chart","bar_chart",["mirrored"]]],"visType":["bar_chart"],"compType":["mirrored"],"compressed_tree":[{"composite_pattern":"mirrored","visualization_type":[["bar_chart"]]},{"composite_pattern":"mirrored","visualization_type":[["bar_chart"]]},{"composite_pattern":"mirrored","visualization_type":[["bar_chart"]]}],"coOccurrence":[["bar_chart","bar_chart",["coOccurrence"]]],"year":2017,"conference":["VAST"],"authors":["Emily Wall","Leslie M. Blaha","Lyndsey Franklin","Alex Endert"],"title":"Warning, Bias May Occur: A Proposed Approach to Detecting Cognitive Bias in Interactive Visual Analytics","doi":"10.1109/VAST.2017.8585669","abstract":"Visual analytic tools combine the complementary strengths of humans and machines in human-in-the-loop systems. Humans provide invaluable domain expertise and sensemaking capabilities to this discourse with analytic models; however, little consideration has yet been given to the ways inherent human biases might shape the visual analytic process. In this paper, we establish a conceptual framework for considering bias assessment through human-in-the-loop systems and lay the theoretical foundations for bias measurement. We propose six preliminary metrics to systematically detect and quantify bias from user interactions and demonstrate how the metrics might be implemented in an existing visual analytic system, InterAxis. We discuss how our proposed metrics could be used by visual analytic systems to mitigate the negative effects of cognitive biases by making users aware of biased processes throughout their analyses.","keywords":"cognitive bias,visual analytics,human-in-the-loop,mixed initiative,user interaction,H.5.0 [Information Systems]: Human-Computer Interaction-General","caption":"Figure 3: A depiction of InterAxis throughout the usage scenario described  in  Section  6.   InterAxis  is  a  system  that  allows  users to  define  custom  scatterplot  axes  using  dimension  reduction  byinteracting with data points. The proposed bias metrics have been integrated into InterAxis in the bar visualization on the lower rightportion of the interface","img_size":{"width":994,"height":2259},"subfigures":[{"x":12.11113776998929,"y":4.554546344113366,"width":963.6082281290941,"height":552.8227247500207,"type":"interface","id":"interface-0"}],"visualizations":[{"x":16.104247653286166,"y":95.1604138301088,"width":183.51521589347246,"height":225.46155095483758,"type":"bar_chart","id":"bar_chart-0"},{"x":306.23306516106163,"y":427.23556639924936,"width":491.1216730101499,"height":131.08229706676613,"type":"bar_chart","id":"bar_chart-1"},{"x":792.111446288541,"y":308.38761705871485,"width":185.26297985436258,"height":157.2987564801192,"type":"bar_chart","id":"bar_chart-2"},{"x":13.220230075641894,"y":813.7325522963379,"width":182.14510773367826,"height":228.98242115090983,"type":"bar_chart","id":"bar_chart-3"},{"x":784.1453573825127,"y":1029.9187787839676,"width":185.26297985436258,"height":155.55099251922914,"type":"bar_chart","id":"bar_chart-4"},{"x":296.51921229414313,"y":1140.0279083200512,"width":412.47229477009034,"height":132.83006102765606,"type":"bar_chart","id":"bar_chart-5"},{"x":12.460917070798189,"y":1530.0527735373082,"width":182.14510773367832,"height":234.18656708615777,"type":"bar_chart","id":"bar_chart-6"},{"x":298.6889435094355,"y":1860.5160404255532,"width":496.99593681617944,"height":137.90986728407051,"type":"bar_chart","id":"bar_chart-7"},{"x":798.2869532932388,"y":1753.8310487529702,"width":179.54303476605435,"height":163.93059696031062,"type":"bar_chart","id":"bar_chart-8"},{"x":215.34933919477055,"y":33.9886751989513,"width":578.5098710546606,"height":374.0214876305057,"type":"scatterplot","id":"scatterplot-9"},{"x":210.97777561506405,"y":727.8641443647466,"width":567.2519069420267,"height":398.1171640464683,"type":"scatterplot","id":"scatterplot-10"},{"x":210.21846261022037,"y":1457.194730443837,"width":577.6601988125226,"height":390.3109451435962,"type":"scatterplot","id":"scatterplot-11"}],"relations":[{"vislist":[{"vislist":["bar_chart-1"],"relation":null,"id":"group-0"}],"relation":"mirrored","id":"relation-0"},{"vislist":[{"vislist":["bar_chart-5"],"relation":null,"id":"group-1"}],"relation":"mirrored","id":"relation-1"},{"vislist":[{"vislist":["bar_chart-7"],"relation":null,"id":"group-2"}],"relation":"mirrored","id":"relation-2"}]},"2581_0":{"comp":[["bar_chart","bar_chart",["mirrored"]]],"visType":["bar_chart"],"compType":["mirrored"],"compressed_tree":[{"composite_pattern":"mirrored","visualization_type":[["bar_chart"]]}],"coOccurrence":[["bar_chart","bar_chart",["coOccurrence"]]],"year":2014,"conference":["VAST"],"authors":["Fei Wan","Wei Che","Feiran Wu","Ye Zhao","Han Hong","Tianyu Gu","Long Wang","Ronghua Liang","Hujun Bao"],"title":"A Visual Reasoning Approach for Data-driven Transport Assessment on Urban Roads","doi":"10.1109/VAST.2014.7042486","abstract":"Transport assessment plays a vital role in urban planning and traffic control, which are influenced by multi-faceted traffic factors involving road infrastructure and traffic flow. Conventional solutions can hardly meet the requirements and expectations of domain experts. In this paper we present a data-driven solution by leveraging a visual analysis system to evaluate the real traffic situations based on taxi trajectory data. A sketch-based visual interface is designed to support dynamic query and visual reasoning of traffic situations within multiple coordinated views. In particular, we propose a novel road-based query model for analysts to interactively conduct evaluation tasks. This model is supported by a bi-directional hash structure, TripHash, which enables real-time responses to the data queries over a huge amount of trajectory data. Case studies with a real taxi GPS trajectory dataset (&amp;gt; 30GB) show that our system performs well for on-demand transport assessment and reasoning.","keywords":"Road-based Query, Taxi Trajectory, Hash Index, Visual Analysis","caption":"Fig. 1. Our system consists of two parts: a sketch-based query and multiple coordinated views. a) The Flow Comparative View shows the variation of traf\ufb01c \ufb02ow of two directions over time. b) The Velocity-and-Distance view shows the relationship between a trip\u2019s average speed and distance. c) The Flow-and-Velocity View shows the status of transportation distributed on a road. d) The Topology View shows the ratio of different \ufb02ow and is also used as a topology \ufb01lter. e) The Flow Density View shows the density of traf\ufb01c \ufb02ow distributed on a road.","img_size":{"width":2019,"height":1085},"subfigures":[{"x":63.16280156411476,"y":16.94990690357583,"width":1892.6743968717715,"height":1062.956238206719,"type":"interface","id":"interface-0"}],"visualizations":[{"x":1590.5968379446642,"y":51.46244036821509,"width":358.092885375494,"height":373.10276679841905,"type":"bar_chart","id":"bar_chart-0"},{"x":1600.0834256582643,"y":764.7560349954001,"width":303.2129822184589,"height":102.94267914824228,"type":"heatmap","id":"heatmap-1"},{"x":60.46008241335568,"y":21.1367231571854,"width":1533.0930626865159,"height":1056.9560618823502,"type":"heatmap","id":"heatmap-7"},{"x":1604.7626383468212,"y":885.4797223601571,"width":331.2882583497976,"height":120.72368736475687,"type":"map","id":"map-4"},{"x":65.6677698509775,"y":18.57117068049024,"width":1527.0733368683905,"height":1061.9821080080344,"type":"map","id":"map-6"},{"x":1592.7411067193677,"y":441.7193573642625,"width":351.66007905138343,"height":268.03359683794474,"type":"scatterplot","id":"scatterplot-5"}],"relations":[{"vislist":[{"vislist":["bar_chart-0"],"relation":null,"id":"group-0"}],"relation":"mirrored","id":"relation-0"}]},"2444_1":{"comp":[["area_chart","area_chart",["mirrored"]]],"visType":["area_chart"],"compType":["mirrored"],"compressed_tree":[{"composite_pattern":"mirrored","visualization_type":[["area_chart"]]}],"coOccurrence":[["area_chart","area_chart",["coOccurrence"]]],"year":2013,"conference":["VAST"],"authors":["Megan Monroe","Rongjian Lan","Hanseung Lee","Catherine Plaisant","Ben Shneiderman"],"title":"Temporal Event Sequence Simplification","doi":"10.1109/TVCG.2013.200","abstract":"Electronic Health Records (EHRs) have emerged as a cost-effective data source for conducting medical research. The difficulty in using EHRs for research purposes, however, is that both patient selection and record analysis must be conducted across very large, and typically very noisy datasets. Our previous work introduced EventFlow, a visualization tool that transforms an entire dataset of temporal event records into an aggregated display, allowing researchers to analyze population-level patterns and trends. As datasets become larger and more varied, however, it becomes increasingly difficult to provide a succinct, summarizing display. This paper presents a series of user-driven data simplifications that allow researchers to pare event records down to their core elements. Furthermore, we present a novel metric for measuring visual complexity, and a language for codifying disjoint strategies into an overarching simplification framework. These simplifications were used by real-world researchers to gain new and valuable insights from initially overwhelming datasets.","keywords":"Event sequences, simplification, electronic heath records, temporal query","caption":"Fig. 2. EventFlow consists of three panels: the control panel (left), the aggregated record display (center), and the individual record display (right). Here, a sample dataset is aligned by the Stroke event in each patient record, creating mirrored alignments in both the individual and aggregated displays. In EventFlow, record filtering is done using the \u201cRemove\u201d buttons at the top of the control panel. Category filtering is done using the checkboxes in the legend. Time and Attribute filtering is done using the \u201cWindow\u201d and \u201cAttribute\u201d tabs respectively.","img_size":{"width":2088,"height":894},"subfigures":[{"x":6.685797139726517,"y":5.132405320262243,"width":2075.7166553568313,"height":879.3802747755741,"type":"interface","id":"interface-0"}],"visualizations":[{"x":485.67397521448993,"y":127.53002859866535,"width":754.3870352716874,"height":728.510962821735,"type":"area_chart","id":"area_chart-0"}],"relations":[{"vislist":[{"vislist":["area_chart-0"],"relation":null,"id":"group-0"}],"relation":"mirrored","id":"relation-0"}]}}')},276:function(e,t,i){},338:function(e,t,i){"use strict";i.r(t);var a=i(1),r=i.n(a),s=i(53),o=i.n(s),n=(i(276),i(87)),l=i(86),c=i(81),h=i(379),d=i(340),p=i(400),u=i(393),g=i(48),m=i(214),y=i(382),f=i(384),v=i(387),b=i(402),w=i(405),_=i(388),x=i(404),z=i(385),k=i(386),T=i(4),S=Object(h.a)((function(e){return{root:{margin:"15px 0 0 0px",justifyContent:"center",alignItems:"center",position:"relative",display:"flex",width:"100%",height:"7%"},container:{margin:"0 25px 0 25px",padding:"0px 20px 0px 20px",width:"92%",height:"80%",display:"flex",justifyContent:"end",alignItems:"center",borderRadius:"50px"},icon:{margin:"0px 10px 0px 10px",width:"30px",height:"30px"},text:{width:"20%",display:"inline"},select:{width:"10%"},input:{minWidth:"55%",maxWidth:"100%"},img:{},formControl:{},option:{textTransform:"capitalize"}}}));var O=Object(g.b)("d")(Object(g.c)((function(e){var t=e.d,i=S(),a=r.a.useState(null),s=Object(n.a)(a,2),o=s[0],l=s[1],c=function(e){l(document.getElementById("search_achorel"))},h=Boolean(o),d=h?"simple-popover":void 0;return Object(T.jsx)("div",{className:i.root,children:Object(T.jsxs)(y.a,{className:i.container,variant:"outlined",children:[Object(T.jsx)(f.a,{className:i.icon,onClick:c,children:Object(T.jsx)(z.a,{})}),Object(T.jsx)(m.a,{className:i.text,onClick:c,id:"search_achorel",children:t.filterState.filterBarState.searchState||"Search All"}),Object(T.jsx)(f.a,{className:i.icon,onClick:c,children:Object(T.jsx)(k.a,{})}),Object(T.jsx)(v.a,{className:i.input,onKeyDown:function(e){"Enter"===e.key&&(t.updateSearchWords(e.target.value),t.updateFilteredImagesData())}}),Object(T.jsxs)(b.a,{id:d,open:h,anchorEl:o,onClose:function(){l(null)},anchorOrigin:{vertical:"bottom",horizontal:"center"},transformOrigin:{vertical:"top",horizontal:"center"},children:[Object(T.jsxs)(w.a,{className:i.option,selected:t.filterStateSelected("searchState")===Object.keys(t.filterState.searchState).length,onClick:function(){return t.changeFilterState("searchState","All")},children:[Object(T.jsx)(_.a,{primary:"Select All"}),Object(T.jsx)(x.a,{checked:t.filterStateSelected("searchState")===Object.keys(t.filterState.searchState).length})]}),["keywords","title","abstract"].map((function(e){return Object(T.jsxs)(w.a,{className:i.option,selected:t.filterState.searchState[e],onClick:function(){return t.changeFilterState("searchState",e)},children:[Object(T.jsx)(_.a,{primary:e}),Object(T.jsx)(x.a,{checked:t.filterState.searchState[e]})]},e)}))]})]})})}))),A=i(394),V=i(401),C=i(389),D=i(390),M=i(391),I=i(392),W={tree:"#e8c7c7",graph:"#d8a3a3",arc_diagram:"#d8bea3",treemap:"#c87e7e",hierarchical_edge_bundling:"#b85a5a",sunburst_icicle:"#a93636",line_chart:"#d8bea3",parallel_coordinate:"#c8a47e",polar_plot:"#b88a5a",storyline:"#a97036",flow_diagram:"#c8c87e",chord_diagram:"#b8b85a",sankey_diagram:"#a9a936",map:"#70a936",heatmap:"#7ec87e",heatmap_matrix:"#a93670",heatmap_map:"#a93670",unit_visualization:"#5ab85a",glyph_based:"#36a936",scatterplot:"#36a970",matrix:"#7ec8c8",table:"#5ab8b8",small_multiple:"#36a9a9",pie_chart:"#7ea4c8",sector_chart:"#5a8ab8",donut_chart:"#3670a9",error_bar:"#7e7ec8",box_plot:"#5a5ab8",stripe_graph:"#3636a9",bar_chart:"#7036a9",area_chart:"#b85ab8",proportional_area_chart:"#a936a9",word_cloud:"#a93670",contour_graph:"#d8bea3",surface_graph:"#b88a5a",vector_graph:"#a97036",scivis:"#c8c87e",others:"#d3d3d3",repeated:"#1f77b4",stacked:"#1f77b4",mirrored:"#1f77b4",large_view:"#e28034",coordinated:"#e28034",annotated:"#e28034",accompanied:"#e28034",nested:"#519c3e"},q={area_chart:"area chart",bar_chart:"bar chart",box_plot:"box plot",arc_diagram:"arc diagram",contour_graph:"contour graph",chord_diagram:"chord diagram",donut_chart:"donut chart",error_bar:"error bar",flow_diagram:"flow diagram",glyph_based:"glyph based",graph:"graph",heatmap:"heatmap",heatmap_matrix:"heatmap matrix",heatmap_map:"heatmap map",hierarchical_edge_bundling:"hierarchical edge bundling",line_chart:"line chart",matrix:"matrix",map:"map",others:"others",parallel_coordinate:"parallel coordinate",pie_chart:"pie chart",polar_plot:"polar plot",proportional_area_chart:"proportional area chart",sankey_diagram:"sankey diagram",scatterplot:"scatterplot",scivis:"scivis",sector_chart:"sector chart",small_multiple:"small multiple",storyline:"storyline",stripe_graph:"stripe graph",sunburst_icicle:"sunburst icicle",surface_graph:"surface graph",table:"table",tree:"tree",treemap:"treemap",unit_visualization:"unit visualization",vector_graph:"vector graph",word_cloud:"word cloud"},F={area_chart:"Area",arc_diagram:"Arc",bar_chart:"Bar",box_plot:"Box",comb:"Composite",contour_graph:"Contour",chord_diagram:"Chord",donut_chart:"Donut",error_bar:"Error Bar",flow_diagram:"Flow",glyph_based:"Glyph",graph:"Graph",heatmap:"Heatmap",heatmap_matrix:"Heatmap Matrix",heatmap_map:"Heatmap Map",hierarchical_edge_bundling:"HEB",line_chart:"Line",map:"Map",matrix:"Matrix",node_link:"Node-link",parallel_coordinate:"PCP",pie_chart:"Pie",polar_plot:"Polar",proportional_area_chart:"PAC",radar_chart:"Radar",sankey_diagram:"Sankey",scatterplot:"Scatter",scivis:"SciVis",sector_chart:"Sector",small_multiple:"Small Multiples",storyline:"Storyline",stripe_graph:"Stripe",sunburst_icicle:"Sunburst/Icicle",surface_graph:"Surface",table:"Table",tree:"Tree",treemap:"Treemap",unit_visualization:"Unit",vector_graph:"Vector",word_cloud:"Word Cloud",overlaid:"Overlaid",juxtaposed:"Juxtaposed",repeated:"Repeated",stacked:"Stacked",mirrored:"Mirrored",accompanied:"Accompanied",large_view:"Large Panel",annotated:"Annotated",coordinated:"Coordinated",nested:"Nested",coOccurrence:"Co-occurrence",others:"Others",InfoVis:"InfoVis",VAST:"VAST",Vis:"Vis",SciVis:"SciVis",null:"Any Types"},G={};Object.keys(q).forEach((function(e){return G[q[e]]=e}));var j={};Object.keys(F).forEach((function(e){return j[F[e]]=e}));i(282);var P=Object(h.a)((function(e){return{root:{width:"50%",height:"100%"},cardContentLeft:{display:"flex",height:"70%",margin:"8px 8px 5px 20px",justifyContent:"space-between",alignItems:"center",borderRadius:"7px"},cardContentRight:{display:"flex",height:"70%",margin:"8px 20px 5px 5px",justifyContent:"space-between",alignItems:"center",borderRadius:"7px"},text:{minWidth:"120px",maxWidth:"160px",overflow:"hidden"},icon:{margin:"0px 10px 0px 10px",width:"30px",height:"30px"},option:{height:"50px",width:"230px"},popover:{overflowY:"hidden",overflowX:"hidden"},list:{},optGrp:{paddingLeft:"5%",textTransform:"capitalize",height:"50px",fontWeight:"bold"},logic:{textTransform:"capitalize",fontWeight:"bold",paddingLeft:"6%",paddingRight:"3%",width:"30%",display:"inline"},btn:{margin:"6px"},textField:{margin:"4px",marginRight:0},logicWrap:{backgroundColor:"rgba(180, 180, 180, 0.2)"},textFieldWrap:{backgroundColor:"rgba(180, 180, 180, 0.2)"}}}));var E=Object(g.b)("d")(Object(g.c)((function(e){var t=e.value,i=e.d,a=P(),s=r.a.useState(null),o=Object(n.a)(s,2),l=o[0],c=o[1],h=r.a.useState(50),p=Object(n.a)(h,2),g=p[0],v=p[1],z=function(e){c(document.getElementById(t))},S=Boolean(l),O=S?"simple-popover":void 0,A=function(){switch(t){case"Composition Type:":return"compType";case"Visualization Type:":return"visType";case"Conference:":return"conference";case"Authors:":return"authors";default:return}}();return Object(T.jsx)("div",{className:a.root,children:Object(T.jsx)(y.a,{className:"compType"===A||"conference"===A?a.cardContentLeft:a.cardContentRight,variant:"outlined",children:Object(T.jsxs)("div",{style:{display:"flex",alignItems:"center",width:"100%",justifyContent:"space-between"},children:[Object(T.jsx)(f.a,{className:a.icon,onClick:z,children:function(){switch(t){case"Composition Type:":return Object(T.jsx)(C.a,{});case"Visualization Type:":return Object(T.jsx)(D.a,{});case"Conference:":return Object(T.jsx)(M.a,{});case"Authors:":return Object(T.jsx)(I.a,{});default:return}}()}),Object(T.jsx)(m.a,{noWrap:!0,className:a.text,id:t,onClick:z,children:"".concat(t," ").concat(i.filterState.filterBarState[A])}),Object(T.jsx)(f.a,{className:a.icon,onClick:z,children:Object(T.jsx)(k.a,{})}),Object(T.jsxs)(b.a,{id:O,open:S,anchorEl:l,onClose:function(){c(null)},anchorOrigin:{vertical:"bottom",horizontal:"center"},transformOrigin:{vertical:"top",horizontal:"center"},children:["authors"===A?Object(T.jsx)("div",{className:a.textFieldWrap,children:Object(T.jsx)(V.a,{className:a.textField,size:"small",label:"author...",onKeyDown:function(e){"Enter"===e.key&&i.updateSearchAuthors(e.target.value)},variant:"outlined"})}):null,"conference"!==A?Object(T.jsxs)("div",{className:a.logicWrap,children:[Object(T.jsx)(m.a,{className:a.logic,children:"logic"}),["or","and"].map((function(e){return Object(T.jsx)(d.a,{className:a.btn,variant:"contained",size:"small",color:i.filterState.filterType[A]===e?"primary":"default",onClick:function(){return i.changeFilterType(A,e)},disableElevation:!0,children:e})})),Object(T.jsx)(u.a,{})]}):null,("visType"===A||"conference"===A)&&Object.keys(i.filterState[A]).map((function(e){return Object(T.jsxs)(w.a,{className:a.option,selected:i.filterState[A][e],onClick:function(){return i.changeFilterState(A,e)},children:[Object(T.jsx)(_.a,{primary:F[e]}),Object(T.jsx)(x.a,{checked:i.filterState[A][e],secondary:!0})]},e)})),"authors"===A&&i.searchedAuthorsList.slice(0,g).map((function(e){return Object(T.jsxs)(w.a,{className:a.option,selected:i.filterState[A][e],onClick:function(){return i.changeFilterState(A,e)},children:[Object(T.jsx)(_.a,{primary:e}),Object(T.jsx)(x.a,{checked:i.filterState[A][e]})]},e)})),"compType"===A?Object(T.jsxs)("div",{children:[Object(T.jsx)(w.a,{className:a.optGrp,selected:i.filterState[A].repeated&&i.filterState[A].stacked&&i.filterState[A].mirrored,children:"juxtaposed"},"juxtaposed"),["repeated","stacked","mirrored"].map((function(e){return Object(T.jsxs)(w.a,{className:a.option,selected:i.filterState[A][e],onClick:function(){return i.changeFilterState(A,e)},children:[Object(T.jsx)(_.a,{primary:F[e]}),Object(T.jsx)(x.a,{checked:i.filterState[A][e]})]},e)})),Object(T.jsx)(w.a,{className:a.optGrp,selected:i.filterState[A].large_view&&i.filterState[A].annotated&&i.filterState[A].coordinated&&i.filterState[A].accompanied,children:"overlaid"},"overlaid"),["large_view","annotated","coordinated","accompanied"].map((function(e){return Object(T.jsxs)(w.a,{className:a.option,selected:i.filterState[A][e],onClick:function(){return i.changeFilterState(A,e)},children:[Object(T.jsx)(_.a,{primary:F[e]}),Object(T.jsx)(x.a,{checked:i.filterState[A][e]})]},e)})),Object(T.jsx)(w.a,{className:a.optGrp,selected:i.filterState[A].nested,children:"nested"},"nested_father"),["nested"].map((function(e){return Object(T.jsxs)(w.a,{className:a.option,selected:i.filterState[A][e],onClick:function(){return i.changeFilterState(A,e)},children:[Object(T.jsx)(_.a,{primary:F[e]}),Object(T.jsx)(x.a,{checked:i.filterState[A][e]})]},e)}))]}):null,"authors"===A&&i.searchedAuthorsList.length>g?Object(T.jsx)(w.a,{className:a.option,onClick:function(){v(g+50)},children:Object(T.jsx)(_.a,{primary:"..."})}):null]})]})})})}))),H=Object(h.a)((function(e){return{root:{width:"100%",height:"15%",margin:"0 0px 0 0px"},grid:{width:"100%",height:"50%"},text:{textAlign:"right",color:"steelblue",marginTop:"2.5%",marginRight:"2.5%"}}}));var L=Object(g.b)("d")(Object(g.c)((function(){var e=H();return Object(T.jsxs)("div",{className:e.root,children:[Object(T.jsxs)(A.a,{className:e.grid,container:!0,item:!0,xs:12,children:[Object(T.jsx)(E,{className:e.leftCard,value:"Composition Type:"},"compFilter"),Object(T.jsx)(E,{className:e.rightCard,value:"Visualization Type:"},"visFilter")]}),Object(T.jsxs)(A.a,{className:e.grid,container:!0,item:!0,xs:12,children:[Object(T.jsx)(E,{className:e.leftCard,value:"Conference:"},"confFilter"),Object(T.jsx)(E,{className:e.rightCard,value:"Authors:"},"authFilter")]})]})}))),R=i(18),B=i(406),N=(i(235),i(290),Object(h.a)((function(e){return{root:{width:"100%",height:"8%",marginBottom:"5px"},bar:{marginTop:"1.8%",height:"70%",width:"100%"},slider:{marginLeft:"7%",marginRight:"9%"}}}))),J=Object(R.a)({root:{color:"primary",height:8,padding:"7px"},thumb:{height:12,width:12,backgroundColor:"#fff",border:"2px solid currentColor",marginTop:-2,marginLeft:-6,"&:focus, &:hover, &$active":{boxShadow:"inherit"}},active:{},valueLabel:{left:"calc(-50% - 8px)"},track:{height:8,borderRadius:4},rail:{height:8,borderRadius:4}})(B.a);var K=Object(g.b)("d")(Object(g.c)((function(e){var t,a=e.d,s=N(),o={title:{},tooltip:{},legend:{},grid:{left:"4%",right:"4%",top:0,bottom:"0px"},xAxis:{show:!1,type:"category",data:Object.keys(a.imagesYearList)},yAxis:{show:!1},series:[{type:"bar",data:Object.keys(a.imagesYearList).map((function(e){return a.imagesYearList[e]})),itemStyle:{color:"#afafaf"}}]};return r.a.useEffect((function(){var e=i(250);null!==t&&""!==t&&void 0!==t&&t.dispose(),(t=e.init(document.getElementById("bar_chart"))).setOption(o),window.addEventListener("resize",(function(){t.resize()})),t.off("click"),t.on("click",(function(e){a.changeFilterYears(e,[e.name,e.name]),a.changeFilterYearsCommit()}))}),[o]),Object(T.jsxs)("div",{className:s.root,children:[Object(T.jsx)("div",{className:s.bar,id:"bar_chart"}),Object(T.jsx)("div",{className:s.slider,children:Object(T.jsx)(J,{min:2006,max:2020,value:a.filterState.years,onChange:a.changeFilterYears,onChangeCommitted:a.changeFilterYearsCommit,"aria-labelledby":"discrete-slider-custom",step:1,valueLabelDisplay:"on"})})]})}))),U=i(123),Y=i(407),Z=i(263),X=i(403),Q=i(395),$="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAADUAAAA1CAYAAADh5qNwAAAACXBIWXMAABCcAAAQnAEmzTo0AAAAAXNSR0IArs4c6QAAAARnQU1BAACxjwv8YQUAAAUbSURBVHgB7ZrBTxtHFMa/XVxIjUqQIiepRIRRo0oFqYFUVI1yqHuK2kptemiuca4lEr2015C/IDduUYjUW3rIBSQuDaiqAqQC92AOUVK2CqhgN1WgAkoBb983YR3b2LszZom8UX4Hj9f7dj1vZva9b2fGggZzC277v0fQa1v40gJSroUkXLTjkJH/yriAswtMWi7unnvbcjSvqw2d2YljsAB8+zKcCEIqO7Hr4ro4NxFgV52ZnDvouhhqBGcqsSyM7BaUc07V89V+nM65N1CQ3mlsnJ0dfHW+w8pUntjn1MyKe0t6KI0oYOHZzjY+qXSszKmI9FA54lihgL7SoVh06v6fblqi2y1EE6d5E319XdYzHtj8EIeS4tA1RJekpJziCFNOxWxc5glEGNvGIFOQ+s6PQlQCgx+SerzesqeX3IvQ6KXs4lM4+TXoMPN4Wds2t7aJB49XEAZNFj5mGXObkLI0Lph/8hSJtjjyq5uIt8TQc+pYTdtfH62gu+MYnNyasku0vVnT9q+1DTx4tIx4cwwbWzvoP30C9SKSKsUhKEMRZ0wudPKryEvremQX/8a6VKYa89K7eam0Bytfy5b35L1f/M+a6kVTNuNI2SJOe3EAJrNP8EdJZfwYnXOkN/7TsmUDcHSYYrtIxurVdsPjvyHV0xG67UR2sax3TRE11G4jJIbuTGlXxsT2zv2HylETQnOqkXglnYrBkP7TJ9Ha8gaOH42rUJ3qOaXKS+felVDfXGbrnau0qWbL0L++1abuzZJ431kemlNjcwtSGf8/GLjwvrEtE3tOgokfn/d1aecwa3pZ4oUGzC864ZgJ2sSW6AQN9mxrS3AfiOS7rt1TTm7VIOO7kmdW8NnZLugwOusgnepGWGgHCi/jZyUhssJ+0HnqufWtbYzNLiAIT/uNTMwjDIyjn4mc8ZzzoB1lVS0qhW1Q49XiwCHdRM5QvFJW6TIymUU91O2USaansB0OiG6lXLoxioMQWvJlpVl5HdgYbBQdONwHbv4EE17LpKhgLJNK5QzxvnuyqRS+ITNXdSbalFTqTLxVlEyeFColnXpPld998cHecY+6B0sTtBWFeg6mHhZVQC1YAWb+73/4WTnjR6q7Q71nDdy85/vKT9hwnrN+UFGELpM8OWMifXTfrYIalBjLJEYinTfY50rCwWVN6aNTWROMZBJbdEaS7WiA9KGSoNLgNSb5KSyMo9+GGobbxWNKmayPoiideaKjpq/m9VB3SKeOy+3pwHzAVNa66rl/VGPoJuiDULdT1HClmo8O1prT4xTa2OzvxWPa+c3pld6n1j39CC35/iiyR3f+jyK4UtgyuKSHx1WPDo9n1LPI5/eqoUQixsn3sGAeGrhwBklJ0F6yZeK99vVHMCXGJX2rQZZx+t85qcrSRNyaMJt0cW1kYtyrAAOnOJuk+zsr941MrjAPdSaOqkTL8jBxt+HEuPGiCbgYZBw/EsPk1BIm55d87TwnGBGvivzx49OzSTVLFBqy/stFbWtvaTR4IiECcH/FhyesKzZXtbmTBK8AuwXcZqlCOrfGIOKwY7ztPcopHkS9t6Rjrnjf7YofHUSQglu+T6lsufeXnNsrieteI26yqoU4dFscSpf+tm8NO0qOVXOI7NN+549bGe71QYMPxb0hl652zne3geSwIclhDbUbRmcjY+AWCiZnKVLi3KCUB1rJrxtRClLRu8xDQbsyn5sb4O2l5TYF6+U8c06hCRk+EiYX/Q9GM4fBUMUWTAAAAABJRU5ErkJggg==",ee="data:image/png;base64,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",te="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAADUAAAA1CAYAAADh5qNwAAAACXBIWXMAABCcAAAQnAEmzTo0AAAAAXNSR0IArs4c6QAAAARnQU1BAACxjwv8YQUAAATsSURBVHgB3ZrPbxtFFMe/u04c24kd08YOrdLEaaXSNkATIhWhKCQ99dICuVWiiHBEHMIZIRGExAEO/QeQSiUOSBxACjcOLSrQNvxKRdWiqqJO0tT5jeM4duLYHt6bdp34V7y7acyuP9J4Pbuz9n53Zt57O/sU6ODPB8K/7kK3quB1BRgUCkIQ8GOPof+aEEA4A/yoCHz3ygElrPO88rCYtAcjWeD9aoioBF3s1YzAxyTuaoV2pRmfFyNCYNQKYgpRFHyZyUpx4ZLHS+28OS8uIku9Y23C6TSG+tqUicIDRaLG58Ql6qFh2AEF0fQmThcKyxNlkx7Kh4Rls+jZPhRzoq5HxDBZt0uwJ2FnEj09nUqUKyp/kKAQCfoI9iVELic3wqSoOhVv8wHYGFXFCLsg+Z0/snYxDDtBrkfrLfXmjHgDNu8lDYeCAd6qwoFB1AgUUg3yEKShiJOoIZIeDKoUnHYbOenX+3O6287HkrLo5c70kqH2pVAFQnVGYrs7D5fw+dhv+OT8y2iod1Rs/8OtadyfXcG7Z56HHr64chuv9R5BsKsNZqFoyF8HEzz6N45mj7Niu2RqExly98txfXd/NZmS26mFVXz10135/YOhUzCKKVF7jdPpQEeLD2ZRYUHogZAtGc72dsIMlhS1sZnB1GIMZqna8HM762VpqCtvYBzq4/i6PeA1NZc0qiaKjQYXFhb0NWJ/k6eozfm+Y+hq24/dUvXhx8ImF6O4/XAOS/EEWUeROxb0uiGwe/63OZVKZ6S4W1MR3JtdxPRyTPopdsC7xRKGIr6ewkIsnuenvv/9H5jF9Jxy0oTn4nY66Xms9KJUk2uZ2iRpDjVhg1ZJeOhxD1X8bfJT6zralcO0KL44LnyX99GkP+j3SpHbOUchz9rGJtr2bTlSnkeR6OqO4lwUgrX6PLh2d0bWjx58Bq3NHujlqVi/ZbpQLoXiAj43AnDntWWrx4WFcSlFbC2Fa3/P5OrNnobqi9LQxDV7XPC6GqT51gR++PUveOvV43iO7jrDN6DJ5cQq9fRKYj2v54J+Dy70H9+qN7thhD3xU3yRXLYzuRCjZewI0tlUxfN5+LW3eGEWS4ZJbP0+/XbctAW0pCgtSg/6G2EGy0bpbBhOHWmFGQzNKXdDvdy+cCgoxz2HODzRo4mkLv+jF47S51YSMIshUZ0BHz670I8W75Z5ZUvHfii+voG52FqRgTCDr9GJF9tb8NfkoqwfoqjdT2ZdL4ZE8RrF6Dc3cHF4QPZUIX6PW5pyjhwST6IHfpw3CvupsT+2jMTZlw7D37FHojTuRRZ1rVGYhf3Uud7DubpR827JNYr5aAJjZcz5e2dOyghjJ2y38KJnac6QqA4yFPxkevpECEbpapvCwIkOhALlV4mOHniEAIVEz5I5f7P/GMyi3JgVD5QaeUHAZBQM8ZPQBGoIsYmwyokXqBXo/S+/1FY5kwQ1Ao06qUXlt9qcSYIaIJPFZd7KgJZTY2BzuGO09B4piit27y3qmHe072rBzjBsSFbk5ynlrW39PC+66wSuWDHJqhwk6DIJGt6+r2jBzk7CSgliip58+4LKBOf6wOJD8cmQGy51bMckxusRMUohh6WyYfQkMioVfkPmLdFmkMSN0NbQm/ynBkUK7FjZD1XKynzc3ABaLi2nKSjVmXPhrAMTPCWMnPQfIIbZctEp7qoAAAAASUVORK5CYII=",ie="data:image/png;base64,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",ae="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAADYAAAA1CAYAAAAK0RhzAAAACXBIWXMAABCcAAAQnAEmzTo0AAAAAXNSR0IArs4c6QAAAARnQU1BAACxjwv8YQUAAAT3SURBVHgB3ZrNbxtFGMbf2fVHrPZgcuEQkOyKAxyKjJAqVQWSSCBVXBqucAnqtVLSA1dI+AcAqdcKeqDX5FgJpDhISaUKpIhcOJTaUVsJOJQc2tpe7+7beWY97maz9n7YTr35Sc54Z3ez88z7Ma/tERQTbmyVbcrVyMhfYXYXZE+FSJRp8uwxGU1me5upu1mqLjbj3CSiLlCCjJkVKWb1hIREIOqC7fV89cP60KuGnbQOdleIeW06BAUQ4ifHba8PsuBAYd2D3e+YaZWmm6bDncUwcaHCrIOdH4nFMmWDQ4t58Wz10p6/0wheBUtlSBQoF4TYajW2Kv7OI8JajZ3lDLhfGGVTFDf8HX1hUGwK8Q1ll1qnsbOmD/rCTGMGoiqUYYQQK1ie8F4JUwfsLlH2KXeouIw3SlibCktTuValwBDiimrxxzSMeTo18AI80Isx5hqdItqyptXJI1KY8+996v61TVnAJKNixL04S8JYZvfYwl4F/OyJmtA0TLUw68871P71RipxUyuMrRbZD+6RODNL5utvUVKmVpjzaF+1aUSBsQvDLD/7eZXc/x/TKNh/31Nt4d3LlIaJWUwUSsf6uNtSgpEUhqGSxn/3yXhtTrliGnI0ZnLnLqhXEAy2/csNcnuiih9dpdyb50P/R7dnrfzb6QuiiVgM7nis7+F+XxTo7t8ZaDmnd3/a+AJjF9a5e1u9rD82jj5IupUfuGRLWjAoDqkdEwBrpnVD9TwaIxisthaqlOeb3/YHjtkvXvyccm+8dD+cgzh/otH3m9ULNApjFeY89FJ0TsYG4kwP3Nb9sk9bDm3+/GUv9nyLsCtbWMoff0g6SRlb8sAALRk3GFRBCkOLF2Kp89tNYpm2hRSjr5mZv6pa4+yscl2IgzWVG/qSDwTDirB2EsZmMZQ/AOsOBqxdsCgFGPIY5zvbN1WfFgXR2kWxPNi9RdmfDZVlU2TH1BZDXCBBYEbxcBwrF+rNtvPksRo40vrMJ9eos3tbrU15KVxfD7GuLJ2K73+m+mA1ypeOJBoIFoU5SkoqYbAGZl+nbx38/ioBMWJ8+lV/kBCHSdApHP0FKUjHEo5L8npnxIpFk8oVdUo+1h8YVDDFB9elfC8WNSoupcVgybC1MAnpLGYlz1IAlg2KDZ5X7tgD4mY+vkZpSGUxxFFYLVgYEuSYjG6EFYKf0OEZUXXlIFIJgyisQf1j6T6Il2GVAu5BkhhKvhSvLwbps+JTbyYhaJRi1U/hnXlyH72sKZFBwzwjDomFoQqwft8gc3aOTJRI50YrffzA4qWlr5ULQtCweIwisTDnH68SsB8Qnfnie5oEo1T1msTC8FB/zTetJBamkkDCuu2kYRKHWliTYvyEhNSL7zNeFcjEcb4DEWQ3e8JE09u3MRjP79N9sTIu4sZel0xPGLO7LX80W4j6p+MI6hOgiR/a1QLtklun04IQdTRKWEntcvE6so7j2rfQ9ksqh+11yjyiXuptReoLOw1Wc5i+1O+N4yf4kDIIM6+Xqheb+viIMJywmBYzJ475h2L10pq/K3Qv1dPGTq0gaCsLOwnkUnWrWP1gOdgf+nkM64DDxnvkVSRTi8t0PUwUiNyIiW08Yvq2ItUt5uvBHW9+IoWBVuNuRc7PginECsXYYTAZZNwLYxPrVClidymIJcyPJ9KuCBI1cQIx6GKzJdHeMOuE8QKsZClDXZFHMAAAAABJRU5ErkJggg==",re="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAADUAAAA1CAYAAADh5qNwAAAACXBIWXMAABCcAAAQnAEmzTo0AAAAAXNSR0IArs4c6QAAAARnQU1BAACxjwv8YQUAAAR3SURBVHgB3Zo/bBtVHMd/v3e24ysdTAeoVEA2rUQZAomEIvHXjsRQwUC7MLAQlBUpXbpCzcLI0rUqHciajJVAioOUtKpARGRhKNghRAKG4CEl9vnufn2/55zrP+e78/mc3OUjOXf33vPlfd/vz3vnewgBoOpazoTUDIj0R0R2SZbkATAHk2eLQNSIzHWC1qpemK8F+RJ6VSoxIrskhVw/JhE+YAXJLKcL71Y8Ww2rMHY2l4DoZjzE9IH4rWU3ysMs5yqqtbP5DRFch3hTM4iunS28vdVfMSDK2Nm4A4QLkAzqUth8vzDRfcEWSpAgJpdBXDusruW7CzuWOqxuLGiIdyCZ1NLUnMXCfJ0vlKVYqRT0JSSXvAGZTg5QolIi+ylXQIJBxCWegvhciSKiBUg+Ocdaoln98Sok3EoOiKLIR4GgleDUQCV2QQEoXodjwvz9ITz+brJzuiGNJGPKngn6BXq8D9Q6hCgw/9qG5vptiBqCVF6Msrb7f/UrsP7chiiw9/fA+m8PogaBcgJiRuP7W9D6bR3GIXailIsb47l4LESxZVrb9yAqYiHKlrFlH+wPlHO2DGO1yEWx+zR+uKU6Oi7NB8uh7hO9KDmy1j+PIhEVlhREjHj2Augf3FDHk2IiMXWSgpjILcWupz1/ybcdt8GM3j5/YbpTnrpc7AxKevoKiLPnYFQiF2XubvuK4mTCneUPn2vnLnTKUy9Od87TF+fa53JphmkdghK5qKk3rvm24eXWKPAgZd//PHD7yEV5ob00DWfOf+HZht2X3c9xTePXez3uGYSJimr+vAIZGSP4TDsulAsduRG7FHe4u1516OW5nntkXrsi/wR3PXUPCInq1OayGlkm/WpRBbYDz1OmXP5octT7O6q+L1cQXC+koPTl4tD/0y04KKFFGT+tqGeizrUcdZLHzJEwdqEzH389NMC5fuq9RdDO+2fKUQk9T5l/PBwos3Z7n7X8MhZnuv42vLBt3l92vX9QQluKA7l/sYk+vs/p3knZbhgyBp1nKSVKunjqlSKMSmhLuf0zt9hx4AHguccL6+9HPdfmbrin7NCW4qzEluHHAz6m5ETpJYrbeCUEp03PdYgkwYyV0rmTfh0dham3PoFG5TbY9T3QnrvUTuchCCWKfZ9dI1tcjHTxypbRP7wB4xIqptj3OT7cnlbjQChLZUuLYMmfuLwy2Ukysijr36cZipPEcZK6OBesnfzUYIQXBDx/jDMxjkMwUdYWtmoPVgjsq3BKkO+AZ4VF5ng/h8aLOr/UFgTaKpwWEJUWoRferPFOEjgFWLZ5l49qnpIuWIbEgxX9aHuPEtW+SLa1LILPnHPRV1iDBCJfxJfbYdSmZxvPQXVjJoOwFstNVkMgsu9OFd5Z6C4b2JuUJGFugpiBBS3neYvELMTcFdnl3AQxnpsYm9WNm4gYt90wFYussu6xkdFTFHNYvZ+XP3iVNMQleRn4TX60UB1QrPI8pPvsymR8RfXcuvpLrgEHMwjIn4nHnC1DwALYctuo6MUTm824Xxqr/+IAAAAASUVORK5CYII=",se="data:image/png;base64,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",oe="data:image/png;base64,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",ne=Object(h.a)((function(e){return{root:{position:"relative",width:"100%",maxWidth:"100%",minWidth:"0px",height:"8vh"},tabs:{width:"100%"},tab:{textTransform:"none",minWidth:"0px"},btnGrp:{},label:{display:"flex",alignItems:"center"},labelText:{fontSize:"0.875rem",letterSpacing:"0.02857em",lineHeight:1.75,fontWeight:500},img:{width:"42px",height:"42px",padding:"0 8px 0 0px"}}})),le=function(e){switch(e){case"Repeated":return $;case"Mirrored":return ee;case"Stacked":return te;case"Large Panel":return re;case"Coordinated":return se;case"Accompanied":return ae;case"Annotated":return ie;case"Nested":return oe}},ce=Object(R.a)({indicator:{display:"flex",justifyContent:"center",backgroundColor:"transparent","& > span":{position:"relative",height:"1.5px",width:"180px",backgroundColor:"#3f51b5"}}})((function(e){return Object(T.jsx)(X.a,Object(l.a)(Object(l.a)({},e),{},{TabIndicatorProps:{children:Object(T.jsx)("span",{})}}))}));var he=Object(g.b)("d")(Object(g.c)((function(e){var t=e.d,i=ne(),a=r.a.useState(0),s=Object(n.a)(a,2),o=s[0],l=s[1],h=r.a.useState(-1),d=Object(n.a)(h,2),p=d[0],u=d[1],g=function(e){var i=0;if("and"===t.filterState.filterType.compType&&0===t.filterStateSelected("compType"))return!1;if("coOccurrence"===e)return!1;if("juxtaposed"===e){if(["repeated","stacked","mirrored"].forEach((function(e){!1===t.filterState.compType[e]&&(i+=1)})),3===i)return!0}else if("overlaid"===e){if(["large_view","annotated","coordinated","accompanied"].forEach((function(e){!1===t.filterState.compType[e]&&(i+=1)})),4===i)return!0}else if("nested"===e)return!t.filterState.compType[e];return!1},y=function(e){return("and"!==t.filterState.filterType.compType||0!==t.filterStateSelected("compType"))&&(e=f[e],!t.filterState.compType[e])},f=Object(c.a)({"Co-occurrence":"coOccurrence",Repeated:"repeated",Stacked:"stacked",Mirrored:"mirrored","Large Panel":"large_view",Annotated:"annotated",Coordinated:"coordinated",Accompanied:"accompanied",Nested:"nested",Juxtaposed:"juxtaposed",Overlaid:"overlaid"},"Nested","nested"),v=function(){switch(o){case 0:return[];case 1:return["Repeated","Stacked","Mirrored"];case 2:return["Large Panel","Annotated","Coordinated","Accompanied"];case 3:return["Nested"];default:return[]}}();return Object(T.jsxs)("div",{className:i.root,children:[Object(T.jsxs)(X.a,{className:i.tabs,value:o,onChange:function(e,i){t.dataState.overviewDetailState=!1,t.changeOverviewState(f[e.target.textContent]),l(i),u(-1),"nested"===f[e.target.textContent]&&u(0)},indicatorColor:"primary",textColor:"primary",variant:"fullWidth",children:[Object(T.jsx)(Q.a,{className:i.tab,disabled:g("coOccurrence"),label:"Co-occurrence"}),Object(T.jsx)(Q.a,{className:i.tab,disabled:g("juxtaposed"),label:"Juxtaposed"}),Object(T.jsx)(Q.a,{className:i.tab,disabled:g("overlaid"),label:"Overlaid"}),Object(T.jsx)(Q.a,{className:i.tab,disabled:g("nested"),label:"Nested"})]}),Object(T.jsx)(ce,{className:i.tabs,value:p,onChange:function(e,i){e.target.textContent?t.dataState.overviewDetailState=f[e.target.textContent]:t.dataState.overviewDetailState=f[e.target.id],t.updateHeatmapData(),u(i)},indicatorColor:"primary",textColor:"primary",variant:"fullWidth",scrollButtons:"auto","aria-label":"scrollable auto tabs",children:v.map((function(e){return Object(T.jsx)(Q.a,{className:i.tab,disabled:y(e),label:Object(T.jsxs)("div",{className:i.label,children:[Object(T.jsx)("img",{className:i.img,src:le(e),id:e}),Object(T.jsx)(m.a,{className:i.labelText,id:e,children:e})]})})}))})]})}))),de=(i(291),Object(h.a)((function(e){return Object(Y.a)({margin:{margin:e.spacing(1)}}),{root:{width:"100%",height:"66%",position:"relative"},optionWrap:{position:"relative",zIndex:99,display:"flex"},optionbar:{},checkbox:{},heatmapWrap:{width:"30vw",height:"90%"},heatmap:{zIndex:1,width:"100%",height:"100%"},bar:{width:"100%",height:"38%"},icon:{marginLeft:"5%"},btnGrp:{justifyContent:"flex-end"},OverviewTab:{}}})));Object(Z.a)({palette:{primary:{light:"#2179B6",main:"#2179B6",dark:"#2179B6"}}});var pe=Object(g.b)("d")(Object(g.c)((function(e){var t=e.d,a=de(),s={tooltip:{position:"top",trigger:"item",formatter:function(e){if("heatmap"===e.seriesType){var i=e.data;if(!i)return;return"".concat(i[2]," results</br>")+e.marker+"Child: ".concat(F[t.indexToClient[i[0]]],"</br>")+e.marker+"Parent: ".concat(F[t.indexToHost[i[1]]])}return e.marker+"".concat(e.name," ").concat(e.data)}},grid:[{top:"30%",left:"30%",right:"7%",bottom:"10%"},{top:"3%",bottom:"70%",left:"30%",right:"7%"},{left:"3%",top:"30%",right:"70%",bottom:"10%"}],xAxis:[{gridIndex:0,show:!1,type:"category",data:Object.keys(t.filteredVisType).map((function(e){return F[e]})),inverse:!0},{show:!1,gridIndex:1,type:"category",data:Object.keys(t.filteredVisType).map((function(e){return F[e]})),inverse:!0},{gridIndex:2,show:!1,inverse:!0}],yAxis:[{gridIndex:0,show:!1,type:"category",data:Object.keys(t.filteredVisType).map((function(e){return F[e]}))},{gridIndex:1,show:!1},{show:!1,gridIndex:2,type:"category",data:Object.keys(t.filteredVisType).map((function(e){return F[e]}))}],visualMap:{show:!1,seriesIndex:0,inRange:{color:["#ffffff",t.dataState.matrixColor]},min:0,max:10},dataZoom:[{type:"inside",xAxisIndex:[0,1],filterMode:"none"},{type:"inside",yAxisIndex:[0,2],filterMode:"none"},{show:!0,realtime:!0,filterMode:"none",xAxisIndex:[0,1],left:"30%",top:"91%",bottom:"5%",right:"7%"},{show:!0,realtime:!0,filterMode:"none",yAxisIndex:[0,2],left:"94%",top:"30%",bottom:"10%",right:"2%"}],series:[{name:"composization",type:"heatmap",data:t.heatmapViewData,xAxisIndex:0,yAxisIndex:0,itemStyle:{borderWidth:"0.5",borderColor:"#ffffff"},emphasis:{itemStyle:{shadowBlur:10,shadowColor:"rgba(0, 0, 0, 5)"}}},{name:"ClientBar",label:{show:"true",color:"#6F6F6F",formatter:"{b}",rotate:90,position:"insideBottom",verticalAlign:"middle",align:"top"},xAxisIndex:1,yAxisIndex:1,type:"bar",barCategoryGap:"1px",itemStyle:{color:"#f1f1f1"},emphasis:{itemStyle:{color:"#f1f1f1",shadowBlur:10,shadowColor:"rgba(0, 0, 0, 5)"}},data:Object.keys(t.heatmapData).map((function(e){var i=[];return Object.keys(t.heatmapData[e]).forEach((function(a){i=[].concat(Object(U.a)(i),Object(U.a)(t.heatmapData[e][a]))})),new Set(i).size}))},{name:"HostBar",label:{show:!0,color:"#6F6F6F",formatter:"{b}",position:"insideRight"},xAxisIndex:2,yAxisIndex:2,type:"bar",barCategoryGap:"1px",itemStyle:{color:"#f1f1f1"},emphasis:{itemStyle:{color:"#f1f1f1",shadowBlur:10,shadowColor:"rgba(0, 0, 0, 5)"}},data:function(){var e={};return Object.keys(t.heatmapData).forEach((function(i,a){Object.keys(t.heatmapData[i]).forEach((function(r){0===a&&(e[r]=[]),e[r]=[].concat(Object(U.a)(e[r]),Object(U.a)(t.heatmapData[i][r]))}))})),Object.keys(e).map((function(t){return new Set(e[t]).size}))}()}]};return"".concat(t.detailsBar.type,": ").concat(F[t.detailsBar.visType]),t.detailsBarData.map((function(e){return"Parent"===t.detailsBar.type?F[t.indexToClient[e.idx]]:"Child"===t.detailsBar.type?F[t.indexToHost[e.idx]]:void 0})),t.detailsBarData.map((function(e){return e.num})),r.a.useEffect((function(){var e=i(250).init(document.getElementById("heat_map"));e.setOption(s),e.off("click"),e.on("click",(function(e){if("bar"===e.seriesType)t.detailsBar.type=1===e.seriesIndex?"Child":"Parent","Child"===t.detailsBar.type?t.updateImgList(j[e.name],null):t.updateImgList(null,j[e.name]);else if("heatmap"===e.seriesType){var i=e.value;if(0==i[2])return;var a=t.indexToClient[i[0]],r=t.indexToHost[i[1]];t.updateImgList(a,r)}})),window.addEventListener("resize",(function(){e.resize()})),t.detailsBar.show||e.resize(),e.dispatchAction({type:"dataZoom",dataZoomIndex:[1,2],start:0,end:100}),e.dispatchAction({type:"downplay"}),e.dispatchAction({type:"highlight",seriesIndex:0,dataIndex:t.highlightIndexList})}),[s,t.detailsBar.show,t.detailsBar.select,t.highlightIndexList,t.dataState.matrixColor]),Object(T.jsxs)("div",{className:a.root,children:[Object(T.jsx)("div",{className:a.optionWrap,children:Object(T.jsx)(he,{className:a.OverviewTab})}),Object(T.jsx)("div",{className:a.heatmapWrap,id:"heatmap_wrap",children:Object(T.jsx)("div",{className:a.heatmap,id:"heat_map"})})]})}))),ue=i(408),ge=i(256),me={transition:"transform .135s cubic-bezier(0.0,0.0,0.2,1),opacity linear .15s"},ye={transform:"translateZ(0px) scale3d(0.9, 0.9, 1)",transition:"transform .135s cubic-bezier(0.0,0.0,0.2,1),opacity linear .15s"},fe={backgroundColor:"#eee",cursor:"pointer",overflow:"hidden",position:"relative"},ve=Object(g.b)("d")(Object(g.c)((function(e){var t=e.d,i=e.index,a=e.photo,r=e.margin,s=e.direction,o=e.top,n=e.left,c=(100-30/a.width*100)/100,h=(100-30/a.height*100)/100;ye.transform="translateZ(0px) scale3d(".concat(c,", ").concat(h,", 1)");var d=(t.zoomInState.activate?t.zoomInImgList:t.imgList)[i];return"column"===s&&(fe.position="absolute",fe.left=n,fe.top=o),Object(T.jsxs)("div",{style:Object(l.a)({margin:r,height:a.height,width:a.width},fe),className:"",onClick:function(){t.activeSelectedImgState(d),document.getElementById("gallery_wrap").style.width="49%"},children:[Object(T.jsx)(ge.LazyLoadImage,Object(l.a)({alt:a.title,style:Object(l.a)(Object(l.a)({},me),ye)},a)),Object(T.jsx)("style",{children:".not-selected:hover{outline:2px solid #06befa}"})]})}))),be=i(397),we=i(398),_e=i(399),xe=i(185),ze=i(396),ke=i(258),Te=i.n(ke),Se=i(259),Oe=i.n(Se),Ae=i(410),Ve=Object(h.a)((function(e){return{root:{},labelRoot:{display:"flex",alignItems:"center"},labelIcon:{padding:"0 15px 0 10px"},labelText:{fontSize:"1em",lineHeight:4}}})),Ce="1",De=Object(R.a)((function(e){return{root:{backgroundColor:e.palette.common.black,color:e.palette.common.white}}}))(Ae.a),Me=function(e){switch(e){case"repeated":return $;case"mirrored":return ee;case"stacked":return te;case"large_view":return re;case"coordinated":return se;case"accompanied":return ae;case"annotated":return ie;case"nested":return oe}};var Ie=Object(g.b)("d")(Object(g.c)((function(e){var t=e.relationsTree,i=e.d,a=Ve(),r=function(e,t,a){var r=t||"balanced",s=a||null;i.transformVisualizationsFromRaw(e,r,s)},s=function(e){var t={};return e.map((function(e){return"string"!==typeof e?e:!0===t[e.split("-")[0]]?void 0:(t[e.split("-")[0]]=!0,e)})).filter((function(e){return e}))},o=function(e){if(1===e.vislist.length&&"string"!==typeof e.vislist[0].vislist){var t=s(e.vislist[0].vislist);return n(t)}return 2===e.vislist.length?e.vislist.map((function(t,i){var a=s(t.vislist);return Object(T.jsx)(De,{onClick:function(){return r(e.vislist[i],"unbalanced",e.relation)},nodeId:Ce+=1,style:{padding:"0 0 0 70px"},label:0===i?"Child":"Parent",children:n(a,!0)})})):"string"===typeof e.vislist[0].vislist?n(e.vislist[0].vislist):void 0},n=function(e,t){return e.map((function(e){return Object(T.jsx)(T.Fragment,{children:"string"===typeof e?Object(T.jsx)(De,{style:{padding:t?"0 0 0 0px":"0 0 0 70px"},nodeId:Ce+=1,label:F[e.split("-")[0]]}):Object(T.jsx)(De,{onClick:function(){return r(e)},nodeId:Ce+=1,label:Object(T.jsxs)("div",{className:a.labelRoot,children:[Object(T.jsx)("img",{src:Me(e.relation),color:"inherit",className:a.labelIcon}),Object(T.jsx)(m.a,{variant:"body2",className:a.labelText,children:"".concat(F[e.relation]," Visualization")})]}),children:o(e)})})}))};return Object(T.jsx)("div",{children:Object(T.jsx)(ze.a,{className:a.root,defaultCollapseIcon:Object(T.jsx)(Te.a,{}),defaultExpandIcon:Object(T.jsx)(Oe.a,{}),multiSelect:!0,children:t&&n(t)})})}))),We=function(e){console.log(e);var t=e.split("_");return"https://github.com/composite-visualizations/data/blob/main/".concat(t[0],"/").concat(t[1],".png?raw=true")},qe=Object(h.a)((function(e){return{root:{position:"absolute",left:"65vw",top:"13.2vh",width:"35vw",height:"88vh",backgroundColor:"black"},img:{maxWidth:"100%",maxHeight:"100%",boxShadow:"-3px 4px 3px 4px rgba(200, 200, 200, 1)"},imgView:{position:"relative",display:"flex",justifyContent:"center",alignItems:"center",width:"100%",height:"40%"},imgWrapping:{position:"relative",maxWidth:"98%",maxHeight:"98%",display:"flex"},icon:{color:"white"},button:{display:"flex",flexDirection:"row-reverse"},infoBlock:{display:"block",position:"relative",margin:"20px 0 0 0",maxHeight:"45%",padding:"0px 20px 0px 20px",overflowY:"scroll"},caption:{margin:"5px",width:"100%",color:"white",backgroundColor:"black",lineHeight:1.25},textWrap:{display:"flex",height:"100%",maxHeight:"30%"},text:{display:"inline",margin:"5px",maxWidth:"80%",color:"white",wordWrap:"break-word"},textType:{width:"70px",display:"inline",textTransform:"capitalize",margin:"5px",maxWidth:"50%",color:"#7689EF",fontWeight:"bold",wordWrap:"break-word"},bottomBtn:{display:"inline",color:"white"},index:{display:"inline",color:"white"},btnG:{position:"absolute",bottom:"3%",left:"40%"},multilineColor:{color:"white"},input:{width:"50px"},canvasOnImg:{position:"absolute",width:"100%",height:"100%"},relTable:{maxHeight:"10vh"}}})),Fe=function(e){var t=e.shapeProps,i=e.isSelected,a=e.isHighlighted,s=e.onSelect,o=(e.onChange,r.a.useRef()),n=r.a.useRef();return r.a.useEffect((function(){i&&(n.current.nodes([o.current]),n.current.getLayer().batchDraw())}),[i]),Object(T.jsxs)(r.a.Fragment,{children:[Object(T.jsx)(xe.b,Object(l.a)(Object(l.a)({onClick:s,onTap:s,ref:o},t),{},{stroke:a?"#3977AF":t.stroke,fillEnabled:a,strokeScaleEnabled:!1})),i&&Object(T.jsx)(xe.d,{ref:n,rotateEnabled:!1,keepRatio:!1,boundBoxFunc:function(e,t){return t.width<5||t.height<5?e:t}})]})};var Ge=Object(g.b)("d")(Object(g.c)((function(e){var t=e.d,i=(e.top,qe()),a=function(e){e.target};return Object(T.jsxs)("div",{className:i.root,children:[Object(T.jsx)("div",{className:i.button,children:Object(T.jsx)(f.a,{onClick:t.closeSelectedImgState,children:Object(T.jsx)(be.a,{className:i.icon})})}),Object(T.jsx)("div",{className:i.imgView,id:"imgView",children:Object(T.jsxs)("div",{className:i.imgWrapping,id:"imgWrapping",children:[Object(T.jsx)("img",{onLoad:function(e){var i=e.target,a=.98*document.getElementById("imgView").clientHeight,r=.98*document.getElementById("imgView").clientWidth,s=Math.min(a/i.naturalHeight,r/i.naturalWidth);t.imgState.imgSize.height=i.naturalHeight,t.imgState.imgSize.width=i.naturalWidth,t.imgState.viewDimension.height=s*i.naturalHeight,t.imgState.viewDimension.width=s*i.naturalWidth,console.log(t.imgState),t.getImgDetails(t.imgState.imgId.split(".")[0])},className:i.img,src:We(t.imgState.imgId),alt:"",style:{width:t.imgState.viewDimension.width,height:t.imgState.viewDimension.height}}),Object(T.jsx)(xe.c,{className:i.canvasOnImg,width:t.imgState.viewDimension.width,height:t.imgState.viewDimension.height,children:Object(T.jsxs)(xe.a,{children:[t.imgState.subfigures&&t.imgState.subfigures.map((function(e,t){return Object(T.jsx)(Fe,{shapeProps:e,isSelected:!1,isHighlighted:!0,onSelect:a},e.id)})),t.imgState.visualizations&&t.imgState.visualizations.map((function(e,t){return Object(T.jsx)(Fe,{shapeProps:e,isSelected:!1,isHighlighted:!1},e.id)}))]})})]})}),Object(T.jsxs)("div",{className:i.infoBlock,children:[Object(T.jsx)(Ie,{className:i.relTable,d:t,relationsTree:t.imgState.relations}),Object(T.jsx)(V.a,{className:i.caption,value:"".concat(t.imgState.caption),multiline:!0,color:"primary",InputProps:{classes:{input:i.multilineColor}}}),Object(T.jsxs)("div",{className:i.textWrap,children:[Object(T.jsx)(m.a,{className:i.textType,children:"Title:"}),Object(T.jsx)(m.a,{className:i.text,children:"".concat(t.imgState.title)})]}),Object(T.jsxs)("div",{className:i.textWrap,children:[Object(T.jsx)(m.a,{className:i.textType,children:"Abstract:"}),Object(T.jsx)(m.a,{className:i.text,children:"".concat(t.imgState.abstract)})]}),Object(T.jsxs)("div",{className:i.textWrap,children:[Object(T.jsx)(m.a,{className:i.textType,children:"Authors:"}),Object(T.jsx)(m.a,{className:i.text,children:t.imgState.authors?t.imgState.authors.join(", "):t.imgState.authors})]}),Object(T.jsxs)("div",{className:i.textWrap,children:[Object(T.jsx)(m.a,{className:i.textType,children:"Year:"}),Object(T.jsx)(m.a,{className:i.text,children:"".concat(t.imgState.year)})]})]}),Object(T.jsxs)("div",{className:i.btnG,children:[Object(T.jsx)(f.a,{className:i.bottomBtn,onClick:function(){t.changeImgId(-1)},children:Object(T.jsx)(we.a,{})}),Object(T.jsx)(m.a,{className:i.index,children:"".concat(t.imgList.indexOf(t.imgState.imgId)," / ").concat(t.imgList.length-1)}),Object(T.jsx)(f.a,{className:i.bottomBtn,onClick:function(){t.changeImgId(1)},children:Object(T.jsx)(_e.a,{})})]})]})}))),je=i(260),Pe=function(e){var t=e.split("_");return"https://github.com/composite-visualizations/data/blob/main/".concat(t[0],"/").concat(t[1],".png?raw=true")},Ee=Object(h.a)((function(e){return{root:{width:"100%",height:"100%"},galleryBar:{marginTop:"0.6vh",marginBottom:"0.6vh",width:"100%",height:"4vh",display:"flex",alignItems:"center"},galleryWrap:{margin:"1%",width:"99%",marginRight:0,height:"94%",overflowY:"scroll"},galleryTest:{display:"flex"},slider:{top:"1%",left:"40%",width:"20%"},text:{marginLeft:"3%"},gallery:{marginLeft:"3%",fontWeight:500,lineHeight:1.85},tile:{margin:""},chip:{margin:"10px"}}}));var He=Object(g.b)("d")(Object(g.c)((function(e){var t=e.d,i=Ee(),r=t.zoomInState.activate?t.zoomInImgList:t.imgList;r=0===r.length?[]:r.map((function(e){var i=t.getImageSize(e).width/500*t.imgState.galleryScale,a=t.getImageSize(e).height/500*t.imgState.galleryScale;return{src:Pe(e),width:i,height:a,imgId:e}}));var s=Object(a.useCallback)((function(e){var t=e.index,i=e.left,a=e.top,r=e.photo;return Object(T.jsx)(ve,{index:t,margin:"2px",photo:r,left:i,top:a})}),[]);return Object(T.jsxs)("div",{className:i.root,children:[Object(T.jsxs)("div",{className:i.galleryBar,children:[Object(T.jsx)(m.a,{className:i.gallery,variant:"h5",children:"Gallery "}),Object(T.jsx)(m.a,{className:i.text,children:"".concat(r.length," figures found")}),t.zoomInState.activate&&Object(T.jsx)(ue.a,{label:"".concat(F[t.zoomInState.levelName],": ").concat(F[t.zoomInState.client],"/").concat(F[t.zoomInState.host]),onDelete:function(){t.zoomInState={activate:!1,levelName:null,client:null,host:null}},className:i.chip})]}),Object(T.jsx)(u.a,{id:"gallery_divider"}),Object(T.jsx)("div",{className:i.galleryWrap,id:"gallery_wrap",children:Object(T.jsx)(je.a,{className:i.galleryTest,photos:r,margin:10,renderImage:s})}),t.dataState.selectGalleryImg&&Object(T.jsx)(Ge,{className:i.visImage},t.imgState.imgId)]})}))),Le=i(82),Re=Object(h.a)((function(e){return{root:{width:"100%",height:"92%",display:"flex",flexDirection:"column",alignItems:"center",backgroundColor:"#e5e5e5",overflowY:"scroll"},teaser:{width:"100%"},teaserImg:{width:"100%"},teaserCav:{width:"100%",zIndex:2},content:{position:"relative",width:"70%",paddingBottom:"50px",display:"flex",flexDirection:"column",alignItems:"center"},indicator:{backgroundColor:"#3977AF"},tabs:{width:"100%"},parentDef:{width:"100%",backgroundColor:"white",borderRadius:"5px",boxShadow:"0 0px 4px 3px rgba(176, 190, 197, 0.1)"},childDef:{width:"100%"},blockWrap:{width:"100%",padding:"10px 0 0 0",display:"flex"},icon:{margin:"0 10px 0 0",width:"5vw",height:"5vw",borderRadius:"5px",boxShadow:"0 0px 4px 3px rgba(176, 190, 197, 0.1)"},textWrap:{width:"100%",padding:"20px",backgroundColor:"white",borderRadius:"5px",boxShadow:"0 0px 4px 3px rgba(176, 190, 197, 0.1)"},name:{fontSize:"24px",margin:"0 0 24px"},definition:{fontSize:"16px",margin:"16px 0"},example:{width:"100%"},spanStyle:{fontFamily:["Roboto","Helvetica","Arial","sans-serif"]},li:{fontFamily:["Roboto","Helvetica","Arial","sans-serif"],lineHeight:1.5,fontWeight:400,letterSpacing:"0.00938em"}}}));function Be(e){var t=e.icon,i=e.name,a=e.definition,r=e.advantages,s=e.disadvantages,o=e.suggestions,n=e.figure,l=Re();return Object(T.jsxs)("div",{className:l.blockWrap,children:[Object(T.jsx)("img",{src:t,className:l.icon}),Object(T.jsxs)("div",{className:l.textWrap,children:[Object(T.jsx)(m.a,{className:l.name,children:i}),Object(T.jsxs)(m.a,{className:l.definition,children:[Object(T.jsx)("b",{className:l.spanStyle,children:"Definition: "}),a]}),Object(T.jsx)("img",{src:n,className:l.example}),r.length>0?Object(T.jsx)("b",{className:l.spanStyle,children:"Advantages:"}):null,r.length>0?Object(T.jsx)("ol",{children:r.map((function(e){return Object(T.jsx)("li",{className:l.li,children:e})}))}):null,s.length>0?Object(T.jsx)("b",{className:l.spanStyle,children:"Disadvantages:"}):null,s.length>0?Object(T.jsx)("ol",{children:s.map((function(e){return Object(T.jsx)("li",{className:l.li,children:e})}))}):null,o.length>0?Object(T.jsx)("b",{className:l.spanStyle,children:"Observations:"}):null,o.length>0?Object(T.jsx)("ol",{children:o.map((function(e){return Object(T.jsx)("li",{className:l.li,children:e})}))}):null]})]})}var Ne=function(){var e=Re(),t=r.a.useState("juxtaposition"),i=Object(n.a)(t,2),a=i[0],s=i[1];return Object(T.jsx)("div",{className:e.root,children:Object(T.jsxs)("div",{className:e.content,children:[Object(T.jsx)(X.a,{className:e.tabs,value:a,indicatorColor:"primary",onChange:function(e,t){s(t)},centered:!0,children:Object.keys(Le).map((function(e){return Object(T.jsx)(Q.a,Object(l.a)({value:e,label:e},Le[e].name))}))}),""==Le[a].definition?null:Object(T.jsxs)("div",{className:e.parentDef,children:[Object(T.jsx)(m.a,{style:{fontSize:"24px",margin:"24px"},children:Le[a].name}),Object(T.jsxs)(m.a,{style:{fontSize:"16px",margin:"16px 24px 20px 24px"},children:[Object(T.jsx)("b",{className:e.spanStyle,children:"Definition: "}),Le[a].definition]}),Object(T.jsxs)("div",{style:{fontSize:"16px",margin:"16px 24px 20px 24px"},children:[Le[a].advantages.length>0?Object(T.jsx)("b",{className:e.spanStyle,children:"Common Observations:"}):null,Le[a].advantages.length>0?Object(T.jsx)("ol",{children:Le[a].advantages.map((function(t){return Object(T.jsx)("li",{className:e.li,children:t})}))}):null,Le[a].disadvantages.length>0?Object(T.jsx)("b",{className:e.spanStyle,children:"Common Disadvantages:"}):null,Le[a].disadvantages.length>0?Object(T.jsx)("ol",{children:Le[a].disadvantages.map((function(t){return Object(T.jsx)("li",{className:e.li,children:t})}))}):null,Le[a].suggestions.length>0?Object(T.jsx)("b",{className:e.spanStyle,children:"Common Suggestions:"}):null,Le[a].suggestions.length>0?Object(T.jsx)("ol",{children:Le[a].suggestions.map((function(t){return Object(T.jsx)("li",{className:e.li,children:t})}))}):null]})]}),Object(T.jsx)("div",{className:e.childDef,children:Le[a].subtypes.map((function(e){var t=e.id,i=e.name,a=e.definition,r=e.advantages,s=e.disadvantages,o=e.suggestions;return Object(T.jsx)(Be,{icon:""+"/patterns/".concat(t,"-icon.png"),name:i,definition:a,advantages:r,disadvantages:s,suggestions:o,figure:""+"/patterns/".concat(t,".png")})}))})]})})},Je=i(58),Ke=i(222),Ue=Object(h.a)((function(e){var t,i;return{App:{position:"relative",width:"100vw",height:"100vh",overflow:"hidden"},appBar:{height:"8%",width:"100%"},mainView:{width:"100%",height:"92%",display:"flex"},leftView:{width:"30%",height:"100%",boxShadow:"0 0px 4px 4px rgba(176, 190, 197, 0.48)"},rightView:{width:"70%",height:"100%"},root:{height:"8%",width:"100%",backgroundColor:"white",boxShadow:"0 0px 4px 4px rgba(176, 190, 197, 0.48)",display:"flex",justifyContent:"space-between",alignItems:"center",position:"relative",zIndex:"1"},buttonGroup:{padding:"20px",marginRight:"15px"},button:{fontSize:"20px"},heading:{fontFamily:"Helvetica, Arial, sans-serif",fontWeight:"bold",fontSize:"32px",padding:"30px",margin:"30px"},linkNoraml:(t={margin:"10px",padding:"20px",fontSize:"0.875em"},Object(c.a)(t,"fontSize","20px"),Object(c.a)(t,"letterSpacing","0.02875em"),Object(c.a)(t,"textTransform","none"),Object(c.a)(t,"paddingBottom",10),Object(c.a)(t,"color","black"),t),linkSelected:(i={margin:"10px",padding:"20px",fontSize:"0.875em"},Object(c.a)(i,"fontSize","20px"),Object(c.a)(i,"letterSpacing","0.02875em"),Object(c.a)(i,"textTransform","none"),Object(c.a)(i,"paddingBottom",10),Object(c.a)(i,"borderBottom","3px solid #3f51b5"),Object(c.a)(i,"color","#3f51b5"),i),logo:{margin:e.spacing(2,5),height:"3vh"},btnSelected:{padding:"12px",borderBottom:"2px solid #3f51b5"},btnNoraml:{padding:"12px"}}}));function Ye(e){e.icon;var t=e.primary,i=e.to,a=e.selectedLink,s=e.setSelectedLink,o=r.a.useMemo((function(){return r.a.forwardRef((function(e,t){return Object(T.jsx)(Ke.a,Object(l.a)({to:i,ref:t},e))}))}),[i]),n=Ue();return Object(T.jsx)(d.a,{style:{borderRadius:0},className:a===t?n.linkSelected:n.linkNoraml,onClick:function(){return s(t)},component:o,children:t})}var Ze,Xe,Qe,$e,et,tt,it,at,rt,st,ot,nt,lt,ct,ht,dt,pt,ut,gt,mt,yt,ft,vt,bt,wt,_t,xt,zt,kt,Tt,St,Ot,At,Vt,Ct,Dt,Mt,It,Wt,qt,Ft,Gt,jt,Pt,Et,Ht,Lt,Rt,Bt,Nt,Jt,Kt,Ut,Yt,Zt,Xt=Object(g.b)("d")(Object(g.c)((function(e){e.d;var t=Ue(),i=Object(a.useState)("Explorer"),r=Object(n.a)(i,2),s=r[0],o=r[1];return Object(T.jsx)(Je.a,{initialEntries:["/explorer"],initialIndex:0,children:Object(T.jsxs)("div",{className:t.App,children:[Object(T.jsxs)("div",{className:t.root,children:[Object(T.jsx)(m.a,{className:t.heading,children:"Composite Visualization"}),Object(T.jsxs)(p.a,{className:t.buttonGroup,children:[Object(T.jsx)(Ye,{to:"/explorer",primary:"Explorer",selectedLink:s,setSelectedLink:o}),Object(T.jsx)(Ye,{to:"/pattern",primary:"Design Patterns",selectedLink:s,setSelectedLink:o})]})]}),Object(T.jsxs)(Je.d,{children:[Object(T.jsx)(Je.b,{path:"/explorer",children:Object(T.jsxs)("div",{className:t.mainView,children:[Object(T.jsxs)("div",{className:t.leftView,children:[Object(T.jsx)(O,{}),Object(T.jsx)(L,{}),Object(T.jsx)(u.a,{}),Object(T.jsx)(K,{}),Object(T.jsx)(u.a,{}),Object(T.jsx)(pe,{})]}),Object(T.jsx)("div",{className:t.rightView,children:Object(T.jsx)(He,{})})]})}),Object(T.jsx)(Je.b,{path:"/pattern",children:Object(T.jsx)(Ne,{})})]})]})})}))),Qt=function(e){e&&e instanceof Function&&i.e(3).then(i.bind(null,411)).then((function(t){var i=t.getCLS,a=t.getFID,r=t.getFCP,s=t.getLCP,o=t.getTTFB;i(e),a(e),r(e),s(e),o(e)}))},$t=i(211),ei=i(35),ti=i(262),ii=i(36),ai=(i(337),i(226)),ri=i(15),si=i(227),oi=i(228),ni=Object.keys(oi).sort().reduce((function(e,t){return e[t]=oi[t],e}),{});function li(e,t,i){if("and"==i){var a,r=Object(ai.a)(t);try{for(r.s();!(a=r.n()).done;){var s=a.value;if(-1==e.indexOf(s))return!1}}catch(c){r.e(c)}finally{r.f()}return!0}if("or"==i){var o,n=Object(ai.a)(t);try{for(n.s();!(o=n.n()).done;){var l=o.value;if(e.indexOf(l)>-1)return!0}}catch(c){n.e(c)}finally{n.f()}return!1}}var ci=(Ze=ri.n.shallow,Xe=ri.n.deep,Qe=ri.n.deep,$e=function(){function e(t){Object($t.a)(this,e),Object(ei.a)(this,"authorsList",et,this),Object(ei.a)(this,"dataState",tt,this),Object(ei.a)(this,"filteredImagesData",it,this),Object(ei.a)(this,"imgList",at,this),Object(ei.a)(this,"zoomInState",rt,this),Object(ei.a)(this,"zoomInImgList",st,this),Object(ei.a)(this,"coOccurrenceData",ot,this),Object(ei.a)(this,"filterState",nt,this),Object(ei.a)(this,"imagesYearList",lt,this),Object(ei.a)(this,"filteredVisType",ct,this),Object(ei.a)(this,"detailsBar",ht,this),Object(ei.a)(this,"imgState",dt,this),Object(ei.a)(this,"heatmapData",pt,this),Object(ei.a)(this,"heatmapViewData",ut,this),Object(ei.a)(this,"indexToClient",gt,this),Object(ei.a)(this,"indexToHost",mt,this),Object(ei.a)(this,"detailsBarData",yt,this),Object(ei.a)(this,"searchedAuthorsList",ft,this),Object(ei.a)(this,"highlightIndexList",vt,this),Object(ei.a)(this,"resetImgState",bt,this),Object(ei.a)(this,"resetImagesYearList",wt,this),Object(ei.a)(this,"resetFilterState",_t,this),Object(ei.a)(this,"resetFilteredVisType",xt,this),Object(ei.a)(this,"resetHeatmapData",zt,this),Object(ei.a)(this,"resetDetailsBar",kt,this),Object(ei.a)(this,"updateImgList",Tt,this),Object(ei.a)(this,"updateSearchWords",St,this),Object(ei.a)(this,"updateFilteredImagesData",Ot,this),Object(ei.a)(this,"searchRequest",At,this),Object(ei.a)(this,"getImgDetails",Vt,this),Object(ei.a)(this,"loadData",Ct,this),this.getImageSize=function(e){return ni[e].img_size},Object(ei.a)(this,"updateImagesYearList",Dt,this),Object(ei.a)(this,"updateHeatmapData",Mt,this),Object(ei.a)(this,"updateHeatmapViewData",It,this),Object(ei.a)(this,"updateDetailsBarData",Wt,this),Object(ei.a)(this,"updateFilteredVisType",qt,this),Object(ei.a)(this,"changeFilterState",Ft,this),Object(ei.a)(this,"filterStateSelected",Gt,this),Object(ei.a)(this,"changeFilterYears",jt,this),Object(ei.a)(this,"changeFilterYearsCommit",Pt,this),Object(ei.a)(this,"changeFocusVisType",Et,this),Object(ei.a)(this,"transformDataFromRaw",Ht,this),Object(ei.a)(this,"transformVisualizationsFromRaw",Lt,this),Object(ei.a)(this,"transformRelationsFromRaw",Rt,this),Object(ei.a)(this,"activeSelectedImgState",Bt,this),Object(ei.a)(this,"closeSelectedImgState",Nt,this),Object(ei.a)(this,"changeImgId",Jt,this),Object(ei.a)(this,"changeFilterType",Kt,this),Object(ei.a)(this,"changeOverviewState",Ut,this),Object(ei.a)(this,"updateSearchAuthors",Yt,this),Object(ei.a)(this,"countPatterns",Zt,this),Object(ri.m)(this),this.root=t}return Object(ti.a)(e,[{key:"init",value:function(){this.resetFilterState(),this.resetImgState(),this.updateFilteredImagesData()}}]),e}(),et=Object(ii.a)($e.prototype,"authorsList",[Ze],{configurable:!0,enumerable:!0,writable:!0,initializer:function(){return si}}),tt=Object(ii.a)($e.prototype,"dataState",[Xe],{configurable:!0,enumerable:!0,writable:!0,initializer:function(){return{selectGalleryImg:!1,overviewState:"coOccurrence",overviewDetailState:!1,matrixColor:"#e46366"}}}),it=Object(ii.a)($e.prototype,"filteredImagesData",[ri.n],{configurable:!0,enumerable:!0,writable:!0,initializer:function(){return{}}}),at=Object(ii.a)($e.prototype,"imgList",[ri.n],{configurable:!0,enumerable:!0,writable:!0,initializer:function(){return[]}}),rt=Object(ii.a)($e.prototype,"zoomInState",[ri.n],{configurable:!0,enumerable:!0,writable:!0,initializer:function(){return{activate:!1,levelName:null,client:null,host:null}}}),st=Object(ii.a)($e.prototype,"zoomInImgList",[ri.n],{configurable:!0,enumerable:!0,writable:!0,initializer:function(){return[]}}),ot=Object(ii.a)($e.prototype,"coOccurrenceData",[ri.n],{configurable:!0,enumerable:!0,writable:!0,initializer:function(){return{}}}),nt=Object(ii.a)($e.prototype,"filterState",[Qe],{configurable:!0,enumerable:!0,writable:!0,initializer:function(){return{}}}),lt=Object(ii.a)($e.prototype,"imagesYearList",[ri.n],{configurable:!0,enumerable:!0,writable:!0,initializer:function(){return{}}}),ct=Object(ii.a)($e.prototype,"filteredVisType",[ri.n],{configurable:!0,enumerable:!0,writable:!0,initializer:function(){return{}}}),ht=Object(ii.a)($e.prototype,"detailsBar",[ri.n],{configurable:!0,enumerable:!0,writable:!0,initializer:function(){return{}}}),dt=Object(ii.a)($e.prototype,"imgState",[ri.n],{configurable:!0,enumerable:!0,writable:!0,initializer:function(){return{}}}),pt=Object(ii.a)($e.prototype,"heatmapData",[ri.n],{configurable:!0,enumerable:!0,writable:!0,initializer:function(){return{}}}),ut=Object(ii.a)($e.prototype,"heatmapViewData",[ri.n],{configurable:!0,enumerable:!0,writable:!0,initializer:function(){return[]}}),gt=Object(ii.a)($e.prototype,"indexToClient",[ri.n],{configurable:!0,enumerable:!0,writable:!0,initializer:function(){return{}}}),mt=Object(ii.a)($e.prototype,"indexToHost",[ri.n],{configurable:!0,enumerable:!0,writable:!0,initializer:function(){return{}}}),yt=Object(ii.a)($e.prototype,"detailsBarData",[ri.n],{configurable:!0,enumerable:!0,writable:!0,initializer:function(){return[]}}),ft=Object(ii.a)($e.prototype,"searchedAuthorsList",[ri.n],{configurable:!0,enumerable:!0,writable:!0,initializer:function(){return Object.keys(si)}}),vt=Object(ii.a)($e.prototype,"highlightIndexList",[ri.n],{configurable:!0,enumerable:!0,writable:!0,initializer:function(){return[]}}),bt=Object(ii.a)($e.prototype,"resetImgState",[ri.f],{configurable:!0,enumerable:!0,writable:!0,initializer:function(){var e=this;return function(){e.imgState={imgId:null,caption:null,abstract:null,visType:null,compType:null,title:null,authors:null,year:null,conference:null,img_size:null,subfigure:null,galleryScale:1,viewDimension:{width:1,height:1},imgSize:{width:1,height:1}}}}}),wt=Object(ii.a)($e.prototype,"resetImagesYearList",[ri.f],{configurable:!0,enumerable:!0,writable:!0,initializer:function(){var e=this;return function(){return e.imagesYearList={2006:0,2007:0,2008:0,2009:0,2010:0,2011:0,2012:0,2013:0,2014:0,2015:0,2016:0,2017:0,2018:0,2019:0,2020:0}}}}),_t=Object(ii.a)($e.prototype,"resetFilterState",[ri.f],{configurable:!0,enumerable:!0,writable:!0,initializer:function(){var e=this;return function(){e.filterState={compType:{repeated:!1,stacked:!1,mirrored:!1,large_view:!1,annotated:!1,coordinated:!1,accompanied:!1,nested:!1},visType:{arc_diagram:!1,area_chart:!1,bar_chart:!1,box_plot:!1,comb:!1,contour_graph:!1,chord_diagram:!1,donut_chart:!1,error_bar:!1,flow_diagram:!1,glyph_based:!1,graph:!1,heatmap:!1,line_chart:!1,matrix:!1,map:!1,others:!1,parallel_coordinate:!1,pie_chart:!1,polar_plot:!1,proportional_area_chart:!1,sankey_diagram:!1,scatterplot:!1,scivis:!1,sector_chart:!1,small_multiple:!1,storyline:!1,stripe_graph:!1,sunburst_icicle:!1,surface_graph:!1,table:!1,tree:!1,treemap:!1,unit_visualization:!1,vector_graph:!1,word_cloud:!1},conference:{InfoVis:!1,VAST:!1,SciVis:!1,Vis:!1},authors:e.authorsList,years:[2006,2020],searchWords:"",filterBarState:{compType:"All",visType:"All",conference:"All",authors:"All",searchState:"Search All"},filterType:{visType:"or",compType:"and",conference:"or",authors:"or"},searchState:{keywords:!0,title:!0,abstract:!0}}}}}),xt=Object(ii.a)($e.prototype,"resetFilteredVisType",[ri.f],{configurable:!0,enumerable:!0,writable:!0,initializer:function(){var e=this;return function(){e.filteredVisType={}}}}),zt=Object(ii.a)($e.prototype,"resetHeatmapData",[ri.f],{configurable:!0,enumerable:!0,writable:!0,initializer:function(){var e=this;return function(){e.heatmapData={},Object.keys(e.filteredVisType).forEach((function(t){e.heatmapData[t]={},Object.keys(e.filteredVisType).forEach((function(i){e.heatmapData[t][i]=[]}))}))}}}),kt=Object(ii.a)($e.prototype,"resetDetailsBar",[ri.f],{configurable:!0,enumerable:!0,writable:!0,initializer:function(){var e=this;return function(){e.detailsBar={show:!1,type:null,visType:null,select:null}}}}),Tt=Object(ii.a)($e.prototype,"updateImgList",[ri.f],{configurable:!0,enumerable:!0,writable:!0,initializer:function(){var e=this;return function(t,i){t=t||null,i=i||null,e.dataState.selectGalleryImg&&e.closeSelectedImgState();var a=e.heatmapData;if(null!==t&&null!==i)a=a[t][i];else if(null!==t&&null===i)a=a[t];else if(null===t&&null!==i){var r={};Object.keys(e.heatmapData).forEach((function(t,a){Object.keys(e.heatmapData[t]).forEach((function(a){a===i&&(a in r||(r[a]=[]),r[a]=[].concat(Object(U.a)(r[a]),Object(U.a)(e.heatmapData[t][a])))}))})),a=r}if(null===t||null===i){var s=[];Object.keys(a).forEach((function(e){s=s.concat(a[e])})),a=Array.from(new Set(s))}e.zoomInImgList=Array.from(new Set(a)),e.zoomInState={activate:!0,levelName:!1===e.dataState.overviewDetailState?e.dataState.overviewState:e.dataState.overviewDetailState,client:t,host:i}}}}),St=Object(ii.a)($e.prototype,"updateSearchWords",[ri.f],{configurable:!0,enumerable:!0,writable:!0,initializer:function(){var e=this;return function(t){e.filterState.searchWords=t}}}),Ot=Object(ii.a)($e.prototype,"updateFilteredImagesData",[ri.f],{configurable:!0,enumerable:!0,writable:!0,initializer:function(){var e=this;return function(){e.searchRequest(e.filterState)}}}),At=Object(ii.a)($e.prototype,"searchRequest",[ri.f],{configurable:!0,enumerable:!0,writable:!0,initializer:function(){var e=this;return function(t){e.imgList=function(e){var t=[],i=e.years,a=Object.keys(e.compType).filter((function(t){return!0===e.compType[t]})),r=Object.keys(e.authors).filter((function(t){return!0===e.authors[t]})),s=Object.keys(e.conference).filter((function(t){return!0===e.conference[t]})),o=Object.keys(e.visType).filter((function(t){return!0===e.visType[t]})),l=e.filterType,c=e.searchState,h=e.searchWords.toLowerCase();return h=""==h?[]:h.split(" "),Object.keys(ni).forEach((function(e){var d=ni[e],p=d.year>=i[0]&&d.year<=i[1];if(p&&h.length>0){for(var u=[],g=0,m=Object.entries(c);g<m.length;g++){var y=Object(n.a)(m[g],2),f=y[0];1==y[1]&&(u=[].concat(Object(U.a)(u),Object(U.a)(d[f].toLowerCase().split(" "))))}p=li(u,h,"and")}p&&a.length>0&&(p=li(d.compType,a,l.compType)),p&&r.length>0&&(p=li(d.authors,r,l.authors)),p&&s.length>0&&(p=li(d.conference,s,l.conference)),p&&o.length>0&&(p=li(d.visType,o,l.visType)),p&&t.push(e)})),t}(t),e.updateImagesYearList(),e.updateHeatmapData()}}}),Vt=Object(ii.a)($e.prototype,"getImgDetails",[ri.f],{configurable:!0,enumerable:!0,writable:!0,initializer:function(){var e=this;return function(t){e.loadData(ni[t]),e.transformDataFromRaw()}}}),Ct=Object(ii.a)($e.prototype,"loadData",[ri.f],{configurable:!0,enumerable:!0,writable:!0,initializer:function(){var e=this;return function(t){e.imgState.visType=t.visType,e.imgState.compType=t.compType,e.imgState.authors=t.authors,e.imgState.caption=t.caption,e.imgState.abstract=t.abstract,e.imgState.conference=t.conference,e.imgState.year=t.year,e.imgState.title=t.title,e.imgState.doi=t.doi,e.imgState.subfiguresRaw=t.subfigures,e.imgState.visualizationsRaw=t.visualizations,e.imgState.relationsRaw=t.relations,e.transformRelationsFromRaw()}}}),Dt=Object(ii.a)($e.prototype,"updateImagesYearList",[ri.f],{configurable:!0,enumerable:!0,writable:!0,initializer:function(){var e=this;return function(){e.resetImagesYearList(),e.imgList.forEach((function(t){e.imagesYearList[ni[t].year]+=1})),e.updateFilteredVisType()}}}),Mt=Object(ii.a)($e.prototype,"updateHeatmapData",[ri.f],{configurable:!0,enumerable:!0,writable:!0,initializer:function(){var e=this;return function(){e.resetHeatmapData(),e.resetDetailsBar(),e.patternCnt=0;var t=["repeated","stacked","mirrored"],i=["large_view","annotated","coordinated","accompanied"],a=["nested"];document.getElementById("heatmap_wrap")&&(document.getElementById("heatmap_wrap").style.height="90%"),"coOccurrence"===e.dataState.overviewState?e.imgList.forEach((function(t){ni[t].coOccurrence.forEach((function(i){i[0]in e.filteredVisType&&i[1]in e.filteredVisType&&e.heatmapData[i[0]][i[1]].push(t)}))})):e.imgList.forEach((function(r){ni[r].comp.forEach((function(s){var o=function(e,t){return e.filter((function(e){return t.indexOf(e)>-1})).length};if(!1!==e.dataState.overviewDetailState){if(0===o([e.dataState.overviewDetailState],s[2]))return}else{if("juxtaposed"===e.dataState.overviewState&&0===o(t,s[2]))return;if("overlaid"===e.dataState.overviewState&&0===o(i,s[2]))return;if("nested"===e.dataState.overviewState&&0===o(a,s[2]))return}e.heatmapData[s[0]][s[1]].push(r)}))})),Object.keys(e.heatmapData).forEach((function(t){Object.keys(e.heatmapData[t]).forEach((function(i){e.heatmapData[t][i]=Array.from(new Set(e.heatmapData[t][i]))}))})),e.updateHeatmapViewData()}}}),It=Object(ii.a)($e.prototype,"updateHeatmapViewData",[ri.f],{configurable:!0,enumerable:!0,writable:!0,initializer:function(){var e=this;return function(){e.heatmapViewData=[],e.indexToClient={},e.indexToHost={},Object.keys(e.heatmapData).forEach((function(t,i){e.indexToClient[i]=t,e.heatmapViewData=e.heatmapViewData.concat(Object.keys(e.heatmapData[t]).map((function(a,r){return e.indexToHost[r]=a,[i,r,e.heatmapData[t][a].length]})))}))}}}),Wt=Object(ii.a)($e.prototype,"updateDetailsBarData",[ri.f],{configurable:!0,enumerable:!0,writable:!0,initializer:function(){var e=this;return function(){e.detailsBarData=[],e.heatmapViewData.forEach((function(t){var i=t[0],a=t[1],r=t[2];e.detailsBar.show&&("Child"===e.detailsBar.type&&e.indexToClient[i]===e.detailsBar.visType?e.detailsBarData.push({num:r,idx:a}):"Parent"===e.detailsBar.type&&e.indexToHost[a]===e.detailsBar.visType&&e.detailsBarData.push({num:r,idx:i}))})),e.detailsBarData.sort((function(e,t){return e.num>t.num?1:t.num>e.num?-1:0}))}}}),qt=Object(ii.a)($e.prototype,"updateFilteredVisType",[ri.f],{configurable:!0,enumerable:!0,writable:!0,initializer:function(){var e=this;return function(){e.resetFilteredVisType(),e.dataState.overviewState,e.imgList.forEach((function(t){ni[t].comp.forEach((function(t){[t[0],t[1]].forEach((function(t){t in e.filteredVisType||(e.filteredVisType[t]=0),e.filteredVisType[t]+=1}))}))}));var t={};Object.keys(e.filteredVisType).sort().forEach((function(i){t[i]=e.filteredVisType[i]})),e.filteredVisType=t}}}),Ft=Object(ii.a)($e.prototype,"changeFilterState",[ri.f],{configurable:!0,enumerable:!0,writable:!0,initializer:function(){var e=this;return function(t,i){if("All"===i&&e.filterStateSelected(t)!==Object.keys(e.filterState[t]).length?Object.keys(e.filterState[t]).forEach((function(i){e.filterState[t][i]=!0})):"All"===i?Object.keys(e.filterState[t]).forEach((function(i){e.filterState[t][i]=!1})):"All"!==i&&(e.filterState[t][i]=!e.filterState[t][i]),e.filterStateSelected(t)===Object.keys(e.filterState[t]).length)e.filterState.filterBarState[t]="All";else{e.filterState.filterBarState[t]="".concat("Part")}"searchState"===t&&(e.filterState.filterBarState[t]="Search ".concat(e.filterState.filterBarState[t])),e.updateFilteredImagesData(),e.updateImagesYearList(),e.updateHeatmapData()}}}),Gt=Object(ii.a)($e.prototype,"filterStateSelected",[ri.f],{configurable:!0,enumerable:!0,writable:!0,initializer:function(){var e=this;return function(t){var i=0;return Object.keys(e.filterState[t]).forEach((function(a){("or"===e.filterState.filterType.compType&&"coOccurrence"===a||e.filterState[t][a])&&(i+=1)})),i}}}),jt=Object(ii.a)($e.prototype,"changeFilterYears",[ri.f],{configurable:!0,enumerable:!0,writable:!0,initializer:function(){var e=this;return function(t,i){e.filterState.years=i}}}),Pt=Object(ii.a)($e.prototype,"changeFilterYearsCommit",[ri.f],{configurable:!0,enumerable:!0,writable:!0,initializer:function(){var e=this;return function(){e.updateFilteredImagesData(),e.updateImagesYearList(),e.updateHeatmapData()}}}),Et=Object(ii.a)($e.prototype,"changeFocusVisType",[ri.f],{configurable:!0,enumerable:!0,writable:!0,initializer:function(){return function(){}}}),Ht=Object(ii.a)($e.prototype,"transformDataFromRaw",[ri.f],{configurable:!0,enumerable:!0,writable:!0,initializer:function(){var e=this;return function(){var t=e.imgState.imgId.split(".")[0],i=e.imgState.viewDimension,a=e.imgState.imgSize;["img_size"].forEach((function(i){e.imgState[i]=ni[t].img_size[i]})),e.imgState.subfigures=e.imgState.subfiguresRaw.map((function(e,t){var r=parseInt(e.id.replace(e.type+"-",""));return{x:e.x/a.width*i.width,y:e.y/a.height*i.height,width:e.width/a.width*i.width,height:e.height/a.height*i.height,stroke:"#000000",opacity:"0.5",dash:[50,15],dashEnable:!0,strokeWidth:5,id:e.id,numId:r,type:e.type}}))}}}),Lt=Object(ii.a)($e.prototype,"transformVisualizationsFromRaw",[ri.f],{configurable:!0,enumerable:!0,writable:!0,initializer:function(){var e=this;return function(t,i,a){var r,s,o,n,l=i||"balanced",c=t.relation||a,h=e.imgState.viewDimension,d=e.imgState.imgSize,p=function e(t,i){return"string"===typeof t?i.push(t):"balanced"===l?t.vislist.forEach((function(t){t.vislist.forEach((function(t){i=e(t,i)}))})):(l="balanced",t.vislist.forEach((function(t){i=e(t,i)}))),i}(t,[]),u=!1;e.imgState.visualizationsRaw.forEach((function(e,t){p.indexOf(e.id)>-1&&(!1===u?(r=e.x,s=e.y,o=e.x+e.width,n=e.y+e.height,u=!0):(o=Math.max(o,e.x+e.width),n=Math.max(n,e.y+e.height),r=Math.min(r,e.x),s=Math.min(s,e.y)))})),e.imgState.visualizations=[{x:r/d.width*h.width,y:s/d.height*h.height,width:(o-r)/d.width*h.width,height:(n-s)/d.height*h.height,stroke:W[c],strokeWidth:5,id:"vis",numId:0,type:"type"}]}}}),Rt=Object(ii.a)($e.prototype,"transformRelationsFromRaw",[ri.f],{configurable:!0,enumerable:!0,writable:!0,initializer:function(){var e=this;return function(){e.imgState.relations=e.imgState.relationsRaw.map((function(e){return e}))}}}),Bt=Object(ii.a)($e.prototype,"activeSelectedImgState",[ri.f],{configurable:!0,enumerable:!0,writable:!0,initializer:function(){var e=this;return function(t){e.dataState.selectGalleryImg=!0,t!==e.imgState.imgId&&(e.imgState.subfigures=null,e.imgState.visualizations=null),e.imgState.imgId=t}}}),Nt=Object(ii.a)($e.prototype,"closeSelectedImgState",[ri.f],{configurable:!0,enumerable:!0,writable:!0,initializer:function(){var e=this;return function(){e.dataState.selectGalleryImg=!1,e.resetImgState(),document.getElementById("gallery_wrap").style.width="99%"}}}),Jt=Object(ii.a)($e.prototype,"changeImgId",[ri.f],{configurable:!0,enumerable:!0,writable:!0,initializer:function(){var e=this;return function(t){var i=e.imgList.indexOf(e.imgState.imgId),a=t+i;a<0||a>=e.imgList.length||(e.imgState.imgId=e.imgList[i+t],e.imgState.subfigures=null,e.imgState.visualizations=null,e.activeSelectedImgState(e.imgState.imgId))}}}),Kt=Object(ii.a)($e.prototype,"changeFilterType",[ri.f],{configurable:!0,enumerable:!0,writable:!0,initializer:function(){var e=this;return function(t,i){i!==e.filterState.filterType[t]&&(e.filterState.filterType[t]=i,e.updateFilteredImagesData(),e.updateImagesYearList(),e.updateHeatmapData())}}}),Ut=Object(ii.a)($e.prototype,"changeOverviewState",[ri.f],{configurable:!0,enumerable:!0,writable:!0,initializer:function(){var e=this;return function(t){e.dataState.overviewState=t,e.dataState.matrixColor={coOccurrence:"#e46366",juxtaposed:"#1f77b4",overlaid:"#ef8536",nested:"#519c3e"}[t],e.updateFilteredVisType(),e.updateHeatmapData()}}}),Yt=Object(ii.a)($e.prototype,"updateSearchAuthors",[ri.f],{configurable:!0,enumerable:!0,writable:!0,initializer:function(){var e=this;return function(t){e.searchedAuthorsList=Object.keys(e.authorsList).map((function(e){if(e.toLowerCase().indexOf(t.toLowerCase())>=0)return e})).filter((function(e){return e&&e.trim()})),console.log(e.searchedAuthorsList)}}}),Zt=Object(ii.a)($e.prototype,"countPatterns",[ri.f],{configurable:!0,enumerable:!0,writable:!0,initializer:function(){var e=this;return function(){var t=0;return e.imgList.forEach((function(i){e.filteredImagesData[i].comp.forEach((function(e){e[2].indexOf("coOccurrence")>-1?t+=e[2].length-1:t+=e[2].length}))})),t}}}),$e),hi=new function e(){Object($t.a)(this,e),this.d=new ci(this),this.d.init()};o.a.render(Object(T.jsx)(g.a,{d:hi.d,children:Object(T.jsx)(Xt,{})}),document.getElementById("root")),Qt()},82:function(e){e.exports=JSON.parse('{"juxtaposition":{"name":"Juxtaposition","definition":"In a juxtaposition visualization, the components have no overlapping and are positioned side-by-side. Please note that, although a user interface (UI) may also consist of visualizations without overlapping, it is not considered a juxtaposition visualization in the context of this study. The component interrelationships in a UI are considerably looser than those in a juxtaposition visualization. As a rule of thumb, we consider a UI an arbitrary placement of visualizations or interface components (e.g., buttons, sliders, and progress bars) and only extract the visualizations for this study.","subtypes":[{"id":"repeated","name":"Repetition","definition":"Repetition refers to the juxtaposition visualizations which are of the same structure (visualization type or composite visualization), but their components are not symmetrical with respect to coordinate axes. ","advantages":["The visual similarity of repetition components provides a strong visual hint of grouping.","Repetition visualizations are easy for users to compare and find anomalies.","Repetition visualizations are easy to implement because codes can be reused conveniently."],"disadvantages":["It is difficult to compare when the number of components gets large.","Because of the same appearance of components, users may directly compare visual properties, such as size and position, without a careful reference to the scales and attributes of individual components, leading to incorrect insights."],"suggestions":["Keeping the component number between 2 and 8 in a repetition visualization is the most popular. When using it as the main view for analysis, the number is even fewer ([2,4))","In many examples, it tends to omit unnecessary visual elements to reduce visual clutter. For example, using a shared axis and removing duplicated marks for saving space and assisting comparison."]},{"id":"mirrored","name":"Mirror","definition":"Mirror pattern refers to symmetrically placing two components of the same structure with respect to an coordinate axis. Two components have the same scale on both sides of an axis of symmetry.","advantages":["Taking advantage of people\'s experience with mirror reflections, mirror visualizations imply identical objects and invite people to compare the mirror two components","Mirror visualizations are aesthetically pleasing because of symmetry. From the samples, we discover that in some cases, mirror visualizations are adopted as a part of a symmetrical design."],"disadvantages":["Mirror visualizations only support comparing two data series.","Because of the symmetry layout, it is more difficult to discover precise differences between components."],"suggestions":["Mirror visualizations might not be a good choice when the main design goal is precise comparison, but they can be used as auxiliary components within a symmetric design. When using mirror visualizations, a number of designs use an explicit encoding to represent the difference or hide the redundant elements."]},{"id":"stacked","name":"Stack","definition":"Components of different types or structures are aligned or concatenated by the same data items or a shared margin (e.g., axis) in a stack visualization.Please note that, although a repetition visualization may also have a shared axis, stack visualizations are different in terms of representation and usage.First, the components in a stack visualization are often different, while components in a repetition visualization are strictly homogeneous. Second, a repetition visualization is mainly used for visual comparison in a space-efficient manner, while a stack visualization more focuses on presenting different facets of the same data in an interconnected manner.","advantages":["A stack visualization can present different aspects of the same data at the same time in a compact manner.","Relationships between two stack components are maintained by a shared axis or shared visual items. Users can conveniently switch back and forth between components to explore the data because of such visual continuity."],"disadvantages":["The visual continuity is reduced when the number of items or the distance between aligned items increases."],"suggestions":["A visualization could be created by connecting different charts for better visual coherence using intermediate components if the back-end data of the charts are related. In this case, stacking multiple visualizations along the same direction or using a grid layout could improve space usage.","When the number of aligned items is large or the alignments obscure, visual hints are used to indicate the relationships, such as color encoding, highlighting-on-hover, or visual links."]}],"advantages":["Compared to overlay and nesting patterns where visual components are overlay on or contained by other components, juxtaposition visualizations offer a flexible and clear layout for visual components without visual occlusions."],"disadvantages":[],"suggestions":[]},"overlay":{"name":"Overlay","definition":"In an overlay visualization, visual components are overlaid over other components.","subtypes":[{"id":"accompanied","name":"Co-Axis","definition":"Component visualizations share the same coordinate system in a co-axis visualization.","advantages":["A co-axis visualization places multiple components in the same coordinate system to facilitate direct comparison and pattern recognition."],"disadvantages":[],"suggestions":["Overlaid components might use transparency to reduce occlusion or put summary/important components on the top. For example, placing box plots on top of a scatterplot for anomaly detection tasks.","A number of designs adopt multiple coordinate systems in a co-axis visualization, which might introduce potential biases."]},{"id":"coordinated","name":"Coordinate","definition":"In a visualization with coordinate design patterns, parent components provide coordinates (e.g., Cartesian coordinate system, geographic coordinate system, and other reference systems such as grids of the matrix) for child components (or their visual elements). The reference systems are regarded to be part of the parent components. In other words, the positions of child components encode back-end spatial data referring to the parent component.","advantages":["Compared with components of a co-axis visualization that have independent but identical coordinate systems, the layout of child components is determined by their parent components in coordinate visualizations. Therefore, they are effective in helping users interpret child components in the context of a parent component."],"disadvantages":[],"suggestions":["Various designs choose to combine a parent component that provides spatial context and child components whose visual elements do not encode spatial information, such as word cloud and proportional area charts.","In addition to the inevitable occlusions between child components and parent components, the overlapping between the child components may exacerbate the overall occlusions."]},{"id":"annotated","name":"Annotation","definition":"Child components of small size are overlaid on parent components and connected to elements of parent components in annotation visualizations, but the positions of child components do not encode spatial information. Moreover, the child components provide a ``cut-out\'\' lens for the visual elements connected.","advantages":["The advantage of annotated visualizations is the flexibility in positioning child components."],"disadvantages":[],"suggestions":["In most cases, only details of focused data items are visualized following the rule of details on demand.","In some designs, the positions of child components are organized using layout optimization models (e.g., saliency-based method) to utilize empty space and reduce line crossings."]},{"id":"large-panel","name":"Large Panel","definition":"Child components of small size overlay directly on parent components without visual links in a large panel visualization, and the positions of child components do not encode spatial information. Unlike annotations, large panels do not connect child and parent components using links or anchors and the child components show details of the parent components in an overview + detail manner.","advantages":["Compared with annotated visualizations, large-panel visualizations offer even more flexibility for placing child components, since they do not require any anchoring points in the parent component."],"disadvantages":[],"suggestions":["For large-panel visualizations, they generally place child components at positions where elements are less important (such as corners) to mitigate visual occlusion."]}],"advantages":["Compared with juxtaposition visualizations, an overlay visualization often has a more compact layout.","Overlay visualizations can directly represent the correspondences between different components, thus enhancing the visual effect."],"disadvantages":["A common disadvantage of overlay visualizations is occlusions, compared with juxtaposition visualizations and nesting visualizations."],"suggestions":["When designing an overlay visualization, it would be better to use clutter reduction techniques (e.g., edge bundling) to improve the visual appearance."]},"nesting":{"name":"Nesting","definition":"","subtypes":[{"id":"nesting","name":"Nesting","definition":"In nesting visualizations, some components (denoted by child components) are embedded into the visual elements or internal area of other components (denoted by parent components)","advantages":["Nesting visualizations have no occlusions between parent and child components and imply a hierarchical information, compared to overlay visualizations. Nesting visualizations are well-suited to visualize the overview while maintaining simple details of the child items (e.g., graph nodes and matrix cells).","Nesting visualizations are more compact than overlay visualizations and juxtaposition visualizations."],"disadvantages":[],"suggestions":["A number of designs choose to use relatively common/simple visualizations in child components, such as bar charts and heatmaps. We infer that this is because visualizations with complex configurations are hard to identify due to the limited space of child components.","A number of designs apply geometric transformations to the elements of parent components to make room for child components. For example, Sun et al. proposed a route-zooming technique to distort the map for hosting visualizations for spatio-temporal information."]}],"advantages":[""],"disadvantages":[],"suggestions":[]}}')}},[[338,1,2]]]);
//# sourceMappingURL=main.2ac4486d.chunk.js.map